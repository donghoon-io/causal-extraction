<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Bayesian Framework for Learning Proactive Robot Behaviour in Assistive Tasks</title>
				<funder ref="#_GtS3YG5">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_ZffQRfg">
					<orgName type="full">Italian Ministry for Universities and Research</orgName>
					<orgName type="abbreviated">MUR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>PAL</roleName><forename type="first">Antonio</forename><surname>Andriella</surname></persName>
							<email>antonio.andriella@pal-robotics.com</email>
						</author>
						<author>
							<persName><forename type="first">Robotics</forename><forename type="middle">(</forename><surname>Spain</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Antonio</forename><surname>Origlia</surname></persName>
							<email>antonio.origlia@unina.it</email>
						</author>
						<author>
							<persName><forename type="first">Silvia</forename><surname>Rossi</surname></persName>
							<email>silvia.rossi@unina.it</email>
						</author>
						<author>
							<persName><forename type="first">Ilenia</forename><surname>Cucciniello</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Information Technologies</orgName>
								<orgName type="institution" key="instit1">Ilenia Cucciniello University of Naples Federico II</orgName>
								<orgName type="institution" key="instit2">University of Naples Federico II</orgName>
								<orgName type="institution" key="instit3">University of Naples Federico II</orgName>
								<orgName type="institution" key="instit4">University of Naples Federico II</orgName>
								<address>
									<settlement>Napoli</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Interdepartmental Center for Advances in Robotic Surgery</orgName>
								<orgName type="institution">University of Naples Federico II</orgName>
								<address>
									<settlement>Napoli</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Bayesian Framework for Learning Proactive Robot Behaviour in Assistive Tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.21203/rs.3.rs-3845717/v1</idno>
					<note type="submission">Received: date / Accepted: date</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Assistive Robotics, Proactive Behaviour, In uence Diagrams Assistive Robotics</term>
					<term>Proactive Behaviour</term>
					<term>Influence Diagrams</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Noname manuscript No.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Socially assistive robots (SAR) are designed to help vulnerable user populations, such as those who are undergoing rehabilitation, therapy, or require lifelong assistance. They can perform a variety of tasks, including reminding users to take medication <ref type="bibr" target="#b15">(Di Napoli et al., 2023)</ref>, encouraging physical activity <ref type="bibr" target="#b17">(Fasola and Mataric, 2010)</ref>, providing cognitive training <ref type="bibr" target="#b36">(Maggi et al., 2021)</ref>, and offering social and emotional support <ref type="bibr" target="#b44">(Rossi et al., 2020)</ref>. To account for the variability in tasks and users' behaviours, researchers are focusing on the role of the robot's adaptive behaviour. This involves the robot learning and performing behaviours that are tailored to meet the needs and preferences of different users, as well as adapting to different social situations and roles. <ref type="bibr" target="#b0">(Ahmad et al., 2017)</ref>. Indeed, adaptability is a crucial element when designing robots that are aimed to interact with humans. For instance, in elderly care, robots need to adapt to the cognitive and physical capabilities of older adults <ref type="bibr" target="#b2">(Andriella et al., 2022)</ref>. Likewise, in education, robots are requested to tailor their behaviour to children to improve their learning performance <ref type="bibr" target="#b1">(Ahmad et al., 2019)</ref>. Nonetheless, most robotic systems are purely reactive to human inputs or triggering events. In many contexts, robots need to adopt proactive behaviour and learn when to intervene <ref type="bibr" target="#b50">(Sirithunge et al., 2019)</ref>.</p><p>Proactivity can be defined as the ability to identify the requirements of situations, such as the user's needs or intentions, and to act in advance, without external instructions. This requires the robot to take the initiative by anticipating such needs and autonomously decide to perform a specific action <ref type="bibr" target="#b33">(Liu et al., 2018)</ref> to prevent negative outcomes in case of a problematic situation or to improve the performance of the human-robot team <ref type="bibr" target="#b45">(Rozo et al., 2016)</ref>. Moreover, the selection of the correct time in which to act is a fundamental part of human-human social interaction, as well as of human-robot interaction (HRI), especially for the quality of collaborative tasks <ref type="bibr" target="#b24">(Hoffman et al., 2014)</ref> and to avoid being intrusive or annoying. Indeed, acting too early or failing to act because it is too late can harm interaction. Despite its relevance in robotics, only a few studies have investigated the appropriate timing for robots to take action, with the majority of research focusing only on the prediction and recognition of human behaviour to select the proper action for anticipation. Moreover, the majority of these works rely on Wizard of Oz (WoZ) techniques to regulate proactive behaviour, in which human operators control the robots. And, only a handful of studies have developed computational approaches based on AI, in which the robot learns when to intervene autonomously or directly learns proactivity from humans. Finally, according to <ref type="bibr" target="#b30">(Kraus et al., 2020)</ref> adaptation and proactivity are also linked to the possibility of achieving a specific goal with different degrees of autonomy since this has an impact on the users' perception and trust in the assistive tool. When dealing with HRI this also implies the possibility of achieving the same goal, performing the same actions, but in different ways <ref type="bibr" target="#b14">(Dautenhahn, 2007)</ref>. This modulation of the actions might arise, for example, by leveraging on non-functional parameters of actions <ref type="bibr" target="#b15">(Di Napoli et al., 2023)</ref>, such as speed, Fig. <ref type="figure">1</ref>: Illustration of the learning pipeline in two learning phases. The "Proactive Robot with Confidence" is related to the use case chosen for testing. trajectories, as well as non-verbal behaviour <ref type="bibr" target="#b36">(Maggi et al., 2021)</ref>. In the case of dialogue systems, different degrees of proactive behaviours might arise from how to communicate the need for an intervention, for example, by providing a notification or a suggestion about an action or by acting directly without any communicative act. Indeed, it is necessary to explore how robots must identify the requirements of a situation and learn their way of acting more and more confidently according to the current situational awareness. Consequently, different proactive strategies may be possible.</p><p>In this work, we intend to investigate how robots could be endowed with proactive behaviour to predict the users' needs and support them in assistive tasks. We want to overcome the main limitation of WoZ settings and to propose a definition of a computational approach that can be used for incrementally learning what assistance, when humans require it, and how confidently the robot should take control and intervene. Hence, the final goal is to learn an Influence Diagram (ID) <ref type="bibr" target="#b40">(Pawlak, 2004</ref>) that represents an extension of Bayesian networks, used to model decision-making problems based on uncertain information with the criterion of maximum expected utility. To this end, we devised a data-driven framework, which can be generalised to any type of assistive task and consists of a pipeline of different learning phases (in our case two) (see Figure <ref type="figure">1</ref>) to learn incrementally the different facets of the needed proactive behaviour. Each phase requires a different data collection in which users are requested to interact with a peer, i.e., either a virtual robot or a real one. Specifically, in the first phase, namely Learning to be Proactive, we request users to interact with a virtual-screen robot from which assistance can be requested to learn what assistance users need and when they request it. Since we want to understand what variables influence user requests and whether these depend on a user model, we ask users to complete a question-naire before the execution of the assistive task. In the second phase, namely Learning to be Proactive with Confidence, we request users to interact with a proactive virtual-screen robot to learn the confidence level of the robot's actions. Specifically, such a proactive robot is trained with the data collected in the previous phase and is able to decide when and what assistance to provide, providing it with random confidence. Finally, the resulting IDs are used to model the behaviour of a Furhat robot in an assistive task. The resulting framework has been tested by comparing the proactive behaviour learnt during the learning pipeline (Proactive Robot), which can determine what, when, and how confidently to assist users, with an assistive behaviour that is randomly generated (Non-Proactive Robot). With this experiment, we aim to investigate the following research question:</p><p>-Would the robot, endowed with an ID's decision system, be capable of providing proactive assistance to the users based on their individual needs? and if so, would that have an impact on their performance as well as on their overall perception?</p><p>The results of the study showed that participants who interacted with the assistance of the proactive robot performed better than those who interacted with the non-proactive robot. This is reflected in achieving higher scores, with fewer mistakes, while also asking for fewer additional interventions from the robot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Adaptivity is a key characteristic of robots that are requested to interact with humans. Indeed, if a robot can change its behaviour according to the user's individual needs <ref type="bibr" target="#b0">(Ahmad et al., 2017)</ref>, this adaptation can have a direct effect on the quality of the interaction <ref type="bibr" target="#b27">(Ikemoto et al., 2012)</ref>, the acceptance of the robot <ref type="bibr" target="#b45">(Rossi et al., 2023)</ref> and the user's overall engagement <ref type="bibr" target="#b51">(Szafir and Mutlu, 2012)</ref>. While adapting to the specific needs of the user is very important, knowing when to act in an anticipatory way and with what confidence are additional characteristics that robots should have. In this section, we report the most representative works on designing adaptive (see Section 2.1) and proactive robots (see Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Adaptive Robots</head><p>In the literature, different Artificial Intelligence (AI) approaches have been used to develop robots that can adapt their behaviour according to the users' preferences. Some researchers has employed Reinforcement Learning (RL) in which the system is requested to learn from its experience with the environment and take suitable action in it to maximise the cumulative reward <ref type="bibr" target="#b51">(Sutton and Barto, 2018)</ref>. <ref type="bibr" target="#b10">Clabaugh et al. (2019)</ref> designed a framework that used RL for long-term personalisation of a SAR as support in mathematical tasks for children with autism spectrum disorders. <ref type="bibr" target="#b43">Ritschel and André (2017)</ref> proposed a real-time learning process using RL and social signals to adapt to human preferences. <ref type="bibr" target="#b8">Chan and Nejat (2012)</ref> designed a control architecture that enabled the robot to be a motivator in cognitive training activities. In their work, they used a hierarchical RL approach to allow the robot to learn increasingly appropriate assistive behaviours and personalise the interaction based on their performance. <ref type="bibr" target="#b23">Hemminghaus and Kopp (2017)</ref> investigated the use of RL for the generation of assistive robot social behaviour in an adaptive way to learn when and how to guide the attention of users in solving a memory game. However, the RL approach is not transparent by nature and may take time to converge based on the space of states. Our approach turns out to be different in that ID enhances a transparent decision process based on what it believes is most useful to the user in that state, maximising the expected utility.</p><p>While RL attempts to learn the optimal policy given a reward function, Learning from Demonstration (LfD) is a paradigm in which robots acquire new skills by learning from demonstrations provided by an expert <ref type="bibr" target="#b46">(Schaal, 1996)</ref>. <ref type="bibr" target="#b38">Moro et al. (2018)</ref> developed an architecture that combined RL and LfD algorithms, obtaining a time reduction required to teach SARs new personalised behaviours. <ref type="bibr" target="#b34">Louie and Nejat (2020)</ref> presented an LfD system that allowed SARs to learn personalised group recreational activities from caregivers. In the context of LfD, Inverse Reinforcement Learning (IRL) aims at estimating the reward function of a Markov Decision Process (MDP) given humans' demonstrations encoded as policies <ref type="bibr" target="#b26">(Hussein et al., 2019)</ref>. <ref type="bibr" target="#b2">Andriella et al. (2022)</ref> developed a framework based on LfD through IRL which by combining therapist's demonstrations and their expertise on the patient's cognitive and physical abilities was capable of learning personalised assistance that fits with users' unique needs. <ref type="bibr" target="#b55">Woodworth et al. (2018)</ref> proposed a Repeated IRL based on maximum-margin methods to learn a reward function. The system must infer user preferences based only on observation of user behaviour in different tasks. In our case, the system acquires the ability to estimate users' needs -in terms of what assistance to provide and when -based on game matches made by users in the first learning phase. However, the decision is made in combination with utility functions, which are already defined and do not have to be estimated, unlike the reward function in the IRL.</p><p>A similar approach to RL is Interactive Reinforcement Learning (IntRL) which enables one to learn from the environment's observations but also from feedback or advice provided by a human (Arzate <ref type="bibr" target="#b3">Cruz and Igarashi, 2020)</ref>. <ref type="bibr" target="#b54">Tsiakas et al. (2016)</ref> extended the RL framework by adding as communication channels the feedback, provided by the user, and the guidance, provided by the supervisor, aiming to learn from primary and secondary users as the agent interacts with them in a robot-assisted therapy context. <ref type="bibr" target="#b29">Knox and Stone (2009)</ref> introduced a framework that modelled agent policy through reinforcement signals from a human trainer and used its model by choosing the actions that were expected to be most reinforced. <ref type="bibr" target="#b35">MacGlashan et al. (2017)</ref> developed an algorithm for learning from human feedback, which considered it dependent on the agent's current policy and used it to model the policy itself. Similar to this approach, our learning process is driven by user feedback in that the confidence level generated randomly in phase two, is modelled in phase three based on the action taken by the user. However, in our approach, such a process is carried out offline, after the data collection.</p><p>Finally, other research is based on the Bayesian Network (BN), a probabilistic graphical model for representing knowledge in situations of uncertainty <ref type="bibr" target="#b41">(Pearl, 1988)</ref>. For instance, <ref type="bibr" target="#b47">(Schadenberg et al., 2017)</ref> designed a BN that adapted the difficulty of a game to the child's skill level to personalise the game's progress. Similarly, <ref type="bibr" target="#b19">(Gordon and Breazeal, 2015)</ref> implemented in a robot tutor a Bayesian active learning process that assessed the children's word-reading skills and adapted the interaction to each child's specific skill. <ref type="bibr" target="#b48">Schodde et al. (2017)</ref> presented a system, designed on Bayesian Knowledge Tracing <ref type="bibr" target="#b11">(Corbett and Anderson, 1994)</ref> for language learning, to model the child's overall knowledge and to decide which skill the robot has to teach next. Similarly to <ref type="bibr" target="#b48">Schodde et al. (2017)</ref>, our approach is based on BN but we adopt a generalised version of BNs designed to solve, not only inference problems but also decision-making processes, specifically we use Influence Diagrams <ref type="bibr" target="#b25">(Howard and Matheson, 2005)</ref>. This is implemented by adding two special types of nodes representing actions that can be taken and their corresponding utility given the probability of the involved observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Proactive Robots</head><p>In the current research, proactivity has been focused on two main aspects: deciding when to approach humans <ref type="bibr" target="#b18">(Garrell et al., 2017;</ref><ref type="bibr" target="#b28">Kato et al., 2015)</ref> and establishing when to support them in assistive tasks <ref type="bibr" target="#b20">(Grosinger et al., 2016;</ref><ref type="bibr" target="#b31">Kraus et al., 2021;</ref><ref type="bibr" target="#b33">Liu et al., 2018)</ref>. Our work focuses on the latter, aiming to develop a computation model that can anticipate and predict users' needs to support them in assistive tasks.</p><p>Regarding the works featured in the first category, <ref type="bibr" target="#b28">Kato et al. (2015)</ref> developed an algorithm that predicts the intentions of pedestrians and uses this information to model a robot's respectful approach in a physical shopping mall. Similarly, <ref type="bibr" target="#b18">Garrell et al. (2017)</ref> made use of proxemics rules to learn the robot's proactive behaviour for approaching people in real-world settings and establishing friendly interaction with them.</p><p>For the second category, <ref type="bibr" target="#b20">Grosinger et al. (2016)</ref> developed a framework to make robots proactive by providing them with the ability to plan whether to act (condition), how (what action), and when (in which current or future state). They introduced the notion of opportunities to decide which goals to pursue and act upon them. In a later work, they proposed a framework for proactivity based on Equilibrium Maintenance with the desirability of states through fuzzy logic to keep the system in the most desired states <ref type="bibr" target="#b21">(Grosinger et al., 2017)</ref>. Building on the results of these works, they then proposed a framework that formalises proactivity through reasoning about the actions the robot can perform, the state of the environment, and the user's state, intentions, and preferences <ref type="bibr" target="#b22">(Grosinger et al., 2019)</ref>. In addition, based on the latter work, it was defined a new architecture combining Equilibrium Maintenance with "human intention recognition and reasoning" to create a proactive robot that considered both human intentions and temporal predictions <ref type="bibr" target="#b7">(Buyukgoz et al., 2022)</ref>. While those works focused on anticipatory ways to make temporal projections to predict undesirable future states, they did not predict the temporal time to act.</p><p>A different approach is proposed by <ref type="bibr" target="#b33">Liu et al. (2018)</ref> with a method for learning proactive behaviour from human-human interactions. The Authors used the data of a shopkeeper who interacted with a customer in a camera shop. Similarly, in the first phase, we learn from human-computer interactions by requesting users to perform alone the assistive task and ask for assistance when they feel it is necessary. Particularly, we learn the type of assistance they need in that state but also when they need it. However, differently from our approach, in the work of <ref type="bibr" target="#b33">Liu et al. (2018)</ref>, the robot was trained to generate multimodal actions only in moments of silence or after users provided backchannel utterances.</p><p>Again, <ref type="bibr" target="#b30">Kraus et al. (2020)</ref> studied proactive dialogue strategies, using only speech interaction on different levels of proactivity and two-timing strategies for a planning task. They defined four levels of proactivity: i) None, in which subjects could only explicitly request help from robot NAO, and, as a response, the robot suggests the solution with the highest score; ii) Notification, in which the user is informed via speech that NAO had found a solution and the user can decide to ask the system for help or not; iii) Suggestion, in which NAO directly suggests a solution by also providing a proactive explanation for its decision; iv) Intervention, in which the system activated an appropriate option in place of the user by also providing a proactive explanation. Even differently, they used timing strategies via timeouts after which the robot takes the initiative at a fixed time or by inferring users' hesitation in performing tasks. However, their work served as an inspiration for defining the different levels of confidence with which the robot should take control and intervene. Specifically, the None level of proactivity was used in phase one of learning as a basic condition for developing the proactive strategies in the next phases, while the other three levels were used for the definition of confidence.</p><p>Nevertheless, a typical approach used in the literature to develop proactivity is using WoZ, in which a human wizard controls the robot and triggers proactive interactions. <ref type="bibr" target="#b42">Peng et al. (2019)</ref> proposed three levels of proactivity (high, medium, low) in two dimensions (anticipation and autonomy), for decision-making in assistive contexts, evaluating the impact of robot proactivity on users' perception with a WoZ experiment. Likewise, <ref type="bibr" target="#b52">Tan et al. (2020)</ref> conducted a WoZ study designing five levels of proactive behaviour to explore the relationship between robot proactivity and users' perception of anthropomorphic attributes on robots. Our work aims to overcome this limitation by proposing an approach in which the robot autonomously learns when to interact by using an ID algorithm. Fig. <ref type="figure">2</ref>: Example of the task with the sequence of 4 cards: the sequence shown to the user (sx), the sequence requested to repeat to the user after 5 secs (dx).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Assistive Scenario</head><p>This section describes the task chosen to evaluate our learning framework. The experiment entails a computer short-term memory game in which participants are given instructions to memorise a sequence of cards. We chose a sequential memory game as an assistive task due to its simple rules and the possibility of defining increasing degrees of assistance for the participants. Thus, it is a concrete use case that can be applied in several contexts, such as cognitive training therapies <ref type="bibr" target="#b2">(Andriella et al., 2022)</ref>.</p><p>The objective of the game is to attain a high score by progressing through multiple levels while minimising reliance on assistance, which participants have the option to request or be provided with. Specifically, a sequence of cards is shown on the screen for 5 seconds, and the participant is asked to reconstruct it in the correct order, after the cards have been flipped, by choosing from a deck of cards (see Figure <ref type="figure">2</ref>). A level is passed only if the user can recall the entire sequence. The difficulty of the game increases, level by level, by varying the number of cards to remember and the deck to choose from. In addition, some levels could contain a repetition of the same card in the sequence, while the deck could contain cards present or not in the sequence. The number of cards in the sequence varies from a minimum of 4 to a maximum of 9 cards, also in accordance with Miller's theory <ref type="bibr" target="#b37">(Miller, 1956)</ref>. As a consequence, the minimum number of cards in the deck is also 4, while the maximum could be up to 15 cards. By combining the variation in the sequence length, the presence or not of repetition and the number of cards in the deck, a maximum level could be defined.</p><p>To avoid experiencing negative feelings in case of failure to complete the task, the player can decide to end the game at any time before reaching the final level. Points are earned depending on whether the participant placed the correct card (+10 points) or not (-5 points) and on the assistance requested, which will be detailed in the next section. We defined four increased degrees of assistance that the user can request at the cost of losing points on their score:</p><p>-Hide card (-1 point): it allows a card to be temporarily hidden from those to be selected; -Suggest position (-2 points): it allows more cards to be temporarily hidden to the right or left of those to be selected; -Indicate position (-3 points): it allows all cards except the correct one to be temporarily hidden; -Review sequence (-4 points): it allows the user to review the entire sequence of cards for 5 seconds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Approach</head><p>In this section, we outline the computational methodology proposed for learning the appropriate type (what) and timing (when) of assistance to provide to the user, as well as determining the level of confidence (how) for the robot to take control and intervene. Initially, we present an overview of the main phases involved in the learning pipeline (see Section 4.1). Subsequently, we concentrate on the training of the Influence Diagram (ID) for the specific assistive scenario to tackle the primary objective of designing proactive robots (see Section 4.2). The IDs, being a model-based approach, adapt to the case at hand because of the known causal structure of the problem. Model-based approaches, different from model-free approaches, like standard reinforcement learning, leverage the known causal relationships of the problem to reduce the amount of data needed to compute utility scores and better support explainability. Influence diagrams are particularly adapted to perform decisions under uncertainty where only machine learning predictions are available, at decision time, about the future state of random variables influencing the utility outcome of the decision through combination. Aiming to foster reproducibility, we have open-sourced our code<ref type="foot" target="#foot_0">foot_0</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Learning Pipeline</head><p>The proposed learning pipeline consists of different phases. Each phase requires a different data collection stage in which users are requested to interact with the assistance of a virtual robot (represented on a screen) to rely on the possibility of collecting a relevant amount of data by engaging users online. The idea is to build an ID incrementally where in each phase a different facet of the needed proactive behavior is added to the selection of the proper assistive action to be performed. In our case, we want to consider timing aspects for the selection of the action as well as the modality with which the action has to be performed. Hence, we rely on two phases (see Figure <ref type="figure">1</ref>). Specifically, in the first phase, namely Learning to be Proactive, players can play the game by requesting assistance, when needed, from a purely reactive virtual robot. A virtual assistant is inserted from the very beginning of the  With the data collected in the first phase, we build an ID whereby the system can learn what assistance, among those defined in Section 3, but also when the user asks for assistance.</p><p>In the second phase, namely Learning to be Proactive with Confidence, we request users to interact with a proactive virtual-screen robot that uses the ID model trained in the first phase. The agent is able to decide when and what assistance to provide, but it acts with a random confidence. The goal is to learn the level of confidence with which the robot should intervene. Hence, with the data collected in this phase, we extend our ID model by deciding not only what action to take and when to take it, but also with what confidence to recommend it to the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Influence Diagram</head><p>The implemented ID consists of three sub-diagrams, linked by a chain of dependency:</p><p>1. Assistance Decision Network (see Figure <ref type="figure" target="#fig_1">3a</ref>), trained to make decisions about whether and what degree of assistance to provide to the user. Its decision output influences the second and third networks. 2. Time Decision Network (see Figure <ref type="figure" target="#fig_1">3b</ref>), trained to make decisions about when to intervene. Its decision output influences the third network. 3. Confidence Decision Network (see Figure <ref type="figure" target="#fig_1">3c</ref>), trained to make decisions about how to intervene.</p><p>Each ID is a graphical representation of a different decision situation (drawn as rectangles) based on uncertain information (drawn as ovals) that follows a different utility function (drawn as hexagons). The decision nodes define the choices to be made, and their value will only be defined when the decision network is resolved. The chance nodes define the uncertainties to be modelled, i.e., random variables described by probability distributions. Each chance node is associated with a variable that has a finite set of outcomes, i.e., the values the variable can take, and the conditional probability distribution over these outcomes. As in a BN, an arc between the variables represents the causal influence that one variable has on another. Finally, the utility nodes define a quantitative measure of preferences among the possible states. Parents are variables describing the outcome state that directly affect utility.</p><p>Thus, decision theory extends probability theory with utility theory to describe how an agent should act in an uncertain world. In general, probabilistic graphical models based on Bayesian inference model the joint probability of all the variables in the network as the product of the conditional probabilities of all the random variables X i in the network so that</p><formula xml:id="formula_0">P (X 1 , . . . , X n ) = n i=1 P (X i |P arents Xi )<label>(1)</label></formula><p>where P arents Xi indicates the nodes that affect the node X i . Bayesian inference is, therefore, computed using the Bayes theorem using both prior distributions and contextual evidence over the observable variables. A rational agent, to decide between alternative actions, will choose the one that maximises the expected utility. Following the utility theory, the expected utility is computed by summing up the utilities of all potential outcome states o k (indexed by k ) resulting from that particular action (A), weighted by the probabilities assigned to each state:</p><formula xml:id="formula_1">EU (A) = k U (o k )P (o k ) (2)</formula><p>Since our goal is to anticipate the request for help from the user, the general structure of the IDs used in this work consists of a variable R representing reality and of a variable F , representing a forecast over the value of R. A decision node D represents the possible actions that may be taken by each ID, given the forecast F , and a utility node U represents the final utility of each combination of R and D. In the case of the Assistance Decision Network, for example, the prior over R represents the probability that at each instant t m , a specific request for help (R i ) will arrive within t m+1 , such as between the last action of the user (selection of a card from the deck) and the following one. This probability is estimated over the recordings collected during the pilot testing phase as:</p><formula xml:id="formula_2">P (R i ) = N i N a (3)</formula><p>This way, the probability that R i will represent a specific request for help is equal to the number of actual requests for help N i that arrived when considering all the users' actions N a . Anticipating the need for help means deciding to provide this help before it is requested. Hence, the utility of the decision taken by the system is computed based on the combination of a decision node D and of the actual future need for help described by R, while only considering the forecast F . Details about the utility function are provided in the next section.</p><p>At decision time, only an estimate of the future state of each kind of event represented by R can be provided. This estimate, in our case, is provided by a Support Vector Machine (SVM) trained to predict the occurrence of a request for help at the beginning of each move. The SVM is trained on the reference data set using a Radial Basis Function Kernel with C = 1 and γ = 1/n f eatures. The train/test protocol is the 10-fold cross-validation. The prediction of the SVM, consisting of a probability distribution over the possible values of R represents a soft evidence for the ID to consider when deciding whether or not to provide help proactively. The performance of the SVM over the test set is used as the prior distribution of the prediction node S, conditioned over the true value of R so that the ID is informed, at decision time, of the probability of the SVM providing a correct prediction or a wrong one, when evidence is added. The final causal structure of the ID explicitly describes the situation in which the real need for help R influences the prediction S, which is considered when selecting an action D. Ultimately, however, it is the combination of D and R, unobservable at decision time, that defines the expected utility of the selected action.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Training the IDs for Proactive Behavior</head><p>Since we want to understand what variables influence user requests and whether these might depend on a user model, we ask users to complete a questionnaire before the execution of the assistive task. In the field of games, we chose the Demographic Game Design (DGD) model <ref type="bibr" target="#b6">(Bateman and Boon, 2005</ref>) as the user model, which allows players to be profiled on alternative characteristics. Particularly, it provides four non-exclusive types of players:</p><p>-Conqueror: players, who are more oriented towards winning in all possible ways; -Manager: players, who are more logical or strategic; -Wanderer: players, who are more fun-oriented; -Participant: players, who are more story-oriented.</p><p>The original survey was published online<ref type="foot" target="#foot_1">foot_1</ref> and included 16 questions about the way one plays with binary responses, to determine the degree of belonging to each typology. Each question is about a particular type. The final score for each type is the sum of the agreement expressed for each question that corresponds to that type. Therefore, as highlighted in <ref type="bibr" target="#b12">Cowley (2009)</ref>, it could be hard for a user to choose between the definitive agreement or disagreement, above all, if the questions describe a specific situation or attitude in game-play. For this reason, a 5-point Likert scale is adopted in this work. Particularly, participants are asked to indicate the degree to which they think the statement applies to themselves by clicking on the scale that goes from left to right from "Does not really apply" to "Applies fully".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Phase 1 -Learning to be Proactive</head><p>The first phase aims to learn both what assistive action to offer and the timing at which such assistance needs to be provided. In this phase, we requested participants to play alone with the assistance of a virtual robot introduced as an assistant from whom they could seek aid if necessary. The levels of assistance the user could ask for are those presented in Section 3. Explicitly seeking assistance is a strategy that has been defined in previous work as a "low level of proactivity" <ref type="bibr" target="#b30">(Kraus et al., 2020)</ref> but it provided the baseline condition for the proactive strategy developed in the following phases.</p><p>We designed an online study and developed a website with Flask<ref type="foot" target="#foot_2">foot_2</ref> and hosted it on PythonAnywhere<ref type="foot" target="#foot_3">foot_3</ref> . Before starting to play the game, a tutorial with game instructions about how to score points and request assistance is shown to the participant, with the possibility to try the game. After the user has agreed to participate, they are asked to first fill in a demographic questionnaire about age, gender, and level of education, and then the DGD questionnaire. Finally, the user started playing the game with the possibility of requesting assistance (Figure <ref type="figure">2</ref>). The length of the sequence could vary from 4 to 7, while the number of cards in the deck could increase to 15, with 26 being the maximum level. The game ended when the user pressed the end button or when one reached the maximum level. For each user, we collected the answers to the questionnaires and the history of the game, move by move.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Training Assistance Decision Natwork</head><p>Data from 84 participants are then analysed. We divided the participants into four groups based on the DGD questionnaire but, since some participants might belong to more than one class, the results involved statistics with repeating players. The results indicated that 45 players belong to the Conqueror class, 20 to the Manager, 10 to the Wanderer, and finally 9 to the Participant. For each type of player, we identified some objective discriminating variables relating to the participant's performance during the execution of the sequential task: number of levels achieved, score, number of mistakes, and assistance requested. Preliminary results confirmed our main idea of profiling participants according to the DGD questionnaire as they showed differences between them in terms of what assistance they require and when <ref type="bibr" target="#b13">(Cucciniello et al., 2023)</ref>. As a consequence, the ID will fit the user's model to avoid a one-size-fits-all policy.</p><p>The dataset for constructing the classifier, aimed at determining the forecast of the degree of assistance to provide, is created by processing the data collected during the first phase. For each move made by the participants during the game, we assessed whether or not it was a request for assistance. If so, we marked it with the corresponding assistance requested, otherwise as none. In addition, each labelled move is associated with the user profile and game status. The user profile is defined by the four final scores of the DGD questionnaire, one for each typology. Conversely, the state of the game is defined by the length of the sequence to be remembered, the index of the current card to be placed, the number of cards in the deck from which to choose, and the action that led to the current state of the game. Hence, the user profile and game status correspond to the features of the classifier, while the type of assistance requested is the target. Specifically, the latter could assume the following values: None, Hide Card, Suggest Position, Indicate Position, and Review Sequence. Notably, the class None included actions other than requests for assistance, i.e., a match or a mistake made during the task.</p><p>The resulting dataset consisted of 4708 samples. Next, we split the dataset into train and test sets, the latter with 10 samples from each class. However, in the train set the classes were highly imbalanced, with a predominance of class None that could cause overfitting. Therefore, we rebalanced the dataset using the Synthetic Minority Oversampling Technique (SMOTE) <ref type="bibr" target="#b9">(Chawla et al., 2002)</ref> on the minor classes.</p><p>An SVM Multiclass Classifier with an RBF kernel is implemented to estimate the probabilities of the assistance request' forecast, namely the Assistance Requested Classifier. Given as input the player's profile and the state of the game, it returned the set of probabilities associated with each grade of assistance. In the end, an estimator with an accuracy of 74% is obtained on 50 samples of the test set. In Table <ref type="table" target="#tab_0">1</ref> we report the main classification metrics. Lastly, the Assistance Decision Network (see Figure <ref type="figure" target="#fig_1">3a</ref>) is implemented to make decisions on whether or not to provide a specific assistive action to the user. The network consisted of two chance nodes, a utility node, and a decision node, with a total of four edges. The a priori probability distributions of the nodes are depicted in Figure <ref type="figure">4a</ref>. Furthermore, in consideration of the possibility of the assistance being either absent or progressively increasing, we formulated a utility function that assigns a lower significance to the potential harm caused by failing to provide assistance compared to the potential negative impact of offering undesired assistance. This approach is motivated by the nature of the game environment where unwanted help has the potential to disrupt the enjoyable experience. Thus, given the distance between the classes as input, the utility function assumed its maximum value if the distance was zero, while it had a higher slope to the right and a lower to the left, as in Figure <ref type="figure">4b</ref>. The value of Decision Assistance, the decision node, will only be defined when the ID is resolved, depending on the evidence that will be set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Training Time Decision Network</head><p>The dataset for constructing the classifier, aimed at determining the forecast of the time in providing assistance, is created by processing the data collected during the first phase. Instead of including all moves, the focus here was only on requests of assistance: for each assistance request the "help time" is calculated as the difference, in seconds, between the assistance request and the previous action and associated with time bins of one second at a time. Thus, each help time is associated with the degree of assistance required, the user profile and the game status, which represent the features of the classifier, while the time is the target. Given the short reaction times of the game and the fact that most requests are concentrated between 2 and 5 seconds (see Figure <ref type="figure" target="#fig_3">5</ref>), we consider only this temporal range, for a total of 336 samples and 3 bins as target classes. Next, we split the dataset into train and test sets, the latter with 10 samples from each class. As the classes were slightly imbalanced, we rebalanced the dataset reducing the two largest classes.</p><p>An SVM Multiclass Classifier with an RBF kernel is implemented to estimate the time prediction probabilities of a request for assistance, namely Request Time Classifier. Given as input an assistance request with the player's profile and the state of the game, it returns the set of probabilities associated with each temporal bin. In the end, an estimator with an accuracy of 63% is obtained on 30 samples of the test set. Table <ref type="table" target="#tab_1">2</ref> summarises the report of its main classification metrics. Finally, the Time Decision Network (see Figure <ref type="figure" target="#fig_1">3b</ref>) is implemented to make decisions on when to provide a certain degree of assistance to the user. The network consisted of two chance nodes, a utility node, and a decision node, with a total of four edges. The a priori probability distributions of the nodes are depicted in Figure <ref type="figure">6a</ref>. Moreover, since we tried to anticipate the user's actions, it is generally considered preferable to give help a little earlier than later as it may be too late to give it. Thus, given the distance between the classes as input, the utility function assumed its maximum value if the distance was zero, while it decreased to the left and drastically to the right, as in Figure <ref type="figure">6b</ref>. The value of Decision Time, the decision node, will only be defined when the ID is resolved, depending on the evidence that will be set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Phase 2: Learning to be Proactive with Confidence</head><p>The second phase aimed to learn the level of confidence for the robot to take control of the task. According to <ref type="bibr" target="#b30">Kraus et al. (2020)</ref>, we defined four increasing levels of confidence: 1. None, in which users could only explicitly request assistance; 2. Notification, in which the user is informed that assistance might be needed; 3. Tip, in which a possible degree of assistance that might be needed is suggested directly to the user; 4. Action, in which the system selected a degree of assistance for the user.</p><p>Here, the focus is on the last three levels as the first one, i.e. the None level, had already been trained in the first phase in which participants could explicitly ask for assistance when they needed it. Indeed, with the data collected in the first phase, we built a computational model whereby the system could choose what type of assistance to provide to users and at what moment it was more likely to provide it during the execution of the game. Thus, in this learning phase, participants will be assisted by a proactive virtual robot that, based on their model, will propose the assistance action most suited to their needs with random confidence, to train the confidence by recording the participants' responses. Thereby, the computational model will be extended with the possibility of defining not only what assistance and when to provide it, but also with what level of confidence to propose it to the user.</p><p>As with the first phase, for the online study, we developed a website with Flask and hosted it on PythonAnywhere. Before starting to play the game, a tutorial with game instructions about how to score points and request assistance is shown to the participant, with the possibility to try the game. After the user has agreed to participate, they are asked to first fill out a demographic questionnaire about age, gender, and level of education, and then the DGD questionnaire. Finally, the user started playing the game with the possibility of requesting assistance, should one deem it necessary (see Figure <ref type="figure" target="#fig_5">7a</ref>), or receiving assistance, should the virtual robot deem it necessary. Indeed, during the game, the decision system could propose the decided degree of assistance, at that time, with different confidence levels, choosing the confidence randomly. In particular: it could propose it as a Notification, unlocking all the degrees of assistance for the user but allowing them the choice (Figure <ref type="figure" target="#fig_5">7b</ref>); or, it could propose it as a Tip, unlocking only that decided degree of assistance but always allowing them the choice (Figure <ref type="figure" target="#fig_5">7c</ref>); or again, it could propose it as an Action, directly activating it, with the possibility, then, of expressing the degree of the pleasantness of that action (Figure <ref type="figure" target="#fig_5">7d</ref>). The length of the sequence could vary from 6 to 9, while the number of cards in the deck could increase to 15, with 18 being the maximum level. We removed the initial levels with sequences of 4 and 5 cards to remember and introduced new ones with 8 and 9 cards because the latter may need more assistance than the former to be completed as more difficult. The game ended when the user pressed the end button or when one achieved the maximum level. For each user who has finished playing, we have collected the answers to the questionnaires and the history of the game, move by move.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Training Confidence Decision Network</head><p>The dataset for constructing the classifier, aimed at determining the forecast of the level of confidence in providing the necessary assistance, is created by processing the data collected from 50 participants during the second phase. The study involved individuals ranging from 20 to 63 years old, including 29 females and 21 males. Nearly 88% of the participants reported having postgraduate education, while the remaining individuals had lower levels of education, such as graduate or high school education. For each assistance request, we evaluated the real confidence on some preliminary considerations based on the different confidence generated randomly in the second phase:</p><p>-In the case where the system suggested assistance in the form of a Notification, which allows access to all types of assistance, and the user decided to utilise the same assistance as the one selected by the ID, the system could propose it with a higher level of confidence, referred to as a Tip.</p><p>Conversely, if the user opted for a different action, it was appropriate to propose it in the original way. -If the system recommended assistance in the form of a Tip, unlocking only a specific type of assistance, and the user chose to utilise it, the system could propose it with a higher level of confidence, referred to as an Action.</p><p>Conversely, if the user took a different action, it would have been preferable to propose it with a lower confidence level, referred to as a Notification. -When the system suggested assistance in the form of an Action, directly activating assistance, if the user expressed positive feedback on it then it was appropriate to propose it in that manner. However, if the user did not appreciate it, it would have been better to propose it with a lower confidence level, referred to as a Tip.</p><p>Accordingly, evaluations are made on the concordance between system decisions of assistance, proposed with random confidence, and the user's next move, which led to changes to the real value of confidence. Table <ref type="table">3</ref> summarises the evaluation scheme for real confidence. Thus, each real confidence is asso-Table <ref type="table">3</ref>: Evaluation system adopted to assess the real confidence to be used, starting with the randomly generated confidence. Specifically, the first column indicates the random decision made by the system on the confidence level to be adopted in suggesting the assistance; the second column indicates whether there was an agreement between what the system decided, and the action taken by the user, while the third column indicates the final confidence level to be adopted as a result of the comparison. ciated with the degree of assistance required, the help time, the user profile and the game status, which represent the features of the classifier. The resulting dataset consisted of 678 samples. Next, we split the dataset into train and test sets, the latter with 10 samples from each class. As the classes were slightly imbalanced, we rebalanced the dataset reducing the two largest classes.</p><p>An SVM Multiclass Classifier with an RBF kernel is implemented to estimate the confidence prediction probabilities of a request for assistance at a given moment, namely the Confidence Classifier. Given as input an assistance request, a temporal bin in which to propose assistance, the player's profile, and the state of the game, it returned the set of probabilities associated with each grade of confidence. In the end, an estimator with an accuracy of 70% is ob-  Finally, the Confidence Decision Network (see Figure <ref type="figure" target="#fig_1">3c</ref>) is implemented to make decisions on which level of confidence to propose assistance to the user. The network consisted of two chance nodes, a utility node, and a decision node, with four edges. The a priori probability distributions of the nodes are depicted in Figure <ref type="figure">8a</ref>. Assuming that the confidence may be gradually increasing, we considered that, in general, it is preferable to decide on a lower confidence than for a higher one, which could be considered overstated. Thus, given the distance between the classes as input, the utility function assumed its maximum value if the distance was zero, while it decreased to the left and drastically to the right, as in Figure <ref type="figure">8b</ref>. The value of Decision Confidence, the decision node, will only be defined when the ID is resolved, depending on the evidence that will be set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The Final Proactive Decision System</head><p>The final decision system consisted of 3 IDs that communicate with each other to provide a combined solution: the Assistance Decision Network could decide to provide no assistance (None), Hide Card, Suggest Position, Indicate Position, or Review Sequence, for a total of 5 possible decisions (see Sec. 5.1.1); -the Time Decision Network could decide to provide assistance between <ref type="bibr">[2,3 [, [3, 4 [ or [4,5 ]</ref> seconds, for a total of 3 possible decisions (see Sec. 5.1.2); -the Confidence Decision Network could decide to provide assistance as Notification, Tip, or Action, for a total of 3 possible decisions (see Sec. 5.2.1).</p><p>Given as input the Player Profile and Game State, the Assistance Requested Classifier is queried to return the set of probabilities of each possible outcome of the input sample. This vector will then be set as evidence for the Assistance Decision Network, on which inference will be made to make decisions. If the system returns None then no assistance will be provided. Otherwise, further information is needed to compose the final decision, that is, the system needs to know the time and confidence decisions for that type of assistance requested.</p><p>To determine the time, the system uses the Request Time Classifier, which takes as input the Player Profile, Game State and Decided Assistance Requested. The resulting probabilities are then used as evidence for the Time Decision Network, which makes the final decision on when to provide assistance.</p><p>To determine the confidence level, the system uses the Confidence Classifier, which takes as input the Player Profile, Game State, Decided Assistance Requested, and Decided Request Time. The resulting probabilities are then used as evidence for the Confidence Decision Network. which makes the final decision on the appropriate level of confidence for recommending assistance to the user.</p><p>Figure <ref type="figure" target="#fig_7">9</ref> depicts the scheme of this decision process. The ID is queried every time the user performs a move.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation of Proactive Behaviour</head><p>To evaluate the proposed approach we designed a laboratory experiment during which participants played the sequential memory game with the assistance of a Furhat<ref type="foot" target="#foot_4">foot_4</ref> robot. The study was designed as a between-subject study in which participants are randomly assigned to one of the following two experimental conditions:</p><p>-Non-Proactive Robot: assisted by a robot that decides what assistance to provide randomly, that is, it chooses what, when, and with what confidence to offer assistance; -Proactive Robot: assisted by a robot that decides what, when and with which confidence to offer assistance using the trained ID.</p><p>To demonstrate the presence or absence of an effect, we analysed the data using a T-test (normality checked with Shapiro-Wilk test) and Mann-Whitney U test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Hypotheses</head><p>With the objective of answering our research question, we formulated the following hypotheses: H1: Participants who interacted with the Proactive Robot performed better than those who interacted with the Non-Proactive. H2: Participants who interacted with the Proactive Robot requested less assistance than those who interacted with the Non-Proactive. H3: Participants who interacted with the Proactive Robot rated the perceived capabilities and characteristics of the robot higher than those who interacted with the Non-Proactive. H4: Participants who interacted with the Proactive Robot rated the degree of proactivity exhibited by the robot higher than those who interacted with the Non-Proactive.</p><p>Concerning H1, we speculated that equipping the robot with proactive and adaptive behaviour to the users' needs could have an impact on their performance. Indeed, results from <ref type="bibr" target="#b23">Hemminghaus and Kopp (2017)</ref> showed that users were able to solve a memory game faster with the assistance of an adaptive robot, which guided the user's attention to targeted objects, compared to a random condition. Hence, we believed that the Proactive group might reach a higher game level, achieve a higher score, make fewer mistakes and use fewer assistance instances. Furthermore, aiming to act in advance to help users and prevent negative outcomes, a robot with proactive behaviour should offer users assistance that is appropriate to their gameplay needs by preventing them from explicitly requesting it. Therefore, concerning H2, we hypothesised that the number of assistance users-activated in the proactive group would be lower than that in the non-proactive group. Regarding H3, based on previous studies, proactive behaviour may influence users' perceptions positively, as the robot takes a more engaged and responsive role in the interaction <ref type="bibr" target="#b42">(Peng et al., 2019;</ref><ref type="bibr" target="#b52">Tan et al., 2020)</ref>. Finally, H4 is grounded in the idea that proactive behaviour inherently aligns with users' expectations for the robot to act in advance, anticipate their needs, and provide assistance without explicit requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation Measures</head><p>To assess our research hypotheses, we gathered subjective and objective measures. Regarding subjective measures, we used the Perceived Social Intelligence (PSI) questionnaire <ref type="bibr" target="#b5">(Barchard et al., 2020)</ref> with a Likert-type scale from 1 to 5 (see Appendix A) to evaluate participants' perceptions of the robot's capabilities and characteristics. Particularly, we examined the following constructs: Social Competence (SOC), Adapts to Human Cognitions (AC), Predicts Human Cognitions (PC), Recognizes Human Cognitions (RC), Recognises Human Behaviours (RB), Helpful (HLP), and Trustworthy (TRU). These measures helped us to address H3. To evaluate the users' perception of the degrees of proactivity exhibited by the robot, we used the Robotic Service Proactivity (RSP) questionnaire <ref type="bibr" target="#b56">(Xie et al., 2022)</ref> (see Appendix B) with a Likert-type scale from 1 to 7.</p><p>In terms of objective measures, participants' performance is evaluated based on (i) the highest level achieved in the game, (ii) the total score obtained, the number of mistakes, and (iii) the number of assistance instances used during gameplay (to tackle H1). Subsequently, the value of the score, mistakes and assistance instances are normalised to the level achieved since each participant could end the experimentation at any time before reaching the final level. Furthermore, among the assistance instances, we distinguished those explicitly requested by the participant from those provided by the robot as an autonomous action (to evaluate H2). Fig. <ref type="figure">10:</ref> A participant playing the sequential memory game with the Furhat robot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Participants</head><p>We recruited a total of 60 participants (37 identified themselves as male, 21 as female and 2 as not binary). The study involved a diverse sample population ranging in age from 19 to 44 years (M=24.63, SD=4.90). The experiment was conducted within a laboratory setting at the University of Naples Federico II (see Figure <ref type="figure">10</ref>). Six participants were discarded from the data analysis as their performance did not achieve the minimum level required (third level). Hence, we considered data from 54 participants (34 male, 18 female and 2 not binary) aged between 19 and 33 years (M=24.11, SD=3.66). Specifically, 27 participants (18 male, 8 female and 1 not binary) interacted with the Proactive Robot, whereas the other half of the participants interacted with the Non-Proactive Robot (16 male, 10 female and 1 not binary). For N=54, we estimated an effect size of d = 0.35 with 0.81 power at an α level of 0.05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Procedure</head><p>Upon arrival, participants were provided with a tutorial that explained the rules of the game, including how to score points and request assistance. After obtaining the participant's consent to participate, they were asked to complete a demographic questionnaire, providing information about their age, gender, and level of education. Subsequently, the participants were requested to complete the DGD questionnaire to assess their player types.</p><p>Following the questionnaire completion, participants began playing the game. During the game, participants could request different levels of assis- tance in order to solve the game. At the same time, the robot could also provide assistance randomly or proactively, depending on the experimental conditions. The game involved remembering a sequence of 6 to 9 cards, with the number of cards increasing up to 15 or 18. The game would end either when the participant pressed the end button or when the maximum level was reached. After the game, participants were asked to complete two questionnaires, which assessed their perceptions of the robot's social intelligence (PSI) and proactivity (RSP). Finally, in the debriefing phase, the researcher provided a full explanation of the experiment addressing any question asked by the participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>To assess our hypotheses, we employed the non-parametric Mann-Whitney U test, comparing the performance outcomes between participants interacting with the Proactive Robot and those with the Non-Proactive Robot.</p><p>Concerning H1, results showed that the difference in terms of achieved level is not significant (z = 0.69, p = 0.246) between participants who interacted with the proactive robot (M = 10.48, SD = 4.34) and those who interacted with the non-proactive robot (M = 9.96, SD = 5.03). On the contrary, those participants who belonged to the proactive group (M = 54.95, SD = 11.08) achieved a significantly higher score than those in the nonproactive (M = 45.44, SD = 17.01), z = 2.01, p = 0.022, with effect size d = 0.66. Furthermore, the number of mistakes made by those participants in the proactive group (M = 3.46, SD = 2.26) was significantly lower than the one made by the participants in the non-proactive (M = 5.35, SD = 3.28), z = -2.49, p = 0.006, with effect size d = 0.67. Finally, in terms of the amount of assistance provided by the robot, the number of assistance instances provided by the proactive robot (M = 2.32, SD = 1.07) was not significantly lower than the number provided by the non-proactive one (M = 2.27, SD = 0.75), z = -0.30, p = 0.381. Figure <ref type="figure" target="#fig_8">11</ref> depicts the results obtained by comparing the performance of the two groups. Based on these findings, we can conclude that H1 is confirmed since the participants who belonged to the proactive group performed better than those in the non-proactive in terms of maximising the gameplay score and minimising the mistakes committed while still receiving the same amount of support in both cases.</p><p>Regarding H2, the results indicate that the participants who interacted with the proactive robot had explicitly requested assistance from it fewer times (M = 0.43, SD = 0.41) compared to those who interacted with the non-proactive (M = 1.14, SD = 0.43), with z = -4.78, p &lt; 0.001, with effect size d = 1.68 (see Figure <ref type="figure" target="#fig_9">12</ref>). To understand better the magnitude of the differences, we computed the percentage of time the robot intervention was requested. It turned out that participants who belonged to the proactive group asked for assistance from the robot only 25.52% of the time, while those who belonged to the non-proactive group 50.96%. Furthermore, when the robot proposed to assist the players their hints were accepted more often in the proactive condition (10% more). Therefore, we can confirm that H2 was correct.</p><p>With respect to H3, the results show that for all the PSI constructs, the participants who interacted with the proactive robot did not obtain significantly higher scores than those who interacted with the non-proactive (see Table <ref type="table" target="#tab_4">5</ref>). Therefore, our third hypothesis is rejected, as the proactive robot is not perceived by the participants to be better than the non-proactive one.</p><p>Finally, for H4, the scores calculated for the RSP questionnaire highlighted that the proactive robot (M = 5.59, SD = 0.88) did not score significantly higher than the non-proactive one (M = 5.41, SD = 0.77), z = 1.02, p = 0.155. Thus, H4 is rejected as a higher degree of proactivity is not perceived by the participants who interacted with the proactive robot. Hence, also H4 is not sustained by the results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Discussion</head><p>The presented analysis aimed to investigate the impact of proactive versus non-proactive robotic interactions on user performance and perception of the robot. The discussion that follows synthesises these findings, offering insights into the multifaceted effects of proactive robot behaviour as they pertain to the initial research hypotheses. Overall, only H1 and H2 were sustained by our results. This delineates a difference between what could be objectively measured (H1 and H2) and what was subjectively perceived by participants (H3 and H4). Concerning H1, results provided evidence on the effect of the adaptive ability of the robot; Indeed, the ID, learnt during the first phase (see Section 5.1) was notably more effective, as participants made fewer errors and attained higher scores. A noteworthy revelation about the efficacy of the robot's assistance is that the amount of support did not significantly differ between the two conditions, highlighting the quality of the assistance provided by the proactive robot. Our findings align with prior research indicating the impact of adaptivity on participants' performance in human-robot interaction tasks <ref type="bibr" target="#b23">(Hemminghaus and Kopp, 2017;</ref><ref type="bibr" target="#b16">Donnermann et al., 2022;</ref><ref type="bibr" target="#b53">Tanevska et al., 2020)</ref>.</p><p>Moving to H2, we substantiated not only the adaptive capacity of the ID but also its proactive nature. The fact that participants who interacted with the proactive robot requested assistance less frequently supports our claim that the IDs learnt from previous interactions (phases 1 and 2) were able to anticipate the needs of participants. Additionally, we found evidence that participants in the proactive condition preferred the assistance offered by the robot, indicating a greater level of trust in its behaviour. Our data supports the conclusions drawn in previous studies about the role of proactivity in assistive context and how this relates to anticipating user's intentions and needs and making the interactions with the robot more reliable <ref type="bibr" target="#b30">(Kraus et al., 2020;</ref><ref type="bibr" target="#b18">Garrell et al., 2017;</ref><ref type="bibr" target="#b4">Baraglia et al., 2016)</ref>.</p><p>Concerning H3 and H4, the experimental results indicate that participants did not perceive any distinction between the proactive robot and the robot providing assistance randomly. Despite our anticipation of significant differences, the absence of participant awareness does not come as a surprise. Understanding the reasons behind these findings is challenging. Three variables, namely "what", "when" and "which confidence" could have influenced these outcomes. Regarding the "what" aspect, the adaptivity dimension of the PSI, represented by AC, though higher in the proactive condition, lacks statistical significance. We hypothesise that participants interacting with the robot exhibiting random behaviour might have perceived it as a form of adaptability. Moreover, the amount of interventions provided in the two conditions was the same. Hence, we hypothesize that results were mainly impacted by the "interactivity level" that was the same in both conditions (i.e., the average number of interactions initiated by the robot), with respect to the "quality" of the proposed suggestions (that had an impact on performance).</p><p>In terms of "when", the PSI dimensions measuring this include PC, RC, RB, and the RSP questionnaire. The results suggest that only PC, relating to the robot's ability to anticipate people's beliefs, was somewhat more relevant and approached statistical significance (p = 0.06). The other dimensions showed no significant differences. We posit that the characteristics of the considered cognitive game and limiting the robot intervention to 3-time intervals, between 2 and 5 seconds, allowed for sufficient data for training and validation but may have impacted user perception. In a cognitively demanding task, users might not have focused on such fine-grained details, even though these details influenced their overall performance, as evidenced by H1 and H2. If we investigate these results a bit more in detail, we can observe how most of the time, the robot attempted to provide assistance in the first 2 seconds (see Figure <ref type="figure">6a</ref>). However, this anticipation happened in only 20% of the entire game, as the robot learnt not to intervene for most of the game (see Figure <ref type="figure">4a</ref>). Finally, concerning "which confidence" previous research by <ref type="bibr" target="#b32">Kraus et al. (2022)</ref> revealed that how the robot intervenes can affect participants' trust and acceptance. We did not explicitly assess whether this variable had an impact on trust, but by further investigating the percentage of time each degree of confidence was provided, around 90% of the time the robot provided "intervention". Hence, while the proactive robot has learnt the needed assistance and provided it with higher confidence, the randomness (i.e., the variability) of the non-proactive condition might be better perceived. This suggests that acceptance and trust in the robot are not only linked to its competence in the task but also the other factors related to the interaction's variability, such as the ways of presenting suggestions. Therefore, such factors need to be considered while evaluating the robot's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Limitations</head><p>Despite the interesting results, we were able to validate with this study, some limitations need to be pointed out and motivate future research. We divided them into methodological and developmental. Concerning the methodological ones, we mention the following:</p><p>-Type of task : The chosen task to evaluate the proposed system in this work was a high cognitive demand task. Although the proactive robot's support led to an improvement in the users' performance, their subjective perceptions about the robot may have been influenced by the task selected.</p><p>During the game, users were found to be focused on the task and sometimes ignored the presence of the robot. For the same reason, it was sometimes complicated for the robot to intervene while the user was playing because the reaction times were short. Indeed, the intervention times learnt by the robot could vary between 2 and 5 seconds. Most of the time it takes around 2 seconds to anticipate the user. To increase users' awareness and perception, the implemented system could be replicated by testing it on a collaborative task, which actively involves the robot's participation. -Sample population: While in the first two phases, we could collect data from very diverse population samples, that was not possible in the final study with the robot, in which we relied on a more convenient sample. Indeed, the participants were mainly undergraduate students. Our next step will be to confirm these findings with a larger, more diverse sample.</p><p>Regarding the developmental ones, we include the following:</p><p>-Offline model : The developed decision system was trained on data acquired in the different phases of learning that lead to the modelling of the final system. Hence, although the system could adapt to the player profile style and game state, it did not tailor its behaviour to the individual's unique needs. Therefore, as future work, an online model with dynamic IDs could be developed that can personalise respect to the interaction by learning from time to time. -No explanations: During the game interaction, the robot was able to provide assistance to users using phrases such as "I think you could use some hint" or "I suggest you use x ", providing the chosen degree of assistance but no further motivation. As an extension, similar to the work of <ref type="bibr" target="#b30">Kraus et al. (2020)</ref>, the robot could also explain why one degree of assistance is chosen over another. This could lead the user to be more accepting of the provided suggestions, also because justifying explanations have been shown to improve user confidence in automated systems <ref type="bibr" target="#b39">(Nothdurft et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This study focused on defining an incremental approach to enable robots to learn how to proactively assist users in various tasks. We choose a sequential memory task as a case study and propose a computational approach that uses data-driven models to determine three key aspects of robot behaviour. These are: 1) determining the appropriate type of assistance required, 2) determining the right time for the robot to provide assistance, and 3) deciding with what confidence level the robot should take control. To do so, we propose a twophase pipeline that involves learning three Influence Diagrams for each of the three crucial interaction aspects. The state of the game and the player style profile are taken into account during this process.</p><p>During the first phase, we aimed to learn what level of assistance is required and when it should be provided. Participants were asked to play the game online alone, during which they could activate different degrees of assistance from a virtual robot when needed. During the second phase of the study, we aimed to determine the appropriate level of confidence with which the robot should intervene and take control. To achieve this, participants were asked to play an online game with the help of a virtual-screen robot that was programmed based on the data collected in the first phase. However, the robot's assistance was provided with a random level of confidence. By the end of this phase, we could develop three IDs.</p><p>To assess the effectiveness of the proactive decision-making system and answer the initial research question, a between-subject study was conducted. In this study, participants played a sequential memory game with the assistance of the Furhat robot, which was programmed with the computational model learned during the two phases. Our findings indicated that by using a learning pipeline with a data-driven approach, we could endow the robot with proactive capabilities (feasibility). The proactive robot had an impact on user performance making them complete the game with fewer errors and a higher score than those who interacted with a robot with random behaviour (performance). Additionally, the robot was able to assist users in an anticipatory manner, reducing their effort of having to explicitly ask for it. However, we could not provide significant evidence that participants perceived those differences. We believe that could be due to several reasons, e.g., high-cognitive demanding tasks or a too short time window to intervene and the lack of variability in the learned interaction. We believe this aspect needs further investigation. The assessment of the computational pipeline in a different assistive context will be the main focus of our future work. We believe these results can pave the way to the development of more complex decision-making systems that not only react to the users' behaviour but also proactively take the initiative.</p><p>In summary, this work shows possible directions for the future development of autonomous proactive social robot behaviour in assistive contexts. programme under the Marie Sk lodowska-Curie grant agreement No 801342 (Tecniospring INDUSTRY) (A. Andriella).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations Compliance with Ethical Standards</head><p>Conflict of Interest: The authors declare that they have no conflict of interest.</p><p>Ethical Standard: All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards.</p><p>Informed Consent: Informed consent was obtained from all individual participants included in the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Perceived Social Intelligence</head><p>Perceived Social Intelligence (PSI) <ref type="bibr" target="#b5">(Barchard et al., 2020)</ref> questionnaire aims to measure user perception of robots' social information processing capabilities with 20 different scales. The questionnaire is located on the International Personality Item Pool website<ref type="foot" target="#foot_5">foot_5</ref> . Each Scale contains four items in which the single best item is given first. The PSI items can be administered as a Long Form (80 items) or Short Form (20 items, the best ones) questionnaire, or can be freely used and adapted as needed. Indeed, we used only some dimensions of the original PSI scale. For what concern the Social Information Processing, we used: The final score for one scale is calculated by first reversing the score of any items that have a [R] next, and then averaging the item scores. The reverse score is calculated as 6 minus the original score. Thus, each scale's scores range from 1 to 5. To calculate the total score, the scores of each scale are added together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Robotic Service Proactivity</head><p>The Robotic Service Proactivity questionnaire aims to measure users' perceptions of robot proactivity with one scale. The questions are extracted from <ref type="bibr" target="#b56">Xie et al. (2022)</ref>, who adapted them from the work of <ref type="bibr" target="#b49">Shin et al. (2017)</ref>. The score of the construct is calculated by averaging the item scores. The list of questions will be shown below.</p><p>1. The robot anticipated my problem even before I found out about it. 2. The robot informed me before I could find out about the problem. 3. The robot made things happen rather than just reacting to a situation or waiting for something to happen. 4. The robot took action before I asked it to. 5. The robot did not wait to be asked by me to act. 6. The robot got to my issue before I took my issue to it.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: ID to decide a) what degree of assistance to provide, b) when to provide assistance, and c) what degree of confidence to adopt.</figDesc><graphic coords="11,72.00,90.93,117.86,140.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig. 4: a) Table of a priori probability distributions of the chance nodes of Assistance Decision Network; b) Plot of the utility function for the utility node of Assistance Decision Network.</figDesc><graphic coords="16,227.77,113.21,185.19,85.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Binning of assistance Request Times.</figDesc><graphic coords="17,88.84,89.45,303.06,166.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig. 6: a) Table of a priori probability distributions of the chance nodes of Time Decision Network; b) Plot of the utility function for the utility node of Time Decision Network.</figDesc><graphic coords="18,87.42,89.45,117.86,113.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Examples of assistive behaviour with a different confidence.</figDesc><graphic coords="19,83.19,163.03,151.53,57.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Fig. 8: a) Table of a priori probability distributions of the chance nodes of Confidence Decision Network; b) Plot of the utility function for the utility node of Confidence Decision Network.</figDesc><graphic coords="21,75.64,89.45,124.58,113.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 :</head><label>9</label><figDesc>Fig. 9: Proactive Decision System.</figDesc><graphic coords="22,105.67,89.45,269.39,253.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 :</head><label>11</label><figDesc>Fig. 11: Performance of the two groups with proactive and non-proactive robot assistance, for (a) level achieved, (b) score, (c) number of mistakes and (d) assistance provided (left and orange proactive robot, right and blue nonproactive robot). * denotes p&lt;0.05, while ns denotes non-significance.</figDesc><graphic coords="26,72.00,89.45,336.71,108.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 :</head><label>12</label><figDesc>Fig. 12: Number of assistance instances explicitly requested by participants in the two groups (left and orange proactive robot, right and blue non-proactive robot. * * denotes p&lt;0.001.</figDesc><graphic coords="27,156.18,89.45,168.36,152.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>-</head><label></label><figDesc>Social Competence (SOC): The robot appears to have strong social skills. -Adapts to Human Cognitions (AC): The robot appears to adapt its behavior appropriately based upon people's thoughts and beliefs. -Predicts Human Cognitions (PC): The robot appears to anticipate people's thoughts and beliefs. -Recognizes Human Cognitions (RC): The robot appears to detect people's thoughts and beliefs. -Recognizes Human Behaviors (RB): The robot appears to detect people's behaviors. Conversely, for what concern the Social Presentation, we used:-Helpful (HLP): The robot appears willing to assist in tasks.-Trustworthy (TRU): The robot appears deserving of trust.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,72.00,89.45,336.74,172.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Classification Report for Assistance Requested.</figDesc><table><row><cell>Class</cell><cell>Precision</cell><cell>Recall</cell><cell>F1-score</cell><cell>Support</cell></row><row><cell>None</cell><cell>0.57</cell><cell>0.80</cell><cell>0.67</cell><cell>10</cell></row><row><cell>Hide Card</cell><cell>1.00</cell><cell>0.90</cell><cell>0.95</cell><cell>10</cell></row><row><cell>Suggest Position</cell><cell>0.83</cell><cell>0.50</cell><cell>0.62</cell><cell>10</cell></row><row><cell>Indicate Position</cell><cell>0.73</cell><cell>0.80</cell><cell>0.76</cell><cell>10</cell></row><row><cell>Review Sequence</cell><cell>0.70</cell><cell>0.70</cell><cell>0.70</cell><cell>10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Classification Report for Request Time.</figDesc><table><row><cell>Class</cell><cell>Precision</cell><cell>Recall</cell><cell>F1-score</cell><cell>Support</cell></row><row><cell>[2;3[</cell><cell>0.62</cell><cell>0.80</cell><cell>0.70</cell><cell>10</cell></row><row><cell>[3;4[</cell><cell>0.58</cell><cell>0.70</cell><cell>0.64</cell><cell>10</cell></row><row><cell>[4;5]</cell><cell>0.80</cell><cell>0.40</cell><cell>0.53</cell><cell>10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Table 4 summarises the main classification metrics. Classification Report for Confidence.</figDesc><table><row><cell>Class</cell><cell>Precision</cell><cell>Recall</cell><cell>F1-score</cell><cell>Support</cell></row><row><cell>Notification</cell><cell>0.67</cell><cell>0.60</cell><cell>0.63</cell><cell>10</cell></row><row><cell>Tip</cell><cell>0.75</cell><cell>0.60</cell><cell>0.67</cell><cell>10</cell></row><row><cell>Action</cell><cell>0.69</cell><cell>0.90</cell><cell>0.78</cell><cell>10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Comparison between the proactive robot and the non-proactive one on the Perceived Social Intelligence constructs.</figDesc><table><row><cell></cell><cell>Proactive</cell><cell>Non-Proactive</cell><cell>z</cell><cell>p</cell></row><row><cell></cell><cell>Mean±SD</cell><cell>Mean±SD</cell><cell></cell><cell></cell></row><row><cell>SOC</cell><cell>3.02±0.96</cell><cell>3.08±0.73</cell><cell>-0.18</cell><cell>0.573</cell></row><row><cell>AC</cell><cell>3.33±1.01</cell><cell>3.26±0.64</cell><cell>0.20</cell><cell>0.420</cell></row><row><cell>PC</cell><cell>3.25±0.90</cell><cell>2.97±0.83</cell><cell>1.53</cell><cell>0.063</cell></row><row><cell>RC</cell><cell>3.05±0.88</cell><cell>3.14±0.57</cell><cell>-0.67</cell><cell>0.749</cell></row><row><cell>RB</cell><cell>3.19±0.70</cell><cell>3.14±0.68</cell><cell>0.14</cell><cell>0.445</cell></row><row><cell>HLP</cell><cell>4.03±0.72</cell><cell>4.19±0.57</cell><cell>-0.69</cell><cell>0.755</cell></row><row><cell>TRU</cell><cell>3.85±0.74</cell><cell>3.87±0.81</cell><cell>-0.10</cell><cell>0.539</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/Prisca-Lab/proactive robot behaviour</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://survey.ihobo.com/DGD/DGD1.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>http://flask.pocoo.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>https://www.pythonanywhere.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>https://furhatrobotics.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>https://ipip.ori.org/newMultipleconstructs.htm</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially funded by the <rs type="funder">Italian Ministry for Universities and Research (MUR)</rs> under the grant <rs type="grantNumber">FIT4MEDROB</rs> (<rs type="grantNumber">MUR: PNC0000007</rs>) (<rs type="person">S. Rossi</rs>), and by the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020</rs> research and innovation</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZffQRfg">
					<idno type="grant-number">FIT4MEDROB</idno>
				</org>
				<org type="funding" xml:id="_GtS3YG5">
					<idno type="grant-number">MUR: PNC0000007</idno>
					<orgName type="program" subtype="full">Horizon 2020</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A systematic review of adaptivity in human-robot interaction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Orlando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimodal Technologies and Interaction</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robot&apos;s adaptive emotional feedback sustains children&apos;s social engagement and promotes their vocabulary learning: a longterm child-robot interaction study</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Orlando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="243" to="266" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introducing caresser: A framework for in situ learning robot social assistance from expert knowledge and demonstrations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andriella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Torras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Abdelnour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alenyà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey on interactive reinforcement learning: Design principles and open challenges</title>
		<author>
			<persName><forename type="first">Arzate</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Igarashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 ACM designing interactive systems conference</title>
		<meeting>the 2020 ACM designing interactive systems conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1195" to="1209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Initiative in robot assistance during collaborative task execution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Baraglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cakmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nagai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Asada</surname></persName>
		</author>
		<idno type="DOI">10.1109/HRI.2016.7451735</idno>
	</analytic>
	<monogr>
		<title level="m">2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Measuring the perceived social intelligence of robots</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Barchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lapping-Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Westfall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fink-Armold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Banisetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Feil-Seifer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Human-Robot Interaction (THRI)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">21st Century Game Design (game development series)</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bateman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Charles River Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Buyukgoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grosinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chetouani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saffiotti</surname></persName>
		</author>
		<title level="m">Two ways to make your robot proactive: Reasoning about human intentions or reasoning about possible futures. Frontiers in Robotics and AI 9</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Social intelligence for a robot engaging people in cognitive training activities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nejat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Robotic Systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">113</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Smote: synthetic minority oversampling technique</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long-term personalization of an in-home socially assistive robot for children with autism spectrum disorders</title>
		<author>
			<persName><forename type="first">C</forename><surname>Clabaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pakkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Becerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ragusa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matarić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Robotics and AI</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Knowledge tracing: Modeling the acquisition of procedural knowledge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User modeling and user-adapted interaction</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="253" to="278" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Player profiling and modelling in computer and video games</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">U</forename><surname>Cowley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Ulster</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards a computational approach for proactive robot behaviour in assistive tasks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Cucciniello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andriella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="521" to="525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Socially intelligent robots: dimensions of human-robot interaction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phil Trans R Soc B pp</title>
		<imprint>
			<biblScope unit="page" from="679" to="704" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Personalized home-care support for the elderly: a field experience with a social robot at home</title>
		<author>
			<persName><forename type="first">Di</forename><surname>Napoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ercolano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="405" to="440" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Social robots in applied settings: A long-term study on adaptive robotic tutors in higher education</title>
		<author>
			<persName><forename type="first">M</forename><surname>Donnermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schaper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lugrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Robotics and AI</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Robot exercise instructor: A socially assistive robot system to monitor and encourage physical exercise for the elderly</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fasola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mataric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th International Symposium in Robot and Human Interactive Communication</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="416" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Teaching robot&apos;s proactive behavior using human assistance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Garrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Villamizar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Moreno-Noguer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sanfeliu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="249" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian active learning-based robot tutor for children&apos;s wordreading skills</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Making robots proactive through equilibrium maintenance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grosinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pecora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saffiotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3375" to="3381" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Proactivity through equilibrium maintenance with fuzzy desirability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grosinger</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pecora</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saffiotti</surname></persName>
			<affiliation>
				<orgName type="collaboration">SMC</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Systems, Man, and Cybernetics</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2117" to="2122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robots that maintain equilibrium: Proactivity by reasoning about user intentions and preferences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grosinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pecora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saffiotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page" from="85" to="93" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards adaptive social behavior generation for assistive robots using reinforcement learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hemminghaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kopp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction</title>
		<meeting>the 2017 ACM/IEEE International Conference on Human-Robot Interaction</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="332" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Timing in human-robot interaction</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cakmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction</title>
		<meeting>the 2014 ACM/IEEE international conference on Human-robot interaction</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="509" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="127" to="143" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Inverse reinforcement learning of interaction dynamics from demonstrations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Begum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petrik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2267" to="2274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Physical human-robot interaction: Mutual learning and adaptation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ikemoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Amor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishiguro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE robotics &amp; automation magazine</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="24" to="35" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">May i help you? design of human-like polite approaching behavior</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishiguro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction</title>
		<meeting>the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interactively shaping agents via human reinforcement: The tamer framework</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Knox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth international conference on Knowledge capture</title>
		<meeting>the fifth international conference on Knowledge capture</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Effects of proactive dialogue strategies on humancomputer trust</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Minker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization, UMAP &apos;20</title>
		<meeting>the 28th ACM Conference on User Modeling, Adaptation and Personalization, UMAP &apos;20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The role of trust in proactive conversational assistants</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Callejas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Minker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="112821" to="112836" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Including social expectations for trustworthy proactive human-robot dialogue</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Untereiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Minker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization</title>
		<meeting>the 30th ACM Conference on User Modeling, Adaptation and Personalization<address><addrLine>New York, NY, USA, UMAP &apos;22</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="23" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning proactive behavior for interactive social robots</title>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Glas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ishiguro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Robots</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1067" to="1085" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A social robot learning to facilitate an assistive group-based activity from non-expert caregivers</title>
		<author>
			<persName><forename type="first">Wyg</forename><surname>Louie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nejat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1159" to="1176" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Interactive learning from policy-dependent human feedback</title>
		<author>
			<persName><forename type="first">J</forename><surname>Macglashan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Loftin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2285" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">don&apos;t get distracted!&quot;: The role of social robots&apos;interaction style on users&apos;cognitive performance, acceptance, and noncompliant behavior</title>
		<author>
			<persName><forename type="first">G</forename><surname>Maggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dell'aquila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cucciniello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2057" to="2069" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The magical number seven, plus or minus two: Some limits on our capacity for processing information</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">81</biblScope>
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning and personalizing socially assistive robot behaviors to aid with activities of daily living</title>
		<author>
			<persName><forename type="first">C</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nejat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mihailidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Human-Robot Interaction (THRI)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Probabilistic human-computer trust handling</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nothdurft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Minker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th annual meeting of the special interest group on discourse and dialogue (SIGDIAL)</title>
		<meeting>the 15th annual meeting of the special interest group on discourse and dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Decision networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pawlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rough Sets and Current Trends in Computing</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Tsumoto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Komorowski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Grzyma La-Busse</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Probabilistic reasoning in intelligent systems: networks of plausible inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Morgan kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Design and evaluation of service robot&apos;s proactivity in decision-making support process</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, CHI &apos;19</title>
		<meeting>the 2019 CHI Conference on Human Factors in Computing Systems, CHI &apos;19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Real-time robot personality adaptation based on reinforcement learning and social signals</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ritschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>André</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the companion of the 2017 acm/ieee international conference on human-robot interaction</title>
		<meeting>the companion of the 2017 acm/ieee international conference on human-robot interaction</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="265" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Emotional and behavioural distraction by a social robot for children anxiety reduction during vaccination</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Larafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ruocco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="765" to="777" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Personality-based adaptation of robot behaviour: Acceptability results on individuals with cognitive impairments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Napoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Garramone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Salvatore</forename><forename type="middle">E</forename><surname>Santangelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G ;</forename><surname>Rozo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Silvério</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Calinon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Caldwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2016">2023. 2016</date>
		</imprint>
	</monogr>
	<note>Frontiers in Robotics and AI</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning from demonstration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems 9</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Personalising game difficulty to keep children motivated to play with a social robot: A bayesian approach</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Schadenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Neerincx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cnossen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Looije</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive systems research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="222" to="231" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adaptive robot language tutoring based on bayesian knowledge tracing and predictive decision-making</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schodde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kopp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, HRI &apos;17</title>
		<meeting>the 2017 ACM/IEEE International Conference on Human-Robot Interaction, HRI &apos;17</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="128" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Employing proactive interaction for service failure prevention to improve customer service experiences</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Ellinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Mothersbaugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Service Theory and Practice</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="164" to="186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Proactive robots with the perception of nonverbal human behavior: A review</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sirithunge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abp</forename><surname>Jayasekara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chandima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="77308" to="77327" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Pay attention! designing adaptive agents that monitor and improve user engagement</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ag</forename><forename type="middle">;</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Szafir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mutlu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
		<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2012">2018. 2012</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
	<note>Reinforcement learning: An introduction</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Relationship between social robot proactive behavior and the human perception of anthropomorphic attributes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced Robotics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="1324" to="1336" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A socially adaptable framework for human-robot interaction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tanevska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Rea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cañamero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sciutti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Robotics and AI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Adaptive robot assisted therapy using interactive reinforcement learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tsiakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dagioglou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karkaletsis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Makedon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Robotics: 8th International Conference</title>
		<meeting><address><addrLine>Kansas City, MO, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-11-01">2016. 2016. November 1-3, 2016</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="11" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Preference learning in assistive robotics: Observational repeated inverse reinforcement learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Woodworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Zosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Riek</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="j">Machine learning for healthcare conference</title>
		<imprint>
			<biblScope unit="page" from="420" to="439" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Proactivity or passivity? an investigation of the effect of service robots&apos; proactive behaviour on customer co-creation intention</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Hospitality Management</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">103271</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
