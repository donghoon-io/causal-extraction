<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic Influence Diagram-Based Deep Reinforcement Learning Framework and Application for Decision Support for Operators in Control Rooms</title>
				<funder ref="#_J6NFehb">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_Bs76xYz">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mário</forename><forename type="middle">P</forename><surname>Brito</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hugin Expert A/S /TU Dublin, Denmark. Food Science Environmental Health</orgName>
								<orgName type="institution" key="instit2">Technological University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Terje</forename><surname>Aven</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hugin Expert A/S /TU Dublin, Denmark. Food Science Environmental Health</orgName>
								<orgName type="institution" key="instit2">Technological University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Piero</forename><surname>Baraldi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hugin Expert A/S /TU Dublin, Denmark. Food Science Environmental Health</orgName>
								<orgName type="institution" key="instit2">Technological University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marko</forename><surname>Čepin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hugin Expert A/S /TU Dublin, Denmark. Food Science Environmental Health</orgName>
								<orgName type="institution" key="instit2">Technological University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enrico</forename><surname>Zio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hugin Expert A/S /TU Dublin, Denmark. Food Science Environmental Health</orgName>
								<orgName type="institution" key="instit2">Technological University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joseph</forename><surname>Mietkiewicz</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Technological University</orgName>
								<address>
									<addrLine>Ireland. Data Science</addrLine>
									<settlement>Dublin</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ammar</forename><forename type="middle">N</forename><surname>Abbas</surname></persName>
							<email>ammar.abbas@scch.at</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Applied Sciences and Technology</orgName>
								<orgName type="laboratory">Safety, Reliability and Risk Centre (SAfeR)</orgName>
								<orgName type="institution">Software Competence Center Hagenberg</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Winifred</forename><surname>Chidera</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Amazu</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anders</forename><forename type="middle">L</forename><surname>Madsen</surname></persName>
							<email>anders@hugin.com</email>
							<affiliation key="aff4">
								<orgName type="department">Department of computer science</orgName>
								<orgName type="institution" key="instit1">Hugin Expert A/S</orgName>
								<orgName type="institution" key="instit2">Aalborg University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gabriele</forename><surname>Baldissone</surname></persName>
							<email>gabriele.baldissone@polito.it</email>
							<affiliation key="aff5">
								<orgName type="department">SAfeR -Department of Applied Sciences and Technology</orgName>
								<orgName type="institution">Politecnico di Torino</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic Influence Diagram-Based Deep Reinforcement Learning Framework and Application for Decision Support for Operators in Control Rooms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.3850/978-981-18-8071-1_P531-cd</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Decision support</term>
					<term>Dynamic influence diagram</term>
					<term>Reinforcement learning</term>
					<term>Process safety</term>
					<term>Intervention procedures</term>
					<term>Human-machine interface</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In today's complex industrial environment, operators are often faced with challenging situations that require quick and accurate decision-making. The human-machine interface (HMI) can display too much information, leading to information overload and potentially compromising the operator's ability to respond effectively. To address this challenge, decision support models are needed to assist operators in identifying and responding to potential safety incidents. In this paper, we present an experiment to evaluate the effectiveness of a recommendation system in addressing the challenge of information overload. The case study focuses on a formaldehyde production simulator and examines the performance of an improved Human-Machine Interface (HMI) with the use of an AI-based recommendation system utilizing a dynamic influence diagram in conjunction with reinforcement learning. The preliminary results indicate the potential of these methods to aid operators in decision-making during challenging situations and enhance process safety in the industry.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In a chemical process control room, operators are responsible for monitoring the process and responding to deviations. To do so they have to handle the available information and follow a set of procedures in order to restore the process to normal. However, human errors can occur due to overload or inadequate training. To address these issues, optimal procedures are required to assist operators in their tasks. We develop a system that provides operators with the appropriate and optimal procedure in real-time using a dynamic influence diagram combined with reinforcement learning. This system detects anomalies and provides operators with the reason for the deviation, as well as the specific procedure to follow in each case updated with the current state of the system. This framework is then tested on a simulator of formaldehyde production. Three deviation scenarios are designed and presented to two groups of participants. The first group has to respond to the scenario without the recommendation system and the second group with. The efficacy of the recommendation system is then evaluated based on its ability to assist the participants in handling deviant scenarios. The objective of this experiment is to determine if this approach reduces the operator's workload and enhances situational awareness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>The experiment is made to optimize the display of the procedure to the operator. For this purpose, we use artificial intelligence to display directly to the operator the right procedure update with the live value of the process. For this purpose, a dynamic influence diagram combined with reinforcement learning is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Procedures</head><p>Procedures are supporting tools that guide control operators to manage process plant operations and safety. These process operations can be; the startup and shut-down of a plant, normal operations, emergency operations, and more. In a study done by <ref type="bibr" target="#b3">Bakar et al. (2017)</ref>, to identify process safety management elements that are main accident contributors (from amongst 770 major accident cases) in chemical process plants, Operating procedures were found to be the second most contributors to accidents in this plants at 17 % just after process failures at 19 %. Similarly, findings in the nuclear industry have also shown that operators' noncompliance behaviour due to procedures is one of the leading causes of accidents in this industry <ref type="bibr" target="#b9">Park and Jung (2003)</ref>. As one of the process safety management elements, these procedures are critical to ensuring safety and should be paid close attention to beyond the initial stages of design and installation.</p><p>Several constraints the procedures pose leading to these non-compliance behaviours have been highlighted in industrial studies. These constraints, related to inaccuracy or incompleteness and complexity of the procedures, have led to non-compliance issues by operators, which is one of the reasons for the accidents <ref type="bibr" target="#b9">Park and Jung (2003)</ref>. Also, there have been studies on constraints related to design. That is, the design of these procedures (medium of presentation and the presentation style) and how they impact the operators' workload, especially in emergencies, seeing that some industries have moved over years from paper-based, screen-based and, in some cases, computerised procedures <ref type="bibr" target="#b4">Gao et al. (2013)</ref>, <ref type="bibr" target="#b12">Xu et al. (2008)</ref>. The ease of use of the procedures, their ability to support operators' situational awareness and reduce workload within the available time in abnormal situations are goals to be attained by decision-makers if safety is to be ensured. In this work, a screen-based procedure (following best practices in procedural formatting -HPOG) added or not with AI-based support is developed to compare and assess the impact of different procedural support mediums on process control room operators during an intervention in process safety scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">AI-based Recommendation System</head><p>The AI-based recommendation system is using both Deep Reinforcement Learning (DRL) and a dynamic influence diagram. The DRL is trained on the simulator in an online setting by interacting with the environment and observing process behavior through its actions. The dynamic influence diagram is constructed from expert knowledge consisting of the physical equation of the plants. Those models are combined to detect deviance in the process and recommend the best action to the operator by providing a detailed procedure with specific values adapted to the current situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Dynamic Influence diagram</head><p>In the realm of decision-making under uncertainty, influence diagrams <ref type="bibr" target="#b6">Howard (1983)</ref> have emerged as an effective modeling framework. These diagrams provide a natural way to capture the semantics of decision-making with minimal clutter and confusion for the decision-maker <ref type="bibr" target="#b10">Shachter and Peot (1992)</ref>. It is perfect to model uncertainty in the process and provide the best recommendation. An influence diagram is a graphical probabilistic model that provides a framework for optimal decision-making under uncertainty. Dynamic Influence diagrams (DID) can be used to monitor the process over time by modeling the dynamics of the system and the influence of various factors on the system's behavior. DID can also be used to predict the future behavior of the system by simulating different scenarios and observing their impact on the overall system. This allows for better decision-making based on the potential outcomes of different choices. <ref type="bibr" target="#b7">Kjaerulff et al. (2013)</ref>.</p><p>In this study, the physical model of the plant is used to build the dynamic influence diagram. The different nodes can represent:</p><p>(1) values, such as temperature, pressure, etc.</p><p>(2) temporal clones of values, such as temperature, and pressure, representing the influence of the past. (3) failure, such as control valve failure. ( <ref type="formula">4</ref>) decisions, such as set points.</p><p>(5) costs associated with a particular event.</p><p>Each of these nodes is linked to other nodes through causal links. There is an associated cost called utility with each possible action of the decision node. The model outputs to the operator the action with the maximum expected utility.</p><p>For example, in the case of choosing the right flow of nitrogen to avoid overpressure in a tank. If A is a set point for a flow with options 0 -1, . . . , 6 -7 (Nm 3 /h), H is a specific alarm link to the underpressure of the tank with states F alse, T rue, and is a set of observations in the form of evidence, then we can compute the utility of each outcome of the hypothesis and the expected utility of each action. The utility of an outcome (0 -1, T rue) is U (0 -1, T rue), where U (•) is our utility function. The expected utility of performing action setting 4 -5 Nm 3 /h as a nitrogen flow is calculated by</p><formula xml:id="formula_0">EU (4 -5) = U (4 -5, T rue)P (T rue| ) + U (4 -5, F alse)P (F alse| ) 2.2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.2. Using Dynamic Influence Diagram</head><p>The model is dynamic to monitor the process over time. The model assesses the state of the system at the current time and predicts the future state for numerous subsequent time steps. The dynamic influence diagram serves three distinct purposes:</p><p>(1) Detecting anomalies (2) Predicting the future state of the system (3) Determine an optimal decision. The model is built using expert knowledge in the form of the physical equation of the process. The detection of anomalies uses the present data and can detect for example a deviation from a setpoint. The model is able to predict the future state of the system for the next time steps. According to this prediction, an ideal scenario can be built and presented to the operator. This recommendation is based on the procedure associated with the detected anomaly. The procedure is adapted to provide concise instruction and precise values to set according to the system's current state to the operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3.">Specialized Reinforcement learning</head><p>Agent (SRLA)</p><p>Reinforcement Learning (RL) is a type of machine learning in which an agent learns to make decisions by interacting with an environment and receiving feedback in the form of rewards or penalties. The goal of the agent is to learn a policy, or a mapping of states to actions, that maximizes its cumulative reward over time <ref type="bibr" target="#b11">Sutton and Barto (2018)</ref>.</p><p>The equation of reinforcement learning can be represented using the Q-learning algorithm, which is a model-free reinforcement learning algorithm. In Q-learning, an agent learns to make decisions by iteratively updating a Q-value function that estimates the expected cumulative reward for taking a particular action in a particular state. The Qvalue function can be represented as follows:</p><formula xml:id="formula_1">Q(s, a) = E[r + γ * max a Q(s , a )]<label>(1)</label></formula><p>DRL extends Q-learning by using deep neural networks to estimate the Q-value function. The neural network takes the state as input and produces the Q-value estimates for all possible actions as output. The Q-value function is then updated by minimizing the difference between the predicted Q-values and the actual Q-values obtained from the rewards received by the agent during training. The equation for updating the Qvalue function in deep reinforcement learning can be represented as follows:</p><formula xml:id="formula_2">Q(s, a) = Q(s, a)+ α(r + γ * max a Q(s , a ) -Q(s, a)) (2)</formula><p>In both equations, the symbol γ represents the discount factor, r represents the immediate reward received by the agent, s represents the current state of the agent, a represents the action taken by the agent, s represents the next state of the agent, and a represents the action taken in the next state. The symbol α represents the learning rate, which determines the step size of the Q-value updates.</p><p>Specialized Reinforcement Learning Agent (SRLA) combines the advantages of probabilistic modeling (such as dynamic influence diagram) and Deep Reinforcement Learning (DRL) <ref type="bibr" target="#b0">Abbas et al. (2022)</ref> as shown in fig. <ref type="figure" target="#fig_0">1</ref>. It allows the DRL agent to specialize in a specific case within the environment where the DRL agent is most required (such as process abnormalities). Hence, increasing training efficiency and reducing data inefficiency.</p><p>In the figure, P (s t ) represents the probability of being in a particular state, x * (s t ) represents the specialized state on which the DRL agent is activated and the system state S is filtered to provide the information regarding that particular state. The optimal control strategy π is then recommended to the operator.</p><p>SRLA modifies eq. ( <ref type="formula">2</ref>) as shown in eq. (3):</p><formula xml:id="formula_3">Q(x * , a) = Q(x * , a)+ α(r + γ * max a Q(x * , a ) -Q(x * , a)) (3)</formula><p>where x * represents the specialized state on which the DRL agent is activated and trained and is identified through a probabilistic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Framework</head><p>In our proposed AI recommendation system framework with the Human-in-the-Loop (HITL) setting, we use Multi Specialized Reinforcement Learning Agent (M-SRLA) setting. The multiagents in this setting act independently and only a specific agent is activated to suggest the optimal control strategy to the operator in case of the identified process abnormality through the influence diagram as shown in fig. <ref type="figure">4</ref>. We name this framework Human-Centered Artificial Intelligence for Safety-Critical systems "HAISC".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Procedure and Dynamic Influence Diagram</head><p>The procedure in this study is written as a hierarchical rule-based task representation format and is further presented on screen for the operators. Each procedure is written under three broad task contexts; troubleshooting, control, and evaluation. An example is shown in fig. <ref type="figure" target="#fig_1">2</ref>. The recommendation of the influence diagram is based on the procedure. The influence diagram detects the anomaly and recommends the procedure associated with it.</p><p>The procedure is simplified by directly providing the action to do without troubleshooting and control. In case of different anomalies at the same time, the influence diagram chose the best action to do according to their utility. The specific value to set in the procedure is then specified jointly with reinforcement learning. In this way, the procedure is adapted to the specific situation of the system and provide the operator with a complete and concise set of instruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Dynamic Influence Diagram and Reinforcement learning</head><p>The approach uses an influence diagram to identify the specific failure in the system. Once the procedure associated with the failure is identified, the necessary step of the procedure according to the current situation is displayed to the operator. If the procedure requires continuous values to be set, reinforcement learning is employed to specify the appropriate value based on the current state of the system. The influence diagram provides a value in the form of an interval due to the discretization of the data. If the value obtained from the reinforcement learning falls outside of this interval, only the procedure along with the interval is displayed to the operator. This is done to ensure the interpretability and safety of the overall system. All in all the influence diagram models the system globally and the reinforcement learning answers </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Recommendation</head><p>The operator is provided with recommendations that include the identified faults and the appropriate procedures for restoring the system to its normal state. Traditionally, these procedures were developed by experts. However, with the advent of the AI framework, the procedures have been simplified and specific values are now provided based on the current state of the system. This eliminates any extraneous or irrelevant steps, allowing the operator to quickly and easily follow the complete set of recommendations. fig. <ref type="figure">3</ref> depicts an example of a simplified procedure compared to the traditional one. The simulator is one of the productions of formaldehyde operating the partial oxidation of methanol with air. The details of the simulator can be found in Amazu and all ( <ref type="formula">2023</ref>). The operator is responsible for monitoring the process and correcting any deviations. fig. <ref type="figure" target="#fig_2">5</ref> shows the main screen of the simulator, and for this preliminary study, three scenarios have been created. In the first scenario, a control valve failure in the tank section occurred. The operator must open the tank part of the system, switch to manual mode, and adjust the set point of the flow value. In the second scenario, a valve failure in the tank section occurred. In this scenario, the operator must switch to the backup system and adjust the pump power due to a delay in the nitrogen flow coming from the backup system. The third scenario simulated a failure of temperature indicator control that has an impact on the reactor. The operator needs to maintain the right temperature in the reactor. The first group of participants has all the procedures available on the screen, while the second group has additional support from the recommendation system which provides a concise live procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Physiological measurement</head><p>Physiological measurement is used to have an objective measurement of the operator's workload and situation awareness and have a better insight into the recommendation system's benefit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Heart rate</head><p>By monitoring the operator's heart rate (HR) and heart rate variability (HRV), before and after using the recommendation system, we can determine whether the system is reducing or increasing their stress and workload levels <ref type="bibr" target="#b4">Gao et al. (2013)</ref>, <ref type="bibr" target="#b8">Muhajir et al. (2021)</ref>. If the recommendation system is effective, we would expect to see a decrease in the operator's workload and stress levels after using the system compared to before. However, it is important to note that a decrease in heart rate doesn't necessarily mean that the recommendation system is effective. There are other factors that could contribute to a decrease in heart rate, such as taking a break, delegating tasks, or even just the passage of time. Therefore, it is important to combine these physiological measures with other metrics such as task completion time and error rate to determine the effectiveness of the recommendation system. Monitoring the operator's HR, HRV, and EDA, can provide valuable insights into their workload and the effectiveness of the recommendation system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Eye tracker</head><p>Eye tracking is a valuable technique for monitoring participants during experiments. By tracking eye movements, it is possible to gain more insights into the participant's cognitive states of attention, mental workload, and situational awareness Hinss  <ref type="formula">2022</ref>), <ref type="bibr" target="#b2">Amazu et al. (2022)</ref>. During the experiment, the eye tracker monitors the participant's eye movement as they interact with the recommendation system on the human-machine interface and respond to the different scenarios. This information is analyzed to determine which support types (screen or AI) are most effective in guiding the participant's decision-making process. Additionally, eye tracking can reveal when and where the participant experiences difficulty or confusion, allowing researchers to identify areas that require improvement. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NASA-TLX (National Aeronautics and Space</head><p>Administration-Task Load Index) is a widely used subjective rating scale that measures the perceived workload and mental effort required to complete a task. During the experiment, NASA-TLX is used to assess the participant's subjective workload after operating in a scenario. Participants rate their overall perceived workload in the scenario based on six different dimensions, including mental demand, physical demand, temporal demand, performance, effort, and frustration. The result compares the workload of people with and without recommendations during the scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Situation awareness</head><p>The Situation Awareness Rating Technique (SART) is a subjective rating technique used to assess situational awareness post-trial. It measures the situational awareness of test participants in ten dimensions; attention, information quality, and more. During the experiment, SART is completed post-scenario by the participants to assess their overall situational awareness. The use of SART in this experimental study allows us to study the variation in situational awareness between the two groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Recommendation system</head><p>Questionnaires are given to the participant to assess the efficiency of the recommendation system. The questionnaire is designed to gather feedback from the participants on the ease of use, clarity, and relevance of the recommendations provided by the system. The questionnaire includes questions related to the participant's perception of the recommendation system's ability to detect faults, the accuracy of the recommendations provided, and the system's usefulness in guiding decisionmaking during the deviance scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Preliminary result</head><p>A pilot study was conducted to evaluate the performance of the recommendation system. It was with 2 participants without the recommendation system and 2 with. It did not allow us to obtain sufficiently significant statistical data. But we observed that the group with the recommendation system acts faster but tends to follow the recommendation blindly. In this case, the recommendation system tends to reduce the workload but also to reduce situational awareness. These promising results suggest that the recommendation system effectively reduces workload but decreases situational awareness during process safety decisionmaking. Further research with larger participant samples is needed to confirm these findings and to optimize the design of the recommendation system for wider application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The presentation of the procedure to the operator is crucial. Providing the operator with the right and simplified procedure that adapts to the current system state has shown promising results in assisting the operator's work. Thanks to the collaboration between the influence diagram and reinforcement learning, the recommended procedure is interpretable and based on expert knowledge. This system would be particularly advantageous for operators in situations of overload, stress, or inexperienced operators.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Specialized Reinforcement Learning Agent (SRLA) Abbas et al. (2022)</figDesc><graphic coords="5,78.83,74.69,335.97,182.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. First steps of the procedure for one alarm</figDesc><graphic coords="5,255.83,415.97,197.50,108.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Simulator main screen</figDesc><graphic coords="7,295.55,74.33,132.09,224.06" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the 33rd European Safety and Reliability Conference(ESREL 2023)   </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work has been done within the <rs type="projectName">Collaborative Intelligence for Safety-Critical Systems</rs> project (<rs type="projectName">CISC</rs>). The CISC project has received funding from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 Research and Innovation Programme</rs> under the <rs type="grantName">Marie Skłodowska-Curie</rs> grant agreement no. <rs type="grantNumber">955901</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Bs76xYz">
					<orgName type="project" subtype="full">Collaborative Intelligence for Safety-Critical Systems</orgName>
				</org>
				<org type="funded-project" xml:id="_J6NFehb">
					<idno type="grant-number">955901</idno>
					<orgName type="grant-name">Marie Skłodowska-Curie</orgName>
					<orgName type="project" subtype="full">CISC</orgName>
					<orgName type="program" subtype="full">Horizon 2020 Research and Innovation Programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Interpretable input-output hidden markov model-based deep reinforcement learning for the predictive maintenance of turbofan engines</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Chasparis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kelleher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data Analytics and Knowledge Discovery: 24th International Conference</title>
		<meeting><address><addrLine>DaWaK; Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022-08-22">2022. 2022. August 22-24, 2022</date>
			<biblScope unit="page" from="133" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Analysing &quot;human-in-theloop</title>
		<author>
			<persName><forename type="first">B</forename><surname>Amazu</surname></persName>
		</author>
		<author>
			<persName><surname>All</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>for advances in process safety: a design of experiment in a simulated process control room</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Human-in-the-loop configurations in process and energy industries: a systematic review</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Amazu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Demichela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fissore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd European Safety and Reliability Conference (ESREL 2022)</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Leva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Patelli</forename><surname>Edoardo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Podofillini</forename><surname>Luca</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wilson</forename><surname>Simon</surname></persName>
		</editor>
		<meeting>the 32nd European Safety and Reliability Conference (ESREL 2022)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Research Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3234" to="3241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis of main accident contributor according to process safety management elements failure</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T A</forename><surname>Bakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Siong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kidam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Hassim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kamarden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical Engineering Transactions</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="991" to="996" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mental workload measurement for emergency operating procedures in digital nuclear power plants</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ergonomics</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1070" to="1085" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cognitive effects of prolonged continuous humanmachine interaction: The case for mental state-based adaptive interfaces</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Hinss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroergonomics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Readings on the principles and applications of decision analysis: General collection</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Strategic Decisions Group</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">U</forename><surname>Kjaerulff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Networks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Influence diagrams: a guide to construction and analysis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stress level measurements using heart rate variability analysis on android based application</title>
		<author>
			<persName><forename type="first">D</forename><surname>Muhajir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mahananto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Sani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="page" from="189" to="197" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The operators&apos; noncompliance behavior to conduct emergency operating procedures -Comparing with the work experience and the complexity of procedural steps</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliability Engineering and System Safety</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="131" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Decision making using probabilistic inference methods</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Peot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="276" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An ergonomics study of computerized emergency operating procedures: Presentation style, task complexity, and training level</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Salvendy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliability Engineering and System Safety</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1500" to="1511" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
