<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reasoning with Contextual Knowledge and Influence Diagrams</title>
				<funder ref="#_tsbxUZe">
					<orgName type="full">Dutch Research Council (NWO)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Erman</forename><surname>Acar</surname></persName>
							<email>erman.acar@vu.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Milano-Bicocca</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rafael</forename><surname>Pe Ñaloza</surname></persName>
							<email>rafael.penaloza@unimib.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Milano-Bicocca</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vrije</forename><forename type="middle">Universiteit</forename><surname>Amsterdam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Milano-Bicocca</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Reasoning with Contextual Knowledge and Influence Diagrams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Influence diagrams (IDs) are well-known formalisms extending Bayesian networks to model decision situations under uncertainty. Although they are convenient as a decision theoretic tool, their knowledge representation ability is limited in capturing other crucial notions such as logical consistency. We complement IDs with the light-weight description logic (DL) EL to overcome such limitations. We consider a setup where DL axioms hold in some contexts, yet the actual context is uncertain. The framework benefits from the convenience of using DL as a domain knowledge representation language and the modelling strength of IDs to deal with decisions over contexts in the presence of contextual uncertainty. We define related reasoning problems and study their computational complexity. S D TA P c D 0.3 S D 0.4 ¬D 0.1 c D P TA 0 D P ¬TA 5 D ¬P TA 20 D ¬P ¬TA 90 ¬D P TA 2 ¬D P ¬TA 20 ¬D ¬P TA 0 ¬D ¬P ¬TA 20 TA S ¬S P D TA 0.7 D ¬TA 0.9 ¬D TA 0.4 ¬D ¬TA 0.1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A well-known limitation of classical description logics (DLs) is their inability to deal with uncertainty <ref type="bibr" target="#b3">(Baader et al. 2007</ref>). To model different aspects of knowledge domains where uncertainty is unavoidable, such as in the bio-medical sciences, many probabilistic extensions of DLs have been proposed in the literature <ref type="bibr" target="#b15">(Lukasiewicz and Straccia 2008;</ref><ref type="bibr" target="#b17">Niepert, Noessner, and Stuckenschmidt 2011;</ref><ref type="bibr" target="#b12">Gutiérrez-Basulto et al. 2017;</ref><ref type="bibr" target="#b19">Riguzzi et al. 2015)</ref>. Among them, a prominent example are Bayesian DLs <ref type="bibr" target="#b10">(Ceylan and Peñaloza 2017;</ref><ref type="bibr">Ceylan and Peñaloza 2014b;</ref><ref type="bibr" target="#b7">Botha, Meyer, and Peñaloza 2019;</ref><ref type="bibr" target="#b10">d'Amato, Fanizzi, and Lukasiewicz 2008)</ref>, which provide a means for expressing complex probabilistic and logical dependencies between axioms. For example, in these logics it is easy to express that two axioms must always appear together, or that if one axiom holds, then the likelihood of another one holding is some probability p.</p><p>The expressive power of Bayesian DL arises from combining a set of (classical) DL ontologies (called contexts) with a Bayesian network (BN) <ref type="bibr" target="#b18">(Pearl 1988)</ref> representing the joint probability distribution of these ontologies. This allows to reason about the likelihood of a consequence to hold, given the current knowledge and update the beliefs about the probabilities of the contexts. However, this remains a passive attitude towards knowledge, in the sense that nothing is done with it. In practice, an agent should be able to make choices depending on its knowledge and observations and maximize its expected returns. BNs cannot express them.</p><p>Influence diagrams (IDs) <ref type="bibr" target="#b21">(Shachter 1986</ref>) generalise BNs to model potential decisions made by an agent and their associated costs. Consider for example the fictitious disease idelium, which may remain asymptomatic, and two potential tests for detecting whether an individual is infected or not. Test A is cheap, but not very reliable, while Test B is much more reliable, but expensive and intrusive. The cost of false positives and false negatives is high. The former due to the inconveniences it causes in the life of the subject, and the latter because it can further spread the disease. The joint probabilities of finding false positives or false negatives in the presence or absence of symptoms dependent on the test used can be modelled via a BN. However, an agent would be more interested in deciding which test to perform, in order to minimise the expected combined cost of test, intrusiveness, and false results. Thus, we extend the BN to an ID which includes the decision node for the test to perform, along information about the cost of each setting (see Figure <ref type="figure" target="#fig_0">1</ref>). We propose an extension of the Bayesian DL BEL (Ceylan and Peñaloza 2014a) which allows for agent decisionmaking combining influence diagrams with the light-weight DL EL <ref type="bibr" target="#b4">(Baader, Brandt, and Lutz 2005)</ref>. We call it ID-EL. Our main goal is to allow automated decision making in the presence of uncertainty and domain knowledge.</p><p>In ID-EL, the contexts consider the uncertainty in the network, together with the potential choices from the agent and, obviously, their associated costs. More importantly, the ontological knowledge can be used as evidence about the potential context, thus modifying the underlying probabilities, during the agent decision process. For example, if idelium causes a green coloration of the bones, we want to add the knowledge Bone ∃hasColor.Green which holds only in case of disease, but not when the subject is healthy. We study the reasoning problems associated with the selection, by the agent, of a strategy that minimises its expected cost given such evidence, together with other relevant tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>We first introduce the basic notions of influence diagrams and the DL EL needed for the rest of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Influence Diagrams</head><p>Influence diagrams (IDs) <ref type="bibr" target="#b21">(Shachter 1986</ref>) are graphical models which generalise Bayesian networks (BNs) <ref type="bibr">(Pearl</ref>  The probability table for the node TA is not specified. 1988) by allowing three types of nodes: chance nodes that reflect the uncertainty of the environment as in BNs; decision nodes, which express the choices made by an agent in response to the environment; and a cost node (also called a utility node), which reflects the cost (or utility) of a given outcome. From a formal perspective, each of these nodes is a discrete random variable, and the main difference is how this variable is interpreted or used within the network. Importantly, the agent can only influence its own decision nodes, while chance nodes can be seen as environment attacks.</p><p>Formally, an influence diagram is a pair D = (G, Φ) where G = (V ∪ {c}, E) is a directed acyclic graph (DAG), whose nodes V are partitioned into two disjoint sets B and D of chance nodes (or Bayesian nodes), and decision nodes, respectively, and c is a single cost node. For simplicity, we assume w.l.o.g. that all nodes in V are Boolean random variables (RVs). <ref type="foot" target="#foot_1">1</ref> The cost node c has no outgoing edges, and represents a cost function from the valuations of its parent nodes to a finite set val(c) ⊆ R of values. For a node v ∈ V ∪{c}, π(v) denotes the parents of v. Given a decision node d ∈ D, d-anc(d) is the set of all decision ancestors of d, and its influence set is</p><formula xml:id="formula_0">infl(d) := d-anc(d) ∪ π(d).</formula><p>When D uses the nodes V ∪ {c}, we say that D is an ID over V . Φ is a class of conditional probability distribution tables (PDTs) P (v | π(v)), one for each chance node v ∈ B given its parents. Note that no probability distribution is associated to decision nodes, and recall that the node c represents a function from the class of all valuations of π(c) to R.</p><p>IDs are represented graphically using circles to denote chance nodes, squares for decision nodes, and a diamond for the cost node. Figure <ref type="figure" target="#fig_0">1</ref> shows an ID for our fictitious idelium disease. The probability of getting an infection (D) is 0.3, and it has highly specific symptoms (S). There are two tests: Test A (TA) which is cheaper, and Test B (¬TA) which is more precise. The overall cost depends on whether the diagnosis (P stands for a positive diagnosis) is correct, and which test was used. Seen in this way, an ID are incomplete BN where some of the nodes are missing their conditional probability tables, given their parents;<ref type="foot" target="#foot_2">foot_2</ref> e.g., in Figure <ref type="figure" target="#fig_0">1</ref>, the decision node TA has no associated PDT.</p><p>If the missing tables were added to the ID, then one could derive the joint probability distribution of all the variables in V using the standard chain rule from BNs</p><formula xml:id="formula_1">P D (V ) = v∈V P (v | π(v)).</formula><p>Instead, in an ID, the decision nodes correspond to possible choices by an agent based on the information available. The actual response of the agent is called a strategy, and each strategy has an associated value. Since it is the agent itself who is making the choices, these can depend on previous decisions made, of which the agent has full knowledge. Hence, choices depend on the whole influence set of a node. We emphasise once again that the strategy at a decision node does not depend on its parents only, but on its whole influence set; that is, it depends on its decision ancestors. Intuitively, we can see the direction of the DAG edges as a precedence in the choices made. Hence, every decision depends also on the choices made earlier. This can be understood as having implicit connections between the node d and its influence set. This assumption, known as no-forgetting, is commonly used in IDs, thus we include it in our formalism. However, removing it would have no effect over the results in this work, modulo a smaller size of the tables representing local strategies. In the ID from Figure <ref type="figure" target="#fig_0">1</ref>, a possible pure strategy S is to assign P (TA | ¬S) = P (¬TA | S) = 1. To distinguish pure and general strategies, the former are also called actions. P D(S) denotes the probability distribution obtained by adopting the strategy S in the ID D.</p><p>Clearly, an agent has a very large (in fact, infinite) class of strategies from which to choose. Which one is better depends on the probability of paying different costs given the chosen strategy. One usual approach for choosing a strategy is to try to minimise the expected cost. Definition 2 (Expected cost). Given a global strategy S on the ID D, the expected cost of S w.r.t. D is</p><formula xml:id="formula_2">E[D | S] := r∈val(c) r • P D(S) (c = r).</formula><p>The example strategy S on the ID D of Figure <ref type="figure" target="#fig_0">1</ref> yields P D(S) (c = 2) = P D(S) (¬D, P, TA) = P D(S) (¬D, P, TA, S) = 0.7•0.9•0.4 = 0.252 and in general Strategies in IDs are often targeted to minimising the expected cost on the resulting network. However, other kinds of problems can also be considered over these networks; e.g., finding the most likely cost, or maximising the probability of the minimum cost. If we limit ourselves to pure strategies only, then one can verify that the strategy S which assigns P (TA | S) = P (TA | ¬S) = 1 maximises the probability of observing the least possible cost 0: P D(S ) (c = 0) = 0.63. This strategy also minimises the expected cost. In general, strategies reflect the response of the agent to the situations imposed by the environment.</p><formula xml:id="formula_3">P D(S) (c = r) =             </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">EL</head><p>EL <ref type="bibr" target="#b4">(Baader, Brandt, and Lutz 2005)</ref> is a light-weight description logic, which allows for polynomial reasoning in standard reasoning tasks. As with all DLs, its main components are concepts and roles, corresponding to unary and binary predicates of first-order logic, respectively.</p><p>Let N C and N R be two disjoint sets of concept names and role names, respectively. EL concepts are built through the grammar rule In the next section, we combine IDs with EL, where the knowledge is divided in different contexts, and later study some of its reasoning problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IDs and Contextual Ontologies</head><p>We now introduce a new logic that combines EL with an ID to allow reasoning and deriving strategies according to observed knowledge. The connection between the two formalisms is based on adding a contextual annotation to every axiom, expressing in which circumstances it is required to hold. This notion of a knowledge base is formalised next.</p><p>Definition 3 (KB). Consider three mutually disjoint sets V , N C , and N R of contextual variables (or variables for short), concept names, and role names, respectively. A (contextual) general concept inclusion (V -GCI) is an expression of the form C D : ϕ where C, D are two EL concepts and ϕ is a propositional formula over V . A V -TBox is a finite set of V -GCIs. An ID-EL knowledge base (KB) is a pair K = (D, T ), where D is an ID over V and T is a V -TBox.</p><p>As with other existing context-based DLs <ref type="bibr" target="#b10">(Ceylan and Peñaloza 2017;</ref><ref type="bibr" target="#b6">Baader, Knechtel, and Peñaloza 2012)</ref>, the idea is that a V -GCI is only required to hold when its context ϕ is satisfied. This intuition is formalised via a possible world semantics using so-called V -interpretations. These combine classical DL interpretations with propositional valuations to link the GCIs with their contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4 (Semantics</head><formula xml:id="formula_4">). A V -interpretation is a triple of the form I = (∆ I , • I , V I ), where (∆ I , • I ) is an EL inter- pretation, and V I : V → {0, 1} is a valuation of V . The interpretation function • I is extended to complex concepts as usual in EL. The V -interpretation I satisfies the V -GCI C D : ϕ (I |= C D : ϕ ) iff V I |= ϕ or C I ⊆ D I . It is a model of the V -TBox T iff it satisfies all V -GCIs in T .</formula><p>When there is no ambiguity, we omit the prefix V and speak of e.g., interpretations or TBoxes. Clearly, the probabilistic DL BEL (Ceylan and Peñaloza 2017)-which combines a contextual ontology with a BN-is a special case of ID-EL, in which there are no decision nodes, and the cost node is ignored (e.g., it may be disconnected from the rest of the DAG). As in that special case, it is often useful to consider the classical EL TBoxes induced by the valuations of the variables in V. These correspond to the GCIs that would need to be satisfied by any model which uses this valuation.</p><p>Definition 5 (Restricted KB). Let K = (D, T ) be a KB, and W a valuation of the variables in V . The restriction of T to W is the EL TBox</p><formula xml:id="formula_5">T W := {C D | C D : ϕ ∈ T , W |= ϕ}.</formula><p>To consider the uncertainty associated with the contexts, BEL defines a possible world semantics where each world is associated with a probability that needs to be compatible with the probability distribution of the nodes. In ID-EL this definition cannot be applied directly, because the actual probability distribution is underspecified. In fact, recall that the full distribution depends on the strategy chosen by the agent. Thus, the notion of probabilistic models must be parameterised w.r.t. a strategy.</p><p>Definition 6 (Probabilistic model). A probabilistic interpretation is a pair P = (I, P I ), where I is a finite set of V -interpretations and P I is a probability distribution over I. This probabilistic interpretation is a model of the TBox T if every Given an ID D and a strategy S on D, the probabilistic interpretation P is consistent with D w.r.t. S if for every possible valuation W of the variables in V it holds that</p><formula xml:id="formula_6">I ∈ I is a model of T . i W i Sub Ii Inf Ii Con Ii Dis Ii Ben Ii Saf Ii 1 {D, S, P, ¬TA} {δ} {δ} {δ} {δ} ∅ ∅ 2 {D, S, ¬P, ¬TA} ∅ ∅ ∅ ∅ ∅ ∅ 3 {D, ¬S, P, TA} {δ} {δ} ∅ ∅ ∅ ∅ 4 {D, ¬S, ¬P, TA} {δ} {δ} ∅ ∅ {δ} {δ} 5 {¬D, S, P, ¬TA} {δ} ∅ {δ} {δ} ∅ ∅ 6 {¬D, S, ¬P, ¬TA} ∅ ∅ {δ} {δ} {δ} ∅ 7 {¬D, ¬S, P, TA} {δ} ∅ {δ} ∅ ∅ ∅ 8 {¬D, ¬S, ¬P, TA} ∅ ∅ ∅ {δ} ∅ {δ}</formula><formula xml:id="formula_7">P D(S) (W) = I∈I,V I =W P I (I).</formula><p>P is a model of the KB K = (D, T ) w.r.t. the strategy S (denoted as P |= S K) iff it is a model of T and consistent with D w.r.t. S.</p><p>We explain these notions with a brief example. Example 7. Let K ex = (D, T ex ) be the ID-EL KB where D is the ID in Figure <ref type="figure" target="#fig_0">1</ref>, and 3</p><formula xml:id="formula_8">T ex := { Subject Infectious : D , Subject Control : S ∨ P , Control Distance : S , Control Benefits : ¬P Subject Safe : ¬P ∧ ¬S }. W ex = {D, ¬S, TA, ¬P} is a valuation of V . The interpreta- tion I ex = ({δ}, • Iex , W ex ) with Sub Iex = Inf Iex = Con Iex =</formula><p>{δ} and Dis Iex = Ben Iex = Saf Iex = ∅ satisfies the first three GCIs, but not the last two. Indeed, W ex |= ¬P but Con Iex ⊆ Ben Iex , and</p><formula xml:id="formula_9">W ex |= ¬P ∧ ¬S but Con Iex ⊆ Saf Iex Let now I i := ({δ}, • Ii , W i ), 1 ≤ i ≤ 8</formula><p>be the V -interpretations defined by the interpretation functions and valuations from Table <ref type="table" target="#tab_1">1</ref>. These simple interpretations are depicted in Figure <ref type="figure">2</ref>. It is easy to verify that the probabilistic interpretation P ex = (I, P I ) given by I = {I 1 , . . . , I 8 } and the distribution P I from Table <ref type="table" target="#tab_2">2</ref> is a model of T ex which is also consistent with the strategy S that assigns</p><formula xml:id="formula_10">P (TA | ¬S) = P (¬TA | S) = 1. Hence P ex is a model of K ex w.r.t. S.</formula><p>In this example, we see how domain knowledge is separated from the ID. For example, we model that subjects are put under medical control if they present symptoms or have 3 Following the example in the introduction, we could add Bone ∃hasColor.Green : D to this TBox. We chose not to do so to simplify the following examples. been tested positive. Implicitly, in the context of symptoms, every subject should keep a safe distance. Note that these are not part of the ID itself, but give us knowledge that holds in case some of its nodes are made true.</p><p>The notion of a model is always dependent on a given strategy chosen by the agent. This is in line with our general understanding of IDs. For instance, the strategy of an agent could be such that some contexts become impossible; e.g., the strategy S from Example 7, requires valuations containing S and TA to have probability 0 (i.e., symptomatic people are always presented with test B in this strategy). Then, a model of the knowledge of this agent should disallow any positive probability in those contexts. As a consequence, the basic reasoning tasks in ID-EL must also be parameterised on the chosen strategy. We also note that the requirement for I to be finite can be relaxed by imposing some additional constraints in the probability distribution P I . To avoid unnecessary technicalities, we simply focus on the finite case.</p><p>Recall that the choice of a strategy is only a means, and the actual value of interest is the cost associated to this strategy. We extend this idea and define the cost associated with V -interpretations and probabilistic models.</p><formula xml:id="formula_11">Definition 8 (Expected cost). Given an ID D over V, the cost of the V -interpretation I = (∆ I , • I , V I ) is defined by c(I) := c(V I | π(c) )</formula><p>, where V I | π(c) denotes the restriction of the valuation V I to the parents of c.</p><p>Given a strategy S on D and a probabilistic interpretation P = (I, P I ) which is consistent with D w.r.t. S, the expected cost of P (w.r.t. S) is</p><formula xml:id="formula_12">E[P | S] := I∈I P I (I) • c(I).</formula><p>Since the probability distribution in a probabilistic model must be consistent with the distribution induced by the strategy S, the expected cost of any model of a KB K = (D, T ) w.r.t. S corresponds exactly to the expected cost of D w.r.t. S. That is, once that the strategy has been chosen, the expected cost does not depend on the specific model of K, but only on the probabilities associated to this strategy. Thus, we can define the expected cost of the KB K w.r.t. S as</p><formula xml:id="formula_13">E[K | S] := E[P | S],</formula><p>where P is any model of K.</p><p>Before moving to the next section, we present the following remark. Rather than defining a cost function directly on the nodes of the network, it sometimes makes sense to consider this function to be implicitly defined by the properties of the contexts that the node c can observe. In the extreme case, all nodes in V are parents of c and defining the cost function in terms of the contexts obtained by each valuation avoids having to represent the exponentially large mapping. A natural choice for such a cost function is the size of the context. Intuitively, this function would allow us to express that a smaller context is preferred over a larger one. Using this function makes sense, for instance, when the context needs to be transferred or manipulated over an unreliable channel. A smaller ontology is preferred to reduce the risk of errors. However, many other functions can be considered depending on the application. As an additional example, if the contexts refer to different levels of granularity of access, then considering the size of the vocabulary as cost is more relevant, as a larger vocabulary corresponds to a wider access to the knowledge. We emphasise, however, that ID-EL does not require the use of any of these cost functions, or even that the node c is influenced by all nodes in V. These are just given as concrete examples with an application-oriented motivation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Reasoning in ID-EL</head><p>Before delving into the reasoning tasks for ID-EL, note that as in the special cases EL and BEL, every ID-EL ontology is consistent: for every ID-EL KB and every strategy S, there is a model of K w.r.t. S, which can be built as follows. Let K = (D, T ) be a KB and S a strategy, and let V be the set of variables in D. For every valuation W of V , consider the interpretation I W = ({δ}, • I W , W) where A I W = ∅ and r I W = ∅ for all A ∈ N C , r ∈ N R . The probabilistic interpretation P = (I, P I ) with</p><formula xml:id="formula_14">I = {I W | W is a valuation of V } and P I (I W ) = P D(S) (W) is a model of K w.r.t. S.</formula><p>Hence, we are more interested in reasoning problems related to subsumptions (as in EL), their probabilities (as in BEL), but most importantly, their costs.</p><p>The first reasoning task that we consider in this setting corresponds to computing bounds on the expected costs associated with the models of a given KB K. To this end, we would like to find an optimal strategy, which minimises the expected cost w.r.t. D, and a pessimal strategy, which maximises this cost. From the previous discussion, it follows that these bounds correspond exactly to the bounds on the expected cost of the ID D from K. In order to study the computational complexity of finding these bounds, we consider their associated decision problem versions. As both problems are PSPACE-complete <ref type="bibr" target="#b14">(Littman, Majercik, and Pitassi 2001)</ref>, their extension to the setting of ID-EL KBs, must also be PSPACE-complete.</p><p>Theorem 10. Given an ID-EL KB K = (D, T ) and b ∈ R, deciding if there exists a strategy S such that E</p><formula xml:id="formula_15">[K | S] &lt; b (or, dually, such that E[K | S] &gt; b) is PSPACE-complete.</formula><p>However, in general we cannot expect a polynomial-space algorithm to enumerate an optimal strategy. Indeed, even if we limit the search to pure strategies (which means that the probability tables for decision nodes is Boolean), every pure local strategy corresponds to a Boolean function over the parent variables. It is well known that for every n ≥ 2 there are Boolean functions (and hence, local strategies) that cannot be expressed with circuits of size smaller or equal to 2 n /2n <ref type="bibr" target="#b22">(Shannon 1949)</ref>. It is not hard to construct, for a Boolean function f , an ID whose optimal pure strategy is in fact f , which translates the hardness result to our setting.</p><p>One can also consider the problem of entailment of a contextual subsumption, or computing the probability of a subsumption relation to hold. For the latter, as already explained, one must first instantiate the chosen strategy, as otherwise the probability is not well-defined. In particular, we denote as P (C P D) the case where α = true is the universal context satisfied by all propositional valuations. Iin this case, satisfaction of an axiom by an interpretation corresponds exactly to the classical definition in EL, as the condition of violating the context can never hold.</p><p>Recall that an ID together with a strategy forms a BN, and hence after choosing the strategy, the probability of each instantiation of all the variables in V is fully specified. Still, one can choose different models for the KB w.r.t. this strategy. Indeed, note that the universal EL model which contains only one element belonging to all concepts and connected to itself via all roles, or the empty model defined at the beginning of this section, can always be used to build a probabilistic model P such that P ( C P D : α ) = 1 for all concepts C, D and contexts α. Choosing the infimum in the definition of the probability of a subsumption is the natural cautious bound that is guaranteed to hold in all models.</p><p>In a decision situation, an agent might observe a fact, and try to act upon it with the best available strategy. In IDs, the observations made are modelled through the introduction of evidence, which formally is just the instantiation of one (or more) of the chance nodes. In our setting, we are more interested in observing facts that arise from the ontological perspective. That is, our knowledge about the context is not directly accessible through the variables of the ID, but rather through the consequences that are known to hold.</p><p>Hence, rather than observing the behaviour of the ID, we observe a fact that provides information about the possible contexts that can still hold. This information obviously also influences the probability distribution over the underlying ID, even if the truth value of all nodes in the graph may still remain uncertain. In practice, when we observe a consequence, we can immediately exclude some cases (i.e., contexts) which contradict our observation. The probabilities of the remaining cases need to be updated accordingly, after the impossible cases are removed. Like when dealing with probabilities alone, if one is trying to understand the expected cost given an observation it becomes important to consider all the possible models of the KB. Accordingly, we can consider an optimistic or a pessimistic approach depending on whether we try to maximise or minimise this expected cost. Note that, as mentioned already, for every context it is always possible to construct an EL model of the context that satisfies also the GCI C D. In the models P = (I, P I ) constructed as explained earlier in this paper, it always holds that P I (I | C D) = P I (I) for all I ∈ I. In particular, this also means that</p><formula xml:id="formula_16">E[P | S, C D] = E[P | S]</formula><p>for all strategies S. This yields the following result. Proposition 14. For every ID-EL KB K, strategy S, and concepts C, D, it holds that</p><formula xml:id="formula_17">E[K | S, C D] ≤ E[K | S] ≤ E[K | S, C D].</formula><p>This proposition means that the expected cost of a KB w.r.t. a given strategy-which, as seen earlier, corresponds to the expected cost of its underlying ID-provides bounds for the expected costs given an observed consequence. This can immediately help prune the search space for the optimistic and pessimistic bounds. In addition, it hints at the idea that these bounds can be found by manipulating the distribution of the ID. As the following example shows, the inequalities from Proposition 14 may be strict. Example 15. Consider again the KB K ex from Example 7. We have already seen that under the pure strategy S defined by</p><formula xml:id="formula_18">P (TA | ¬S) = P (¬TA | S) = 1, it holds that E[K ex | S] = E[D | S] = 4.604.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consider the evidence Subject</head><p>Benefits. Figure <ref type="figure" target="#fig_8">3</ref> depicts V -interpretations, which form a probabilistic model P of K ex with the same probability distribution as in Example 7. We check that E[P | S, Sub Ben] = 60.149. Note that I 2 , I 4 , and I 6 entail Sub Ben, but all other interpretations do not entail it. Hence, P (Sub P Ben) = P I (I 2 ) + P I (I 4 ) + P (I 6 ) = 0.094, and the conditional probabilities are C] = 69.149. The worst-case scenario is that we get a cost of 90 (the highest possible in our model) with probability 1, thus giving a expected cost of 90; however, our evidence is such that every model satisfying the valuation ¬D, ¬P must also satisfy Sub Ben. Since the cost associated to this valuation is 20, the overall expected cost must decrease, as in our model.</p><formula xml:id="formula_19">P I (I i | Sub Ben) =        0.</formula><p>Similarly, E[P | S, Sub Saf] = 1.5. The only Vinterpretations that satisfy Sub Saf are I 4 and I 8 , which are associated to cost 5 and 0, respectively, which yields</p><formula xml:id="formula_20">E[P | S, Sub Saf] = 5 54 180 = 1.5. It follows that E[K ex | S, Sub Saf] ≤ 1.5.</formula><p>Hence, in general the pessimistic and optimistic expected costs given an evidence do not coincide with the expected cost of the KB. This example also shows that different models may reduce or increase the expected cost, in manners that may not be obvious at first sight.</p><p>This example suggests a method for computing the optimistic and pessimistic expected costs. For the former, we want to maximize the probability of observing the smallest possible costs, while minimizing the probability of getting high costs. The dual approach helps us find the pessimistic expected cost. Theorem 16. Optimistic and pessimistic expected costs given C D can be computed in polynomial space on the number of nodes of the underlying ID.</p><p>Proof. There are exponentially many valuations of the variables in V , but each of them is linearly represented in the size of V . For each valuation W, we construct the TBox T W .</p><p>Let n be the smallest value in val(c). We construct a probabilistic model P = (I, P I ) as follows. For each valuation W, I contains a V -interpretation</p><formula xml:id="formula_21">I W = (∆ I W , • I W , W) such that (i) (∆ I W , • I W ) |= T W , (ii) if c(I) = n then (∆ I W , • I W ) |= C D, and (iii) if c(I) = n and T W |= C D, then (∆ I W , • I W ) |= C D.</formula><p>Moreover, P I (I W ) = P D(S) (W). It is easy to verify that this is a model, constructed in exponential time, which minimises the expected cost. To compute this cost in polynomial space, we store only one interpretation at a time, and accumulate the relative cost of each interpretation iteratively. For the pessimistic expected cost, the proof is analogous, but using the largest value of val(c) instead.</p><p>We are not interested in the expected costs per se, but rather as a means to identify the best strategy for the agent to follow under the evidence. We thus have the choices to minimise or maximise the optimistic or pessimistic expected costs, yielding four different notions. To reduce the overhead of the definition, we focus only on minimising these costs; maximisation can be treated analogously, with just the obvious modifications in the definitions and techniques. Definition 17 (Dominant strategies). Let K be an ID-EL KB and C, D two concepts. The strategy S is called dominant optimistic if for every strategy S it holds that</p><formula xml:id="formula_22">E[K | S, C D] ≤ E[K | S , C D]. It is dominant pessimistic if for all strategies S , E[K | S, C D] ≤ E[K | S , C D].</formula><p>To avoid confusions, we emphasise that a dominant pessimistic strategy minimizes the pessimistic expected cost. In terms of decision making, such a strategy ensures that in the worst case, the overall cost remains manageable.</p><p>A naïve approach for finding pure dominant strategies is to enumerate all possible options, bulding the Boolean functions for each local strategy, and preserving those that yield the lowest expected costs. In the worst case, there are doubly-exponentially many such strategies on the size of V , which makes this naïve approach infeasible, despite its effectiveness. On the other hand, it is easy to see that the optimal strategy for the whole network is a special case of Definition 17, where the subsumption C D of interest corresponds to any EL tautology (e.g., A A).</p><p>Consider the decision problems (D-Dom-Opt and D-Dom-Pes, respectively) associated with Definition 17: given a KB K, two concepts C, D and b ∈ R, decide whether there are strategies S, S such that E[K | S, C D] &lt; b, and E[K | S , C D] &lt; b, respectively. Using an approach similar to Theorem 16, we can build a polynomial-space algorithm for deciding D-Dom-Opt under pure strategies by enumerating all valuations of the chance nodes, guessing for each of them a valuation of the decision variables and computing the minimal cost that arises from each of them. The only issue is that this needs to be done in a specific order to guarantee that for equal parent nodes, the same guess is made always in a decision variable.</p><p>Theorem 18. The problems D-Dom-Opt and D-Dom-Pes are PSPACE-complete for pure strategies.</p><p>Proof sketch. PSPACE-hardness follows from Theorem 10 since D-Opt is a special case of D-Dom-Opt. For the upper bound, we use the result from Theorem 16: to verify D-Opt, for every valuation of the chance variables (B), we can guess (in polynomial time) a valuation of the decision variables (D) and compute in polynomial space its expected cost. This gives a non-deterministic polynomial space algorithm, which by Savitch's theorem <ref type="bibr" target="#b20">(Savitch 1970</ref>) yields a PSPACE upper bound.</p><p>Obviously, the PSPACE complexity lower bound holds also for arbitrary strategies, as it is a more general problem. The upper bound can be extended to non-pure strategies, as long as they are representable in exponential space; otherwise, we would not be able to guess them in exponential time. The biggest problem when dealing with arbitrary strategies is that there are uncountably many of them, and a different choice in one decision node may greatly affect the probability in a node that it influences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Computing Optimal Arbitrary Strategies</head><p>We have previously restricted ourselves to pure strategies. We now remove this restriction, and investigate the case where the strategies can be arbitrary; namely, mixed strategies which generalizes the notion of pure strategy. To carry out our analysis, we incorporate techniques from game theory; these will be sequential forms in extended-form games <ref type="bibr" target="#b11">(Fudenberg and Tirole 1991;</ref><ref type="bibr" target="#b17">Nisan et al. 2007)</ref>. In what follows, we assume basic knowledge of game theory (see <ref type="bibr" target="#b11">(Fudenberg and Tirole 1991)</ref> for further details).</p><p>As mentioned already, an influence diagram can be understood as an agent making decisions against nature. In game-theoretic terms, this can be thought of as a two-player game where the nodes of the influence diagram are partitioned in two sets which belonging to the different players. In particular, one player (which we call the first player or Player 1), is the agent endowed with the decision nodes and the cost function (implemented by our cost node) and the other player (the second player) is nature endowed with chance nodes. Player 1 has a preference between different outcomes determined by the (expected) cost while Player 2 is indifferent between any outcome.<ref type="foot" target="#foot_3">foot_3</ref> This interpretation will help us make use of any formal tool which is used to find (Nash) equilibria (i.e., a state where both players minimize their cost function concurrently. The reason is that, in such a setting, the equilibrium notion boils down to the case where it is dependent only on a single player, namely the case in which Player 1 minimizes their cost function.</p><p>To incorporate the techniques from extended-form games for a given influence diagram D, we construct a game tree G D = (V g , E g ) from D. As this process is quite intuitive, to avoid cumbersome technicalities, we give a rather brief and informal description:</p><p>i. for every chance and decision node in the ID, add a node and label it by the player that controls it i.e., 1 if it is a decision node and 2 if it is a chance node;</p><p>ii. add a directed edge for every value of that node where the source is the player which controls the value of that node and the target is the node (player) which controls the child node in the ID; and</p><p>iii. add a leaf node for every value of the cost node respecting the path in the ID.</p><p>For simplicity, we assume w.l.o.g. that players are alternating. Dropping this assumption does not affect our analysis, since it can easily be converted to such a form: if several nodes of the same type are consecutive, they can be replaced by a single non-binary random variable.</p><p>Consider for example the game tree obtained by transforming the influence diagram in Figure <ref type="figure" target="#fig_0">1</ref>, which is depicted in Figure <ref type="figure" target="#fig_9">4</ref>. Observe that every non-terminal node is labeled by the player which controls it in the influence diagram. Moreover, shapes of the node for players correspond to the shape of the nodes (i.e., 1 and 2) that they control in the ID. In parallel, leaf nodes ∈ L which represent outcomes are diamond-shaped. Since the root node in the ID (in Figure <ref type="figure" target="#fig_0">1</ref>), player 2 (nature) is the root node in the game tree.</p><p>We introduce some necessary notions for computing the cost minimization problem with arbitrary strategies. A move ω is an edge in the game tree, and corresponds to a value of a particular decision node in an ID i.e., ω ∈ val(d). A sequence σ is a path (a sequence of moves) in the game tree. For example, the empty sequence ∅ and DS¬PTA are sequences in Figure <ref type="figure" target="#fig_9">4</ref>. A sequence of player i is the sequence σ i of its moves along the game tree e.g., DS¬P for σ 2 and TA for σ 1 . We denote all possible sequences of Player 1 and Player 2, by S 1 and S 2 , respectively. Given a leaf node ∈ L, we denote the sequence which reaches by σ( ), and σ i ( ) denotes the sequential moves of Player i. We refer to the content of such a leaf, as c( ) ∈ val(c), after the cost function c.<ref type="foot" target="#foot_4">foot_4</ref> An information set is a set of nodes in which a player has the same moves e.g., oval h in Figure <ref type="figure" target="#fig_9">4</ref>. In our case, we collapse information sets to singletons since Player 1 (the agent in ID) has access to the conditional probability distribution of each chance node. In game-theoretic terms, this correspond to perfect information game where Player 1 can observe what Player 2 has chosen. We denote available moves for a player i in an information set h as Ω h which corresponds to values of a particular node d in the ID, and the set of its information sets as H i . If both players can remember all of their moves along the path of the game tree, the game has perfect recall. Intuitively, it means that no player can get additional information about their position in the game three by remembering earlier actions. Observe that this is indeed inline with our initial assumption of no forgetting.</p><p>We translate the conditional distributions in the ID to the game tree in a way that it simulates the overall behaviour faithfully. We use the well-known notion of behaviour strategy in extended-form games. A behaviour strategy is a probability distribution β on the next available moves in a state in the game tree. For instance, in Figure <ref type="figure" target="#fig_9">4</ref>, the probability that the move DS¬P is taken can be chosen w.r.t. the ID in Figure <ref type="figure" target="#fig_0">1</ref> and the strategy S, which would be, then, 0.012. Hence β 2 (DS¬P) = 0.012 where β 2 is the behavior strategy for Player 2. Obviously, a behaviour strategy β i for player i satisfies the following: ω∈Ω h β i (ω) = 1 and β i (ω) ≥ 0 for all h ∈ H i , ω ∈ Ω h . Then by extending behaviour strategies to sequences, we obtain realization probability of a sequence σ of Player i under β i : β i (σ) := Π ω∈σ β i (ω) which is in line with the standard chain rule. Note that β i (∅) = 1 for any β i . In terms of the game tree, the expected cost (in Definition 2) can be rewritten as</p><formula xml:id="formula_23">∈L c( ) • β 1 ( ) • β 2 ( ).</formula><p>(1)</p><p>Moreover, given a h ∈ H and a sequence σω being an extension of sequence σ ∈ h with a move ω, then we define</p><formula xml:id="formula_24">β i (σ) := Σ ω∈h β i (σω).<label>(2)</label></formula><p>We define β i (σ ) = 0 for any non-realizable sequence σ . Then any µ 1 being a vector value of such a β 1 (hence for Player 1) is called a realization plan. 6 This is analogous for Player 2, but since it is indifferent for any outcome, and observing that its realization plan is fixed, 7 considering only the expected cost minimization of Player 1 fulfills our goals. We can represent the cost of player 1 in terms of a cost matrix C, as follows. For every leaf node ∈ L in G D , the entries c σ1( )σ2( ) := c( ) construct a |S 1 | × |S 2 | matrix. The expected cost of Player 1 is µ 1 (Cµ 2 ) where µ 1 is the realization plan of Player 1 (a global strategy), C is the cost matrix, and µ 2 is the realization plan of nature (chance nodes).</p><p>We now have all we need to formulate the expected cost minimization problem of Player 1 in terms of linear constraints. Given a fixed realization plan µ 2 ,</p><formula xml:id="formula_25">min µ 1 (Cµ 2 ) subject to R • µ 1 = r, µ 1 ≥ 0 (3)</formula><p>where R is the matrix for realization constraints i.e., columns correspond to elements of S 1 , and rows are of size |H 1 | + 1. Intuitively, the first row of R and r implements β i (∅) = 1, and the remaining rows implement Equation <ref type="formula" target="#formula_24">2</ref>in the form of for -β 1 (σ) + ω∈Ω h β 1 (σω) = 0 for every h ∈ H 1 and 0 is the zero vector. And optimal mixedstrategy is a strategy that is a solution for the LP given in Equation <ref type="formula">3</ref>. Realize that the size of LP is linear in the size of the game tree. However, game tree grows exponentially for a given ID, realising every valuation of its conditional dependency tables. Hence, hardness remains. In parallel, recall that mixed-strategies also include pure strategies. Hence, PSpace-completeness remains. Yet one can easily modify the LP given above to fully-mixed strategies by setting µ 1 &gt; 0 i.e., requiring every component of the strategy to be greater than zero. To apply these results to ID-EL, we simply modify the linear program to consider the evidence of the context that is given by the observations of the results.</p><p>Hence, all problems are still solvable in polynomial space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>In addition to the probabilistic logics mentioned in the introduction, some earlier works <ref type="bibr" target="#b2">(Acar 2014;</ref><ref type="bibr" target="#b1">Acar, Thorne, and Stuckenschmidt 2015;</ref><ref type="bibr" target="#b0">Acar et al. 2017</ref>) employed (probabilistic) DLs in a decision-theoretic setting. However, neither addressed observations, nor contextual reasoning. Hence, they stay completely orthogonal to our work. Earlier work <ref type="bibr" target="#b13">(Koller and Milch 2003;</ref><ref type="bibr" target="#b23">Zhou, Lü, and Liu 2013)</ref> has used IDs in a game-theoretic setting, yet in a different direction: to represent sequential games with more than n ≥ 2 players compactly and to solve them. We borrow (in Section 4) the notion of game-tree from game theory to compute arbitrary strategies in IDs. There we simulate the ID as a 2-player game (against nature) in a game-tree, which allows us to employ linear programming based solution. These works also do not consider contextual reasoning (since this is not their motivation). To our knowledge, the closest work is (Ceylan and Peñaloza 2014a) which is of no surprise, since we propose its decision-theoretic extension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We introduced ID-EL, a new extension of the light-weight DL EL capable of modeling and dealing with decision situations under uncertainty. This is achieved by integrating an influence diagram to represent the uncertainty, potential decisions, and the overall costs of a choice into the knowledge base. The ontological (EL) portion and the influence representation are combined through the use of contexts, which express the situations in which knowledge is required to hold. From an abstract point of view, we build a collection of ontologies, which are necessarily true only in specific contexts; but, in line with the open-world assumption, could still be verified in other situations. These ontologies contain only certain knowledge (i.e., there is no mention of uncertainty within the ontological knowledge), but the specific context under consideration is uncertain.</p><p>Extending the basic idea of the probabilistic DL BEL, our framework allows for an agent to influence its context through choices in specific nodes of the network, trying to minimise the overall expected cost over the network. Intuitively, this means minimising the probability of large costs, and maximising the probability of low costs. Obviously, the framework remains uncertain, and there is no absolute guarantee that the observation of the environment do yield the lowest possible cost. But the agent can only influence its own choices, not those of the environment.</p><p>For this paper, we studied the basic reasoning problems in this logic, and gave tight complexity bounds for all of them. Interestingly, the decision problem associated with finding a dominating optimal strategy, in which the agent should find the best strategy conditioned on an ontological observation, remains PSPACE-complete, just as in making inferences over an ID. A practical algorithm for solving this problem-and its effective implementation-is left for future work. As future work we will also consider other decision-based reasoning tasks, and complexity classes. Notably, we will study whether optimal strategies or costs can be approximated efficiently, and whether reasoning becomes tractable over some given parameters. We note that this is still an open problem even for the special case of BEL. For example, inferences on a Bayesian network are tractable over a bounded tree-width, but this property is lost in the currently known algorithms for reasoning in BEL <ref type="bibr">(Ceylan and Peñaloza 2014c)</ref>.</p><p>Another task to consider is that of building strategies iteratively, as a response to the environment; this is justified by the no-forgetting assumption of IDs, and allows an agent to react to newer observations, rather than designing an overall strategy from the beginning. Some of the complexity issues highlighted in this paper can be alleviated in this way. Another interesting issue to resolve is how to dislodge the strategies from the underlying ID, and allow the agent to select consequences (rather than direct contexts) instead.</p><p>To conclude, we note that the choice of EL as a logical formalism is motivated by its polynomial-time reasoning problems, which allow us to understand complexity issues better. Likewise, considering TBoxes exclusively, without the addition of ABoxes was a design choice to simplify the introduction of the formalism. However, our framework can be combined with other (potentially more expressive) logics, akin to what was done for Bayesian DLs <ref type="bibr" target="#b10">(Ceylan and Peñaloza 2017;</ref><ref type="bibr" target="#b7">Botha, Meyer, and Peñaloza 2019)</ref>. Building those extensions introduces further problems (e.g., consistency) that would need to be studied in detail as well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An influence diagram; D, S, P are choice nodes, TA is a decision node, and c is the cost node; val(c) = {0, 2, 5, 20, 90}.The probability table for the node TA is not specified.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>r = 90. Hence, expected cost of this strategy is E[D | S] = 0 • 0.504 + 2 • 0.252 + 5 • 0.108 + 20 • 0.124 + 90 • 0.12 = 4.604.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>C ::= A | | C C | ∃r.C, where A ∈ N C and r ∈ N R . A general concept inclusion (GCI) is an expression of the form C D, where C, D are EL concepts, and a TBox is a finite set of GCIs. We often call a TBox also an ontology. The semantics of EL is based on interpretations. These are tuples of the form I = (∆ I , • I ), where ∆ I is a set called the domain (of the interpretation) and • I is the interpretation function which maps every concept name A ∈ N C to a set A I ⊆ ∆ I and every role name r ∈ N R to a binary relation r I ⊆ ∆ I × ∆ I . The interpretation function is extended to arbitrary EL concepts by setting I := ∆ I , (C D) I := C I ∩ D I ; and (∃r.C) I := {δ ∈ ∆ I | ∃γ ∈ C I .(δ, γ) ∈ r I }. The interpretation I satisfies the GCI C D (denoted by I |= C D) iff C I ⊆ D I . It is a model of the TBox T (denoted by I |= T ) iff it satisfies all GCIs in T . Intuitively, a TBox expresses constraints on the interpretation of concepts and roles in the knowledge domain that is being represented. Hence, we are only interested in models of the TBox. Since EL cannot express negations, every TBox from this logic is consistent; i.e., it has a model. The main reasoning problem in EL is thus subsumption: given a TBox T , and two EL concepts C and D, C is subsumed by D w.r.t. T (T |= C D) iff every model I of T satisfies the GCI C D. Subsumption in EL is in PTime.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 2: V -interpretations satisfying Tex from Example 7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Problem 9 (</head><label>9</label><figDesc>Optimal/Pessimal strategy). Consider an ID D and a value b ∈ R. The optimal strategy problem (D-Opt) consists in deciding whether there exists a strategy S such that E[D | S] &lt; b. Dually, the pessimal strategy problem (D-Pes) is to decide whether there exists a strategy S such that E[D | S] &gt; b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Definition 11 (Probabilistic subsumption). Let K = (D, T ) be a KB, α a context, and C, D two ID-EL concepts. Given the probabilistic interpretation P = (I, P I ), the probability of C D : α w.r.t. P and w.r.t. the strategy S over D are defined, respectively, as P ( C P D : α ) := I∈I,I|= C D:α P I (I), and P ( C K,S D : α ) := inf P|= S K P ( C P D : α ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Definition 12 (Conditional expected cost). Let K = (D, T ) be an ID-EL KB, S a strategy on D, P = (I, P I ) a probabilistic model of D w.r.t. S, and C, D two concepts such that P (C P D) &gt; 0. The conditional probability of the interpretation I ∈ I given the subsumption C D is P I (I | C D) := 0 if I |= C D P I (I) P (C P D) otherwise. The conditional expected cost of P given C D w.r.t. S is E[P | S, C D] := I∈I P I (I | C D) • c(I).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Definition 13. Let K be an ID-EL KB, S a strategy, and C, D two concepts. The optimistic expected cost E and the pessimistic expected cost E of K w.r.t. S given C D are defined, respectively, by E[K | S, C D] := inf P|= S K E[P | S, C D], E[K | S, C D] := sup P|= S K E[P | S, C D].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Interpretations forming a model P of Kex such that E[Kex | S, A C] = E[P | S, A C] and E[Kex | S, A D] = E[P | S, A D].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The game tree obtained from Figure 1.</figDesc><graphic coords="8,54.59,54.00,237.32,84.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Definition 1 (Strategy). A (local) strategy on a decision node d ∈ D is a conditional PDT of d given its influence set infl(d). A (global) strategy on the ID D is a set of local strategies, containing one for each d ∈ D. A local or global strategy is pure if it only assigns probabilities 0 or 1.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Interpretation functions and valuations for Example 7.</figDesc><table><row><cell>i</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell></row><row><cell cols="9">P I (I i ) 0.108 0.012 0.126 0.054 0.252 0.028 0.294 0.126</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Probability distribution for Example 7.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the 17th International Conference on Principles of Knowledge Representation and Reasoning(KR 2020)   Main Track</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>In general, chance and decision nodes can be arbitrary finite RVs, and IDs may have more than one cost node. Considering only Boolean RVs with a unique cost node greatly simplifies the notation and presentation, without affecting its generality.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>The utility function can be seen as a special kind of probability distribution over val(c), where probabilities are always 0 or 1.Proceedings of the 17th International Conference on Principles of Knowledge Representation and Reasoning(KR 2020)   Main Track</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>This can be implemented by any cost function whose codomain is a singleton. Proceedings of the 17th International Conference on Principles of Knowledge Representation and Reasoning (KR 2020) Main Track</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Traditionally, one would write c1( ) to denote the cost of Player 1 in . We drop this since we are interested in a single player.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>This extension of β is a mixed-strategy (over S1). By Kuhn's theorem<ref type="bibr" target="#b16">(Maschler, Solan, and Zamir 2013)</ref>, if a player has perfect recall, then a mixed strategy is equivalent to a behaviour strategy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>Indeed, this is the case since given an ID, chance nodes have certain distributions which can be considered as a fixed global strategy realizing µ2. Proceedings of the 17th International Conference on Principles of Knowledge Representation and Reasoning (KR 2020) Main Track</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors thank all anonymous reviewers. Erman Acar is funded by the <rs type="programName">MaestroGraph research programme</rs> with project number <rs type="grantNumber">612.001.552</rs>, which is financed by the <rs type="funder">Dutch Research Council (NWO)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_tsbxUZe">
					<idno type="grant-number">612.001.552</idno>
					<orgName type="program" subtype="full">MaestroGraph research programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-attribute decision making with weighted description logics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meilicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IfCoLog Journal of Logics and its Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1973" to="1996" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards decision making via expressive probabilistic ontologies</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Algorithmic Decision Theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="52" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Computing subjective expected utility using probabilistic description logics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Acar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">STAIRS 2014 -Proceedings of the 7th European Starting AI Researcher Symposium</title>
		<editor>
			<persName><forename type="first">U</forename><surname>Endriss</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Leite</surname></persName>
		</editor>
		<meeting><address><addrLine>Prague, Czech Republic, Au-</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2014">2014. 18-22, 2014</date>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Baader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Calvanese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patel-Schneider</forename></persName>
		</author>
		<title level="m">The Description Logic Handbook: Theory, Implementation, and Applications</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pushing the EL envelope</title>
		<author>
			<persName><forename type="first">F</forename><surname>Baader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 19th</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Kaelbling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Saffiotti</surname></persName>
		</editor>
		<meeting>19th</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m">Joint Conf. on Artificial Intelligence (IJCAI&apos;05)</title>
		<imprint>
			<publisher>Professional Book Center</publisher>
			<biblScope unit="page" from="364" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Contextdependent views to axioms and consequences of semantic web ontologies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Baader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Knechtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="22" to="40" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Bayesian extension of the description logic ALC</title>
		<author>
			<persName><forename type="first">L</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th European Conference on Logics in Artificial Intelligence (JELIA&apos;19)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting>the 16th European Conference on Logics in Artificial Intelligence (JELIA&apos;19)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">11468</biblScope>
			<biblScope unit="page" from="339" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Bayesian description logic BEL</title>
		<author>
			<persName><forename type="first">İ</forename><forename type="middle">İ</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
		<author>
			<persName><surname>Springer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">İ</forename><forename type="middle">İ</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Joint Conference on Automated Reasoning (IJCAR&apos;14</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Demri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Kapur</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Weidenbach</surname></persName>
		</editor>
		<meeting>the 7th International Joint Conference on Automated Reasoning (IJCAR&apos;14</meeting>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">8562</biblScope>
			<biblScope unit="page" from="447" to="458" />
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reasoning in the description logic BEL using Bayesian networks</title>
		<author>
			<persName><forename type="first">İ</forename><forename type="middle">İ</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 AAAI Workshop on Statistical Relational Artificial Intelligence, volume WS-14-13 of AAAI Workshops</title>
		<meeting>the 2014 AAAI Workshop on Statistical Relational Artificial Intelligence, volume WS-14-13 of AAAI Workshops</meeting>
		<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tractable reasoning with bayesian description logics</title>
		<author>
			<persName><forename type="first">İ</forename><forename type="middle">İ</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peñaloza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fanizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Scalable Uncertainty Management (SUM 2008)</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Greco</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</editor>
		<meeting>the Second International Conference on Scalable Uncertainty Management (SUM 2008)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2017. 2008</date>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="146" to="159" />
		</imprint>
	</monogr>
	<note>The Bayesian ontology language BEL</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tirole</surname></persName>
		</author>
		<title level="m">Game Theory</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic description logics for subjective uncertainty</title>
		<author>
			<persName><forename type="first">V</forename><surname>Gutiérrez-Basulto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schröder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1" to="66" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Multi-agent influence diagrams for representing and solving games. Games and economic behavior</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Milch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="181" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stochastic Boolean satisfiability</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Majercik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="251" to="296" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Managing uncertainty and vagueness in description logics for the semantic web</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Straccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="291" to="308" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Game theory (translated from the hebrew by ziv hellman and edited by mike borns)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Maschler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zamir</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">979</biblScope>
			<biblScope unit="page">4</biblScope>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Log-linear description logics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Noessner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">V</forename><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Second International Joint Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2007">2011. 2007</date>
		</imprint>
	</monogr>
	<note>Algorithmic Game Theory</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic description logics under the distribution semantics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Riguzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bellodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="477" to="501" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Relationships between nondeterministic and deterministic tape complexities</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Savitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="192" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="871" to="882" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The synthesis of two-terminal switching circuits</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell System Technical Journal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="98" />
			<date type="published" when="1949">1949</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Game theory-based influence diagrams</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="351" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
