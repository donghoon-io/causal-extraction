<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cost-effectiveness analysis with influence diagrams</title>
				<funder ref="#_JnFmDqz">
					<orgName type="full">FONCICYT</orgName>
				</funder>
				<funder ref="#_Syq8h3v">
					<orgName type="full">Spanish Ministry of Science and Technology</orgName>
				</funder>
				<funder ref="#_pktEwfy #_nVuRr52">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2014-06-02">June 2, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">M</forename><surname>Arias</surname></persName>
							<email>marias@dia.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. Artificial Intelligence</orgName>
								<orgName type="institution">UNED</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
							<email>fjdiez@dia.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. Artificial Intelligence</orgName>
								<orgName type="institution">UNED</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cost-effectiveness analysis with influence diagrams</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-06-02">June 2, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cost-benefit analysis</term>
					<term>cost effectiveness</term>
					<term>decision trees</term>
					<term>influence diagrams</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Introduction: Cost-effectiveness analysis (CEA) is used increasingly in medicine to determine whether the health benefit of an intervention outweighs the economic cost. Decision trees, the standard decision modeling technique for non-temporal domains, can only perform CEAs for very small problems. Objective: To develop a method for CEA in problems involving several dozen variables. Methods: We explain how to build influence diagrams (IDs) that explicitly represent cost and effectiveness. We propose an algorithm for evaluating cost-effectiveness IDs directly, i.e., without expanding an equivalent decision tree. Results: The evaluation of an ID returns a set of intervals for the willingness to pay-separated by incremental cost-effectiveness ratios (ICERs)-and, for each interval, the cost, the effectiveness, and the optimal intervention. The algorithm that evaluates the ID directly is in general much more efficient than the brute-force method, which is in turn more efficient than the expansion of an equivalent decision tree. Using OpenMarkov, an open-source software tool that implements this algorithm, we have been able to perform CEAs on two medical IDs whose equivalent decision trees contain billions of branches. Conclusion: IDs can perform CEA on many problems that could not be analyzed with decision trees.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In medicine, many new interventions become available every year for the diagnosis, prevention, and treatment of different diseases. 1 Given that economic resources are limited, it is necessary to assess whether the health benefit of an intervention is worth its cost. The more common approach to economic evaluation is cost-effectiveness analysis (CEA) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. In this context, the net monetary benefit <ref type="bibr" target="#b2">[3]</ref> of an intervention I is</p><formula xml:id="formula_0">NMB I (λ) = λ • e -c ,<label>(1)</label></formula><p>where e is its effectiveness and c its cost. The parameter λ, usually called willingness to pay, costeffectiveness threshold or ceiling ratio, converts effectiveness into a monetary scale. It takes values on the set of positive real numbers, i.e., on the interval (0, +∞). It is measured in effectiveness units divided by cost units; for example, in dollars per death avoided or euros per quality-adjusted life year (QALY) <ref type="bibr" target="#b3">[4]</ref>.</p><p>As the willingness to pay is different for each decision maker, CEA must consider all the possible values.</p><p>The result of the analysis is usually a set of intervals for λ, each one having an optimal intervention. When the consequences of the interventions are not deterministic, it is necessary to build a model that takes into account the probability of each outcome. Decision trees are the tool used most frequently for modeling decision problems with uncertainty, especially in medicine <ref type="bibr" target="#b4">[5]</ref>. Their main drawback is that their size grows exponentially with the number of variables. 2 In the medical literature, trees usually have 3 or 4 variables and between 6 and 10 leaf nodes. A tree of 5 variables typically contains around 20 leaf nodes, which implies that building, debugging, and analyzing it would require a significant effort. Given that the maximum size of decision trees in practice is of the order of 50 nodes, they can only solve problems of at most 6 or 7 variables.</p><p>Influence diagrams (IDs) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5]</ref>, in contrast, have the advantages of being very compact, representing conditional independencies, and using direct probabilities, i.e., the probability of the effect conditioned on the cause. They have been used to solve complex medical problems. For example, Arthronet <ref type="bibr" target="#b7">[8]</ref>, an ID for knee arthroplasty, contains 23 variables and Mediastinet <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, for lung cancer, 27. 3  Building an ID that represents cost and effectiveness is easy, but evaluating it is not. Standard methods, such as arc reversal <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> and variable elimination <ref type="bibr" target="#b12">[13]</ref>, can only evaluate unicriterion IDs. An approximate solution would be to combine cost and effectiveness into a single criterion, the NMB (cf. Eq. 1), and evaluate the ID for several values of λ. The problem is that the more precision we require, the more values of λ we must examine; finding the exact solution would need infinite evaluations. Another approach would be to expand the the ID into an equivalent decision tree <ref type="bibr" target="#b6">[7]</ref> and evaluate it as proposed in <ref type="bibr" target="#b5">[6]</ref>. The problem is that the size of the tree grows exponentially with the number of variables. When trying to convert the unicriterion versions of Arthronet and Mediastinet into decision trees, our computer ran out of memory, even though arc reversal and variable elimination were able to evaluate those IDs in a fraction of a second. The decision trees for the cost-effectiveness versions of those diagrams would run out of memory even faster, as we will discuss in Section 4. <ref type="bibr" target="#b1">2</ref>.</p><p>In this paper we propose a new method for evaluating cost-effectiveness IDs, which combines arc reversal with the same idea used in <ref type="bibr" target="#b5">[6]</ref> to evaluate cost-effectiveness decision trees: given that the values of λ are infinite and it is impossible to evaluate sequentially an infinite number of IDs, our algorithm groups the λ's having the same cost, effectiveness, and optimal intervention into a finite set of intervals, whose boundaries are determined dynamically during the evaluation of the ID. This algorithm is in general much more efficient than the brute-force method, which is in turn more efficient than the expansion of an equivalent decision tree. After implementing the algorithm in OpenMarkov, an open-source software package for probabilistic graphical models, which is available at www.openmarkov.org, we have been able to evaluate several cost-effectiveness IDs, including Arthronet and Mediastinet, which contain dozens of variables.</p><p>The rest of this paper is structured as follows: Section 2 reviews the basic concepts of CEA and IDs. Section 3 presents the new algorithm, Section 4 compares IDs with decision trees from the point of view of knowledge representation and that of the computational complexity, Section 5 analyzes some related work, and Section 6 summarizes the conclusions. The appendix contains some formal definitions, the pseudo-code of the algorithms, and a detailed example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deterministic CEA</head><p>When we have a set of interventions such that their cost and effectiveness are known with certainty, we can perform a deterministic CEA, which returns the intervention that maximizes the NMB (cf. Eq. 1) for each value of λ.</p><p>The result of a CEA can be expressed as a cost-effectiveness partition (CEP), which consists of a set of intervals such that the cost, effectiveness, and optimal intervention is the same for all the λ's inside an interval, as shown in Figure <ref type="figure" target="#fig_1">1</ref>.</p><p>Figure <ref type="figure" target="#fig_1">1</ref>: A cost-effectiveness partition (CEP) of four thresholds (five intervals). All the λ's inside the i-th interval have the same cost (c i ), effectiveness (e i ), and optimal intervention (I i ).</p><p>The standard algorithm for deterministic CEA consists of finding a subset of interventions that dominates the other interventions for every value of λ <ref type="bibr" target="#b13">[14]</ref>. A slightly more efficient algorithm is presented in <ref type="bibr" target="#b5">[6]</ref> and in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Decision trees</head><p>A decision tree is a model for decision analysis of problems involving probabilistic outcomes <ref type="bibr" target="#b14">[15]</ref>. It has three types of nodes: chance, decision, and utility. Utility nodes represent the decision maker's preferences. All the leaves are utility nodes and, conversely, all utility nodes are leaves.</p><p>A unicriterion decision tree can be evaluated with the roll-back algorithm, which proceeds from the leaves to the root: the utility of a chance node is the average of the utilities of its branches and the utility of a decision node is the maximum of their utilities.</p><p>It is possible to build a bi-criteria decision tree such that each utility node, instead of representing a single value, represents cost and effectiveness separately. If the only decision node is the root, the tree can be evaluated by a modified version of the roll-back algorithm that computes the cost and effectiveness of each node separately and then performs a deterministic CEA at the root node <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>A tree containing embedded decision nodes can be evaluated with a modified version of the roll-back algorithm that works with CEPs instead of scalar utilities: each chance node is evaluated by averaging the CEPs of its branches, and each decision node is evaluated by performing a deterministic CEA for each interval of λ <ref type="bibr" target="#b5">[6]</ref> . This method is the basis for the evaluation of IDs proposed in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Unicriterion influence diagrams</head><p>An ID is a probabilistic graphical model that consists of an acyclic directed graph containing three types of nodes-chance, decision, and utility-, a probability distribution and one or several utility functions. Every node represents a variable, so we will speak of nodes and variables indifferently. In the rest of the paper, an uppercase letter (X) denotes a variable or a node, and a lowercase letter (x) a value of the corresponding variable. A bold uppercase letter denotes a set of variables, X = {X 1 , . . . , X n }, and a bold lowercase letter a configuration of the corresponding set of variables: x = (x 1 , . . . , x n ).</p><p>In a graph, if there is an arc from node X to node Y , we say that X is a parent of Y ; the set of parents of Y is denoted by P a(Y ), and pa(Y ) denotes a configuration of P a(Y ). For every chance node C the ID contains a family of conditional probability distributions of the form P (c|pa(C)). A unicriterion ID also contains a utility function U j (pa(U j )) for each utility node U j .</p><p>The meaning of an arc in an ID depends on the type of nodes that it links. An arc X → C, where C is a chance node, denotes a probabilistic dependence of C on X; in practice, it usually means that X is a cause of C. An arc from a decision D i to a decision D j (in general, any directed path from D i to D j ) means that D i is made before D j . Every ID must contain a directed path passing through all the decision nodes, which determines a total ordering of the decisions. An arc from a chance node C to a decision node D j means that the value of variable C is known when making decision D j . IDs assume the non-forgetting hypothesis, which means that a variable C known for a decision is also known for any posterior decision. An arc from a variable X to a utility node U j means that the utility depends on X.</p><p>The maximum expected utility (MEU ) of an ID whose chance and decision variables are all discrete is</p><formula xml:id="formula_1">MEU = c0 max d1 c1 . . . cn-1 max dn cn C∈V C P (c|pa(C)) • j U j (pa(U j )) ,<label>(2)</label></formula><p>where C i denotes the set of variables known after making D i and before making D i+1 . Due to the nonforgetting hypothesis, the variables known when making</p><formula xml:id="formula_2">D i are C 0 ∪ {D 1 } ∪ C 1 ∪ . . . ∪ {D i-1 } ∪ C i-1 .</formula><p>The optimal policy for D i consists of selecting, for each configuration of these variables, the value d i that maximizes the expected utility.</p><p>Arc reversal <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> is the standard algorithm for evaluating unicriterion IDs; in this context, arc and link are synonymous. Reversing an arc X → Y (where X and Y are chance variables) consists of replacing it with Y → X, computing new conditional probabilities for X and Y , and adding some links if necessary, as described in the appendix. The algorithm proceeds by removing a node in each iteration. When no node can be removed immediately, there is always a sequence of arc reversals that make one node removable. Section 4.2 discusses the complexity of this and other algorithms for IDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cost-effectiveness analysis with IDs</head><p>This section describes our method for performing CEAs with IDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Construction of the ID</head><p>The construction of an ID for CEA is almost identical to the unicriterion case; the only difference is that some utility nodes represent effectiveness and the others represent economic costs.</p><p>Example 1 For a disease whose prevalence is 0.14, there are two possible therapies. The effectiveness of each therapy depends on whether the disease is present or not, as shown in Table <ref type="table" target="#tab_0">1</ref>. There is a test with a sensitivity of 90%, a specificity of 93%, and a cost of 150 e. Is the test cost-effective? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation of cost-effectiveness IDs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Initial step: CEP potential for the utility node</head><p>The first step of the evaluation consists of combining all the utility nodes into a single node, U , whose parents are all the chance and decision nodes having at least one utility node in the original ID; we denote this set by X. The utility for node U is a CEP potential, i.e., a function U (x) that assigns a CEP to each configuration x. In this initial ID, every CEP U (x) consists of a single interval, because no threshold has been generated so far; the cost is the sum of the costs in the original ID for configuration x and the effectiveness is the sum of the effectiveness values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Arc reversal and node removal</head><p>After this initial step, the arc reversal algorithm proceeds by removing all the chance and decision nodes, as in the evaluation of unicriterion IDs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>; the only difference is that now utility tables are potentials of CEPs instead of potentials of real numbers.</p><p>A chance or a decision node having no children can be removed without more ado.</p><p>When removing a chance node C having U as the only descendant, the old parents of X become parents of U and the new CEP potential for U is computed as follows: for each configuration v of the new parents of U we collect all the corresponding CEPs in the old potential and find the union of all their thresholds. In each interval we average the costs and then the effectiveness values, weighted by the conditional probabilities of C-a probability for each value c.</p><p>Similarly, when removing a decision node D the old parents of D become parents of U in the new ID. The new CEP potential for U is computed as follows: for each configuration v of the new parents of U we collect all the corresponding CEPs in the old potential for U and collect all their thresholds. In each interval we perform a deterministic CEA, which may originate new thresholds. It is also possible that some of the old thresholds become unnecessary because the subintervals that they separate have the same cost, effectiveness, and optimal policy. Those thresholds should be removed as soon as they are detected.</p><p>When it is not possible to remove any node immediately, there is always a sequence of arc reversals that make at least one node removable. Reversing an arc in a cost-effectiveness ID is exactly the same as in the unicriterion case.</p><p>After removing all the chance and decision nodes, the potential of U contains only one CEP, which is the solution of the CEA.</p><p>The appendix contains the pseudo-code for this algorithm and a detailed numerical example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Comparison with decision trees 4.1 Construction of the model: influence diagrams vs. decision trees</head><p>The main advantage of IDs is that they are much easier to build than decision trees, mainly because they are much more compact: an ID contains only one node for each variable in the problem, while in a tree the number of branches grows exponentially with the number of variables. For example, the ID in Figure <ref type="figure" target="#fig_0">2</ref> contains 6 nodes while the equivalent tree contains 32-see <ref type="bibr" target="#b5">[6]</ref>. A symmetric decision tree containing n binary variables has 2 n leaf nodes. (A tree is said to be symmetric if every path from the root to a leaf node contains the same variables and in the same order, and all the nodes representing a variable have the same number of outgoing branches.) The number of leaves may be smaller due to asymmetries, but it may also be bigger if there are multi-valued variables. For this reason we said in the introduction that decision trees are unsuitable for problems involving more than 6 or 7 variables.</p><p>Compared with decision trees, ID do not only require much fewer parameters: these parameters are much easier to obtain because each conditional probability only involves one node (the effect) and its parents in the graph (its causes). These probabilities can be obtained from objective data, such as databases or epidemiological studies, or from subjective estimates. In contrast, the distribution probability for the branches of a node in a tree is usually conditioned on several of its causes and effects; when the tree contains more than a few variables, obtaining these conditional probabilities is extremely difficult if not impossible.</p><p>This explains why many medical problems for which it was unfeasible to build a decision tree directly have been solved with IDs; in the introduction we have mentioned two examples-Arthronet and Mediastinet-and there are many more <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Complexity of the evaluation algorithms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Influence diagrams vs. decision trees</head><p>The evaluation of unicriterion IDs, closely related to the evaluation of Bayesian networks, is NP-hard <ref type="bibr" target="#b16">[17]</ref>, which makes it unlikely that there exist polynomial complexity algorithms to evaluate them. Both the brute-force method, which consists of the direct application of Equation <ref type="formula" target="#formula_1">2</ref>, and the transformation of the ID into an equivalent tree have exponential complexity in time and space. However, the latter is more inefficient than brute-force because it requires more space to store the structure of the tree and more time to compute the conditional probabilities of its branches.</p><p>Arc reversal and other exact algorithms for IDs, such as variable elimination <ref type="bibr" target="#b12">[13]</ref> and strong junction trees <ref type="bibr" target="#b17">[18]</ref>, also have worst-case exponential complexity, both in time and space, but in many cases they are much more efficient. In fact, the property that most affects the complexity of these algorithms is not the number of nodes, but the treewidth of the graph (after removing the information arcs), a concept that has been extensively studied in Bayesian networks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>. Given that the treewidth of an ID is usually much smaller than the number of variables-as is also the case for Bayesian networks-these algorithms are in general much more efficient than the brute-force method and, consequently, much more efficient than the expansion of an equivalent tree.</p><p>In the case of cost-effectiveness analysis, the complexity of CEPs operations is proportional to the number of thresholds (see Algorithms 2 and 3 in the appendix), hence the difference is even more favorable for IDs, which perform fewer CEP operations than decision trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Evaluation of cost-effectiveness IDs</head><p>A deterministic CEA (cf. Sec. 2.1) involving n interventions may generate up to n -1 thresholds. The combination of CEPs generates a new CEP that may inherit the thresholds of all of them. Therefore, the number of thresholds might grow exponentially with the number of variables. However, in practice this number depends on the numerical parameters (the probabilities and utilities) of the model. Thus, when a subset of k interventions dominates the others, only k -1 thresholds are generated. In many cases k is smaller than the number of interventions; frequently k = 1, which generates no new threshold. Additionally, a significant number of thresholds are usually discarded when removing a decision variable (see line 7 of Algorithm 3 in the appendix). For these reasons, the number of thresholds often remains within manageable limits. For example, the evaluation of the ID in Figure <ref type="figure" target="#fig_0">2</ref> might generate up to 12 thresholds, but the maximum number during the evaluation is 3, and the final CEP contains only 2 (see the appendix).</p><p>As mentioned above, the complexity of CEPs operations is proportional to the number of thresholds. If the average of thresholds per CEP during the evaluation of an ID is k, then the computational cost the evaluation is roughly k times the cost of evaluating its unicriterion version. Thus, OpenMarkov is able to evaluate the unicriterion version of Mediastinet (with λ = 30, 000 e/QALY, which is the reference value in Spain) in 18 ms on a desktop computer; the evaluation of the cost-effectiveness version needs 57 ms, only 3.13 times more. The evaluation of Arthronet requires 38 ms and 266 ms respectively, 6.93 times more. <ref type="foot" target="#foot_0">4</ref> The evaluation of these IDs is very fast, even though the equivalent decision trees have billions of branches. Thus, if we had to perform a sensitivity analysis for any of these networks, we might run 10,000 simulations in less than an hour-or in some minutes in a parallel implementation. Given that cost-effectiveness analyses are usually performed off-line (to inform health policies rather than to make bedside clinical decisions), the problems that can be solved with this method are much bigger than those that could be solved using decision trees, especially because it was generally accepted that it was not possible to perform CEAs with decision trees containing embedded decision nodes <ref type="bibr" target="#b22">[23]</ref>, until a new method was proposed recently <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>To the best of our knowledge, our algorithm is the first method for solving cost-effectiveness IDs. Previously the only technique for analyzing multi-attribute IDs was the method by Nielsen et al. <ref type="bibr" target="#b23">[24]</ref>: they select a particular configuration of α-the vector that represents the decision maker's preferences-and evaluate the corresponding unicriterion ID; then they obtain a set of inequalities, which delimit the region of R n in which α can vary without leading to a different optimal strategy. This approach is clearly insufficient for cost-effectiveness analysis, especially in medicine, because it does not return the intervals for λ nor the optimal strategy for each interval. In contrast, the algorithm proposed in this paper limits itself to bicriteria IDs, but is able to solve them completely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and future work</head><p>In this paper we have explained how to build IDs for cost-effectiveness analysis, which can solve many medical problems for which it would be absolutely impossible to build a decision tree directly. In particular, our research group has built cost-effectiveness IDs for two complex medical problems <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>; the equivalent decision trees would contain billions of branches.</p><p>Additionally, we have adapted the arc reversal algorithm <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> to evaluate cost-effectiveness IDs by combining it with a method for performing CEA in decision trees <ref type="bibr" target="#b5">[6]</ref>. It is straightforward to adapt it to other algorithms for unicriterion trees, such as variable elimination <ref type="bibr" target="#b12">[13]</ref> and strong junction trees <ref type="bibr" target="#b17">[18]</ref>, because all of them perform essentially the same operations. These algorithms are in general much more efficient in time and space than expanding the ID into an equivalent decision tree. In particular, after implementing this algorithm in OpenMarkov, an open source tool for probabilistic graphical models, we were able to perform CEAs on the IDs mentioned above, whereas expanding the equivalent decision tree was impossible even for their unicriterion versions because our computer ran out of memory. This implementation, together with the IDs mentioned in this paper, is publicly available at www.openmarkov. org/cea.</p><p>An open line for future research is to summarize into a small policy tree the result of evaluating a costeffectiveness ID, by adapting the method proposed in <ref type="bibr" target="#b8">[9]</ref>. Another line is to adapt our CEA algorithms to the evaluation of decision analysis networks (DANs) <ref type="bibr" target="#b24">[25]</ref>, which present several advantages over IDs, especially in the case of asymmetric decision problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Cost-effectiveness partition</head><formula xml:id="formula_3">Definition 1 A cost-effectiveness partition of n intervals is a tuple Q = (Θ Q , C Q , E Q , I Q )</formula><p>, where:</p><formula xml:id="formula_4">• Θ Q = {θ 1 , . . . , θ n-1 } is a set of n -1 values (thresholds), such that 0 &lt; θ 1 &lt; . . . &lt; θ n-1 ,</formula><p>• C Q = {c 0 , . . . , c n-1 } is a set of n values (costs),</p><p>• E Q = {e 0 , . . . , e n-1 } is a set of n effectiveness values, and</p><formula xml:id="formula_5">• I Q = {I 0 , . . . , I n-1 } is a set of n interventions.</formula><p>For the sake of coherence, in this presentation we establish that θ 0 = 0 and θ n = +∞ for every CEP. Alternatively, a CEP can be denoted by a set of n 4-tuples of the form (interval, cost, effectiveness, intervention),</p><formula xml:id="formula_6">Q = {((0, θ 1 ), c 0 , e 0 , I 0 ), ((θ 1 , θ 2 ), c 1 , e 1 , I 1 ), . . . , ((θ n-1 , +∞), c n-1 , e n-1 , I n-1 )} ,</formula><p>which means that when λ is in the interval (θ i , θ i+1 ) the most beneficial intervention is I i , which has a cost c i and an effectiveness e i , as shown in Figure <ref type="figure" target="#fig_1">1</ref>. When λ = θ i+1 , there is a tie between I i and I i+1 .</p><p>Put formally, we may define the function index :</p><formula xml:id="formula_7">index Q (λ) = max{i | θ i ≤ λ}<label>(7)</label></formula><p>and the following three functions:</p><formula xml:id="formula_8">cost Q (λ) = c i (8) eff Q (λ) = e i (9) interv Q (λ) = I i ,<label>(10)</label></formula><p>where i = index Q (λ). The net monetary benefit for a particular value of λ is</p><formula xml:id="formula_9">NMB Q (λ) = λ • eff Q (λ) -cost Q (λ)<label>(11)</label></formula><p>It is easy to see that if two values of λ lie in the same subinterval of a partition, then they have the same cost and the same effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Algorithms for deterministic CEA</head><p>When an intervention I i is more effective and less expensive than I j , the former always has a higher monetary benefit than the latter (cf. Eq. 1); we then say that I i dominates I j (simple dominance). When I i is more effective and more expensive than I j , we can define the incremental cost-effectiveness ratio:</p><formula xml:id="formula_10">ICER(I j , I i ) = c i -c j e i -e j .</formula><p>and conclude that</p><formula xml:id="formula_11">λ &lt; ICER (I j , I i ) =⇒ NMB i (λ) &gt; NMB j (λ) (12) λ &gt; ICER (I j , I i ) =⇒ NMB j (λ) &gt; NMB i (λ) . (<label>13</label></formula><formula xml:id="formula_12">)</formula><p>Therefore the ICER separates two intervals of λ having different optimal interventions and, consequently, different cost and different effectiveness.</p><p>The standard algorithm for CEA analysis eliminates first the interventions dominated by another intervention (simple dominance), then those dominated by a pair of other interventions (extended dominance), and finally computes the ICERs-see <ref type="bibr" target="#b13">[14]</ref> or any book on medical decision analysis.</p><p>An alternative is Algorithm 1 <ref type="bibr" target="#b5">[6]</ref>, which selects first the intervention with the lowest cost and at each step of the while loop it selects the intervention having the smallest ICER with respect to the previously selected intervention. This algorithm is slightly more efficient because it requires fewer comparisons of pairs of interventions and no comparison involving three interventions. Result: In the second iteration of the "for" loop we obtain θ 1 = ICER(th1, th2) = 33 384 e/QALY. Therefore, the resulting CEP is {((0, 10 739), 150, 4.05, "no therapy"), ((10 739, 33 384), 20 150, 5.91, "therapy 1"), ((33 384, +∞), 70 150, 7.41, "therapy 2")}.</p><formula xml:id="formula_13">A CEP Q = (Θ Q , C Q , E Q , I Q ), with I Q = {I σ(0) , . . . , I σ(n-1) }. 1 σ(0) := arg min i cost(I i ) 2 R 0 := {i | I i ∈ I ∧ eff(I i ) &gt; eff(I σ(0) )} 3 i := 1; 4 while R i-1 = ∅ do 5 σ(i) := arg min j∈Ri ICER(I σ(i-1) , I j ) 6 θ i := ICER(I σ(i-1) , I σ(i) ) 7 c i := cost(I σ(i) ) 8 e i := eff(I σ(i) ) 9 R i := {j | j ∈ R i-1 ∧ eff(I j ) &gt; eff(I σ(i) )} 10 i := i + 1 effectiveness (QALY) cost (e)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Operations with CEPs</head><p>In this section we describe the basic operations for evaluating cost-effectiveness IDs. The weighted average of CEPs generalizes the weighted average of utilities and, analogously, finding the optimal CEP generalizes the maximization of a set of utilities.</p><p>A.4.1 Weighted average Definition 2 (Weighted average of CEPs) Given a set of m CEPs {Q 1 , . . . , Q m }, a chance variable X, whose domain is {x 1 , . . . , x m }, and a probability distribution for X, P (x j ), we say that a CEP Q is a weighted average of the CEPs if</p><formula xml:id="formula_14">∀λ, cost Q (λ) = m j=1 P (x j ) • cost Qj (λ)<label>(14)</label></formula><p>and</p><formula xml:id="formula_15">∀λ, eff Q (λ) = m j=1 P (x j ) • eff Qj (λ) .<label>(15)</label></formula><p>A straightforward consequence of this definition is that, because of Equation <ref type="formula" target="#formula_0">1</ref>,</p><formula xml:id="formula_16">∀λ, NMB Q (λ) = m j=1 P (x j ) • NMB Qj (λ) .<label>(16)</label></formula><p>These three equalities mean that for every value of λ, the cost, effectiveness, and NMB of the weighted average partition Q are the same as if we had performed a weighted average for the values of cost and effectiveness of the Q j 's.</p><p>The partition Q can be efficiently computed by Algorithm 2, which collects all the thresholds of the Q j 's (line 3) and averages the costs and the effectiveness values inside each interval (lines 6 and 7). If for a certain interval all the Q j 's have the same intervention, then this is the intervention for Q (line 9); otherwise, the optimal intervention for Q depends on the value of X: "if the chance variable X takes on the value x j , then follow the policy indicated by the i-th partition, Q i " (line 11).</p><p>The reason for removing the Q j 's such that P (x j ) = 0 (line 1) is that those CEPs do not affect the average values computed at lines 6 and 7, and the intervention generated at line 9 should not include the clause "if X = x j " when this condition is never met. <ref type="foot" target="#foot_3">6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2: Weighted average of CEPs</head><p>Input: A set of m CEPs {Q 1 , . . . , Q m }, with Q j = (Θ j , C j , E j , I j ), a chance variable X, whose domain is {x 1 , . . . , x m }, and a probability distribution for X, P (x j ).</p><formula xml:id="formula_17">Result: A new CEP Q = (Θ, C, E, I). 1 remove the Q j 's such that P (x j ) = 0; 2 m ← number of remaining Q j 's; 3 Θ ← m j=1 Θ j ; 4 n ← card(Θ); 5 for i ← 1 to n do 6 c i ← m j=1 P (x j ) • cost Qj (θ i ); 7 e i ← m j=1 P (x j ) • eff Qj (θ i ); 8 if interv Qj (θi) = interv Q1(θi) for all j then 9 I i ← interv Q1(θi) 10 else 11 I i ← "if X = x 1 , then interv Q1(θi) ; if X = x 2 , then interv Q2(θi) ..."</formula><p>Example 3 Let us consider two CEPs (m = 2), Q 1 = {((0, 10 739), 150, 4.05, "no therapy"), ((10 739, 33 384), 20 150, 5.91, "therapy 1"), ((33 384, +∞), 70 150, 7.41, "therapy 2")} and Q 2 = {((0, +∞), 150, 9.85, "no therapy")}, a chance variable X = Test, whose domain is {positive, negative}, and a probability distribution {P (positive) = 0.186, P (negative) = 0.814}.</p><p>When applying Algorithm 2, Q 1 contributes two thresholds: Θ 1 = {10 739, 33 384}; Q 2 does not contribute any: Θ 2 = ∅. Therefore, Θ = Θ 1 ∪ Θ 2 = {10 739, 33 384}. These two thresholds define three intervals (n = 3). In each interval, the cost and the effectiveness will be the weighted average of the corresponding values in the input CEPs. For example, in the first interval. In this interval, the optimal intervention is "no therapy" for both results of the test; therefore, the resulting intervention is "no therapy" (cf. line 9 of Algorithm 2). In contrast, in the interval (10 739, 33 384) the optimal intervention depends on the result of the test; the optimal intervention generated at line 11 of Algorithm 2 is "if Test = positive, then therapy 1; if Test = negative, then no therapy". Finally, the weighted average of these CEPs is the partition {((0, 10 739), 150, 8.77, "no therapy"), ((10 739, 33 384), 3 874, 9.11, "if Test = positive, then therapy 1; if Test = negative, then no therapy"), ((33 384, +∞), 13 184, 9.39, "if Test = positive, then therapy 2; if Test = negative, then no therapy")}.</p><p>Algorithm 2 is a generalization of Equation 3: just as that equation computes the weighted average of utilities when removing a chance node from a unicriterion ID, the removal of a chance node from a costeffectiveness ID generates a new utility potential, U new , such that each CEP U new (v) is computed with Algorithm 2 taking P c|v ↓P a(C) as the input probability distribution and the set U old c, v ↓P a(U )\{C}for all the values of C-as the input CEPs. </p><formula xml:id="formula_18">, . . . , d m }, a CEP Q is optimal if ∀λ, ∃j, NMB interv Q j (λ) (λ) = max j NMB interv Q j (λ) (λ) ,<label>(17)</label></formula><formula xml:id="formula_19">interv Q (λ) = " [choose option] d j ; [then apply] interv Qj (λ)" ,<label>(18) cost</label></formula><formula xml:id="formula_20">Q (λ) = cost Qj (λ) , (<label>19</label></formula><formula xml:id="formula_21">) eff Q (λ) = eff Qj (λ) .<label>(20)</label></formula><p>In this definition each CEP Q j is associated with a particular value d j (a possible choice) of decision D. Equation 17 means that when making decision D for a particular value of λ we select j such that interv Qj (λ) is the intervention that attains the highest NMB. Put another way, for every λ the NMB of the optimal intervention in Q is the same as if we had performed a unicriterion maximization of the NMB for each single value of λ. Equation 18 means that the optimal intervention for decision D is to choose first the option d j and then apply the intervention interv Qj (λ). Obviously, the cost and effectiveness associated with intervention interv Q (λ) are those of Q j (Eqs. <ref type="bibr">19 and 20)</ref>.</p><p>The optimal CEP can be obtained by applying Algorithm 3. This algorithm collects all the thresholds of the Q j 's (line 1) and performs a deterministic CEA (cf. Sec. 2.1) on each interval, which may generate new thresholds and new intervals. Finally, it eliminates the unnecessary thresholds, i.e., those that separate intervals having the same optimal intervention, the same cost, and the same effectiveness (line 7).</p><p>Example 4 Let us consider a decision D = Do test, whose domain is {do test, do not test}, and two CEPs (m = 2), Q 1 = {((0, 10 739), 150, 8.77, no therapy), ((10 739, 33 384), 3 874, 9.11, "if Test = positive, then therapy 1; if Test = negative, then no therapy", ((33 384, +∞), 13 184, 9.39, "if Test = positive, then therapy 2; if Test = negative, then no therapy"} and Q 2 = {((0, 65 360), 0, 8.77, "no therapy), ((65 360, +∞), 20 000, 9.07, "therapy 1")}.</p><p>When applying Algorithm 3, Q 1 contributes two thresholds: Θ 1 = {10 739, 33 384}; Q 2 contributes one: Θ 2 = {65 360}. Therefore, Θ = Θ 1 ∪ Θ 2 = {10 739, 33 384, 65 360}. These three thresholds define four intervals (n = 4). In each interval, we perform a deterministic CEA with Algorithm 1 (as we did in Example 2) considering two interventions, one for "do test" and another one for "do not test".</p><p>In the first interval, "do not test" dominates "do test"; therefore, no new threshold is generated. According to Equation 18, the optimal policy for this interval is "do not test; no therapy". In the second interval, the ICER is (3 874 -0)/(  threshold is not added to Θ because it falls outside the interval under analysis. Finally, in the fourth interval "do test" dominates "do not test", and no threshold is created. Hence, we would obtain a fiveinterval CEP: {((0, 10 739), 0, 8.77, "do not test; no therapy"), ((10 739, 11 171), 0, 8.77, "do not test; no therapy"), ((11 171, 33 384), 3 874, 9.11, "do test; if Test = positive, then therapy 1; if Test = negative, then no therapy"), ((33 384, 65 360), 13 184, 9.39, "do test; if Test = positive, then therapy 2; if Test = negative, then no therapy"), ((65 360, +∞), 13 184, 9.39, "do test, if Test = positive, then therapy 2; if Test = negative, then no therapy")}.</p><formula xml:id="formula_22">}, with Q j = (Θ j , C j , E j , I j ) Result: A new CEP Q = (Θ, C, E, I). 1 Θ ← m j=1 θ j ; 2 n ← card(Θ); 3 for i ← 1 to n do</formula><p>However, the two intervals separated by the threshold 10 739 have the same cost, effectiveness, and intervention, which implies that this threshold should be removed, joining the contiguous intervals (line 7 in Algorithm 3). The same occurs for the threshold 65 360. Consequently, the CEP returned by this algorithm has three intervals: {((0, 11 171), 0, 8.77, "do not test; no therapy"), ((11 171, 33 384), 3 874, 9.11, "do test; if Test = positive, then therapy 1; if Test = negative, then no therapy"), ((33 384, +∞), 13 184, 9.39, "do test; if Test = positive, then therapy 2; if Test = negative, then no therapy")}.</p><p>Algorithm 3 is a generalization of Equation 4: just as that equation computes the new expected utility when removing a decision node from a unicriterion ID, the removal of a decision node from a cost-effectiveness ID generates a new utility potential, U new , such that each CEP U new (v) is computed with Algorithm 3 taking the set U old d, v ↓P a(D)\{D} -for all the values of D-as the input CEPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Evaluation of cost-effectiveness IDs</head><p>Now we have all the elements necessary to solve the cost-effectiveness problem stated in Example 1. As mentioned earlier, we build first the ID shown in Figure <ref type="figure" target="#fig_0">2</ref>. <ref type="foot" target="#foot_4">7</ref> It has a utility table for each utility node, as if it were a unicriterion ID; the difference is that it has two types of utility nodes.</p><p>The first step performed by the algorithm is to combine all the utility nodes into a single one, U , whose parents are X = {Disease, Dec:Test, Therapy}, as explained in Section 3.2.1-see Figure <ref type="figure" target="#fig_7">4</ref>. In this new ID, U does not have a utility table but the CEP potential shown in Table <ref type="table">2</ref>. In this potential, every CEP U (x) consists of a single interval, because no threshold has been generated so far; the cost is the sum of the costs in the original ID for configuration x and the effectiveness is the sum of the effectiveness values, taken from Table <ref type="table" target="#tab_0">1</ref>.</p><p>Given that the node Disease is not the parent of any decision, it must be removed first. Initially it is not possible because this node has a child, Test. Therefore, the algorithm reverses the arc Disease → Test, thus generating the ID shown in Figure <ref type="figure" target="#fig_8">5</ref>. In the new ID the conditional probabilities of the chance nodes are:  do not test no therapy { ( (0, +∞), 0, 10.0, "" ) } absent do not test therapy 1 { ( (0, +∞), 20 000, 9.9, "" ) } absent do not test therapy 2 { ( (0, +∞), 70 000, 9.3, "" ) } Table <ref type="table">2</ref>: CEP potential for the utility node in Figure <ref type="figure" target="#fig_7">4</ref>. The values of cost and effectiveness are obtained from Table <ref type="table" target="#tab_0">1</ref>.</p><p>The removal of node Disease makes Test a parent of U (Figure <ref type="figure" target="#fig_9">6</ref>). The new utility potential depends on Dec:Test, Test, and Therapy, as shown in Table <ref type="table">3</ref>. The values of cost and effectiveness in this table are obtained by averaging each pair of potentials (lines 6 and 7 of Algorithm 2). For example, the effectiveness 4.05 in the first row is obtained as the weighted average of 1.2 and 10.0, taken from Table <ref type="table">2</ref>, using these weights: P (Disease = present | Dec:Test = do test, Test = positive) = 0.677 and P (Disease = negative, Dec:Test = do test, Test = positive) = 0.323. In this table we have omitted the configurations whose probability is 0 (for example, those for "do not test" and "positive"), because they do not affect the subsequent computations (see line 1 in Algorithm 2 and the explanation in Section A.4.1).</p><p>The elimination of the decision node Therapy is performed by applying Algorithm 3 on each configuration of {Dec:Test, Test}, as explained in Section A.4.2, taking the three CEPs (one for each value of Therapy) in Table <ref type="table">3</ref>. For instance, the first three CEPs in that table are the same as those in Example 2; the CEP obtained in that example becomes the first CEP in Table <ref type="table">4</ref>.</p><p>The elimination of the chance node Test is performed by applying again Algorithm 2 (cf. Sec. A.4.1). In fact, the two CEPs for do test in Table <ref type="table">4</ref> are the same we used in Example 3 and the CEP obtained in that example is the first one in Table <ref type="table">5</ref>.</p><p>Finally, the elimination of Dec:Test is performed by applying again Algorithm 3 (cf. Sec. A.4.2) on the two CEPs in Table <ref type="table">5</ref>, as we did in Example 4. The optimal CEP obtained in that example is shown in Table <ref type="table">6</ref>.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Cost-effectiveness influence diagram for the Example 1.</figDesc><graphic coords="5,162.71,55.00,272.14,151.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 :</head><label>1</label><figDesc>Deterministic CEA Input: A set I = {I 1 , . . . , I m } of interventions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Example 2</head><label>32</label><figDesc>Figure 3: The result of applying Algorithm 1 to the interventions {nth, th1, th2} is a CEP whose thresholds are the slopes of the lines from nth to th1 and from th1 to th2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>c 1</head><label>1</label><figDesc>= 0.186 × 150 + 0.814 × 150 = 150 e e 1 = 0.186 × 4.05 + 0.814 × 9.85 = 8.77 QALY .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>A. 4 . 2</head><label>42</label><figDesc>Optimal CEP Definition 3 (Optimal CEP) Given a set of m CEPs {Q 1 , . . . , Q m } and a decision D, whose domain is {d 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>4</head><label></label><figDesc>perform a deterministic CEA analysis on the i-th interval; 5 add the new thresholds to Θ; 6 assign the cost, effectiveness, and optimal intervention of each interval (Eqs. 18 to 20); 7 remove the unnecessary thresholds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>P</head><label></label><figDesc>new (test | dec:test) = disease P old (disease) • P old (test | disease, dec:test) P new (disease | dec:test,test) = P old (disease) • P old (test | disease, dec:test) P new (test | dec:test) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Initial influence diagram built by the evaluation algorithm. Node U results from combining the three utility nodes in Figure 2. Disease Dec:Test Therapy CEP present do test no therapy { ( (0, +∞), 150, 1.2, "" ) } present do test therapy 1 { ( (0, +∞), 20 150, 4.0, "" ) } present do test therapy 2 { ( (0, +∞), 70 150, 6.5, "" ) } present do not test no therapy { ( (0, +∞), 0, 1.2, "" ) } present do not test therapy 1 { ( (0, +∞), 20 000, 4.0, "" ) } present do not test therapy 2 { ( (0, +∞), 70 000, 6.5, "" ) } absent do test no therapy { ( (0, +∞), 150, 10.0, "" ) } absent do test therapy 1 { ( (0, +∞), 20 150, 9.9, "" ) } absent do test therapy 2 { ( (0, +∞), 70 150, 9.3, "" ) } absentdo not test no therapy { ( (0, +∞), 0, 10.0, "" ) } absent do not test therapy 1 { ( (0, +∞), 20 000, 9.9, "" ) } absent do not test therapy 2 { ( (0, +∞), 70 000, 9.3, "" ) }</figDesc><graphic coords="15,185.39,55.00,226.77,137.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Influence diagram obtained after reversing the arc Disease → Test.</figDesc><graphic coords="17,185.39,139.06,226.77,136.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Influence diagram obtained after removing the node Disease.</figDesc><graphic coords="17,221.67,485.21,154.20,132.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Cost and effectiveness of each intervention for the Example 1. The ID for this example is shown in Figure2. Decisions are drawn as rectangles, chance nodes as rounded rectangles, and utility nodes as hexagons. The node Dec:Test represents the decision whether or not to do the test; it has two values: do test and do not test. The node Test represents the result of the test; its values are positive, negative, and not performed.</figDesc><table><row><cell>Therapy</cell><cell>Cost</cell><cell cols="2">Effectiveness +disease ¬disease</cell></row><row><cell>no therapy</cell><cell cols="3">0 e 1.2 QALY 10.0 QALY</cell></row><row><cell>therapy 1</cell><cell cols="2">20 000 e 4.0 QALY</cell><cell>9.9 QALY</cell></row><row><cell>therapy 2</cell><cell cols="2">70 000 e 6.5 QALY</cell><cell>9.3 QALY</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>9.11 -8.77) = 11 171 e/QALY, which becomes a new threshold. In the third interval, (33 384, 65 360), the ICER is (13 184 -0)/(9.39 -8.77) = 21 072 e/QALY, but this Algorithm 3: Optimal CEP Input: A variable D whose domain is {d 1 , . . . , d m } and a set of m CEPs {Q 1 , . . . , Q m</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>These four networks are available at www.probmodelxml.org/networks. The web page www.openmarkov.org/cea explains how to evaluate them.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1"><p>There is an apparent inaccuracy in the numerical results because in the arithmetic operations we have used the values obtained from the evaluation of Example 1 (Table3), while in the statement of the example we have rounded the values.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Technical Report CISIAD-14-02, UNED, Madrid, 2014.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3"><p>If there is a j such that P (x j ) = 1, then m = 1 at line 2 and consequently Q = Q j . Therefore, checking whether m = 1 before executing the rest of the algorithm might avoid some computations. However, we have not included this optimization in the pseudo-code of the algorithm to keep it clearer.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4"><p>This ID, built with OpenMarkov's graphical user interface, is available at www.openmarkov.org/cea.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been supported by grants <rs type="grantNumber">TIN2006-11152</rs> and <rs type="grantNumber">TIN2009-09158</rs>, from the <rs type="funder">Spanish Ministry of Science and Technology</rs>, by <rs type="funder">FONCICYT</rs> grant <rs type="grantNumber">85195</rs>, and by grant <rs type="grantNumber">PI13/02446</rs> of the <rs type="institution">Health Institute Carlos III</rs>. We would also like to thank the reviewers for their valuable comments and suggestions.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_pktEwfy">
					<idno type="grant-number">TIN2006-11152</idno>
				</org>
				<org type="funding" xml:id="_Syq8h3v">
					<idno type="grant-number">TIN2009-09158</idno>
				</org>
				<org type="funding" xml:id="_JnFmDqz">
					<idno type="grant-number">85195</idno>
				</org>
				<org type="funding" xml:id="_nVuRr52">
					<idno type="grant-number">PI13/02446</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>This paper contains a brief description of the arc reversal algorithm, a formal definition of CEP, the pseudo-code for CEA algorithms, and a detailed solution of the problem stated in Example 1. It may be useful to compare it with the decision tree solution <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Arc reversal for unicriterion IDs</head><p>The arc reversal algorithm <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> assumes that the ID has only one utility node, U ; otherwise, all the utility nodes must be summed up into a single node. The four basic operations of the algorithm are:</p><p>1. Barren node removal. A node is said to be barren if it has no children. Barren nodes can be removed from the ID without performing any additional operation. </p><p>where V = P a(C) ∪ (P a(U )\{C}) and ↓ denotes the projection of configurations; for example, v ↓P a(C) is the configuration of P a(C) in which every parent of C takes the same value as in v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Decision node removal.</head><p>A decision node D whose only child is the utility node U can be removed from the ID by drawing links from each parent of D to U . If U old (pa(U )) is the utility potential before eliminating D, the new utility potential after eliminating D is</p><p>where V = P a(D) ∪ (P a(U )\{D}). The values of d that maximize the expected utility for each configuration v determine the optimal policy for D.</p><p>4. Arc reversal. If the ID contains a link X → Y such that there is no other directed path from X to Y in the graph, this link can be reversed, i.e., replaced by Y → X, by performing the following additional operations: (1) all the parents of X become parents of Y , and vice versa; (2) the new probability of Y is</p><p>and the new probability of X is</p><p>where A = P a(X)\P a(Y ), B = P a(X) ∩ P a(Y ), and</p><p>Each of these operations transforms an ID into an equivalent ID having the same expected utility and the same optimal policies for the remaining decisions.</p><p>If the ID contains a chance node C having no decision as a child, that node must be removed before any decision. If C is the parent of other chance nodes, there is a sequence of arc reversals that generate an equivalent ID in which either C is a barren node or U is the only child of C-see Theorem 4 in <ref type="bibr" target="#b11">[12]</ref>. Therefore, it is always possible to remove a chance or a decision node, until only U remains; at the end the potential for U contains a single real number, which is the expected utility of the ID. { ( (0, +∞), 70 150, 9.25, "" ) } do not test not performed no therapy { ( (0, +∞), 0, 8.77, "" ) } do not test not performed therapy 1 { ( (0, +∞), 20 000, 9.07, "" ) } do not test not performed therapy 2 { ( (0, +∞), 70 000, 8.91, "" ) } </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dec</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Methods for the Economic Evaluation of Health Care Programmes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Sculpher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Torrance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Stoddart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Cost-Effectiveness in Health and Medicine</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Weinstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Net health benefit: A new framework for the analysis of uncertainty in cost-effectiveness analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Stinnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mullahy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Decision Making</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="68" to="S80" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">QALYs: The basics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Torrance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcguire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Value in Health</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="5" to="S9" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The influence of influence diagrams in medicine</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pauker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="238" to="244" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Cost-effectiveness analysis with sequential decisions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
		<ptr target="www.cisiad.uned.es/techreports/cea-multidec.php" />
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>UNED</publisher>
			<pubPlace>Madrid, Spain</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings on the Principles and Applications of Decision Analysis</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</editor>
		<meeting><address><addrLine>Menlo Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Strategic Decisions Group</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="719" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic Graphical Model for Total Knee Arthroplasty</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dept. Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>UNED. Madrid, Spain</pubPlace>
		</imprint>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models for Decision Making in Medicine</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luque</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>UNED. Madrid</publisher>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A decision support system for the mediastinal staging of non-small cell lung cancer</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Disdier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">st Annual Meeting of the Society for Medical Decision Making</title>
		<meeting><address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">On Representing and Solving Decision Problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Olmsted</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Engineering-Economic Systems. Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Evaluating influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="871" to="882" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bayesian Networks and Decision Graphs. 2nd ed</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Nielsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Foundations of cost-effectiveness analysis for health and medical practices</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Stason</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977">1977</date>
			<publisher>New England Journal of Medicine</publisher>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="page" from="716" to="721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Clinical Decision Analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Fineberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Elstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Saunders</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Sox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Blatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Marton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Decision Making</title>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Butterworth-Heinemann</publisher>
			<pubPlace>Woburn, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The computational complexity of probabilistic inference using Bayesian belief networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="393" to="405" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">From influence diagrams to junction trees</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Dittmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI&apos;94)</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>De Mantaras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Poole</surname></persName>
		</editor>
		<meeting>the Tenth Conference on Uncertainty in Artificial Intelligence (UAI&apos;94)<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="367" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Compiling Bayesian networks using variable elimination</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chavira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (IJCAI&apos;07)</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Veloso</surname></persName>
		</editor>
		<meeting>the Twentieth International Joint Conference on Artificial Intelligence (IJCAI&apos;07)<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="2443" to="2449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recursive conditioning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="5" to="41" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models: Principles and Techniques</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The necessity of bounded treewidth for efficient inference in Bayesian networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kwisthout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bodlaender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Gaag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th European Conference on Artificial Intelligence (ECAI&apos;10)</title>
		<meeting>the 19th European Conference on Artificial Intelligence (ECAI&apos;10)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="237" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modelling in economic evaluation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Kuntz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Weinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Economic Evaluation in Health Care</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Drummond</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Mcguire</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="141" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multi-currency influence diagrams</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Probabilistic Graphical Models</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Salmerón</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gámez</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="275" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Decision analysis networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>König</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth European Workshop on Probabilistic Graphical Models (PGM&apos;12)</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Cano</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Gómez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Nielsen</surname></persName>
		</editor>
		<meeting>the Sixth European Workshop on Probabilistic Graphical Models (PGM&apos;12)<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="83" to="90" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
