<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">INFLUENCE DIAGRAMS IN ANALYSIS OF DISCRETE EVENT SIMULATION DATA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jirka</forename><surname>Poropudas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Systems Analysis Laboratory</orgName>
								<orgName type="institution">Helsinki University of Technology</orgName>
								<address>
									<postBox>P.O. Box 1100</postBox>
									<postCode>FIN -02015 HUT</postCode>
									<country key="FI">FINLAND</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai</forename><surname>Virtanen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Systems Analysis Laboratory</orgName>
								<orgName type="institution">Helsinki University of Technology</orgName>
								<address>
									<postBox>P.O. Box 1100</postBox>
									<postCode>FIN -02015 HUT</postCode>
									<country key="FI">FINLAND</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">INFLUENCE DIAGRAMS IN ANALYSIS OF DISCRETE EVENT SIMULATION DATA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, influence diagrams (IDs) are used as simulation metamodels to aid simulation based decision making. A decision problem under consideration is studied using discrete event simulation with decision alternatives as simulation parameters. The simulation data are used to construct an ID that presents the changes in simulation state with chance nodes. The decision alternatives and objectives of the decision problem are included in the ID as decision and utility nodes. The solution of the ID gives the optimal decision alternatives, i.e., the values of the simulation parameters that, e.g., maximize the expected value of the utility function measuring the attainment of the objectives. Furthermore, the constructed ID enables the analysis of the consequences of the decision alternatives and performing effective what-if analyses. The paper illustrates the construction and analysis of IDs with two examples from the field of military aviation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Discrete event simulation is a flexible and widely used methodology for the analysis of complex real world systems <ref type="bibr" target="#b10">(Law 2006)</ref>. In simulation analysis, a simulation experiment is conducted by running simulations with alternative values of simulation parameters that determine the properties of the studied system. The values of the simulation parameters and the corresponding output are recorded to produce the simulation data that are used to estimate, e.g., descriptive statistics, empirical distributions of the simulation output, or statistical models that describe the dependence between the simulation parameters and the simulation output <ref type="bibr" target="#b10">(Law 2006)</ref>. Furthermore, in order to support decision making, the simulation data can be used for finding the simulation parameters that describe optimal system settings or configurations. The optimization is carried out either directly through simulation based optimization (e.g., <ref type="bibr" target="#b6">Fu, Glover, and April 2005</ref><ref type="bibr" target="#b14">, Ólafsson and Kim 2002</ref><ref type="bibr" target="#b20">, Swisher and Jacobson 1999)</ref> or by using simulation metamodels (e.g., <ref type="bibr" target="#b2">Cheng and Currie 2004</ref><ref type="bibr" target="#b5">, Friedman 1996</ref><ref type="bibr" target="#b1">, Barton 1998)</ref> which refer to simplified and analytical models representing the simulation model. Such approaches are used to determine the simulation parameters that result in the desired simulation outcome or produce optimal simulation output with respect to a given optimization criterion. In general, the optimization criteria of such analyses depend on the final outcome of the simulation or measure the system performance using time averages. Thus, they omit the time evolution of the simulation and give no explicit information on the progress of the simulation with different values of the simulation parameters.</p><p>In this paper, simulation based decision making refers to the use of simulation in the analysis and solution of decision problems under uncertainty. The definition of the decision problem consists of available decision alternatives and an objective describing the preferences of the decision maker. The alternatives are compared using a suitable simulation model that represents the uncertain, random, or uncontrollable factors that may be an integral part of the decision problem. The alternatives are fed to the simulation model as simulation parameters and the resulting simulation output is collected. Then, based on the simulation output, one can solve the optimal decision alternative or rank the alternatives based on a given optimization criterion associated with the objective of the decision problem.</p><p>The simulation data can be used, in addition to the optimization of the simulation output, to better understand what actually happens during the simulation. In such case, the data should be presented in a form that describes the evolution of the simulation, i.e., how the simulation state changes in time. For increased analytical capability, the presentation should also include the interdependencies between the simulation states at different time instants -preferably in a probabilistic</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Poropudas and Virtanen</head><p>manner in order to represent the uncertainties related to simulation. <ref type="bibr" target="#b16">Poropudas and Virtanen (2007)</ref> presents a method for analyzing the evolution of discrete event simulations with dynamic Bayesian networks (DBNs, e.g., <ref type="bibr" target="#b13">Neapolitan 2004</ref><ref type="bibr" target="#b9">, Jensen and Nielsen 2007</ref><ref type="bibr" target="#b15">, Pearl 1986</ref>). In the presented approach, chance nodes of a DBN and their interconnecting arcs are used to describe the joint probability distribution of the random variables that presents the evolution of the simulation state during simulation. The analysis of such networks has been found more effective and less time consuming than the brute force analysis of raw simulation data <ref type="bibr" target="#b16">(Poropudas and Virtanen 2007)</ref>. Unfortunately, DBNs are only descriptive and offer no direct way for optimizing the simulation output.</p><p>In this paper, the above mentioned analysis is extended to simulation based decision making by constructing influence diagrams <ref type="bibr">(IDs, Howard and</ref><ref type="bibr" target="#b7">Matheson 1984, Howard and</ref><ref type="bibr" target="#b8">Matheson 2005)</ref> from simulation data. The IDs are probabilistic models that are used for structuring and solving decision problems under uncertainty (e.g., <ref type="bibr" target="#b4">Diehl and</ref><ref type="bibr">Haimes 2004, Virtanen, Raivio, and</ref><ref type="bibr" target="#b21">Hämäläinen 1999)</ref>. In the construction of an ID, a DBN is first built by combining simulation data with expert knowledge <ref type="bibr">(Neapolitan 2004, Poropudas and</ref><ref type="bibr" target="#b16">Virtanen 2007)</ref> to present the evolution of the simulation state. Then, the DBN is extended into an ID by including the simulation parameters into the model to represent the parameters' effect on the simulation output and the changes in the simulation state. In practice, the parameters are represented by decision nodes that have a discrete set of states corresponding to the available decision alternatives.</p><p>To enable the comparison of decision alternatives, the preferences of the decision maker are included into the ID by adding a utility node and a corresponding utility function <ref type="bibr" target="#b22">(von Neumann and Morgenstern 1944)</ref>. The utility function is defined as a function of the simulation output that measures the attainment of the objectives of the decision problem. Such an approach is versatile because different utility functions offer almost unlimited possibilities for modeling the preferences of the decision maker. The constructed ID is then solved to find the optimal decision alternatives that maximize the expected value of the utility function. The ID is also used for studying the evolution of the simulation and conducting what-if analyses. Thus, the ID methodology offers an approach to simulation metamodeling that makes the simulation analysis of decision problems more transparent and gives valuable information about the consequences of decision alternatives.</p><p>The paper is organized as follows. The construction of IDs from simulation data is presented in Section 2. In Section 3, potential ways for utilizing the IDs are outlined. The utilization of IDs is illustrated in Section 4 with two examples of simulation analysis involving the maintenance of military aircraft and a 1 vs. 1 air combat engagement. Finally, conclusions are made and future research topics are proposed in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CONSTRUCTION OF INFLUENCE DIAGRAMS FROM SIMULATION DATA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Influence Diagrams</head><p>IDs <ref type="bibr">(Howard and</ref><ref type="bibr" target="#b7">Matheson 1984, Howard and</ref><ref type="bibr" target="#b8">Matheson 2005)</ref> are models that give graphical and analytical means for outlining and solving decision problems under uncertainty. IDs can be used to model the dependence relations between available decision alternatives and the objectives of the decision problem. Moreover, if the decision problem involves factors that are beyond the decision maker's control, they too can be incorporated in the ID. The objectives are described using a utility function that includes both the preferences of the decision maker as well as her attitude towards risk <ref type="bibr" target="#b22">(von Neumann and Morgenstern 1944)</ref>. The IDs are useful for structuring decision problems and, more importantly, they can be solved with effective algorithms to obtain the combination of decision alternatives that is most preferred by the decision maker <ref type="bibr">(Shachter 1986, Jensen and</ref><ref type="bibr" target="#b9">Nielsen 2007)</ref>.</p><p>The definition of an ID is based on a directed acyclical graph over decision, chance, and utility nodes (see, Fig. <ref type="figure">1</ref>). Each decision node of the ID, denoted by d( j), j ∈ {1,...,m}, has a discrete set of states, denoted by D( j), presenting the available decision alternatives at the given node. The decision nodes are ordered so that the decisions are made in sequence and the previous decisions are recalled when making further decisions. The arcs of the ID are used to model both the dependencies between nodes and the flow of information. Mainly, if there is an arc from a chance node to a decision node, the state of the chance node is known at the time of the decision.</p><p>Each chance node x(i), i ∈ {1,...,n}, of the ID has a discrete set of states, denoted by X(i), and a probability table that gives the conditional probabilities of these states when the states of the parents of the node, i.e., the nodes with an arc pointing to the node of interest, are known. The chance nodes are used to model the framework and environment of the decision problem by representing the joint distribution of random variables, i.e., the probabilities P(x(1) = x 1 ,...,x(n) = x n ) for all possible combinations of states x 1 ,...,x n , where each x i ∈ X(i). The random variables present uncertain factors that affect the outcome of the decision problem but can not be directly controlled by the decision maker. Yet, the probability distributions of these variables may depend on the chosen decision alternatives. In other words, if there is an arc from a decision node to a chance node, the probability distribution of the chance node depends on the state of the decision node. A utility node u is used to describe the objective of the decision maker.In this paper, only cases with one objective, i.e., a single utility node, are discussed. IDs could also be used for analyzing decision problems with multiple objectives represented by several utility nodes <ref type="bibr" target="#b4">(Diehl and Haimes 2004)</ref>. The utility node has a set of states, denoted by U, that represent different outcomes of the decision problem and depend on the states of the decision and chance nodes with an arc pointing to u. The decision maker's preference between these outcomes is modeled using a utility function f (•) : U → [0, 1] where the least and most desirable outcomes are scaled to values 0 and 1, respectively. If the decision maker, whose preferences are represented by the utility function, is prepared to accept the axiomatic definition of rationality as given by utility theory (see, e.g., Keeney and Raiffa 1993), her objective is set as the maximization of the expected value of the utility function <ref type="bibr" target="#b22">(von Neumann and Morgenstern 1944)</ref>. Thus, when making a decision, the decision maker selects the state of a decision node that maximizes her expected utility.</p><p>It should be noted that technically there is no other distinction between decision nodes and chance nodes except that the decision maker can choose the states of the decision nodes. On the other hand, if the chance nodes of the ID are considered independently from the rest of the diagram, they form a Bayesian network (BN, also known as Bayesian belief network, see, e.g., <ref type="bibr">Pearl 1986, Jensen and</ref><ref type="bibr" target="#b9">Nielsen 2007)</ref>. When a BN is divided into disjoint time slices, where each time slice consists of random variables realized at the same time instant, it is called a dynamic Bayesian network. By connecting the time slices with arcs that represent the dependence between random variables realized at different times, the DBNs can be applied for modeling time dependent phenomena. In this paper, the chance nodes of an ID form a DBN that represents the time evolution of the simulation and gives the probability distribution of the simulation state at different times.</p><p>There are many methods for solving an ID and finding the optimal decision alternatives for all decision nodes (see, e.g., <ref type="bibr" target="#b9">Jensen and Nielsen 2007)</ref>. Generally, the combination of decision alternatives that maximizes the expected utility is sought. On the other hand, the ID provides the probability distribution for the states of the utility node conditional on a given combination of decision alternatives. Thus, other criteria could also be used for comparing the decision combinations. Regardless of the method used and the optimization criterion, the optimal solution of the ID is found in feedback form that gives the optimal decision alternative for each decision node as a function of its parents' states. In practice, the solution of the ID is obtained with computationally effective algorithms (e.g., <ref type="bibr" target="#b18">Shachter 1986</ref><ref type="bibr" target="#b19">, Shachter 1988</ref><ref type="bibr" target="#b9">, Jensen and Nielsen 2007)</ref> that are already implemented in available software such as GeNIe (Decision Systems Laboratory 2009) and Hugin <ref type="bibr" target="#b0">(Andersen, Olesen, and Jensen 1990)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Construction of Influence Diagrams</head><p>When analyzing a decision problem using simulation and an ID, the ID is constructed by combining expert knowledge with automated learning where the probability tables of chance nodes and the structure of the network are estimated from data (e.g., <ref type="bibr" target="#b13">Neapolitan 2004)</ref>. First, the decision problem at hand is presented by identifying the decision alternatives and the objective. In simulation, the values of simulation parameters correspond to the decision alternatives and simulation output used to measure the attainment of the objective. The simulation state is defined in such a manner that it gives a comprehensive and effective presentation for the decision problem. In practice, the simulation state at each time instant t ∈ {t 0 ,t 1 ,...,t n } is represented by a discrete random variable, x(t), that is associated with a chance node in the ID.(If necessary, continuous simulation state variables may be discretized resulting in discrete valued variables.) The time evolution of the simulation state and interdependence between the states at different times are modeled with the conditional probability tables of the chance nodes. This presentation for the simulation state is in fact a DBN <ref type="bibr" target="#b16">(Poropudas and Virtanen 2007)</ref>.</p><p>The evolution of the simulation is affected by the values of the simulation parameters that represent factors that may or may not be controlled by the decision maker. To model this dependence, the simulation parameters are included in the ID. If the factors presented by the simulation parameters are controllable, they are included in the ID as decision nodes. If the parameters can not be controlled, they are added as chance nodes representing external random variables. In such cases, expert knowledge is needed to define the prior distributions of the external variables, i.e., the probabilities of different simulation parameter values.</p><p>When the decision and chance nodes of the ID have been determined, the initial structure of the ID is drawn by a subject matter expert. In other words, the nodes are connected with arcs to delineate their interdependence. The conditional probability tables of the chance nodes are estimated using automated learning where the initial structure of the diagram and the pre-processed simulation data are fed to a software such as GeNIe or Hugin. The estimation of probabilities is based on the observed frequencies, i.e., the probability of a combination of states depends on the number of times it has been observed <ref type="bibr" target="#b13">(Neapolitan 2004</ref>). The final structure of the diagram is found by comparing various structure alternatives and the best structure is selected, e.g., by using a scoring rule <ref type="bibr">(Neapolitan 2004, Poropudas and</ref><ref type="bibr" target="#b16">Virtanen 2007)</ref>. The scoring rules are based on trade-off between the size of the model and the fit between the probabilities given by the model and those estimated from the simulation data. If there exists notable lack-of-fit, additional arcs may be added to the initial structure in order to include the observed dependencies. When constructing IDs for continuous time phenomena, the time instants represented by the chance nodes are selected so that the maximal absolute error between the probabilities estimated from the simulation data and those given by the ID is minimized. The optimization problem and its solution are presented in detail in <ref type="bibr" target="#b17">Poropudas and Virtanen (2009)</ref>.</p><p>Finally, a utility node is added to the model. In practice, the dependence between the state of the utility node and the states of the decision and chance nodes is represented with arcs. All combinations of the states of the utility node's parents are associated with a state of the utility node. Each of these states represents a potential outcome of the decision problem that results from the selected decision alternatives and the realized states of the chance nodes. Thus, the ID can be used to calculate the probability distribution of the states of the utility for each combination of the decision alternatives. The decision maker's preference between the states of the utility node is measured using a utility function that can be elicitated by, e.g., proposing lotteries between different states and finding the subjective probabilities that render the alternatives equally desirable (Keeney and Raiffa 1993).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ANALYSIS OF SIMULATION DATA WITH INFLUENCE DIAGRAMS</head><p>The constructed IDs are studied in order to better understand the decision problem and solve the optimal decision alternatives. In this paper, the IDs are used for the following purposes: studying time evolution and tracking of the probability of a given simulation state, conducting what-if analyses, and solving optimal decision alternatives as well as studying the decision alternative's effects on the evolution of simulation. It should be noted that such analyses could also be conducted by brute force estimation and comparison of probability distributions calculated directly from the simulation data. Nevertheless, the utilization of IDs makes the analysis more effective and less time consuming as there is no need for repeated screening of the simulation data <ref type="bibr" target="#b16">(Poropudas and Virtanen 2007)</ref>. Furthermore, the available software tools can be utilized both to calculate probability distributions and solve the optimal decision alternatives.</p><p>Time Evolution and Tracking. The estimated ID gives the joint distribution of the random variables describing the simulation state at times t ∈ {t 0 ,...,t n }. In other words, the probability of the simulation progressing through the states x 0 ,...,x n at the respective time instants is P(x(t 0 ) = x 0 ,...,x(t n ) = x n ). The joint distribution can be used to calculate the probability distribution P(x(t i ) = x) over the simulation states x ∈ X(i) at fixed time instant t i . The changes in this distribution can be studied visually to better understand the evolution of the simulation <ref type="bibr" target="#b16">(Poropudas and Virtanen 2007)</ref>. On the other hand, one can simply inspect the probability of the simulation being in a fixed state x at different times t ∈ {t 0 ,...,t n }. These probabilities, P(x(t i ) = x), can be tracked to analyze the likelihood of a given simulation event taking place, i.e., the simulation being in the state x, during the simulation. To compare the available decision alternatives, the ID is used to calculate the conditional probability distributions P(x(t 0 ) = x 0 ,...,x(t n ) = x n |d( j) = d j ) and P(x(t) = x|d( j) = d j ) for each decision alternative d j ∈ D( j). The conditional probability distributions show the consequences of a given decision alternative by describing the progress of the simulation when that alternative is selected. In cases where the simulation state has a reasonable numerical interpretation, all the above mentioned distributions can be used to calculate descriptive statistics such as the expected value of the simulation state at time t, E(x(t)), that shows the evolution of the average state of the simulated system.</p><p>What-if Analysis. The chance nodes of the ID represent the dependencies between simulation states at specific times as well as between simulation parameters and simulation states. The IDs are used to conduct what-if analysis where the model is fed evidence, i.e., the state of the simulation at a given time t or the value of an uncontrollable simulation parameter. Then, the distributions of other variables are updated accordingly to study the effects of this observation, P(x(t 0 ) = x 0 ,...,x(t n ) = x n |x(t) = x). The updated distributions show how the occurrence of a given simulation state at given time affects both the progress and the final state of the simulation. The same kind of analysis can also be conducted conditional on decision alternatives available in the node d( j). Then, the conditional distributions P(x(t 0 ) = x 0 ,...,x(t n ) = x n |x(t) = x, d( j) = d j ) are calculated to see how the simulation progresses when the alternative d j has been chosen and the simulation is observed in state x at time t. When applicable, it is possible to use all these conditional probability distributions to calculate the respective conditional expected values of the simulation state, e.g., E(x(t n )|x(t) = x).</p><p>Solution of Optimal Decisions. The ID is solved to see how the decision alternatives affect the distribution of the utility node. The alternatives can be compared to find the one that maximizes the expected utility E( f (•)| d( j) = d j ). On the other hand, the ID retains the information necessary for further analysis by, e.g., studying different utility functions.</p><p>Consequences of Decisions. In addition, the ID shows the progress of the simulation for a given decision alternative which increases one's understanding over the decision problem and reveals the actual consequences of the decisions in addition to the resulting expected value of the utility. By representing the evolution of the simulation, the probability distributions produced by the ID show how or why the alternative performs better than others. The ID also gives probabilities for simulation events consequent on the decision alternatives that can be easily compared. For example, one can recognize alternatives that lead to high values of the expected utility but may result in the occurrence of unwanted events during the simulation with an unacceptably high probability. Thus, the analysis of the ID may give additional insight to decision problems in comparison to other approaches used in simulation based optimization (see, e.g., <ref type="bibr" target="#b2">Cheng and Currie 2004</ref><ref type="bibr" target="#b6">, Fu, Glover, and April 2005</ref><ref type="bibr" target="#b14">, Ólafsson and Kim 2002</ref><ref type="bibr" target="#b20">, Swisher and Jacobson 1999)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXAMPLE ANALYSES</head><p>Next, two examples on the construction and utilization of IDs in the analysis of simulation data are presented. In the first example, an ID is constructed to study a discrete event simulation model for the maintenance of a military aircraft fleet <ref type="bibr" target="#b11">(Mattila, Virtanen, and Raivio 2008)</ref>. The ID is used to describe the dependence between the number of personnel in a maintenance unit and the availability of aircraft. In the second example, a discrete event air combat simulation model called X-Brawler is studied (L-3 Communications Analytics Corporation 2002). Here, an ID is constructed for comparing the effectiveness of decision alternatives in 1 vs. 1 air combat. The comparison is carried out based on several alternative objectives in order to see how the optimal decision alternative depends on the objectives. On the other hand, the ID is used to describe the evolution of air combat and study the consequences of the available decision alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Aircraft Maintenance Simulation</head><p>In this example, the maintenance of military aircraft is studied using a discrete event simulation model <ref type="bibr" target="#b11">(Mattila et al. 2008</ref>). The simulation model is presented in detail in <ref type="bibr" target="#b11">Mattila et al. (2008)</ref>. The example is based on a simplified model with only one air command. The example presents a scenario where a fleet of 10 aircraft is serviced by a maintenance unit within a single air command. The maintenance unit is responsible for turnaround and preflight inspections, minor periodic maintenance, and minor failure repairs such as simple component changes. In the example, an ID is constructed from the simulation data to describe the dependence between the number of personnel in the maintenance unit and the availability of aircraft, i.e., the number of mission capable aircraft, that is used to measure the performance of the maintenance unit.</p><p>For demonstration purposes, the number of personnel, denoted by z ∈ Z = {2, 3, 4}, is studied as an uncontrollable simulation parameter. In other words, it is taken as a factor that is included in the simulation model only as a parameter and added to the ID as a chance node. The simulation state x(t) at time t, x(t) ∈ X(t) = {0, 1,...,10}, is set as the availability of the aircraft at the beginning of the day t. At the beginning of the simulation there are nine available aircraft, i.e., x(0) = 9. The state of the simulation is checked daily for 20 days, t ∈ {0, 1,...,20}. To model the interdependencies between the simulation states as well as the dependence between the simulation parameter and the simulation states, the structure of the ID is defined as shown in Fig. <ref type="figure">2</ref>.</p><p>To gather the necessary simulation data, the simulation is replicated 10000 times for each value of z. The simulation data is fed into the GeNIe software to estimate the conditional probability tables for the chance nodes x(t). The software</p><formula xml:id="formula_0">x(0) x(1) x(2) x(3) . . . x(18) x(19) x(20) z Figure 2:</formula><p>The ID for the aircraft maintenance example. The progress of the simulation is described with chance nodes x(t). The simulation state x(t) depends only on the previous state and the number of personnel in the maintenance unit,</p><formula xml:id="formula_1">z ∈ Z = {2, 3, 4}.</formula><p>is also used to confirm that the structure of the ID is satisfying and there are no statistically significant dependencies that would require additional arcs. The prior distribution of the external variable z can not be estimated from simulation data. Therefore, it is assessed by an expert and defined as P(z = 2) = P(z = 3) = 0.20 and P(z = 4) = 0.60. In other words, the most probable alternative is that the maintenance unit operates at full capacity and the other two alternatives are equally probable.</p><p>To analyze the evolution of the simulation, the constructed ID is used to calculate the probability distribution of the number of available aircraft P(x(t) = x|z) for all time instants t and values of z. The conditional expected values for these distributions E(x(t)|z) for each value of z are presented in Fig. <ref type="figure">3</ref>(a) where the continuous lines present the values estimated from the simulation data and circles with the dotted lines represent the values given by the ID. The red curve presents the expected value of availability given by the ID that incorporates the expert knowledge about the distribution of z to the simulation data. In other words, the curve combines the expert knowledge with the simulation data giving a comprehensive overall picture of the simulated scenario.</p><p>The dependence between the performance of the maintenance unit and the number of personnel is studied in a what-if type analysis, see Fig. <ref type="figure">3(a)</ref>. There is a slight difference between the curves representing values z = 3 and z = 4, but in effect they act in a similar manner to the overall expected value of availability. On the other hand, the maintenance unit with only two mechanics, i.e., z = 2, struggles to service the fleet and the expected value of availability dips heavily in the second half of the simulation.</p><p>The ID also enables further what-if analysis where the state of the simulation is observed at a given time and the consequences of this observation are calculated. For example, the ID is fed evidence that x(10) = 8, i.e., it is assumed that there are eight aircraft available at the beginning of day 10. The probabilities of the evidence for different values of z are P(x(10) = 8|z = 2) = 0.189, P(x(10) = 8|z = 3) = 0.229, and P(x(10) = 8|z = 4) = 0.246. Thus, the probability of the observed simulation state increases along the number of personnel. The resulting conditional expected values of availability are presented in Fig. <ref type="figure">3(b</ref>). In the case of two mechanics, the expected value of availability dips considerably at the latter stages of the simulation, despite there being eight available aircraft at time t = 10.</p><p>In addition to the estimates of the expected availability that have already been studied in <ref type="bibr" target="#b11">Mattila et al. (2008)</ref>, the ID gives the probabilities of states P(x(t) = x) and the conditional probabilities of states P(x(t) = x|z) in an easily handleable and compact form. For example, if the number of available aircraft falls to four or less, i.e., x(t) ≤ 4, no more than two pairs of aircraft can be deployed to carry out missions. The ID can be used to effectively calculate the probability of the occurrence of such an event for different sizes of personnel, as presented in Fig. <ref type="figure">3(c</ref>). The figure shows that, in the case of two mechanics, the probability peaks at P(x( <ref type="formula">12</ref>) ≤ 4|z = 2) = 0.157 and the performance capacity of the fleet may be found inadequate at this time.</p><p>To summarize the findings, the analysis of the ID constructed from simulation data shows that the availability of the aircraft is heavily influenced by the number of personnel. Based on the prior probability distribution of the number of personnel, the expected value of availability remains mostly above seven aircraft and the probability of less than four available aircraft is low. There is no clear difference between the expected value of availability and the conditional expected values with three or four mechanics, even though the maintenance unit with four mechanics performs best. On the other hand, if there are only two mechanics in the maintenance unit, the performance degrades noticeably. The expected value of availability dips heavily later in the simulation. This is true even for the case where there are eight available aircraft on the tenth day. (c) The probability of "at most 4 aircraft available", P(x(t) ≤ 4) and the conditional probabilities P(x(t) ≤ 4|z) for different numbers of personnel.</p><p>Figure <ref type="figure">3</ref>: Performance of the maintenance unit. The continuous lines depict the estimates calculated from the simulation data. The circles and dotted lines present the corresponding estimates given by the ID. The red curve gives the corresponding estimates when the prior distribution of z is included in the ID.</p><p>In fact, with only two mechanics there is a remarkably high probability of less than four available aircraft on the latter half of the simulation.</p><p>The utilization of the ID gives several advantages to the analysis of the simulation data. The fit between the ID and the simulation data is almost perfect as the continuous and dotted blue curves in Fig. <ref type="figure">3</ref> are indistinguishable from each other. This refers to the validity of the model and it would appear that the ID incorporates the essential information included in the simulation data. In what-if analyses, the ID can be used to calculate conditional probabilities effortlessly and accurately. The ID also shows the time dependence of the simulation state in a compact manner. Furthermore, by using the ID, expert knowledge can be seamlessly joined with the simulation data for more extensive analysis that includes factors that are only modeled as parameters in the simulation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Air Combat Simulation</head><p>In the second example, an air combat scenario is analyzed using a discrete event air combat simulation model called X-Brawler <ref type="bibr">(L-3 Communications Analytics Corporation 2002)</ref>. The scenario presents a 1 vs. 1 air combat where blue chooses between two alternative tactics at the beginning of the engagement. The scenario is studied using generic unclassified models for blue and red aircraft as well as for missiles, radars, and other hardware.</p><p>The decision problem analyzed in the scenario concerns the maneuvering of blue and is described as follows. The initial geometry of the scenario is advantageous for blue as it approaches red from behind near the launch area of the medium range missiles. In other words, at the start of the scenario blue is preparing to launch its missile towards red. On the other hand, blue has only one semi-active medium range missile at its disposal while red carries two such missiles. Therefore, blue will be at a considerable disadvantage if its missile misses the target. In addition to the medium range missiles, both aircraft are equipped with short range missiles that are used if the engagement leads to combat within visual range.</p><p>Suppose now that blue has two decision alternatives: an aggressive and defensive tactic. In the aggressive alternative, blue launches its missile and continues to approach towards the opponent in order to engage within visual range combat and use its short range missiles if the initial missile is unsuccessful. If the defensive alternative is chosen, blue launches its missile and performs a drag maneuver, i.e., flies away from the opponent, before continuing the engagement. This maneuvering should allow blue to avoid the first missile that is possibly launched by red.</p><p>To analyze the decision problem, the ID presented in Fig. <ref type="figure" target="#fig_1">4</ref> is constructed. In the ID, decision node d corresponds to the decision of blue, where the set of available decision alternatives is D = {aggressive, defensive}. To model the evolution of the simulation, the state of the air combat at time t is described by a random variable x(t) that corresponds to a chance node of the ID. The set of states for variable is X(t) = {neutral, blue advantage, red advantage, mutual disadvantage} where the definitions of the states are</p><p>• neutral, both sides are alive • blue advantage, blue is alive and red has been killed • red advantage, blue has been killed and red is alive • mutual disadvantage, both sides have been killed</p><p>In other words, the variable x(t) reflects the outcome of the simulated air combat up to the time t.</p><p>x(0)</p><p>x( <ref type="formula">122</ref> The structure of the ID, i.e., the arcs between the decision nodes and the chance nodes, is determined by a subject matter expert. The structure implies that the simulation state at time t depends on the previous simulation state and the decision taken by blue. In addition, decision d is made before the start of the engagement without any knowledge of the simulation states at latter time instants.</p><p>To gather the necessary simulation data for constructing the ID, the scenario is simulated 10000 times for both decision alternatives. The time instants represented by the chance nodes are selected by minimizing the maximal absolute error between the probabilities estimated from the simulation data and those given by the ID. The optimal solution corresponds to time instants t ∈ <ref type="bibr">{0, 122, 135, 146, 157, 202, 237, 500} (in seconds)</ref>. The GeNIe software is used to estimate the conditional probability tables of x(t) and to determine that no additional arcs are needed to represent the dependencies found in simulation data.</p><p>To complete the ID, utility node u is added. In the scenario, the objective of the decision problem depends only on the final state of the air combat. Thus, the set of states for u is defined similarly to chance nodes x(t) of the ID, i.e., U = X(t). The dependence between the utility node and other nodes is defined simply by setting the state of u as equal to the final state of the simulation, i.e., x(500).</p><p>The constructed ID is used to calculate the probability distribution of simulation state x(t) for all time instants t. In Figs. 5(a) and 5(b), the probability distributions estimated from the simulation data are presented with the continuous lines and the dotted lines with circles correspond to the probabilities given by the ID. Evidently, the ID gives an accurate representation of the simulation data and there are no noticeable differences between the curves.  The continuous lines depict the probabilities calculated from the simulation data. The circles and the dotted lines present the corresponding probabilities given by the ID. Fig. <ref type="figure" target="#fig_3">5</ref>(a) shows how the simulated air combat progresses when the decision alternative "aggressive" is chosen. The first observation is that the probability curves remain nearly unchanged before time instant 122 and after 237, i.e., the most important changes in the simulation state take place between these times. There is a sharp peak in the probability of the state "blue advantage" between time instants 135 and 157. This is explained by blue launching its missile first and shooting down red with probability 0.462 before time instant 146. Nevertheless, in this scenario, red has time to launch a missile before being shot down. This leads to a 0.409 probability that blue is also killed before time instant 157 and the air combat ends in the state "mutual disadvantage" with probability 0.416.</p><p>In the end, there is only a 0.141 probability for blue winning the engagement. Furthermore, even if blue is not successful in shooting down red with its medium-range missile, there is a 0.397 probability of the air combat resulting in the state "red advantage" where blue is shot down later in the engagement. Overall, there is only a 0.046 probability of both sides surviving the engagement and the simulation ending in the state "neutral".</p><p>Fig. <ref type="figure" target="#fig_3">5</ref>(b) shows the respective probability curves for the decision alternative "defensive". Unlike the previous case, now there is no peak in the probability of the state "blue advantage". Instead, the probability of "blue advantage" rises sharply to 0.372 by the time instant 157 representing a hit by the blue missile. After this early rise, the probability of the state "blue advantage" continues to climb towards the final value of 0.445. Thus, by performing the drag maneuver, blue is able avoid the missile that red may have launched before being shot down. On the other hand, there is a 0.477 probability that red will shoot down blue with its second medium range missile later, i.e., the red holds a considerable advantage in the following engagement. Overall, there is a 0.072 probability of both aircraft surviving the combat and only 0.007 chance that both aircraft are shot down.</p><p>In addition to describing the evolution of the simulation, the ID is used to calculate the probability distribution of the states of the utility node for both decision alternatives (see, Table <ref type="table" target="#tab_1">1</ref>). The values of the utility function associated with the states of the utility node can be defined in many ways to represent the alternative objectives that the decision maker might have. In the discussed case, the least preferred outcome for blue is clearly "red advantage" and the most preferred "blue advantage". This leaves only the values of the utility function for the states "neutral" and "mutual disadvantage" to be determined. The utility functions are scaled so that the least and most desirable states produce utilities equal to 0 and 1, respectively.</p><p>In Table <ref type="table">2</ref>, alternative utility functions are presented. Utility function f 1 (•) represents a decision maker whose only objective is the survival of blue, i.e., the decision maker receives the highest utility in those states of the utility node where blue has survived the engagement. Conversely, f 2 (•) represents a decision maker who is only interested in shooting down red and receives the maximal utility in the states where red has been shot down. Utility function f 3 (•) measures the probability of blue winning the air combat. In the utility function f 4 (•), the states "neutral" and "mutual disadvantage" are taken equally preferred and their utility is half of the utility received from "blue advantage". Utility function f 5 (•) gives an example of a decision maker who is indifferent between the decision alternatives.</p><p>Table <ref type="table">2</ref>: The comparison of five utility functions. All the utility functions take values 0 and 1 in the states "red advantage" and "blue advantage", respectively. The different values associated with the states "neutral" and "mutual disadvantage" represent alternative objectives. For each utility function, the optimal decision is solved by finding a decision alternative that maximizes the expected value of the utility function. </p><formula xml:id="formula_2">(•) 1 0 0 1 0.187 &lt; 0.517 f 2 (•) 1 0 1 0 0.557 &gt; 0.452 f 3 (•) 1 0 0 0 0.141 &lt; 0.445 f 4 (•) 1 0 0 .5 0 .5 0.372 &lt; 0.485 f 5 (•) 1 0 0 .8 0 .9 0.515 = 0.515</formula><p>Table 2 also presents the optimal decision alternatives that are solved by comparing the expected utilities of the decision alternatives. In the case of f 1 (•), f 3 (•), and f 4 (•), the decision maker prefers the defensive tactic because it produces the highest expected utility. In the case of f 2 (•), the aggressive tactic is found to be preferable. If the utility function is f 5 (•), the decision maker is indifferent between the two alternatives, i.e., both tactics give the same expected utility.</p><p>In addition to solving the optimal decision alternative for a given utility function, the ID can be fed evidence of the simulation state to conduct what-if analysis and study the potential consequences of the decision alternatives. For example, if the simulation is in the state "neutral" at time 157, it is known that both aircraft have missed with their first missiles. The probabilities of such evidence are P(x(157) = neutral| d = aggressive) = 0.164 and P(x(157) = neutral| d = defensive) = 0.616. Thus, the both aircraft are more likely to survive up to this time instant if the defensive alternative is chosen. In the case of the aggressive tactic, Fig. <ref type="figure" target="#fig_5">6</ref>(a) implies that blue remaining within visual range combat is slightly favorable to red who has a 0.382 probability of shooting down blue and surviving, compared to the 0.303 probability for blue. On the other hand, Fig. <ref type="figure" target="#fig_5">6(b)</ref> shows that the defensive tactic is disastrous for blue if both sides have survived the first missiles. In this case, red is going to win the air combat with a 0.754 probability, compared to the 0.119 probability for blue. Thus, if blue uses the defensive tactic and both aircraft miss with their first missiles, the increased distance between aircraft is highly disadvantageous for blue due to its lack of additional medium range missiles.</p><p>The results provided by the ID can be summarized as follows. The defensive tactic is preferable in the cases where the decision maker values the survival of blue. With this tactic, blue can avoid the first missile of red even though it leaves blue in a disadvantageous position should the blue missile miss its target. On the other hand, if the objective of the decision maker is to shoot down the red aircraft, the aggressive tactic should be selected. Unfortunately, this tactic gives little chance for the survival of blue and is likely to result in both aircraft being shot down.</p><p>In this example, the ID constructed from the simulation data was found helpful in many ways. It gives an accurate representation of the simulation data as the continuous and dotted blue curves in Figs. 5 and 6 coincide very well -especially at the time instants included in the ID. The ID also provides an informative presentation for the evolution of the simulated  AC. Most importantly, the optimal decision alternatives are easily solved for a variety of utility functions with the help of suitable software. The ID also reveals the consequences of the decision alternatives by enabling various what-if analyses that can be conducted fast and effortlessly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>In this paper, IDs are combined with discrete event simulation in order to solve decision problems. The paper presents both the construction of IDs from simulation data and their utilization in the analysis of decision problems. In such an analysis, a suitable simulation model is used to gather the necessary simulation data for the construction of an ID. Then, the simulation state and its probabilistic changes during the simulation are described by random variables that are represented by the chance nodes of the ID. The decision alternatives related to the simulation parameters are included in the ID as decision nodes and the objective of the decision problem as a utility node with an appropriate utility function. If the effects of uncontrollable factors are studied, the simulation parameters are included in the ID as external variables with prior distributions given by an expert. The construction of the ID involves expert input but is nevertheless straightforward and can be carried out based on a single sweep of the simulation data with the help of suitable software.</p><p>IDs can also be seen as a new type of simulation metamodel that is used to analyze the progress of the simulation, effectively solve optimal decision alternatives, and study the consequences of the decision alternatives. The IDs show the time evolution of the simulation and the dependencies between the simulation states at different time instants. Furthermore, the IDs give an effective tool for simulation based decision making. The IDs offer thorough insight into the course of the simulation and show how different events affect its outcome, making simulation based decision making more transparent. Additionally, the IDs present the probability distribution of the states of the utility node and thus alternative utility functions can be compared with little extra effort. It should also be noted that the analysis of the constructed IDs could be extended into multi-objective settings where the decision alternatives are compared with respect to several, possibly conflicting, objectives <ref type="bibr" target="#b4">(Diehl and Haimes 2004)</ref>.</p><p>The examples presented in the paper involve military aviation but IDs constructed from simulation data can be undoubtedly applied in the analysis of almost any discrete event simulation model where the simulation state can be defined in a relatively compact manner. In such applications, the IDs are useful for describing the effects of simulation parameters and finding optimal simulation settings. Most importantly, the constructed IDs are valuable in explaining why a given decision alternative should be selected as they describe the consequences of the decision. Thus, the IDs can be used to better explain and rationalize the results of simulation based decision making.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The expected value of availability E(x(t)) and the conditional expected values of availability E(x(t)|z) for different numbers of personnel. The conditional expected value of availability E(x(t)|x(10) = 8) and the conditional expected values of availability E(x(t)|x(10) = 8, z) for different numbers of personnel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: The ID for the air combat example. Decision node d represents the tactic chosen by blue. The progress of the simulated air combat is modeled with chance nodes x(t). The simulation state x(t) depends only on the previous state and the decision taken by blue. The objective of the decision problem is described by utility node u.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>d = defensive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The probability distribution of the air combat state as a function of time for tactics d ∈ {aggressive, defensive}.The continuous lines depict the probabilities calculated from the simulation data. The circles and the dotted lines present the corresponding probabilities given by the ID.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>d = defensive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The probability distribution of the air combat state as a function of time for tactics d ∈ {aggressive, defensive} conditional on x(157) = neutral.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The probability distribution of the states of the utility node for each decision alternative.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">State of utility node u</cell><cell></cell></row><row><cell>Tactic, d</cell><cell cols="4">blue adv. red adv. mut. dis. neutral</cell></row><row><cell>aggressive</cell><cell>0.141</cell><cell>0.397</cell><cell>0.416</cell><cell>0.046</cell></row><row><cell>defensive</cell><cell>0.445</cell><cell>0.477</cell><cell>0.007</cell><cell>0.072</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR BIOGRAPHIES</head><p>JIRKA POROPUDAS received his M.Sc. degree in systems and operations research from the Helsinki University of Technology (HUT), <ref type="bibr">Espoo, Finland, in 2005</ref>. He is currently working on his doctoral thesis at the Systems Analysis Laboratory, HUT. His research interests include statistics, simulation, simulation metamodeling, and statistical analysis of basketball. His e-mail address is &lt;Jirka.Poropudas@tkk.fi&gt;. KAI VIRTANEN received the M.Sc. and Dr. Tech. degrees in systems and operations research from the Helsinki University of Technology (HUT), <ref type="bibr">Espoo, Finland, in 1996 and</ref><ref type="bibr">2005, respectively.</ref> He is currently Teaching Research Scientist at the Systems Analysis Laboratory, HUT. His research interests include optimization, decision and game theory with particular attention to aerospace applications as well as discrete-event simulation. His e-mail address is &lt;Kai.Virtanen@tkk.fi&gt;.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Hugin -a shell for building Bayesian belief universes for expert systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Olesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Simulation metamodels</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Barton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 Winter Simulation Conference</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Medeiros</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Watson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Carson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Manivannan</surname></persName>
		</editor>
		<meeting>the 1998 Winter Simulation Conference<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimization by simulation metamodelling methods</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Currie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Winter Simulation Conference</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Ingalls</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Rossetti</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Peters</surname></persName>
		</editor>
		<meeting>the 2004 Winter Simulation Conference<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="473" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Available via</title>
		<ptr target="&lt;http://genie.sis.pitt.edu/" />
	</analytic>
	<monogr>
		<title level="m">GeNIe (graphical network interface)</title>
		<imprint>
			<date type="published" when="2009-06-05">2009. June 5, 2009</date>
		</imprint>
		<respStmt>
			<orgName>Decision Systems Laboratory</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Influence diagrams with multiple objectives and tradeoff analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Diehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Haimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part A</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="293" to="304" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The simulation metamodel</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Simulation optimization: A review, new developments, and applications</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>April</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Winter Simulation Conference</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Kuhl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Steiger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Armstrong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Joines</surname></persName>
		</editor>
		<meeting>the 2005 Winter Simulation Conference<address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="83" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Principles and Applications of Decision Analysis</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</editor>
		<meeting><address><addrLine>Palo Alto, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Strategic Decision Group</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="719" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Influence diagrams. Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="127" to="143" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Decisions with multiple objectives: preferences and value tradeoffs</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D L</forename><surname>Nielsen ; R</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Raiffa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">2007. 1993</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY; Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
	<note>Bayesian networks and decision graphs</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Simulation modeling and analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Law</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>McGraw-Hill Science/Engineering/Math</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Fourth ed</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improving maintenance decision making in the Finnish air force through simulation</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Mattila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raivio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interfaces</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="201" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Communications Analytics Corporation 2002. The X-Brawler air combat simulator management summary</title>
		<imprint>
			<publisher>L-3 Communications Analytics Corporation</publisher>
			<pubPlace>Vienna, VA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning Bayesian networks</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Neapolitan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simulation optimization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ólafsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim ; E. Yücesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Snowdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Charnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Winter Simulation Conference</title>
		<meeting>the 2002 Winter Simulation Conference<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="79" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fusion, propagation, and structuring in belief networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="288" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analyzing air combat simulation results with dynamic Bayesian networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Poropudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Virtanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Winter Simulation Conference</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Henderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Biller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M.-H</forename><surname>Hsieh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Shortle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Barton</surname></persName>
		</editor>
		<meeting>the 2007 Winter Simulation Conference<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1370" to="1377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Simulation metamodeling through dynamic Bayesian networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Poropudas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Virtanen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Manuscript</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluating influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="871" to="882" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic inference and influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="589" to="604" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey of ranking, selection, and multiple comparison procedures for discrete-event simulation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Swisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Jacobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Winter Simulation Conference</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Farrington</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Nembhard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Sturrock</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Evans</surname></persName>
		</editor>
		<meeting>the 1999 Winter Simulation Conference<address><addrLine>Phoenix, AZ</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="492" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Decision theoretical approach to pilot simulation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raivio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Hämäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Aircraft</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="632" to="641" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Theory of games and economic behavior</title>
		<author>
			<persName><forename type="first">J</forename><surname>Von Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Morgenstern</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1944">1944</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
