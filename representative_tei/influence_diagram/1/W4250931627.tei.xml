<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SIMULATION METHOD FOR SOLVING HYBRID INFLUENCE DIAGRAMS IN DECISION MAKING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial &amp; Enterprise Systems Engineering</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Urbana</orgName>
								<address>
									<postCode>61801</postCode>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Enlu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial &amp; Enterprise Systems Engineering</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign Urbana</orgName>
								<address>
									<postCode>61801</postCode>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SIMULATION METHOD FOR SOLVING HYBRID INFLUENCE DIAGRAMS IN DECISION MAKING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Influence diagrams (IDs) are powerful tools for representing and solving complex decision making problems. This paper presents a simulation-based approach for solving decision making problems formulated by hybrid IDs, which involve both discrete and continuous decision and chance variables. In the proposed method, Monte-Carlo simulation is applied in both approximating the expected conditional utility and solving the optimal decision strategies. The forward Monte-Carlo method is presented for expectation calculation, and it does not require Bayesian inference as in the standard "roll-back" method. The cross-entropy method in optimization is introduced to solve the optimal strategies. The decision variables are treated as random variables, and the decision strategies are solved by recursively updating the probability density of the decision variables. Finally, we present the simulation results of a bidding problem as an illustration.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In decision making problems under uncertainty, the goal is to find an optimal alternative which maximizes the expected utility of the outcome. IDs <ref type="bibr" target="#b6">(Howard and Matheson 2005)</ref> are graphical representation of the decision problems. It describes the probability dependence among the chance variables, specifies the information for each of the decisions, and provides a computational framework for solving the best decision strategy. Hybrid IDs are IDs involving both discrete and continuous chance and decision variables. Solving the optimal decision of hybrid IDs not only includes the computation of the expectation of the utility associated with a mixed joint distribution of discrete and continuous random variables, but also includes the optimization problem on the continuous support. Both the computation of expected utility and the optimization problem may be intractable, especially when the probability model is complex, the expected utility as an objective function is complicated, and a sequence of decisions is included. In addition, in most of the decision making problems, the interested marginal probability and the conditional probability in the standard "roll-back" method for solving IDs are not given, and Bayesian inference is required. Bayesian inference increases the computation, and may also be intractable in the hybrid IDs. Therefore, we propose a simulation method to provide approximate optimal strategies of the decision problem.</p><p>In the review of literature, most of the past research considered discrete IDs which contain only discrete chance and decision variables, and provided exact solutions, such as <ref type="bibr" target="#b13">(Shachter 1986</ref><ref type="bibr" target="#b16">, Tatman and Shachter 1990</ref><ref type="bibr" target="#b7">, Jensen, Jensen, and Dittmer 1994</ref><ref type="bibr" target="#b17">, Zhang 1998</ref>). For the problems with continuous chance variables, some papers deal with the particular probability, the multivariate Gaussian, and solve the continuous IDs using exact methods, such as <ref type="bibr" target="#b13">(Shachter and</ref><ref type="bibr">Kenley 1989, Madsen and</ref><ref type="bibr" target="#b9">Jensen 2005)</ref>. Several papers studied approximation methods of solving IDs with continuous chance variables. Some papers use Gaussian mixtures to approximate arbitrary continuous probability <ref type="bibr" target="#b10">(Poland 1994)</ref>, or use mixtures of truncated exponential potentials to approximate probability density functions and utility functions <ref type="bibr" target="#b5">(Cobb and Shenoy 2008)</ref>. Some papers use discretization to provide the approximate solution, such as the moment methods for decision analysis <ref type="bibr" target="#b15">(Smith 1993)</ref>. The simulation method has also been studied. <ref type="bibr" target="#b8">(Jenzarli 1995)</ref> investigated the use of Gibbs sampling for solving IDs; <ref type="bibr" target="#b0">(Bielza, Muller, and Insua 1999)</ref> explored the approach of using Markov Chain Monte Carlo (MCMC) method to solve a single-stage decision problem by defining an artificial distribution of the product space of alternatives and chances; <ref type="bibr" target="#b4">(Charnes and Shenoy 2004)</ref> proposed a multi-stage method to decompose the problem of multiple decisions into many subproblems involving single decisions; <ref type="bibr" target="#b3">(Cano, Gomez, and Moral 2006)</ref> proposed a forward-backward Monte Carlo method to solve the decision with very large models. However, most of the papers considered the problems that only involve the continuous chance variables, and few of them studied the problems with both continuous chance and continuous decision variables. In addition, in these simulation methods, they need the "roll-back" procedure and the Bayesian inference to generate the samples.</p><p>In this paper, a method of solving IDs with a mixture of discrete and continuous chance and decision variables by Monte Carlo simulation is proposed. We use simulation to evaluate the conditional expected utility, and also solve the optimization problem by simulation-based method to get the approximate optimal decision on a continuous support. The proposed method is suitable for the problem with discrete information sets, which means that the information known before making each of the decisions belongs to a discrete set. In the proposed method, the continuous decision nodes are treated as random variables, which are independent to all of the chance variables and other decisions at first, and the ID becomes a Bayesian network with a mixture of discrete and continuous nodes. By doing so, the simulation method to generate random variables in Bayesian network could be used to generate samples of the decision problem. We then classify these samples based on different associated information, and calculate the estimated expected utility of each category. To solve for the optimal decision strategies, we use the simulation-based optimization method. In particular, we use the cross-entropy method <ref type="bibr" target="#b2">(Boer et al. 2005</ref><ref type="bibr" target="#b11">, Rubinstein 1999</ref>). In the proposed method, we only need the samples of the chance and decisions variables with specified joint probability distribution. Thus, we do not need to calculate the Bayesian inference, which reduces the computation, and is useful especially for problems where the Bayesian inference is intractable. Using cross-entropy method to solve the optimization allows us to deal with problems with complex expected utility functions on continuous domain.</p><p>The organization of the paper is as follows. In section 2, the ID representation of decision making problem is presented, and an example of an asymmetric decision problem involving Bayesian inference, a bidding problem, is described. In section 3, the simulation-based method for solving IDs is proposed. We first present the forward Monte-Carlo method for calculating the expected utility, and then present the cross-entropy method for solving the optimal strategies. In section 4, the simulation results of the bidding example are provided, and we discuss the comparison of the results by different smoothing update approaches in cross-entropy method. Finally, we provide concluding remarks and indicate some directions for future research in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">INFLUENCE DIAGRAM REPRESENTATION OF BIDDING PROBLEM</head><p>To illustrate the proposed method, we consider a bidding problem as an example. This problem contains sequential decisions, and both discrete and continuous chance variables and decision variables. The ID of this decision making problem is a hybrid ID, which is usually hard to solve using the exact "roll-back" method. Moreover, this problem involves Bayesian inference of probabilities when solving for the best strategies. With the hybrid structure, the Bayesian inference is usually intractable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Statement</head><p>A company needs to decide how much to bid on the ownership of the patent of a new product. The profit of producing the new product is uncertain. The bid in this example is blind bid, in which the bidders do not know other bidders' bidding amount, and the highest bidder gets the patent immediately. That is, the company will get the patent if the value of its bidding amount is larger than or equal to the maximal competitive bid (MCB). To get a better bidding strategy, the company also has the option to pay some money to get the results of a survey, which provides the range of the MCB. But the range of MCB provided by the survey is imperfect.</p><p>Let P denote the profit of producing the new product in thousand dollar. P is a continuous random variable with truncated normal distribution N(80, 15 2 ) in the support <ref type="bibr">[-20, 100]</ref>. The instantiation of the profit is denoted by the lowercase p. The maximal competitive bid (MCB) in thousand dollar, denoted as B, given the profit of producing the product p, is a beta distribution in the support B ∈ <ref type="bibr">[-20, p]</ref>. Given the profit p, the random variable B+20 p+20 , which is normalized between 0 and 1, is according to beta distribution Beta(10, 3). The company also has an option to pay c = 2.2 thousand dollar to get the result of the survey. The decision of whether to do the survey is denoted as S. Let S = 1 denote doing the survey, and S = 0 denote not doing the survey. The result of the survey is denoted as SR, and it provides the imperfect information about the range of the MCB. If SR = low or 1, it implies that the maximal competitive bid lies in <ref type="bibr">[-20, 40]</ref>; if SR = mediun or 2, it implies that the maximal competitive bid is in <ref type="bibr">[40,</ref><ref type="bibr">70]</ref>; if SR = high or 3, it implies that the maximal competitive bid lies in <ref type="bibr">[70,</ref><ref type="bibr">100]</ref>. However, the result of the survey is imperfect.</p><formula xml:id="formula_0">SR = 1 w.p. 1 , if B ∈ [-20, 30] SR = 1 w.p. 0.5 2 w.p. 0.5 , if B ∈ (30, 50] SR = 2 w.p. 0.5 3 w.p. 0.5 , if B ∈ (50, 80] SR = 3 w.p. 1 , if B ∈ [80, 100]</formula><p>The decision of how much to bid is denoted as X, and the lowercase x denotes an instantiation of the bidding amount. The goal is to solve for the optimal decision whether to do the survey or not, and the optimal bidding amount, which is denoted as x * , based on different information or survey results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Influence Diagram Representation of Decision Problems</head><p>An influence diagram (ID) <ref type="bibr" target="#b6">(Howard and Matheson 2005)</ref> is an acyclic graphical representation of the decision problems. An ID consists of directed arrows and three types of nodes: decision nodes, chance nodes, and value nodes. Decision node is denoted as a square, and represents the decision variables and set of alternatives available to the decision maker; chance node is denoted as a circle, and represents the uncertain events in the decision situation; value node is denoted as a diamond, and represents the value function or the utility function associated with the decisions and instantiations of the chance variables. There is zero or more decision and chance nodes, and at most one value node, which represents the objective or utility to be maximized in expectation. The arrows from chance nodes to chance nodes represent the probability dependence of the random variables; the arrows from chance or decision nodes to decision nodes represent the information known before making the decision; the arrows from decision nodes to chance nodes represent the decisions impact on chance; the arrows from chance and decision nodes to value node represent the arguments of the value or utility function.</p><p>The ID of the above bidding problem is shown in figure <ref type="figure" target="#fig_0">1</ref>. As we may see from the diagram, there are </p><formula xml:id="formula_1">U(p, x, b, S) = (p -x)I {x≥b} -cI {S=1} (1)</formula><p>The decision maker will get the patent if and only if his or her bidding amount is larger than or equal to the MCB. We introduce an artificial state SR = 0, which indicates no survey result and S = 0. The objective function to be maximized is the expected payoff given the survey results. The optimal decision strategy is</p><formula xml:id="formula_2">(x * , S * ) = arg max x,S E P,B [U(P, B, X, S)|SR] (2)</formula><p>where U(P, B, X, S) is represented in (1).</p><p>When solving the ID, the standard method is the "roll-back" method <ref type="bibr">(Shachter 1986, Bielza and</ref><ref type="bibr" target="#b1">Shenoy 1999)</ref>. That is to solve the ID by removing nodes in the backward sequence of the information flow. The node reduction order of this bidding problem is shown in Fig. <ref type="figure" target="#fig_1">2</ref>. The chance node is removed by calculating the 3. Remove the decision node X. The value is replaced by</p><formula xml:id="formula_3">v SR (sr, s) = max x v X (x, SR = sr, S = s)</formula><p>The optimal bidding amount is x * = arg max x v X (x, SR = sr, S = s). 4. Remove the chance node SR. The value is replaced by</p><formula xml:id="formula_4">v S (s) = E SR [v SR (SR, S)|S = s]</formula><p>5. At last, remove the decision node S. The value is replaced by</p><formula xml:id="formula_5">v = max s v S (s)</formula><p>The optimal decision of whether to do the survey is s * = arg max s v S (s).</p><p>By the standard "roll-back" method to solve IDs, the Bayesian inference to calculate the reversed conditional probability according to the information flow is required, since we only know the conditional or marginal probability given in the ID. Specifically, for solving the above bidding problem, the conditional probability p(p|b, sr) and p(b|sr) are needed in the "roll-back" procedure, but the ID only provides the conditional probability p(b|p) and p(sr|b, p). With the probability densities given in this problem, the reversed conditional probability is intractable to solve. Using Bayesian inference to solve the reversed conditional probability is required in both the exact methods and the simulation methods in literature. In the problems with a mixed joint distribution of continuous and discrete chance variables and with non-Gaussian distributed chance variables, the exact method to solve the Bayesian inference is usually intractable. The optimal decision strategies could also be hard to solve if the expected conditional utility as an objective to maximize is complicated, especially for the problems with multiple local maxima.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SIMULATION METHOD IN SOLVING INFLUENCE DIAGRAMS</head><p>Because of the limitation of the exact method and the previously proposed simulation method to solve IDs, we present a new simulation method to solve IDs in this section, and simulation is used in both calculating the expectation and solving the optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simulation Method in Solving Expectation</head><p>Monte-Carlo simulation method is an important method to approximate the expectation. In this section, we consider the simulation method in calculating the conditional expected utility when solving IDs.</p><p>The probability model in influence diagram provides the order of factorization of the joint probability in terms of the marginal and conditional probability according to the Bayes's rule. If we change the decision node to a probability node, and delete the value node, the ID in Fig. <ref type="figure" target="#fig_0">1</ref> becomes the Bayesian network shown in Fig. <ref type="figure" target="#fig_2">3</ref>. Thus, we may use the simulation method in Bayesian network to solve IDs. In the previous "roll-back" method, the conditional probabilities given the observation are required, and we need to calculate the Bayesian inference in most of the decision making problems. However, the Bayesian inference may be intractable using the exact method. In order to avoid calculating the Bayesian inference, we use forward Monte-Carlo simulation method to generate the samples of the chance variables with given joint probability function. In this method, we do not solve the ID by reducing decision and chance nodes in the reverse order of the sequence determined by the information flow. However, we consider the joint probability and the whole domain of the variables of the decision problem, and only calculate the expected utility given the observation before each of the decisions.</p><p>For the bidding problem, we generate N independent sample sets </p><formula xml:id="formula_6">(P k , B k , SR k ) (k = 1, • • • , N) in</formula><formula xml:id="formula_7">E a [U(P, B, X, S)|SR = i] = 1 N i N k=1 (p k -x)I {x&gt;b k } -cI {S=1} I {SR k =i}<label>(3)</label></formula><p>where i = 0, 1, 2, 3 and</p><formula xml:id="formula_8">N i = k I {SR k =i} .</formula><p>In general, the steps of the forward Monte-Carlo method are listed as below:</p><p>1. Consider the decision variables as chance variables with specified distribution. 2. Generate independent sample sets with the joint probability distribution specified in the ID in the same order defined in the ID according to forward Monte-Carlo method. 3. Classify the samples based on different information or observation of each of the decision scenarios. 4. Calculate the approximate conditional expected utility given different scenarios.</p><p>By the forward Monte-Carlo method, we generate samples over the overall joint space of the utility function, and do not calculate the expected utility locally as in the "roll-back" method. Our proposed method reduce the calculation especially in the problem that needs Bayesian inference when using standard "roll-back" method. Note that this method can only be used in the problems with discrete observations and with small number of instantiations of observation, since we need to classify the samples based on different scenarios and treat the problem globally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Simulation Method in Solving Optimization</head><p>In this section, we present the simulation-based optimization method in solving decision making problems, where the conditional utility as objective function is complicated, and the optimal solution to maximize the expected utility is hard to solve by the exact method. We choose cross-entropy (CE) method <ref type="bibr" target="#b2">(Boer, Kroese, Mannor, and Rubinstein 2005</ref><ref type="bibr" target="#b11">, Rubinstein 1999</ref><ref type="bibr" target="#b12">, Rubinstein and Kroese 2004)</ref>, which is a Monte Carlo approach to optimization, and returns a near optimal solution.</p><p>The cross-entropy method is originated from rare event simulation and importance sampling. In the decision making problems, the decision variables are considered as random variables with specified parameterized family probability distribution. Then, we use the rate event simulation technique to update the probability density for simulation, such that there will be more samples generated around the maxima of the objective function. The probability density function updates iteratively, and for each iteration, there involves two stages as shown in Fig. <ref type="figure" target="#fig_4">4</ref>. Let the objective function we want to maximize be</p><formula xml:id="formula_9">x * = arg max x EU(x)</formula><p>We first generate random samples x 1 , x 2 , • • • , x M according to the specified probability density function f (x, v), where v is the parameter we need to update. The random variable x is usually chosen to be an exponential family for the continuous optimization, such that the solution of the minimal cross-entropy has an analytical solution. It could also be used in discrete problems with updating the specified probability mass function (pmf). Then, we update the parameter v of the probability density function based on the value of EU(x), such that we will generate better samples in the next iteration.</p><p>For the bidding problem in section 2, the decision variable of how much to bid, X, is a continuous decision variable, and is treated as a random variable according to the Gaussian distribution N(m, s 2 ), when using cross-entropy method to solve optimization. The variance s 2 is large at the first step, and the variable X is approximately uniformly distributed, since we have no information about which decision value is better at the beginning. Based on the value of expected utility, we update the parameter m and s of the Gaussian distribution, and the samples become more and more concentrated on the maxima of the objective function, as the number of iteration increases. We stop until the variance become small enough, and the probability becomes a near Dirac delta function.</p><p>In some of the cases, the standard cross-entropy method presented above has the "freezing" problem, which means that the probability density will converge to a Dirac delta function very fast, and the iteration may stop at a local optimum instead of a global optimum. In order to improve the performance of the CE method, some smooth updating procedures have been proposed. One method is to use smoothing parameter <ref type="bibr" target="#b2">(Boer, Kroese, Mannor, and Rubinstein 2005)</ref>. Instead of updating the parameter vt-1 to vt directly, we may introduce a smooth parameter q , and the updated parameter of the probability density function is vt = q ṽt + (1 -q ) vt-1 where q ∈ [0, 1]. Thus, the parameter vt will not converge to fast. However, by introducing the smooth parameter, there will be a tradeoff between the accuracy and the computing speed. Sometimes, it still does not solve the "freezing" problem well.</p><p>To provide a better solution as well as reduce computation time, we could also add an artificial noise to the samples and disturb the samples, such that it will not converge too fast <ref type="bibr" target="#b18">(Zhou, Fu, and Marcus 2010)</ref>. The artificial noise is large at the beginning, and gradually becomes smaller as it converges to the true optima. Thus, instead of using the samples x k generated from the probability density function f (x, vt ), we disturb the sample by a noise, and use</p><formula xml:id="formula_10">x a k = x k + w k , k = 1, 2, • • • , M where w k = ab k-1 w, b ∈ (0, 1)</formula><p>w is the noise, and is usually chosen to be the standard Gaussian noise N(0, I), a is the initial standard deviation of the noise, and b is the coefficient of the noise reduction rate. This method is called noisy CE method, and is denoted as NCE. By introducing the artificial noise, the number of iterations needed may reduce, and it may return better solution especially in the problem with multiple local optima, since by adding the noise, the solution is not easily trapped in local optima.</p><p>We may also use an adaptive smoothing parameter to provide better solution with less iterations, and we denote the adaptive smoothing CE method by ACE. It is a variation of the adaptive smoothing in <ref type="bibr" target="#b12">(Rubinstein and Kroese 2004)</ref> with different adaptive smoothing parameter. Instead of using the constant smoothing parameter q , we change the parameter every iteration, and the adaptive parameter is denoted by q t . At first, q t is chosen to be near 1, and the probability parameter vt changes fast; as iteration increases, the smoothing parameter q t becomes smaller, such that it may return more accurate solution. The parameter vt is updated by vt = q t ṽt + (1 -q t ) vt-1 where q t = q + (t + 1) -a q is chosen to be a small number such as 0.1 or 0.2, and a ∈ [0, 1]. As the iteration number t goes to infinite, the smoothing parameter q t converges to q ; at the beginning, the smoothing parameter q t is near 1. The rate of the change of q t may be adjusted by the value of the parameter a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SIMULATION RESULTS</head><p>To illustrate the effectiveness of the proposed simulation method, we provide the simulation results of the bidding problem in section 2. The decision maker needs to make the decision how much to bid and whether to do the survey to get information about the MCB before bidding. But the survey gives imperfect information about the MCB. The uncertainty involved in the problem is the profit of the bidding item P, the MCB B, and the survey results SR.</p><p>The ID of this bidding problem is given in Fig. <ref type="figure" target="#fig_0">1</ref>. The conditional probabilities associated with the ID are given in section 2. The profit P is with truncated normal distribution N(80, 15 2 ) in the support <ref type="bibr">[-20, 100]</ref>; the maximal competitive bid B given P is beta distributed with a = 10 and b = 3, that is B+20 p+20 ∼ Beta(10, 3). The cost of the survey is c = 2.2, and the survey gives imperfect information. If the real maximal competitive bid B is in <ref type="bibr">[-20, 30]</ref>, SR is equal to 1 with probability 1; if B is in (30, 50), SR is equal to 1 or 2 with probability 0.5; if B lies in <ref type="bibr">[50,</ref><ref type="bibr">80]</ref>, SR is equally likely to be equal to 2 or 3; if B lies in (80, 100], SR is equal to 3 for sure.</p><p>We use the proposed simulation method to solve this decision problem, and choose the sample size N for approximating the expected utility to be 10 4 , and the sample size M for calculating the optimal decision strategies to be 300. We use the CE method with fixed smooth parameter q , the noisy CE method (NCE), and the adaptive smoothing CE method (ACE) to calculate the optimal bidding amount, and compares the results in table 1. In the CE method the smoothing parameter is chosen to be q = 0.8 and q = 0.3. In NCE, the artificial noise is chosen to be the standard Gaussian noise N(0, I n×n ), and the parameter a = 2 and b = 0.98. In ACE, q is chosen to be 0.1 and a is 0.4. From the table, we may see that the CE method with smoothing parameter q = 0.3, the NCE and ACE gives better optimal solution compared with the CE method with q = 0.8. However, the CE method with q = 0.3 needs more iterations, and NCE and ACE method need less iterations. The adaptive smoothing parameter CE method needs almost the same number of iterations as the CE method with q = 0.8, but the ACE method has better solution. We also did the simulation by changing the number of sample size M in calculating the optimization, and observe the average performance of the standard CE, NCE and ACE. The results are shown in Fig. <ref type="figure" target="#fig_5">5</ref>. The black curve is the average maximal expected utility by CE method with smoothing parameter q = 0.3, the blue curve is for CE with q = 0.8, the red curve is for adaptive smoothing CE (ACE), and the green curve is for noisy CE (NCE). In this particular bidding problem, the performance of ACE and NCE is better than the CE with smoothing parameter q = 0.8, but they needs less iterations compared with the CE with q = 0.3. Note that the presented bidding problem is only a simple example with commonly used distribution. In the problems that the objective function to maximize has multiple local optima, the NCE and ACE method may have much better performance than the standard CE.</p><p>engineering from Zhejiang University, China, in 2004, and received the Ph.D. degree in electrical engineering from the University of Maryland, College Park, in 2009. Her research interests include stochastic control, nonlinear filtering, and simulation optimization. Her email address is &lt;enluzhou@illinois.edu&gt;.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Influence diagram of the bidding problem</figDesc><graphic coords="3,190.13,435.71,234.01,150.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Nodes reduction order of the bidding problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Probability model of bidding problem</figDesc><graphic coords="5,179.70,323.68,254.87,111.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>the same order as in the ID, P → B → SR. Thus, we only need the conditional probability density function f (p), f (b|p), and f (sr|b), which are given in the ID. Then the samples (P, B, SR) are empirically distributed with the joint probability defined in the ID. Having the samples with desired joint distribution, we classify these samples based on the different scenarios. In the bidding problem, there are four different scenarios: bid without survey, bid given the survey result indicates low MCB, medium MCB, and high MCB. The expected conditional utility given different observations can be approximate by the summation. That is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Two stages of cross-entropy method</figDesc><graphic coords="6,179.63,384.79,255.00,78.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparison of the smooth updating approaches in cross-entropy method</figDesc><graphic coords="8,179.36,366.28,255.55,191.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Optimal decision strategies of bidding Problems CE (q = 0.8) CE (q = 0.3)</figDesc><table><row><cell>NCE</cell><cell>ACE</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we proposed a simulation method to solve IDs in complex decision making problems. We consider the decision problems with a hybrid of continuous and discrete chance and decision variables. The proposed method uses simulation in both calculating the expectation and optimization involved in solving IDs. We use forward Monte-Carlo method to approximate the conditional expectation, and avoid to solve Bayesian inference, which is intractable in most hybrid IDs. For solving optimization, we use cross-entropy method, which returns near optimal global solutions. The proposed method applies in most hybrid decision making problems with discrete information sets. As an illustration, we incorporate the proposed method in the bidding problem, and discuss the comparison of smooth updating approaches in cross-entropy method.</p><p>Our current and future research directions of interest include solving more sophisticated decision making problems such as bidding problems with sequential bidding decisions and the updated information of the maximal competitive bid, and solving the problem with different simulation-based optimization. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Decision analysis by augmented probability simulation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bielza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Insua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="995" to="1007" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comparison of graphical techniques for asymmetric decision problems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bielza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1552" to="1569" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A tutorial on the cross-entropy method</title>
		<author>
			<persName><forename type="first">P</forename><surname>Boer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kroese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mannor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Operations Research</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="67" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A forward-backward monte carlo method for solving influence diagrams</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="119" to="135" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multistage monte carlo method for solving influence diagrams using local computation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Charnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="405" to="418" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Decision making with hybrid influence diagrams using mixtures of truncated exponentials</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Cobb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="261" to="275" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Influence diagrams. Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="127" to="143" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">From influence diagrams to junction trees</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dittmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 10th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="367" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Modeling dependence in project management</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jenzarli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Lawrence, KS</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Kansas Business School</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Solving linear-quadratic conditional gaussian influence diagrams</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="263" to="282" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Decision analysis with continuous and discrete variables: A mixture distribution approach</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Poland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<pubPlace>Stanford, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University, Department of Engineering-Economic Systems</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The cross-entropy method for combinatorial and continuous optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methodology and Computing in Applied Probability</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="127" to="190" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The cross-entropy method: A unified approach to combinatorial optimization, monte-carlo simulation, and machine learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kroese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evaluating influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="871" to="882" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Gaussian influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Kenley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="527" to="550" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Moment methods for decision analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="340" to="358" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic programming and influence diagrams</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tatman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="365" to="379" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic inference in influence diagrams</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 14th Annual Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="514" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A particle filtering framework for randomized optimization algorithms: EDAS, CE, MRAS, and more</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marcus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>under revision</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
