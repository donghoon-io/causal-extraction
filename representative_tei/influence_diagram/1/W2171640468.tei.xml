<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Explanation of Bayesian networks and influence diagrams in Elvira</title>
				<funder ref="#_UpPcbDh">
					<orgName type="full">Department of Education of the Comunidad de Madrid</orgName>
				</funder>
				<funder>
					<orgName type="full">European Social Fund</orgName>
					<orgName type="abbreviated">ESF</orgName>
				</funder>
				<funder ref="#_EDppbBy">
					<orgName type="full">Spanish CICYT</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Carmen</forename><surname>Lacave</surname></persName>
							<email>carmen.lacave@uclm.es</email>
						</author>
						<author>
							<persName><forename type="first">Manuel</forename><surname>Luque</surname></persName>
							<email>mluque@bec.uned.es</email>
						</author>
						<author>
							<persName><forename type="first">Francisco</forename><forename type="middle">Javier</forename><surname>Díez</surname></persName>
							<email>fjdiez@dia.uned.es</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dept. Technology and Information Sys- tems</orgName>
								<orgName type="institution">University of Castilla</orgName>
								<address>
									<addrLine>La Mancha Ciudad Real</addrLine>
									<postCode>13071</postCode>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. Artificial Intelligence</orgName>
								<orgName type="institution">UNED</orgName>
								<address>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Explanation of Bayesian networks and influence diagrams in Elvira</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">received July 1, 2006; revised ...</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T18:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian networks</term>
					<term>influence diagrams</term>
					<term>expert systems</term>
					<term>explanation</term>
					<term>Elvira</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bayesian networks and influence diagrams are probabilistic graphical models widely used for building diagnosisand decision-support expert systems. Explanation of both the model and the reasoning is important for debugging these models, for alleviating users' reluctance to accept their advice, and for using them as tutoring systems. This paper describes some explanation options for Bayesian networks and influence diagrams that have been implemented in Elvira and how they have been used for building medical models and for teaching probabilistic reasoning to pre-and post-graduate students.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Bayesian networks (BNs) and influence diagrams (IDs) are two types of probabilistic graphical models widely used for building expert systems in several application domains. Both of them consist of acyclic directed graphs and probability distributions <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. The main difference among them is that BNs only contain chance nodes, each representing a random variable, while IDs also contain decision nodes, which represent the options available to one or several decision makers, and utility nodes, which represent the decision makers' preferences. As a consequence, BNs can only be used in diagnostic problems, while IDs can be used as decisionsupport tools.</p><p>In the context of expert systems, either probabilistic or heuristic, the development of explanation facilities is important for three main reasons <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. First, because the construction of those systems with the help of human experts is a difficult and time-consuming task, prone to errors and omissions. An explanation tool can help the experts and the knowledge engineers taking part in the project to debug the system when it does not yield the expected results and even before a malfunction occurs. Second, because human beings are reluctant to accept the advice offered by a machine if they are not able to understand how the system arrived at those recommendations; this reluctancy is especially clear in medicine <ref type="bibr" target="#b5">[6]</ref>. And third, because an expert system used as an intelligent tutor must be able to communicate the apprentice the knowledge it contains, the way in which the knowledge has been applied for arriving at a conclusion, and what would have happened if the user had introduced different pieces of evidence (what-if reasoning).</p><p>These reasons are especially relevant in the case of probabilistic expert systems, because the elicitation of probabilities is more difficult than the assessment of uncertainty in heuristic expert systems and because, even though probabilistic reasoning is just a formalization of (a part of) common-sense reasoning, the algorithms for the computation of probabilities and utilities are very different from the way a human being would draw conclusions from a probabilistic model.</p><p>Unfortunately, the explanation methods proposed so far are still unsatisfactory, as shown by the fact that most expert systems and commercial tools available today, either heuristic or probabilistic, have virtually no explanation capability <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>. Despite the practical interest of this issue, very little research is currently carried out about explanation in probabilistic graphical models. As an attempt to palliate this shortcoming, in this paper we describe some methods for explaining both the model and the reasoning of probabilistic expert systems, which have been implemented in Elvira, a public software tool developed as a joint project of several Spanish universities. We also discuss how such methods respond to the needs that we have detected when building and debugging medical expert systems <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> and when teaching probabilistic graphical models to pre-and postgraduate students of computer science and medicine <ref type="bibr" target="#b10">[11]</ref>.</p><p>The rest of this paper is structured as follows: After reviewing the main features of explanation in expert systems in Section I-A and describing the Elvira software in Section I-B, we present the fundamentals of BNs and IDs in Sections II-A and II-B, respectively. Section III presents the facilities provided by Elvira for explaining both the model (Sec. III-A) and the reasoning (Sec. III-B) in BNs. Section IV analyzes how these facilities have been adapted for IDs in order to explain both the model (Sec. IV-A) and the results of inference (Sec. IV-B), to permit the introduction of evidence (Sec. IV-D), and to perform what-if reasoning with suboptimal policies (Sec. IV-E). The application of standard techniques, such as decision trees and sensitivity analysis, to explanation in IDs is discussed in Sections IV-C and IV-F, respectively. Section V analyzes related work and possible lines for future research, and Section VI presents the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Features of explanation in expert systems</head><p>Explanation methods are characterized by several properties, corresponding to the main concepts on which an explanation is based <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref>: content, communication and adaptation. The content of an explanation deals with either the model, the reasoning, or the available evidence. Explanation of the model, also known as static explanation <ref type="bibr" target="#b11">[12]</ref>, consists in showing the information represented by the knowledge base of the expert system in a way that it can be easily understood by the user. Explanation of the reasoning, or dynamic explanation, describes how and why the system has obtained certain results. Explanation of evidence usually consists in finding the most probable configuration that justify the evidence <ref type="bibr" target="#b0">[1]</ref>, which is also known as abduction. Dynamic explanations can be generated at the micro or the macro level <ref type="bibr" target="#b12">[13]</ref>: micro-level explanations try to justify why the probability of a certain variable has varied, why the belief on a certain hypothesis has changed, or why a rule has fired as a consequence of the variations in its neighbor variables or rules; on the contrary, macro-level explanations analyze the main lines of reasoning (the paths in the Bayesian network, the chains of rules, etc.) that led from the evidence to a certain conclusion.</p><p>The second main aspect of explanation, namely communication, is related to the way of interacting with the user and the way of presenting the explanations, either textually or graphically or by a combination of both.</p><p>Finally, adaptation refers to the ability to modify the explanations and the interaction depending on the user's expertise and needs. See <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref> for a more detailed analysis of these features and for a detailed review of the most relevant methods and systems offering some kind for explanation, both for Bayesian networks <ref type="bibr" target="#b3">[4]</ref> and for heuristic expert systems <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Elvira</head><p>Elvira 1 is a tool for building and evaluating graphical probabilistic models <ref type="bibr" target="#b13">[14]</ref>. It resulted from a joint research project of several Spanish universities. It is implemented in Java, so that it can run on different platforms. It contains a graphical interface for editing networks, with specific options for canonical models (e.g., OR, AND, MAX...), exact and approximate algorithms for discrete and continuous variables, explanation facilities, learning methods for building networks from databases, algorithms for fusing networks, etc. Although some of the algorithms work with both discrete and continuous variables, the explanation capabilities assume that all the variables are discrete.</p><p>a) Architecture of Elvira: Elvira is structured in four main modules:</p><p>• Data representation, which contains the definition of the data structures needed for managing BNs and IDs in Java. • Data acquisition, including the classes necessary for saving and loading a network both from a file and from a data base, the parser, etc. It also contains classes for exporting and importing the networks in several formats. • Processing. This module implements the algorithms for processing and evaluating the models. It is organized in several submodules, one for each task: inference, learning, fusion, decision trees, sensitivity analysis... 1 At <ref type="url" target="http://www.ia.uned.es/">http://www.ia.uned.es/</ref> ˜elvira it is possible to obtain the source code and several technical documents about Elvira.</p><p>• Visualization, which mainly defines the Elvira GUI and, obviously, makes use of the classes included in the previous modules. This module contains the classes for generating explanations and for the internationalization of the whole program, i.e., for displaying the interface in different languages. Currently, only Spanish and English are supported, but other languages can be easily added. The main advantages of this modular design is that each group involved in the project can focus on a different task and that the program can be easily extended with new functionalities or adapted to different needs.</p><p>b) Working with the Elvira GUI: In addition to invoking Elvira's classes from the command line and using it as an API, it is possible to interact with Elvira by means of its GUI, which has two working modes:</p><p>• edit, for graphically editing BNs and IDs. This is possible by means of several windows which help the user to build or to modify the model manually, by requesting all the data associated to the nodes, the arcs and the properties of the whole BN or ID. Alternatively, BNs can be built from data bases by applying some of the many learning algorithms implemented in Elvira; and • inference, for propagating evidence and explaining the results. The introduction of evidence can be done by clicking on the node, as in other software tools, or by means of an editor of cases <ref type="bibr" target="#b14">[15]</ref>, which provides a list of the variables in the model. With respect to the inference process, the user can choose one of several algorithms, with many variations, and in the case of a BN, they can select either evidence propagation or abduction <ref type="foot" target="#foot_0">2</ref> and whether the evidence is propagated automatically (i.e., just after the user introduces or removes a finding) or manually (by demand). Most of the explanation capabilities provided by Elvira (see below) are offered in the inference mode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MATHEMATICAL FOUNDATIONS</head><p>Before giving the definition of Bayesian network (BN) and influence diagram (ID), we establish some notational conventions.</p><p>Notation: Given that each node in a probabilistic graphical model represents a variable, in this paper we will use both terms indifferently. We will use a capital letter V to represent a variable, and its corresponding lower case letter v for representing a generic value. Sets of variables will be represented by bold capital letters V, and a bold lower case letter v will represent a configuration of values of V. In the context of directed graphs, P a(V ) represents the set of parents of node V , and pa(V ) a configuration of the variables in P a(V ).</p><p>Definitions: A finding f is a piece of information that states with certainty the value taken on by a chance variable. A finding may be, for example, the fact that the patient is a male; other findings might be that he is 54 years old, he has fever, he does not usually have headaches, etc. The set of findings is called evidence and corresponds to a certain configuration e of the observed variables E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Bayesian networks</head><p>A BN consists of an acyclic directed graph (ADG), whose nodes represent a set V C of chance variables, where C stands for "chance", and whose links represent -roughly speaking-probabilistic dependencies among them, together with a probability distribution over its variables that satisfies the d-separation property <ref type="bibr" target="#b0">[1]</ref>. This property implies that the joint probability distribution can be factored as the product of the probability of each node conditioned on its parents.</p><formula xml:id="formula_0">P (v C ) = V ∈V C P (v|pa(V ))<label>(1)</label></formula><p>As a consequence, the quantitative information of a Bayesian network can be given by assigning to each chance node C a probability distribution P (c|pa(C)) for each configuration of its parents, pa(C). Both the graph and the probabilities of a BN can be obtained automatically, from data bases, or manually, from human experts' knowledge and the literature for the domain to be modeled. In this case, the elicitation of probabilities constitutes a very difficult task, usually referred to as a bottleneck in the development of BNs <ref type="bibr" target="#b15">[16]</ref>. Probabilistic reasoning in BNs usually consists in computing the posterior probability of some variables of interest V I ⊆ V C \ E given the available evidence, P (v I |e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Influence Diagrams</head><p>1) Definition of an ID: An influence diagram (ID) contains three kinds of nodes: chance nodes V C , decision nodes V D , and utility nodes V U -see Fig. <ref type="figure" target="#fig_0">1</ref>. Chance nodes represent events not controlled by the decision maker. Decision nodes correspond to actions under the direct control of the decision maker. Utility nodes represent the decision maker's preferences. Utility nodes can not be parents of chance or decision nodes.</p><p>In the extended framework proposed by Tatman and Shachter <ref type="bibr" target="#b16">[17]</ref> there are two kinds of utility nodes: ordinary utility nodes, whose parents are decision and/or chance nodes (such as U 1 and U 2 in Fig. <ref type="figure" target="#fig_0">1</ref>), and super-value nodes, whose parents are utility nodes (U 0 in Fig. <ref type="figure" target="#fig_0">1</ref> is a super-value node). We assume that there is a utility node that is either the only utility node or a descendant of all the other utility nodes, and therefore has no children; we denote it by U 0 . <ref type="foot" target="#foot_1">3</ref>There are three kinds of arcs in an ID, depending on the type of node they go into. Arcs into chance nodes represent probabilistic dependency. Arcs into decision nodes represent availability of information, i.e., an arc Y → D means that the state of Y is known when making decision D. Arcs into utility nodes represent functional dependence: for ordinary utility nodes, they represent the domain of the associated utility function; for a super-value node they indicate that the associated utility is a function (usually the sum or the product) of the utility functions of its parents.</p><p>Standard IDs require that there is a directed path that includes all the decision nodes and indicates the order in which the decisions are made. This in turn induces a partition of V C such that for an ID having n decisions {D 0 , . . . , D n-1 }, the partition contains n+1 subsets {C 0 , C 1 , ..., C n }, where C i is the set of chance variables C such that there is a link C → D i and no link C → D j with j &lt; i; i.e., C i represents the set of chance variables known for D i and unknown for previous decisions. C n is the set of variables having no link to any decision, i.e., the variables whose true value is never known directly. In our example (Fig. <ref type="figure" target="#fig_0">1</ref>),</p><formula xml:id="formula_1">D 0 = T , D 1 = D, C 0 = ∅, C 1 = {Y }, and C 2 = {X}.</formula><p>The variables known to the decision maker when deciding on D i are called informational predecessors of D i and denoted by IPred(D i ). Standard IDs assume the no-forgetting hypothesis, which means that the decision maker remembers all previous observations and decisions. By assuming such property we have</p><formula xml:id="formula_2">IPred(D i ) = IPred(D i-1 ) ∪ {D i-1 } ∪ C i (2) = C 0 ∪ {D 0 } ∪ C 1 ∪ . . . ∪ {D i-1 } ∪ C i . (3)</formula><p>An arc V → D, where D is a decision and V is either a decision or a chance node, is said to be non-forgetting is there is another directed path from V to D. In standard IDs nonforgetting arcs are irrelevant: they can be added or removed without changing the semantics of the ID.</p><p>The quantitative information that defines an ID is given by assigning to each chance node C a probability distribution P (c|pa(C)) for each configuration of its parents (as in the case of BNs), assigning to each ordinary utility node U a function ψ U (pa(U )) that maps each configuration of its parents onto a real number, and assigning a utility-combination function to each super-value node. The domain of each function U is given by its functional predecessors, FPred(U ). For an ordinary utility node, FPred(U ) = P a(U ), and for a supervalue node FPred(U ) = U ∈P a(U ) FPred(U ). In the above example, FPred(U 1 ) = {X, D}, FPred(U 2 ) = {T }, and FPred(U 0 ) = {X, D, T }. In order to simplify the notation, we assume without loss of generality that FPred(U 0 ) = V C ∪V D .</p><p>For each configuration v D of the decision variables V D we have a joint distribution over the set of chance variables V C :</p><formula xml:id="formula_3">P (v C : v D ) = C∈V C P (c|pa(C))<label>(4)</label></formula><p>which represents the probability of configuration v C when the decision variables are externally set to the values given by v D <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Policies and expected utilities:</head><p>A stochastic policy for a decision D is a probability distribution defined over D and conditioned on the set of its informational predecessors, P D (d|iPred(D)). If P D is degenerate (consisting of ones and zeros only) then we say that the policy is deterministic.</p><p>A strategy ∆ for an ID is a set of policies, one for each decision,</p><formula xml:id="formula_4">{P D |D ∈ V D }. A strategy ∆ induces a joint distribution over V C ∪ V D defined by P ∆ (v C , v D ) = P (v C : v D ) D∈V D P D (d|IPred(D)) = C∈V C P (c|pa(C)) D∈V D P D (d|pa(D))<label>(5)</label></formula><p>Let I be an ID, ∆ a strategy for I and r a configuration defined over a set of variables R ⊆ V C ∪ V D such that P ∆ (r) = 0. The conditional probability distribution induced by strategy ∆ given the configuration r, defined over R = (V C ∪ V D ) \ R, is given by:</p><formula xml:id="formula_5">P ∆ (r |r) = P ∆ (r, r ) P ∆ (r)<label>(6)</label></formula><p>Using this distribution we can compute the expected utility of U under strategy ∆ given the configuration r as:</p><formula xml:id="formula_6">EU U (∆, r) = r P ∆ (r |r)ψ U (r, r )<label>(7)</label></formula><p>For the terminal utility node U 0 , EU U 0 (∆, r) is said to be the expected utility of strategy ∆ given the configuration r, and denoted by EU (∆, r).</p><p>We define the expected utility of U under strategy ∆ as EU U (∆) = EU U (∆, ), where is the empty configuration. We have that</p><formula xml:id="formula_7">EU U (∆) = v C v D P (v C , v D )ψ U (v C , v D )<label>(8)</label></formula><p>We also define the expected utility of strategy ∆ as</p><formula xml:id="formula_8">EU (∆) = EU U 0 (∆).</formula><p>An optimal strategy is a strategy ∆ opt that maximizes the expected utility:</p><formula xml:id="formula_9">∆ opt = arg max ∆∈∆ * EU (∆)<label>(9)</label></formula><p>where ∆ * is the set of all strategies for I. Each policy in an optimal strategy is said to be an optimal policy. The maximum expected utility (MEU) is</p><formula xml:id="formula_10">MEU = EU (∆ opt ) = max ∆∈∆ * EU (∆)<label>(10)</label></formula><p>The evaluation of an ID consists in finding the MEU and an optimal strategy, composed by an optimal policy for each decision. It can be proved <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b2">[3]</ref> that</p><formula xml:id="formula_11">MEU = c0 max d0 . . . cn-1 max dn-1 cn P (v C : v D )ψ(v C , v D ) (11)</formula><p>For instance, the MEU for the ID in Fig. <ref type="figure" target="#fig_0">1</ref> is</p><formula xml:id="formula_12">MEU = max t y max d x P (x) • P (y|t, x) • (U 1 (x, d) + U 2 (t) U 0 (x,d,t) )<label>(12)</label></formula><p>3) Cooper policy networks: A strategy ∆ = {P D |D ∈ V D } can be used to convert the ID into a BN, that we call Cooper policy network (CPN), as follows: each decision D is replaced by a chance node with probability potential P D and parents IPred(D), and each utility node U is converted into a chance node whose parents are its functional predecessors, FPred(U )-see Fig. <ref type="figure" target="#fig_1">2</ref>. The values of each new chance variable U are {+u, ¬u} and its probability is</p><formula xml:id="formula_13">P CPN (+u|fPred(U )) = norm U (U (fPred(U )))</formula><p>, where norm U is a linear transformation that maps the utilities U (fPred(U )) from the interval [α U , β U ] onto the interval [0, 1] [19]; α U and β U are defined as:</p><formula xml:id="formula_14">α U = min fPred(U ) ψ U (fPred(U ))<label>(13)</label></formula><formula xml:id="formula_15">β U = max fPred(U ) ψ U (fPred(U )) . (<label>14</label></formula><formula xml:id="formula_16">)</formula><p>The joint distribution of the CPN is:</p><formula xml:id="formula_17">P CPN (v C , v D , v U ) = P ∆ (v C , v D ) U ∈V U P U (u|pa(U ))<label>(15)</label></formula><p>Given two configurations r and r defined over two set of variables,</p><formula xml:id="formula_18">R ⊆ V C ∪ V D and R ⊆ (V C ∪ V D ), such that R ∩ R = ∅ and P (r) = 0,</formula><p>and U a utility node, it holds that</p><formula xml:id="formula_19">P ∆ (r ) =P CPN (r )<label>(16)</label></formula><formula xml:id="formula_20">P ∆ (r |r) =P CPN (r |r) (<label>17</label></formula><formula xml:id="formula_21">)</formula><formula xml:id="formula_22">EU U (∆) = norm -1 U (P CPN (+u))<label>(18</label></formula><p>)</p><formula xml:id="formula_23">EU U (∆, r) = norm -1 U (P CPN (+u|r))<label>(19)</label></formula><p>In Section IV we will use these equations to compute on a CPN the probabilities and expected utilities to be displayed in the GUI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPLANATION OF BAYESIAN NETWORKS IN ELVIRA</head><p>This section describes the main options available in Elvira for generating explanations of both the model and the reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Explanation of the model</head><p>Elvira offers verbal and graphical explanations at the micro level of given nodes and links (cf. Sec. I-A), and also of the whole network, by means of windows and menus, as follows.</p><p>Currently Elvira treats all variables as if they were ordinal. In the case of non-ordinal variables, such as sex or race, the order is that in the list of states defined by the user while editing the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Explanation of nodes:</head><p>In edit mode, nodes are displayed as contracted <ref type="bibr" target="#b14">[15]</ref>, i.e., drawn as an oval containing only its name. However, in inference mode, nodes can also be displayed as expanded, i.e., drawn as rounded-corner rectangles which graphically display the main properties of the nodes (states and its probabilities). For example, in the BN in Fig. <ref type="figure" target="#fig_2">3</ref> the nodes Virus A, Virus B, Disease 1 and Disease 2 are expanded and the rest are contracted.</p><p>The verbal explanation of a given node, which can be accessed by right-clicking on it, contains the following information: name, states, parents and children, prior odds and posterior odds. This is very useful for analyzing the correctness of some probabilities, since in some cases human experts know that a value is certain times more probable than other, instead of the concrete data. Also the verbal explanation of a node includes some other properties, such as the purpose and the importance factor <ref type="bibr" target="#b14">[15]</ref> of such node. The purpose of a node is defined by the role it plays in the model, according to several categories, such as "symptom" or "disease". The importance factor, a value assigned by the human expert on a 0-10 scale, is the same as the relevance factor used in DIAVAL <ref type="bibr" target="#b7">[8]</ref> for selecting the main diagnoses and equivalent to the importance factor in MYCIN <ref type="bibr" target="#b19">[20]</ref>. Additionally, the importance factor can work in conjunction with the expansion threshold set by the user <ref type="bibr" target="#b4">[5]</ref>-in Fig. <ref type="figure" target="#fig_2">3</ref> it is set to 7.00 (see the upper left corner of the figure). The nodes whose importance factor is higher than the expansion threshold and whose role is one of those selected by the user are expanded, and the rest are contracted. In Fig. <ref type="figure" target="#fig_2">3</ref> the only selected role (determined by means of a specific screen) was disease. It is also possible to manually expand or contract a particular node.</p><p>The facility of selectively expanding nodes has been very useful when building and debugging real-world models containing a high number of nodes, such as Prostanet, a BN for diagnosing prostate cancer <ref type="bibr" target="#b4">[5]</ref>, and Hepar II, a BN for the diagnosis of liver disorders <ref type="bibr" target="#b20">[21]</ref>. For example, when evaluating Prostanet, which contains 47 nodes, the expert wanted to focus only on the probabilities of the main diseases, in order to make a differential diagnosis between prostate cancer and some other benign diseases related to prostate. We could do it by automatically expanding the nodes whose purpose was disease/anomaly and whose importance factor was greater than 7.</p><p>In a similar way to DIAVAL <ref type="bibr" target="#b7">[8]</ref>, Elvira allows the user to navigate across the explanation windows associated to the nodes and links of the network in order to analyze at a micro level all the information related to each of them. This facility is not necessary for networks containing "only" a few dozens nodes, because the graph can be seen on a screen, but may be useful for bigger networks with intricate graphs.</p><p>2) Explanation of links: One of the more useful features of Elvira is the automatic coloring of links <ref type="bibr" target="#b4">[5]</ref>, which offers qualitative insight about the conditional probability tables. This coloring is based on the sign of influence <ref type="bibr" target="#b21">[22]</ref> and the magnitude of influence <ref type="bibr" target="#b4">[5]</ref>, which are defined as follows: </p><formula xml:id="formula_24">(M I) for link A → C is M I(A, C) = max c,a,b |P (C ≥ c|a, b) -P (C ≥ c|a 0 , b)| (20)</formula><p>where a 0 is the normal value of A.</p><p>The normal value of a variable is the state that represents the absence of anomaly. For instance, if X represents a disease having a domain {present, absent} or {severe, moderate, mild, absent}, the normal value is "absent". If the domain is {increased, normal, decreased}, the normal value is "normal". Therefore, the M I(A, C) measures to what extent a certain cause A is able to shift C from its normality state to a state of anomaly. </p><formula xml:id="formula_25">P (C ≥ c|a, b) ≥ P (C ≥ c|a , b)<label>(21)</label></formula><p>We also say that the link is positive. The intuition motivating these definitions is that an influence is positive when higher values of A make high values of C more probable, as shown in the following example.  <ref type="table" target="#tab_0">I</ref>, in which a 1 clearly leads to higher values of C than a 0 ; it is a case of positive influence according with Definition 2, but it would have not been so if we had used "P (c|a, b) ≥ P (c|a , b)" in the definition, because P (c 0 |a 1 ) &lt; P (c 0 |a 0 ) and P (c 1 |a 1 ) &lt; P (c 1 |a 0 ). The definitions of negative influence and negative link are analogous. When M I(A, C) = 0 we say that the influence of link A → C is null. From a point of view of knowledge representation, a BN should not contain null links. When the influence is neither positive nor negative nor null, then it is said to be undefined. A link A → C may be undefined for several reasons. One of them is the case in which A has more than two values and the cumulative probability of C increases when A changes from a 0 to a 1 but decreases when changing from a 1 to a 2 . For instance, the probability of prostate cancer increases until a man is in his 50's and decreases afterwards. A link can also be undefined if A increases the probability of high values of C for some configurations of B and decreases it for other configurations. For instance, a certain drug might be beneficial for a type of patients and harmful for others.</p><p>Positive links are colored in red, negative in blue, undefined in purple, and null in black. <ref type="foot" target="#foot_2">4</ref> In Fig. <ref type="figure" target="#fig_2">3</ref> we can see that most links are red, because in general the presence of the cause increases the probability of the effect; the only exception in that example is the link Vaccination-→Disease2, for obvious reasons. We can also see in that figure that the thickness of links varies with the magnitude of influence, i.e., with the strength of the association.</p><p>The coloring and the width of links is one of the most powerful tools provided by Elvira in order to help both experts and knowledge engineers to detect wrong influences, which frequently occurs when probabilities are subjectively estimated, and even when the probabilities are obtained from databases, either because of several biases or because of values missing non-randomly. In fact, without Elvira's graphical explanation of the links it would have been much more difficult to detected some wrong probabilities estimated by the experts when building Prostanet <ref type="bibr" target="#b4">[5]</ref> and Hepar II <ref type="bibr" target="#b20">[21]</ref>. Elvira also allowed us to see at a glance that many of the influences in the database version of Hepar II (i.e., the model in which all the probabilities were drawn from a database) were negative <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b22">[23]</ref>, which seriously questioned the validity of that database as a source of information for building BNs. <ref type="foot" target="#foot_3">5</ref>Additionally, Elvira can offer verbal explanations for a selected link, which we do not describe here because of the lack of space. The interested reader is referred to <ref type="bibr" target="#b14">[15]</ref>.</p><p>3) Explanation of the network: Elvira can generate a verbal explanation of the whole network based mainly on the purpose of each node. It consists of a text containing a description of the disease/anomaly nodes, based on their parents and children. For example, a fragment of the verbal explanation of the network in Fig. <ref type="figure" target="#fig_2">3</ref> is: The network "Two Diseases" represents the following information: The disease / anomaly Virus A has neither causes nor risk factors represented in the network. It may cause the following DISEASES / ANOMALIES: Disease 1, SYMPTOMS: Symptom, SIGNS: Sign. This tool has been very useful when building the causal graph of Prostanet <ref type="bibr" target="#b4">[5]</ref>, because the natural-language texts provided by Elvira, which is similar to the way in which the network would be described by a human being, helped the experts to understand the causal model represented by the graph of the BN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Explanation of reasoning: evidence cases 1) Explanation of an evidence case:</head><p>In Elvira an evidence case is defined as a set of findings plus the corresponding posterior probabilities: Definition 4: Given a Bayesian network, defined over a set of variables V C , and evidence e, an evidence case (EC) is a pair (e, P * ), where e is the configuration of the observed variables E that represents the set of findings, and P * is the set of posterior probabilities of the unobserved nodes:</p><formula xml:id="formula_26">P * ={P (V |e), V ∈ V C \ E}.</formula><p>The individual probabilities P (v|e) can be observed by inspecting the posterior probability of each value in the expanded nodes, as shown in Fig. <ref type="figure" target="#fig_2">3</ref>. Additionally, it is possible to have an overall view of the changes in the probabilities all the variables by selecting automatic explanation in the explanation options menu, which performs a coloring of nodes depending on the changes of their posterior probabilities, in accordance with the following definitions.</p><p>Definition 5: Evidence e influences variable V more than</p><formula xml:id="formula_27">θ (with θ ≥ 0) iff ∃v, |P (V ≥ v|e) -P (V ≥ v)| &gt; θ,<label>(22)</label></formula><p>When the influence exists, it is said to be positive iff</p><formula xml:id="formula_28">∀v, P (V ≥ v|e) ≥ P (V ≥ v) (<label>23</label></formula><formula xml:id="formula_29">)</formula><p>and it is negative iff</p><formula xml:id="formula_30">∀v, P (V ≥ v|e) ≤ P (V ≥ v) (<label>24</label></formula><p>) If e does not influence V , we can say that the influence is null. A non-null influence that is neither positive nor negative is undefined. In the case of a binary variable V , the influence is positive if P (+v|e) &gt; P (+v), negative if P (+v|e) &lt; P (+v) and null if P (+v|e) = P (+v).</p><p>This definition, as well as those for the coloring of links in Sec. III-B.2, is based on Wellman's work on qualitative probabilistic networks, QPN <ref type="bibr" target="#b21">[22]</ref>. However, the fact that our networks contain numerical probabilities and that propagation of evidence is done by quantitative algorithms, allows us to determine the sign of probability changes in many cases in which Wellman's algorithms would lead to "unknown" signs.</p><p>The quantitative aspect of influence is measured by the following magnitude: Definition 6: If evidence e influences variable V , we define the magnitude of the impact of evidence e over V , as</p><formula xml:id="formula_31">M I e (V ) = max v |P (V ≥ v|e) -P (V ≥ v)| (<label>25</label></formula><formula xml:id="formula_32">)</formula><p>If V is a binary variable then M I e (V ) = |P (+v|e) -P (+v)| = |P (¬v|e) -P (¬v)|.</p><p>In Elvira, nodes are colored in red if they receive positive influence from e, in blue if the influence is negative, and in purple if it is undefined. If the influence is null, they remain colored in yellow, the default color. The saturation of the color depends on the magnitude of the impact of evidence. The threshold θ (cf. Eq. 22) can be set from the GUI.</p><p>The coloring of nodes is especially useful to analyze the propagation of evidence along different chains of reasoning <ref type="bibr" target="#b23">[24]</ref>. For instance, in Fig. <ref type="figure">4</ref> we can see how the finding X-ray=positive propagates up to variable Vaccination and why it causes a decrease of P (vaccination). The coloring of nodes and links offers an intuitive idea of how the probabilities have changed due to evidence propagation. The fact that link Anomaly→X-ray is positive explains why a positive finding for X-ray leads to an increase in the probability of Anomaly, which is colored in red-see the rules for the combination of signs in <ref type="bibr" target="#b21">[22]</ref>. The same explanation applies to the positive link Disease 2→Anomaly. On the contrary, the link Vaccination→Disease 2 (depicted in blue) is negative, and this explains why an increase in the probability of Disease 2 makes us suspect that the patient was not vaccinated, which is reflected in the blue coloring of node Vaccination.</p><p>Additionally, Elvira is able to classify the findings depending on the kind and magnitude of influence that they exert on a certain variable V , selected by the user, according to the following definitions: Definition 7: Given evidence e, the magnitude of influence exerted by a finding f over variable V is</p><formula xml:id="formula_33">M I f (V ) = max v |P (V ≥ v|e) -P (V ≥ v|e \ {f })| (26)</formula><p>In this context, we say a finding f positively influences variable</p><formula xml:id="formula_34">V iff M I f (V ) = 0 and ∀v, P (V ≥ v|e) &gt; P (V ≥ v|e \ {f }) (<label>27</label></formula><formula xml:id="formula_35">)</formula><p>The definitions of negative and null influence are similar. When a non-null influence is neither positive nor negative, then it is said to be undefined. Please note that Definitions 5 and 6 refer to the impact of a set of evidence as a whole, while Definition 7 focuses on the impact of an individual finding (in the context of other findings).</p><p>The classification of findings allows the user to understand why the probability of a node receiving different kinds of influence has increased or decreased. For example, given the network in Fig. <ref type="figure" target="#fig_2">3</ref>, if the user introduces the evidence {Vaccination=yes, Anomaly=present}, the probability of Disease 2 increases, as shown by the red coloring of this node. The classification of findings helps the user to understand that the positive influence of Vaccination=yes, whose magnitude is 0.493, prevails over the negative influence of Anomaly=present, whose magnitude is only 0.145, as it is shown in Fig. <ref type="figure" target="#fig_6">5</ref>.</p><p>These explanation options can be accessed by opening a window which contains the following information about the current evidence case:</p><p>1) The name of the case and its associated findings.</p><p>2) The probability of evidence e. This may be useful, for instance in medicine, because diagnosing a rare disease can be explained by a low value of P (e). It can also be used to detect conflicts between findings <ref type="bibr" target="#b24">[25]</ref>. 3) A panel for the analysis of sensitivity to the evidence. <ref type="foot" target="#foot_4">6</ref>This panel shows the states of a certain variable V selected by the user, their prior probabilities, their posterior probabilities and the logarithmic ratio of both probabilities for each state v:</p><formula xml:id="formula_36">S(v|e) = lg P (v|e) P (v)<label>(28)</label></formula><p>We have chosen this function because its meaning can be easily explained to users: positive values mean that the probability of v has increased, and vice versa, and the absolute value of S measures the impact of the evidence on v. 4) Two buttons, How and Why, whose names are inspired in MYCIN's explanation facilities <ref type="bibr" target="#b30">[31]</ref>. The How button highlights the chains of reasoning by hiding the links and nodes that are in no active path from the evidence nodes E to variable V , and colors the nodes in active paths, as explained in the previous section. The decision of whether a path is active, inactive, or blocked is based on the d-separation criteria <ref type="bibr" target="#b0">[1]</ref>. In turn, the Why button opens a window having four list of findings, depending on whether the influence exerted by each one on V is positive, negative, null, or undefined, according with Equation 7, as we have described earlier and illustrated by Fig. <ref type="figure" target="#fig_6">5</ref>. Then, the coloring of the nodes in the paths from the findings to a given variable V helps the user to analyze how evidence flows through the network, increasing or decreasing the probability of some variables in the way up to V , with different degrees of intensity. The classification of findings also helps the users to detect the findings that have more impact than others and also the possible conflicts among findings. The study of different evidence cases (see below) allows the user to analyze the impact of each finding by itself and its impact in the context of a whole set of evidence.</p><p>2) Handling several evidence cases: One of the specific features of Elvira, which differentiates it from the tools developed previously, is its ability to manage several evidence cases simultaneously <ref type="bibr" target="#b14">[15]</ref>. By default, Elvira creates a prior case, which corresponds to the absence of evidence, and whose associated probabilities are the prior probabilities of each node in the network: (∅, {P (V )|V ∈ V C }). It also generates a new case automatically when the user introduces the first finding. Later, the user can create new cases to accommodate new sets of findings; the new case inherits all the findings of the previous one.</p><p>Most of the operations are performed on the current case, which can be selected by the user among the list of available evidence, which we are discussing now, refers to how the set of findings has affected the posterior probabilities <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>. In contrast, the analysis of sensitivity to the parameters studies how different variations of the conditional probabilities that define the network would affect the prior and posterior probabilities <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. In Section IV-F we will discuss the analysis of sensitivity to the parameters in IDs.</p><p>cases. A different bar is displayed for each evidence case and each state in the expanded nodes, although the numerical probability is displayed only for the current case. In Fig. <ref type="figure" target="#fig_2">3</ref> four evidence cases are considered-this is why each expanded node has four colored bars associated to each state. The first one is colored in green and it represents the prior probabilities of each node, i.e, the absence of evidence. Nodes whose value is known with certainty, because the current evidence case contains one finding associated to it, are colored in gray. In Fig. <ref type="figure" target="#fig_2">3</ref> the there is only one gray node, Symptom, representing the only finding of the current case. Also the tool bar shows a label with the same color as the current case and its name. For example, in Fig. <ref type="figure" target="#fig_2">3</ref> the current case corresponds to the one colored in red and identified as "Presence of Symptom". If every node were expanded the user could identify the findings associated to the rest of cases because the corresponding colored bars were set to the maximum possible length.</p><p>A monitor of cases permits the user to control which cases are stored and displayed, to remove cases from memory, and to modify some properties of the cases, such as the name and color that Elvira assigns by default, which helps the user to easily identify each evidence case. For example, in Fig. <ref type="figure" target="#fig_2">3</ref> the current case has been renamed as "Presence of symptom". An editor of cases makes it possible to navigate through the different evidence cases stored in the memory, to edit each of them, and to propagate new evidence.</p><p>The analysis of the propagation of evidence through chains of reasoning, combined with the possibility of handling several evidence cases simultaneously, has been very useful for our students to have an intuitive understanding of the d-separation properties, a notion that was quite complicated for them before we used Elvira in our tuition. Using some example networks, we illustrate, for instance, the difference between active and inactive paths by showing how the introduction of a certain finding changes the color of some nodes, while others remain in yellow. This change or lack of change in the probabilities can also be seen (when the nodes are expanded) by observing the probability bars. Similarly, the fact that two sets of variables, X and Y are d-separated by Z can be illustrated by first introducing a finding for each variable in Z and then creating a new case that, in addition, contains evidence for some of the variables in X. It can be clearly seen that the nodes in Y remain in yellow, which means that P (y|z) = P (y|z, x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPLANATION OF INFLUENCE DIAGRAMS IN ELVIRA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Explanation of the model</head><p>The explanation of IDs in Elvira is based, to a great extent, on the methods developed for explanation of BNs. One of the methods that have proven to be more useful is the automatic colorings of links. The definitions in Section III-A.2 for the sign of influence and magnitude of influence, inspired on <ref type="bibr" target="#b21">[22]</ref>, have been adapted to utility nodes as follows: </p><formula xml:id="formula_37">A → U is M I(A, U ) = norm U (max a,b |ψ U (a, b) -ψ U (a 0 , b)|) (29)</formula><p>We say that A positively influences variable U iff</p><formula xml:id="formula_38">M I(A, U ) = 0 and ∀a, ∀a , ∀b, a &gt; a =⇒ ψ U (a, b) ≥ ψ U (a , b)<label>(30)</label></formula><p>We also say that the link is positive. The definitions of negative influence and negative link are analogous. When M I(A, U ) = 0 the influence of link A → U is said to be null; in that case, link A → U should be removed. When the influence is neither positive nor negative nor null, then it is said to be undefined.</p><p>For instance, in Fig. <ref type="figure" target="#fig_0">1</ref> the link X → Y is colored in red because it represents a positive influence: the presence of the disease increases the probability of a positive result of the test. The link X → U 1 is colored in blue because it represents a negative influence: the disease decreases the expected quality of life. The link D → U 1 is colored in purple because its influence is undefined: the treatment is beneficial for patients suffering from X but detrimental for healthy patients.</p><p>As in the case of BNs, the coloring of links in Elvira has been very useful for debugging IDs, by detecting probability and utility tables whose numerical values do not agree with the qualitative influences assessed by the expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Displaying the results of inference</head><p>In Section II-B.3 we have seen that, given a strategy ∆, an ID can be converted into a Cooper policy network (CPN), which is a true Bayesian network. Consequently, all the explanation capabilities for BNs are also available for IDs by exploiting such transformation.</p><p>The information displayed for nodes depends on the kind of node-see Fig. <ref type="figure" target="#fig_7">6</ref>. Chance and decision nodes display bars and numbers corresponding to the probabilities of their states, P ∆ (v), a marginal probability of P ∆ (v C , v D ), defined by Equation <ref type="formula" target="#formula_4">5</ref>. P ∆ (v) is the probability that a chance variable V takes a certain value v, or the probability that the decision maker chooses option v for decision V <ref type="bibr" target="#b31">[32]</ref>. P ∆ (v) can be computed on the Cooper policy network (CPN) by means of Equation <ref type="formula" target="#formula_19">16</ref>. Each utility node U displays the expected utility EU U (∆), defined by Equation <ref type="formula" target="#formula_7">8</ref>, which is computed by propagating on the CPN and transforming back with the use of Equation <ref type="formula" target="#formula_22">18</ref>. The guide bar (black line) indicates the range of the utilities.</p><p>Links pointing into a decision node D are drawn with the color and thickness indicated in Section III-A.2, by examining the policy P D (returned by the evaluation of the ID) as if it were the conditional probability table of a chance node. Nonforgetting links added during the evaluation of the diagram <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, such as link T → D in Fig. <ref type="figure" target="#fig_7">6</ref>, are drawn as discontinuous arrows.</p><p>Elvira, as most software tools for IDs, can show the utility table associated to each decision. For instance, in Table <ref type="table" target="#tab_1">II</ref> each column corresponds to a configuration (t, y) of the informational predecessors of decision D and each cell contains the expected utility of option d given t and y provided that every future decision will be made optimally EU (d|iPred(d)) = EU (d|t, y). In that table the order of the variables in IPred(D) is chosen to make it compatible with the partial order induced by the ID, i.e., the order in which the observations and decisions are known by the decision maker during the decision process. The highest utility in each column is highlighted in red. We have contracted the columns that represent impossible scenarios, i.e., configurations such that</p><formula xml:id="formula_39">P (iPred(D))=0.</formula><p>This table is used by the evaluation algorithm to compute the optimal policy; in this example, d opt = arg max d EU (d|t, y), as shown in Table <ref type="table" target="#tab_2">III</ref>. A toggle allows the user to view either the expected utilities for a decision (Table <ref type="table" target="#tab_1">II</ref>) or the optimal policy (Table <ref type="table" target="#tab_2">III</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Explanation of reasoning: decision trees</head><p>Initially, IDs were proposed as an alternative representation for decision trees (DTs) <ref type="bibr" target="#b1">[2]</ref>. Not surprisingly, the first algorithm for evaluating IDs was to expand the equivalent DTs. Nowadays we have much more efficient algorithms for IDs, such as arc reversal <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref> and variable elimination <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b34">[35]</ref>, but the operations that they perform are only understood by experts in probabilistic graphical models. On the contrary DTs are easily understood by many users, because human beings tend to analyze decision problems by figuring out the possible scenarios, and each branch of a DT just represents a possible scenario, having a certain probability and a certain utility. An additional reason for using DTs when building medical decision-support systems is that most of the physicians learned about them as pregraduate students, and even many of them have done decision analysis with some software packages for DTs.</p><p>For this reason, even though Elvira uses the most efficient algorithms for evaluating IDs (otherwise it would be impossible to solve large models), it also offers the possibility of converting an ID into an equivalent DT and expanding and contracting its branches to the desired level of detail. Clearly, in the case of models containing dozens of nodes only a fraction of the branches can be expanded.</p><p>This idea, even though not original, has proven to be very useful in many situations. For instance, given the ID in Fig. <ref type="figure" target="#fig_0">1</ref>, if the user wonders how Elvira obtained the utilities and the policy for D, it is possible to expand the DT shown in Fig. <ref type="figure" target="#fig_8">7</ref>. In particular, the value EU (D=yes|T =yes, Y =positive) = 81.05 in Table <ref type="table" target="#tab_1">II</ref>, which also appears in the branch {T =yes, Y =positive, D=yes} in the DT, can be explained as the weighted average of the utility for the presence of the disease (U = 78.00, with probability 0.70) and the utility for the absence of the disease (U = 88.00, with probability 0.30). In turn, the utility for the disease, U = 78.00 can be explained as the utility associated to the quality of life, U 1 (x, d) = 80.00 minus the cost of test, U 2 = 2.00. In the same way, the DT can explain the value EU (D=no|T =yes, Y =positive) = 49.32 in Table <ref type="table" target="#tab_1">II</ref>.</p><p>The optimal decision for scenario {T =yes, Y =positive} is D=yes, because 81.05 &gt; 49.32. For this reason, branch {T =yes, Y =positive, D=yes} in the DT is highlighted with a red square, in accordance the highlighting of value 81.05 in Table <ref type="table" target="#tab_1">II</ref>.</p><p>Therefore, the main difference of Elvira with respect to other software tools is that, in addition to showing the (global) expected utility of each branch, it can also show the individual utilities that compose it, i.e., the utilities associated to the utility nodes other than U 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Introduction of evidence</head><p>Elvira's ability to manage several evidence cases simultaneously in BNs is also available for IDs. The evidence is introduced in the ID by using its corresponding Cooper policy network. Given evidence e, Elvira displays for each chance and decision node V the probability P ∆ (v|e) (cf. Eqs. 6 and 17), and for each utility node U the expected utility EU U (∆, e) (cf. Eqs. 7 and 19), as shown in Fig. <ref type="figure" target="#fig_3">8</ref>.</p><p>1) Clarifying the concept of evidence in influence diagrams: In order to avoid confusions, we must mention that the meaning of evidence in Elvira is very different from its meaning in some methods oriented to the computation of the value of information in IDs, such as <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. For those methods, the introduction of evidence e leads to a different decision problem in which the values of the variables in E would be known with certainty before making any decision. For instance, introducing evidence {+x} in the ID in Fig. <ref type="figure" target="#fig_0">1</ref> would mean that X were known when making decisions T and D. Therefore, the expected utility of the new decision problem, which we call "Ezawa's scenario" <ref type="bibr" target="#b37">[38]</ref>, would be max t y</p><formula xml:id="formula_40">max d P (y|+x : t, d) • (U 1 (+x, d) + U 2 (t) U0(+x,d,t)</formula><p>)</p><p>where P (y|+x : t, d) = P (+x, y : t, d)/P (+x : t, d) = P (+x, y : t)/P (+x) = P (y|+x : t). In spite of the apparent similarity of this expression with Equation <ref type="formula" target="#formula_12">12</ref>, the optimal strategy changes significantly from "test, and treat only if the result is positive" to "always treat, without testing", because if we knew with certainty that the disease X is present. the result of the test would be irrelevant. The MEU for the new decision problem would be U 0 (+x, +d, ¬t) = U 1 (+x, +d).</p><p>In contrast, the introduction of evidence in Elvira does not lead to a new decision scenario nor to a different strategy, since the strategy is determined before introducing the "evidence". Put another way, when introducing evidence in Elvira we adopt the point of view of an external observer of a system including the decision maker as one of its components. The probabilities and expected utilities given by Equations 5 and 7 are those corresponding to the subpopulation indicated by e when the decision maker applies strategy ∆. For instance, given the evidence {+x}, the probability P ∆ (+t|+x) shown by Elvira is the probability that a patient suffering from X receives the test, which is 1 (it was 0 in Ezawa's scenario), and P ∆ (+d|+x) is the probability that he receives the treatment; contrary to Ezawa's scenario, this probability may differ from 1 because of false negatives. The expected utility for a patient suffering from X is</p><formula xml:id="formula_41">EU (∆, {+x}) = = t,y,d P ∆ (t, y, d|+x) • (U 1 (+x, d) + U 2 (t))</formula><p>where P ∆ (t, y, d|+x) = P ∆ (t) • P (y|t, +x) • P ∆ (d|t, y). For the optimal strategy,</p><formula xml:id="formula_42">EU (∆ opt , {+x}) =[P (+y|+x) • U 1 (+x, +d) + P (¬y|+x) • U 1 (+x, ¬d)] + U 2 (+t)</formula><p>A second difference is that the evidence introduced in Elvira may include "findings" for decision variables. For instance, e = {+d} would represent the subpopulation of patients who have received therapy, and P ∆ (+x|+d) is the probability that a patient receiving therapy has disease X.</p><p>And the third difference is that Elvira admits the possibility of analyzing non-optimal strategies, as we will see below.</p><p>We must stress that the two approaches are not rivals. They correspond to different points of view when considering evidence in IDs and can complement each other in order to perform a better decision analysis and to explain the reasoning. We have implemented first the options that, in our opinion, can be more useful, but in the future we will implement as well Ezawa's method and the possibility of computing the expected value of perfect information (EVPI).</p><p>2) Example: Fig. <ref type="figure" target="#fig_3">8</ref> shows two evidence cases. In this example, ∆ is the optimal strategy obtained when evaluating the ID, because no policy was imposed by the user. The first evidence case in Fig. <ref type="figure" target="#fig_3">8</ref> is the prior case, which was also displayed in Fig. <ref type="figure" target="#fig_7">6</ref>. Its probabilities and expected utilities are those of the general population. The second evidence case is given by e = {+y}; i.e., it displays the probabilities and utilities of the subpopulation of patients in which the test has given a positive result. Node Y is colored in gray to highlight the fact that there is evidence about it. The probability P ∆ (+x|+y), represented by a red bar, is 0.70; the green bar close to it represents the probability of +x for the prior case, i.e., P ∆ (+x), which equals P (+x) because the decision maker's actions do not affect X. The red bar is longer than the green one because P ∆ (+x|+y) &gt; P ∆ (+x), as it was expected from the fact that link X → Y is positive. The global utility for the second evidence case, EU (∆, {+y}), represented by a red bar in node U 0 , is smaller than EU (∆, ∅), the expected utility for the general population, represented by a green bar, because the presence of the symptom worsens the prognosis. The red bar for Treatment=yes, which represents P ∆ (+d|+y), is 1.00 because the optimal strategy determines that all symptomatic patients must be treated. Similarly, P ∆ (+t|+y) = 1.00 because a positive result of the test implies that the test has been done.</p><p>3) Debugging influence diagrams by introducing evidence: The possibility of introducing evidence in Elvira has been useful for building IDs in medicine <ref type="bibr" target="#b9">[10]</ref>: before having this explanation facility, when we were interested in computing the posterior probability of a certain diagnosis given a set of findings, we needed to manually convert the ID into a BN by removing decision and utility nodes. Each time the ID was modified, even slightly, we had to repeat this conversion, which was tedious and time consuming. (When building medical expert systems, the time of interaction with the experts is a precious resource that must not be waisted.) This was the reason for implementing a facility that allowed us to compute the probabilities directly on the ID, which is much more convenient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. What-if reasoning: analysis of non-optimal strategies</head><p>In Elvira it is possible to have a strategy in which some of the policies are imposed by the user and the others are computed by maximization. The way of imposing a policy consists in setting a probability distribution P D for the corresponding decision D by means of Elvira's GUI; the process is identical to editing the conditional probability table of a chance node. In fact, such a decision will be treated by the inference algorithms as if it were a chance node, and the maximization will be performed only for the rest of the decisions.</p><p>This way, in addition to computing the optimal strategy (when the user has imposed no policy), as any other software tool for IDs, Elvira also permits to analyze how the expected utilities and the rest of the policies would vary if the decision maker chose a non-optimal policy for some of the decisions (what-if reasoning).</p><p>The reason for implementing this explanation facility is that when we were building a certain medical influence diagram <ref type="bibr" target="#b9">[10]</ref> our expert wondered why the model recommended not to perform a certain test. We wished to compute the a posteriori probability of the disease given a positive result in the test, P ∆ (+x|+y), but we could not introduce this "evidence", because it was incompatible with the optimal policy (not to test): P ∆ (+y) = 0. After we implemented the possibility of imposing non-optimal policies (in this case, performing the test) we could see that the posterior probability of the disease remained below the treatment threshold even after a positive result in the test, and given that the result of the test would be irrelevant, it was not worthy to do it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Sensitivity analysis and decision thresholds</head><p>Recently Elvira has been endowed with some well-known sensitivity analysis tools, such as one-way sensitivity analysis, tornado diagrams, and spider diagrams <ref type="bibr" target="#b38">[39]</ref>, which can be combined with the above-mentioned methods for the explanation of reasoning. One-way sensitivity analysis can be used for finding treatment thresholds in different scenarios <ref type="bibr" target="#b39">[40]</ref> and, in consequence, to explain the optimal policies. For instance, in Fig. <ref type="figure">9</ref>, which shows the results of one-way sensitivity analysis on the prevalence of X for the ID given in Fig. <ref type="figure" target="#fig_0">1</ref>. This graph is obtained by evaluating several instances of the ID, each having a different value of P (+x). We can see that the treatment threshold is approximately 0.17, i.e., when P (+x) &lt; 0.17 the best option is not to treat the patient, and when P (+x) &gt; 0.17 it is better to treat.</p><p>By introducing evidence about Y in the ID we can see that P (+x|+y) = 0.83; this means that the prevalence of X in the subpopulation {+y} is 0.83, which is above the 0.17 threshold. In contrast, P (+x|¬y) = 0.015 &lt; 0.17. This explains why the optimal policy for D is to treat only after a positive result of the test. In the construction of more complex IDs this kind of analysis has been useful for understanding why some tests are necessary or not, and why sometimes the result of a test is irrelevant, as discussed in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RELATED WORK AND FUTURE RESEARCH</head><p>In spite of the importance of explanation in artificial intelligence, for reasons mentioned in Section I, most software tools for building expert systems -either probabilistic or heuristic-offer no facilities for this task. There are several prototype systems developed to demonstrate new explanation options, but most of them never became publicly availablesee <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b6">[7]</ref> for a review. Among the few available environments for probabilistic graphical models endowed with some explanation facilities, we can mention the following: • The latest version of Hugin can perform an analysis of sensitivity to evidence in BNs and IDs. Clearly, Elvira offers more explanation facilities than any of these tools, but there are still many options that can be added. In particular, we will further explore the generation of verbal explanations and the possibility of adapting them to different user needs. However, the goal of offering a natural language dialog between human users and Elvira is still impossible given the current state of the art.</p><p>We are currently in the process of implementing probabilistic analysis of sensitivity to the parameters in Elvira. Other kinds of sensitivity analysis for both BNs and IDs will be added in the future. It would also be possible to integrate sensitivity analysis in IDs with the expansion of decision trees.</p><p>As mentioned above, we also intend to implement new facilities for introducing evidence in Ezawa's style <ref type="bibr" target="#b37">[38]</ref> and for computing the value of information-see Sec. IV-D.1. On the other hand, we are studying how to obtain a set of rules that summarize a strategy; for instance, "if the patient presents with symptom S and the blood test is positive, then apply treatment T ; otherwise, do not treat"; see the work by Fernández del Pozo et al. <ref type="bibr" target="#b40">[41]</ref> on this subject. The work on explanation in factored Markov decision processes by Elizalde et al. <ref type="bibr" target="#b41">[42]</ref>, which focuses on the variable that receives the higher impact from an action performed by the decision maker, may be applied to ordinary IDs as well.</p><p>Other techniques indirectly related with explanation are the facility of dealing with submodels, the possibility of simplifying the model <ref type="bibr" target="#b4">[5]</ref> in order to improve both the efficiency of the algorithms and the generation of explanations, the application of different techniques for the visualization of Bayesian networks <ref type="bibr" target="#b42">[43]</ref>, and the development of a graphical user interface that facilitates the construction of BNs and IDs by non-expert users.</p><p>In any case, the new explanation options for Elvira will be selected as a response to the most relevant needs detected in our research on building medical application and in our task of teaching probabilistic graphical models to computer science students and to health professionals.</p><p>Finally, we intend to use Elvira for developing models in other domains, such as financial risk analysis, costeffectiveness studies, and collaborative e-learning, which will certainly pose new challenges for the explanation of the models and the reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper we have described the main explanation facilities for Bayesian networks and influence diagrams implemented in Elvira, a public software package, and how they have helped us in building medical applications <ref type="bibr" target="#b22">[23]</ref> and when teaching probabilistic graphical models to pre-and postgraduate students <ref type="bibr" target="#b10">[11]</ref>. In our experience, the most useful explanation options for BNs among those offered by Elvira are, in this order, the simultaneous display of several evidence cases, the possibility of coding the sign and magnitude of influences by the color and thickness of links, and the explanation of evidence cases by highlighting the active chains of reasoning, which includes the coloring of nodes in those chains. With respect to IDs, the most useful options are the possibility of introducing evidence, the conversion of IDs into decision trees, the possibility of analyzing non-optimal policies imposed by the user, and the analysis of sensitivity to the parameters. Further research is still necessary to make probabilistic reasoning more understandable to human users.  Fig. <ref type="figure">4</ref>. Chains of reasoning for the graphical explanation of a case whose evidence is defined by the finding X-ray=positive. The selection of a variable of interest (Vaccination in this example) makes Elvira hide the nodes and links that do not make part of any active path from the evidence to the variable of interest.      <ref type="figure">9</ref>. Elvira's one-way sensitivity analysis on the prevalence of the disease, which is represented in the the x-axis. The y-axis represents the expected utility. The treatment threshold is 0.17.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 1 :</head><label>1</label><figDesc>Let A and C be two ordinal variables such that the former is one of the parents of the latter, P a(C) = {A}∪B. The magnitude of the influence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Definition 2 :</head><label>2</label><figDesc>If A and C are ordinal variables and P a(C) = {A} ∪ B, we say that A positively influences variable C iff M I(A, C) = 0 and ∀c, ∀a, ∀a , ∀b, a &gt; a =⇒</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Example 3 :</head><label>3</label><figDesc>If A and C are binary, the ordering +a &gt; ¬a and +c &gt; ¬c implies that P (C ≥ +c|a, b) = P (+c|a, b) and P (C ≥ ¬c|a, b) = P (+c|a, b) + P (¬c|a, b) = 1. Therefore P (C ≥ ¬c|a, b) = P (C ≥ ¬c|a , b) in all cases. Consequently, A positively influences C iff P (+c|+a, b) ≥ P (+c|¬a, b) for all b's and the inequality holds strictly for at least one b. The reason for using P (C ≥ c|a, b) instead of P (c|a, b) in the above definitions becomes clear by observing the example in Table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Definition 8 :</head><label>8</label><figDesc>Let U be an ordinary utility node having α U = β U (see Equations 13 and 14) and P a(U ) = {A} ∪ B. The magnitude of the influence (MI) for the link</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 1 . 1 Fig. 2 .</head><label>112</label><figDesc>Fig. 1. ID with two decisions (rectangles), two chance nodes (ovals) and three utility nodes (hexagons). Please note that there is a directed path T -Y -D-U 1 -U 0 including all the decisions and the global utility node U 0 .</figDesc><graphic coords="14,136.57,77.51,339.53,346.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Elvira main window in inference mode.</figDesc><graphic coords="15,136.38,78.02,339.23,272.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. This figure illustrates the impact that each finding, Vaccination=yes and Anomaly=present, has separately over the selected node Disease 2 in the network of Fig. 3.</figDesc><graphic coords="16,136.23,79.82,339.96,234.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. ID resulting from the evaluation of the ID in Figure 1. It shows the probability P ∆ (v) of each chance and decision node and the expected utilities.</figDesc><graphic coords="16,136.43,417.56,339.21,272.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig.7. Decision tree for the ID in Figure1, where some branches have been expanded to obtain more level of the detail.</figDesc><graphic coords="17,136.45,76.98,339.57,257.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. ID resulting from the evaluation of the ID in Figure 1. It shows two evidence cases: the prior case (no evidence) and the case in which e = {+y}.</figDesc><graphic coords="17,136.43,421.30,339.21,271.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig.</head><label></label><figDesc>Fig.9. Elvira's one-way sensitivity analysis on the prevalence of the disease, which is represented in the the x-axis. The y-axis represents the expected utility. The treatment threshold is 0.17.</figDesc><graphic coords="18,181.74,313.06,248.70,132.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I A</head><label>I</label><figDesc>PROBABILITYTABLE SHOWING A POSITIVE INFLUENCE OF A ON C (SEE DEF. 2, EQ. 21).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II EXPECTED</head><label>II</label><figDesc>UTILITIES FOR DECISION D IN THE ID IN FIGURE 1.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III OPTIMAL</head><label>III</label><figDesc>POLICY FOR DECISION D IN THE ID IN FIGURE 1.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>•</head><label></label><figDesc>BayesiaLab 7 , Netica8 , and especially SamIam9 , are able to perform an analysis of sensitivity to the parameters of the model in BNs (seeFootnote 6). TreeAge 10 can convert an ID into a decision tree (in fact, the main representation framework in TreeAge are decision trees, not IDs) and to perform several types of analysis of sensitivity to the parameters.• GeNIE 11 , Hugin12 , and MSBNx 13 permit to compute the value of information. • Recent versions of BayesiaLab are able to simultaneously display probability bars for several evidence cases simultaneously, and to represent the sign and magnitude of influences by the color and thickness of links, as in Elvira.</figDesc><table /><note><p><p>7 </p>http://www.bayesia.com. 8 http://www.norsys.com/netica.html. 9 http://reasoning.cs.ucla.edu/samiam/. Its acronym stands for "Sensitivity Analysis, Modeling, Inference and More". 10 http://www.treeage.com/. 11 http://genie.sis.pitt.edu/. 12 http://www.hugin.com. 13 http://research.microsoft.com/adapt/MSBNx/.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>In the context of BNs, evidence propagation usually refers to computing the posterior probability of each single variable given the available evidence, while abduction consists in computing the joint probability of a set of variables of interest given the evidence, what is also called Maximum A Posteriori Probability (MAP).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>An ID that does not fulfill this condition can be transformed by adding a super-value node U 0 of type sum whose parents are the utility nodes that did not have descendants. The expected utility and the optimal strategy of the transformed diagram are the same as those of the original one.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>The coding of influences and probabilities in Elvira is inspired in physics, where high temperatures are associated with the red color and low temperatures with blue.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Because of our experience in the field of medical applications, we suspect that the quality of some of the databases used for building BNs with learning algorithms may suffer from similar biases. In that case, a cross-validation of the model (against another portion of the database) does not at all mean that the resulting BN represents the real-world correlations and influences.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>There are two kinds of sensitivity analysis in BNs. Sensitivity to the</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The conversion of IDs into decision trees and sensitivity analysis in IDs have been implemented in Elvira by <rs type="person">Jorge Fernández</rs> and <rs type="person">Jacinto Ruiz</rs>, respectively, two students of the <rs type="institution">Computer Science School of the UNED</rs>, under the supervision of the authors of this paper.</p><p>This work has been partially financed by the <rs type="funder">Spanish CICYT</rs> under projects <rs type="grantNumber">TIC-97-1135-C04</rs> and <rs type="grantNumber">TIC-2001-2973-C05</rs>. The author has benefited from a grant from the <rs type="funder">Department of Education of the Comunidad de Madrid</rs>, partially covered by the <rs type="funder">European Social Fund (ESF)</rs>.</p></div>
			</div>
			<div type="funding">
<div><p>They are all members of the <rs type="institution">Research Center on Intelligent Decision-Support Systems (CISIAD)</rs>, at <rs type="institution">UNED</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EDppbBy">
					<idno type="grant-number">TIC-97-1135-C04</idno>
				</org>
				<org type="funding" xml:id="_UpPcbDh">
					<idno type="grant-number">TIC-2001-2973-C05</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings on the Principles and Applications of Decision Analysis</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Matheson</surname></persName>
		</editor>
		<meeting><address><addrLine>Menlo Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Strategic Decisions Group</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="page" from="719" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Bayesian Networks and Decision Graphs</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A review of explanation methods for Bayesian networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lacave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge Engineering Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="107" to="127" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Explanation in causal Bayesian networks. Medical applications</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lacave</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>UNED</publisher>
			<pubPlace>Madrid, Spain; Spanish</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation, Dept. Inteligencia Artificial</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Customized explanations using causal knowledge</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Wallis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Shortliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Shortliffe</surname></persName>
		</editor>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="371" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A review of explanation methods for heuristic expert systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lacave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge Engineering Review</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="133" to="146" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">DIAVAL, a Bayesian expert system for echocardiography</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Iturralde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zubillaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="59" to="73" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge acquisition in Prostanet, a Bayesian network for diagnosing prostate cancer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lacave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Knowledge-Based Intelligent Information and Engineering Systems (KES&apos;2003)</title>
		<title level="s">ser. Lecture Notes in Computer Science</title>
		<meeting>the Seventh International Conference on Knowledge-Based Intelligent Information and Engineering Systems (KES&apos;2003)<address><addrLine>Oxford, UK; Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2774</biblScope>
			<biblScope unit="page" from="1345" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Influence diagrams for medical decision problems: Some limitations and proposed solutions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Disdier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Intelligent Data Analysis in Medicine and Pharmacology</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holmes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Peek</surname></persName>
		</editor>
		<meeting>the Intelligent Data Analysis in Medicine and Pharmacology</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="85" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Teaching probabilistic medical reasoning with the Elvira software</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IMIA Yearbook of Medical Informatics</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Haux</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Kulikowski</surname></persName>
		</editor>
		<imprint>
			<publisher>Schattauer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="175" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Qualitative propagation and scenariobased approaches to explanation of probabilistic reasoning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henrion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Druzdzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Conference on Uncertainty in Artificial Intelligence (UAI&apos;90)</title>
		<meeting>the 6th Conference on Uncertainty in Artificial Intelligence (UAI&apos;90)<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="17" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Strategies for generating micro explanations for Bayesian belief networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sember</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zukerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Uncertainty in Artificial Intelligence</title>
		<meeting>the 5th Workshop on Uncertainty in Artificial Intelligence<address><addrLine>Windsor, Ontario</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Elvira: An environment for creating and using probabilistic graphical models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Elvira</forename><surname>Consortium</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First European Workshop on Probabilistic Graphical Models (PGM&apos;02)</title>
		<meeting>the First European Workshop on Probabilistic Graphical Models (PGM&apos;02)<address><addrLine>Cuenca, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graphical explanation in Bayesian networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lacave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Atienza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Medical Data Analysis (ISMDA-2000)</title>
		<meeting>the International Symposium on Medical Data Analysis (ISMDA-2000)<address><addrLine>Frankfurt, Germany; Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="122" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Decision support systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Druzdzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Flynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Library and Information Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Kent</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>M. Dekker, Inc</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="120" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic programming and influence diagrams</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Tatman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="365" to="379" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Probabilistic Networks and Expert Systems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Cowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A method for using belief networks as influence diagrams</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Uncertainty in AI, University of Minnesota</title>
		<meeting>the 4th Workshop on Uncertainty in AI, University of Minnesota<address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An evaluation of MYCIN&apos;s advice</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Fagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Wraith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Clancey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hannigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Shortliffe</surname></persName>
		</editor>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1984">1984</date>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="589" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Extension of the Hepar II model to multiple-disorder diagnosis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Oniśko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Druzdzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wasyluk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Information Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Kłopotek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Michalewicz</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wierzchoń</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="303" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fundamental concepts of qualitative probabilistic networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Wellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="257" to="303" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Use of Elvira&apos;s explanation facilities for debugging probabilistic expert systems</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lacave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oniśko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Knowledge-Based Systems</publisher>
			<biblScope unit="page" from="730" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Explanation in Bayesian belief networks</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Suermondt</surname></persName>
		</author>
		<idno>STAN-CS- 92-1417</idno>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>Dept. Computer Science, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Analysis in HUGIN of data conflict</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nordahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Uncertainty in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">P</forename><surname>Bonissone</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Henrion</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">N</forename><surname>Kanal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Lemmer</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="519" to="528" />
			<date type="published" when="1991">1991</date>
			<publisher>Elsevier Science Publishers</publisher>
			<pubPlace>Amsterdam, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sensitivity analysis in bayesian networks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Aldenryd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">946</biblScope>
			<biblScope unit="page" from="243" to="250" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sensitivity analysis in discrete Bayesian networks</title>
		<author>
			<persName><forename type="first">E</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Hadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics-Part A: Systems and Humans</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="412" to="423" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">When do numbers really matter?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="265" to="287" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Properties of sensitivity analysis of Bayesian belief networks</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M H</forename><surname>Coupé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Van Der Gaag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="323" to="356" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sensitivity analysis for probability assessments in Bayesian networks</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Laskey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="901" to="909" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project</title>
		<editor>B. G. Buchanan and E. H. Shortliffe</editor>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Probabilities of future decisions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings from the International Conference on Informational Processing and Management of Uncertainty in knowledge-based Systems</title>
		<meeting>from the International Conference on Informational Processing and Management of Uncertainty in knowledge-based Systems</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="1454" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">On representing and solving decision problems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Olmsted</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<pubPlace>CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dept. Engineering-Economic Systems, Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Evaluating influence diagrams</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Shachter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="871" to="882" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Variable elimination for influence diagrams with super-value nodes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Díez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second European Workshop on Probabilistic Graphical Models</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Lucas</surname></persName>
		</editor>
		<meeting>the Second European Workshop on Probabilistic Graphical Models</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Decision making using probabilistic inference methods</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual Conference on Uncertainty in Artificial Intelligence (UAI-92)</title>
		<meeting>the 8th Annual Conference on Uncertainty in Artificial Intelligence (UAI-92)<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="276" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Myopic value of information in influence diagrams</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Dittmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference on Uncertainty in Artificial Intelligence (UAI&apos;97)</title>
		<meeting>the 13th Conference on Uncertainty in Artificial Intelligence (UAI&apos;97)<address><addrLine>Providence, RI; San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Evidence propagation and value of evidence on influence diagrams</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ezawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="73" to="83" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Making Hard Decisions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Clemen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Reilly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Duxbury</publisher>
			<pubPlace>Pacific Grove, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Sensitivity analysis for threshold decision making with Bayesian belief networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Van Der Gaag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Coupe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">1792</biblScope>
			<biblScope unit="page" from="37" to="48" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A list-based compact representation for large decision tables management</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fernández Del Pozo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bielza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="638" to="662" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Explanation generation through probabilistic models for an intelligent assistant</title>
		<author>
			<persName><forename type="first">F</forename><surname>Elizalde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sucar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>De Buen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Submitted to IB-ERAMIA&apos;06</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Visualization of Bayesian belief networks</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Zapata-Rivera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Neufeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Greer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization 1999</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Late Breaking Hot Topics Proceedings</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="85" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">She received a M.S. in Mathematics from the Universidad Complutense de Madrid in 1990 and a Ph.D. from the Universidad Nacional de Educacin a Distancia (UNED) in 2003. She is currently professor at the Department of Technologies and Systems of Information at the</title>
	</analytic>
	<monogr>
		<title level="m">Carmen Lacave was born in Valdepeas (Ciudad Real)</title>
		<meeting><address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967">1967</date>
		</imprint>
		<respStmt>
			<orgName>Universidad de Castilla-La Mancha</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">He is a Ph.D. candidate in the decision-support systems unit of the Department of Artificial Intelligence, at the Universidad Nacional de Educacin a Distancia (UNED), Madrid, since 2003</title>
	</analytic>
	<monogr>
		<title level="m">Theoretical Physics from the Universidad Autnoma de Madrid and a Ph.D. from the Universidad Nacional de Eduacin a Distancia</title>
		<meeting><address><addrLine>Madrid, Spain; Spain</addrLine></address></meeting>
		<imprint>
			<publisher>UNED</publisher>
			<date type="published" when="1965">1977. 1965. 1994</date>
		</imprint>
		<respStmt>
			<orgName>Ciudad Real, and member of the Research Center on Intelligent Decision-Support Systems (CISIAD) ; University of Mlaga, Spain ; Department of Computer Science of Aalborg University</orgName>
		</respStmt>
	</monogr>
	<note>Denmark. Francisco Javier Dez was born in Burgos. He is currently associate professor at the Department of Artificial Intelligence at the UNED, in Madrid, and Director of the Research Center on Intelligent Decision-Support Systems (CISIAD), at the same university</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
