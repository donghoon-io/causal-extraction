<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Counterfactual Fairness-aware Domain Generalization in Changing Environments *</title>
				<funder ref="#_EtbEgx2">
					<orgName type="full">National Natural Science Foundation of China program</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yujie</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of New Media and Communication</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chen</forename><surname>Zhao</surname></persName>
							<email>chenzhao@baylor.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Baylor University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minglai</forename><surname>Shao</surname></persName>
							<email>shaoml@tju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of New Media and Communication</orgName>
								<orgName type="institution">Tianjin University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Baoluo</forename><surname>Meng</surname></persName>
							<email>baoluo.meng@ge.com</email>
							<affiliation key="aff2">
								<orgName type="institution">GE Aerospace Research</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xujiang</forename><surname>Zhao</surname></persName>
							<email>xuzhao@nec-labs.com</email>
							<affiliation key="aff3">
								<orgName type="institution">NEC Labs America</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
							<email>haifeng@nec-labs.com</email>
							<affiliation key="aff3">
								<orgName type="institution">NEC Labs America</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Counterfactual Fairness-aware Domain Generalization in Changing Environments *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recognizing domain generalization as a commonplace challenge in machine learning, data distribution might progressively evolve across a continuum of sequential domains in practical scenarios. While current methodologies primarily concentrate on bolstering model effectiveness within these new domains, they tend to neglect issues of fairness throughout the learning process. In response, we propose an innovative framework known as Disentanglement for Counterfactual Fairness-aware Domain Generalization (DCFDG). This approach adeptly removes domain-specific information and sensitive information from the embedded representation of classification features. To scrutinize the intricate interplay between semantic information, domain-specific information, and sensitive attributes, we systematically partition the exogenous factors into four latent variables. By incorporating fairness regularization, we utilize semantic information exclusively for classification purposes. Empirical validation on synthetic and authentic datasets substantiates the efficacy of our approach, demonstrating elevated accuracy levels while ensuring the preservation of fairness amidst the evolving landscape of continuous domains.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The distribution shifts across sequential data domains drive the need for machine learning models with evolving domain generalization capabilities <ref type="bibr" target="#b6">[Wang et al., 2022]</ref>. It requires the development of models in learning invariant representations across distinct temporal periods, consequently enhancing generalization to evolving data distributions. The temporal alignment between source and target domains <ref type="bibr" target="#b7">[Zeng et al., 2023]</ref> contributes to adaptive machine learning solutions, which prove indispensable in dynamic environments or evolving data streams.</p><p>As methodologies extend domain generalization to continuously evolving environments, there is a tendency to prioritize accuracy, neglecting equitable model treatment across novel domain sequences. Fairness, a significant concern in machine learning, cannot be disregarded. Sensitive features, containing protected information, include attributes like race, gender, religion, or socioeconomic status, safeguarded by ethical considerations, legal regulations, or societal norms. For instance, during the COVID-19 pandemic, systemic algorithms exhibited discrimination against African American individuals in bank loans <ref type="bibr" target="#b4">[Miller, 2020]</ref>. Causal models have been widely applied in machine learning to address issues related to model fairness. Structural Causal Models (SCMs) <ref type="bibr" target="#b0">[Hitchcock and Pearl, 2001]</ref> provide a means of explaining machine learning model predictions. Analyzing causal graphs and paths helps understand how the model's predictions for different groups are formed, thereby identifying and addressing potential unfair factors. Simultaneously, to analyze fairness based on SCMs, a concept known as counterfactual fairness <ref type="bibr">[Kusner et al., 2017]</ref> has been introduced. This concept seeks to minimize the impact on predicted values when counterfactual interventions are applied to sensitive attributes. In the context of dynamically evolving environments, we propose a framework, denoted as Disentanglement for Counterfactual Fairness-aware Domain Generalization (DCFDG), designed to address the issue of counterfactual fairness.</p><p>Our objective can be succinctly summarized as aiming to enhance the model's generalization capacity across unfamiliar domain sequences while concurrently ensuring counterfactual fairness in decision-making. Therefore, to model the relationships among sensitive attributes, domain-specific information, and semantic information, we partition the exogenous variables into four latent variables: 1) semantic information caused by sensitive attributes: U s , 2) semantic information not caused by sensitive attributes: U ns , 3) domainspecific information caused by sensitive attributes: U v1 , and 4) domain-specific information not caused by sensitive attributes: U v2 . Among these, we posit that the distribution of semantic information remains invariant across all domains, whereas the distribution of domain-specific information varies with changes in the environment. Here, the data arXiv: <ref type="bibr">2309.13005v2 [cs.</ref>LG] 6 May 2024 feature X is composed of two components, wherein sensitive attribute A directly causes a subset of features (X s ), while another subset of features (X ns ) is not directly influenced by A but may still exhibit correlations with it. They are encoded in the latent space as the first two exogenous variables (i.e., U s and U ns ). The advantages of this partitioning will be elucidated in the causal structure of DCFDG (Section 4.1). By employing such an approach, we skillfully disentangle domainspecific information (i.e., U v1 and U v2 ) from the embedded representation of classification features, ensuring a reduction in the impact of environmental changes on the model while concurrently upholding its decision fairness. In conclusion, our contributions can be summarized as follows:</p><p>• We introduce a novel causal structure framework, DCFDG, which adeptly addresses data distributions that evolve within dynamic environments and are influenced by sensitive information. To the best of our knowledge, this is the first method of addressing counterfactual fairness issues in dynamic evolving environments.</p><p>• We analyze the Evidence Lower Bound (ELBO) that should be considered within evolving environments. Besides, we theoretically demonstrate the rationality of DCFDG.</p><p>• Experimental results conducted on both synthetic and realworld datasets demonstrate that DCFDG exhibits superior predictive capabilities compared to existing exogenous variable disentanglement methods, while concurrently ensuring fairness.</p><p>2 Related Work Domain Generalization in Changing Environments. To address the generalization issues in continuously changing environments, <ref type="bibr" target="#b0">Bai et al. [2022]</ref> involve passing the parameters of neural networks into a temporal encoder to train domain-specific parameters for each different domain. Another approach is to separately model environmental information in both features and labels, enabling the simultaneous handling of covariate shift and concept shift <ref type="bibr" target="#b6">[Qin et al., 2022]</ref>. <ref type="bibr" target="#b7">Zeng et al. [2023]</ref> explore aligning the data distribution in the training domain with that in an unseen domain as a means of addressing these challenges. Additionally, a classic work proposed a model-agnostic meta-learning (MAML) algorithm that learns to adapt quickly to new domains, demonstrating its effectiveness in few-shot domain generalization <ref type="bibr" target="#b0">[Finn et al., 2017]</ref>. Building upon this work, <ref type="bibr">Zhao et al. [2021a;</ref><ref type="bibr">2022;</ref><ref type="bibr">2023]</ref> introduces a method that incorporates fairness considerations.</p><p>Counterfactual Fairness with Variational Autoencoder. Consider X, A, Y , and U as data features, sensitive attributes, classification labels, and exogenous variables, respectively. Conditional Variational Autoencoder (CVAE) <ref type="bibr" target="#b6">[Sohn et al., 2015]</ref> extends this framework by incorporating additional conditional information, such as labels Y , during the generation process. <ref type="bibr" target="#b4">Louizos et al. [2017]</ref> propses a causal graph. In their CEVAE, A and X have an indirect connection through U , while A has both a direct and an indirect connection with Y simultaneously. However, this approach embeds A's information in U , rendering the counterfactual generation process of p(y|¬a, u) infeasible. To address this issue, an enhanced causal graph is proposed, assuming that X and Y are caused by both A and U <ref type="bibr" target="#b6">[Pfohl et al., 2019]</ref>. It employs Maximum Mean Discrepancy to regularize the generations, effectively removing A's information from U . Although this approach eliminates all A-related components from U , the ideal scenario should involve the removal of only the portion in U that is caused by A, rather than all A-related components. Therefore, DCEVAE <ref type="bibr" target="#b2">[Kim et al., 2021]</ref> is proposed to define X s ⊂ X as a subset of features caused by A whereas X ns ⊂ X is the other subset of irrelevant features to the intervention. The intervention on A should be imposed on X s , and X ns should be maintained in a counterfactual generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Structual Causal Model and Do-operator</head><p>Structural causal models (SCMs) are widely used in causal inference to model the causal relationships among variables. An SCM consists of a directed acyclic graph (DAG) and a set of structural equations that define the causal relationships among the variables in the graph <ref type="bibr" target="#b5">[Pearl, 2009;</ref><ref type="bibr">Spirtes et al., 2000;</ref><ref type="bibr">Pearl and Mackenzie, 2018]</ref>. The structural equation for an endogenous variable V i can be expressed as follows:</p><formula xml:id="formula_0">Vi = fV i (P aV i , UV i )<label>(1)</label></formula><p>where P a Vi denotes the parent set of V i in the graph, and U Vi denotes the set of exogenous variables that directly affect V i . The function f i represents the causal relationship between the parent variables and V i . SCMs are used to estimate causal effects and test causal hypotheses. By including sensitive variables in the graph and modeling their causal relationships with other variables, SCMs can adjust for sensitive and produce unbiased estimates of causal effects <ref type="bibr">[Hernán and Robins, 2018]</ref>.</p><p>Interventions on SCMs involve changing the value of a variable to a specified value. This can be represented mathematically using the do-operator, denoted by do(V i = v). The do-operator separates the effect of an intervention from the effect of other variables in the system. For example, if we want to investigate the effect of drug treatment on a disease outcome, we might use the do-operator to set the value of the treatment variable to "treated" and observe the effect on the outcome variable. In the following narrative, we will employ an alternative representation for the do-operator. For two variables: Ŷ , A and given exogenous variable set U ,</p><formula xml:id="formula_1">P ŶA←a(U )) = P Ŷ (U )|do(A = a)).</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Counterfactual Fairness Problem</head><p>Counterfactual fairness is a concept that models fairness using causal inference tools, first introduced by <ref type="bibr">[Kusner et al., 2017]</ref>. Given a predictive problem with fairness considerations, where A, X, Y , and Ŷ represent the sensitive attributes, remaining attributes, the output of interest, and model estimation respectively. A SCM G := ⟨U, V, F, P(u)⟩ is given, where V is the set of endogenous variables, P(v) ,u)=v} P(u), and U is the set of exogenous variables. the set of deterministic functions F is defined in V i = f Vi (P a Vi , U Vi ) like Eq.1. We can say predictor Ŷ is counterfactually fair, if</p><formula xml:id="formula_2">:= P(V = v) = {u|f V (V</formula><formula xml:id="formula_3">P ŶA←a(U ) = y|X = x, A = a = P ŶA←¬a(U ) = y|X = x, A = a (3)</formula><p>for all y and any value ¬a attainable by A. By setting A to both a and ¬a separately, Ŷ evolves into two distinct variants: ŶA←a and ŶA←¬a . From an intuitive perspective, counterfactual fairness seeks to ensure that the values of sensitive attribute A do not influence the distribution of predicted outcome Ŷ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Counterfactual Fairness in Evolving Environments</head><p>We consider classification tasks where the data distribution evolves gradually with time. In training stage, we are given T sequentially arriving source domains S = {D 1 , D 2 , ..., D T }, where each domain D t = {(x t i , a t i , y t i )} nt i=1 is comprised of n t labeled samples for t ∈ {1, 2, ..., T }. And x, a, and y denote the data features, the sensitive label, and the class label respectively. The trained model will be tested on M target domains T = {D T +1 , D T +2 , ..., D T +M }, D t = {(x t i , a t i , y t i )} nt i=1 (t ∈ {T + 1, T + 2, ..., T + M }), which are not available during training stage. For simplicity, we omit the index i whenever x t i refers to a single data point. Our primary objective is to enhance the robustness of the model on these unseen domains to achieve higher accuracy. Meanwhile, we are also committed to ensuring classification fairness across these M target domains, resulting in the following expression for Eq.3:</p><formula xml:id="formula_4">P Ŷ t A t ←a t (U t ) = y t |X t = x t , A t = a t = P Ŷ t A t ←¬a t (U t ) = y|X t = x t , A t = a t for t ∈ {T + 1, T + 2, ..., T + M }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methodology</head><p>In this section, we will introduce the causal structure of our model. Building upon this causal structure, we will further elaborate on the entire training process of the model, including the formulation of the loss function used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Causal Structure of DCFDG</head><p>The causal graph depicting two consecutive domains is illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. To achieve the counterfactual generation of p(y|¬a, u) for intervention on A, it is crucial to ensure that the exogenous variable U does not contain any part caused by A. Otherwise, there will be situations where intervention on A occurs, but the information caused by A in U remains unchanged, leading to an erroneous generation of y. To address the problem, we define X s ⊂ X as a subset of features caused by A, whereas X ns ⊂ X is the other subset of irrelevant features to the intervention. This is a common method of partitioning features in the context of fairness issues <ref type="bibr">[Zhao et al., 2021b;</ref><ref type="bibr">Grari et al., 2021;</ref><ref type="bibr" target="#b2">Kim et al., 2021]</ref>. For instance, considering the 'Sex' attribute in the Adult dataset as the sensitive attribute, we can broadly describe the characteristics of this attribute as X s = {Occupation, W orkclass, ...}, while the remaining features can be denoted as X ns . Similarly, let's define the exogenous variables of X ns and X s to be U ns and U s , respectively. We assume that U s and U ns are disentangled. Ideally, U s contains the portion caused by A, rather than the part correlated with A. Therefore, we need to disentangle U s from A.</p><p>On the other hand, U ns contains only the part correlated with A and does not require decoupling from A. However, in the face of a constantly changing environment, it becomes imperative to devise strategies for decoupling the domain-specific information from X s and X ns . To simulate dynamic environments, we adopt two variables, U v1 and U v2 , to capture the dynamic changes in the distributions of X s and X ns respectively, as they vary with the environments. For the domain D t at timestamp t, we represent U v1 and U v2 as U t v1 and U t v2 , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Network Architecture of DCFDG</head><p>Based on our causal graph, the corresponding neural network architecture is shown in Fig. <ref type="figure" target="#fig_1">2</ref>, encompassing both the inference and generation processes. During the inference stage, we employ four distinct encoders to model q(u s |x t s , a t ), q(u ns |x t ns ), q(u v1 |x t s ) and q(u v2 |x t ns ), respectively. The prior distributions for u s and u ns follow standard normal distributions. For the environmental variable sequences {U )). Hence, all the prior distributions are as follows:</p><formula xml:id="formula_5">p(us) = N (0, I); p(uns) = N (0, I); p(u t v1 ) = p(u t v1 |u &lt;t v1 ) = N (µ(u t v1 ), σ 2 (u t v1 )); p(u t v2 ) = p(u t v2 |u &lt;t v2 ) = N (µ(u t v2 ), σ 2 (u t v2 )),<label>(4)</label></formula><p>where the distribution p(u t v1 |u &lt;t v1 ) and p(u t v2 |u &lt;t v2 ) can be encoded using recurrent neural networks such as LSTM <ref type="bibr">[Hochreiter and Schmidhuber, 1997]</ref>. Wherein, at the initial state when t = 0, u 0 v1 and u 0 v2 is initialized to 0. In the generation phase, all latent variables are fed into two distinct decoders and a classifier to reconstruct X s , X ns , and Y . To enhance adaptability within a dynamically changing environment, we solely utilize environment-independent semantic information to reconstruct Y .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evidence Lower Bound of DCFDG</head><p>For any given time point t and domain</p><formula xml:id="formula_6">D t = {(x t i , a t i , y t i )} nt i=1</formula><p>, we employ U s and U ns to capture the invariant semantic information within the distribution, while U t v1 and U t v2 are utilized to encapsulate the domain-relevant information. Analogous to the Variational Autoencoder (VAE) <ref type="bibr">[Kingma and Welling, 2013]</ref>, in this context, q denotes the inference process, while p signifies the generation process. The detailed derivation process of the ELBO for DCFDG is provided in Appendix A.5. Sensitive Part. To encode representations containing sensitive information, we employ the sensitive attribute A to contribute to the encoding process. Therefore, the ELBO of the sensitive part can be represented as follows:</p><formula xml:id="formula_7">ELBOs = T t=1 {E q(us|x t s ,a t )q(u t v1 |u &lt;t v1 ,x t s ) log p x t s |us, u t v1 , a t -KL q(us|x t s , a t )||p(us) -KL q(u t v1 |u &lt;t v1 , x t s )||p(u t v1 |u &lt;t v1 ) }.<label>(5)</label></formula><p>Non-sensitive Part. Like the sensitive part, the ELBO of the non-sensitive part can be represented as follows:</p><formula xml:id="formula_8">ELBOns = T t=1 {E q(uns|x t ns )q(u t v2 |u &lt;t v2 ,x t ns ) log p x t ns |uns, u t v2 -KL q(uns|x t ns )||p(uns) -KL q(u t v2 |u &lt;t v2 , x t ns )||p(u t v2 |u &lt;t v2 ) }.<label>(6)</label></formula><p>Prediction Generation. We use semantic representations and sensitive attributes for classification and the loss is:</p><formula xml:id="formula_9">L cla = T t=1 E q(us|x t s ,a t )q(uns|x t ns ) log p y t |us, uns, a t . (7)</formula><p>Final ELBO of DCFDG. Taking into account the three aforementioned components, we derive the final ELBO as follows:</p><formula xml:id="formula_10">log p(x 1:T s , x 1:T ns , y 1:T |a 1:T ) ≥ ELBOs + ELBOns + L cla = ELBO. (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>During the training process, it is imperative to maximize this ELBO, consequently rendering its negative counterpart, the -ELBO , a constituent of the objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Counterfactual Fairness Loss of DCFDG</head><p>The essence of counterfactual fairness lies in minimizing the impact of A on the predicted value Ŷ . Therefore, for our model, if the condition:</p><formula xml:id="formula_12">p(ŷ t |a t , us, uns) = p(ŷ t |¬a t , us, uns) (9)</formula><p>is satisfied, the model's predictions attain complete counterfactual fairness in such a case. To earnestly achieve fairness in classification, it is imperative to augment the objective function with a fairness regularization term:</p><formula xml:id="formula_13">L f = T t=1 E q(us|x t s ,a t )q(y t |x t ns ) ||p(y t |a t , us, uns) -p(y t |¬a t , us, uns)||2 , (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>where for the sake of simplicity, every attribute A is treated as a binary variable in this paper, and ¬a denotes the negation of its original value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Adversarial Loss of DCFDG</head><p>Building upon the analysis of causal structure, U s is concurrently disentangled from both A and U ns . In other words, U s is simultaneously independent of both A and U ns (i.e., q(u s , a t , u ns ) = q(u s )q(a t , u ns )). Hence, the disentanglement objective is equivalent to minimizing the KL divergence between q(u s , a t , u ns ) and q(u s )q(a t , u ns ). However, computing this KL divergence directly is infeasible, prompting us to leverage an approach akin to the one proposed in Fac-torVAE <ref type="bibr" target="#b2">[Kim and Mnih, 2018]</ref>, which bears resemblance to <ref type="bibr">GAN-like [Goodfellow et al., 2014]</ref> principles, to address this challenge. We begin by employing a discriminator D, which outputs a probability that a set of samples originates from the distribution q(u s , a t , u ns ) rather than q(u s )q(a t , u ns ).</p><p>Hence, we can approximate the KL divergence as follows using the loss function L T C about D:</p><formula xml:id="formula_15">LT C = T t=1</formula><p>KL q(us, a t , uns)∥q(us)q(a t , uns)</p><formula xml:id="formula_16">≈ T t=1 E q(us,a t ,uns) log D(us, a t , uns) 1 -D(us, a t , uns) . (<label>11</label></formula><formula xml:id="formula_17">)</formula><p>Furthermore, to train the discriminator D, we should maximize M D :</p><formula xml:id="formula_18">MD = T t=1 E q(us,a t ,uns) log(D([us, a t , uns])) + E q(us)q(a t ,uns) log (1 -D([us, a t , uns])) = T t=1</formula><p>E q(us,a t ,uns) log(D([us, a t , uns]))</p><formula xml:id="formula_19">+ E q(us,a t ,uns) log (1 -D(perm[us, a t , uns])) ,<label>(12)</label></formula><p>Algorithm 1 Optimization procedure for DCFDG end for 14: end for where perm[u s , a t , u ns ] denotes the randomized alteration of the relative sequence between (a t , u ns ) and u s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Ultimate Objective Function</head><p>We denote all parameters of DCFDG, including all encoders, decoders, and prior networks (LSTMs), as θ, and the parameters of discriminator D as ψ. Summing up the preceding sections, the training objectives of the model can be summarized into two phases as follows:</p><formula xml:id="formula_20">min θ LDCF DG := -ELBO + λ f L f + λtcLT C , (13) max ψ MD. (<label>14</label></formula><formula xml:id="formula_21">)</formula><p>After the completion of training within the DCFDG framework (Algorithm. 1), we require the trained static feature extractor E s and E ns to obtain semantic information (u s and u ns ). Finally, the classifier C is utilized for prediction by inputting both u s and u ns alongside sensitive attribute a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Theoretical Guarantee of DCFDG</head><p>Due to the usual representation of ELBO as a sum of multiple terms, we delve into its equivalent optimization objective in theoretical analysis. Lemma 1. In the vanilla VAE, the KL divergence KL(q(u|x)||p(u|x)) can be represented as</p><formula xml:id="formula_22">KL(q(u|x)||p(u)) -E q(u|x) [log p(x|u)] + log p(x). (<label>15</label></formula><formula xml:id="formula_23">)</formula><p>Based on Lemma 1, we can derive the Evidence Lower Bound (ELBO) of the vanilla VAE in the following formula:</p><formula xml:id="formula_24">ELBO = log p(x) -KL(q(u|x)||p(u|x)) (16)</formula><p>It means that optimizing the ELBO of VAEs is equivalent to optimizing KL(q(u|x)||p(u|x)). We denote the samples from the source domains as X 1:T s and X 1:T ns , while the features of samples from the unseen target domains are represented as X T +m s and X T +m ns for m ≥ 1. The relationship between the source domains and the target domains can be expressed as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem</head><p>1.</p><formula xml:id="formula_25">The KL divergence between q(u s , u ns |x T +m s , a T +m , x T +m ns )</formula><p>and the unknown domain-invariant ground truth distribution p(u s , u ns |x T +m s , a T +m , , x T +m ns ) can be bounded as follows:</p><formula xml:id="formula_26">KL(q(us, uns|x T +m , a T +m )||p(us, uns|x T +m , a T +m ) ≤ inf I∈I [ i∈I βi(KL(q(us|x 1:T,i s , a 1:T,i )||p(us|x 1:T,i s )) + KL(q(uns|x 1:T,i ns , a 1:T,i )||p(uns|x 1:T,i ns )))],</formula><p>where x 1:T,i s , a 1:T,i and x 1:T,i This inequality expresses that the ELBO on the target domains can be optimized by separately optimizing the ELBO concerning X s and X ns on the source domains. Therefore, Theorem 1 ensures that DCFDG is a rational and effective methodology. The detailed proof of Theorem 1 is provided in Appendix A.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>FairCircle is a synthetic dataset containing 12 domains. For each domain, followed by <ref type="bibr">[Zafar et al., 2017]</ref>, we generate 2000 binary class labels uniformly at random and assign a two-dimensional feature vector x = [x s , x ns ] T per label by sampling from two distinct Gaussian distributions: P(x|y = 0) = N (µ 0 , [10, 1; 1, 3]) and P(x|y = 1) = N (µ 1 , [5, 1; 1, 5]), where µ 0 and µ 1 will changed by domain. Sensitive attributes of data samples are drawn from a Bernoulli distribution P(a = 1) = P(x ′ |y=1)</p><formula xml:id="formula_27">P(x ′ |y=1)+P(x ′ |y=0)</formula><p>, where x ′ = [cos(ϕ), -sin(ϕ); sin(ϕ), cos(ϕ)][x s ; 1] is simply a rotated vector related to x s . The ϕ controls the correlation between the sensitive attribute and the class labels. The ϕ in each domain is a random number between π 8 and π 4 . The closer ϕ is to zero, the higher the correlation. To construct multiple sequentially changing domains, we uniformly sampled 12 values of µ 0 and µ 1 from two circular arcs with radii of 25 and 34, respectively, to simulate the variation in data distribution. The visualization of the dataset is provided in Appendix B.1.</p><p>Adult <ref type="bibr" target="#b3">[Kohavi and others, 1996]</ref> contains a diverse set of attributes pertaining to individuals in the United States. The dataset is often utilized to predict whether an individual's annual income exceeds 50,000 dollars, making it a popular choice for binary classification tasks. We categorize gender as a sensitive attribute. Income is designated as the dependent variable Y . Race, age, and country of origin constitute the set X ns , while the remaining variables comprise the set X s <ref type="bibr">[Zhao et al., 2021b;</ref><ref type="bibr">Grari et al., 2021;</ref><ref type="bibr" target="#b2">Kim et al., 2021]</ref>. We divided the samples into 18 domains based on age, ranging from younger to older. Specifically, the source domain tends to represent a younger demographic, while the target domain tends to represent an older demographic. Chicago Crime <ref type="bibr" target="#b7">[Zhao and Chen, 2020</ref>] dataset includes a comprehensive compilation of criminal incidents in different communities across Chicago city in 2015. We use race (i.e., black and non-black) as the sensitive attribute. To better delineate between X s and X ns , we measured the Pearson Product-Moment Correlation Coefficients (PPMCC) values between each feature and sensitive attribute (Appendix B.2). This was done to gauge their correlation and aid in the partitioning process. Grocery count, per capita income, aged 25+ without high school diploma, and housing crowd of origin constitute the set X ns , while the remaining variables comprise the set X s . The dataset was collected over time, and as a result, we partition the data into 18 domains based on chronological order. The target domain consists of the most recent samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Baseline Methods</head><p>We evaluate the proposed DCFDG against seven baseline methods. These baselines are selected from two perspectives: approaches that utilize causal structures to tackle evolving domain generalization <ref type="bibr">(DIVA [Ilse et al., 2020]</ref>, LSSAE <ref type="bibr" target="#b6">[Qin et al., 2022]</ref>, and MMD-LSAE <ref type="bibr" target="#b6">[Qin et al., 2023]</ref>), and methods that utilize causal structures to address counterfactual fairness <ref type="bibr">(CVAE [Sohn et al., 2015]</ref>, CEVAE <ref type="bibr" target="#b4">[Louizos et al., 2017]</ref>, mCEVAE <ref type="bibr" target="#b6">[Pfohl et al., 2019]</ref>, and DCEVAE <ref type="bibr" target="#b2">[Kim et al., 2021]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation Metrics</head><p>We employed two metrics, total causal effect and counterfactual effect, to evaluate the fair classification. Assuming A is the intervention target of the do-operator, Y is influenced by this intervention. The post-intervention distribution of Y mentioned in Section 3.1 can be further abbreviated as P(y a ). Definition 1 (Total Causal Effect (TCE) <ref type="bibr" target="#b5">[Pearl, 2009]</ref>). The total causal effect of the value change of A from a to ¬a on Y = y is given by T CE(a, ¬a) = |P(y a ) -P(y ¬a )|. Definition 2 (Counterfactual Effect (CE) [Shpitser and <ref type="bibr">Pearl, 2008]</ref>). Given context O = o, the counterfactual effect of the value change of A from a to ¬a on Y = y is given by CE(a, ¬a|o) = |P(y a |o) -P(y ¬a |o)|.</p><p>Smaller TCE and CE indicate that the prediction results are more stable in the counterfactual generation of changing the sensitive attribute, implying greater fairness <ref type="bibr" target="#b6">[Wu et al., 2019]</ref>.</p><p>For the Adult dataset, we set context of counterfactual effect as O = {race, native country}. For the Crime dataset, we set context of counterfactual effect as O = {grocery count, per capital income}. In both two datasets, o ij denotes the first attribute as i and the second attribute as j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Experimental Setup</head><p>We partitioned the domains into source, intermediary, and target domains by the ratio ( 1 2 : 1 6 : 1 3 ). The source domains are employed for training the DCFDG, while the intermediary domains serves as the validation set. All evaluations are conducted within the target domains. For the FairCircle dataset, direct computation of its counterfactual effect (CE) is unfeasible because its features are randomly sampled continuous numerical values. As for the other two datasets, both the total causal effect (TCE) and CE were employed for evaluation purposes. For all the encoders, decoders, classifiers, and discriminators, we employed the most common fully connected layers and ReLU activation functions. The specific architecture details can be found in Appendix B.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Results Analysis</head><p>Overall Performance. We computed the mean performance across all testing domains, as depicted in Table <ref type="table" target="#tab_2">1</ref>. Smaller values of TCE and CE indicate closer adherence of the classification outcomes to counterfactual fairness. To facilitate observation, the reported results encapsulate the values of TCE and CE across all outcomes. Across the three datasets, DCFDG consistently demonstrates favorable generalization capabilities to unknown domains compared to other approaches, achieving optimal performance. Notably, its pronounced superiority in accuracy on the FairCircle dataset is believed to stem from the discernible advantage exhibited as the data distribution between each domain varies to a greater extent. Regarding TCE and CE, DCFDG consistently achieves optimal or near-optimal outcomes. This underscores the resilience of our approach to maintaining high performance while simultaneously upholding fairness principles. For the Chicago Crime dataset, while there hasn't been a substantial improvement in decision accuracy, it is noteworthy that both its TCE and CE values are considerably lower than the highest accuracy method: DIVA. In other words, in the context of comparable accuracy levels, fairness significantly outperforms alternative methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(f) TCE on Crime</head><p>Figure <ref type="figure">3</ref>: Accuracy and total causal effect for each testing domain. The 1st, 3rd, and 5th figures illustrate the accuracy curves, while the 2nd, 4th, and 6th figures depict the total causal effect curves. Performance Across Each Domain. In Figure <ref type="figure">3</ref>, we present the results across each testing domain. For the Fair-Circle dataset, there are four testing domains, while the Adult and Chicago Crime datasets have six testing domains each. The 1st, 3rd, and 5th figures represent accuracy outcomes, with higher curves indicating superior performance. The 2nd, 4th, and 6th figures illustrate TCE results, with lower curves signifying enhanced compliance with counterfactual fairness, concurrently denoted by the shaded regions representing standard deviations. Across all testing domains, DCFDG consistently maintains superior accuracy and minimal TCE values. Regarding the tabulated data encompassing the mean and standard deviation of all three metrics across each domain, we present this information uniformly within the Appendix B.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Ablation Study</head><p>We evaluate the effect of components in the design of DCFDG's objective. We have specifically examined two variants of DCFDG as follows.</p><p>Without Disentanglement. We attempted to refrain from decoupling features into domain-specific and semantic information, opting instead for utilizing a globally modeled dynamic Gaussian distribution for predictions. As indicated in Table <ref type="table" target="#tab_3">2</ref>, the absence of feature decoupling adversely impacted classification fairness, particularly evident in the Crime dataset.</p><p>Without Fairness Loss. We eliminated the loss associated with counterfactual fairness to assess changes in the outcomes. Despite achieving a marginal advantage in prediction accuracy on the adult dataset, a sharp increase in the TCE value resulted in unfair classification outcomes (Table <ref type="table" target="#tab_3">2</ref>).</p><p>Experimental results regarding the CE values can be found in Appendix B.4. The above experiments indicate that decoupling domain-specific information and incorporating the fairness loss are both indispensable for ensuring counterfactual fairness.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Fairness-accuracy Trade-off</head><p>Due to the absence of fairness loss in certain baselines, we compare our method with four baselines about the trade-off between accuracy and fairness on target domains under different parameters. We varied the parameter λ f across five values ([0.02, 0.1, 0.2, 0.5, 1]) to obtain the results of each baseline under these five settings. In Figure <ref type="figure" target="#fig_5">4</ref>, the horizontal axis represents TCE values, and the vertical axis represents accuracy, indicating that data points tending towards the upper-left corner exhibit superior performance. Experimental results regarding the CE values can be found in Appendix B.5. All the results demonstrate that DCFDG achieves the best overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In summary, this paper has proposed a novel framework, DCFDG, to address issues of fairness within continuously evolving dynamic environments. This method disentangles exogenous variables based on the relationships among sensitive attributes, domain-specific information, and semantic information, partitioning them into four latent variables. By leveraging these latent variables, a causal structure is constructed for our method. We establish an appropriate model and optimize the corresponding objective function through this causal graph. Theoretical analysis and experimental validation attest to the efficacy of DCFDG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Introduction</head><p>This is the supplementary material for the paper 'Towards Counterfactual Fairness-aware Domain Generalization in Changing Environments'. A.3 Theoretical Guarantee of DCFDG Lemma 2. In the vanilla VAE, the KL divergence KL(q(u|x)||p(u|x)) can be represented as KL(q(u|x)||p(u)) -E q(uc|x) [log p(x|u c )] + log p(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Notations</head><p>(17) Based on Lemma 1, we can derive the Evidence Lower Bound (ELBO) of the vanilla VAE in the following fomula: ELBO = log p(x) -KL(q(u|x)||p(u|x)) (18) It means that optimizing the ELBO of VAEs is equivalent to optimizing KL(q(u|x)||p(u|x)). We denote the samples from the training domain as X t s and X t ns for t ∈ {1, 2, ..., T }, while the features of samples from the unseen testing domain are represented as x T +m s and X T +m ns for m ≥ 1. And all the training data can be represented as X 1:T s and X 1:T ns . Definition 1. Based on the previous work <ref type="bibr" target="#b6">[Wang et al., 2021]</ref>, we will consider scenarios involving thge sensitive attribute A and the partitioning of X t into X t s and X t ns . There exists a non-empty feasible set I which is defined as</p><formula xml:id="formula_28">I ={I|q(u s , u ns |x T +m s , a T +m , x T +m ns ) ≤ i∈I β i q(u s , u ns |x 1:T,i s , a 1:T,i , x 1:T,i ns )} ∩ {I|ϕ c (x T +m s , a T +m , x T +m ns ) = ϕ c (x 1:T,i s , a 1:T,i , x 1:T,i ns ), (<label>19</label></formula><formula xml:id="formula_29">)</formula><p>where I is the index set, and ϕ c is a function to extract features' semantic information. Theorem 2. The KL divergence between q(u s , u ns |x T +m s , a T +m , x T +m ns ) and the unknown domain-invariant ground truth distribution p(u s , u ns |x T +m s , a T +m , x T +m ns ) can be bounded as follows:</p><formula xml:id="formula_30">KL(q(u s , u ns |x T +m s , a T +m , x T +m ns )||p(u s , u ns |x T +m s , a T +m , x T +m ns )) ≤ inf I∈I [ i∈I β i (KL(q(u s |x 1:T,i s , a 1:T,i )||p(u s |x T,i s )) + KL(q(u ns |x 1:T,i ns )||p(u ns |x 1:T,i ns )))],<label>(20)</label></formula><p>where x 1:T,i s , a 1:T,i and x 1:T,i ns denotes features with index i in source domains. The feasible set I [Wang et al., 2021] is defined in Definition 1.</p><p>This inequality expresses that the ELBO on the target domains can be optimized by separately optimizing the ELBO concerning X s and X ns on the source domains. Therefore, Theorem 2 ensures that DCFDG is a rational and effective methodology.</p><p>A.4 Proof for Theorem 2</p><formula xml:id="formula_31">∀I ∈ I,we have KL(q(u s , u ns |x T +m s , a T +m , x T +m ns )||p(u s , u ns |x T +m s , a T +m , x T +m ns )) = us uns q(u s , u ns |x T +m s , a T +m , x T +m ns )log q(u s , u ns |x T +m s , a T +m , x T +m ns ) p(u s , u ns |x T +m s , a T +m , x T +m ns ) ≤ i∈I us uns β i q(u s , u ns |x 1:T,i s , a 1:T,i , x 1:T,i ns )log q(u s , u ns |x 1:T,i s , a 1:T,i , x 1:T,i ns ) p(u s , u ns |x 1:T,i s , a 1:T,i , x 1:T,i ns ) = i∈I us uns β i q(u s |x 1:T,i s , a 1:T,i )q(u ns |x 1:T,i ns )log q(u s |x t s , a 1:T,i )q(u ns |x 1:T,i ns ) p(u s |x 1:T,i s , a 1:T,i )p(u ns |x 1:T,i ns ) = i∈I us uns β i q(u s |x 1:T,i s , a 1:T,i )q(u ns |x 1:T,i ns )[log q(u s |x 1:T,i s , a 1:T,i ) p(u s |x 1:T,i s , a 1:T,i ) + log q(u ns |x 1:T,i ns ) p(u ns |x 1:T,i ns ) ] = i∈I us uns β i q(u s |x 1:T,i s , a 1:T,i )q(u ns |x 1:T,i ns )log q(u s |x 1:T,i s , a 1:T,i ) p(u s |x 1:T,i s , a 1:T,i ) + i∈I us uns β i q(u s |x 1:T,i s , a 1:T,i )q(u ns |x 1:T,i ns )log q(u ns |x 1:T,i ns ) p(u ns |x 1:T,i ns ) = i∈I us β i q(u s |x 1:T,i s , a 1:T,i )log q(u s |x 1:T,i s , a 1:T,i ) p(u s |x 1:T,i s , a 1:T,i ) uns q(u ns |x 1:T,i ns ) + i∈I uns β i q(u ns |x 1:T,i ns )log q(u ns |x 1:T,i ns ) p(u ns |x 1:T,i ns ) us q(u s |x 1:T,i s , a 1:T,i ) = i∈I us β i q(u s |x 1:T,i s , a 1:T,i )log q(u s |x 1:T,i s , a 1:T,i ) p(u s |x 1:T,i s , a 1:T,i ) + i∈I uns β i q(u ns |x 1:T,i ns )log q(u ns |x 1:T,i ns ) p(u ns |x 1:T,i ns ) ≤ i∈I β i (KL(q(u s |x 1:T,i s , a 1:T,i )||p(u s |x 1:T,i s , a 1:T,i ) + KL(q(u ns |x 1:T,i ns )||p(u ns |x 1:T,i ns ))),<label>(21)</label></formula><p>where the inequality holds for any I ∈ I, therefore, its infimum can be taken as follows:</p><formula xml:id="formula_32">KL(q(u s , u ns |x T +m s , a T +m , x T +m ns )||p(u s , u ns |x T +m s , a T +m , x T +m ns )) ≤ inf I∈I [ i∈I β i (KL(q(u s |x 1:T,i s , a 1:T,i )||p(u s |x 1:T,i s , a 1:T,i ) + KL(q(u ns |x 1:T,i ns )||p(u ns |x 1:T,i ns )))].<label>(22)</label></formula><p>A.5 Derivation of ELBO for DCFDG</p><p>We assume the prior distribution of latent variables U s and U ns satisfy Markov property like the following equations:</p><formula xml:id="formula_33">p(u t v1 ) = p(u t v1 |u &lt;t v1 ), p(u t v2 ) = p(u t v2 |u &lt;t v2 ).<label>(23)</label></formula><p>The joint distribution of data and latent variables is:</p><formula xml:id="formula_34">p(x 1:T s , x 1:T ns , y 1:T , u s , u ns , u 1:T v1 , u 1:T v2 |a 1:T ) = T t=1 p(x t s |u s , u t v1 , a t )p(x t ns |u ns , u t v2 )p(y t |u s , u ns , a t ) p(u s )p(u ns )p(u t v1 )p(u t v2 ).<label>(24)</label></formula><p>According to the causal structure of DCFDG, we can draw the evidence lower bound for log p(x 1:T s , x 1:T ns , y 1:T |a 1:T ) as: log p(x 1:T s , x 1:T ns , y 1:T |a 1:T ) ≥E q log p(x 1:T s , x 1:T ns , y 1:T , u s , u ns , u 1:T v1 , u 1:T v2 |a 1:T ) q(u s , u ns , u 1:T v1 , u 1:T v2 |a 1:T , x 1:T s , x 1:T ns , y 1:T ) </p><formula xml:id="formula_35">=E q log T t=1 p(x t s |u s , u t v1 , a t )p(x t ns |u ns , u t v2 )p(y t |u s , u ns , a t )p(u s )p(u ns )p(u t v1 )p(u t v2 ) T t=1 q(u s |x t s , a t )q(u ns |x t ns )q(u t v1 |u &lt;t v1 , x t s )q(u t v2 |u &lt;t v2 , x t s ) =E q - T t=1 log q(u s |x t s , a t ) p(u s ) - T t=1 log q(u ns |x t ns ) p(u ns ) - T t=1 log q(u t v1 |u &lt;t v1 , x t s ) p(u t v1 ) - T t=1 log q(u t</formula><p>The final greater than or equal to sign is derived using the Jensen's inequality, thus concluding the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Inplementation of Experiments</head><p>B.1 Visualization of Fair-circle dataset.            </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Causal Structure of DCFDG. The figure depicts the causal structures across two consecutive domains, wherein, due to the gradual evolution of the environment, we posit a correlation between the environmental information of each domain and that of the preceding domain.</figDesc><graphic coords="3,60.08,54.00,230.85,69.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Network Architecture of DCFDG. We separately decouple the environmental information Uv1 and Uv2 for Xs and Xns, and employ the adversarial loss (Section 4.5) to remove sensitive information from Us. Semantic information Us and Uns are used for classification.</figDesc><graphic coords="4,113.22,54.00,385.55,129.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>ns denotes features with index i in source domains. The feasible set I [Wang et al., 2021] and constant β i are defined in Appendix A.3. Semantic information u s and u ns are defined in Section 4.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Fairness-accuracy Trade-off on Adult and Crime. Each baseline is represented by five data points, corresponding to the outcomes under five distinct fairness parameter λ f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Visualization of Fair-circle dataset. From left to right, these are respectively the training set, validation set, and test set.</figDesc><graphic coords="13,129.60,95.05,352.81,220.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Fairness-accuracy Trade-off on Adult and Crime. Each baseline is represented by five data points, corresponding to the outcomes under five distinct fairness parameter λ f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Input: sequential source labeled datasets S with T domains; static feature extractor E s , E ns ; dynamic inference networks E v1 , E v2 and their corresponding prior networks (LSTM)F v1 , F v2 ; decoder D s , D ns ; discriminator D; classifier C. 2: Initialize E s , E ns , E v1 , E v2 , F v1 , F v2 , D s , D ns , D, C Update E s , E ns ,E v1 , E v2 ,F v1 , F v2 ,D s , D ns and C by L DCF DG</figDesc><table><row><cell cols="2">3: Assign u 0 v1 , u 0 v2 ← 0</cell></row><row><cell cols="2">4: for t = 1, 2, ..., T do</cell></row><row><cell>5: 6:</cell><cell>Generate prior distribution p(u t v1 |u &lt;t v1 ) via F v1 Generate prior distribution p(u t v2 |u &lt;t v2 ) via F v2</cell></row><row><cell>7:</cell><cell>for i = 1, 2, ... do</cell></row><row><cell>8:</cell><cell>Sample a batch of data (x t s , x t ns , a t , y t ) from D t</cell></row><row><cell>9:</cell><cell>Calculate L DCF DG by Eq. 13</cell></row><row><cell>10:</cell><cell></cell></row><row><cell>11:</cell><cell>Calculate M D by Eq. 12</cell></row><row><cell>12:</cell><cell>Update D by M D</cell></row><row><cell>13:</cell><cell></cell></row></table><note><p>1:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Accuracy outcomes and TCE value results across the three datasets. Within the experiment, the variable O comprises two attributes, where oij denotes the first attribute as i and the second attribute as j.</figDesc><table><row><cell></cell><cell cols="2">FairCircle</cell><cell></cell><cell></cell><cell>Adult</cell><cell></cell><cell cols="3">Chicago Crime</cell></row><row><cell>Methods</cell><cell>Acc ↑</cell><cell>TCE ↓ (×10)</cell><cell>Acc ↑</cell><cell>TCE ↓ (×10)</cell><cell>CE ↓ (×10) o00 o01 o10 o11</cell><cell>Acc ↑</cell><cell>TCE ↓ (×10)</cell><cell>o00</cell><cell>CE ↓ (×10) o01 o10 o11</cell></row><row><cell>DIVA [Ilse et al., 2020]</cell><cell>69.10</cell><cell>1.15</cell><cell>68.04</cell><cell>0.81</cell><cell cols="2">0.88 0.62 0.34 0.86 56.19</cell><cell>1.68</cell><cell cols="2">1.68 1.46 1.84 1.75</cell></row><row><cell>LSSAE [Qin et al., 2022]</cell><cell>89.25</cell><cell>5.03</cell><cell>57.79</cell><cell>1.91</cell><cell cols="2">2.96 3.64 1.70 1.67 53.72</cell><cell>0.85</cell><cell cols="2">0.77 0.93 0.90 0.77</cell></row><row><cell cols="2">MMD-LSAE [Qin et al., 2023] 82.79</cell><cell>0.70</cell><cell>60.34</cell><cell>1.60</cell><cell cols="2">1.17 1.35 1.05 1.68 53.83</cell><cell>0.35</cell><cell cols="2">0.23 0.41 0.36 0.31</cell></row><row><cell>CVAE [Sohn et al., 2015]</cell><cell>49.99</cell><cell>0.18</cell><cell>61.83</cell><cell>0.56</cell><cell cols="2">0.53 0.55 0.51 0.57 54.43</cell><cell>0.72</cell><cell cols="2">0.67 0.70 0.74 0.77</cell></row><row><cell>CEVAE [Louizos et al., 2017]</cell><cell>49.99</cell><cell>0.34</cell><cell>62.49</cell><cell>0.69</cell><cell cols="2">0.68 0.69 0.69 0.69 54.23</cell><cell>0.42</cell><cell cols="2">0.40 0.43 0.42 0.44</cell></row><row><cell>mCEVAE [Pfohl et al., 2019]</cell><cell>63.30</cell><cell>0.28</cell><cell>61.05</cell><cell>0.48</cell><cell cols="2">0.45 0.35 0.50 0.48 51.83</cell><cell>0.01</cell><cell cols="2">0.01 0.01 0.01 0.01</cell></row><row><cell>DCEVAE [Kim et al., 2021]</cell><cell>53.25</cell><cell>0.18</cell><cell>62.69</cell><cell>0.39</cell><cell cols="2">0.39 0.38 0.39 0.38 51.29</cell><cell>0.44</cell><cell cols="2">0.48 0.45 0.44 0.39</cell></row><row><cell>DCFDG (Ours)</cell><cell>88.70</cell><cell>0.12</cell><cell>69.85</cell><cell>0.22</cell><cell cols="2">0.10 0.01 0.17 0.26 55.93</cell><cell>0.01</cell><cell cols="2">0.01 0.01 0.01 0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Ablation study results across the two datasets. The results in the table represent the mean values of all test domain outcomes.</figDesc><table><row><cell></cell><cell cols="2">Adult</cell><cell cols="2">Chicago Crime</cell></row><row><cell>Metric</cell><cell>Acc ↑</cell><cell>TCE ↓ (×10)</cell><cell>Acc ↑</cell><cell>TCE ↓ (×10)</cell></row><row><cell cols="4">w/o disentanglement 71.48 0.47 54.43</cell><cell>1.61</cell></row><row><cell>w/o fairness loss</cell><cell cols="3">72.24 2.76 54.89</cell><cell>1.75</cell></row><row><cell>DCFDG</cell><cell cols="3">69.85 0.22 55.93</cell><cell>0.01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Important notations and their description.</figDesc><table><row><cell cols="2">Notation Description</cell><cell></cell></row><row><cell>T</cell><cell cols="2">Total number of training domains</cell></row><row><cell>t</cell><cell>Indices of domains</cell><cell></cell></row><row><cell>D t</cell><cell>Domain at time t</cell><cell></cell></row><row><cell>X s</cell><cell cols="2">Features caused by sensitive attribute</cell></row><row><cell>X ns</cell><cell cols="2">Features not caused by sensitive attribute</cell></row><row><cell>A</cell><cell>Sensitive attribute</cell><cell></cell></row><row><cell>Y</cell><cell>Ground truth of samples</cell><cell></cell></row><row><cell>U s</cell><cell cols="2">Semantic information caused by sensitive attribute</cell></row><row><cell>U ns</cell><cell cols="2">Semantic information not caused by sensitive attribute</cell></row><row><cell>U v1</cell><cell cols="2">Domain specific information caused by sensitive attribute</cell></row><row><cell>U v2 E s E ns</cell><cell cols="2">Domain specific information not caused by sensitive attribute Encoder for encoding U s Encoder for encoding U ns</cell></row><row><cell>E v1</cell><cell cols="2">Encoder for encoding U v1</cell></row><row><cell>E v2 D s D ns</cell><cell cols="2">Encoder for encoding U v2 Decoder for decoding X s Decoder for decoding X ns</cell></row><row><cell>C</cell><cell>Classifier for predicting</cell><cell>Ŷ</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Product-Moment Correlation Coefficients (PPMCC) of all three datasets.</figDesc><table><row><cell></cell><cell>Xs</cell><cell>Xns</cell><cell>Y</cell></row><row><cell>Fair-circle</cell><cell cols="3">.0910 .0186 .1249</cell></row><row><cell>Adult</cell><cell cols="3">.1892 .0597 .2158</cell></row><row><cell cols="4">Chicago Crime .0341 .0029 .1355</cell></row><row><cell>B.3 Specific Model Architecture</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Implementation of Encoder (E s and E ns ).</figDesc><table><row><cell>#</cell><cell>Layer</cell></row><row><cell>1</cell><cell>Linear(in=d, output=128)</cell></row><row><cell>2</cell><cell>ReLU</cell></row><row><cell>3</cell><cell>Linear(in=128, output=128)</cell></row><row><cell>4</cell><cell>ReLU</cell></row><row><cell>5</cell><cell>Linear(in=128, output=128)</cell></row><row><cell>6</cell><cell>ReLU</cell></row><row><cell>7</cell><cell>Linear(in=128, output=d)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Implementation of Encoder (E v1 and E v2 ).</figDesc><table><row><cell>#</cell><cell>Layer</cell></row><row><cell>1</cell><cell>Linear(in=d, output=128)</cell></row><row><cell>2</cell><cell>ReLU</cell></row><row><cell>3</cell><cell>Linear(in=128, output=128)</cell></row><row><cell>4</cell><cell>ReLU</cell></row><row><cell>5</cell><cell>Linear(in=128, output=128)</cell></row><row><cell>6</cell><cell>ReLU</cell></row><row><cell>7</cell><cell>Linear(in=128, output=d)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Implementation of Decoder (D s and D ns ).</figDesc><table><row><cell>#</cell><cell>Layer</cell></row><row><cell>1</cell><cell>Linear(in=d, output=16)</cell></row><row><cell>2</cell><cell>BatchNorm</cell></row><row><cell>3</cell><cell>LeakyReLU(0.2)</cell></row><row><cell>4</cell><cell>Linear(in=16, output=64)</cell></row><row><cell>5</cell><cell>BatchNorm</cell></row><row><cell>6</cell><cell>LeakyReLU(0.2)</cell></row><row><cell>7</cell><cell>Linear(in=64, output=128)</cell></row><row><cell>8</cell><cell>BatchNorm</cell></row><row><cell>9</cell><cell>ReLU</cell></row><row><cell>10</cell><cell>Linear(in=128, output=d)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Implementation of Classifier C.</figDesc><table><row><cell>#</cell><cell>Layer</cell></row><row><cell>1</cell><cell>Linear(in=d, output=d × 4)</cell></row><row><cell>2</cell><cell>ReLU</cell></row><row><cell>3</cell><cell>Linear(in=d × 4, output=d)</cell></row><row><cell>4</cell><cell>ReLU</cell></row><row><cell>5</cell><cell>Linear(in=d, output=d/4)</cell></row><row><cell>6</cell><cell>ReLU</cell></row><row><cell>7</cell><cell>Linear(in=d/4, output=2)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Implementation of Discriminator D.</figDesc><table><row><cell>#</cell><cell>Layer</cell></row><row><cell>1</cell><cell>Linear(in=d, output=128)</cell></row><row><cell>2</cell><cell>ReLU</cell></row><row><cell>3</cell><cell>Linear(in=128, output=256)</cell></row><row><cell>4</cell><cell>ReLU</cell></row><row><cell>5</cell><cell>Linear(in=256, output=128)</cell></row><row><cell>6</cell><cell>ReLU</cell></row><row><cell>7</cell><cell>Linear(in=128, output=2)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10 :</head><label>10</label><figDesc>Ablation study results across the two datasets. The results in the table represent the mean values of all test domain outcomes.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Adult</cell><cell>Chicago Crime</cell></row><row><cell></cell><cell cols="4">Methods</cell><cell cols="3">CE ↓ (×10)</cell><cell>CE ↓ (×10)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">o00 o01 o10 o11 o00 o01 o10 o11</cell></row><row><cell></cell><cell cols="7">w/o disentanglement 1.35 0.01 0.53 0.50 1.66 1.53 1.69 1.56</cell></row><row><cell></cell><cell cols="4">w/o fairness loss</cell><cell cols="3">3.64 1.45 2.57 2.91 0.33 0.29 0.31 0.26</cell></row><row><cell></cell><cell cols="4">DCFDG (Ours)</cell><cell cols="3">0.10 0.01 0.17 0.26 0.01 0.01 0.01 0.01</cell></row><row><cell cols="5">B.5 CE Values for Trade-off Outcomes</cell><cell></cell><cell></cell></row><row><cell>0.70 0.72</cell><cell>(a) Trade-off on Adult</cell><cell></cell><cell>0.70 0.72</cell><cell cols="3">(a) Trade-off on Adult CVAE CEVAE mCEVAE DCEVAE DCFDG</cell><cell>0.70 0.72</cell><cell>(a) Trade-off on Adult DCFDG DCEVAE mCEVAE CEVAE CVAE</cell><cell>0.70 0.72</cell></row><row><cell>0.68</cell><cell></cell><cell></cell><cell>0.68</cell><cell></cell><cell></cell><cell></cell><cell>0.68</cell><cell>0.68</cell></row><row><cell>0.64 0.66 Accuracy</cell><cell cols="2">CVAE CEVAE mCEVAE DCEVAE DCFDG</cell><cell>0.64 0.66 Accuracy</cell><cell></cell><cell></cell><cell cols="2">0.64 0.66 Accuracy</cell><cell>0.64 0.66</cell></row><row><cell>0.62</cell><cell></cell><cell></cell><cell>0.62</cell><cell></cell><cell></cell><cell></cell><cell>0.62</cell><cell>0.62</cell></row><row><cell>0.60</cell><cell></cell><cell></cell><cell>0.60</cell><cell></cell><cell></cell><cell></cell><cell>0.60</cell><cell>0.60</cell></row><row><cell></cell><cell>0.00 Counterfactual Effect (o00) 0.02 0.04 0.06 0.08 0.10</cell><cell cols="2">0.12</cell><cell cols="2">0.00 Counterfactual Effect (o01) 0.02 0.04 0.06 0.08 0.10</cell><cell>0.12</cell><cell>0.00 Counterfactual Effect (o10) 0.02 0.04 0.06 0.08 0.10 0.12</cell><cell>0.00 0.02 0.04 0.06 0.08 0.10 0.12 Counterfactual Effect (o11)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 :</head><label>11</label><figDesc>Accuracy of the Fair-circle dataset.</figDesc><table><row><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell></row><row><cell>DIVA</cell><cell cols="4">96.47± 0.17 77.20± 2.36 52.92± 2.01 50.00± 0.00</cell></row><row><cell>LASSE</cell><cell cols="4">81.82± 5.33 95.72± 3.64 96.10± 3.32 86.80± 2.75</cell></row><row><cell>MMD-LASE</cell><cell cols="4">96.10±3.32 96.81±1.55 82.62±2.29 55.65±1.13</cell></row><row><cell>CVAE</cell><cell cols="4">49.88±0.31 50.06±0.23 50.03±0.11 49.98±0.05</cell></row><row><cell>CEVAE</cell><cell cols="4">50.08±0.27 49.93±0.23 49.96±0.11 49.99±0.09</cell></row><row><cell>mCEVAE</cell><cell cols="4">50.24±0.00 50.75±0.18 64.06±3.04 87.06±1.48</cell></row><row><cell>DCEVAE</cell><cell cols="4">61.99±1.75 50.92±0.51 50.11±0.02 49.95±0.00</cell></row><row><cell cols="5">DCFDG (Ours) 98.33±0.30 98.35±0.17 90.88±0.46 67.21±1.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 :</head><label>12</label><figDesc>Total causal effect of the Fair-circle dataset.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Total causal effect (×10)</cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell></row><row><cell>DIVA</cell><cell cols="4">1.70±0.52 2.00±0.22 0.28±0.19 0.63±0.89</cell></row><row><cell>LASSE</cell><cell cols="4">4.34±0.77 4.72±0.56 5.20±0.88 5.85±0.93</cell></row><row><cell>MMD-LASE</cell><cell cols="4">0.68±0.57 0.23±0.00 0.89±0.20 1.00±0.07</cell></row><row><cell>CVAE</cell><cell cols="4">0.10±0.09 0.15±0.13 0.12±0.10 0.20±0.18</cell></row><row><cell>CEVAE</cell><cell cols="4">0.15±0.15 0.26±0.16 0.40±0.14 0.55±0.13</cell></row><row><cell>mCEVAE</cell><cell cols="4">0.32±0.06 0.27±0.13 0.26±0.15 0.25±0.17</cell></row><row><cell>DCEVAE</cell><cell cols="4">0.34±0.12 0.22±0.15 0.12±0.14 0.04±0.07</cell></row><row><cell cols="5">DCFDG (Ours) 0.07±0.06 0.06±0.03 0.15±0.02 0.20±0.07</cell></row><row><cell>Results on the Adult dataset</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 13 :</head><label>13</label><figDesc>Accuracy of the Adult dataset.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Accuracy</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">69.82±1.82 67.56±1.71 67.62±2.29 67.78±2.55 67.55±2.11 67.51±1.78</cell></row><row><cell>LASSE</cell><cell cols="2">60.01±1.81 57.34±1.78</cell><cell>56.56±2.5</cell><cell cols="3">56.34±2.00 57.16±1.84 59.32±1.85</cell></row><row><cell>MMD-LASE</cell><cell cols="6">60.99±3.56 60.41±2.12 59.73±1.09 60.19±0.43 59.50±2.34 61.21±2.31</cell></row><row><cell>CVAE</cell><cell cols="6">60.60±0.23 59.41±1.65 58.82±1.15 59.52±1.52 63.35±1.28 69.24±1.80</cell></row><row><cell>CEVAE</cell><cell cols="6">61.02±0.23 60.08±0.28 59.05±0.40 59.79±0.40 64.08±0.42 70.90±0.32</cell></row><row><cell>mCEVAE</cell><cell cols="2">59.73±0.71 59.10±0.78</cell><cell>58.1±0.43</cell><cell cols="3">58.37±1.47 62.42±0.82 68.53±1.86</cell></row><row><cell>DCEVAE</cell><cell cols="6">61.27±0.10 60.37±0.07 59.46±0.00 60.11±0.15 64.38±0.02 71.22±0.07</cell></row><row><cell cols="7">DCFDG (Ours) 72.71±0.04 72.29±0.04 68.33±0.04 69.64±0.89 66.72±0.04 69.39±1.92</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 14 :</head><label>14</label><figDesc>Total causal effect of the Adult dataset.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Total causal effect (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">0.79±0.11 0.81±0.12 0.86±0.14 0.80±0.11 0.78±0.09 0.80±0.12</cell></row><row><cell>LASSE</cell><cell cols="6">1.92±0.12 2.02±0.06 1.94±0.06 1.96±0.07 1.89±0.01 1.75±0.19</cell></row><row><cell>MMD-LASE</cell><cell cols="6">1.68±1.05 1.64±0.89 1.61±1.01 1.58±0.98 1.55±1.16 1.51±1.20</cell></row><row><cell>CVAE</cell><cell cols="6">0.56±0.47 0.56±0.48 0.57±0.47 0.55±0.48 0.57±0.49 0.56±0.47</cell></row><row><cell>CEVAE</cell><cell cols="6">0.69±0.27 0.69±0.27 0.69±0.27 0.69±0.27 0.69±0.28 0.69±0.28</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.46±0.25 0.45±0.25 0.47±0.28 0.47±0.29 0.46±0.28 0.46±0.28</cell></row><row><cell>DCEVAE</cell><cell cols="6">0.38±0.05 0.38±0.05 0.38±0.05 0.38±0.05 0.38±0.05 0.38±0.05</cell></row><row><cell cols="4">DCFDG (Ours) 0.02±0.02 0.01±0.01 0.01±0.01</cell><cell>0.3±0.05</cell><cell cols="2">0.47±0.15 0.52±0.05</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 15 :</head><label>15</label><figDesc>Counterfactual effect of the Adult dataset, where condition O := o00.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Counterfactual Effcet: o00 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">1.39±0.74 1.21±0.21 0.50±0.28 0.55±0.43 0.84±0.30 0.78±0.27</cell></row><row><cell>LASSE</cell><cell cols="6">1.93±0.45 3.04±1.89 3.61±2.55 3.63±2.35 3.06±1.69 2.49±1.54</cell></row><row><cell>MMD-LASE</cell><cell cols="6">0.80±1.14 1.52±2.15 1.38±1.96 1.43±2.03 1.33±1.88 0.54±0.77</cell></row><row><cell>CVAE</cell><cell cols="6">0.55±0.47 0.45±0.46 0.50±0.51 0.55±0.50 0.56±0.48 0.55±0.51</cell></row><row><cell>CEVAE</cell><cell cols="6">0.68±0.27 0.68±0.28 0.68±0.27 0.67±0.25 0.67±0.26 0.67±0.25</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.43±0.18 0.44±0.10 0.41±0.13 0.49±0.23 0.45±0.22 0.51±0.20</cell></row><row><cell>DCEVAE</cell><cell cols="6">0.40±0.06 0.38±0.06 0.38±0.06 0.38±0.06 0.40±0.01 0.38±0.07</cell></row><row><cell cols="7">DCFDG (Ours) 0.20±0.28 0.00±0.00 0.30±0.42 0.10±0.15 0.00±0.00 0.00±0.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 16 :</head><label>16</label><figDesc>Counterfactual effect of the Adult dataset, where condition O := o01.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Counterfactual Effcet: o01 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell>0.61±0.34</cell><cell>0.65±0.39</cell><cell cols="4">0.75±0.42 0.41±0.16 0.72±0.48 0.57±0.35</cell></row><row><cell>LASSE</cell><cell>3.93±1.03</cell><cell>3.07±0.98</cell><cell cols="4">3.20±1.39 4.32±1.33 3.87±1.96 3.44±1.47</cell></row><row><cell>MMD-LASE</cell><cell>1.56±1.59</cell><cell>1.22±1.26</cell><cell cols="4">1.39±1.39 1.47±1.33 1.15±1.45 1.29±1.37</cell></row><row><cell>CVAE</cell><cell>0.53±0.47</cell><cell>0.57±0.45</cell><cell cols="4">0.55±0.44 0.53±0.45 0.56±0.46 0.55±0.45</cell></row><row><cell>CEVAE</cell><cell>0.69±0.26</cell><cell>0.69±0.26</cell><cell cols="4">0.69±0.26 0.69±0.26 0.69±0.26 0.70±0.27</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.39±0.05 0.37±0.073 0.34±0.06 0.35±0.05 0.35±0.06 0.34±0.09</cell></row><row><cell>DCEVAE</cell><cell>0.38±0.06</cell><cell>0.37±0.06</cell><cell cols="4">0.37±0.06 0.38±0.06 0.38±0.05 0.38±0.06</cell></row><row><cell cols="2">DCFDG (Ours) 0.05±0.07</cell><cell>0.02±0.04</cell><cell cols="4">0.03±0.04 0.03±0.04 0.00±0.00 0.00±0.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 17 :</head><label>17</label><figDesc>Counterfactual effect of the Adult dataset, where condition O := o10.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Counterfactual Effcet: o10 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">0.17±0.00 0.19±0.00 0.23±0.00 0.64±0.00 0.49±0.00 0.31±0.00</cell></row><row><cell>LASSE</cell><cell cols="6">1.75±1.11 1.84±0.96 1.65±0.92 1.53±0.68 1.72±0.69 1.74±1.12</cell></row><row><cell>MMD-LASE</cell><cell cols="6">0.96±1.11 0.87±1.12 1.07±1.17 1.08±1.19 1.27±1.23 1.03±1.20</cell></row><row><cell>CVAE</cell><cell cols="6">0.48±0.49 0.55±0.54 0.53±0.50 0.53±0.53 0.51±0.55 0.47±0.45</cell></row><row><cell>CEVAE</cell><cell cols="6">0.70±0.29 0.69±0.29 0.69±0.28 0.69±0.29 0.69±0.29 0.70±0.30</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.51±0.34 0.48±0.31 0.52±0.39 0.50±0.38 0.52±0.37 0.45±0.27</cell></row><row><cell>DCEVAE</cell><cell cols="6">0.37±0.05 0.39±0.06 0.38±0.05 0.39±0.05 0.38±0.05 0.38±0.06</cell></row><row><cell cols="7">DCFDG (Ours) 0.18±0.26 0.24±0.34 0.05±0.07 0.13±0.17 0.21±0.29 0.22±0.30</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 18 :</head><label>18</label><figDesc>Counterfactual effect of the Adult dataset, where condition O := o11.Results on the Chicago Crime dataset</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Counterfactual Effcet: o11 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">0.84±0.14 0.86±0.12 0.93±0.13 0.86±0.13 0.80±0.07 0.86±0.11</cell></row><row><cell>LASSE</cell><cell cols="6">1.65±0.37 1.83±0.37 1.72±0.27 1.67±0.36 1.66±0.26 1.53±0.06</cell></row><row><cell>MMD-LASE</cell><cell cols="6">1.78±0.94 1.75±0.76 1.69±0.87 1.64±0.86 1.63±1.04 1.61±1.18</cell></row><row><cell>CVAE</cell><cell cols="6">0.57±0.47 0.57±0.47 0.57±0.47 0.56±0.47 0.57±0.48 0.57±0.47</cell></row><row><cell>CEVAE</cell><cell cols="6">0.69±0.27 0.69±0.27 0.69±0.27 0.69±0.27 0.69±0.28 0.69±0.28</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.47±0.29 0.47±0.30 0.48±0.31 0.48±0.34 0.47±0.32 0.48±0.33</cell></row><row><cell>DCEVAE</cell><cell cols="6">0.38±0.05 0.38±0.05 0.38±0.05 0.38±0.05 0.38±0.05 0.38±0.05</cell></row><row><cell cols="7">DCFDG (Ours) 0.00±0.00 0.00±0.00 0.00±0.00 0.36±0.04 0.57±0.16 0.63±0.08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 19 :</head><label>19</label><figDesc>Accuracy of the Chicago Crime dataset. 66±2.86 50.39±0.14 48.38±0.34 50.19±1.03 55.81±0.41 51.55±0.84 DCEVAE 53.86±0.14 47.24±0.03 43.58±2.03 47.04±0.03 56.37±1.20 59.66±4.30 DCFDG (Ours) 58.47±0.10 57.01±0.55 55.28±0.20 54.34±0.55 56.10±0.87 54.37±0.38</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">59.65±0.73 54.41±0.37 51.97±1.94 53.85±1.89 58.15±1.79 59.02±2.35</cell></row><row><cell>LASSE</cell><cell cols="6">52.74±0.73 51.33±0.27 50.56±0.17 53.35±0.06 56.64±1.22 57.68±1.15</cell></row><row><cell>MMD-LASE</cell><cell cols="6">55.18±0.27 53.58±0.94 48.27±3.28 53.31±4.40 56.54±0.80 56.10±0.59</cell></row><row><cell>CVAE</cell><cell cols="6">53.63±2.45 52.34±0.82 51.32±2.82 53.15±1.44 58.91±0.79 51.26±2.60</cell></row><row><cell>CEVAE</cell><cell cols="6">53.35±1.08 53.17±5.33 52.91±5.05 54.33±2.62 56.59±4.85 51.55±0.84</cell></row><row><cell>mCEVAE</cell><cell>54.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 20 :</head><label>20</label><figDesc>Total causal effect of the Chicago Crime dataset. 71±0.01 0.74±0.02 0.73±0.01 0.70±0.01 0.73±0.02 0.72±0.03 CEVAE 0.41±0.19 0.41±0.19 0.43±0.18 0.44±0.19 0.41±0.18 0.42±0.21 mCEVAE 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 DCEVAE 0.44±0.05 0.46±0.05 0.45±0.04 0.44±0.05 0.44±0.06 0.42±0.04 DCFDG (Ours) 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Total causal effect (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">1.42±0.14 1.60±0.10 1.61±0.26 1.71±0.04 1.99±0.21 1.73±0.21</cell></row><row><cell>LASSE</cell><cell cols="6">0.63±0.16 0.64±0.34 0.73±0.23 0.94±0.30 0.91±0.54 1.25±0.89</cell></row><row><cell>MMD-LASE</cell><cell cols="6">0.35±0.23 0.29±0.05 0.33±0.15 0.40±0.20 0.37±0.15 0.39±0.25</cell></row><row><cell>CVAE</cell><cell>0.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 21 :</head><label>21</label><figDesc>Counterfactual effect of the Chicago Crime dataset, where condition O := o00. 47±0.06 0.51±0.07 0.49±0.07 0.47±0.06 0.48±0.08 0.46±0.05 DCFDG (Ours) 0.01±0.01 0.02±0.03 0.05±0.00 0.02±0.03 0.01±0.01 0.01±0.01</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Counterfactual Effcet: o00 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">1.39±0.15 1.69±0.13 1.53±0.23 1.91±0.32 1.97±0.12 1.60±0.28</cell></row><row><cell>LASSE</cell><cell cols="6">0.40±0.16 0.35±0.46 0.75±0.31 0.81±0.59 0.92±0.51 1.37±0.96</cell></row><row><cell>MMD-LASE</cell><cell cols="6">0.23±0.16 0.33±0.12 0.29±0.11 0.36±0.18 0.34±0.03 0.36±0.03</cell></row><row><cell>CVAE</cell><cell cols="6">0.66±0.00 0.67±0.04 0.64±0.00 0.66±0.01 0.70±0.01 0.66±0.05</cell></row><row><cell>CEVAE</cell><cell cols="6">0.39±0.19 0.38±0.19 0.41±0.18 0.42±0.21 0.40±0.19 0.39±0.21</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00</cell></row><row><cell>DCEVAE</cell><cell>0.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 22 :</head><label>22</label><figDesc>Counterfactual effect of the Chicago Crime dataset, where condition O := o01. 45±0.05 0.46±0.06 0.46±0.04 0.45±0.05 0.45±0.05 0.43±0.03 DCFDG (Ours) 0.02±0.03 0.01±0.02 0.01±0.02 0.02±0.03 0.00±0.00 0.02±0.03</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Counterfactual Effcet: o01 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">1.13±0.19 1.58±0.27 1.17±0.21 1.52±0.09 1.76±0.11 1.57±0.15</cell></row><row><cell>LASSE</cell><cell cols="6">0.61±0.24 0.74±0.23 0.97±0.57 0.97±0.21 0.97±0.70 1.32±0.80</cell></row><row><cell>MMD-LASE</cell><cell cols="6">0.58±0.24 0.28±0.01 0.43±0.19 0.39±0.24 0.31±0.30 0.48±0.48</cell></row><row><cell>CVAE</cell><cell cols="6">0.69±0.01 0.71±0.00 0.74±0.00 0.66±0.01 0.70±0.00 0.72±0.01</cell></row><row><cell>CEVAE</cell><cell cols="6">0.41±0.22 0.42±0.19 0.43±0.19 0.46±0.21 0.41±0.20 0.43±0.22</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00</cell></row><row><cell>DCEVAE</cell><cell>0.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 23 :</head><label>23</label><figDesc>Counterfactual effect of the Chicago Crime dataset, where condition O := o10.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Counterfactual Effcet: o10 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="5">1.77±0.18 1.63±0.15 1.71±0.25 1.93±0.07 2.21±0.25</cell><cell>1.77±0.17</cell></row><row><cell>LASSE</cell><cell cols="5">0.65±0.05 0.75±0.34 0.75±0.13 0.89±0.31 1.06±0.59</cell><cell>1.28±0.93</cell></row><row><cell>MMD-LASE</cell><cell cols="5">0.24±0.14 0.25±0.01 0.31±0.20 0.31±0.10 0.58±0.35</cell><cell>0.45±0.26</cell></row><row><cell>CVAE</cell><cell cols="6">0.74±0.02 0.75±0.03 0.73±0.03 0.72±0.04 0.75±0.05 0.722±0.05</cell></row><row><cell>CEVAE</cell><cell cols="5">0.40±0.20 0.41±0.19 0.42±0.18 0.44±0.20 0.42±0.19</cell><cell>0.42±0.21</cell></row><row><cell>mCEVAE</cell><cell cols="5">0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00</cell><cell>0.01±0.00</cell></row><row><cell>DCEVAE</cell><cell cols="5">0.44±0.06 0.45±0.07 0.43±0.08 0.43±0.08 0.45±0.07</cell><cell>0.43±0.06</cell></row><row><cell cols="6">DCFDG (Ours) 0.01±0.02 0.01±0.00 0.01±0.15 0.03±0.05 0.00±0.00</cell><cell>0.01±0.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 24 :</head><label>24</label><figDesc>Counterfactual effect of the Chicago Crime dataset, where condition O := o11.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Counterfactual Effcet: o11 (×10)</cell><cell></cell></row><row><cell></cell><cell>T+1</cell><cell>T+2</cell><cell>T+3</cell><cell>T+4</cell><cell>T+5</cell><cell>T+6</cell></row><row><cell>DIVA</cell><cell cols="6">1.38±0.18 1.50±0.08 2.08±0.40 1.49±0.15 2.03±0.37 2.03±0.38</cell></row><row><cell>LASSE</cell><cell cols="6">0.82±0.18 0.66±0.34 0.38±0.13 1.08±0.16 0.67±0.32 1.03±0.88</cell></row><row><cell>MMD-LASE</cell><cell cols="6">0.33±0.38 0.30±0.13 0.28±0.06 0.54±0.28 0.23±0.11 0.21±0.20</cell></row><row><cell>CVAE</cell><cell cols="6">0.73±0.00 0.80±0.01 0.81±0.01 0.75±0.01 0.76±0.02 0.76±0.00</cell></row><row><cell>CEVAE</cell><cell cols="6">0.43±0.16 0.43±0.17 0.45±0.17 0.45±0.15 0.41±0.15 0.46±0.18</cell></row><row><cell>mCEVAE</cell><cell cols="6">0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00 0.01±0.00</cell></row><row><cell>DCEVAE</cell><cell cols="6">0.39±0.02 0.40±0.02 0.39±0.01 0.39±0.02 0.38±0.02 0.36±0.01</cell></row><row><cell cols="7">DCFDG (Ours) 0.04±0.05 0.01±0.01 0.01±0.01 0.02±0.03 0.01±0.01 0.01±0.01</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported by the <rs type="funder">National Natural Science Foundation of China program</rs> (NSFC #<rs type="grantNumber">62272338</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_EtbEgx2">
					<idno type="grant-number">62272338</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Grari et al., 2021] Vincent Grari, Sylvain Lamprier, and Marcin Detyniecki. Fairness without the sensitive attribute via causal variational autoencoder</title>
		<author>
			<persName><surname>Bai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.10664</idno>
		<idno>arXiv:2109.04999</idno>
	</analytic>
	<monogr>
		<title level="m">Miguel A Hernán and James M Robins. Causal inference. International encyclopedia of statistical science</title>
		<editor>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</editor>
		<imprint>
			<publisher>Hitchcock and Pearl</publisher>
			<date type="published" when="1997">2022. 2022. 2017. 2017. 2014. 2014. 2021. 2018. 2001. 2001. 1997</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Neural computation</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diva: Domain invariant variational autoencoders</title>
		<author>
			<persName><forename type="first">Ilse</forename></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="322" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Counterfactual fairness with disentangled causal effect variational autoencoder</title>
		<author>
			<persName><forename type="first">Mnih</forename><forename type="middle">;</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
	</analytic>
	<monogr>
		<title level="m">Diederik P Kingma and Max Welling. Auto-encoding variational bayes</title>
		<imprint>
			<publisher>Kingma and Welling</publisher>
			<date type="published" when="2013">2018. 2018. 2021. 2021. 2013. 2013</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8128" to="8136" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the AAAI Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><surname>Kohavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Kdd</title>
		<editor>
			<persName><forename type="first">Joshua</forename><surname>Kusner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chris</forename><surname>Loftus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ricardo</forename><surname>Russell</surname></persName>
		</editor>
		<editor>
			<persName><surname>Silva</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1996">1996. 1996. 2017</date>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="202" to="207" />
		</imprint>
	</monogr>
	<note>Counterfactual fairness. Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pearl and Mackenzie, 2018] Judea Pearl and Dana Mackenzie. The book of why: the new science of cause and effect</title>
		<author>
			<persName><surname>Louizos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017. 2017. 2020. 2018</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Basic books</note>
	<note>Causal effect inference with deep latent-variable models</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generalizing to evolving domains with latent structureaware sequential autoencoder</title>
		<author>
			<persName><surname>Pfohl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.05826</idno>
		<idno>arXiv:2206.00047</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<editor>
			<persName><forename type="first">Bilal</forename><surname>Zafar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Isabel</forename><surname>Valera</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Manuel</forename><surname>Gomez Rogriguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Krishna</forename><forename type="middle">P</forename><surname>Gummadi</surname></persName>
		</editor>
		<meeting><address><addrLine>Peter Spirtes, Clark N Glymour, Richard</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="1941">2019. 2019. 2022. 2022. 2023. 1941-1979, 2008. 2015. 2015. 2000. 2021. 2022. 2019. 2019. 2017. 2017</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="962" to="970" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Artificial intelligence and statistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Foresee what you will learn: Data augmentation for domain generalization in non-stationary environments</title>
		<author>
			<persName><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.07845</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Knowledge Graph (ICKG)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2023. 2023. 2020</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Unfairness discovery and prevention for few-shot regression</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive fairnessaware online meta-learning for changing environments</title>
		<author>
			<persName><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14537</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<editor>
			<persName><forename type="first">Enyan</forename><surname>Zhao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kai</forename><surname>Dai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Suhang</forename><surname>Shu</surname></persName>
		</editor>
		<editor>
			<persName><surname>Wang</surname></persName>
		</editor>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2021">2021. 2021. 2021. 2021. 2022. 2022</date>
			<biblScope unit="page" from="2565" to="2575" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards fair disentangled online learning for changing environments</title>
		<author>
			<persName><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
			<biblScope unit="page" from="3480" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
