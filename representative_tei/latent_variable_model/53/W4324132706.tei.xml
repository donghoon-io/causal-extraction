<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Investigating the Impact of User Trust on the Adoption and Use of ChatGPT: Survey Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>PhD;</roleName><forename type="first">Avishek</forename><surname>Choudhury</surname></persName>
							<email>avishek.choudhury@mail.wvu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Industrial and Management Systems Engineering</orgName>
								<orgName type="institution" key="instit1">Benjamin M. Statler College of Engineering and Mineral Resources</orgName>
								<orgName type="institution" key="instit2">West Virginia University</orgName>
								<address>
									<settlement>Morgantown</settlement>
									<region>WV</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Industrial and Management Systems Engineering Benjamin M. Statler College of Engineering and Mineral Resources West Virginia University</orgName>
								<address>
									<addrLine>321 Engineering Sciences Building 1306 Evansdale Drive Morgantown</addrLine>
									<postCode>26506</postCode>
									<region>WV</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>MSc</roleName><forename type="first">Hamid</forename><surname>Shamszare</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Industrial and Management Systems Engineering</orgName>
								<orgName type="institution" key="instit1">Benjamin M. Statler College of Engineering and Mineral Resources</orgName>
								<orgName type="institution" key="instit2">West Virginia University</orgName>
								<address>
									<settlement>Morgantown</settlement>
									<region>WV</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Investigating the Impact of User Trust on the Adoption and Use of ChatGPT: Survey Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.2196/47184</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ChatGPT</term>
					<term>trust in AI</term>
					<term>artificial intelligence</term>
					<term>technology adoption</term>
					<term>behavioral intention</term>
					<term>chatbot</term>
					<term>human factors</term>
					<term>trust</term>
					<term>adoption</term>
					<term>intent</term>
					<term>survey</term>
					<term>shared accountability</term>
					<term>AI policy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background: ChatGPT (Chat Generative Pre-trained Transformer) has gained popularity for its ability to generate human-like responses. It is essential to note that overreliance or blind trust in ChatGPT, especially in high-stakes decision-making contexts, can have severe consequences. Similarly, lacking trust in the technology can lead to underuse, resulting in missed opportunities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objective</head><p>: This study investigated the impact of users' trust in ChatGPT on their intent and actual use of the technology. Four hypotheses were tested: (1) users' intent to use ChatGPT increases with their trust in the technology; (2) the actual use of ChatGPT increases with users' intent to use the technology; (3) the actual use of ChatGPT increases with users' trust in the technology; and (4) users' intent to use ChatGPT can partially mediate the effect of trust in the technology on its actual use. Methods: This study distributed a web-based survey to adults in the United States who actively use ChatGPT (version 3.5) at least once a month between February 2023 through March 2023. The survey responses were used to develop 2 latent constructs: Trust and Intent to Use, with Actual Use being the outcome variable. The study used partial least squares structural equation modeling to evaluate and test the structural model and hypotheses.</p><p>Results: In the study, 607 respondents completed the survey. The primary uses of ChatGPT were for information gathering (n=219, 36.1%), entertainment (n=203, 33.4%), and problem-solving (n=135, 22.2%), with a smaller number using it for health-related queries (n=44, 7.2%) and other activities (n=6, 1%). Our model explained 50.5% and 9.8% of the variance in Intent to Use and Actual Use, respectively, with path coefficients of 0.711 and 0.221 for Trust on Intent to Use and Actual Use, respectively. The bootstrapped results failed to reject all 4 null hypotheses, with Trust having a significant direct effect on both Intent to Use (β=0.711, 95% CI 0.656-0.764) and Actual Use (β=0.302, 95% CI 0.229-0.374). The indirect effect of Trust on Actual Use, partially mediated by Intent to Use, was also significant (β=0.113, 95% CI 0.001-0.227).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions:</head><p>Our results suggest that trust is critical to users' adoption of ChatGPT. It remains crucial to highlight that ChatGPT was not initially designed for health care applications. Therefore, an overreliance on it for health-related advice could potentially lead to misinformation and subsequent health risks. Efforts must be focused on improving the ChatGPT's ability to distinguish between queries that it can safely handle and those that should be redirected to human experts (health care professionals). Although risks are associated with excessive trust in artificial intelligence-driven chatbots such as ChatGPT, the potential risks can be reduced by advocating for shared accountability and fostering collaboration between developers, subject matter experts, and human factors researchers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>Artificial Intelligence (AI) has been a subject of research and intrigue for scientists, engineers, and thinkers since the emergence of computing machines. The genesis of AI can be traced back to the 1950s, marking the commencement of an extensive voyage that would ultimately lead to the development of intricate, human-like machines capable of independent thinking, learning, and reasoning <ref type="bibr" target="#b0">[1]</ref>. Initially, AI was perceived as a solution to all problems-a technology that could mechanize every task and supplant human labor. Early research focused on building rule-based systems that could make decisions based on predetermined logical rules. Nevertheless, these systems had limited usefulness as they were rigid and could not learn from data or adapt to novel situations <ref type="bibr" target="#b1">[2]</ref>. In the 1960s and 1970s, the emphasis of AI research shifted toward developing expert systems that could reason and make decisions based on extensive domain-specific knowledge <ref type="bibr" target="#b2">[3]</ref>. These systems were widely used in various fields, such as medicine, finance, and engineering, and were seen as a major advancement in AI research <ref type="bibr" target="#b3">[4]</ref>. However, the limitations of expert systems became apparent in the 1980s and 1990s, as they could not handle the complexity and ambiguity of real-world problems <ref type="bibr" target="#b4">[5]</ref>. This led to the development of machine learning algorithms that could learn from data and make decisions based on statistical patterns. With the advent of the internet and the availability of massive amounts of data, deep learning algorithms emerged, which are capable of learning complex patterns in images, speech, and text.</p><p>In recent years, AI has been widely adopted in various fields, including health care, finance, transportation, and entertainment. AI-powered technologies such as self-driving cars, virtual assistants, and personalized recommendations have become integral to our daily lives. One of the most substantial breakthroughs in AI research has been the emergence of large-scale language models that are built on Generative Pre-trained Transformers such as ChatGPT (Chat Generative Pre-trained Transformer; OpenAI) <ref type="bibr" target="#b5">[6]</ref>. These models are trained on vast amounts of textual data and can generate human-like responses to natural language queries. ChatGPT has revolutionized the field of natural language processing and has paved the way for a new generation of AI-powered language applications. ChatGPT is a cutting-edge language model that OpenAI developed in 2019. It is based on a transformer architecture-a deep learning model that has demonstrated remarkable efficacy in processing sequential data, particularly natural language. ChatGPT was trained on a colossal corpus of text data, which included various sources such as books, articles, and websites.</p><p>ChatGPT has garnered substantial traction among computer users, largely due to its impressive ability to generate responses that resemble those of the human language <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref>. Many users appreciate the convenience and efficiency of this technology, particularly in various applications such as chatbots, virtual assistants, and customer service agents <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref>. However, along with its burgeoning popularity, ChatGPT has prompted concerns about the broader implications of its use <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref>. Among these concerns is the potential for its exploitation for malicious purposes, such as social engineering attacks or other forms of fraud <ref type="bibr" target="#b19">[20]</ref>. Another issue relates to the possibility of the technology exacerbating preexisting societal biases, as the model's training data may have inadvertently reflected these biases and cause ChatGPT to produce biased responses <ref type="bibr" target="#b20">[21]</ref>. Moreover, ChatGPT's ability to produce highly convincing fake text has sparked unease regarding its potential misuse in disinformation campaigns, deep fakes, and other malicious activities <ref type="bibr" target="#b21">[22]</ref>. These concerns have catalyzed efforts by researchers and policy makers to identify and address the risks associated with this technology, including developing techniques to detect and prevent malicious use and ensuring that the training data used for ChatGPT and similar models are diverse, representative, and free of any biases <ref type="bibr" target="#b21">[22]</ref>. Therefore, it is crucial to remain vigilant and proactively address the possible risks arising from its use <ref type="bibr" target="#b22">[23]</ref>.</p><p>The consequences of overreliance or exhibiting blind trust in ChatGPT, particularly in high-stakes decision-making contexts, cannot be overstated. Although impressive in its capabilities, the technology is not impervious to errors, especially if it has been trained on biased or incomplete data. Given its nature of continuously learning from internet texts, failure to adequately verify and validate ChatGPT's responses can result in incorrect or incomplete decisions, which can have substantial and far-reaching implications in health care, finance, and law <ref type="bibr" target="#b23">[24]</ref>. Conversely, a complete lack of trust in ChatGPT can lead to the underuse of this technology. Such distrust can lead to hesitancy to use the technology for decision-making, leading to missed opportunities and slower decision-making processes.</p><p>Excessive or lack of trust in ChatGPT can have deleterious effects. Striking a balance between trust and validation is essential to ensure the responsible and efficacious use of ChatGPT to maximize its benefits and mitigate its associated risks. Therefore, this study captured users' trust in ChatGPT and explored its impact on user intent to use the technology. Additionally, it explored its direct and indirect effects on the actual use of ChatGPT. As illustrated in Figure <ref type="figure" target="#fig_4">1</ref>, we explored the following 4 hypotheses:     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis Development</head><p>In this study, we define Trust in ChatGPT as a user's willingness to take chances based on the recommendations made by this technology. This implies that the user believes that the technology has the capacity to execute a particular task accurately while keeping in mind the possibility of negative outcomes. The Intent to Use <ref type="bibr" target="#b24">[25]</ref> ChatGPT refers to the degree to which an end user perceives the technology as useful and user-friendly and their willingness to adopt and use it for decision-making purposes. Actual Use of ChatGPT refers to the extent to which end users have used the technology for decision-making purposes in their respective fields. The extant literature attests to a positive correlation between users' trust in technology and their inclination to use it, as evidenced by many studies <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref>. Notably, one investigation probing patients' and clinicians' perceptions of chatbots found a substantial nexus between users' trust in AI-based health care chatbot services and their intention to use them <ref type="bibr" target="#b29">[30]</ref>. Similarly, a study examining virtual assistants in the health care domain revealed a positive correlation between users' trust in the technology and their willingness to use it for managing their health <ref type="bibr" target="#b31">[32]</ref>. Furthermore, a study conducted in the marketing realm concluded that chatbots augment customers' trust and purchase intention <ref type="bibr" target="#b28">[29]</ref>. Against this backdrop, we posited that the degree of users' intent to use ChatGPT will increase concomitantly with their trust in the technology, thereby underscoring a positive association between the 2 variables. We articulated this hypothesis as H1: users' intent to use ChatGPT increases with their trust in the technology.</p><p>Successful technology implementation depends on users' intention to use it and their actual use. Despite users' intentions to use technology, they may not put it into practice for several reasons, such as the lack of time, resources, technical skills, or negative experiences with the technology <ref type="bibr" target="#b32">[33]</ref>. Prior research has established a positive correlation between intent to use and actual use of technology, indicating that users who intend to use the technology are more likely to actually use it <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref>. For instance, studies on adopting robots as assistive social agents found that users' intent to use them strongly predicted their actual use <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b30">31]</ref>. In addition, research on adopting conversational agents in the form of chatbots for disease diagnosis showed that users' intention to use the chatbot influenced their actual use of the chatbot <ref type="bibr" target="#b33">[34]</ref>. Thus, we hypothesized that users' intent to use ChatGPT will positively influence their actual use of the technology. We articulated this hypothesis as H2: the actual use of ChatGPT increases with users' intent to use the technology.</p><p>Trust can also influence the actual use of ChatGPT. A survey study involving 359 participants revealed that users' intentions to continue using chatbot services were influenced mainly by their trust in the chatbot <ref type="bibr" target="#b34">[35]</ref>. A health care study using interviews revealed that trust is vital in determining whether individuals will use chatbots for disease diagnosis <ref type="bibr" target="#b33">[34]</ref>. Specifically, the level of trust in chatbots as conversational agents was a decisive factor in the interviewees' decision to use the technology. This finding supports the notion that trust positively impacts the actual use of technology, highlighting its critical role in adopting and implementing new technological solutions. Therefore, we hypothesized that trust in ChatGPT will impact the actual use of the technology. We articulated this hypothesis as H3: the actual use of ChatGPT increases with users' trust in the technology.</p><p>We also explored the following hypothesis: H4: users' intent to use ChatGPT can partially mediate the effect of trust in the technology on its actual use. If users trust ChatGPT, they may be more likely to form positive attitudes toward using the technology and develop an intention to use it. This intention, in turn, may lead to the actual use of the technology. Therefore, users' intent to use ChatGPT could be a pathway through which trust in the technology can partially mediate its effect on actual use. A study on technology acceptance for assistive social robots among older adult users found that the intention to use plays a mediating role in the relationship between trust and actual use <ref type="bibr" target="#b30">[31]</ref>. This suggests that trust alone may not be sufficient to predict the actual use of assistive social robots among older adult users, as the intention to use plays an important role in this relationship. By considering this potential mediating effect,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XSL • FO</head><p>RenderX researchers can gain a more comprehensive understanding of the factors influencing users' adoption of ChatGPT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Approval</head><p>The study obtained ethical approval from West Virginia University, Morgantown (protocol 2302725983).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semistructured Survey</head><p>We distributed a web-based semistructured survey to adults in the United States who actively use ChatGPT (version 3.5) at least once a month. We collected the data from February 2023 through March 2023. The survey was designed on Qualtrics (Qualtrics LLC) and was distributed by Centiment (Centiment LLC), an audience-paneling service. We leveraged Centiment's service as they reach a broader and more representative audience via their network and social media. They also use fingerprinting technology that combines IP address, device type, screen size, and cookies to ensure that only unique panelists enter the survey.</p><p>We conducted a soft launch of the survey and collected 40 responses. A soft launch is a small-scale test of a survey before it is distributed to a larger audience. A soft launch aims to identify any potential issues with the survey, such as unclear or confusing questions, technical glitches, or other problems that may affect the quality of the data collected. The survey was then distributed to a larger audience.</p><p>Table <ref type="table" target="#tab_0">1</ref> shows the descriptive statistics of the survey questions used in this study. We developed 2 latent constructs based on the question (predictors): Trust and Intent to Use. Participant responses to all the questions were captured using a 4-point Likert scale ranging from 1=strongly disagree to 4=strongly agree. The Actual Use factor, the outcome variable, was captured using a single-item question capturing the frequency of use ranging from 1=once a month to 4=almost every day. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analysis</head><p>All the analyses were done in R (R Foundation for Statistical Computing) <ref type="bibr" target="#b35">[36]</ref> using the seminr package <ref type="bibr" target="#b36">[37]</ref>. We evaluated and validated the latent constructs' convergent and discriminant validity. The convergent and reliability were assessed using 3 criteria <ref type="bibr" target="#b37">[38]</ref>: factor loadings (&gt;0.50), composite reliability (&gt;0.70), and average variance extracted (&gt;0.50). The discriminant validity was accessed using the Heterotrait-Monotrait ratio (&lt;0.90) <ref type="bibr" target="#b38">[39]</ref>. After validating the latent construct (measurement model), we leveraged the partial least squares structural equation modeling (PLS-SEM) to test the structural model and hypotheses. The PLS-SEM method is a well-established method for multivariate analysis <ref type="bibr" target="#b39">[40]</ref>. It allows for estimating complex models with several constructs, indicator variables, and structural paths without imposing distributional assumptions on the data <ref type="bibr" target="#b40">[41]</ref>. PLS-SEM is also suitable for small sample sizes when models comprise many constructs and items <ref type="bibr" target="#b41">[42]</ref>. Thus, PLS-SEM is a good method for exploratory research as it offers the flexibility needed for the interplay between theory and data <ref type="bibr" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In all, 607 respondents completed the survey, of which 182 (30%) used ChatGPT at least once a month, 158 (26%) used it once per week, 149 (24.5%) used it more than once per week, and 118 (19.4%) used it almost every day. Most respondents had at minimum a high school diploma (n=204, 33.6%) or a bachelor's degree (n=262, 43.2%). Most of the respondents used ChatGPT for information gathering (n=219, 36.1%), entertainment (n=203, 33.4%), and problem-solving (n=135, 22.2%). We also noted users who used the technology for health-related queries (n=44, 7.2%) and other activities (n=6, 1%), such as generating ideas, grammar checks, and writing blog content. Participants acknowledged the ease of use, usefulness, and accessibility as the 3 most important factors encouraging them to use ChatGPT. Other factors were in the following order: trustworthiness, algorithm quality, privacy, brand value, and transparency. Table <ref type="table" target="#tab_1">2</ref> depicts that the effect of Trust on Intent to Use was stronger than its effect on Actual Use, with path coefficients of 0.711 and 0.221, respectively. The model explained 50.5% and 9.8% of the variance in Intent to Use and Actual Use, respectively. Reliability estimates indicated high levels of internal consistency for all 3 latent variables, with Cronbach α and rho values exceeding the recommended threshold of 0.7. The average variance extracted for Trust and Intent to Use also exceeded the recommended threshold of 0.5, indicating that these variables are well-defined and reliable. Table <ref type="table" target="#tab_2">3</ref> shows the Heterotrait-Monotrait ratios for the paths between Trust and Intent to Use, Trust and Actual Use, and Intent to Use and Actual Use. The results suggest that the Heterotrait-Monotrait ratios are below the recommended threshold of 0.9, indicating discriminant validity in the model.</p><p>According to our bootstrapped PLS-SEM results, we found support for all 4 hypotheses. Figure <ref type="figure" target="#fig_5">2</ref> illustrates the conceptual framework that connects trust in ChatGPT, users' intent to use ChatGPT, and its actual use. Factors T1 through T7 indicate the 7 observed variables forming the latent construct of Trust, and factors U1 through U3 form the construct of Intent to Use. The thickness of the arrows in the inner model reflects the magnitude of the direct effects.</p><p>H1 posited that trust in ChatGPT would have a direct effect on users' intentions to use the technology. Our results confirmed this hypothesis (β=0.711, 95% CI 0.656-0.764), indicating a strong positive relationship.</p><p>H2 suggested that users' intent to use ChatGPT would have an effect on their actual use. This was also supported by our data (β=0.114, 95% CI 0.001-0.229), underlining the role of intent as a predictor of use.</p><p>H3 proposed that trust in ChatGPT would directly influence its actual use. Our results corroborated this hypothesis (β=0.302, 95% CI 0.229-0.374), affirming that trust can directly drive actual use.</p><p>Finally, H4 postulated that the effect of trust on actual use would be partially mediated by the intent to use. Our analysis also confirmed this, with the indirect effect of trust on actual use through intent to use being significant (β=0.113, 95% CI 0.003-0.227).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Principal Findings</head><p>This is the first study exploring the role of trust in ChatGPT's adoption from a human factors viewpoint. This study contributes to the extant literature by shedding light on the importance of trust as a determinant of both the intention to use and the actual use of chatbot technologies. Furthermore, the study highlights the mediating role of intention to use in the relationship between trust and actual use. These insights are particularly relevant for organizations and developers seeking to design and market chatbot technologies that users are more likely to adopt and use. Moreover, the results show how users engage with chatbot technologies, including information gathering, entertainment, problem-solving, and health-related queries. This highlights the potential of chatbot technologies to meet various needs and suggests that developers may consider designing chatbots with diverse functionalities to enhance user satisfaction and engagement.</p><p>Our findings complement and build upon the insights from the other studies by providing a nuanced understanding of the role of trust in chatbot adoption. Our study found that trust has a significant direct effect on both intentions to use (β=0.711) and actual use (β=0.302) of the technology. Moreover, the indirect effect of trust on actual use, partially mediated by intent to use, was also significant. This aligns with the prior study <ref type="bibr" target="#b43">[44]</ref>, which explored the antecedents and consequences of chatbot initial trust. They revealed that compatibility, perceived ease of use, and social influence significantly boost users' initial trust toward chatbots, enhancing the intention to use chatbots and encouraging engagement. Another study <ref type="bibr" target="#b44">[45]</ref> focused on the impact of anthropomorphism on user response to chatbots from the perspective of trust and relationship norms. Their findings complement our study by highlighting the role of anthropomorphism in trust formation, ultimately influencing chatbot use. Following the technology acceptance model and diffusion of innovations theory, a prior study <ref type="bibr" target="#b27">[28]</ref> examined the intention of users to use chatbots on smartphones for shopping. The study found that attitude toward chatbots was considerably influenced by perceived usefulness, the ease of use, enjoyment, price consciousness, perceived risk, and personal innovativeness. On the other hand, the intention to use was directly influenced only by trust, personal innovativeness, and attitude. Therefore, the study supports our findings by emphasizing the role of trust in the intention to use chatbots and adding other factors such as personal innovativeness and attitude. Similarly, a study <ref type="bibr" target="#b28">[29]</ref> reported that credibility, competence, anthropomorphism, social presence, and informativeness influence user trust in chatbots, affecting purchase intention-thus, emphasizing the importance of trust and its antecedents in determining the use of chatbots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical Contribution</head><p>Our study makes several important theoretical contributions to understanding trust and its role in adopting and using AI-based chatbots (ChatGPT). By examining the direct and indirect effects of trust on intentions to use and actual use of the technology, the study confirms the importance of trust in the adoption process. It extends the existing literature by highlighting the underlying mechanisms through which trust influences actual use. This new understanding contributes to developing a more comprehensive theoretical framework for studying chatbot adoption.</p><p>Our findings emphasize the critical role of trust in adopting and using chatbots. By demonstrating that trust has a significant direct effect on intentions to use and actual use, the study reinforces the centrality of trust in technology adoption research. This is consistent with the findings of prior literature, which also underscore the importance of trust in various aspects of chatbot adoption, such as initial trust <ref type="bibr" target="#b43">[44]</ref>, response to anthropomorphic attributes <ref type="bibr" target="#b44">[45]</ref>, and purchase intention <ref type="bibr" target="#b28">[29]</ref>.</p><p>Our study extends the existing literature by uncovering the mediating role of intention to use in the relationship between trust and actual use. By showing that the indirect effect of trust on actual use is partially mediated by intention to use, the study provides valuable insights into the mechanisms through which trust influences actual use. This novel contribution enhances our understanding of the complex interplay between trust and behavioral outcomes, laying the groundwork for future research on the dynamics of trust in technology adoption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Policy Implications</head><p>Our study's findings can significantly inform the decision-making processes for policy makers and public administrators as they face the challenges of implementing AI-driven solutions. By emphasizing the importance of trust, our study lays the groundwork for addressing potential pitfalls and governance challenges, ultimately promoting the successful integration of chatbots.</p><p>First, establishing trust in AI-powered conversational agents should be a priority for policy makers and technology developers. This can be achieved through transparent disclosure of the agents' operational processes, information sources, and guiding algorithms. Disclosures should be easily accessible, user-friendly, and presented in clear language. Additionally, conversational agents should include explicit disclaimers to minimize the risk of misleading or erroneous responses.</p><p>Second, developers and policy makers should design conversational agents prioritizing user needs and preferences. Incorporating features that allow users to tailor the agent's responses to their specific requirements, such as tone, vocabulary, and response time, will enhance user satisfaction. Furthermore, agents should prioritize providing accurate and relevant information while minimizing the potential for algorithmic bias, which could result in discriminatory or inaccurate responses.</p><p>Third, policy makers should encourage shared accountability to promote the responsible development and deployment of chatbots such as ChatGPT. We define shared accountability as a collaborative approach to ensuring the responsible development and deployment of AI-based technologies, involving stakeholders who share responsibility for ensuring the technology's accuracy, safety, and ethical use. This approach fosters a culture of transparency and responsibility, enabling stakeholders to identify and address potential issues and optimize the technology for the benefit of all users.</p><p>By promoting shared accountability, policy makers can help create a culture of responsibility and transparency that motivates all stakeholders to optimize the technology. For example, developers and data-quality teams will be motivated to ensure that the AI is accurate and reliable. At the same time, users will be encouraged to provide feedback and report any issues or concerns. This sense of accountability and responsibility can make a substantial difference in ensuring that the technology is developed and deployed in a responsible and ethical manner. Furthermore, shared accountability can help to address concerns around biases and other ethical considerations in AI development. By involving diverse stakeholders in the development process, policy makers can ensure that the technology is designed to meet the needs and expectations of a broad range of users while minimizing the risk of unintentional harm or bias.</p><p>Lastly, policy makers should establish policies and regulations promoting the responsible development and deployment of conversational agents <ref type="bibr" target="#b45">[46]</ref>. These policies should mandate adherence to ethical and legal guidelines related to privacy, data security, and bias. Policy makers should also provide guidance on appropriate use cases for conversational agents, such as information retrieval and customer service. Implementing such policies and regulations will ensure that conversational agents are developed and deployed to maximize benefits while minimizing potential risks and misuse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Practical Implications</head><p>Our study also contributes to the human factors and health sciences literature by examining the role of trust in adopting AI-driven chatbots such as ChatGPT for health-related purposes. Our findings align with and extend the current understanding of other studies by identifying key factors influencing user adoption, such as trustworthiness, algorithm quality, privacy, transparency, and brand value <ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref>. From a human factors perspective, our study emphasizes the importance of designing chatbot technologies that cater to user needs and preferences while addressing potential concerns and risks.</p><p>Moreover, given the increasing use of AI-powered chatbots for various activities, it is important to note that many respondents used the technology for health-related queries. This implies that health providers can leverage chatbots to provide health information and support to patients <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52]</ref>. However, to ensure user safety and the accuracy of health information provided, health providers must collaborate with technology providers to develop and integrate reliable and trustworthy health-related information sources into the chatbots <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b52">53]</ref>. Given the complexity and sensitivity of health-related issues, users must exercise caution when seeking health advice from an AI chatbot such as ChatGPT. Users should be aware of the limitations of AI technology in the medical field and should not use ChatGPT as a replacement for professional medical advice. To mitigate these risks, it may be useful for ChatGPT developers to provide clear disclaimers and warnings regarding the limitations of the technology in the medical field and simultaneously work toward integrating reliable medical databases to provide more accurate and trustworthy health advice.</p><p>Although risks are associated with excessive trust in AI-driven chatbots such as ChatGPT, it is important to recognize that these technologies continually evolve as they process new data from the internet. However, biased or false information across the web can potentially influence ChatGPT's responses, reinforcing misinformation or perpetuating skew perspectives. To address this concern, a proactive approach should be gradually adopted to develop mechanisms that filter out false or biased information from the chatbot's training model.</p><p>Since data floating on the internet can be manipulated, systematic efforts should be made to design and implement robust algorithms that identify and remove unreliable or unbalanced data, ensuring that ChatGPT is trained on diverse and accurate information. This can help prevent the chatbot from placing excessive weightage on certain polarities of data, which may result from skewed information on the internet. By refining the chatbot's training model and incorporating more reliable data sources, the performance of ChatGPT can be continually improved to provide more accurate and unbiased responses.</p><p>In addition to these technological improvements, collaboration between developers, subject matter experts, and human factors researchers can further ensure that AI-driven chatbots such as ChatGPT are designed and deployed with a comprehensive understanding of user needs and potential challenges. By addressing the risks associated with excessive trust and actively improving the chatbot's performance, the development and application of AI-driven technologies such as ChatGPT can continue advancing, promoting positive outcomes and responsible use in various domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>Our study has limitations, including using a cross-sectional survey and self-report measures, which may introduce biases. The limited geographic scope of the sample, focused on US respondents, may affect the generalizability of our findings to other cultural contexts. Future research should use longitudinal data; explore trust in chatbot adoption across different cultural contexts; and control for potential confounding factors such as participants' familiarity with AI technology, prior experiences with chatbots, and demographic factors. Future research should use various methods, such as tracking actual chatbot use and conducting qualitative interviews, to assess trust and user behavior. Increasing data collection frequency and ensuring participants' anonymity can also help mitigate biases. Future research can better understand trust's role in chatbot adoption by addressing these limitations and enabling developers and organizations to design technologies that meet users' needs and expectations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Our study provides novel insights into the factors driving the adoption of chatbot technologies such as ChatGPT. Our results suggest that trust is critical to users' adoption of ChatGPT and few people tend to use it for health-related queries. Even as ChatGPT evolves, it remains crucial to highlight that this tool, while powerful, was not initially designed with a specific focus on health care applications. Therefore, an overreliance on it for health-related advice or diagnoses could potentially lead to misinformation and subsequent health risks.</p><p>Efforts must also be focused on improving the system's ability to distinguish between queries that it can safely handle and those that should be redirected to a human health care professional.</p><p>Companies and policy makers should prioritize building trust and transparency in developing and deploying chatbots. Although risks are associated with excessive trust in AI-driven chatbots such as ChatGPT, it is important to recognize that the potential risks can be reduced by advocating for shared accountability and fostering collaboration between developers, subject matter experts (such as health care professionals), and human factors researchers.</p><p>A systematic collaborative approach can ensure that AI-driven chatbots are designed and deployed with a comprehensive understanding of user needs and potential challenges. By addressing the risks associated with excessive trust and actively improving the chatbot's performance, the development and application of AI-driven technologies such as ChatGPT can continue advancing, promoting positive outcomes and responsible use in various domains. ©Avishek Choudhury, Hamid Shamszare. Originally published in the Journal of Medical Internet Research (<ref type="url" target="https://www.jmir.org">https://www.jmir.org</ref>), 14.06.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ref type="url" target="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ref>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on <ref type="url" target="https://www.jmir.org/">https://www.jmir.org/</ref>, as well as this copyright and license information must be included.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>H1: User's intent to use ChatGPT increases with their trust in the technology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>•H2:</head><label></label><figDesc>The actual use of ChatGPT increases with users' intent to use the technology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>•H3:</head><label></label><figDesc>The actual use of ChatGPT increases with users' trust in the technology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>•</head><label></label><figDesc>H4: Users' intent to use ChatGPT can partially mediate the effect of trust in the technology on its actual use.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The conceptual structural framework. H1 through H4 indicate the hypotheses. The dashed line connecting trust and actual use indicates the indirect effect, whereas solid lines indicate the direct paths.</figDesc><graphic coords="3,56.69,92.57,481.82,193.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Conceptual framework illustrating the significant paths connecting trust in ChatGPT (Chat Generative Pre-trained Transformer), users' intent to use ChatGPT, and its actual use (AU). T1 through T7: factors for trust; U1 through U3: factors for intent to use. *P&lt;.05 and ***P&lt;.001.</figDesc><graphic coords="6,56.69,92.57,481.82,187.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Descriptive statistics of study variables (N=607).</figDesc><table><row><cell>Value, mean (SD)</cell></row></table><note><p>a ChatGPT: Chat Generative Pre-trained Transformer.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Model fit and reliability measures.</figDesc><table><row><cell>Intent to Use</cell><cell>Actual Use</cell></row></table><note><p>b AVE: average variance extracted.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Discriminant validity measures.</figDesc><table><row><cell></cell><cell>Original estimate</cell><cell>Bootstrap, mean (SD)</cell><cell>95% CI</cell></row><row><cell>Trust → Intent to Use</cell><cell>0.896</cell><cell>0.897 (0.035)</cell><cell>0.827-0.962</cell></row><row><cell>Trust → Actual Use</cell><cell>0.320</cell><cell>0.320 (0.040)</cell><cell>0.241-0.397</cell></row><row><cell>Intent to Use → Actual Use</cell><cell>0.320</cell><cell>0.321 (0.044)</cell><cell>0.233-0.406</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>J Med Internet Res 2023 | vol. 25 | e47184 | p. 2 https://www.jmir.org/2023/1/e47184 (page number not for citation purposes)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>J Med Internet Res 2023 | vol. 25 | e47184 | p. 3 https://www.jmir.org/2023/1/e47184 (page number not for citation purposes)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>J Med Internet Res 2023 | vol. 25 | e47184 | p. 4 https://www.jmir.org/2023/1/e47184 (page number not for citation purposes)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>(page number not for citation purposes)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>J Med Internet Res 2023 | vol. 25 | e47184 | p. 6 https://www.jmir.org/2023/1/e47184 (page number not for citation purposes)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>J Med Internet Res 2023 | vol. 25 | e47184 | p. 7 https://www.jmir.org/2023/1/e47184 (page number not for citation purposes)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>J Med Internet Res 2023 | vol. 25 | e47184 | p. 10 https://www.jmir.org/2023/1/e47184 (page number not for citation purposes)</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>J Med Internet Res 2023 | vol. 25 | e47184 | p. 11 https://www.jmir.org/2023/1/e47184 (page number not for citation purposes)</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of Interest</head><p>None declared. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abbreviations</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The impact of artificial intelligence in medicine on the future role of the physician</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Ahuja</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj.7702</idno>
		<idno>Medline: 31592346</idno>
	</analytic>
	<monogr>
		<title level="j">PeerJ</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">7702</biblScope>
			<date type="published" when="2019-10-04">2019 Oct 4</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Artificial Intelligence: A Modern Approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Pearson Education, Inc</publisher>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Artificial intelligence -where are we?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Bobrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Hayes</surname></persName>
		</author>
		<idno type="DOI">10.1016/0004-3702(85)90077-3</idno>
	</analytic>
	<monogr>
		<title level="j">Artif Intell</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="375" to="415" />
			<date type="published" when="1985-03">1985 Mar</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning from artificial intelligence&apos;s previous awakenings: the history of expert systems</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Brock</surname></persName>
		</author>
		<idno type="DOI">10.1609/aimag.v39i3.2809</idno>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2018-09-28">2018 Sep 28</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Expert systems versus systems for experts: computer-aided dispatch as a support system in real-world environments. Cambridge Series on Human Computer Interaction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Whalen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="161" to="183" />
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Introducing</forename><surname>Chatgpt</surname></persName>
		</author>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<idno>2023-05-29</idno>
		<ptr target="https://openai.com/blog/chatgpt" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ChatGPT: the future of discharge summaries? Lancet Digit Health</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lam</surname></persName>
		</author>
		<idno type="DOI">10.1016/S2589-7500(23)00021-3</idno>
		<imprint>
			<date type="published" when="2023-03">2023 Mar</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="107" to="e108" />
		</imprint>
	</monogr>
	<note>FREE Full text. Medline: 36754724</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">How does ChatGPT perform on the United States Medical Licensing Examination? the implications of large language models for medical education and knowledge assessment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Safranek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Socrates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><forename type="middle">L</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename></persName>
		</author>
		<idno type="DOI">10.2196/45312</idno>
		<idno>Medline: 36753318</idno>
	</analytic>
	<monogr>
		<title level="j">JMIR Med Educ</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">45312</biblScope>
			<date type="published" when="2023-03-08">2023 Mar 08</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ChatGPT and other artificial intelligence applications speed up scientific writing</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1097/JCMA.0000000000000900</idno>
		<idno>Medline: 36791246</idno>
	</analytic>
	<monogr>
		<title level="j">J Chin Med Assoc</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="351" to="353" />
			<date type="published" when="2023-04-01">2023 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ChatGPT: future directions and open possibilities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aljanabi</surname></persName>
		</author>
		<idno type="DOI">10.58496/mjcs/2023/003</idno>
	</analytic>
	<monogr>
		<title level="j">Mesopotamian Journal of CyberSecurity</title>
		<imprint>
			<biblScope unit="volume">2023</biblScope>
			<biblScope unit="page" from="16" to="17" />
			<date type="published" when="2023-01-31">2023 Jan 31</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cheatham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Medenilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sillos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Leon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Elepaño</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000198</idno>
		<idno>Medline: 36812645</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS Digit Health</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">198</biblScope>
			<date type="published" when="2023-03">2023 Mar</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ChatGPT: five priorities for research</title>
		<author>
			<persName><forename type="first">Eam</forename><surname>Van Dis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zuidema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Rooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Bockting</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-023-00288-7</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">614</biblScope>
			<biblScope unit="issue">7947</biblScope>
			<biblScope unit="page" from="224" to="226" />
			<date type="published" when="2023-03-03">2023 Mar 03</date>
		</imprint>
	</monogr>
	<note>FREE Full text. Medline: 36737653</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ChatGPT and the future of medical writing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<idno type="DOI">10.1148/radiol.223312</idno>
		<idno>Medline: 36728748</idno>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">307</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">223312</biblScope>
			<date type="published" when="2023-04-01">2023 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">ChatGPT passing USMLE shines a spotlight on the flaws of medical education. PLOS Digit Health</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Mbakwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lourentzou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Mechanic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dagan</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pdig.0000205</idno>
		<idno>Medline: 36812618</idno>
		<imprint>
			<date type="published" when="2023-03-09">2023 Mar 9</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">205</biblScope>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Chatting about ChatGPT: how may AI and GPT impact academia and libraries? Library Hi Tech News</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1108/lhtn-01-2023-0009</idno>
		<imprint>
			<date type="published" when="2023-02-14">2023 Feb 14</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="26" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ChatGPT: bullshit spewer or the end of traditional assessments in higher education</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.37074/jalt.2023.6.1.9</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Learning and Teaching</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2023-01-24">2023 Jan 24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ChatGPT is shaping the future of medical writing but still requires human judgment</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Kitamura</surname></persName>
		</author>
		<idno type="DOI">10.1148/radiol.230171</idno>
		<idno>Medline: 36728749</idno>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">307</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">230171</biblScope>
			<date type="published" when="2023-04-01">2023 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Is ChatGPT better than human annotators? potential and limitations of ChatGPT in explaining implicit hate speech. 2023 Apr 30 Presented at: WWW &apos;23: The ACM</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><forename type="middle">J</forename></persName>
		</author>
		<idno type="DOI">10.1145/3543873.3587368</idno>
		<imprint>
			<date type="published" when="2023-04-30">2023. April 30 to May 4, 2023</date>
			<biblScope unit="page" from="294" to="297" />
			<pubPlace>Austin, TX</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Are ChatGPT and AlphaCode going to replace programmers?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Castelvecchi</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-022-04383-z</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="2022-12-08">2022 Dec 08</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health. Front Public Health</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Angelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Baglivo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Arzilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Privitera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Tozzi</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpubh.2023.1166120</idno>
		<idno>Medline: 37181697</idno>
		<imprint>
			<date type="published" when="2023-04-25">2023 Apr 25</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1166120</biblScope>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What does ChatGPT say: the DAO from algorithmic intelligence to linguistic intelligence</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/jas.2023.123486</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA J Autom Sinica</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="575" to="579" />
			<date type="published" when="2023-03">2023 Mar</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ChatGPT and antimicrobial advice: the end of the consulting infection doctor?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gerada</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1473-3099(23)00113-5</idno>
	</analytic>
	<monogr>
		<title level="j">Lancet Infect Dis</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="405" to="406" />
			<date type="published" when="2023-04">2023 Apr</date>
		</imprint>
	</monogr>
	<note>Medline: 36822213</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ChatGPT is fun, but not an author</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Thorp</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.adg7879</idno>
		<idno>Medline: 36701446</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="issue">6630</biblScope>
			<biblScope unit="page">313</biblScope>
			<date type="published" when="2023-01-27">2023 Jan 27</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generating scholarly content with ChatGPT: ethical challenges for medical publishing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Liebrenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buadze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bhugra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1016/S2589-7500(23)00019-5</idno>
	</analytic>
	<monogr>
		<title level="j">Lancet Digit Health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="105" to="e106" />
			<date type="published" when="2023-03">2023 Mar</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robot acceptance model for care (RAM-care): a principled approach to the intention to use care robots</title>
		<author>
			<persName><forename type="first">T</forename><surname>Turja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Aaltonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Taipale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oksanen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.im.2019.103220</idno>
	</analytic>
	<monogr>
		<title level="j">Information &amp; Management</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">103220</biblScope>
			<date type="published" when="2020-07">2020 Jul</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The study on the factors influencing on the behavioral intention of chatbot service for the financial sector: focusing on the UTAUT model. Article in Korean</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.9728/dcs.2019.20.1.41</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Contents Society</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="50" />
			<date type="published" when="2019-01-31">2019 Jan 31</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Factors influencing adoption intention of AI powered chatbot for public transport services within a smart city</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kuberkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Emerging Technologies in Learning</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="948" to="958" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Understanding the attitude and intention to use smartphone chatbots for shopping</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Kasilingam</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.techsoc.2020.101280</idno>
	</analytic>
	<monogr>
		<title level="j">Technology in Society</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">101280</biblScope>
			<date type="published" when="2020-08">2020 Aug</date>
		</imprint>
	</monogr>
	<note>FREE Full text</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trust me, if you can: a study on the factors that influence consumers&apos; purchase intention triggered by chatbots based on brain image evidence and self-reported assessments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Chiang</surname></persName>
		</author>
		<idno type="DOI">10.1080/0144929x.2020.1743362</idno>
	</analytic>
	<monogr>
		<title level="j">Behaviour &amp; Information Technology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1177" to="1194" />
			<date type="published" when="2020-03-24">2020 Mar 24</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Can we trust health and wellness chatbot going mobile? empirical research using TAM and HBM</title>
		<author>
			<persName><forename type="first">K</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kulkarni</surname></persName>
		</author>
		<idno type="DOI">10.1109/tensymp54529.2022.9864368</idno>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE Region 10 Symposium (TENSYMP)</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022-08-29">2022 Aug 29. July 1-3, 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Assessing acceptance of assistive social agent technology by older adults: the Almere model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Heerink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kröse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Evers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wielinga</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12369-010-0068-5</idno>
	</analytic>
	<monogr>
		<title level="j">Int J of Soc Robotics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="361" to="375" />
			<date type="published" when="2010-09-04">2010 Sep 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Analyzing the determinants to accept a virtual assistant and use cases among cancer patients: a mixed methods study</title>
		<author>
			<persName><forename type="first">Mjp</forename><surname>Van Bussel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Odekerken-Schröder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Swart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mjg</forename><surname>Jacobs</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12913-022-08189-7</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Health Serv Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">890</biblScope>
			<date type="published" when="2022-07-09">2022 Jul 09</date>
		</imprint>
	</monogr>
	<note>FREE Full text. Medline: 35804356</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mobile apps for healthy living: factors influencing continuance intention for health apps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Filieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Raguseo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gorton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.techfore.2021.120644</idno>
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page">120644</biblScope>
			<date type="published" when="2021-05">2021 May</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Chatbot acceptance in healthcare: explaining user adoption of conversational agents for disease diagnosis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Laumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Gubler</surname></persName>
		</author>
		<idno type="DOI">10.1145/3322385.3322392</idno>
		<ptr target="https://aisel.aisnet.org/ecis2019_rp/88/" />
	</analytic>
	<monogr>
		<title level="m">27th European Conference on Information Systems (ECIS)</title>
		<meeting><address><addrLine>Stockholm &amp; Uppsala, Sweden URL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-08">2019. June 8-14, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Determinants of continuance intention towards banks&apos; chatbot services in Vietnam: a necessity for sustainable development</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yth</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<idno type="DOI">10.3390/su13147625</idno>
	</analytic>
	<monogr>
		<title level="j">Sustainability</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">7625</biblScope>
			<date type="published" when="2021-07-08">2021 Jul 08</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">R: a language for data analysis and graphics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ihaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gentleman</surname></persName>
		</author>
		<idno type="DOI">10.1080/10618600.1996.10474713</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="1996-09">1996 Sep</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Jfj</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gtm</forename><surname>Hult</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Danks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><forename type="middle">S</forename><surname>The Seminr Package</surname></persName>
		</author>
		<title level="m">Partial Least Squares Structural Equation Modeling (PLS-SEM) Using R: A Workbook</title>
		<meeting><address><addrLine>Cham, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021-11-04">Nov 4, 2021</date>
			<biblScope unit="page" from="49" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Impact of entrepreneurial leadership on project success: mediating role of knowledge management processes. Leadership &amp; Organization Development Journal</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Latif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shahzad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Imranullah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">F</forename><surname>Sahibzada</surname></persName>
		</author>
		<idno type="DOI">10.1108/lodj-07-2019-0323</idno>
		<imprint>
			<date type="published" when="2020-04-04">2020 Apr 4</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="237" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<author>
			<persName><forename type="first">Ab</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mohmad</forename><surname>Sidek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename></persName>
		</author>
		<idno type="DOI">10.1088/1742-6596/890/1/012163</idno>
	</analytic>
	<monogr>
		<title level="m">1st International Conference on Applied &amp; Industrial Mathematics and Statistics</title>
		<meeting><address><addrLine>Pahang, Malaysia</addrLine></address></meeting>
		<imprint>
			<publisher>Kuantan</publisher>
			<date type="published" when="2017-08-08">2017 Sep 20. 2017. 2017. August 8-10, 2017</date>
			<biblScope unit="volume">890</biblScope>
			<biblScope unit="page">12163</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">PLS-SEM: indeed a silver bullet</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarstedt</surname></persName>
		</author>
		<idno type="DOI">10.2753/mtp1069-6679190202</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Theory and Practice</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="152" />
			<date type="published" when="2014-12-08">2014 Dec 08</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">When to use and how to report the results of PLS-SEM</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Risher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<idno type="DOI">10.1108/ebr-11-2018-0203</idno>
	</analytic>
	<monogr>
		<title level="j">European Business Review</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="24" />
			<date type="published" when="2019-01-14">2019 Jan 14</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mirror, mirror on the wall: a comparative evaluation of composite-based structural equation modeling methods</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gtm</forename><surname>Hult</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiele</forename><surname>Ko</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11747-017-0517-x</idno>
	</analytic>
	<monogr>
		<title level="j">J Acad Mark Sci</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="616" to="632" />
			<date type="published" when="2017-02-16">2017 Feb 16</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The use of partial least squares structural equation modelling (PLS-SEM) in management accounting research: directions for future theory development</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nitzl</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.acclit.2016.09.003</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Accounting Literature</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="19" to="35" />
			<date type="published" when="2016-12">2016 Dec</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Antecedents and consequences of chatbot initial trust</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kasamani</surname></persName>
		</author>
		<idno type="DOI">10.1108/ejm-02-2020-0084</idno>
	</analytic>
	<monogr>
		<title level="j">Eur J Mark</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1748" to="1771" />
			<date type="published" when="2021-10-20">2021 Oct 20</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Human vs. AI: understanding the impact of anthropomorphism on consumer response to chatbots from the perspective of trust and relationship norms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mou</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2022.102940</idno>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">102940</biblScope>
			<date type="published" when="2022-05">2022 May</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">ChatGPT and the AI Act</title>
		<author>
			<persName><forename type="first">N</forename><surname>Helberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<idno type="DOI">10.14763/2023.1.1682</idno>
	</analytic>
	<monogr>
		<title level="j">Internet Policy Review</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2023-02-16">2023 Feb 16</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cascella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Montomoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bellini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bignami</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-023-01925-4</idno>
	</analytic>
	<monogr>
		<title level="j">J Med Syst</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2023-03-04">2023 Mar 04</date>
		</imprint>
	</monogr>
	<note>FREE Full text. Medline: 36869927</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">An interview with ChatGPT about health care. NEJM Catalyst</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Asch</surname></persName>
		</author>
		<idno type="DOI">10.1056/CAT.23.0043</idno>
		<imprint>
			<date type="published" when="2023-04-04">2023 Apr 4</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">ChatGPT: is this version good for healthcare and research</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vaishya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vaish</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dsx.2023.102744</idno>
	</analytic>
	<monogr>
		<title level="j">Diabetes Metab Syndr</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">102744</biblScope>
			<date type="published" when="2023-04">2023 Apr</date>
		</imprint>
	</monogr>
	<note>Medline: 36989584</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Transforming maritime health with ChatGPT-powered healthcare services for mariners</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10439-023-03195-0</idno>
	</analytic>
	<monogr>
		<title level="j">Ann Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1123" to="1125" />
			<date type="published" when="2023-06">2023 Jun</date>
		</imprint>
	</monogr>
	<note>Medline: 37040060</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Can ChatGPT pass the life support exams without entering the American Heart Association course?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Fijačko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gosak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Štiglic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Douma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.resuscitation.2023.109732</idno>
	</analytic>
	<monogr>
		<title level="j">Resuscitation</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page">109732</biblScope>
			<date type="published" when="2023-04">2023 Apr</date>
		</imprint>
	</monogr>
	<note>Medline: 36775020</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">I asked a ChatGPT to write an editorial about how we can incorporate chatbots into neurosurgical research and patient care…</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>D'amico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Langer</surname></persName>
		</author>
		<idno type="DOI">10.1227/neu.0000000000002414</idno>
		<idno>Medline: 36757199</idno>
	</analytic>
	<monogr>
		<title level="j">Neurosurgery</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="663" to="664" />
			<date type="published" when="2023-04-01">2023 Apr 01</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Evaluating ChatGPT as an adjunct for radiologic decision-making</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kamineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Succi</surname></persName>
		</author>
		<idno type="DOI">10.1101/2023.02.02.23285399</idno>
		<idno>Medline: 36798292</idno>
		<imprint/>
	</monogr>
	<note>medRxiv Preprint posted online on February 7, 2023 [FREE Full text</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
