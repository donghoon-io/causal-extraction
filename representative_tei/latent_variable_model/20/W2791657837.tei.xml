<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Consistent Partial Least Squares Path Modeling via Regularization</title>
				<funder>
					<orgName type="full">Ministry of Education of the Republic of Korea</orgName>
				</funder>
				<funder ref="#_X7BUBnN">
					<orgName type="full">National Research Foundation of Korea</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2018-02-19">19 February 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">James</forename><surname>Gaskin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jaehong</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sunho</forename><surname>Jung</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Universidade Federal de Minas Gerais</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Brigham Young University</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Kyung Hee University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Consistent Partial Least Squares Path Modeling via Regularization</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-02-19">19 February 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3389/fpsyg.2018.00174</idno>
					<note type="submission">This article was submitted to Quantitative Psychology and Measurement, a section of the journal Frontiers in Psychology Received: 02 December 2017 Accepted: 01 February 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T18:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>consistent partial least squares</term>
					<term>structural equation modeling</term>
					<term>ridge-type regularization</term>
					<term>multicollinearity</term>
					<term>Monte Carlo simulation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Partial least squares (PLS) path modeling is a component-based structural equation modeling that has been adopted in social and psychological research due to its data-analytic capability and flexibility. A recent methodological advance is consistent PLS (PLSc), designed to produce consistent estimates of path coefficients in structural models involving common factors. In practice, however, PLSc may frequently encounter multicollinearity in part because it takes a strategy of estimating path coefficients based on consistent correlations among independent latent variables. PLSc has yet no remedy for this multicollinearity problem, which can cause loss of statistical power and accuracy in parameter estimation. Thus, a ridge type of regularization is incorporated into PLSc, creating a new technique called regularized PLSc. A comprehensive simulation study is conducted to evaluate the performance of regularized PLSc as compared to its non-regularized counterpart in terms of power and accuracy. The results show that our regularized PLSc is recommended for use when serious multicollinearity is present.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Structural equation modeling (SEM) has become a common tool in social and psychological research, including business research fields such as marketing and information systems. In no small part, this is due to its ability to provide a flexible measurement and testing framework for investigating interrelationships among observed and latent variables <ref type="bibr" target="#b22">(Kaplan, 2009)</ref>. Covariance structure analysis (CSA) <ref type="bibr" target="#b21">(Jöreskog, 1973)</ref> and partial least squares (PLS) path modeling <ref type="bibr" target="#b32">(Wold, 1975)</ref> represent two technically distinctive approaches to SEM <ref type="bibr" target="#b10">(Fornell and Bookstein, 1982;</ref><ref type="bibr" target="#b28">Reinartz et al., 2009)</ref>. Recently, a new consistent PLS estimator (PLSc) has been introduced as another alternative approach that bridges the gap between CSA and PLS <ref type="bibr" target="#b5">(Dijkstra, 2010;</ref><ref type="bibr" target="#b6">Dijkstra and Henseler, 2015a)</ref>. This technique rests on the idea that when PLS represents latent variables through factors, correcting for a measurement error is required to obtain consistent PLS estimates.</p><p>With the introduction of PLSc, some interest exists in evaluating its relative performance, when compared to CSA and PLS. A recent simulation study by <ref type="bibr" target="#b7">Dijkstra and Henseler (2015b)</ref> showed that PLSc is recommended for use over traditional PLS, if the common factor model holds true for the theoretical construct. This finding is expected, given that PLSc explicitly takes the reliability of construct scores into account, and therefore, corrects the structural paths between the latent variables for attenuation, thereby enabling consistent estimates to be produced. The ability of PLSc to perform well with common factors is an important result, because SEM is frequently conducted with reflectively measured constructs.</p><p>However, <ref type="bibr" target="#b7">Dijkstra and Henseler (2015b)</ref> clearly pointed out the potential weakness of PLSc in their simulation study, as it exhibited relatively lower statistical power and larger standard deviations under multicollinearity, as compared to other techniques. This tendency was particularly evident and problematic with small sample sizes. In practice, a high level of correlations among the latent variables is known to be quite common in the applied research <ref type="bibr" target="#b12">(Grewal et al., 2004)</ref>. In addition, because PLSc employs inter-construct correlations corrected for attenuation as input data for parameter estimations, it would likely encounter multicollinearity problems due to the possibly high correlation between independent variables. The major problem with multicollinearity is that the least squares estimators of the coefficients can produce inflated standard errors, often leading to the loss of statistical power.</p><p>Despite potential multicollinearity problems, no attempt has been made to provide methods for mitigating the problems in PLSc. Therefore, in this paper, we propose a new approach, a ridge-type of regularization, to solve multicollinearity issues in PLSc. Ridge regression <ref type="bibr" target="#b19">(Hoerl and Kennard, 1970)</ref> is one of the possible remedies for multicollinearity in the statistical learning literature, by intentionally trading a small amount of bias for greater efficiency. Derived as an alternative to the ordinary least squares (OLS) regression estimator in the PLSc procedure, we propose a ridge least squares estimator by adding a small positive constant, called the regularization parameter, to the estimation in a straightforward manner.</p><p>The major purpose of this paper is to propose a regularized model of PLSc which handles multicollinearity problems effectively. By doing so, we believe that we can contribute to the related literature. As some researchers have already acknowledged that multicollinearity in PLSc can arouse problems in the estimation, we believe it is necessary for other researchers to consider our new approach, a ridge-type of regularization, to solve the multicollinearity issues in PLSc. The second goal of this paper is to present a comprehensive evaluation of the proposed method, relative to its non-regularized counterpart, under a variety of experimentally manipulated conditions using a Monte Carlo simulation study. With a comprehensive Monte Carlo simulation, our proposed regularized PLSc is better in dealing with a severe multicollinearity problem with common factors than ordinary PLSc.</p><p>In the next section, we discuss the previous PLSc and then propose our theoretical concept of regularized PLSc in a structural equation model. We then suggest a simulation study to confirm the newly proposed model's performance, as compared to the previous method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONSISTENT PARTIAL LEAST SQUARES VIA REGULARIZATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Consistent Reliability Coefficient for PLS</head><p>Traditional PLS approximates common factors with weighted composites of observed variables. Since the composites serve as proxies for the reflective constructs, PLS construct scores are inevitably contaminated with measurement errors. Measurement errors attenuate the relationship between any two constructs, resulting in biased and inconsistent estimates of structural relationships (e.g., <ref type="bibr" target="#b1">Bollen, 1989;</ref><ref type="bibr" target="#b2">Cassel et al., 2000)</ref>. Correcting for measurement error attenuation would be worthwhile, as a structural equation model typically contains one or more common factors.</p><p>To achieve this purpose, <ref type="bibr" target="#b7">Dijkstra and Henseler (2015b)</ref> have recently proposed a consistent reliability coefficient term ρ A , based on the estimation of the indicator weights under Mode A, suitable for reflective indicators. This plays a pivotal role in mitigating PLS' consistency problems in SEM with reflective measurement models. PLSc employs the coefficient of reliability to correct the latent variable correlations for attenuation, thereby adjusting the estimates to make them consistent.</p><p>The reliability measure for PLS' construct scores is determined as the squared correlation between composite scores for each latent variable and the corresponding true scores. A consistent estimator of ρ A can be obtained so as to minimize the sums of squares of the discrepancies between the off-diagonal elements of S and ˆ , in which S is the sample covariance matrix of a latent variable's indicators and ˆ is the implied covariance matrix based on a underlying common factor model. The coefficient of reliability can be consistently estimated using the indicator weights as follows <ref type="bibr" target="#b7">(Dijkstra and Henseler, 2015b)</ref>:</p><formula xml:id="formula_0">ρA = ( ŵ′ ŵ) 2 × ŵ′ (S -diag(S)) ŵ ŵ′ ( ŵ ŵ′ -diag( ŵ ŵ′ )) ŵ , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where ŵ is the estimated weight vector for a block of indicators for the latent variable. In particular, the second part of this equation simply represents a scaling factor corresponding to the constant of proportionality between the indicator weights and the factor loadings. It plays a role in rescaling the former to the latter to adjust for an overestimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularized Consistent PLS</head><p>PLS involves two distinct models: a structural model and a measurement model. As the structural model of PLS includes a series of linear regression models for each endogenous latent variable, we begin by describing the path coefficient estimation procedures for the PLSc. The estimation procedure comprises three main steps: (1) estimate the iteratively updated indicator weights to obtain the latent variable correlations;</p><p>(2) correct these correlations for attenuation using the consistent reliability estimates; and (3) perform the OLS regression to estimate the path coefficients based on the consistent construct correlations.</p><p>Step 1: The first step is to attempt to create latent variable proxies as linear composites of the associated observed indicators, which requires the estimation of indicator weights. This stage involves an iterative algorithm for the estimation of the weights. Accordingly, each latent variable explains as much variance as possible, with adjacent latent variables that are connected to the same latent variable. This step produces the indicator weights and correlations between the latent variable scores as inputs for the next step.</p><p>Step 2: Due to the presence of measurement errors, proxy correlations typically tend to underestimate the true factor correlations. As correlations among the proxies are mainly used for the estimation of the path coefficient in PLSc, a conventional attenuation correction factor can be applicable (e.g., <ref type="bibr" target="#b26">Muchinsky, 1996)</ref>. Specifically, for every pair of composite scores, a consistent construct correlation may be expressed in terms of the original proxy correlations and the two reliabilities obtained in Equation (1). That is, it is calculated by the ratio of the correlation between the construct scores to the square root of their respective reliabilities. Consequently, the correlations between the proxies associated with large measurement errors may be given greater weight than the correlations associated with smaller measurement errors.</p><p>Step 3: By correcting for the attenuation, due to the unreliability, as in the previous step, we are able to determine the underlying latent relationships without the distraction of measurement errors. The third step estimates the path coefficients in the structural model by means of an OLS regression. In other words, the PLSc estimator is obtained by regressing each endogenous latent variable on its causally related latent variables as follows:</p><formula xml:id="formula_2">β = R -1 X r Xy ,<label>(2)</label></formula><p>where β indicates a vector of path coefficients, R X is the consistent correlation matrix of the predictor variables of the structural equation, and r Xy is the vector of consistent correlations between the outcome variable and the predictor variables. This illustrates that the PLSc estimator stems from the OLS regression and consistent correlation estimation. Several variance-based SEM techniques exist, but PLSc seems to be the preferred choice of researchers for evaluating the structural model with common factors. However, although a consistent reliability coefficient helps to establish consistent estimations in the model involving factors, rather ironically, the correction for attenuation is likely to lead to a multicollinearity problem, which can give rise to spurious results. Multicollinearity is considered a major application problem in SEM, because it reduces statistical power and increases the variances for the estimated coefficients, making them unstable <ref type="bibr" target="#b12">(Grewal et al., 2004)</ref>. The more variance the coefficients have, the more difficult it is to interpret them.</p><p>To address this issue, a regularized extension of the PLSc is proposed that integrates a ridge-type of regularization into PLSc. Estimating the path parameters through regularization is straightforward. A ridge least squares estimator for β is given by:</p><formula xml:id="formula_3">β (λ) = (R X + λI) -1 r Xy ,<label>(3)</label></formula><p>where: λ denotes the regularization parameter (or tuning parameter). When λ = 0, the ridge estimates are equivalent to those obtained using ordinary PLSc (Equation <ref type="formula" target="#formula_2">2</ref>). As with PLSc, the ridge estimator can be used as a tool for recursive models that only include unidirectional effects. The proposed regularized PLSc initially entails finding an appropriate value of the regularization parameter. It then estimates the path parameters using Equation ( <ref type="formula" target="#formula_3">3</ref>), for which an optimal value of λ is included in the analysis.</p><p>A significant number of studies emphasize the practical utility of regularization in many multivariate data analysis techniques <ref type="bibr" target="#b16">(Hastie et al., 2001;</ref><ref type="bibr" target="#b31">Tenenhaus and Tenenhaus, 2011;</ref><ref type="bibr" target="#b30">Srivastava et al., 2014)</ref>. In general, the regularization parameter plays a crucial role in controlling the degree of regularization imposed on the parameters. It has the effect of shrinking the least squares estimates toward zero, thereby enabling more accurate solutions to be produced. A regularized estimator intentionally trades bias for reduction in variance. As such, it will certainly be biased (albeit slightly), but will still exhibit a much smaller variability. Therefore, the ridge estimates of parameters tend to be, on average, closer to the true population values than their least squares counterparts (see <ref type="bibr">Groß, 2003, pp. 118-120)</ref>. In particular, this positive effect of regularization is more pronounced under multicollinearity and/or small sample sizes <ref type="bibr">(Takane and Jung, 2008)</ref>.</p><p>The proposed method utilizes the K-fold cross-validation method to select the value of λ, which is typically a small positive constant. In the cross validation, the entire dataset is randomly divided into K subsets (typically, either 5 or 10). One of the K subsets is set aside as a validation sample, while the remaining K-1 subsets are used as a training sample for fitting a single structural equation model for each endogenous construct from which the estimates of the path coefficients are obtained. These resultant estimates are then applied to the validation sample to calculate the prediction error of the structural model. This procedure is repeated k times, changing a single group set aside systematically. The cross-validation estimate of the prediction error is accumulated over all K validation samples. The cross validation procedure also systematically varies the values of λ and the value that yields the lowest prediction error is finally chosen. When K is equal to N (sample size in the original data), the cross validation procedure is also known as the leaving-oneout cross validation, which appears to work reasonably well with small sample sizes (e.g., <ref type="bibr" target="#b25">Molinaro et al., 2005)</ref>.</p><p>As in its ordinary counterpart, the proposed regularized PLSc uses the bootstrap method <ref type="bibr" target="#b8">(Efron, 1982)</ref> to estimate the standard errors of the parameter estimates. More specifically, their standard errors are calculated non-parametrically based on 5,000 bootstrap samples <ref type="bibr" target="#b15">(Hair et al., 2011)</ref>. Furthermore, the bootstrap standard errors can be used to test whether a structural parameter is statistically different from zero, based on a confidence interval approach (Aguirre-Urreta and Rönkkö, forthcoming). For instance, if the 95% confidence interval of a parameter does not include zero, then the observed effect may be considered statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A SIMULATION STUDY</head><p>The primary goal of the present simulation study is to compare the performance of the proposed regularized PLSc (hereafter referred to as RegPLSc) with that of the non-regularized PLSc. A secondary goal is to evaluate the impact of a comprehensive set of design factors and their interactions on the performance of these two estimation methods. This study builds on earlier work <ref type="bibr" target="#b12">(Grewal et al., 2004)</ref>, examining the role of multicollinearity and measurement errors on parameter recovery and inference errors in SEM. All computations for this study were carried out using MATLAB R2009a (The MathWorks, Inc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design Factors</head><p>The Monte Carlo simulation involved manipulating four experimental conditions: multicollinearity (φ), measurement error (θ ), coefficient of determination (R 2 ), and sample size (N). These design factors are essentially the same as those that <ref type="bibr" target="#b12">Grewal et al. (2004)</ref> considered in their simulations within the framework of covariance-based SEM. Prior simulation studies have shown them to be meaningful conditions in evaluating the performance of various SEM techniques (e.g., <ref type="bibr" target="#b20">Hwang et al., 2010;</ref><ref type="bibr" target="#b23">Lu et al., 2011)</ref>. In particular, we employed R 2 as a design factor as a high R 2 has the potential to improve the quality of parameter estimation in the presence of multicollinearity (e.g., <ref type="bibr" target="#b24">Mason and Perreault, 1991;</ref><ref type="bibr" target="#b12">Grewal et al., 2004)</ref>.</p><p>The levels of the design factors should be chosen, such that they would represent the range of values encountered in substantive studies using SEM. The selected ranges for the first three factors (φ, θ , R 2 ) are basically the same as those considered in <ref type="bibr" target="#b12">Grewal et al. (2004)</ref>. First, the level of multicollinearity was varied by systematically altering the correlation between ξ 1 and ξ 2 . The moderate condition (φ = 0.4) was included, plus strong (φ = 0.6) and extreme (φ = 0.8) correlation levels. The amount of random measurement error was then varied at two levels. Specifically, the composite reliability of each latent variable was set at 0.6 or 0.8 that can be considered as weak and strong, respectively. For the coefficient of determination, the value of R 2 for each latent endogenous variable was set to 0.25 or 0.50, corresponding to the medium and large effect sizes, respectively, according to <ref type="bibr" target="#b11">Fritz et al. (2012)</ref>. Finally, the value of N was set to 30, 60, 120, or 200. These sample sizes are identical to the sizes <ref type="bibr" target="#b23">Lu et al. (2011)</ref> considered in their simulations. Various approaches for SEM exist, but PLS path modeling has typically been recommended for use in the case of small samples (e.g., <ref type="bibr" target="#b18">Henseler et al., 2009)</ref>. Prior studies have found that PLS provides a better quality of solution in small samples (e.g., <ref type="bibr" target="#b3">Chin and Newsted, 1999)</ref>. Small sample sizes may be the rule, rather than the exception, in an empirical application of PLS (e.g., <ref type="bibr" target="#b14">Haenlein and Kaplan, 2004)</ref>.</p><p>We specified a structural equation model which consisted of six latent variables and four reflective indicators per latent variable (Figure <ref type="figure" target="#fig_0">1</ref>). We adapted this model from <ref type="bibr" target="#b12">Grewal et al. (2004)</ref>, in which all unstandardized path coefficients were originally fixed at 0.28. Variance-based SEM, such as partial least squares, typically provides standardized parameter estimates and their standard errors. Thus, we calculated different sets of standardized parameter values based on varying levels of φ and R 2 (Table <ref type="table" target="#tab_0">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Generation</head><p>The full factorial design for the simulation leads to a total of 48 factor combinations (4 Sample Sizes × 3 Multicollinearity × 2 Measurement Error × 2 Coefficients of Determination).</p><p>For each of the 48 different combinations, individual-level multivariate normal data were drawn from N(0, ), where is the implied population covariance matrix derived from a CSA formulation using the unstandardized parameter values. During the data generation process, in some rare situations, a consistent correlation matrix is found not to be positive definite. The least squares estimator (Equation <ref type="formula" target="#formula_2">2</ref>) fails with such a matrix. Any simulated sample was removed that failed to produce a consistent non-singular correlation matrix from further consideration to compare the two methods in an impartial manner. The first 500 replications with proper solutions were maintained for each of the combinations of the design factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SIMULATION RESULTS</head><p>In this section, we report the ability of RegPLSc and PLSc to recover the true parameter values for the path coefficients, as well as conduct a statistical inference. The practical benefit of PLS, in  empirical applications, may depend on its ability to determine the significance of a parameter estimate from the statistical power perspective. Although achieving accurate statistical inferences enables researchers to perform reliable hypothesis tests, they also put equal emphasis on the magnitude of the structural parameter to interpret the substantive significance of a result or for predictive purposes. Accordingly, evaluating the ability to recover the true parameters is important for applied researchers who would consider using PLS techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recovery of Path Parameters</head><p>To assess the recovery of the parameters under the two estimation procedures, we calculated the mean absolute differences (MAD) between the parameter values and their estimates as follows:</p><formula xml:id="formula_4">MAD = P j = 1 θj -θ j P ,<label>(4)</label></formula><p>where: θj and θ j denote the parameter estimates and population parameter values, respectively, and P is the number of parameters (e.g., <ref type="bibr" target="#b24">Mason and Perreault, 1991)</ref>.</p><p>For MAD, we conducted the full-factorial five-way mixed ANOVA. A single within-subjects method factor is the estimation method (M, where M = RegPLSc or PLSc). The betweensubject data factors are the above-described four experimental conditions of the study. Table <ref type="table" target="#tab_1">2</ref> presents the results about the capability of the two estimation methods. As illustrated in Table <ref type="table" target="#tab_1">2</ref>, most of the main and interaction effects were statistically significant, due to the large number of observations, in addition to fitting all possible interactions in the ANOVA. For this reason, it is crucial to also examine the effect size (e.g., <ref type="bibr" target="#b27">Paxton et al., 2001)</ref>. Following the accepted practice for identifying a substantial effect, we will focus on the main and interaction effects, having a partial eta-squared (η 2 ) greater than 2%, which deserves further examination (see <ref type="bibr" target="#b28">Reinartz et al., 2009)</ref>. According to <ref type="bibr" target="#b4">Cohen's (1988)</ref> guidelines regarding effect sizes, a value of 0.02 represents a small effect, 0.06 a medium effect, and 0.14 or greater a large effect.</p><p>The analysis method (η 2 = 0.24) had a sufficiently large main effect. This suggests meaningful differences in the average MAD between the two methods (RegPLSc = 0.14 and PLSc = 0.19). The ANOVA for MAD in the parameter recovery revealed that all two-way interaction effects were statistically significant and achieved effect sizes larger than 6%, reflecting a medium effect: Method × Multicollinearity (η 2 = 0.10), Method × Measurement Error (η 2 = 0.13), Method × R 2 (η 2 = 0.06), and Method × Sample Size (η 2 = 0.15). Two additional interactions, Method × Measurement Error × Sample Size (η 2 = 0.03) and Method × R 2 × Sample Size (η 2 = 0.02) were selected for further examination, because they were theoretically and practically related to multicollinearity problems and had an effect size above the cut-off point. We first discuss the two way interaction of Method × Multicollinearity. The remaining twoway interactions are then described below in the context of the three-way interactions that include them. Figure <ref type="figure" target="#fig_1">2</ref> displays the average values of MAD for each method under the three levels of multicollinearity. Overall, we could confirm that RegPLSc is notably superior across different degrees of multicollinearity. As the level of multicollinearity increases, the superiority of RegPLSc over PLSc becomes larger. A closer look at the performance of RegPLSc reveals that the method appears to be an effective tool to deal with multicollinearity in structural equation models. The average MAD value for RegPLSc under extreme conditions remains similar to that under moderate conditions. In contrast, for PLSc, such a stable tendency in the values of MAD cannot be observed, implying that PLSc is highly susceptible to multicollinearity problems.</p><p>The three-way interaction of Method × Measurement Error × Sample Size is presented in Figure <ref type="figure" target="#fig_2">3</ref>. This three-way interaction includes the two-way interaction of Method × Sample Size, which can be seen in each of the two blocks included in the figure . 
In general, the average MAD values for both methods tended to decrease as the sample sizes increased. We find two intriguing characteristics, depending on the level of measurement error. First, when reliability is weak, RegPLSc yields uniformly lower MAD than PLSc across all sample sizes. Second, in contrast, when measures are highly reliable, the differences in the values of MAD of the estimates become negligible, except for the smallest sample size. This implies that the adverse effects of multicollinearity may be largely offset by the measurement properties, such as reliability. The similar pattern was replicated in a simulation study by <ref type="bibr" target="#b12">Grewal et al. (2004)</ref>.</p><p>Another three-way interaction (Figure <ref type="figure" target="#fig_3">4</ref>) is produced by the interaction of R 2 with the Method and Sample Size. Our findings show that R 2 is another meaningful factor that can mitigate the damaging effects of multicollinearity on the estimation accuracy. In general, PLSc and RegPLSc perform similarly for a large R 2 of 0.50, while the difference becomes more markedly with a medium R 2 of 0.25. Consistent with the findings of <ref type="bibr" target="#b24">Mason and Perreault (1991)</ref>, the adverse effects of multicollinearity can be markedly attenuated with a greater portion of explained variance in the dependent variable. Overall, reliability and R 2 are likely to have an important impact on the good recovery of parameters in the presence of multicollinearity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Inference</head><p>The above ANOVA test results suggest that all the experimental conditions (multicollinearity, sample size, reliability, and R 2 )  are meaningful in differentiating the performance of the two methods in parameter recovery. To gain an additional understanding of the performance of these techniques, the statistical power was further investigated under those four experimental conditions. We estimated the standard errors of path coefficients estimates on the basis of the bootstrap method with 200 bootstrap samples (e.g., <ref type="bibr" target="#b28">Reinartz et al., 2009)</ref>.</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the empirically obtained statistical power of each estimation method for each combination of the experimental conditions. The numbers in the table indicate the proportion of simulation trials for which a 95% confidence interval for a path coefficient rejected the null hypothesis that path coefficient equals zero.</p><p>The results suggest that under multicollinearity, RegPLSc has an advantage over PLSc with respect to detecting statistical significance, given that the hypothesized effect actually exists in the population. This pattern of results replicates the findings for path coefficient estimation accuracy. RegPLSc can maintain very similar levels of statistical power, regardless of the degrees of multicollinearity, whereas PLSc is highly hampered by severe multicollinearity. For RegPLSc, it is apparent that the statistical power varies as a function of the sample size, reliability, and R 2 . More specifically, the minimum reasonable size of the sample (N = 30) in this particular study can lead to unacceptably low levels of statistical power. However, even under extreme multicollinearity, a small sample size of N = 60 is adequate for satisfactory statistical power (close to or above 80%), if R 2 is large and reliability is high. With the larger sample sizes, RegPLSc is able to achieve appropriate statistical power (above 80%) in almost all cases, if reflective measures are highly reliable. This highlights the importance of reliable measurements in the presence of multicollinearity. Conversely, when multicollinearity is extreme, PLSc still fails to achieve a sufficient statistical power for γ 11 and γ 12 , which are substantially affected by high correlations between ξ 1 and ξ 2 , even if reliability is high, R 2 is large, and the sample size is relatively large (N = 200).</p><p>Although researchers often pay more attention to the control of Type II error for theory testing in the SEM literature, they also need to consider whether an estimation method shows good control of Type I error rate (e.g., α = 0.05). Variance-based SEM techniques sometimes tends to favor less parsimonious models as they might fail to control Type I error rate (e.g., <ref type="bibr" target="#b17">Henseler, 2012;</ref><ref type="bibr" target="#b7">Dijkstra and Henseler, 2015b)</ref>. In general, a ridge type estimator produces more stable estimates of parameters, for which we have to pay with bias, making them prone to inflated Type I errors <ref type="bibr" target="#b9">(Erickson, 1981)</ref>. It is therefore important to evaluate the ability of RegPLSc to control the Type I error rate under multicollinearity. For the effect γ 22 = 0, PLSc maintained an overall Type I error rate of 5%. This result is in agreement with simulation results already obtained by <ref type="bibr" target="#b7">Dijkstra and Henseler (2015b)</ref>. Although RegPLSc seems to maintain marginally acceptable levels of Type I error (average = 0.085, minimum = 0.02, maximum = 0.164), Table <ref type="table" target="#tab_2">3</ref> suggests that it can have inflated Type I error rates, even in relatively large samples, in the case of severe multicollinearity. PLSc adequately controls Type I error under all conditions, whereas RegPLSc provides greater power. If prior research and theory are sufficient to hypothesize structural model relationships, then we recommend using RegPLSc for theory testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p>A recently developed PLSc is regarded as a viable alternative to traditional PLS if the common factor model holds true. However, in practice, PLSc may suffer from multicollinearity. In this paper, PLSc was combined with ridge-type regularization in order to deal with potential multicollinearity problems. The ridge least squares estimates of the path coefficients can be found by adding the regularization parameter into the OLS estimation. The optimal value of the parameter may be chosen RegPLSc 0.96 0.91 0.76 0.92 0.89 0.72 0.97 0.91 0.70 0.05 0.10 0.11 0.98 0.98 0.96 0.99 0.99 1.00 0.99 0.99 0.97 REL = 0.8 PLSc 1.00 0.97 0.65 1.00 0.93 0.56 1.00 1.00 0.82 0.06 0.06 0.04 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 RegPLSc 1.00 1.00 0.99 1.00 1.00 0.98 1.00 1.00 1.00 0.10 0.12 0.16 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 REL, reliability; R 2 , explained variance; N, sample size; PLSc, consistent PLS; RegPLSc, regularized PLSc.</p><p>through cross-validation. Our overall conclusion is that the proposed regularized PLSc is successful while dealing with a severe multicollinearity problem in structural equation models with common factors.</p><p>A comprehensive Monte Carlo study was conducted which systematically compared the relative performance of the regularized PLSc with non-regularized PLSc in the presence of multicollinearity. In so doing, it provides a greater understanding of the capability of these two estimation methods in terms of parameter recovery and inference errors. The primary goal of this section is to briefly discuss the implications of the simulation study and provide guidelines for choosing between the two methods.</p><p>The following summarizes the major findings for each performance measure.</p><p>1. Mean absolute differences (MAD): both methods behave similarly in terms of MAD under moderate multicollinearity.</p><p>If multicollinearity is from strong to extreme, the regularized PLSc generally recovers the path coefficients much better than non-regularized PLSc. The superior parameter recovery of the regularized PLSc over its non-regularized counterpart is found in most sample sizes considered, particularly when reliability is weak or when R 2 is moderate. When the sample size is very small (N = 30), the regularized PLSc has smaller MAD than the ordinary PLSc, regardless of the levels of reliability and R 2 . 2. Power: as long as multicollinearity is around 0.4, reliability is high, and the sample size is more than 100, researchers should not be overly concerned about the estimation accuracy and statistical power of PLSc. However, if a higher level of multicollinearity is present in the data, the regularized PLSc should be the preferred choice of researchers. Under high or extreme multicollinearity, it has the adequate statistical power, even with relatively small sample sizes, as long as the reliability is high.</p><p>These findings have important implications for researchers who use PLS path modeling to inform substantive hypotheses. First, if researchers are ensured that no serious multicollinearity is present, there may be little reason to choose the regularized PLSc over the non-regularized PLSc, since PLSc generally resulted in similarly accurate parameter estimates and reliable statistical inference. However, this is true only when a measure is reasonably reliable. Otherwise, our results suggest that the regularized PLSc should be the method of choice. Second, when assessing structural models under conditions of multicollinearity, the regularized PLSc is highly recommended for use over non-regularized PLSc in all situations involving sample size, reliability, and R 2 . Despite these important contributions, the present study has a few limitations. First, this study was designed to generate synthetic data within a continuous variable framework. Covariance structural models are often fitted to the data measured on ordinal categorical scales.</p><p>Thus, it might be interesting to investigate the relative performance of ordinal PLSc <ref type="bibr" target="#b29">(Schuberth et al., 2018)</ref> vs. its regularized extension with the sample matrix of ordinalscale variables. More methodological work is needed on how to accommodate ordinal data within the framework of regularized PLSc. Second, as is the case with all Monte Carlo simulation studies, the relative performance of each method is conditioned on the specific levels chosen for the experimental conditions. Although the current simulation took into account important experimental conditions frequently used in Monte Carlo simulation studies within the framework of SEM, it is necessary to contemplate a wider range of models and conditions for more careful investigations of the relative performance of the two approaches in future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc>FIGURE 1 | The specified model for the simulation study. Dashed line represents a path whose true value is zero.</figDesc><graphic coords="4,113.63,494.89,368.40,190.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 2 |</head><label>2</label><figDesc>FIGURE 2 | Two-way interactions of method × multicollinearity with MAD as dependent variable. Dashed line = PLSc, solid line = regularized PLSc.</figDesc><graphic coords="6,54.00,465.63,226.80,211.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 3 |</head><label>3</label><figDesc>FIGURE 3 | Three-way interactions of method × reliability × sample size with MAD as dependent variable. Dashed line = PLSc, solid line = regularized PLSc.</figDesc><graphic coords="6,314.28,243.42,226.80,426.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 4 |</head><label>4</label><figDesc>FIGURE 4 | Three-way interactions of method × R 2 × sample size with MAD as dependent variable. Dashed line = PLSc, solid line = regularized PLSc.</figDesc><graphic coords="7,54.00,69.75,226.80,433.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 |</head><label>1</label><figDesc>The standardized parameters.</figDesc><table><row><cell cols="2">Collinearity R 2</cell><cell cols="4">Population path coefficients</cell></row><row><cell></cell><cell>γ 11</cell><cell>γ 12</cell><cell>γ 31</cell><cell>γ 32</cell><cell>γ 21</cell><cell>γ 23</cell></row><row><cell>φ = 0.4</cell><cell cols="6">R2 = 0.25 0.318 0.279 0.372 0.335 0.354 0.354</cell></row><row><cell></cell><cell>R2 = 0.50 0.45</cell><cell cols="4">0.394 0.525 0.473 0.5</cell><cell>0.5</cell></row><row><cell>φ = 0.6</cell><cell cols="6">R2 = 0.25 0.298 0.261 0.382 0.322 0.354 0.354</cell></row><row><cell></cell><cell cols="5">R2 = 0.50 0.421 0.369 0.541 0.456 0.5</cell><cell>0.5</cell></row><row><cell>φ = 0.8</cell><cell cols="6">R2 = 0.25 0.281 0.246 0.391 0.311 0.354 0.354</cell></row><row><cell></cell><cell cols="4">R2 = 0.50 0.397 0.348 0.554 0.44</cell><cell>0.5</cell><cell>0.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2 |</head><label>2</label><figDesc>The results of ANOVA test for the mean absolute differences (MAD) of parameter estimates.</figDesc><table><row><cell></cell><cell>d.f.</cell><cell>MAD</cell><cell></cell></row><row><cell></cell><cell></cell><cell>F</cell><cell>η2</cell></row><row><cell cols="2">WITHIN-SUBJECTS EFFECTS</cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>1</cell><cell>7384.39</cell><cell>0.24</cell></row><row><cell>M*L</cell><cell>2</cell><cell>1351.16</cell><cell>0.10</cell></row><row><cell>M*F</cell><cell>1</cell><cell>1694.35</cell><cell>0.06</cell></row><row><cell>M*R</cell><cell>1</cell><cell>3417.41</cell><cell>0.13</cell></row><row><cell>M*N</cell><cell>3</cell><cell>1350.97</cell><cell>0.15</cell></row><row><cell>M*L*F</cell><cell>2</cell><cell>6.95</cell><cell>0.01</cell></row><row><cell>M*L*R</cell><cell>2</cell><cell>20.16</cell><cell>0.00</cell></row><row><cell>M*L*N</cell><cell>6</cell><cell>35.87</cell><cell>0.01</cell></row><row><cell>M*F*R</cell><cell>1</cell><cell>11.29</cell><cell>0.00</cell></row><row><cell>M*F*N</cell><cell>3</cell><cell>157.65</cell><cell>0.02</cell></row><row><cell>M*R*N</cell><cell>3</cell><cell>194.46</cell><cell>0.03</cell></row><row><cell>M*L*F*R</cell><cell>2</cell><cell>6.73</cell><cell>0.00</cell></row><row><cell>M*L*F*N</cell><cell>6</cell><cell>1.80</cell><cell>0.01</cell></row><row><cell>M*L*R*N</cell><cell>6</cell><cell>24.78</cell><cell>0.00</cell></row><row><cell>M*F*R*N</cell><cell>3</cell><cell>9.41</cell><cell>0.00</cell></row><row><cell>M*L*F*R*N</cell><cell>6</cell><cell>1.57</cell><cell>0.00</cell></row><row><cell>Error (M)</cell><cell>23952</cell><cell></cell><cell></cell></row><row><cell cols="2">BETWEEN-SUBJECTS EFFECTS</cell><cell></cell><cell></cell></row><row><cell>Intercept</cell><cell>1</cell><cell>172168.43</cell><cell>0.88</cell></row><row><cell>L</cell><cell>2</cell><cell>1970.69</cell><cell>0.14</cell></row><row><cell>F</cell><cell>1</cell><cell>52.85</cell><cell>0.00</cell></row><row><cell>R</cell><cell>1</cell><cell>4726.95</cell><cell>0.17</cell></row><row><cell>N</cell><cell>3</cell><cell>5731.48</cell><cell>0.42</cell></row><row><cell>L*F</cell><cell>2</cell><cell>127.31</cell><cell>0.01</cell></row><row><cell>L*R</cell><cell>2</cell><cell>25.51</cell><cell>0.00</cell></row><row><cell>L*N</cell><cell>6</cell><cell>4.57</cell><cell>0.00</cell></row><row><cell>F*R</cell><cell>1</cell><cell>0.57</cell><cell>0.00</cell></row><row><cell>F*N</cell><cell>3</cell><cell>13.43</cell><cell>0.00</cell></row><row><cell>R*N</cell><cell>3</cell><cell>95.12</cell><cell>0.01</cell></row><row><cell>L*F*R</cell><cell>2</cell><cell>2.24</cell><cell>0.00</cell></row><row><cell>L*F*N</cell><cell>6</cell><cell>7.17</cell><cell>0.00</cell></row><row><cell>L*R*N</cell><cell>6</cell><cell>18.32</cell><cell>0.00</cell></row><row><cell>F*R*N</cell><cell>3</cell><cell>1.44</cell><cell>0.00</cell></row><row><cell>L*F*R*N</cell><cell>6</cell><cell>1.45</cell><cell>0.00</cell></row><row><cell>Error</cell><cell>23952</cell><cell></cell><cell></cell></row><row><cell cols="3">M, method; L, multicollinearity; F, R 2 ; R, reliability; N, sample size.</cell><cell></cell></row><row><cell cols="4">All F-values are statistically significant (p &lt; 0.05) except for those underlined.</cell></row></table><note><p>d.f. = degrees of freedom and η 2 = Effect Size. Interaction effects having η 2 greater than 2% are shown in boldface.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3 |</head><label>3</label><figDesc>Statistical power of PLSc and regularized PLSc.</figDesc><table><row><cell>γ 11 γ 12 γ 21 γ 22 γ 23 β 31 β 32</cell><cell>Collinearity level Collinearity level Collinearity level Collinearity level Collinearity level Collinearity level Collinearity level</cell><cell>0.4 0.6 0.8 0.4 0.6 0.8 0.4 0.6 0.8 0.4 0.6 0.8 0.4 0.6 0.8 0.4 0.6 0.8 0.4 0.6 0.8</cell><cell>0.6 PLSc 0.22 0.18 0.16 0.18 0.14 0.16 0.07 0.08 0.07 0.08 0.05 0.06 0.10 0.08 0.06 0.28 0.26 0.25 0.22 0.21 0.23</cell><cell>RegPLSc 0.36 0.30 0.29 0.30 0.23 0.32 0.25 0.26 0.20 0.07 0.08 0.09 0.26 0.25 0.24 0.34 0.32 0.31 0.29 0.26 0.28</cell><cell>0.8 PLSc 0.26 0.12 0.21 0.21 0.15 0.18 0.17 0.13 0.07 0.04 0.05 0.05 0.21 0.21 0.14 0.33 0.35 0.34 0.30 0.31 0.26</cell><cell>RegPLSc 0.38 0.31 0.59 0.29 0.29 0.54 0.31 0.29 0.22 0.07 0.06 0.08 0.31 0.37 0.32 0.38 0.39 0.38 0.35 0.34 0.33</cell><cell>0.6 PLSc 0.29 0.23 0.15 0.23 0.16 0.15 0.10 0.06 0.09 0.08 0.04 0.09 0.10 0.07 0.11 0.10 0.07 0.11 0.36 0.29 0.32</cell><cell>RegPLSc 0.49 0.48 0.41 0.40 0.37 0.40 0.41 0.35 0.29 0.07 0.09 0.11 0.41 0.38 0.42 0.51 0.56 0.58 0.47 0.44 0.47</cell><cell>0.8 PLSc 0.46 0.32 0.15 0.41 0.27 0.17 0.35 0.20 0.18 0.05 0.02 0.05 0.42 0.28 0.21 0.60 0.65 0.64 0.59 0.49 0.49</cell><cell>RegPLSc 0.63 0.64 0.52 0.57 0.55 0.52 0.54 0.54 0.52 0.07 0.06 0.09 0.57 0.57 0.57 0.72 0.75 0.76 0.68 0.64 0.67</cell><cell>0.6 PLSc 0.26 0.17 0.15 0.21 0.15 0.14 0.09 0.09 0.09 0.04 0.07 0.07 0.11 0.15 0.11 0.38 0.38 0.34 0.28 0.27 0.24</cell><cell>RegPLSc 0.40 0.35 0.49 0.33 0.31 0.45 0.32 0.30 0.23 0.05 0.08 0.10 0.39 0.39 0.36 0.44 0.43 0.41 0.37 0.33 0.35</cell><cell>0.8 PLSc 0.42 0.34 0.33 0.39 0.26 0.24 0.41 0.32 0.15 0.05 0.04 0.04 0.51 0.51 0.46 0.61 0.63 0.60 0.53 0.49 0.47</cell><cell>RegPLSc 0.53 0.53 0.84 0.51 0.51 0.80 0.48 0.45 0.36 0.06 0.05 0.10 0.53 0.53 0.52 0.58 0.61 0.60 0.52 0.51 0.49</cell><cell>0.6 PLSc 0.41 0.29 0.15 0.38 0.28 0.14 0.18 0.12 0.07 0.05 0.05 0.05 0.24 0.21 0.12 0.58 0.58 0.61 0.53 0.51 0.48</cell><cell>RegPLSc 0.62 0.66 0.58 0.60 0.61 0.55 0.58 0.48 0.40 0.08 0.09 0.11 0.58 0.57 0.59 0.70 0.75 0.76 0.68 0.69 0.62</cell><cell>0.8 PLSc 0.77 0.57 0.24 0.67 0.53 0.22 0.81 0.60 0.26 0.05 0.04 0.06 0.87 0.88 0.72 0.90 0.91 0.92 0.83 0.80 0.80</cell><cell>RegPLSc 0.89 0.84 0.74 0.82 0.81 0.72 0.79 0.71 0.70 0.07 0.11 0.11 0.81 0.86 0.86 0.94 0.94 0.94 0.88 0.87 0.88</cell><cell>0.6 PLSc 0.38 0.23 0.19 0.26 0.20 0.18 0.28 0.17 0.10 0.04 0.05 0.06 0.36 0.33 0.24 0.56 0.57 0.56 0.46 0.47 0.42</cell><cell>RegPLSc 0.54 0.45 0.55 0.40 0.36 0.54 0.42 0.31 0.28 0.05 0.05 0.07 0.53 0.53 0.57 0.63 0.63 0.64 0.55 0.53 0.53</cell><cell>0.8 PLSc 0.74 0.54 0.58 0.68 0.48 0.41 0.81 0.64 0.30 0.06 0.04 0.04 0.85 0.86 0.85 0.91 0.93 0.91 0.85 0.85 0.69</cell><cell>RegPLSc 0.81 0.74 0.97 0.79 0.66 0.94 0.83 0.76 0.58 0.06 0.07 0.09 0.87 0.89 0.90 0.92 0.94 0.92 0.86 0.87 0.77</cell><cell>0.6 PLSc 0.66 0.44 0.16 0.60 0.40 0.15 0.60 0.38 0.15 0.04 0.04 0.08 0.71 0.62 0.38 0.83 0.84 0.88 0.78 0.73 0.63</cell><cell>RegPLSc 0.84 0.73 0.56 0.77 0.70 0.55 0.79 0.69 0.47 0.04 0.08 0.10 0.85 0.85 0.86 0.92 0.94 0.93 0.89 0.87 0.81</cell><cell>0.8 PLSc 0.98 0.86 0.51 0.93 0.79 0.33 0.99 0.96 0.60 0.06 0.05 0.03 0.99 1.00 0.97 1.00 1.00 1.00 0.98 0.98 0.97</cell><cell>RegPLSc 1.00 0.98 0.94 0.97 0.97 0.85 0.99 0.99 0.88 0.09 0.11 0.15 0.99 1.00 0.99 1.00 1.00 1.00 1.00 1.00 0.99</cell><cell>0.6 PLSc 0.60 0.35 0.25 0.51 0.32 0.23 0.55 0.36 0.16 0.04 0.04 0.06 0.68 0.68 0.55 0.80 0.83 0.81 0.70 0.70 0.57</cell><cell>RegPLSc 0.73 0.56 0.70 0.65 0.53 0.71 0.66 0.55 0.34 0.02 0.07 0.09 0.75 0.80 0.77 0.84 0.86 0.87 0.75 0.76 0.68</cell><cell>0.8 PLSc 0.94 0.73 0.75 0.85 0.69 0.63 0.95 0.87 0.50 0.05 0.04 0.06 0.97 0.98 0.99 0.99 1.00 0.94 0.97 0.97 0.88</cell><cell>RegPLSc 0.97 0.92 1.00 0.93 0.88 1.00 0.96 0.93 0.78 0.07 0.10 0.16 0.98 0.98 0.99 0.99 1.00 0.93 0.99 0.98 0.95</cell><cell>0.6 PLSc 0.85 0.63 0.21 0.81 0.54 0.19 0.92 0.70 0.25 0.04 0.04 0.04 0.96 0.94 0.72 0.97 0.97 0.98 0.94 0.92 0.90</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.25 REL =</cell><cell></cell><cell>REL =</cell><cell></cell><cell>0.5 REL =</cell><cell></cell><cell>REL =</cell><cell></cell><cell>0.25 REL =</cell><cell></cell><cell>REL =</cell><cell></cell><cell>0.5 REL =</cell><cell></cell><cell>REL =</cell><cell></cell><cell>0.25 REL =</cell><cell></cell><cell>REL =</cell><cell></cell><cell>0.5 REL =</cell><cell></cell><cell>REL =</cell><cell></cell><cell>0.25 REL =</cell><cell></cell><cell>REL =</cell><cell></cell><cell>0.5 REL =</cell></row><row><cell></cell><cell></cell><cell></cell><cell>30 R2 =</cell><cell></cell><cell></cell><cell></cell><cell>R 2 =</cell><cell></cell><cell></cell><cell></cell><cell>60 R 2 =</cell><cell></cell><cell></cell><cell></cell><cell>R 2 =</cell><cell></cell><cell></cell><cell></cell><cell>120 R 2 =</cell><cell></cell><cell></cell><cell></cell><cell>R 2 =</cell><cell></cell><cell></cell><cell></cell><cell>200 R2 =</cell><cell></cell><cell></cell><cell></cell><cell>R 2 =</cell></row><row><cell></cell><cell></cell><cell></cell><cell>N =</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>N =</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>N =</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>N =</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Frontiers in Psychology | www.frontiersin.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>February 2018 | Volume 9 | Article 174</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was supported by the <rs type="funder">Ministry of Education of the Republic of Korea</rs> and the <rs type="funder">National Research Foundation of Korea</rs> (<rs type="grantNumber">NRF-2014S1A5B8060940</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_X7BUBnN">
					<idno type="grant-number">NRF-2014S1A5B8060940</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR CONTRIBUTIONS</head><p>SJ contributed to conducing all research activities including technical development, empirical analyses, and manuscript writing; JP contributed to technical development and manuscript writing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest Statement:</head><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Statistical inference with PLSc using bootstrap confidence intervals</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Aguirre-Ureta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rönkkö</surname></persName>
		</author>
		<ptr target="https://misq.org/forthcoming/?SID=kjm" />
	</analytic>
	<monogr>
		<title level="j">MIS Quart. Available</title>
		<imprint>
			<date>9t850mj6ah2v00hgutnc6l4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Structural Equations with Latent Variables</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On measurement of intangible assets: a study of robustness of partial least squares</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Cassel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hackl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Westlund</surname></persName>
		</author>
		<idno type="DOI">10.1080/09544120050135443</idno>
	</analytic>
	<monogr>
		<title level="j">Total Qual. Manag</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="897" to="907" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Structural equation modeling analysis with small samples using partial least squares</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Newsted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Strategies for Small Sample Research</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Hoyle</surname></persName>
		</editor>
		<meeting><address><addrLine>Beverly Hills, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage Publications</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="307" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Statistical Power Analysis for the Behavioral Sciences, 2nd Edn</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Lawrence Earlbaum Associates</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Latent variables and indices: Herman Wold&apos; s basic design and partial least squares</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Partial Least Squares: Concepts, Methods and Applications in Marketing and Related Fields</title>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Vinzi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Chin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="23" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Consistent and asymptotically normal PLS estimators for linear structural equations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Dijkstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.csda.2014.07.008</idno>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="10" to="23" />
			<date type="published" when="2015">2015a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Consistent partial least squares path modeling</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Dijkstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
		<idno type="DOI">10.25300/MISQ/2015/39.2.02</idno>
	</analytic>
	<monogr>
		<title level="j">MIS Q</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="297" to="316" />
			<date type="published" when="2015">2015b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The Jackknife, the Bootstrap and Other Resampling Plans</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>SIAM</publisher>
			<pubPlace>Philadelphia, PA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Using ridge regression to estimate directly lagged effects in marketing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Erickson</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1981.10477719</idno>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="766" to="773" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Two structural equation models: LISREL and PLS applied to consumer exit-voice theory</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fornell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bookstein</surname></persName>
		</author>
		<idno type="DOI">10.2307/3151718</idno>
	</analytic>
	<monogr>
		<title level="j">J. Market. Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="440" to="452" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effect size estimates: current use, calculations, and interpretation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Richler</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0024338</idno>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="2" to="18" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multicollinearity and measurement error in structural equation models: implications for theory testing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Baumgartner</surname></persName>
		</author>
		<idno type="DOI">10.1287/mksc.1040.0070</idno>
	</analytic>
	<monogr>
		<title level="j">Market. Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="519" to="529" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Linear Regression</title>
		<author>
			<persName><forename type="first">J</forename><surname>Groß</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A beginner&apos;s guide to partial least squares analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Haenlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Kaplan</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15328031us0304_4</idno>
	</analytic>
	<monogr>
		<title level="j">Unders. Stat</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="283" to="297" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">PLS-SEM: indeed a silver bullet</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarstedt</surname></persName>
		</author>
		<idno type="DOI">10.2753/MTP1069-6679190202</idno>
	</analytic>
	<monogr>
		<title level="j">J. Market. Theory Pract</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="139" to="151" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning; Data Mining, Inference, and Prediction</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Why generalized structured component analysis is not universally preferable to structural equation modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11747-011-0298-6</idno>
	</analytic>
	<monogr>
		<title level="j">J. Acad. Market. Sci</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="402" to="413" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The use of partial least squares path modeling in international marketing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Sinkovics</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in International Marketing</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Sinkovics</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Ghauri</surname></persName>
		</editor>
		<meeting><address><addrLine>Bingley</addrLine></address></meeting>
		<imprint>
			<publisher>Emerald</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="277" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ridge regression: biased estimation for nonorthogonal problems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Hoerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Kennard</surname></persName>
		</author>
		<idno type="DOI">10.1080/00401706.1970.10488634</idno>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="55" to="67" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A comparative study on parameter recovery of three approaches to structural equation modeling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tomiuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<idno type="DOI">10.1509/jmkr.47.4.699</idno>
	</analytic>
	<monogr>
		<title level="j">J. Market. Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="699" to="712" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A general method for estimating a linear structural equation system</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural Equation Models in the Social Sciences</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Goldberger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Duncan</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="85" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
		<title level="m">Structural Equation Modeling: Foundations and Extensions, 2nd Edn</title>
		<meeting><address><addrLine>Newbury Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Two new methods for estimating structural equation models: an illustration and a comparison with two established methods</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R R</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cedzynski</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijresmar.2011.03.006</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Res. Market</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="258" to="268" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Collinearity, power, and interpretation of multiple regression analysis</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Perreault</surname></persName>
		</author>
		<idno type="DOI">10.2307/3172863</idno>
	</analytic>
	<monogr>
		<title level="j">J. Market. Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="268" to="280" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Prediction error estimation: a comparison of resampling methods</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Molinaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Pfeiffer</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/bti499</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3301" to="3307" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The correction for attenuation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Muchinsky</surname></persName>
		</author>
		<idno type="DOI">10.1177/0013164496056001004</idno>
	</analytic>
	<monogr>
		<title level="j">Educ. Psychol. Meas</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="63" to="75" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Monte Carlo experiments: design and implementation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15328007SEM0802_7</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equat. Model</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="287" to="312" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An empirical comparison of the efficacy of covariance-based and variance-based SEM</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Reinartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haenlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijresmar.2009.08.001</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Res. Market</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="332" to="344" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Partial least squares path modeling using ordinal categorical indicators</title>
		<author>
			<persName><forename type="first">F</forename><surname>Schuberth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Dijkstra</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11135-016-0401-7</idno>
	</analytic>
	<monogr>
		<title level="j">Qual. Quant</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="9" to="35" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-008-9067-y</idno>
		<ptr target="http://jmlr.org/papers/v15/srivastava" />
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Takane</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Jung</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="671" to="690" />
			<date type="published" when="2008">2014. 2008</date>
		</imprint>
	</monogr>
	<note>Psychometrika</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Regularized generalized canonical correlation analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tenenhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tenenhaus</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-011-9206-8</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="257" to="284" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Path models with latent variables: the NIPALS approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Quantitative Sociology: International Perspectives on Mathematical Statistical Model Building</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Blalock</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Aganbegian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Borodkin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Boudon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Capecchi</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="307" to="357" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
