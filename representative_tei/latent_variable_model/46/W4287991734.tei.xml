<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reducing Selection Bias in Counterfactual Reasoning for Individual Treatment Effects Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-12-19">19 Dec 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zichen</forename><surname>Zhang</surname></persName>
							<email>zichen2@ualberta.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science ‡ Department of Mathematical and Statistical Sciences</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qingfeng</forename><surname>Lan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science ‡ Department of Mathematical and Statistical Sciences</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Ding</surname></persName>
							<email>lding1@ualberta.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science ‡ Department of Mathematical and Statistical Sciences</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yue</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science ‡ Department of Mathematical and Statistical Sciences</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Negar</forename><surname>Hassanpour</surname></persName>
							<email>hassanpo@ualberta.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science ‡ Department of Mathematical and Statistical Sciences</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Russell</forename><surname>Greiner</surname></persName>
							<email>rgreiner@ualberta.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science ‡ Department of Mathematical and Statistical Sciences</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Reducing Selection Bias in Counterfactual Reasoning for Individual Treatment Effects Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-19">19 Dec 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1912.09040v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Counterfactual reasoning is an important paradigm applicable in many fields, such as healthcare, economics, and education. In this work, we propose a novel method to address the issue of selection bias. We learn two groups of latent random variables, where one group corresponds to variables that only cause selection bias, and the other group is relevant for outcome prediction. They are learned by an auto-encoder where an additional regularized loss based on Pearson Correlation Coefficient (PCC) encourages the de-correlation between the two groups of random variables. This allows for explicitly alleviating selection bias by only keeping the latent variables that are relevant for estimating individual treatment effects. Experimental results on a synthetic toy dataset and a benchmark dataset show that our algorithm is able to achieve state-of-the-art performance and improve the result of its counterpart that does not explicitly model the selection bias.</p><p>We represent the observed features of each patient, such as age and gender, as a random vector X. For simplicity, we assume that there are only two treatments, denoted as a binary variable T ∈ {0, 1}.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Studying the causal effect of different treatments on individuals to assist in decision making is an essential problem in various fields. Examples include a doctor deciding the most effective medical treatment for a specific patient, a company deciding the most profitable commercial advertisement for a specific product, etc.</p><p>In this paper, we focus on understanding individual-level causal effects in healthcare. Access of many observational data in this field allows us to develop methods for predicting individual-level causal effects. However, many challenges remain. The first challenge is that the observational data at the individual level tells us only the outcome of received treatments (the factuals), whereas the responses of the alternative treatments (the counterfactuals) are never available. For example, if a patient is given surgery, we would not be able to observe the true effect of applying medication instead. This setting is called counterfactual reasoning, that is, to predict the individual treatment effect of the counterfactual treatment. The second challenge is that the data often exhibits selection bias <ref type="bibr" target="#b5">[Imbens and Rubin, 2015]</ref>. For example, patient living in the rural area may not have access to a certain medication. Consequently, there are only a few, if any, patients receiving that medication in the dataset, i.e., the observational data have a selection bias. In this case, the home address affects only the treatment. In other cases, there are factors that affect both the treatment and the respective outcome, called confounder. It also causes the difficulty of predicting the causal effects since it partially leads to the selection bias. For example, it is more likely for a doctor to prescribe surgery to younger patients while to give medication to older patients. On the other hand, ages may affect the potential outcome regardless of the treatment given. The patients who receive treatment T = 0 or T = 1 are in the control group and treatment group, respectively. Consequently, there are two possible outcomes Y 0 and Y 1 corresponding to each treatment option: T = 0 and T = 1. However, we do not have access to both of the outcomes. For each patient, we only observe the outcome corresponding to the received treatment. We denote all the observed outcomes (the factuals) as Y f and all the unobserved outcomes (the counterfactuals) as Y cf . Moreover, the selection bias can be expressed as p(T X) ≠ p(T ). The goal is to estimate the Individual Treatment Effect (ITE), i.e., E[Y 1 -Y 0 ] for each individual.</p><p>The causal graph in our analysis is shown in Figure <ref type="figure" target="#fig_0">1</ref>, inspired by <ref type="bibr" target="#b3">Hassanpour and Greiner [2019]</ref>. We assume that the covariate X is generated by three types of latent variables. The first type A includes the latent variables that only affect treatment selection procedure but do not determine outcomes. Type B are the confounders which influence both treatments and outcomes. The last type C only affects outcomes.</p><p>Our main contribution is that we propose a novel method that separates the learned feature representations into two parts, corresponding to A and BC described above. Then we reduce the selection bias by using only the representation of type BC to predict the outcomes. We test our algorithm on two datasets: a synthetic toy dataset and a benchmark dataset simulated from real-world data. The results show that our method helps to improve the prediction performance in many settings.</p><p>Assumptions Similar to the work by <ref type="bibr" target="#b11">Shalit et al. [2017]</ref>, we assume that there exists a joint distribution p(X, T, Y 0 , Y 1 ) with "strong ignorability" assumption: Y T X and 0 &lt; p(t = 1 x) &lt; 1, ∀x ∈ X . This is sufficient for the ITE to be identifiable <ref type="bibr" target="#b6">[Imbens and Wooldridge, 2009]</ref>. We also assume that the outcomes of the samples (x 1 , t 1 , y 1 ), ...(x n , t n , y n ) are generated from y i ∼ p(y ti x i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related works</head><p>In the work of <ref type="bibr" target="#b7">Johansson et al. [2016]</ref>, ideas from domain adaptation and representation learning were combined. Besides learning a latent representation for outcome prediction, the discrepancy distance <ref type="bibr" target="#b10">[Mansour et al., 2009]</ref> was introduced as a distribution distance metric. By minimizing the discrepancy distance, the distributions of populations with different treatments were balanced to reduce the selection bias. On the network structure, they simply concatenated the treatment t with the representation Φ which easily led to information loss of treatment t. <ref type="bibr" target="#b11">Shalit et al. [2017]</ref> improved this line of work and proved a generalization error-bound for estimating ITE. The improvements they made were two-fold. First, they introduced a branching network structure where one branch of the network learned the prediction of treated outcome (t = 1) and the other branch learned the prediction of the outcome under control (t = 0). This new network structure solved the issue in the work of <ref type="bibr" target="#b7">Johansson et al. [2016]</ref> of losing the influence of t when the dimension of the representation was large. Second, they introduced a measure of distance between two distributions p(x t = 1) and p(x t = 0), called Integral Probability Metric (IPM). They showed that the expected error of the ITE prediction was upper bounded by the error of learning Y 1 and Y 0 , plus the IPM term. This IPM measure was therefore used in the loss function to encourage that the two distributions of representations being closer.</p><p>From the perspective of network structure, our work is closely related to <ref type="bibr" target="#b0">Atan et al. [2018]</ref>. In this work, a latent representation is learned by using an auto-encoder. By jointly minimizing the reconstruction loss and the distribution distance between different representation groups, it balanced between information loss and bias reduction. However, the entire learned representation was then used for outcome prediction. This could inevitably contain features that is not useful for outcome prediction therefore counteracting the effect of bias reduction in the first step. We address this issue by learning the features that only causes selection bias and discard them during the outcome prediction.</p><p>In terms of disentangling two categories of representations, we are inspired by the work from <ref type="bibr" target="#b1">Cheung et al. [2014]</ref>. This work was in the domain of image classification, where they learned the features of class-independent variations Z apart from the features for classification. They introduced a cross-covariance penalty (XCov) for this purpose. It disentangled factors like the hand-writing style from the digits labels. We improve their work by introducing a penalty term that better reflects the correlation between random variables, as detailed in the next section.</p><p>3 Proposed method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Network Architecture</head><p>Following the model of deep-treat in <ref type="bibr" target="#b0">[Atan et al., 2018]</ref> and the Counter Factual Regression (CFR) framework in <ref type="bibr" target="#b11">[Shalit et al., 2017]</ref>, the overall structure of our method is an autoencoder where the representation learning stage is also followed by an outcome prediction stage that branches based on the treatment t of the input sample x.</p><p>In order to reduce the selection bias, we explicitly model the bias (latent variables type A, note that it is in bold denoting a vector of random variables) in the learned representation Φ(x) and separate it from the rest of the features (latent variables type BC) that are relevant for the outcome prediction. Since the bias variables A do not play a part in the outcome prediction, only the variables BC are then used as the input to the downstream prediction network to predict the outcomes for various treatments ŷ1 (x) and ŷ0 (x) (we consider binary treatment in this work, i.e, t = 1 or t = 0).</p><p>The architecture of the proposed method, named RSB-Net (stands for Reducing Selection Bias), is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. In the next subsection, we explain how this network can be trained to explicitly learn the two groups of latent variables A and BC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Loss Function</head><p>On the high level, the proposed neural network is trained end-to-end with a hybrid loss that is a weighted sum of the following: a prediction loss L pred , a distribution loss L IPM , an input reconstruction loss L recons and a loss based on Pearson correlation coefficient L pcc .</p><formula xml:id="formula_0">L = L pred + αL IPM + βL recon + γL pcc + λR(W )<label>(1)</label></formula><p>where R(W ) is the regularization term of the network weights W that penalizes complexity of the network, and α, β, γ, λ are the weights of the loss terms.</p><p>Prediction Loss and Distribution Loss This is the supervised loss proposed in <ref type="bibr" target="#b11">Shalit et al. [2017]</ref>.</p><p>For a batch of data samples x i , t i , we aim to predict the factual outcome ŷti i . The prediction loss is defined on the factual outcome y ti using a weighted squared loss as</p><formula xml:id="formula_1">L pred = 1 N w i h ti (Φ BC (x i )) -y ti i 2 2</formula><p>(2)</p><p>where N is the sample size,</p><formula xml:id="formula_2">w i = ti 2u + 1-ti 2(1-u) , u = 1 N ∑ i t i .</formula><p>Note that u is the probability of choosing treatment t = 1 in the entire population, i.e. u = p(t = 1). w i compensates for the size difference in different treatment arms. The distribution loss, using Integral Probability Metric(IPM) is defined as</p><formula xml:id="formula_3">L IPM = IPM(Φ BC (x i ) i∶ti=0 , Φ BC (x i ) i∶ti=1 )<label>(3)</label></formula><p>It measures the distribution distance of the latent representation of the treated group and the control group, i.e. between Φ(x t = 1) and Φ(x t = 0).</p><p>Reconstruction Loss Inspired by the approach in <ref type="bibr" target="#b1">Cheung et al. [2014]</ref> and Atan et al.</p><p>[2018], we use an auto-encoder with a squared L 2 loss to learn a set of latent representation for both groups of random variables A and BC. The loss is defined as</p><formula xml:id="formula_4">L recons = x -x 2 2</formula><p>, where x is the reconstruction of the input features of the sample x.</p><p>PCC Loss To explicitly learn the random variables A and BC, the latent representation Φ(x) is first split into two parts (the ratio is a hyperparameter), denoted as Φ A (x) ∈ R m and Φ BC (x) ∈ R n , corresponding to A and BC respectively. m and n denote the dimension of the vectors for each sample x. We would like Φ A (x) and Φ BC (x) to be de-correlated in the learned representation.</p><p>To this end, we define a loss based on Pearson correlation coefficient (PCC):</p><formula xml:id="formula_5">L pcc = 1 2mn m i=1 n j=1 [ 1 N ∑ N k=1 (Φ A (x k ) i -Φ Ai )(Φ BC (x k ) j -Φ BCj ) σ(Φ Ai )σ(Φ BCj ) ] 2<label>(4)</label></formula><p>where Φ A (x k ) i is the i-th element of vector Φ A (x k ) for sample k, Φ Ai is the mean value of the i-th element of vector Φ A for all samples. We use similar notations for Φ BC . The idea of this loss is to take the mean of the squared PCC between every pair of random variables formed by one entry in vector Φ A and one entry Φ BC . Since PCC ∈ [-1, 1], we have the range of this loss L pcc ∈ [0, 0.5], reaching the minimum when features Φ A and Φ BC are linearly independent.</p><p>Algorithm 1: RSB-Net</p><p>Input: Factual samples {(x 1 , t 1 , y f 1 ),...,(x N , t N , y f N )}, coefficients of the loss terms: α, β, γ, λ minibatch size m Compute u = 1 N ∑ N i=1 t i and the sample weight: </p><formula xml:id="formula_6">w i = ti 2u + 1-ti 2(1-u) for i = 1,</formula><formula xml:id="formula_7">L pred = 1 m ∑ m j=1 w ij ( 2 (ŷ ti j ij , y ti j ij )) 2 ; Compute the distribution loss L IPM = IPM (Φ BC (x i ) i∶ti=0 , Φ BC (x i ) i∶ti=1 ) ; Compute the reconstruction loss L recon = 1 m ∑ m j=1</formula><p>( 2 (x ij , x ij )) 2 ; Compute the Pearson correlation coefficient loss L pcc defined in Eq. 4; Sum up the above loss functions and add regularization R to get the total loss f</p><formula xml:id="formula_8">L = L pred + αL IPM + βL recon + γL pcc + λR(W)</formula><p>Optimize all weights W in the neural networks; until max iterations; Output: Neural network weights W</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we present the experimental results of our proposed method on a new synthetic toy dataset and a benchmark dataset. We compare our method with the following baseline methods: k-nearest neighbor (kNN), Bayesian Additive Regressoin Trees (BART) <ref type="bibr" target="#b2">[Chipman et al., 2010]</ref>, Balancing Neural Network (BNN) <ref type="bibr" target="#b7">[Johansson et al., 2016]</ref>, <ref type="bibr">Deep-Treat [Atan et al., 2018]</ref>, Treatment-Agnostic Representation Network (TARNET) <ref type="bibr" target="#b11">[Shalit et al., 2017]</ref>, Counterfactual Regression with Wasserstein metric (CFRW) <ref type="bibr" target="#b11">[Shalit et al., 2017]</ref>, Counterfactual Regression with Importance Sampling Weights (CFR-ISW) <ref type="bibr" target="#b3">[Hassanpour and Greiner, 2019]</ref>, Causal Effect Variational Autoencoder (CEVAE) <ref type="bibr" target="#b9">[Louizos et al., 2017]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Metrics</head><p>Our goal is to estimate the Individual Treatment Effects (ITE), which measures the difference between possible outcomes for each patient. The ground truth ITE and estimated ITE are defined as follows:</p><formula xml:id="formula_9">τ (x) ∶= E[Y 1 -Y 0 x] and τ (x) = h 1 (Φ(x)) -h 0 (Φ(x))</formula><p>where Φ(x) is the representation function of the form Φ ∶ X → R that transforms x from the sample space X into the learned representation space R, and h is the hypothesis function R × {0, 1} → Y, defined over the representation space R and the treatment t ∈ {0, 1}, mapping to the output space Y.</p><p>Following the setup in <ref type="bibr" target="#b11">[Shalit et al., 2017]</ref>, we use the noiseless outcomes µ<ref type="foot" target="#foot_0">foot_0</ref> and µ 0 as the ground truth so that τ (x) = µ 1 (x)µ 0 (x). And we use two metrics to evaluate estimated ITE. The first one is Precision in Estimation of Heterogeneous Effect (PEHE) defined as:</p><formula xml:id="formula_10">PEHE = 1 N N i (τ (x i ) -τ (x i )) 2</formula><p>where N is the sample size. This measures the mean squared difference between the estimated ITE and true ITE. Note that PEHE is originally defined on a continuous distribution <ref type="bibr" target="#b4">[Hill, 2011]</ref>. Here we use the discrete version for finite samples.</p><p>Another metric is the bias of the Average Treatment Effect (ATE):</p><formula xml:id="formula_11">ATE = ATE -ATE = 1 N N i=1 (τ (x i ) -τ (x i )) where ATE = E[τ (x i )] = 1 N ∑ N i=1 τ (x i ).</formula><p>This measures the population difference between the expectation of the estimated ITE and true ITE.</p><p>For all experiments, we report the within-sample and out-of-sample mean and standard errors of √ PEHE and ATE following the literature. Within-sample takes into account the entire training data, including the training and validation split. Out-of-sample result measures the performance on the hold-out test dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation details</head><p>We implemented our RSB net using TensorFlow, based on the code 1 provided by <ref type="bibr" target="#b7">Johansson et al. [2016]</ref>.</p><p>Preprocessing of the data have not been commonly used or mentioned in the literature. In the hyper-parameter tuning, we tested different preprocessing methods such as Z-score Standardization and min-max Normalization. Our empirical result across both datasets suggests that min-max Normalization either improves or shows no impact on the result, compared to the alternatives like Z-score and using raw data.</p><p>During training, the weights of the neural network were initialized randomly and optimized using Adam <ref type="bibr" target="#b8">[Kingma and Ba, 2014]</ref>. The maximum iteration was 5k for all experiments. Early stopping was performed based on the validation loss. We compare our method RSB with its counterpart CFRW <ref type="bibr" target="#b11">[Shalit et al., 2017]</ref>, to evaluate how well reducing the selection bias helps in the presence of directly observable confounders. CFRW is considered as the counterpart since our model RSB follows the same network architecture and can be viewed roughly as CFRW with two additional loss terms: reconstruction loss L recon and Pearson correlation coefficient based loss L pcc .</p><p>The comparison is shown in Table <ref type="table">1</ref>. We ran extensive hyperparameter tuning on both methods, using 50 realizations and report the result of the selected best parameter on 1000 realizations. Although we know the dimensions of the variables A, B, C when we generate the data, we did not use that information to select the best hyper-parameter. Note that the within-sample and out-of-sample results are almost identical on √ PEHE and ATE . This is expected since the true ITE is a constant (10) so if our model produces constant prediction on ITE, the result on training and testing set should be the same. We present the result of √ PEHEnn to show that there's indeed a difference between training and testing set.</p><p>The overall result shows that in a dataset generated with selection bias, in a simple setting, reducing the selection bias explicitly using our method helps to improve the counterfactual prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Benchmark dataset -IHDP</head><p>To further evaluate our method, we benchmark our method in the real-world setting, using a semisimulated dataset based on the Infant Health and Development Program (IHDP), introduced by <ref type="bibr" target="#b4">Hill [2011]</ref>. The data have features from a real randomized experiment, studying the effect of high-quality childcare and home visits on future cognitive test scores. The IHDP dataset uses a simulated outcome and it also artificially introduces sample selection bias by removing a biased subset of the treated population. The dataset has 747 samples in total (139 treated and 608 control). For each sample, there are multiple realizations of the outcomes corresponding to either of the available treatments<ref type="foot" target="#foot_1">foot_1</ref> . We use the same 63/27/10 train/valid/test split as in the literature.</p><p>For the comparison with baselines, we test our method under both 100 and 1000 realizations, using the dataset IHDP-100 and IHDP-1000 provided by <ref type="bibr" target="#b7">Johansson et al. [2016]</ref>. The outcomes in these two datasets are generated with non-linear response surface under setting B in <ref type="bibr" target="#b4">Hill [2011]</ref>. The results are shown in Table <ref type="table" target="#tab_1">2</ref> and<ref type="table" target="#tab_2">3</ref>. Under 100 realizations, we compare with four other neural network based methods: BNN and Deep-Treat whose results are replicated from <ref type="bibr" target="#b0">[Atan et al., 2018]</ref>, CFRW and CFR-ISW for which the results from <ref type="bibr" target="#b3">[Hassanpour and Greiner, 2019]</ref> are replicated (results with the hyperparameter selected based on PEHEnn for a fair comparison). Under 1000 realizations, we compare with all baseline methods described in the beginning of Sec.4, except for CFR-ISW <ref type="bibr" target="#b3">[Hassanpour and Greiner, 2019]</ref> and <ref type="bibr">Deep-Treat [Atan et al., 2018]</ref> which only reported results under 100 realizations.</p><p>Our method achieves state-of-the-art performance in most metrics. Since this dataset is simulated from real-world observational data, it is not clear what categories of hidden features are present. The experimental results show that our method is able to perform well on real-world datasets where the underlying structure of the hidden variables is unknown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a novel and intuitive method to reduce selection bias in the problem of estimating the individual treatment effect. We modeled the input features as generated by three types of latent variables A,B,C (in Figure <ref type="figure" target="#fig_0">1</ref>). The variables of type A only cause selection bias while not contributing to the outcome Y . Discarding it would help to alleviate selection bias. In order to learn the representation of A, an auto-encoder is used to learn the representations of features. We view the learned representations as two random vectors corresponding to categories A and BC. We then apply a loss based on Pearson correlation coefficient between any pair of random variables between these two vectors to encourage the linear independence of A and BC. This allows us to explicitly discard the category (A) that partially induces selection bias and only use the relevant features (BC) for the outcome prediction. We tested our approach on both synthetic and simulated real-world tasks, showing that our method achieved state-of-the-art results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The proposed causal graph for individual treatment effect estimation</figDesc><graphic coords="2,246.60,72.00,118.80,105.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The architecture of the proposed model RSB-Net. The representation learning network is an auto-encoder that learns the bias variables A and the variables BC that are relevant for prediction. The outcome prediction network has a branching structure predicting the outcome y t based on the treatment t and the representation of BC.</figDesc><graphic coords="3,145.58,72.00,320.83,127.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison on the IHDP dataset over 100 realiazations. The metrics are mean and standard errors of √ PEHE and ATE . Best result with statistical significance by Welch's t-test with α = 0.05 is highlighted in blue. Entry '-': not reported in the paper.</figDesc><table><row><cell>Methods</cell><cell>√</cell><cell>Within-sample PEHE ATE</cell><cell>√</cell><cell>Out-of-sample PEHE ATE</cell></row><row><cell cols="5">BNN Deep-Treat CFRW CFR-ISW RSB(Ours) 0.63 ± 0.025 0.25 +/-0.033 0.67 ± 0.043 0.26 ± 0.035 ---2.20 ± 0.130 ---1.93 ± 0.070 --0.88 ± 0.010 0.20 ± 0.003 --0.77 ± 0.010 0.19 ± 0.003</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Performance comparison on the IHDP dataset over 1000 realiazations. The metrics are mean and standard errors of √ PEHE and ATE . Best result with statistical significance by Welch's t-test with α = 0.05 is highlighted in blue.</figDesc><table><row><cell>Methods</cell><cell>√</cell><cell>Within-sample PEHE ATE</cell><cell>√</cell><cell>Out-of-sample PEHE ATE</cell></row><row><cell cols="5">k-NN BART BNN TARNET 0.88 ± 0.0 0.26 ± 0.01 0.95 ± 0.0 0.28 ± 0.01 2.1 ± 0.1 0.14 ± 0.01 4.1 ± 0.2 0.79 ± 0.05 2.1 ± 0.1 0.23 ± 0.01 2.3 ± 0.1 0.34 ± 0.02 2.2 ± 0.1 0.37 ± 0.03 2.1 ± 0.1 0.42 ± 0.03 CFRW 0.71 ± 0.0 0.25 ± 0.01 0.76 ± 0.0 0.27 ± 0.01 CEVAE 2.7 ± 0.1 0.25 ± 0.01 2.6 ± 0.1 0.46 ± 0.02 RSB(Ours) 0.66 ± 0.0 0.26 ± 0.01 0.68 ± 0.0 0.27 ± 0.01</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/clinicalml/cfrnet</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>the counterfactual outcomes are only used for evaluation purposes</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithm 2: Synthetic Data Generation Input: Dimension for each group of features D A , D B , D C ; Sample size N ; Number of realizations M . Compute the weight vector w for each realization h where {w h } M h=1 ∼ U((0, 0.1) D B +D C ) foreach sample (x, t, y CF , y F , µ 1 , µ 0</p><p>) do Compute the mean of A,B,C by µ A ∼ N (0, 5),</p><p>where A and B denote the mean of the feature vector A and B respectively; foreach each realization h under x do µ 0 = w ⊺ h x BC where x BC denote the feature vectors B and C in x ; For multiple realizations, a random split is performed once per realization, to prevent over-fitting. "Realization" refers to the randomized experiments for each input features X and treatment T .</p><p>Unless mentioned otherwise, we run hyperparemeter selection based on the nearest neighbor version of PEHE defined in <ref type="bibr" target="#b11">[Shalit et al., 2017]</ref>, on the validation set: PEHEnn = 1 N ∑ N i=1 ((1 -2t i )(y j(i)y i ) -(ŷ 1 -ŷ0 )) 2 where j(i) is the index of the nearest neighbor to sample i in the opposite treatment group. This metric is used since we do not have access to true PEHE in real-world settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment on Synthetic Dataset</head><p>As a sanity check, we experiment on a synthetic toy dataset to evaluate how well our model handles selection bias in a simple setting, in which the covariates X is generated by simply concatenating the proposed three types of variables A,B and C.</p><p>The detailed explanation can be found in Algorithm 2. The feature vectors A,B and C are sampled from normal distributions where the variances are fixed but the mean are sampled from another normal distribution for each sample. Since treatment T is binary and only affected by variables A and B in our graphical model, a Bernoulli distribution is used to generate T and the probability p is calculated as a sigmoid function applied to a weighted sum of A and B to map the value to [0,1]. The noiseless outcome µ 0 are generated by a linear combination of B and C where the weights are generated for each realization from a uniform distribution U((0, 0.1) D B +D C ) where D B and D C are the dimensions of B and C. µ 1 is then generated by simply adding a constant (10) to µ 0 for all samples. The noisy outcomes Y 1 and Y 0 are generated by adding a Gaussian noise N (0, 1) to µ 1 and µ 0 respectively. The data distribution of the toy dataset is designed to be simple, as the goal is to check if our method of reducing selection bias works in a very simple scenario: all features ABC are directly observable instead of hidden; the outcomes are linear w.r.t. the features BC and the ITE is a constant for all samples.</p><p>We generate 1000 realizations, each contains 1000 samples with 25 covariates (the dimension of A, B, C are 5,15,5). We use a 63/27/10 train/valid/test split following the literature.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep-treat: Learning optimal personalized treatments from observational data using neural networks</title>
		<author>
			<persName><surname>Onur Atan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI. AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Discovering Hidden Factors of Variation in Deep Networks</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><forename type="middle">A</forename><surname>Livezey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arjun</forename><forename type="middle">K</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6583</idno>
		<idno>arXiv: 1412.6583</idno>
		<ptr target="http://arxiv.org/abs/1412.6583.00075" />
		<imprint>
			<date type="published" when="2014-12">December 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">I</forename><surname>Hugh A Chipman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">E</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><surname>Mcculloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian additive regression trees</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="266" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Counterfactual regression with importance sampling weights</title>
		<author>
			<persName><forename type="first">Negar</forename><surname>Hassanpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russell</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="5880" to="5887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bayesian Nonparametric Modeling for Causal Inference</title>
		<author>
			<persName><forename type="first">Jennifer</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<idno type="ISSN">1061-8600</idno>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1537" to="2715" />
			<date type="published" when="2011-01">January 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Causal inference in statistics, social, and biomedical sciences</title>
		<author>
			<persName><forename type="first">W</forename><surname>Guido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Imbens</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recent developments in the econometrics of program evaluation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Guido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">M</forename><surname>Imbens</surname></persName>
		</author>
		<author>
			<persName><surname>Wooldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic literature</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="86" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning Representations for Counterfactual Inference</title>
		<author>
			<persName><forename type="first">Uri</forename><surname>Fredrik D Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3020" to="3029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Causal effect inference with deep latent-variable models</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6446" to="6456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Afshin</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0902.3430</idno>
		<title level="m">Domain adaptation: Learning bounds and algorithms</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Estimating individual treatment effect: generalization bounds and algorithms</title>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fredrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3076" to="3085" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
