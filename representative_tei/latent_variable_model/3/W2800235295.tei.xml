<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">warwick.ac.uk/lib-publications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anurendra</forename><surname>Kumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology (IIT)</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tanaya</forename><surname>Guha</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology (IIT)</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Prasanta</forename><surname>Ghosh</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Science (IISC)</orgName>
								<address>
									<settlement>Bangalore</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">warwick.ac.uk/lib-publications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Author&apos;s Accepted Manuscript The version presented in WRAP is the author&apos;s accepted manuscript and may differ from the published version or Version of Record.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Latent variable model</term>
					<term>Dirichlet distribution</term>
					<term>non-negative matrix factorization</term>
					<term>source separation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Please refer to published version for the most recent bibliographic citation information. If a published version is known of, the repository item page linked to above, will contain details on accessing it.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Modeling time-varying, non-negative data is critical for many signal processing problems. One such important problem is audio source separation, where time varying, non-negative data arise in the form of magnitude spectra <ref type="bibr" target="#b1">[1]</ref>. Source separation is a long standing problem in signal processing, which has widespread applications in speaker recognition, speech enhancement, music editing and audio information retrieval <ref type="bibr" target="#b2">[2,</ref><ref type="bibr" target="#b3">3]</ref>.</p><p>This paper addresses the problem of modeling time varying nonnegative data, looking particularly at the problem of supervised source separation. In the case of supervised source separation, we assume the availability of training data for each source <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b4">4]</ref>. The training data is used to learn the underlying building blocks i.e., the latent bases for each source. These latent bases are later used to separate the sources from the mixture. Two techniques that have been prominent in this field for learning latent bases are: latent variable model (LVM) <ref type="bibr" target="#b4">[4]</ref> and non-negative matrix factorization (NMF) <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b6">6]</ref>. One of the most popular LVM methods is the probabilistic latent component analysis (PLCA), which has widespread application in acoustic modeling <ref type="bibr" target="#b1">[1]</ref>. NMF, on the other hand, is a non-probabilistic approach to learn latent basis with extensive applications to text, image and audio analysis. For certain cost functions, LVM is known to converge to NMF <ref type="bibr" target="#b7">[7]</ref>, and can be thought of as the probabilistic counterpart of NMF.</p><p>The LVM and the NMF in their basic forms do not take into account the temporal correlation in the data. However, many signals, such as music and speech exhibit strong temporal dependence. To address this issue, dynamic variants of LVM and NMF have been developed <ref type="bibr">[8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b10">10]</ref>. Most of these dynamic models capture the temporal dependence in data by imposing temporal constraints on the latent bases and their coefficients <ref type="bibr">[8,</ref><ref type="bibr" target="#b9">9]</ref>. A dynamic variant of PLCA, called the Convolutive PLCA (CPLCA) <ref type="bibr">[8]</ref>, was proposed to capture the temporal structure in data by assuming the likelihood to be a convolutive mixture. Another dynamic version of PLCA involves dynamic filtering and smoothing, where the coefficient matrix was smoothened by using a vector autoregression (VAR) method <ref type="bibr" target="#b11">[11]</ref>. A recent work developed a dynamic NMF (an extension of PLCA) by using an exponential prior <ref type="bibr" target="#b10">[10]</ref>. Apart from the LVMs and NMF methods, the hidden Markov model (HMM) has also been extended to model temporal non-negative data <ref type="bibr" target="#b12">[12]</ref>.</p><p>In this paper, we present a novel dynamic LVM for learning latent bases for time varying, non-negative data. Our model uses a mixture multinomial as the likelihood function, and proposes to use a Dirichlet distribution with dynamic parameters as a prior (referred to as the dynamic Dirichlet prior). The mixture multinomial likelihood function is chosen because it is known to yield superior results in source separation and topic modeling <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b14">14]</ref>. The Dirichlet distribution is the conjugate of multinomial, and has been successfully used (without dynamic properties) as a prior in text modeling <ref type="bibr" target="#b13">[13]</ref>. We propose a dynamic variant of the Dirichlet prior in this work, which is particularly suitable for non-negative data. We develop an expectation maximization (EM) algorithm for the proposed model, and derive a maximum a posteriori (MAP) estimate of the parameters. This leads to simple and intuitive update equations due to multinomial-Dirichlet conjugacy. We refer our model as the dynamic Dirichlet latent variable model (dynamic DLVM) in the rest of the paper. Furthermore, we show that (i) the PLCA model is a special case of the dynamic DLVM, and (ii) our model is also a dynamic version of NMF. The effectiveness of the dynamic DLVM is demonstrated through extensive experiments on speaker source separation and speech-noise separation using the SPIB <ref type="bibr" target="#b15">[15]</ref> and the TIMIT database <ref type="bibr" target="#b16">[16]</ref>. In all cases, our method performs better than several relevant existing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROPOSED DYNAMIC DIRICHLET LATENT VARIABLE MODEL</head><p>Let us consider a time varying signal x(t). We represent x(t) spectrographically by taking its short time Fourier transform (STFT), and retaining its scaled magnitude spectrogram</p><formula xml:id="formula_0">N N = γ|ST F T (x(t))| = γX (1)</formula><p>where, X is magnitude spectrogram, γ is a large integer which ensures that all the elements in N are integers <ref type="bibr" target="#b1">[1]</ref>. The observation spectral data matrix N can be seen as count data, where N f t ∈ N corresponds to the count of frequency f , at a time instant t. Latent variable models assume that the underlying cause of an observed variable f , is a set of unobserved latent variables z k , 1 ≤ k ≤ K. Marginalizing over the latent bases z, the spectrogram at each time instant t, is a mixture of K hidden distributions, where K is a known positive integer</p><formula xml:id="formula_1">Pt(f ) = K k=1 Pt(f, z k ) = K k=1 Pt(z k )P (f |z k )<label>(2)</label></formula><p>where, Pt(f ) is the probability of frequency f at time instant t, P (f |z k ) is a multinomial distribution similar to PLCA <ref type="bibr" target="#b1">[1]</ref> and the coefficients of mixtures are Pt(z k ). Let us now define a state of the data matrix N at time t as st as follows:</p><formula xml:id="formula_2">st = [Pt(z1), ..., Pt(zK )] T = [st(1), st(2)..., st(K)] T<label>(3)</label></formula><p>We impose a Markovian dependence between states, which uses a Dirichlet distribution. This is described below in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Dynamic DLVM</head><p>We propose to model the temporal dependence between states using a Dirichlet distribution with time varying parameters</p><formula xml:id="formula_3">P (st|st-1, D) = Dir(αt-1D st-1 + 1)<label>(4)</label></formula><p>where, αt</p><formula xml:id="formula_4">= f N f t , P (s1) = Dir(1)</formula><p>Here, "Dir" denotes the Dirichlet distribution <ref type="bibr" target="#b17">[17]</ref>, 1 is an all-one vector, αt is the total number of observations at time instant t, and D is a temporal dependence matrix. For simplicity, we assume D to be a diagonal matrix with</p><formula xml:id="formula_5">D kk = d k , 1 ≤ k ≤ K,</formula><p>where d k ∈ R + denotes the temporal dependence between two consecutive time instants for the k-th latent basis. Let us now define pseudoobservation from the previous time instant for each basis k as m tk = αt-1d k st-1(k). Therefore Eq. ( <ref type="formula" target="#formula_3">4</ref>) can be rewritten as follows:</p><formula xml:id="formula_6">P (st|st-1, D) = Γ( k (m tk + 1)) k Γ(m tk + 1)) k st(k) m tk</formula><p>where, Γ is the gamma function.  <ref type="formula" target="#formula_13">8</ref>)), which is the result of multinomial-Dirichlet conjugacy. (ii) The mode of the distribution lies at the normalized pseudo-observations</p><formula xml:id="formula_7">Pmax(st(k)|st-1) = d k st-1(k) k d k st-1(k) (iii)</formula><p>The variance of each entry of the vector st can be obtained from the properties of Dirichlet distribution <ref type="bibr" target="#b17">[17]</ref> V ar(st</p><formula xml:id="formula_8">(k)|st-1) ∝ 1 ( k m tk + K) 2 ( k m tk + K + 1)</formula><p>which decreases as total number of observations at previous time instant increases. It is also intuitive, since we expect the distribution to have less variance when we have more prior information from previous time instant. Thus dynamic DLVM assumes the following generative process of the spectrogram N :</p><p>• Choose a state, st ∼ Dir(αt-1Dst-1 + 1)</p><p>• Sample frequency f , αt times as follows:</p><p>-Choose a latent basis zi ∼ Mult(st)</p><p>-Choose a frequency f ∼ Mult(P (f |zi)).</p><p>• Repeat the above process T times where, T is the total number of time instants, "Mult" denotes the multinomial distribution. Fig. <ref type="figure">1</ref> presents the graphical model for the generative process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">PLCA as a special case of dynamic DLVM</head><p>The relationship between the proposed dynamic DLVM and the well known PLCA <ref type="bibr" target="#b1">[1]</ref> model is noteworthy. When the temporal dependence matrix D is reduced to a zero matrix, the distribution in Eq. ( <ref type="formula" target="#formula_3">4</ref>) becomes a symmetric Dirichlet distribution Dir <ref type="bibr" target="#b1">(1)</ref>. Note that the symmetric Dirichlet distribution Dir(1) is nothing but a uniform distribution, and thus the formulation is equivalent to a static PLCA <ref type="bibr" target="#b18">[18]</ref>. This can also be intuitively understood as a fact that in the absence of prior information, there exists no preference of any state over others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PARAMETER ESTIMATION</head><p>In this section, we describe the parameter estimation steps for the proposed dynamic DLVM. We obtain point estimates for st by performing a maximum a posteriori (MAP) estimate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Expectation step</head><p>The posterior distribution of the latent variable z is given by</p><formula xml:id="formula_9">Pt(z k |f ) = Pt(z k )P (f |z k ) k Pt(z k )P (f |z k )<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Maximization step</head><p>Let us denote the state matrix S = [s1, s2, .....st]. Let β= {P (f |z), D}. We want to maximize the following MAP objective function</p><formula xml:id="formula_10">LMAP = E P t (z|f ) (log P (N, S|β)) = E P t (z|f )</formula><p>log P (N|S, β) + log P (S|β)</p><formula xml:id="formula_11">s.t., f P (f |z k ) = 1, k st(k) = 1, 0 &lt; d k<label>(6)</label></formula><p>The objective function LMAP is concave with respect to each parameters (S, P (f |z), D) when others are fixed 1 . Therefore, we update the parameters in an alternating fashion <ref type="bibr" target="#b19">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Update of P (f |z)</head><p>Maximizing the above constrained expected log-likelihood in Eq. ( <ref type="formula" target="#formula_11">6</ref>) with respect to P (f |z k ) yields the following</p><formula xml:id="formula_12">P (f |z k ) = t N f t Pt(z k |f ) f t N f t Pt(z k |f )<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Update of S</head><p>Similarly, maximizing w.r.t. st(k), while keeping D fixed yields </p><formula xml:id="formula_13">st(k) = f N f t Pt(z k |f ) + m tk k ( f N f t Pt(z k |f ) + m tk )<label>(8</label></formula><formula xml:id="formula_14">+ k m tk log(st(k)) s.t., 0 &lt; d k .<label>(9)</label></formula><p>However, the maximizing function is concave since the Dirichlet distribution is a member of the exponential family 1 . Therefore the local minimum of the function is also a global minimum, which can be obtained via gradient ascent</p><formula xml:id="formula_15">∂LMAP ∂d k = T t=2 αt-1st-1(k)(ψ( i mti + K)- ψ(m tk + 1) + log(st(k)).</formula><p>where, ψ is the di-gamma function. It is to be noted that updates of P (f |z) and S are independent of scaling factor γ. Therefore, we will replace N with X in all the update equations. The complete algorithm is presented in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DYNAMIC DLVM AS DYNAMIC NMF</head><p>The proposed dynamic DLVM learns the latent bases and the states for a data matrix via factorization in Eq. ( <ref type="formula" target="#formula_1">2</ref>). Multiplying both sides of the equation by αt, we rewrite Eq. ( <ref type="formula" target="#formula_1">2</ref>) in matrix form as vt = Wstαt, where, W is a matrix whose columns are latent bases P (f |z), vt is the observation vector at time instant t. Concatenating observation vector for all time instants, we can write the observed data matrix X as XF ×T = WF ×K SK×T GT ×T = WF ×K HK×T where, W is basis matrix, S is a state matrix and G is a diagonal matrix with αt as the diagonal elements. Therefore, we can view dynamic DLVM as a dynamic NMF with the iterative updates for W and S (see Algorithm 1). The novelty of dynamic DLVM lies in the way S is constrained. The columns of S are assumed to be realization from dynamic Dirichlet distribution. In the algorithm, outer loop corresponds to the EM iteration, while the inner loop corresponds to the block-wise update of variables in the maximization step of the EM algorithm. </p><formula xml:id="formula_16">W f k = W f k t X f t (WS) f t S kt W f k = W f k / k W f k while Not converged do m tk = αt-1d k st-1(k) S kt = S kt f W f k X f t (WS) f t + m tk S kt = S kt / t S kt</formula><p>Update d using Eq. 9 end end</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">APPLICATION TO SOURCE SEPARATION</head><p>We demonstrate the effectiveness of the proposed dynamic DLVM through its ability to perform supervised source separation. We first learn the basis matrix W for each source, and then separate the sources by employing a standard source separation algorithm following an earlier work <ref type="bibr" target="#b4">[4]</ref>. Note that we only use the latent bases (and not the dependency matrix D) during the source separation. We perform two types of source separation experiments: (i) speaker source separation, where mixtures contain speech sources from two speakers, and (ii) noise-source separation, where mixtures contain speech and noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental details</head><p>We follow an experimental setup similar to that described in past works on source separation using PLCA and its variants <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b21">21]</ref>. The source separation experiments use samples from the TIMIT database <ref type="bibr" target="#b16">[16]</ref>, and noise data from SPIB <ref type="bibr" target="#b15">[15]</ref>. The magnitude spectrograms are obtained by performing STFT on a 64ms window with 16ms overlap. We learn K = 30 latent basis in each case, and use the maximum number of iterations (250 for outer loop, 8 for inner loop) as the convergence criterion for Algorithm 1.</p><p>To evaluate the performance on source separation, we use four evaluation metrics: signal-to-noise ratio improvement (SNRI) <ref type="bibr" target="#b22">[22]</ref>, source-to-distortion ratio (SDR), source-to-interference ratio (SIR), and source-to-artifact ratio (SAR) <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b25">25]</ref>. The later three metrics measure perceptual quality of the separated sources. The SNR improvement (SNRI) of a speaker is calculated by incorporating the phase information and by comparing the improvement in SNR with that of the mixture signal as defined in literature <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b4">4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speaker source separation</head><p>Following the experimental set up of the past literature <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b21">21]</ref>, we have used ∼ 25 seconds of speech (8 to 9 sentences) from 10 speakers (5 male, 5 female) in the database for our experiments. To model each speaker (source), the first ∼ 17 seconds of the speech is used. The remaining 5 to 7 seconds of speech were used to create 45 synthetic mixtures by adding the speech from two speakers. The speech signals were normalized to zero mean and unit variance prior to addition. Source separation experiments were performed on 45 mixtures using the proposed dynamic DLVM. Fig. <ref type="figure">2</ref> presents a qualitative result of source separation. Fig. <ref type="figure">2b</ref> and Fig. <ref type="figure">2c</ref> present the reconstructed spectrograms of a given source recovered from a mixture using PLCA and dynamic DLVM. Notice that the dynamic DLVM recovers a smoother spectrogram (areas of significant differences are highlighted). The performance of dynamic DLVM is evaluated in terms of the four evaluation metrics mentioned earlier (see Fig. <ref type="figure">3</ref>). The performance of dynamic DLVM is compared against those of three baseline methods -PLCA <ref type="bibr" target="#b1">[1]</ref>, PLCA with dynamic filtering <ref type="bibr" target="#b11">[11]</ref> and PLCA with dynamic smoothing <ref type="bibr" target="#b11">[11]</ref>. Dynamic DLVM performs better than or comparable to the baseline methods in terms of all evaluation metrics. Our model outperforms PLCA by 0.96 dB in SNRI, 0.87 db in SDR, 1.38 db in SIR, and 0.46 db in SAR. The improvement in terms of SAR implies that the artifacts introduced by dynamic DLVM is lesser than the other models. Usually, there is a trade-off between removing noise (measured by SDR and SNRI) and introducing artifacts (measured by SAR). The existing dynamic models <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b12">12]</ref> while improving SDR often introduce artifacts, which leads to a degraded SAR. However, the proposed model shows simultaneous improvement in SDR and SAR. This indicates an overall better modeling ability of dynamic DLVM, and consequently, a better source separation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Speech and noise separation</head><p>We consider a speech denoising scenario where prior information about the noise types and the associated training data is available.</p><p>Both the noise and the speech are first normalized to have zero mean and unit variance. The noisy mixtures were obtained by adding noise (one at a time) to each speaker signal, resulting into a signal to noise ratio of 0 dB. We experiment with five noise types: babble, factory, white, pink and cockpit <ref type="bibr" target="#b15">[15]</ref>, and speech from 10 speakers used in the speaker source separation experiments. The latent bases are learned for each speaker and noise from their respective training data (same parameter values as before). Fig. <ref type="figure">5</ref> presents a sample qualitative result of denoising a source corrupted with babble noise. The performance of dynamic DLVM averaged over 10 mixtures is listed in Table <ref type="table" target="#tab_3">1</ref>, and compared with the baselines. Dynamic DLVM, on average, shows an improvement of 0.9 dB. Note that it performs better than other methods for all noise types, except white noise. This can be explained by the fact that white noise is stationary and has no temporal structure. Nevertheless, for non-stationary noise, the proposed model is able to learn the temporal dependencies in data/noise, which results in better separation. As observed earlier, dynamic DLVM shows 1dB SAR improvement for all noise types as compared to PLCA. This observation supports our earlier claim that our model introduces less artifacts compared to other dynamic models in literature <ref type="bibr" target="#b11">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>We proposed a latent variable model, called the dynamic DLVM, for modeling time varying non-negative data. We introduced a new prior (dynamic Dirichlet distribution) and used a multinomial as likelihood for this model. An EM algorithm was proposed accordingly for parameter estimation. We showed that the popular PLCA model is a special case of our model. A major contribution of this paper is to introduce this dynamic Dirichlet prior for non-negative data.</p><p>The existing dynamic variant of Dirichlet can not be used under non-negativity constraints as it yields negative updates. Due to the proposed dynamic Dirichlet prior, the dynamic DLVM transforms to a dynamic version of NMF. Unlike other dynamic latent variable models, our model does not require any free parameter (except the number of latent bases). Although this work involves modeling magnitude spectra, the proposed model is generic and suitable for modeling other types of non-negative data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGEMENT</head><p>This work is partially supported by the grant IITK/EE/2015052.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>)</head><label></label><figDesc>Update of D Let us define d = [d1, ...., dK ] T . Maximizing LMAP w.r.t. d, keeping S fixed does not have a closed form solution + 1))k log Γ(m tk + 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :Fig. 3 :</head><label>23</label><figDesc>Fig. 3: Results on speaker separation: Dynamic DLVM compared with three existing techniques in terms of four evaluation metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Original source (left); recovered source using PLCA (center) and dynamic DLVM (right) from a noisy signal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,-0.15,-0.00,595.62,118.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Plate notation for the proposed dynamic DLVM. associate an unknown latent variable z of dimension K with one of the entries as 1 and rest as zero, z = [z1, z2, ....zK ]. z k acts as an indicator for the k-th latent basis, which is described by a spectral distribution P (f |z k ).</figDesc><table><row><cell>s t-1</cell><cell></cell><cell></cell></row><row><cell>s t</cell><cell>z</cell><cell>f</cell></row><row><cell></cell><cell></cell><cell>αt</cell></row><row><cell></cell><cell></cell><cell>T</cell></row><row><cell>s t+1</cell><cell></cell><cell></cell></row><row><cell>Fig. 1:</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Each</cell></row><row><cell></cell><cell></cell><cell>column of the matrix N thus corresponds to the spectral distribution</cell></row><row><cell></cell><cell></cell><cell>at each time instant. With each frequency count f ∈ 1, 2, ...F , we</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>) allows us to view the spectrogram at time t as observed count data over K bases. Static models such as PLCA uses this observation data to estimate the states at each time instant. The dynamic Dirichlet prior allows us to have m tk extra pseudoobservations for each basis k (see Eq. (</figDesc><table /><note><p>Note that the the hyperparameters of the Dirichlet distribution are dynamic, hence, we refer to it as the dynamic Dirichlet distribution in the rest of this paper. The proposed dynamic Dirichlet distribution prior has several appealing properties with intuitive understanding: (i) The generative process (with mixture multinomial as likelihood</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Comparison of different methods for noise separation</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Average SNRI</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Babble</cell><cell>Factory</cell><cell>White</cell><cell>Pink</cell><cell>Cockpit</cell></row><row><cell>PLCA [1]</cell><cell>5.63</cell><cell>2.60</cell><cell>5.07</cell><cell>2.04</cell><cell>2.78</cell></row><row><cell>Dynamic filtering [11]</cell><cell>4.93</cell><cell>2.87</cell><cell>5.83</cell><cell>2.06</cell><cell>2.70</cell></row><row><cell>Dynamic smoothing [11]</cell><cell>4.30</cell><cell>2.99</cell><cell>5.36</cell><cell>2.14</cell><cell>2.38</cell></row><row><cell>Dynamic DLVM</cell><cell>5.83</cell><cell>5.30</cell><cell>3.90</cell><cell>4.60</cell><cell>3.03</cell></row><row><cell></cell><cell></cell><cell cols="2">Average SAR</cell><cell></cell><cell></cell></row><row><cell>PLCA [1]</cell><cell>6.69</cell><cell>8.14</cell><cell>8.30</cell><cell>7.82</cell><cell>7.84</cell></row><row><cell>Dynamic filtering [11]</cell><cell>6.44</cell><cell>7.73</cell><cell>5.25</cell><cell>5.97</cell><cell>4.36</cell></row><row><cell>Dynamic smoothing [11]</cell><cell>5.65</cell><cell>7.73</cell><cell>3.98</cell><cell>7.44</cell><cell>3.21</cell></row><row><cell>Dynamic DLVM</cell><cell>7.22</cell><cell>8.75</cell><cell>9.92</cell><cell>8.66</cell><cell>9.13</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A probabilistic latent variable model for acoustic modeling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shashanka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="8" to="9" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Blind source separation: theory and applications</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">From blind to guided audio source separation: How models and side information can improve the separation of sound</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bertin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bimbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="107" to="115" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Latent dirichlet decomposition for single channel speaker separation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Shashanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2006">2006</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Investigating single-channel audio source separation methods based on non-negative matrix factorization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Plumbley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICA Research Network International Workshop</title>
		<meeting>ICA Research Network International Workshop</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Monaural sound source separation by nonnegative matrix factorization with temporal continuity and sparseness criteria</title>
		<author>
			<persName><forename type="first">T</forename><surname>Virtanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on audio, speech, and language processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1066" to="1074" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic latent variable models as nonnegative factorizations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shashanka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational intelligence and neuroscience</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutive speech bases and their application to supervised speech separation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TASLP</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Shift-invariant probabilistic latent component analysis, tech report</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A state-space approach to dynamic nonnegative matrix factorization</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mohammadiha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Panahandeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Doclo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="949" to="959" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Prediction based filtering and smoothing to exploit temporal dependencies in NMF</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mohammadiha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leijon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="873" to="877" />
			<date type="published" when="2013">2013</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Non-negative hidden markov modeling of audio with application to source separation</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mysore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Latent Variable Analysis and Signal Separation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="140" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01">Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Speech Research Unit (SRU) at Institute for Perception-TNO, Netherlands. Signal processing information base (SPIB)</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename></persName>
		</author>
		<ptr target="http://spib.linse.ufsc.br/noise.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DARPA TIMIT acoustic-phonetic continous speech corpus cd-rom. NIST speech disc 1-1.1</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Garofolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Fiscus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Pallett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">NASA STI/Recon technical report</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Tang</surname></persName>
		</author>
		<title level="m">Dirichlet and related distributions: Theory, methods and applications</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">888</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On an equivalence between plsi and lda</title>
		<author>
			<persName><forename type="first">M</forename><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kabán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 26th annual international ACM SI-GIR conference on Research and development in informaion retrieval</title>
		<meeting>of the 26th annual international ACM SI-GIR conference on Research and development in informaion retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="433" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on imaging sciences</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1758" to="1789" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent variable decomposition of spectrograms for single channel speaker separation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Applications of Signal Processing to Audio and Acoustics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Results and demos</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shashanka</surname></persName>
		</author>
		<ptr target="http://cns.bu.edu/mvss/courses/speechseg/" />
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Latent variable framework for modeling and separating single-channel acoustic sources</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>BOSTON UNIVERSITY</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">BSS EVAL toolbox user guide-revision 2</title>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/inria-00564760/" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Performance measurement in blind audio source separation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Févotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on audio, speech, and language processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1462" to="1469" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The 2008 signal separation evaluation campaign: A community-based approach to largescale evaluation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bofill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Independent Component Analysis and Signal Separation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="734" to="741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Static and dynamic source separation using nonnegative factorizations: A unified view</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smaragdis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fevotte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mysore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mohammadiha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="66" to="75" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
