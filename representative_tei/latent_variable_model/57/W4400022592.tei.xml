<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multimodal Large Language Models</title>
				<funder ref="#_R5HJGnU">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
				<funder ref="#_YGt5K5T">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_BRkQ8AR #_PkpwdSE #_U7ayDRa #_MH2G595 #_GWVX3cK #_ZZJu5Wv">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-08-28">28 Aug 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mengdan</forename><surname>Zhu</surname></persName>
							<email>mengdan.zhu@emory.edu</email>
						</author>
						<author>
							<persName><forename type="first">Raasikh</forename><surname>Kanjiani</surname></persName>
							<email>raasikh.kanjiani@emory.edu</email>
						</author>
						<author>
							<persName><forename type="first">Jiahui</forename><surname>Lu</surname></persName>
							<email>jiahui.lu.24@ucl.ac.uk</email>
						</author>
						<author>
							<persName><forename type="first">Andrew</forename><surname>Choi</surname></persName>
							<email>andrew.jaemin.choi@emory.edu</email>
						</author>
						<author>
							<persName><forename type="first">Qirui</forename><surname>Ye</surname></persName>
							<email>qirui.ye@emory.edu</email>
						</author>
						<author>
							<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
							<email>liang.zhao@emory.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science London</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Emory University</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multimodal Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-08-28">28 Aug 2025</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3746252.3761318</idno>
					<idno type="arXiv">arXiv:2406.14862v7[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Explainable AI</term>
					<term>Multimodal Large Language Models</term>
					<term>Deep Generative Models</term>
					<term>Latent Representations</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep generative models like VAEs and diffusion models have advanced various generation tasks by leveraging latent variables to learn data distributions and generate high-quality samples. Despite the field of explainable AI making strides in interpreting machine learning models, understanding latent variables in generative models remains challenging. This paper introduces LatentExplainer 1 , a framework for automatically generating semantically meaningful explanations of latent variables in deep generative models. Latent-Explainer tackles three main challenges: inferring the meaning of latent variables, aligning explanations with inductive biases, and handling varying degrees of explainability. Our approach perturbs latent variables, interprets changes in generated data, and uses multimodal large language models (MLLMs) to produce human-understandable explanations. We evaluate our proposed method on several realworld and synthetic datasets, and the results demonstrate superior performance in generating high-quality explanations for latent variables. The results highlight the effectiveness of incorporating inductive biases and uncertainty quantification, significantly enhancing model interpretability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS Concepts</head><p>â€¢ Computing methodologies â†’ Artificial intelligence.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACM Reference Format: Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, and Liang Zhao. 2025. LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multimodal Large Language Models. In Proceedings</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep generative models, such as Variational Autoencoders (VAEs) <ref type="bibr" target="#b18">[19]</ref> and diffusion models <ref type="bibr" target="#b32">[33]</ref>, have become a state-of-the-art approach in various generation tasks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b41">42]</ref>. These methods effectively leverage latent variables to learn underlying data distributions and generate high-quality samples by capturing the underlying structure of high-dimensional data in a low-dimensional semantic space. As the latent variables represent all the information in a lower dimension, they can be considered as an effective abstraction of key factors in the data. Therefore, it is critical to develop methods for automatically decomposing and explaining meaningful latent dimension semantics given a pretrained generative model and its inherent inductive biases, as illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. Inductive biases are often enforced over latent variables in deep generative models. For instance, disentanglement is a rule of thumb which enforces orthogonality among different latent variables <ref type="bibr" target="#b12">[13]</ref>. Moreover, sometimes latent variables can be grouped, leading to combination bias <ref type="bibr" target="#b19">[20]</ref>. More recently, the desire for controllability in deep generative models, where latent variables are associated with specific properties of interest <ref type="bibr" target="#b37">[38]</ref>, has given rise to conditional bias. Incorporating inductive biases aligned with the actual facts can reduce the hallucination in explaining the latent variables in deep generative models <ref type="bibr" target="#b38">[39]</ref>. The field of explainable artificial intelligence (XAI) has extensively investigated the interpretation of machine learning models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b49">50]</ref>. However, interpreting latent variables in deep generative models remains underexplored. Machine learning model explanation, a.k.a., post-hoc explanation, can be categorized into global and local explanations <ref type="bibr" target="#b14">[15]</ref>. Global explanations focus on elucidating the entire model, while local explanations target the reasoning behind specific predictions. Global explanations are more challenging, with existing work mostly emphasizing attributions to identify which features are most important for model decision-making <ref type="bibr" target="#b33">[34]</ref>. The missing piece is understanding the meaning of features when they are unknown, which is very common in deep generative models. More recently, one category of global explanation methods, called concept-based explanations, aims to generate more human-understandable concepts as explanations <ref type="bibr" target="#b29">[30]</ref>. However, current concept-based methods often rely on human heuristics or predefined concept and feature space, limiting the expressiveness of the explanations and falling short of achieving truly automatic explanation generation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21]</ref>.</p><p>Despite the progress in XAI, interpreting latent variables in deep generative models presents significant challenges. First, these variables are not grounded in real-world concepts, and the black-box nature of the models prevents us from inferring the meaning of latent variables from observations. Second, explanations must adhere to the inductive biases imposed on the latent variables, which is essential yet difficult to ensure. For example, in disentangled latent variables, the semantic meanings should be orthogonal. Third, different latent variables have varying degrees of explainability. Some may be trivial to data generation and intrinsically lack semantic meaning. It is crucial to identify which latent variables are explainable and which do not need explanations.</p><p>To address the aforementioned challenges, we propose LatentExplainer, a novel and generic framework that automatically generates semantically-meaningful explanations of latent variables in deep generative models. Specifically, to explain these variables and work around the black-box nature of the models, we propose to perturb each latent variable and explain the resulting changes in the generated data. Specifically, we perturb and decode each manipulated latent variable to produce the corresponding sequence of generated data samples. The trend in the sequence is leveraged to reflect the semantics of the latent variable to be explained. To align explanations with the intrinsic nature of the deep generative models, we design a generic framework that formulates inductive biases on the Bayesian network of latent variable models into textual prompts. These prompts are understandable to large foundation models and humans. To handle the varying degree of explainability in latent variables, we propose to measure the confidence of the explanations by estimating their uncertainty. This approach assesses whether the latent variables are interpretable and selects the most consistent explanations, ensuring accurate and meaningful interpretation of the latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Deep Generative Models. Deep generative models are essential for modeling complex data distributions. Variational Autoencoders (VAEs) are prominent in this area, introduced by Kingma and Welling <ref type="bibr" target="#b18">[19]</ref>. VAEs encode input data into a latent space and decode it back, optimizing a balance between reconstruction error and the Kullback-Leibler divergence <ref type="bibr" target="#b30">[31]</ref>. They have diverse applications, including image generation <ref type="bibr" target="#b40">[41]</ref>, and anomaly detection <ref type="bibr" target="#b1">[2]</ref>.</p><p>Diffusion models, proposed by Ho et al. <ref type="bibr" target="#b15">[16]</ref>, generate data by a diffusion process that gradually adds noise to the data and then learns to reverse this process to recover the original data. These models have achieved high-fidelity image generation, surpassing generative adversarial networks (GANs) in quality and diversity. Latent diffusion models allow the model to operate in a lower-dimensional space, which significantly reduces computational requirements while maintaining the quality of the generated samples <ref type="bibr" target="#b32">[33]</ref>. Advances have made them applicable to text-to-image synthesis <ref type="bibr" target="#b25">[26]</ref>, and audio generation <ref type="bibr" target="#b21">[22]</ref>. Latent Variable Manipulation and Explanations. Manipulating latent variables in generative models like VAEs and diffusion models is an important technique for editing and enhancing generated images. A key method is latent traverse, which involves traversing different values of latent variables to achieve diverse manipulations in the generated outputs. This technique allows for precise control over the attributes in generated images, enabling adjustments <ref type="bibr" target="#b10">[11]</ref>. For example, latent traverse has been effectively employed to disentangle and control various attributes in generated images <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b47">48]</ref>. However, latent traverse is often used for visualization and editing purposes. It has not yet been widely explored as a tool for explaining the underlying latent space. Their explanations primarily rely on using predefined training attributes as text labels or manually adding explanations <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b34">35]</ref>. Some concept-based models control latent variables in generative models using category concepts to generate data <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b36">37]</ref>. However, these approaches cannot automatically generate free-form textual explanations.</p><p>More recently, Multimodal Large Language Models (MLLMs) integrate diverse data modalities, enhancing their ability to understand and generate complex information <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b42">43]</ref>. Notable models include GPT-4o, which extends GPT-4v with better visual capabilities <ref type="bibr" target="#b26">[27]</ref>, and Gemini that is a family of highly capable multimodal models <ref type="bibr" target="#b35">[36]</ref>. We envision leveraging MLLMs to automatically generate explanations for latent variables and incorporate their inductive biases to reduce hallucination. Our work focuses on: (1) how to decompose the inductive bias formulas to automate the manipulation of latent variables, (2) how to develop prompts that are aligned with the underlying inductive biases of generative models and can be easily understood by MLLMs, and (3) how to evaluate the quality of the generated explanations for latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries and Problem Formulation</head><p>Deep Generative Models. These are a class of models that learn a mapping between observations x and underlying latent factors z.  These models are widely used in deep generative models such as VAEs and latent diffusion models. VAEs, for instance, introduce a probabilistic approach to encoding data by maximizing the evidence lower bound (ELBO) <ref type="bibr" target="#b18">[19]</ref>:</p><formula xml:id="formula_0">L ELBO = E ğ‘ (z|x) [log ğ‘ (x|z)] -KL(ğ‘(z|x)âˆ¥ğ‘ (z)),</formula><p>where KL stands for Kullback-Leibler divergence. Latent diffusion models further refine the generation process by iteratively refining noise into structured data <ref type="bibr" target="#b32">[33]</ref>. These models effectively capture the underlying structure of data in a low-dimensional semantic space. Latent variable manipulation of diffusion models aims at transversing the latent variables z along the semantic latent direction z i . The perturbed vector z</p><formula xml:id="formula_1">= z + ğ›¾ [G(z + z i ) -G(z)],</formula><p>where ğ›¾ is a hyper-parameter controlling the strength and G is a diffusion decoder <ref type="bibr" target="#b28">[29]</ref>. An image sequence can then be generated by G( z). The perturbations in the semantic latent direction lead to semantic changes in the generated image sequence. Inductive Bias in Latent Variables. Inductive biases are usually imposed on latent variables to enhance the performance and interpretability of deep generative models. These inductive biases in deep generative models can be categorized into three common types: Disentanglement Bias: It enforces orthogonality among different latent variables, ensuring that each latent variable captures a distinct factor of variation in the data <ref type="bibr" target="#b12">[13]</ref>. Combination bias: Sometimes latent variables are grouped, leading to biases in how they interact and combine to represent complex data structures <ref type="bibr" target="#b19">[20]</ref>. Conditional Bias: It emphasizes the relationship between specific properties of interest and the corresponding latent variables <ref type="bibr" target="#b37">[38]</ref>. Problem Formulation. We assume a dataset D, where each sample consists of ğ‘¥ or (ğ‘¥, ğ‘¦), with ğ‘¥ âˆˆ R ğ‘ and ğ‘¦ = {ğ‘¦ ğ‘˜ âˆˆ R} ğ¾ ğ‘˜=1 as ğ¾ properties of ğ‘¥. The dataset D is generated by M latent variables ğ‘§ ğ‘– , where ğ‘– âˆˆ {1, . . . , ğ‘€ }. ğ‘§ ğ‘– can be an individual latent dimension in ğ‘§ in the VAE models or a latent vector in the diffusion models. Suppose we are given a generative model with a set of formulas F with respect to ğ‘§ ğ‘– , where F represents an inductive bias that the generative model must satisfy. Our goal is to derive a textual sequence that explains the semantic meanings of ğ‘§ ğ‘– .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Method 4.1 Overview of LatentExplainer</head><p>This paper focuses on the tasks in explaining the semantics of latent variables {ğ‘§ ğ‘– } ğ‘€ ğ‘–=1 in deep generative models. To interpret the semantics of latent variables and work around the blackbox nature of deep generative models, we propose to perturb each ğ‘§ ğ‘– and explain the change it imposes on the generated data. To solve these challenges, we propose a novel LatentExplainer scheme. The pseudo-code of this whole scheme can be found in Algorithm 1. When explaining latent variable models, it is crucial to fully leverage and align with the prior knowledge about them. To do this, we design a generic framework that can automatically formulate inductive bias of generative models into textual prompts. Specifically, we have summarized three common inductive biases and designed their symbol-to-word one-on-one prompts P (Section 4.2). Our scheme can adaptively convert a user-provided inductive bias formulas F into a corresponding prompt P to provide more accurate explanations of the latent variables in Figure <ref type="figure" target="#fig_2">2</ref>(b) (Section 4.3). We decompose the inductive bias to guide the perturbation of ğ‘§ ğ‘– and subsequently decode the manipulated latent variables into generated data that are perceptible by humans such as images. Through a series of perturbations on ğ‘§ ğ‘– , a sequence of generated data samples can be obtained to reflect the changes in ğ‘§ ğ‘– in Figure <ref type="figure" target="#fig_2">2</ref>(a) (Section 4.4). Eventually, the explanations are selected through an uncertainty quantification approach to assess whether the latent variables are interpretable and select the most consistent explanations in Figure <ref type="figure" target="#fig_2">2</ref>(c) (Section 4.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Inductive-bias-guided Prompt Framework</head><p>4.2.1 Generic Framework. In this section, we propose a generic framework that can verbalize the inductive bias in deep generative models into prompts for better latent variable explanations. The prevalent inductive biases in deep generative models are categorized into three types: disentanglement bias, conditional bias, and combination bias.</p><p>Our framework proposes a principled, automatic way that translate the mathematical expression to textual prompts. The prompts include adaptive prompts and a fixed ending. The adaptive prompts  <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b39">40]</ref>. The formula representing this bias focuses on ensuring that different latent variables correspond to different independent underlying factors. Independent factors would be invariant with respect to one another <ref type="bibr" target="#b31">[32]</ref>. By disentangling these factors, researchers can better understand the underlying structure of the data and improve the model's performance on tasks such as representation learning.</p><p>Formula:</p><formula xml:id="formula_2">ğ‘ (ğ‘§ ğ‘– | ğ‘§ ğ‘– â€² = ğ›¼)=ğ‘ (ğ‘§ ğ‘– | ğ‘§ ğ‘– â€² = ğ›½), âˆ€ğ‘– â‰  ğ‘– â€² , ğ›¼ â‰  ğ›½.</formula><p>The above formula is translated into the following prompting using the grammar #1,2,7.</p><p>Prompt: These two rows of images show the same pattern of change despite other variations. <ref type="bibr" target="#b19">[20]</ref>. This bias is significant as it helps in identifying how combinations of factors contribute to the overall data generation process. Recognizing these interactions enables researchers to design models that can generate more complex and realistic data by capturing intricate relationships within the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">From Combination Bias to Prompts. Combination bias involves understanding how different latent variables interact within groups and remain independent across groups</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>â€¢ No inter-group correlation:</head><p>Formula:</p><formula xml:id="formula_3">ğ‘ ğ‘§ ğ‘– | ğ‘§ ğ‘— = ğ›¼ =ğ‘ ğ‘§ ğ‘– | ğ‘§ ğ‘— = ğ›½ , âˆ€ğ‘§ ğ‘– âˆˆğº, ğ‘§ ğ‘— âˆˆğº â€² , ğº â‰  ğº â€² , ğ›¼ â‰  ğ›½.</formula><p>The above formula is translated into the following prompting using the grammar #1,2,4,5,7.</p><p>Prompt: The pattern of change is associated with a group. The first two rows of images show the same pattern of change despite other variations in another group.</p><p>â€¢ Intra-group correlation:</p><formula xml:id="formula_4">Formula: ğ‘ (ğ‘§ ğ‘– | ğ‘§ ğ‘– â€² = ğ›¼) â‰ ğ‘ (ğ‘§ ğ‘– | ğ‘§ ğ‘– â€² = ğ›½) , âˆ€ğ‘§ ğ‘– , ğ‘§ â€² ğ‘– âˆˆğº, ğ‘– â‰  ğ‘– â€² , ğ›¼ â‰  ğ›½.</formula><p>The above formula is translated into the following prompting using the grammar #1,2,4,5,8.</p><p>Prompt: The pattern of change is associated with a group. The pattern of change in the last two rows of images should change given other variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.4</head><p>From Conditional Bias to Prompts. Conditional bias focuses on the relationship between specific properties of interest and the corresponding latent variables <ref type="bibr" target="#b37">[38]</ref>. This bias is important because it allows models to generate data conditioned on particular attributes, enhancing the model's ability to produce targeted and controlled outputs.</p><p>Formula:</p><formula xml:id="formula_5">ğ‘ (ğ‘§ ğ‘– | ğ‘ ğ‘˜ = ğ›¼)â‰ ğ‘ (ğ‘§ ğ‘– | ğ‘ ğ‘˜ = ğ›½), âˆ€ğ‘§ ğ‘– âˆˆğº ğ‘˜ , ğ›¼ â‰  ğ›½.</formula><p>The above formula is translated into the following prompting using the grammar #1,2,3,4,5,8.</p><p>Prompt: If the pattern of change is associated with the group of the property of interest, this image sequence will change as other variations in [property ğ‘˜ ].</p><p>There may exists a latent variable ğ‘§ ğ‘— that are independent of ğ‘ ğ‘˜ : Formula:</p><formula xml:id="formula_6">ğ‘ (ğ‘§ ğ‘— | ğ‘ ğ‘˜ = ğ›¼)=ğ‘ (ğ‘§ ğ‘— | ğ‘ ğ‘˜ = ğ›½), âˆ€ğ‘§ ğ‘— âˆ‰ğº ğ‘˜ , ğ›¼ â‰  ğ›½.</formula><p>The above formula is translated into the following prompting using the grammar #1,2,</p><p>Prompt: If the pattern of change is not associated with the group of the property of interest, this image sequence will remain constant despite other variations in [property ğ‘˜ ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Automatic In-context Prompt Generation</head><p>By leveraging these three common inductive biases identified in generative models, we can automatically generate prompts P that align with F within these three bias using in-context learning.</p><p>As Algorithm 1 shows, our approach starts by extracting mathematical symbols from the formula F using the ExtractSymbols function (line 4). This function traverses the formula to identify the mathematical symbols.</p><p>Next, the algorithm initializes an empty dictionary semantics to store the semantic representations of these symbols (line 5). For each symbol, the pre-trained LLM ğœ‹ ğœƒ extracts its semantic meaning based on few-shot examples H and the optional input symbol information I (lines 6-9).</p><p>Finally, the algorithm generates the prompt P using the formula F , the few-shot examples H , and the gathered semantics (line 10). This step-by-step reasoning process ensures that the generated prompts are contextually relevant and aligned with the underlying formulas, which could reduce hallucination and enhance model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Inductive-bias-guided Data Manipulation</head><p>First, identify the relevant formulas within the input inductive bias formulas with regard to a specific latent variable ğ‘§ ğ‘– to be explained. Then, combine the identified relevant formulas with the inductive Algorithm 1 The LatentExplainer Algorithm 1: Input: Inductive Bias Formula(s) F , Optional Information About the Symbol I return "No clear explanation" 25: end if bias prompt P obtained from Section 4.3 and utilize an LLM as a coding agent to generate prompts that specify the modifications needed in the generative model's decoder code (e.g., adjusting indices through the subscripts of the latent variables or adding properties according to extra information about the symbol I). The coding agent then tests and refines the generated code to effectively perturb ğ‘§ ğ‘– . Through a series of perturbations on ğ‘§ ğ‘– , a sequence of generated images can be obtained, capturing the variations in ğ‘§ ğ‘– and reflecting its influence on the generated data. Finally, all image sequences generated from the relevant formulas are aggregated to generate explanations about ğ‘§ ğ‘– . The implementation details are in Section 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Uncertainty-aware Explanations</head><p>Uncertainty-aware methods can be applied to large language model responses <ref type="bibr" target="#b23">[24]</ref> and image explanations <ref type="bibr" target="#b46">[47]</ref>. To measure the uncertainty of the responses from GPT-4o, we sampled ğ‘› times from the GPT-4o to generate the responses R = {ğ‘Ÿ 1 , ğ‘Ÿ 2 , ğ‘Ÿ 3 , ..., ğ‘Ÿ ğ‘› }. The certainty score of the explanation is the average pairwise cosine similarity of the responses R: 1/ğ¶ â€¢ ğ‘› ğ‘–=1 ğ‘› ğ‘—=1,ğ‘–â‰ ğ‘— sim(ğ‘Ÿ ğ‘– , ğ‘Ÿ ğ‘— ) where ğ¶ = ğ‘› â€¢ (ğ‘› -1). Our final explanation r is the response that has the highest pairwise cosine similarity with other responses if the latent variable is interpretable. Otherwise, r will be "No clear explanation". The implementation details are in Section 5.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>The experiments are conducted on a 64-bit machine with 24-core Intel 13th Gen Core i9-13900K @ 5.80GHz, 32GB memory and NVIDIA GeForce RTX 4090. We set GPT-4o at ğ‘¡ğ‘’ğ‘šğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ = 1 and ğ‘¡ğ‘œğ‘_ğ‘ = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>We utilized five datasets to evaluate the performance of different generative models under three inductive biases: CelebA-HQ <ref type="bibr" target="#b17">[18]</ref>, AFHQ <ref type="bibr" target="#b11">[12]</ref>, LSUN-Church <ref type="bibr" target="#b43">[44]</ref> for the unconditional and conditional diffusion models, and CelebA-HQ <ref type="bibr" target="#b17">[18]</ref>, 3DShapes <ref type="bibr" target="#b8">[9]</ref>, and dSprites <ref type="bibr" target="#b24">[25]</ref> for the VAE models. The CelebA-HQ dataset is a high-quality version of the CelebA dataset, consisting of 30K images of celebrities, divided into 28K for training and 2K for testing. The LSUN-Church dataset contains large-scale images of church buildings. The AFHQ dataset includes high-quality images of animals, divided into three categories: cats, dogs, and wild animals. 3DShapes is a synthetic dataset contains images of 3D shapes with six factors of variation: floor hue, wall hue, object hue, object scale, object shape, and wall orientation, divided into 384K for training and 96K for testing. dSprites consists of 2D shapes (hearts, squares, ellipses) generated with five factors of variation: shape, scale, orientation, position X, and position Y, divided into 516K for training and 221K for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Models and Baselines</head><p>Our evaluation benchmarks our proposed LatentExplainer framework against three state-of-the-art multimodal models with strong vision-language reasoning capabilities: GPT-4o <ref type="bibr" target="#b26">[27]</ref>, Gemini 1.5 Pro <ref type="bibr" target="#b35">[36]</ref>, and Claude 3.5 Sonnet <ref type="bibr" target="#b3">[4]</ref>. We employ GPT-4o, Gemini 1.5 Pro, and Claude 3.5 as a zero-shot baseline, comparing it with the addition of our Latent Exlainer with both the inductive bias prompt and uncertainty quantification included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Generative Models under Inductive Biases</head><p>We explore the latent space in generative models that satisfy the aforementioned three types of inductive biases. For each type, we present the relevant generative models that align with the corresponding inductive bias: (1) Disentanglement Bias: ğ›½-TCVAE <ref type="bibr" target="#b9">[10]</ref> explicitly penalizes the total correlation of the latent variables to disentangle the latent variables. Denoising Diffusion Probabilistic Model (DDPM) <ref type="bibr" target="#b15">[16]</ref> adds Gaussian noise independently at each timestep in the forward process and eventually transforms into pure Gaussian noise, in which the covariance matrix is diagonal. This assumes the latent factors are independent; (2) Combination Bias: CSVAE <ref type="bibr" target="#b19">[20]</ref> has two groups of latent variables ğ‘§ and ğ‘¤, where ğ‘§ and ğ‘¤ are uncorrelated and the latent variables within the group are correlated; (3) Conditional Bias: CSVAE also satisfies conditional bias because one group of latent variables ğ‘¤ is associated with the properties while the other group of latent variables ğ‘§ minimizes the mutual information with the properties. Stable Diffusion <ref type="bibr" target="#b32">[33]</ref> is a latent diffusion model to generate images conditioned on prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Latent Variable Perturbation Implementations</head><p>For VAE models, every time we target at each latent variable. The targeted latent variable is changed from -3 to 3, which is the 3   </p><formula xml:id="formula_8">â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ DDPM (Disentanglement Bias) Gemini 1.</formula><formula xml:id="formula_9">B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ ğ›½-TCVAE (Disentanglement Bias) Gemini 1.</formula><formula xml:id="formula_10">â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ DDPM (Disentanglement Bias)</formula><p>GPT-4o  </p><formula xml:id="formula_11">B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ B â†‘ R â†‘ S â†‘ BS â†‘ BAS â†‘ ğ›½-TCVAE (Disentanglement Bias)</formula><p>GPT-4o    The pattern of change in the first two rows is the background color changing progressively from green to yellow to red to purple while the shape remains a green rectangle.</p><p>The pattern in the first two rows of images shows a gradual transformation from a sphere to a cylinder and then to a cube, with consistent shapes and color tones. This pattern involves a change in the shape of the object.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Uncertainty-aware Implementations</head><p>We follow <ref type="bibr" target="#b48">[49]</ref> to denote the true label of the interpretability for the i-th latent variable ğ‘¦ ğ‘– as 1 if at least two of the three annotators can  see a clear pattern in the generated images, otherwise we denote it as 0. The certainty score of the explanation for the i-th latent variable is sğ‘– . We adopt the Jaccard Index to measure similarity between the predicted label and the true label, ğ¸ (ğœ€) = Jaccard(ğ‘“ (s ğ‘– , ğœ€), ğ‘¦ ğ‘– ), where</p><formula xml:id="formula_12">ğ‘“ (s ğ‘– , ğœ€) = 1(s ğ‘– â‰¥ ğœ€).</formula><p>The threshold is then selected as the one with the maximum similarity with the true label,</p><formula xml:id="formula_13">ğœ€ * = arg max ğœ€ ğ¸ (ğœ€).</formula><p>By solving this equation across all datasets, we find the threshold ğœ€ = 0.2617. Since ğœ€ is solved across all datasets, it reduces the dependence on any specific dataset. Our final output r is the response that has the highest mean pairwise cosine similarity with other responses if the certainty score is equal or greater than the threshold ğœ€. Otherwise, r will be "no clear explanation".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Human Annotaions</head><p>The ground-truth annotations of explanations are performed by three annotators from the United States and China. All annotators are students that had at least an undergraduate degree. Annotators were presented with the same images and the prompts as MLLMs and were asked to annotate the pattern of the images. If there is no clear pattern, just write "No clear explanation". The annotations are then aggregated as references to calculate the automated evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Quantitative Analysis</head><p>For the quantitative explanation evaluation, we use BLEU <ref type="bibr" target="#b27">[28]</ref>, ROUGE-L <ref type="bibr" target="#b22">[23]</ref>, SPICE <ref type="bibr" target="#b2">[3]</ref>, BERTScore <ref type="bibr" target="#b45">[46]</ref>, and BARTScore <ref type="bibr" target="#b44">[45]</ref> as the automated metrics to assess the generated explanations. BLEU, and ROUGE-L are n-gram-based metrics that measure the overlap between generated and reference texts. SPICE compares scene graphs derived from the generated and reference texts. BERTScore and BARTScore utilize pre-trained transformer-based language models to compute contextual embeddings of the generated and reference texts. These metrics together provide a comprehensive assessment of both the lexical and semantic quality of the explanations.</p><p>We evaluate the performance of Gemini 1.5 Pro, Claude 3.5 Sonnet and GPT-4o across all diffusion and vae models and datasets. Our proposed LatentExlainer method is a model-agnostic module and the inclusion of LatentExplainer consistently leads to substantial performance improvements on all MLLMs -Gemini 1.5 Pro, Claude 3.5 Sonnet and GPT-4o. Across diffusion-based models in Table <ref type="table" target="#tab_1">2</ref>, LatentExplainer delivers significant improvements across all datasets and metrics. Notably, when integrated with GPT-4o on CelebA-HQ, BLEU improves from 5. For VAE-based models in Table <ref type="table" target="#tab_3">3</ref>, LatentExplainer achieves even more striking gains. On the ğ›½-TCVAE model with GPT-4o, performance on 3DShapes sees BLEU increase from 5.51 to 25.40, and SPICE from 7.92 to 22.78. Across dSprites, the BLEU jump from 0.00 to 12.55 and ROUGE-L from 16.19 to 37.30 further demonstrate the utility of our approach. In summary, LatentExplainer consistently boosts the interpretability and textual quality of explanations for latent variable models across settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Ablation Study</head><p>To understand the impact of various components in our proposed LatentExplainer, we conducted a comprehensive ablation study on GPT-4o across different models (DDPM, ğ›½-TCVAE, Stable Diffusion, and CSVAE) and inductive biases (disentanglement, combination, and conditional). Specifically, we compare the removal of inductive bias prompts (IB), the removal of uncertainty quantification (UQ), and the full model against the baseline GPT-4o. The results for each dataset are provided in Table <ref type="table" target="#tab_4">4</ref> and Table <ref type="table" target="#tab_6">5</ref>. Removing inductive bias prompts leads to a substantial drop in all generative models. Their consistent results demonstrate that inductive bias is the most important and necessary component when explaining the latent variables of generative models. The removal of uncertainty quantification also results in a slightly decreased performance in all generative models, indicating that uncertainty quantification is also effective, though not as critical as inductive bias prompts. The full model, which incorporates both inductive bias prompts and uncertainty quantification, achieves the highest overall performance, and outperforms all baselines across all models. This confirms the necessity of both inductive bias prompts and uncertainty quantification in our LatentExplainer framework, demonstrating their significant contributions to improving explanatory performance across various generative models. It also shows that our framework can effectively design prompts for different inductive biases in generative models to improve the accuracy and reduce hallucination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Qualitative Evaluation</head><p>To analyze the explanations for DDPM under disentanglement bias, we manipulate the latent variable along a latent direction and compare it with the one that first traverses along another latent direction and then traverses along the same latent direction. The disentangled latent variable would be invariant with respect to the variations in another latent dimension. In Figure <ref type="figure">3</ref>, for each latent direction, we pass two image sequences and an inductive bias prompt based on the disentanglement formula to the MLLM to obtain a common latent explanation. In comparison, the explanations generated without the inductive bias prompt as shown in Figure <ref type="figure" target="#fig_4">4</ref> tend to show "no clear explanation" or wrong explanations as they only align with one image sequence but do not reflect the common pattern in both image sequences in view of the inductive bias. The addition of the inductive bias prompts can assist with ruling out the variation effects of other latent variables to capture the actual meaning.</p><p>We also qualitatively evaluate the explanations for CSVAE under combination bias. We transverse a latent variable and compare it with the one that first traverses another latent variable in another group and then traverses the same latent variable, which is similar to the disentanglement bias. We then compare with the one that first transverses another latent variable in the same group and then traverses the same latent variable. As Figure <ref type="figure" target="#fig_7">5</ref> depicts, our model can clearly show the explanations of latent variable ğ‘§ 1 , ğ‘§ 2 , ğ‘§ 3 as the color of the ground, the background color, and the shape of the object. The effect of removing inductive bias prompts leads to no clear explanation like the disentanglement bias in Figure <ref type="figure" target="#fig_8">6</ref>.</p><p>In Figure <ref type="figure" target="#fig_10">7</ref>, we provide the "young appearance" prompt to Stable Diffusion under conditional bias, and the explanations of all three top latent directions reflect the meaning of youth. The addition of inductive bias prompts can better identify the relation with the property of interest to capture the actual meaning of latent variables. In comparison, the one without the inductive bias prompts in Figure <ref type="figure" target="#fig_11">8</ref>, cannot find clear explanations or simply describe the characteristics in the image sequence, lacking an abstract generalization. More qualitative evaluation results can be found in Figure <ref type="figure" target="#fig_13">9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduced LatentExplainer, a framework designed to generate semantically meaningful explanations of latent variables in deep generative models. Our work makes three key contributions: (1) Inferring the meaning of latent variables by translating inductive bias formulas into structured perturbations of latent variables through a coding agent; (2) Aligning explanations with inductive biases by converting mathematical formulations into textual prompts in MLLMs; (3) Introducing an uncertainty-aware approach that assesses explanation consistency. Quantitative and qualitative evaluations across multiple datasets and generative models demonstrate that LatentExplainer significantly outperforms baseline methods. The incorporation of inductive bias prompts leads to more structured and meaningful explanations, while uncertainty-aware filtering further enhances consistency and reliability. Our findings highlight the importance of inductive bias prompting and uncertainty quantification in bridging the gap between generative models and human interpretability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">GenAI Usage Disclosure</head><p>We used generative AI tools to improve the grammar and clarity of the writing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of how a pretrained generative model, guided by inductive bias formulas, automatically decodes and interprets meaningful latent dimension semantics.</figDesc><graphic coords="2,54.00,86.73,241.69,175.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The overview of our proposed framework LatentExplainer (a) Inductive-bias-guided Data Manipulation generates image sequences by manipulating latent variables with predefined biases; (b) Automatic Prompt Generation with symbol-to-word mapping uses these images and formulas to create prompts for an MLLM to produce explanations; (c) Uncertainty-aware Explanation Generation evaluates multiple responses from the MLLM, selecting the most consistent explanation with a certainty score.</figDesc><graphic coords="3,32.10,96.80,106.41,106.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>6 Figure 3 :</head><label>63</label><figDesc>Figure 3: Visualization of the generated explanations with the inductive bias prompt for the disentanglement bias.</figDesc><graphic coords="7,53.80,268.98,246.99,108.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Visualization of the generated explanations w/o the inductive bias prompt for the disentanglement bias.</figDesc><graphic coords="7,311.04,280.58,247.09,84.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>+</head><label></label><figDesc>Inductive Bias Prompt Inductive Bias Math Formula Ã  Inductive Bias Prompt: The pattern of change is associated with a group. The first two rows of images show the same pattern of change despite other variations in another group. The pattern of change in the last two rows of images should change given other variations. What is the previous pattern of change? Write in a sentence. If there is no clear pattern, just write "No clear explanation".MLLMThe pattern of change in the first two rows shows a change in the color of the ground from green to magenta.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Visualization of the generated explanations with the inductive bias prompt for the combination bias.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Visualization of the generated explanations without the inductive bias prompt for the combination bias.</figDesc><graphic coords="7,311.04,423.56,247.16,158.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>z i is determined by decomposing the inductive bias formulas.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Visualization of the generated explanations with the inductive bias prompt for the conditional bias.</figDesc><graphic coords="8,53.80,83.82,247.13,102.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Visualization of the generated explanations without the inductive bias prompt for the conditional bias.</figDesc><graphic coords="8,311.05,87.99,246.97,96.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>79 to 18.50, ROUGE-L from 23.89 to 40.85, and SPICE from 12.68 to 23.90, highlighting nearly 2x gains. Similar trends are observed with Claude 3.5 Sonnet for DDPM, where BLEU on AFHQ increases from 4.16 to 12.52, and ROUGE-L rises from 22.25 to 31.68, and SPICE from 13.34 to 20.05. Even for weaker baselines like Gemini 1.5 Pro, LatentExplainer consistently improves both lexical and semantic quality, demonstrating its effectiveness in enhancing explainability for latent variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Example of generated explanations for DDPM under the disentanglement bias.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Lookup table for symbol-to-word mapping. the inductive bias formulas. The formulas contain mathematical symbols that consist of mathematical variables and mathematical operators. We use the same color to represent the correspondence between mathematical symbols in the formulas and the text in the prompts. The translation mechanism of adaptive prompts is shown in Table1. Fixed Ending: What is the pattern of change? Write in a sentence. If there is no clear pattern, just write "No clear explanation".</figDesc><table><row><cell>Grammar #</cell><cell>Symbol</cell><cell>Prompt</cell></row><row><cell>1</cell><cell>ğ‘(ğ‘§ ğ‘– | â€¢)</cell><cell>pattern of change</cell></row><row><cell>2</cell><cell cols="2">ğ‘ (ğ‘§ ğ‘– |ğ‘§ ğ‘– â€² ), âˆ€ğ‘– â‰  ğ‘– â€² other variations</cell></row><row><cell>3</cell><cell>ğ‘ ğ‘˜</cell><cell>property of interests</cell></row><row><cell>4</cell><cell>ğº</cell><cell>a group</cell></row><row><cell>5</cell><cell>âˆˆ</cell><cell>associated with</cell></row><row><cell>6</cell><cell>âˆ‰</cell><cell>not associated with</cell></row><row><cell>7</cell><cell>=</cell><cell>same</cell></row><row><cell>8</cell><cell>â‰ </cell><cell>change</cell></row><row><cell cols="2">are converted from</cell><cell></cell></row></table><note><p>4.2.2 From Disentanglement Bias to Prompts. Disentanglement bias refers to the model's ability to separate independent factors in the data</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>2 :</head><label>2</label><figDesc>Require: Few-Shot Examples H , Pre-trained LLM ğœ‹ ğœƒ , Pretrained MLLM ğœ‹ ğœƒ â€² , Generative Model Decoder G ğ‘Ÿ ğ‘– â† ğœ‹ ğœƒ â€² (ğ· ğ‘– , P) ğ‘  ğ‘– = 1 ğ‘›-1 ğ‘–â‰ ğ‘— SIM(ğ‘Ÿ ğ‘– , ğ‘Ÿ ğ‘— ) 19: ğ‘  = ğ‘–â‰ ğ‘— SIM(ğ‘Ÿ ğ‘– , ğ‘Ÿ ğ‘— ) âŠ² Compute certainty score 20: r â† arg max ğ‘Ÿ ğ‘– âˆˆ R ğ‘  ğ‘– 21: if ğ‘  â‰¥ ğœ– then</figDesc><table><row><cell cols="4">3: Output: Final Explanation</cell><cell>r</cell></row><row><cell cols="4">4: symbols â† EXTRACTSYMBOLS(F )</cell></row><row><cell cols="3">5: semantics â† âˆ…</cell></row><row><cell cols="4">6: for symbol in symbols do</cell></row><row><cell>7:</cell><cell cols="3">semantic â† ğœ‹ ğœƒ (symbol, H, I)</cell></row><row><cell>8:</cell><cell cols="3">semantics[symbol] â† semantic</cell></row><row><cell cols="2">9: end for</cell><cell></cell></row><row><cell cols="4">10: P = ğœ‹ ğœƒ (F , H, semantics)</cell><cell>âŠ² Generate inductive bias prompt</cell></row><row><cell cols="4">11: z â† MANIPULATELATENT(ğ‘§, F , P)</cell><cell>âŠ² Latent variable</cell></row><row><cell></cell><cell>perturbation</cell><cell></cell></row><row><cell cols="2">12: ğ· ğ‘– â† G( z)</cell><cell></cell><cell>âŠ² Generate image sequence</cell></row><row><cell cols="2">13: R â† âˆ…</cell><cell></cell><cell>âŠ² Initialize explanation set</cell></row><row><cell cols="3">14: for ğ‘– = 1 to ğ‘› do</cell></row><row><cell>15:</cell><cell></cell><cell></cell></row><row><cell>16:</cell><cell cols="2">R â† R âˆª {ğ‘Ÿ ğ‘– }</cell></row><row><cell cols="2">17: end for</cell><cell></cell></row><row><cell cols="2">18: 1</cell><cell>ğ‘›</cell><cell>ğ‘›</cell></row><row><cell cols="4">ğ‘›â€¢ (ğ‘›-1) ğ‘—=1,22: ğ‘–=1 return r</cell></row><row><cell cols="2">23: else</cell><cell></cell></row><row><cell>24:</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Quantitative results for diffusion models across datasets. B represents BLEU@4, R represents ROUGE-L, S represents SPICE, BS represents BERTScore, and BAS represents BARTScore.</figDesc><table><row><cell>Model</cell><cell>Method</cell><cell>AFHQ</cell><cell>LSUN-Church</cell><cell>CelebA-HQ</cell></row><row><cell></cell><cell>B</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>LatentExplainer 13.27 29.98 20.08 90.17 -3.19 18.33 38.14 25.01 90.99 -3.23 18.50 40.85 23.90 91.75 -2.82 Quantitative results for VAE models across datasets. B represents BLEU@4, R represents ROUGE-L, S represents SPICE, BS represents BERTScore, and BAS represents BARTScore.</figDesc><table><row><cell></cell><cell>5 Pro</cell><cell>2.87 23.18 11.46 88.27 -3.35</cell><cell>1.64 20.75 6.92 87.22 -3.51</cell><cell cols="3">1.80 22.18 8.45 87.96 -3.11</cell></row><row><cell></cell><cell>+ LatentExplainer</cell><cell>3.15 25.62 13.36 88.63 -3.30</cell><cell>5.71 26.71 10.31 87.95 -3.46</cell><cell cols="3">4.97 26.74 9.64 88.72 -3.08</cell></row><row><cell></cell><cell>Claude 3.5 Sonnet</cell><cell>4.16 22.25 13.34 88.02 -3.28</cell><cell>7.76 28.02 14.14 88.65 -3.36</cell><cell cols="3">8.05 25.60 12.11 88.46 -3.10</cell></row><row><cell></cell><cell cols="6">+ LatentExplainer 12.52 31.68 20.05 89.75 -3.06 12.92 32.55 19.52 89.70 -3.23 14.14 34.07 14.80 90.06 -2.94</cell></row><row><cell></cell><cell>GPT-4o</cell><cell>3.08 14.83 8.78 87.55 -3.39</cell><cell>5.52 23.06 11.23 88.47 -3.41</cell><cell>0.11</cell><cell>3.54</cell><cell>1.22 85.97 -3.16</cell></row><row><cell></cell><cell cols="6">+ LatentExplainer 25.91 37.84 29.87 91.48 -2.97 30.92 44.21 29.23 91.80 -3.06 18.49 35.27 18.81 90.30 -2.90</cell></row><row><cell></cell><cell>Gemini 1.5 Pro</cell><cell>0.00 20.36 10.95 88.74 -3.34</cell><cell>0.00 20.24 8.98 88.08 -3.56</cell><cell cols="3">0.00 18.93 7.48 87.83 -3.16</cell></row><row><cell></cell><cell cols="2">+ LatentExplainer 3.29 21.52 15.21 89.09 -3.29</cell><cell>0.00 21.49 9.57 88.09 -3.53</cell><cell cols="3">1.89 21.22 8.60 88.01 -3.09</cell></row><row><cell>Stable Diffusion (Conditional Bias)</cell><cell>Claude 3.5 Sonnet + LatentExplainer</cell><cell>6.57 30.62 17.80 89.53 -3.31 7.69 31.84 18.27 89.85 -3.28</cell><cell>2.37 26.95 13.10 88.74 -3.55 2.69 28.88 14.14 89.01 -3.46</cell><cell cols="3">4.69 26.76 13.52 89.27 -3.15 4.02 28.68 15.22 89.61 -3.08</cell></row><row><cell></cell><cell>GPT-4o</cell><cell>7.61 26.32 17.19 90.04 -3.32</cell><cell>7.80 26.73 14.28 89.44 -3.46</cell><cell cols="3">5.79 23.89 12.68 89.63 -3.04</cell></row><row><cell cols="2">+ Model Method</cell><cell>3DShapes</cell><cell>CelebA-HQ</cell><cell></cell><cell></cell><cell>dSprites</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>LatentExplainer 18.09 33.69 14.26 89.36 -2.92 12.73 33.27 11.21 89.50 -3.05 12.20 35.87 19.29 90.58 -2.95 LatentExplainer 25.40 49.06 22.78 91.90 -2.75 29.93 55.68 30.17 93.55 -2.77 12.55 37.30 21.69 90.28 -2.87 LatentExplainer 25.71 40.00 20.67 90.88 -2.79 24.21 42.88 19.61 91.21 -2.79 21.17 34.99 20.71 89.49 -3.08 Ablation results for diffusion models across datasets on GPT-4o. B represents BLEU@4, R represents ROUGE-L, S represents SPICE, BS represents BERTScore, and BAS represents BARTScore.</figDesc><table><row><cell></cell><cell>5 Pro</cell><cell>2.73 26.45 5.56 88.83 -3.15</cell><cell>0.00 17.28 4.86 87.00 -3.27</cell><cell cols="3">0.00 15.39 6.11 86.61 -3.25</cell></row><row><cell></cell><cell cols="2">+ LatentExplainer 3.11 28.98 8.07 88.94 -3.14</cell><cell>2.19 31.21 10.70 88.98 -3.18</cell><cell cols="3">1.54 17.29 7.61 86.98 -3.22</cell></row><row><cell></cell><cell>Claude 3.5 Sonnet</cell><cell>11.02 30.95 14.13 89.11 -3.01</cell><cell>9.54 30.96 11.11 88.76 -3.14</cell><cell cols="3">3.65 22.32 11.91 88.49 -3.05</cell></row><row><cell></cell><cell>+ GPT-4o</cell><cell cols="2">5.51 29.77 7.92 89.18 -3.13 11.09 37.14 17.24 90.55 -3.07</cell><cell cols="3">0.00 16.19 7.04 87.17 -3.22</cell></row><row><cell cols="7">Gemini 1.5 Pro + LatentExplainer 6.22 25.59 5.69 88.98 -2.97 3.11 22.14 5.39 88.33 -2.99 + CSVAE Claude 3.5 Sonnet 4.55 24.30 9.14 87.08 -3.01 (Combination Bias) + LatentExplainer 15.24 25.57 19.82 88.72 -2.87 19.92 28.85 18.97 89.55 -2.97 17.75 30.87 22.14 89.58 -2.94 1.21 16.52 5.28 88.25 -3.21 1.18 23.15 5.83 88.24 -3.15 3.88 24.17 7.94 88.72 -3.21 1.33 26.43 5.88 89.18 -3.08 9.43 28.77 18.31 89.50 -3.11 7.04 24.16 14.27 88.45 -3.08</cell></row><row><cell></cell><cell>GPT-4o</cell><cell cols="2">6.93 25.07 9.70 89.42 -2.87 10.44 37.42 15.06 90.53 -3.01</cell><cell cols="3">0.00 21.61 6.99 87.19 -3.17</cell></row><row><cell></cell><cell cols="6">+ LatentExplainer 36.18 43.58 36.75 91.72 -2.52 25.34 45.18 26.96 92.09 -2.81 16.03 35.85 21.82 90.05 -2.90</cell></row><row><cell></cell><cell>Gemini 1.5 Pro</cell><cell>8.61 26.41 7.11 87.95 -3.20</cell><cell>3.48 19.77 10.41 87.92 -3.12</cell><cell cols="3">0.00 17.27 8.65 86.80 -3.30</cell></row><row><cell></cell><cell cols="2">+ LatentExplainer 12.12 35.80 9.38 90.14 -3.08</cell><cell>3.63 21.26 10.65 87.95 -3.05</cell><cell cols="3">2.62 22.99 10.53 88.26 -3.18</cell></row><row><cell>CSVAE (Conditional Bias)</cell><cell cols="3">Claude 3.5 Sonnet + LatentExplainer 8.42 31.32 18.34 88.82 -2.93 14.53 34.54 19.58 90.70 -2.90 5.36 26.69 15.28 88.75 -3.04 13.83 34.38 18.15 90.36 -2.98</cell><cell cols="3">8.16 25.09 17.70 88.18 -3.11 8.42 27.99 17.94 88.34 -3.04</cell></row><row><cell></cell><cell>GPT-4o</cell><cell>10.97 30.55 8.83 90.10 -3.02</cell><cell>8.46 28.78 15.78 89.62 -2.98</cell><cell>0.00</cell><cell>9.62</cell><cell>1.03 85.74 -3.34</cell></row><row><cell cols="2">+ Model Method</cell><cell>AFHQ</cell><cell>LSUN-Church</cell><cell></cell><cell></cell><cell>CelebA-HQ</cell></row><row><cell></cell><cell></cell><cell>B</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>UQ 12.36 27.73 20.01 90.03 -3.18 17.19 35.33 21.76 90.73 -3.31 15.01 35.43 23.99 91.07 -2.87 + LatentExplainer 13.27 29.98 20.08 90.17 -3.19 18.33 38.14 25.01 90.99 -3.23 18.50 40.85 23.90 91.75 -2.82</figDesc><table><row><cell></cell><cell></cell><cell>3.08 14.83 8.78 87.55 -3.39</cell><cell>5.52 23.06 11.23 88.47 -3.41</cell><cell>0.11</cell><cell>3.54</cell><cell>1.22 85.97 -3.16</cell></row><row><cell></cell><cell>+ LatentExplainer w/o IB</cell><cell>2.14 11.49 7.82 87.17 -3.41</cell><cell>8.78 27.01 14.08 88.85 -3.37</cell><cell>0.19</cell><cell>4.17</cell><cell>1.80 85.88 -3.16</cell></row><row><cell></cell><cell cols="6">+ LatentExplainer w/o UQ 16.12 31.57 21.70 89.99 -3.12 21.19 37.03 23.65 90.49 -3.19 13.11 27.38 14.03 89.15 -2.92</cell></row><row><cell></cell><cell>+ LatentExplainer</cell><cell cols="5">25.91 37.84 29.87 91.48 -2.97 30.92 44.21 29.23 91.80 -3.06 18.49 35.27 18.81 90.30 -2.90</cell></row><row><cell></cell><cell>GPT-4o</cell><cell>7.61 26.32 17.19 90.04 -3.32</cell><cell>7.80 26.73 14.28 89.44 -3.46</cell><cell cols="3">5.79 23.89 12.68 89.63 -3.04</cell></row><row><cell>Stable Diffusion</cell><cell>+ LatentExplainer w/o IB</cell><cell cols="2">9.12 26.59 16.28 89.77 -3.29 10.07 28.31 15.85 89.92 -3.42</cell><cell cols="3">5.87 24.06 12.17 89.15 -3.05</cell></row><row><cell>(Conditional Bias)</cell><cell>+ LatentExplainer w/o</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Ablation results for VAE models across datasets on GPT-4o. B represents BLEU@4, R represents ROUGE-L, S represents SPICE, BS represents BERTScore, and BAS represents BARTScore.</figDesc><table><row><cell>Model</cell><cell>Method</cell><cell>3DShapes</cell><cell>CelebA-HQ</cell><cell>dSprites</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>5.51 29.77 7.92 89.18 -3.13 11.09 37.14 17.24 90.55 -3.07 0.00 16.19 7.04 87.17 -3.22 + LatentExplainer w/o IB 5.41 31.66 10.07 89.44 -3.13 6.14 32.73 14.04 89.92 -3.11 0.00 18.73 7.54 87.42 -3.20 + LatentExplainer w/o UQ 16.99 37.37 22.89 90.83 -2.80 21.95 48.84 22.60 92.09 -2.88 17.16 37.19 22.40 90.18 -2.89 + LatentExplainer 25.40 49.06 22.78 91.90 -2.75 29.93 55.68 30.17 93.55 -2.77 12.55 37.30 21.69 90.28 -2.87 .07 9.70 89.42 -2.87 10.44 37.42 15.06 90.53 -3.01 0.00 21.61 6.99 87.19 -3.17 + LatentExplainer w/o IB 14.22 28.57 11.79 90.02 -2.85 11.96 37.02 17.49 90.50 -3.01 0.00 16.36 7.26 86.96 -3.24 + LatentExplainer w/o UQ 34.55 39.62 30.30 90.83 -2.62 14.08 38.68 22.49 91.11 -2.87 0.00 28.49 15.65 89.78 -2.91 + LatentExplainer 36.18 43.58 36.75 91.72 -2.52 25.34 45.18 26.96 92.09 -2.81 16.03 35.85 21.82 90.05 -2.90 IB 19.28 39.90 15.74 90.87 -2.88 8.35 28.75 12.11 89.60 -2.97 0.00 11.38 5.26 86.47 -3.29 + LatentExplainer w/o UQ 16.73 32.28 16.19 89.84 -2.86 13.35 37.20 20.05 89.89 -2.92 5.39 19.20 6.36 86.94 -3.26 + LatentExplainer 25.71 40.00 20.67 90.88 -2.79 24.21 42.88 19.61 91.21 -2.79 21.17 34.99 20.71 89.49 -3.08</figDesc><table><row><cell>CSVAE (Combination Bias) 6.93 25CSVAE GPT-4o GPT-4o 10.97 30.55 8.83 90.10 -3.02 + LatentExplainer w/o</cell><cell>8.46 28.78 15.78 89.62 -2.98</cell><cell>0.00</cell><cell>9.62</cell><cell>1.03 85.74 -3.34</cell></row><row><cell>(Conditional Bias)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">National Science Foundation (NSF)</rs> Grant No. <rs type="grantNumber">2414115</rs>, No. <rs type="grantNumber">2403312</rs>, No. <rs type="grantNumber">2007716</rs>, No. <rs type="grantNumber">2007976</rs>, No. <rs type="grantNumber">1942594</rs>, No. <rs type="grantNumber">1907805</rs>, <rs type="grantNumber">NIH R01AG089806</rs>, and <rs type="funder">NIH</rs> <rs type="grantNumber">R01CA297856</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BRkQ8AR">
					<idno type="grant-number">2414115</idno>
				</org>
				<org type="funding" xml:id="_PkpwdSE">
					<idno type="grant-number">2403312</idno>
				</org>
				<org type="funding" xml:id="_U7ayDRa">
					<idno type="grant-number">2007716</idno>
				</org>
				<org type="funding" xml:id="_MH2G595">
					<idno type="grant-number">2007976</idno>
				</org>
				<org type="funding" xml:id="_GWVX3cK">
					<idno type="grant-number">1942594</idno>
				</org>
				<org type="funding" xml:id="_ZZJu5Wv">
					<idno type="grant-number">1907805</idno>
				</org>
				<org type="funding" xml:id="_R5HJGnU">
					<idno type="grant-number">NIH R01AG089806</idno>
				</org>
				<org type="funding" xml:id="_YGt5K5T">
					<idno type="grant-number">R01CA297856</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Peeking inside the black-box: a survey on explainable artificial intelligence (XAI)</title>
		<author>
			<persName><forename type="first">Amina</forename><surname>Adadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Berrada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="52138" to="52160" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Variational Autoencoder based Anomaly Detection using Reconstruction Probability</title>
		<author>
			<persName><forename type="first">Jinwon</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungzoon</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Special Lecture on IE</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spice: Semantic propositional image caption evaluation</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2016: 14th European Conference</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016-10-11">2016. October 11-14, 2016</date>
			<biblScope unit="page" from="382" to="398" />
		</imprint>
	</monogr>
	<note>Proceedings, Part V 14</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><surname>Anthropic</surname></persName>
		</author>
		<ptr target="https://www.anthropic.com/news/claude-3-5-sonnet" />
		<title level="m">Claude 3.5 Sonnet</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chih-Kuan</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cho-Jui</forename><surname>Neil Yc Lin</surname></persName>
		</author>
		<author>
			<persName><surname>Hsieh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.14966</idno>
		<title level="m">Concept gradient: Concept-based interpretation without linear assumption</title>
		<imprint>
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Beyond efficiency: A systematic survey of resource-efficient large language models</title>
		<author>
			<persName><forename type="first">Guangji</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaying</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tingwei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.00625</idno>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-level variational autoencoder: Learning disentangled representations from grouped observations</title>
		<author>
			<persName><forename type="first">Diane</forename><surname>Bouchacourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural Photo Editing with Introspective Adversarial Networks</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theodore</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">M</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Chris</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="https://github.com/deepmind/3dshapes-dataset/" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">3D Shapes Dataset</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Isolating sources of disentanglement in variational autoencoders</title>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Ricky Tq Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03657</idno>
		<title level="m">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stargan v2: Diverse image synthesis for multiple domains</title>
		<author>
			<persName><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngjung</forename><surname>Uh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaejun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8188" to="8197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Guided variational autoencoder for disentanglement learning</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7920" to="7929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A disentangling invertible interpretation network for explaining latent representations</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9223" to="9232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Going beyond xai: A systematic survey for explanation-guided learning</title>
		<author>
			<persName><forename type="first">Yuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyi</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junji</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Sungsoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dazhou</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Surveys</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11239</idno>
		<title level="m">Denoising Diffusion Probabilistic Models</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cascaded diffusion models for high fidelity image generation</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Progressive Growing of GANs for Improved Quality, Stability, and Variation</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Auto-Encoding Variational Bayes. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning latent subspaces in variational autoencoders</title>
		<author>
			<persName><forename type="first">Jack</forename><surname>Klys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Concept bottleneck models</title>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thao</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siang</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Mussmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Been</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5338" to="5348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09761</idno>
		<title level="m">DiffWave: A Versatile Diffusion Model for Audio Synthesis</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubhendu</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.19187</idno>
		<title level="m">Generating with confidence: Uncertainty quantification for black-box large language models</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">Loic</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
		<ptr target="https://github.com/deepmind/dsprites-dataset/" />
		<title level="m">Disentanglement testing Sprites dataset</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.10741</idno>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<ptr target="https://openai.com/index/hello-gpt-4o/" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding the latent space of diffusion models through the lens of riemannian geometry</title>
		<author>
			<persName><forename type="first">Yong-Hyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingi</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoong</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junghyo</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngjung</forename><surname>Uh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="24129" to="24142" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Eleonora</forename><surname>Poeta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Ciravegna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliana</forename><surname>Pastor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tania</forename><surname>Cerquitelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Baralis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2312.12936</idno>
		<title level="m">Concept-based explainable artificial intelligence: A survey</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
		<title level="m">Stochastic Backpropagation and Approximate Inference in Deep Generative Models</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A survey of inductive biases for factorial representationlearning</title>
		<author>
			<persName><forename type="first">Karl</forename><surname>Ridgeway</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.05299</idno>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">BjÃ¶rn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Explaining deep neural networks: A survey on the global interpretation methods</title>
		<author>
			<persName><forename type="first">Rabia</forename><surname>Saleem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fatih</forename><surname>Kurugollu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashiq</forename><surname>Anjum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">513</biblScope>
			<biblScope unit="page" from="165" to="180" />
			<date type="published" when="2022">2022. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Interpreting the latent space of gans for semantic face editing</title>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinjin</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9243" to="9252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Gemini</forename><surname>Team</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petko</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Ving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Libin</forename><surname>Burnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anmol</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrett</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><surname>Tanzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhufeng</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shibo</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.05530</idno>
		<title level="m">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised causal binary concepts discovery with VAE for black-box model explanation</title>
		<author>
			<persName><forename type="first">Kazuto</forename><surname>Thien Q Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youhei</forename><surname>Fukuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Akimoto</surname></persName>
		</author>
		<author>
			<persName><surname>Sakuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="9614" to="9622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Controllable data generation by deep learning: A review</title>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanqi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojie</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaohui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Surveys</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Changlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ananth</forename><surname>Grama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Szpankowski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.19217</idno>
		<title level="m">No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Uncovering the disentanglement capability in text-to-image diffusion models</title>
		<author>
			<persName><forename type="first">Qiucheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Handong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajinkya</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trung</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1900" to="1910" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attribute2Image: Conditional Image Generation from Visual Attributes</title>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="776" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Diffusion probabilistic modeling for video generation</title>
		<author>
			<persName><forename type="first">Ruihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakhar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Mandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">1469</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Shukang</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaoyou</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sirui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.13549</idno>
		<title level="m">A survey on multimodal large language models</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop</title>
		<author>
			<persName><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Bartscore: Evaluating generated text as text generation</title>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="27263" to="27277" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09675</idno>
		<title level="m">Bertscore: Evaluating text generation with bert</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">Qilong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyi</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.10831</idno>
		<title level="m">DUE: Dynamic Uncertainty-Aware Explanation Supervision via 3D Imputation</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Generative Visual Manipulation on the Natural Image Manifold</title>
		<author>
			<persName><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>KrÃ¤henbÃ¼hl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Explaining latent representations of generative models with large multimodal models</title>
		<author>
			<persName><forename type="first">Mengdan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenke</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Angirekula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.01858</idno>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Naofumi Tomita, and Saeed Hassanpour. 2021. Development and evaluation of a deep neural network for histologic classification of renal cell carcinoma on biopsy and surgical resection slides</title>
		<author>
			<persName><forename type="first">Mengdan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryland</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Suriawinata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">7080</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
