<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EmpHi: Generating Empathetic Responses with Human-like Intents</title>
				<funder ref="#_FqdQ6Hs">
					<orgName type="full">Shenzhen Key Laboratory of Marine IntelliSense and Computation</orgName>
				</funder>
				<funder ref="#_8tB5yUQ">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_bqP7ZwT">
					<orgName type="full">Guangdong Basic and Applied Basic Research Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mao</forename><forename type="middle">Yan</forename><surname>Chen</surname></persName>
							<email>chenmaoy19@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen International Graduate School</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Siheng</forename><surname>Li</surname></persName>
							<email>lisiheng21@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen International Graduate School</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EmpHi: Generating Empathetic Responses with Human-like Intents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In empathetic conversations, humans express their empathy to others with empathetic intents. However, most existing empathetic conversational methods suffer from a lack of empathetic intents, which leads to monotonous empathy. To address the bias of the empathetic intents distribution between empathetic dialogue models and humans, we propose a novel model to generate empathetic responses with humanconsistent empathetic intents, EmpHi for short. Precisely, EmpHi learns the distribution of potential empathetic intents with a discrete latent variable, then combines both implicit and explicit intent representation to generate responses with various empathetic intents. Experiments show that EmpHi outperforms state-ofthe-art models in terms of empathy, relevance, and diversity on both automatic and human evaluation. Moreover, the case studies demonstrate the high interpretability and outstanding performance of our model. Our code are avaliable at <ref type="url" target="https://github.com/mattc95/EmpHi">https://github.com/mattc95/EmpHi</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Empathy is a basic yet essential human ability in our daily life. It is a capacity to show one's caring and understanding to others. Many types of research have been conducted on empathetic expression to enhance the empathy ability of Artificial Intelligence, e.g., computational approach for empathy measurement <ref type="bibr" target="#b16">(Sharma et al., 2020)</ref>, empathetic expression understanding in newswire <ref type="bibr" target="#b2">(Buechel et al., 2018)</ref>, online mental health support <ref type="bibr" target="#b15">(Sharma et al., 2021)</ref>, etc. In this work, we focus on the task of generating empathetic responses <ref type="bibr" target="#b14">(Rashkin et al., 2019;</ref><ref type="bibr" target="#b10">Lin et al., 2019;</ref><ref type="bibr" target="#b11">Majumder et al., 2020)</ref> in open-domain conversation.</p><p>Existing empathetic dialogue models pay more attention to the emotion-dependent response generation <ref type="bibr" target="#b10">(Lin et al., 2019;</ref><ref type="bibr" target="#b11">Majumder et al., 2020)</ref>.</p><p>I just started college again, and while I'm doing great in school, it has lead me to feel very lonely with a lack of social life.</p><p>I am sorry to hear that! I know I broke up with my ex, but I can't help but feel irritated when he talks about going on dates.</p><p>A while back my cat knocked over and broke my mother's urn.</p><p>Oh my goodness, I have a cat, I know how you feel.</p><p>I am sorry to hear that . I hope you find someone to help you.</p><p>That is so annoying. I would be upset too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledging</head><p>Sympathizing Agreeing</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EmpHi Output</head><p>Figure <ref type="figure">1</ref>: EmpHi generates empathetic responses with human-like empathetic intents (text in blue box), while existing empathetic dialogue models generate responses with contextually irrelevant and monotonous empathy (text in orange box).</p><p>However, using emotion alone to generate responses is coarse-grained, and the model needs to incorporate empathetic intent information. On the one hand, the speaker often talks with a particular emotion while the listener shows their empathy with specific empathetic intents, e.g., Acknowledging, Agreeing, Consoling and Questioning etc (Welivita and Pu, 2020). On the other hand, see in Figure <ref type="figure">1</ref>, when the user expresses sadness, existing models tend to generate sympathetic responses like "I'm sorry to hear that." However, empathy is not the same as sympathy, so the models should not only generate responses with Sympathizing intent.</p><p>We demonstrate this phenomenon elaborately with a quantitative evaluation in Section 2. In real life situation, humans could reply with various empathetic intents to the same context which depends on personal preference. For example, given a context, "I just failed my exam", an individual may respond "Oh no, what happened?" with Questioning intent to explore the experience of the user, or "I understand this feeling, know how you feel" with Agreeing intent. These types of empathy are more relevant, interactive, and diverse. To address the above issues, we propose a new framework to generate empathetic responses with human-like empathetic intents (EmpHi) which could generate responses with various empathetic intents, see examples in Figure <ref type="figure">1</ref>. Specifically, Em-pHi learns the empathetic intent distribution with a discrete latent variable and adopts intent representation learning in the training stage. During the generation process, EmpHi first predicts a potential empathetic intent and then combines both implicit and explicit intent representation to generate a response corresponding to the predicted intent. Our main contributions are:</p><p>‚Ä¢ We discover and quantify the severe bias of empathetic intents between existing empathetic dialogue models and humans. This finding will lead subsequent researchers to pay more attention to fine-grained empathetic intents.</p><p>‚Ä¢ To address the above problem, we propose EmpHi, which generates responses with human-like empathetic intents. Experiments have proved the effectiveness of our model through the significant improvement in both automatic and human evaluation.</p><p>‚Ä¢ According to the quantitative evaluation and analysis, EmpHi successfully captures humans' empathetic intent distribution, and shows high interpretability in generation process.  MIME, which mimics the speaker emotion to a varying degree. All these models focus on emotion-dependent empathetic response generation, whereas we pay more attention to the empathetic intents and propose to generate a response that is not only emotionally appropriate but also empathetically humanlike.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>One-to-many Response Generation. Given dialogue history, there could be various responses depends on personal preference. <ref type="bibr" target="#b20">Zhao et al. (2017)</ref> propose to learn the potential responses with continuous latent variable and maximize the loglikelihood using Stochastic Gradient Variational Bayes (SGVB) (Kingma and Welling, 2014). To further improve the interpretability of response generation, <ref type="bibr" target="#b19">Zhao et al. (2018)</ref> propose to capture potential sentence-level representations with discrete latent variables. MIME <ref type="bibr" target="#b11">(Majumder et al., 2020)</ref> introduces stochasticity into the emotion mixture for various empathetic responses generation.</p><p>Different from the previous works, we propose a discrete latent variable to control the empathetic intent of response and achieve intent-level diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Empathetic Expression Bias</head><p>Although existing empathetic conversational methods have shown promising progress, we reveal there is a severe bias of empathetic expression between them and humans according to quantitative evaluation.</p><p>Empathy plays a vital role in human conversation, Welivita and Pu (2020) make a taxonomy of empathetic intents and calculate the frequency of each intent in EmpatheticDialogues <ref type="bibr" target="#b14">(Rashkin et al., 2019)</ref>. As shown in Figure <ref type="figure" target="#fig_0">2</ref>, humans show  their empathy naturally by Questioning, Acknowledging, and Agreeing intents etc. However, there are no empirical experiments have shown how empathetic dialogue models express their empathy? To further study, we finetune a BERT classifier <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref> on the released EmpatheticIntents 1 dataset <ref type="bibr" target="#b17">(Welivita and Pu, 2020)</ref>. Our classifier achieves 87.75% accuracy in intent classification and we apply it to identify the empathetic intents of responses generated by the state-of-the-art empathetic dialogue model MIME <ref type="bibr" target="#b11">(Majumder et al., 2020)</ref>. As shown in Figure <ref type="figure" target="#fig_2">4</ref>, the severe empathetic intent distribution bias emerges while comparing humans to MIME. Given context with sad emotion, existing models usually generate "I am sorry to hear that" with Sympathiz-ing intent, which is not human-like and contextually relevant. In addition, we can tell that the empathetic expression of MIME is monotonous. We also quantify the intent distribution of other empathetic dialogue models in the Appendix A. The results are similar to Figure <ref type="figure" target="#fig_2">4</ref>.</p><p>We believe this phenomenon is caused by that existing models only generate responses according to context emotion and lack fine-grained empathetic intent modeling. Therefore, we propose EmpHi, which generates empathetic responses with humanlike empathetic intents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EmpHi Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task Definition and Overview</head><formula xml:id="formula_0">Given the context, C = [c 1 , c 2 , ‚Ä¢ ‚Ä¢ ‚Ä¢ , c m ],</formula><p>which consists of m words for single or multiple utterances. We aim to generate empathetic response,</p><formula xml:id="formula_1">X = [x 1 , x 2 , ‚Ä¢ ‚Ä¢ ‚Ä¢ , x n ],</formula><p>with human-like empathetic intent. The whole model architecture is shown in Figure <ref type="figure" target="#fig_1">3</ref>.</p><p>EmpHi learns the potential empathetic intent distribution with a latent variable z, which could be seen in Figure <ref type="figure" target="#fig_3">5</ref>. Conditional Variational AutoEncoder (CVAE) <ref type="bibr" target="#b18">(Yan et al., 2016;</ref><ref type="bibr" target="#b20">Zhao et al., 2017;</ref><ref type="bibr" target="#b7">Gu et al., 2019)</ref> is trained to maximize the conditional log likelihood, log p(X|C), which involves an intractable marginalization over z. We train the CVAE efficiently with Stochastic Gradient Variational Bayes (SGVB) (Kingma and Welling, 2014) by maximizing the variational lower bound of the log likelihood: p(X|C, z) denotes response reconstruction probability, q(z|X, C) is recognition probability and p(z|C) is prior probability. Our method mainly consists of three aspects:</p><formula xml:id="formula_2">log p(X|C) ‚â•E q(z|X,C) [log p(X|C, z)] -KL(q(z|X, C)||p(z|C)), (1) Z X C C X p(ùëß|ùê∂) q(ùëß|ùëã, ùê∂) p(ùëã|ùê∂, ùëß) p(ùëã|ùê∂) (b) (a)</formula><p>‚Ä¢ To capture the explicit relationship between the latent variable and the intent, we propose an intent representation learning approach to learn the intent embeddings.</p><p>‚Ä¢ We construct an intent predictor to predict potential response intent using contextual information and then use this intent for guiding the response generation.</p><p>‚Ä¢ During the generation process, EmpHi combines both implicit intent embedding and explicit intent keywords to generate responses corresponding to the given intents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Learning Intent Representation</head><p>To achieve more interpretability, we choose a discrete latent variable that obeys categorical distribution with nine categories, each corresponding to one empathetic intent. Directly maximizing Eq.1 would cause two serious problems: the relation between the latent variable and intent is intractable; the vanishing latent problem results in insufficient information provided by the latent variable during generation. <ref type="bibr" target="#b1">(Bowman et al., 2016;</ref><ref type="bibr" target="#b20">Zhao et al., 2017;</ref><ref type="bibr" target="#b7">Gu et al., 2019)</ref>. To solve the above issues, we separately train a recognition network q r (z|X) to encourage intent variable z to capture context-independent semantics, which is essential for z to be interpretable <ref type="bibr" target="#b19">(Zhao et al., 2018)</ref>. The task of the recognition network is to provide the accurate intent label of the response, which corresponds to an intent embedding. Then, by maximizing likelihood p(X|C, z), the embedding captures corresponding intent representation automatically. The recognition network q r (z|X) does not need additional training. We utilize the BERT intent classifier mentioned above, which achieves 87.75% accuracy in intent classification. In addition, as the sample operation easily brings noise for the intent representation learning when sampling a wrong intent, we use argmax operation to avoid the noise, the response reconstruction loss is:</p><formula xml:id="formula_3">L 1 = -log p(X|C, z k ) (2) z k = arg max z k q r (z k |X) (3) k ‚àà {0, 1, 2, ‚Ä¢ ‚Ä¢ ‚Ä¢ , 8}</formula><p>, each integer corresponds to a specific empathetic intent as in Figure <ref type="figure" target="#fig_0">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Intent Predictor and Emotion Classifier</head><p>The intent predictor is based on the prior network p i (z|C), which predicts the distribution of response intent by the given context. During inference, we sample potential intents from this distribution in order to generate human-like empathetic responses.</p><p>Specifically, the context is encoded with gated recurrent units (GRU) <ref type="bibr" target="#b4">(Chung et al., 2014)</ref>:</p><formula xml:id="formula_4">h t = GRU(h t-1 , E(c t )),<label>(4)</label></formula><p>where h t is the hidden state of GRU encoder, E(c t ) denotes the word embedding of the t-th word in context, we use h m as context embedding, then the prior network is:</p><formula xml:id="formula_5">p i (z|C) = Softmax(FFN z (h m )),<label>(5)</label></formula><p>where FFN represents Feed-Forward Network with two layers. The prior intent distribution is supervised by recognition distribution with KLdivergence in Eq.1:</p><formula xml:id="formula_6">L 2 = KL(q r (z|X)||p i (z|C)) = K k=1 q r (z k |X) log q r (z k |X) p i (z k |C) . (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>Since the context emotion is proved to be beneficial to empathetic dialogue generation <ref type="bibr" target="#b14">(Rashkin et al., 2019;</ref><ref type="bibr" target="#b10">Lin et al., 2019;</ref><ref type="bibr" target="#b11">Majumder et al., 2020)</ref>, we also employ an emotion classifier to classify the emotion of context:</p><formula xml:id="formula_8">P = Softmax(FFN e (h m ))]</formula><p>,</p><formula xml:id="formula_9">p e i = P[i]<label>(7)</label></formula><p>Given the ground truth emotion label e t , the emotion classifier is trained with cross-entropy loss:</p><formula xml:id="formula_10">L 3 = -log p e t .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Response Generator</head><p>As for the response generation p(X|C, z), we consider implicit intent embedding for the high-level abstraction of an intent. In addition, we also introduce intent keywords for explicitly utilizing intent knowledge during the generation process. Implicit. To generate response with an empathetic intent, the most intuitive approach is taking the intent embedding as additional input to decoder during the generation process. We also consider emotion embedding as traditional empathetic dialogue models:</p><formula xml:id="formula_11">s t = GRU(s t-1 , [E(x t-1 ); v(z); v(e); c att ]),<label>(9)</label></formula><p>where s t is the state of GRU decoder, c att denotes the context attention value which contains key information of context <ref type="bibr" target="#b0">(Bahdanau et al., 2015)</ref>. v(z) is intent embedding and v(e) is emotion embedding, both will not change during the generation process. However, this may sacrifice grammatical correctness <ref type="bibr" target="#b21">(Zhou et al., 2018;</ref><ref type="bibr" target="#b6">Ghosh et al., 2017)</ref>. Therefore we add a gate operation to capture intent and emotion dynamically:</p><formula xml:id="formula_12">Input = FFN i ([E(x t ); c att ; s t ]), Gate = Sigmoid(Input), v(z) = Gate ‚äô v(z),<label>(10)</label></formula><p>where ‚äô represents element-wise product. Each time step, the intent representation is used appropriately according to current word, state, and context value. The gate operation for emotion is the same as above.</p><p>Explicit. The empathetic expression is quite distinct over vocabularies, e.g., 'know', 'understand', 'agree', are indicative of the empathetic intent Agreeing. Therefore, we employ the copy mechanism to explicitly utilize intent keywords for intent conditional generation. See in Appendix B for more details about intent keywords .</p><formula xml:id="formula_13">Œ± t = Sigmoid(v ‚ä§ s s t ), p(x t = w g ) = Softmax(W g s t ), p(x t = w i ) = Softmax(W i s t ), p(x t ) = (1 -Œ± t ) ‚Ä¢ p(w g ) + Œ± t ‚Ä¢ p(w i ),<label>(11)</label></formula><p>where {s t , v s } ‚àà R d√ó1 , {W g , W i } ‚àà R V √ód , d is hidden size and V denotes the vocabulary size. The copy rate Œ± t is used to balance the choice between intent keywords and generic words, it is trained with binary cross entropy loss:</p><formula xml:id="formula_14">L 4 = n t=1 q t ‚Ä¢ log Œ± t + (1 -q t ) ‚Ä¢ log(1 -Œ± t ),<label>(12)</label></formula><p>n is the amount of words in response, q t ‚àà {0, 1} indicates that whether x t is a intent keyword.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Loss Function</head><p>To summarize, the total loss is:</p><formula xml:id="formula_15">L = Œª 1 L 1 + Œª 2 L 2 + Œª 3 L 3 + Œª 4 L 4 ,<label>(13)</label></formula><p>In order to join all losses with weighting method, we add 4 hyperparameters in total loss, Œª i , where each Œª i is corresponding to L i . L 1 , L 2 , L 3 , L 4 denote the losses of response reconstruction, intent prediction, emotion classification and copy rate prediction respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset</head><p>We evaluate our method and compare with others on EmpatheticDialogues<ref type="foot" target="#foot_0">foot_0</ref>  <ref type="bibr" target="#b14">(Rashkin et al., 2019)</ref> which contains 25k open domain dialogues. Follow the same setting as the authors of this dataset, the proportion of train/validation/test data is 8 : 1 : 1. Each dialogue consists of at least two utterances between a speaker and listener. There are 32 emotion situations in total, which are uniformly distributed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>We compare our model with the three latest empathetic conversational models:</p><p>‚Ä¢ Multitask Transformer (Multi-TRS). A transformer model trained by the response generation task and the context emotion classification task <ref type="bibr" target="#b14">(Rashkin et al., 2019)</ref>.</p><p>‚Ä¢ Mixture of Empathetic Listeners (MoEL).</p><p>An enhanced transformer model with 32 emotion-specific decoders to respond appropriately for each emotion <ref type="bibr" target="#b10">(Lin et al., 2019)</ref>.</p><p>‚Ä¢ MIMicking Emotions for Empathetic Response Generation (MIME). The state-ofthe-art empathetic dialogue model allows the generator to mimic the context emotion to a varying degree based on its positivity, negativity, and content. Furthermore, they introduce stochasticity into the emotion mixture and achieves one-to-many generation <ref type="bibr" target="#b11">(Majumder et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Automatic Metrics</head><p>‚Ä¢ BLEU. We choose BLEU <ref type="bibr" target="#b12">(Papineni et al., 2002)</ref> for relevance evaluation which measures the n-gram overlaps with reference and compute BLEU scores for n ‚â§ 4 using smoothing techniques <ref type="bibr" target="#b3">(Chen and Cherry, 2014)</ref>. Since the state-of-art model MIME and ours are both one-to-many generators, we calculate BLEU recall and BLEU precision <ref type="bibr" target="#b20">(Zhao et al., 2017;</ref><ref type="bibr" target="#b7">Gu et al., 2019)</ref>. For each test case, we sample 5 responses from latent space and use greedy search for MIME and EmpHi, use beam search for MoEL and Multitask-Transformer.</p><p>‚Ä¢ Distinct. Distinct <ref type="bibr" target="#b9">(Li et al., 2016</ref>) is a widely used metric for diversity evaluation. Specifically, we compute the number of distinct unigrams (Distinct-1) and bigrams (Distinct-2), then scale them by the total number of unigrams and bigrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Human Ratings</head><p>First, we randomly sample 100 dialogues and their corresponding generations from the three baseline models and EmpHi. Then, we invite five volunteers with master degrees to do the human evaluation.</p><p>The annotators mark each response from 1 to 5 for empathy, relevance, and fluency.</p><p>To clarify the marking criteria, we provide an explanation for each metric:</p><p>‚Ä¢ Empathy. Whether the response shows that the listener understands and shares the speaker's feeling. Can the listener imagine what it would be like in the speaker's situation?</p><p>‚Ä¢ Relevance. Whether the response is relevant to the context.</p><p>‚Ä¢ Fluency. Whether the response is easy to read and grammatically correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Human A/B Test</head><p>Following <ref type="bibr" target="#b10">(Lin et al., 2019;</ref><ref type="bibr" target="#b11">Majumder et al., 2020)</ref>, we construct this evaluation task to directly compare our model with each baseline. We randomly sample 100 dialogue responses from EmpHi vs {Multitask-Trans, MoEL, MIME}. Given randomly ordered responses from above models, four annotators select the better response, or tie if they think the two responses have the same quality. The average score of four results is calculated, and shown in Table <ref type="table">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Implement Detail</head><p>For MIME<ref type="foot" target="#foot_1">foot_1</ref>  <ref type="bibr" target="#b11">(Majumder et al., 2020)</ref> and MoEL<ref type="foot" target="#foot_2">foot_2</ref>  <ref type="bibr" target="#b10">(Lin et al., 2019)</ref>, we reproduce their results using their open-source codes and their default hyperparameters. According to the log-likelihood in the validation dataset for Multitask-Transformer, we use grid search for the best head number, layer number, and feed-forward neural network size. The best set is 2, 10, and 256, respectively. EmpHi uses a two-layer Bi-GRU as the encoder and a two-layer GRU as the decoder, Œª is set as [1, 0.5, 0.5, 1] respectively. All the feed-forward neural networks in EmpHi have two layers, 300 hidden units and ReLU activations. For the sake of fairness, we use pretrained Glove vectors <ref type="bibr" target="#b13">(Pennington et al., 2014)</ref> with 300 dimensions as the word embedding for all models, the batch size is 16, and the learning rate is set to 1e -4 .</p><p>6 Results and Discussions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results Analysis</head><p>In this section, we mainly testify:</p><p>‚Ä¢ human-like empathetic intent boost EmpHi's performance in terms of empathy, relevance, and diversity.</p><p>‚Ä¢ EmpHi successfully captures the empathetic intent distribution of humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Human Evaluation</head><p>As shown in Table <ref type="table" target="#tab_1">1</ref>, EmpHi outperforms all baselines in terms of empathy, relevance, and fluency. The most distinct improvement is 15.1% on relevance because our model does not only depends on the speakers' emotion, but also makes use of the empathetic intents, which are contextually relevant. It is worth noting that empathy is the primary   metric in empathetic dialogue generation. EmpHi outperforms the previous SOTA on empathy by 9.43%, which directly indicates that human-like empathetic intents are beneficial to the empathy ability of the dialogue model. Last but not least, a decent fluency score proves that our generated response could be understood by humans easily, where our model has an improvement of 9.87% from MoEL. In addition, the human A/B test results in Table 2 also confirm that the responses from our model are preferable to baselines. Overall, EmpHi successfully generates empathetic, relevant, and fluent responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Automatic Evaluation</head><p>As seen in Table <ref type="table" target="#tab_1">1</ref>, the automatic evaluation is consistent with human evaluation. The BLEU recall and F1 score are improved by 14.2% and 8.34%, respectively. However, we only have a slight im-  provement on BLEU precision, which is similar to <ref type="bibr" target="#b20">(Zhao et al., 2017;</ref><ref type="bibr" target="#b7">Gu et al., 2019)</ref> because the precision is penalized when the model generates diverse responses. Also, the distinct value of unigrams and bigrams are 32.04% and 19.32% higher than the previous SOTA, respectively. As shown in Figure <ref type="figure" target="#fig_2">4</ref> and Figure <ref type="figure" target="#fig_4">6</ref>, the empathy intents of EmpHi's responses are more diverse than existing models, so the distinct scores improve significantly.</p><p>Our method enhances the relevance and diversity simultaneously, which proves the effectiveness of human-like intent in empathetic response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Empathetic Intent Distribution</head><p>We apply the same approach in Section 3 and quantify the empathetic intent distribution of EmpHi's responses to prove that EmpHi accurately captures humans' empathetic intent distribution. Comparing Figure <ref type="figure" target="#fig_2">4</ref> and Figure <ref type="figure" target="#fig_4">6</ref>, the difference between them illustrates that our model successfully reduces the bias of empathetic expression. The KL-divergence of intent distributions between models and humans are 0.025 for EmpHi, 1.949 for MIME, 1.545 for MoEL, and 4.570 for Multitask-Transformer (See in Appendix A).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Ablation Study</head><p>We evaluate each component of EmpHi using BLEU and ACC, where ACC indicates the accuracy of predicted empathethetic intent of generated response. Since each conversation could have multiple empathetic responses, the ACC of 26.8% is pretty ideal. As seen in Table <ref type="table" target="#tab_3">3</ref>, there is a dra-1069</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nostalgic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>When my wife and i started dating, our second date ended up lasting like 12 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>That is a pretty long date ! Where did you guys go? Multitask-Trans That is so sad, I'm sorry to hear that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MoEL</head><p>That is great! I am sure she will be fine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIME</head><p>That is a good thing to do. I am sure you will do great.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EmpHi</head><p>That 's awesome ! How long have you been together ? Emotion Angry Turn-1 I just moved to this neighborhood and some dumb criminals shot one of my neighbors and ran into the woods! Turn-2 That's not good. Do you own a gun? Turn-3 I do! I want to be able to protect my son.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>That is always number one goal.   matic drop in the performance of EmpHi without any intent information (both implicit embedding and explicit keywords). Therefore, this proves the effectiveness of empathetic intents and the intent representation learning approach. As for implicit gate control, it improves both response quality and intent accuracy since it helps EmpHi dynamically capture intent information during generation. Same conclusion has been made in <ref type="bibr" target="#b21">(Zhou et al., 2018)</ref>.</p><p>The copy mechanism provides EmpHi the ability to explicitly use intent keywords and thus contributes to the intent accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Case Study</head><p>Intent-level diverse generation. Through sampling intents in the discrete latent space, EmpHi generates different responses with empathetic intents. As in Figure <ref type="figure" target="#fig_6">7</ref>, the speaker shows an exciting emotion for getting a better job. EmpHi</p><p>generates empathetic yet contextually relevant responses as humans. Besides, EmpHi predicts the potential intent distribution and shows successful conditional generation based on the corresponding intents, which improves the interpretability and controllability of empathetic response generation. See Appendix C for error analysis.</p><p>Compare with existing models. For the first instance in Table <ref type="table" target="#tab_5">4</ref>, even though baseline models show naive empathy in their response, it is hard for the speaker to feel empathy because the response is not relevant to the topic. In contrast, EmpHi shows its understanding of the speaker's feelings and asks a relevant question to explore the speaker's experience. For second case, all baselines express contextually irrelevant empathy, while EmpHi truly understands the dialogue history and put itself into speaker's situation, then further reply: "Maybe you should go to the police" with the Suggesting intent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Overall, we reveal the severe bias of empathetic expression between existing dialogue models and humans. To address this issue, this paper proposes EmpHi to generate empathetic responses with human-like empathetic intents. As a result, both automatic and human evaluation prove that EmpHi has a huge improvement on empathetic conversation. According to the anlaysis and case studies, EmpHi successfully learns the emapthetic intent distribution of human and shows high interpretability and controllability during the generation process. We will try large pretrained language models with empathetic intent in our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Empathetic Expression Gap</head><p>For more comprehensive recognization of the severe emathy expression bias between existing empathetic dialogue models and humans, we further quantify the bias of <ref type="bibr">Multitask-Transformer (Rashkin et al., 2019)</ref> in Figure <ref type="figure" target="#fig_7">8</ref> and MoEL <ref type="bibr" target="#b10">(Lin et al., 2019)</ref> in Figure <ref type="figure">9</ref>, the intent index is consistent with Figure <ref type="figure" target="#fig_0">2</ref>. The results are similar with MIME <ref type="bibr" target="#b11">(Majumder et al., 2020)</ref>, we can see the large intent distribution bias and the monotony of empathetic expression of existing models. we concatenate all the responses which are in the same group and remove all the stop words. Finally, we apply TF-IDF to obtain the top k keywords for each intent group, we set k to 30 in our experiments. See Table <ref type="table">5</ref> for top ten keywords for each intent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Error Analysis</head><p>Although EmpHi achieves huge improvement in terms of empathy, relevance, and diversity in empathetic dialogue generation, there is still some flaws. At first, the generation task of EmpHi is far difficult than existing models, because it needs to generate response condition on both context and the predicted intent, while other models generate response only condition on the context, therefor the exposure bias of EmpHi is more severe. See in Table <ref type="table">6</ref>, although the predicted intent of EmpHi is the same as reference and its corresponding response is great, EmpHi also gives high probability for Questioning intent and the corresponding response is not very contextually relevant, EmpHi knows it is suitable for asking more details to show its caring, but it does not know how to ask under this context, thus EmpHi needs better understanding for context information. We believe this issue could be mitigated when using more dialogue data for pretraining.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Empathetic intent distribution of human in empathetic conversation.</figDesc><graphic coords="2,306.14,70.85,218.28,154.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The architecture of EmpHi, which consists of a context encoder, an emotion classifier, a prior network (intent predictor), a recognition network, and a response decoder with copy mechanism.</figDesc><graphic coords="3,70.86,286.06,218.28,163.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Empathetic intent distribution of human and MIME (sad emotion), the intent index represents the same intent as in Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: An illustration of the difference between existing empathetic dialogue models (a) and EmpHi (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Empathetic intent distribution of human and EmpHi (sad emotion), the intent index represents the same intent as in Figure 2.</figDesc><graphic coords="7,70.86,289.95,218.28,163.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Case study of EmpHi.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Empathetic intent distribution of human and Multitask-Transformer (Rashkin et al., 2019)</figDesc><graphic coords="11,70.86,240.38,218.28,163.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Automatic evaluation between EmpHi and other models. All results are the mean of 5 runs for fair comparison. D-1.&amp;2. are magnified 100 times for each model.</figDesc><table><row><cell>Methods</cell><cell cols="4">#Params. Empathy Relevance Fluency</cell><cell>P</cell><cell>BLEU R</cell><cell>F1</cell><cell>Distinct D-1 D-2</cell></row><row><cell>Multitask-Trans MoEL MIME EmpHi Human</cell><cell>20M 21M 18M 11M -</cell><cell>2.68 3.18 2.89 3.48 4.04</cell><cell>2.58 3.18 2.90 3.66 4.40</cell><cell>3.60 3.95 3.77 4.34 4.56</cell><cell cols="2">0.3072 0.4137 0.3526 0.4123 0.3032 0.3614 0.3298 0.8473 0.3202 0.3278 0.3240 0.3952 0.3207 0.4723 0.3820 1.1188 ---7.0356 43.2174 1.1390 4.4698 1.3299 5.3332</cell></row><row><cell>Methods</cell><cell>Win</cell><cell>Loss</cell><cell>Tie</cell><cell></cell><cell></cell></row><row><cell cols="4">EmpHi vs Multitask-trans 56.5% 21.5% 22.0% EmpHi vs MoEL 45.0% 28.5% 26.5% EmpHi vs MIME 53.0% 27.0% 20.0%</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results of Human A/B test.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results of ablation study.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Multitask-Trans What did you do ? MoEL That is a good idea . MIME I am sorry to hear that. I hope you get it ! EmpHi Maybe you should go to the police.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison among EmpHi and other empathetic dialogue models. Thanks a bunch! it pays much better than my current job, so i really hope i do, but i think i got it in the bag.</figDesc><table><row><cell></cell><cell>Oh man, that's awesome. I</cell></row><row><cell></cell><cell>hope you get it!</cell></row><row><cell>Acknowledging</cell><cell>26.27%</cell></row><row><cell>Questioning</cell><cell>15.38%</cell></row><row><cell>Neutral</cell><cell>13.59%</cell></row><row><cell>Encouraging</cell><cell>11.47%</cell></row><row><cell>Agreeing</cell><cell>9.51%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>https://github.com/facebookresearch/ EmpatheticDialogues</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://github.com/declare-lab/MIME</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>https://github.com/HLTCHKUST/MoEL</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank the anonymous reviewers for their insightful comments and suggestions. This research was supported in part by the <rs type="funder">National Key Research and Development Program of China</rs> (No. <rs type="grantNumber">2020YFB1708200</rs>), the <rs type="funder">Guangdong Basic and Applied Basic Research Foundation</rs> (No. <rs type="grantNumber">2019A1515011387</rs>) and the <rs type="funder">Shenzhen Key Laboratory of Marine IntelliSense and Computation</rs> under Contract <rs type="grantNumber">ZDSYS20200811142605016</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8tB5yUQ">
					<idno type="grant-number">2020YFB1708200</idno>
				</org>
				<org type="funding" xml:id="_bqP7ZwT">
					<idno type="grant-number">2019A1515011387</idno>
				</org>
				<org type="funding" xml:id="_FqdQ6Hs">
					<idno type="grant-number">ZDSYS20200811142605016</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical Statement</head><p>Since this paper involves subjects related to human conversation, we have ensured that all the experiments will cause no harm to humans. The dataset EmpatheticDialogues is collected by <ref type="bibr" target="#b14">(Rashkin et al., 2019)</ref>, all the participants join the data collection voluntarily. Also, the dataset provider filters all personal information and obscene languages. Therefore, we believe that the dataset Empathetic-Dialogues used in our experiments are harmless to users, and the model trained on this dataset is not dangerous to humans. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generating sentences a continuous space</title>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>J√≥zefowicz</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2016-08-11">2016. 2016. August 11-12, 2016</date>
			<biblScope unit="page" from="10" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling empathy and distress in reaction to news stories</title>
		<author>
			<persName><forename type="first">Sven</forename><surname>Buechel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anneke</forename><surname>Buffone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Slaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jo√£o</forename><surname>Sedoc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10-31">2018. October 31 -November 4, 2018</date>
			<biblScope unit="page" from="4758" to="4765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A systematic comparison of smoothing techniques for sentencelevel BLEU</title>
		<author>
			<persName><forename type="first">Boxing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation, WMT@ACL 2014</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation, WMT@ACL 2014<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computer Linguistics</publisher>
			<date type="published" when="2014-06-26">2014. June 26-27, 2014</date>
			<biblScope unit="page" from="362" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">√áaglar</forename><surname>G√ºl√ßehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>CoRR, abs/1412.3555</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">2019. June 2-7, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Affectlm: A neural language model for customizable affective text generation</title>
		<author>
			<persName><forename type="first">Sayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Laksana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. 2017. July 30 -August 4</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="634" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dialogwae: Multimodal response generation with conditional wasserstein autoencoder</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06">2019. 2019. May 6-9, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Autoencoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations, ICLR 2014</title>
		<title level="s">Conference Track Proceedings</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14">2014. April 14-16, 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-12">2016. June 12-17, 2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2016. The Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Moel: Mixture of empathetic listeners</title>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamin</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11-03">2019. November 3-7, 2019</date>
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MIME: mimicking emotions for empathetic response generation</title>
		<author>
			<persName><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanshan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiankun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alexander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. November 16-20, 2020</date>
			<biblScope unit="page" from="8968" to="8979" />
		</imprint>
	</monogr>
	<note>Gelbukh, Rada Mihalcea, and Soujanya Poria</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2002-07-06">2002. July 6-12, 2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2014-10-25">2014. October 25-29, 2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards empathetic opendomain conversation models: A new benchmark and dataset</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Boureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07-28">2019. July 28-August 2, 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5370" to="5381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Towards facilitating empathic conversations in online mental health support: A reinforcement learning approach</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inna</forename><forename type="middle">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">S</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">C</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Althoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A computational approach to understanding empathy expressed in text-based mental health support</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">S</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">C</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Althoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11-16">2020. 2020. November 16-20, 2020</date>
			<biblScope unit="page" from="5263" to="5276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A taxonomy of empathetic response intents in human social conversations</title>
		<author>
			<persName><forename type="first">Anuradha</forename><surname>Welivita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pearl</forename><surname>Pu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020</title>
		<meeting>the 28th International Conference on Computational Linguistics, COLING 2020<address><addrLine>Barcelona, Spain (Online)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-08">2020. December 8-13, 2020</date>
			<biblScope unit="page" from="4886" to="4899" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Attribute2image: Conditional image generation from visual attributes</title>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9908</biblScope>
			<biblScope unit="page" from="776" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised discrete sentence representation learning for interpretable neural dialog generation</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyusong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Esk√©nazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07-15">2018. July 15-20, 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1098" to="1107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Esk√©nazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07-30">2017. July 30 -August 4</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018-02-02">2018. February 2-7, 2018</date>
			<biblScope unit="page" from="730" to="739" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
