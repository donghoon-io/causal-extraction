<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bayesian Monte Carlo Filtering for Stochastic Volatility Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Roberto</forename><surname>Casarin</surname></persName>
							<email>casarin@ceremade.dauphine.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Paris IX (Dauphine) and Dept. of Economics University Ca&apos; Foscari</orgName>
								<orgName type="institution">CEREMADE University</orgName>
								<address>
									<settlement>Venice</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Maréchal de Lattre de Tassigny</orgName>
								<orgName type="institution" key="instit1">CEREMADE</orgName>
								<orgName type="institution" key="instit2">University Paris IX (Dauphine)</orgName>
								<address>
									<addrLine>16 place du</addrLine>
									<postCode>75775</postCode>
									<settlement>Paris Cédex 16</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bayesian Monte Carlo Filtering for Stochastic Volatility Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Monte Carlo Filtering</term>
					<term>Particle Filter</term>
					<term>Gibbs Sampling</term>
					<term>Stochastic Volatility Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modelling of the financial variable evolution represents an important issue in financial econometrics. Stochastic dynamic models allow to describe more accurately many features of the financial variables, but often there exists a trade-off between the modelling accuracy and the complexity. Moreover the degree of complexity is increased by the use of latent factors, which are usually introduced in time series analysis, in order to capture the heterogeneous time evolution of the observed process. The presence of unobserved components makes the maximum likelihood inference more difficult to apply. Thus the Bayesian approach is preferable since it allows to treat general state space models and makes easier the simulation based approach to parameters estimation and latent factors filtering. The main aim of this work is to produce an updated review of Bayesian inference approaches for latent factor models. Moreover, we provide a review of simulation based filtering methods in a Bayesian perspective focusing, through some examples, on stochastic volatility models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The analysis of dynamic phenomena, which evolve over time is a common problem to many fields like engineering, physics, biology, statistics, economics and finance. A time varying system can be represented through a dynamic model, which is constituted by an observable component and an unobservable internal state. The hidden state vector represents the desired information that we want to extrapolate from the observations. Several kinds of dynamic models have been proposed in the literature for time series analysis and many approaches have been used for the estimation of these models. The seminal work of Kalman <ref type="bibr" target="#b21">[22]</ref> and Kalman and Bucy <ref type="bibr" target="#b22">[23]</ref> introduces filtering techniques (Kalman-Bucy filter) for continuous valued, linear and Gaussian dynamic systems. Another relevant work on dynamic model analysis is due to Maybeck <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. He motivates the use of stochastic dynamic systems in engineering and examines filtering, smoothing and estimation problems for continuous state space models, in both a continuous and a discrete time framework. Moreover Harvey <ref type="bibr" target="#b19">[20]</ref> extensively studies state space representation of dynamic models for time series analysis and treats the use of Kalman filter for states and parameters estimation, in continuous state space setting. Hamilton <ref type="bibr" target="#b18">[19]</ref> analyzes several kinds of time series models and in particular introduces a filter (Hamilton-Kitagawa filter) for discrete time and discrete valued dynamic system. This filter can be used for dynamic models with a finite number of state values.</p><p>Bauwens, Lubrano and Richard <ref type="bibr" target="#b1">[2]</ref> compare maximum likelihood inference with Bayesian inference on static and dynamic econometric models. Harrison and West <ref type="bibr" target="#b20">[21]</ref> treat the problem of the dynamic model estimation in a Bayesian perspective. They give standard filtering and smoothing equations for Gaussian linear models and investigate the estimation problem for conditionally Gaussian linear models and for general nonlinear and non-Gaussian models. They review some Markov Chain Monte Carlo (MCMC) simulation techniques for filtering and smoothing the hidden states and for estimating parameters. Moreover, also the problem of processing data sequentially has been examined through the use of the adaptive importance sampling algorithm. <ref type="bibr">Kim</ref> and Nelson <ref type="bibr" target="#b23">[24]</ref> analyze Monte Carlo simulation methods for nonlinear discrete valued model (switching regimes models). Recently, Durbin and Koopman <ref type="bibr" target="#b14">[15]</ref> propose an updated review on Markov Chain Monte Carlo methods for estimation of general dynamic models, with both a Bayesian and a maximum likelihood approach.</p><p>Sequential simulation methods for filtering and smoothing in general dynamic models have been recently developed to overcome some problems of the traditional MCMC methods. As pointed out by Liu and Chen <ref type="bibr" target="#b25">[26]</ref>, Gibbs sampler is less attractive when we consider on-line data processing. Furthermore Gibbs sampler may be inefficient when simulated states are very sticky and the sampler has difficulties to move in the state space. In these situations, the use of sequential Monte Carlo techniques and in particular of particle filter algorithms may result more efficient. Doucet, Freitas and Gordon <ref type="bibr" target="#b12">[13]</ref> provide the state of the art on sequential Monte Carlo methods. They discuss both applications and theoretical convergence results for these algorithms, with special attention to particle filters.</p><p>The main aim of this work is to introduce to Bayesian dynamic modelling and to the related inference problems of parameters estimation and hidden states filtering, with application to some basic discrete time stochastic volatility models. The second aim of the work is to review and discuss drawbacks of most important simulation based inference approaches and to show how traditional simulation methods, like the single-move Gibbs sampler and the multi-move Gibbs sampler apply to a dynamic model. Finally we introduces recently developed sequential Monte Carlo simulation methods, focusing on Particle Filters. Throughout the work, many examples illustrate how Bayesian simulation based inference apply to basic Stochastic Volatility models.</p><p>The work is structured as follow. Section 2 introduces the general representation of a dynamic model in a Bayesian framework and deals with continuous stochastic volatility model (SV) and with Markov switching SV model which do not admit analytical filtering and smoothing densities. Section 3 reviews simulation based methods for inference. In particular the section reviews MCMC methods, presents an adaptive importance sampling algorithm and discusses particle filter algorithms. Section 4 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bayesian Dynamic Models</head><p>In the following we give a quite general formulation of a probabilistic dynamic model and we obtain some fundamental relations for Bayesian inference on it. This definition of dynamic model would be general enough to include time series models analyzed in Kalman <ref type="bibr" target="#b21">[22]</ref>, Hamilton <ref type="bibr" target="#b18">[19]</ref>, Harrison and West <ref type="bibr" target="#b20">[21]</ref> and in Doucet, Freitas and Gordon <ref type="bibr" target="#b12">[13]</ref>. Throughout this work, we use a notation similar to that one commonly used in particle filter literature (see Doucet, Freitas and Gordon <ref type="bibr" target="#b12">[13]</ref>).</p><p>We denote by {x t ; t ∈ N}, x t ∈ X , the hidden state vectors of the system, by {y t ; t ∈ N 0 }, y t ∈ Y, the observable variables and by θ ∈ Θ the parameter vector of the model. We assume that state space, observation space and parameter space respectively are X ⊂ R nx , Y ⊂ R ny and Θ ⊂ R n θ . n x , n y and n θ represent the dimensions of the state vector, of the observable variable and of the parameter vector respectively. The main advantage in using the general Bayesian state space representation of a dynamic model, is that it accounts also for nonlinear and non-Gaussian models. The Bayesian state space representation is given by an initial distribution p(x 0 |θ), a measurement density p(y t |x t , y 1:t-1 , θ) and a transition density p(x t |x 0:t-1 , y 1:t-1 , θ). The dynamic model is</p><formula xml:id="formula_0">y t ∼ p(y t |x t , y 1:t-1 , θ)<label>(1)</label></formula><formula xml:id="formula_1">p(x t |x 0:t-1 , y 1:t-1 , θ)<label>(2)</label></formula><p>x 0 ∼ p(x 0 |θ) , with t = 1, . . . , T</p><p>where p(x 0 |θ) can be interpreted as the prior distribution on the initial state of the system. By x 0:t ∆ = (x 0 , . . . , x t ) and by y 1:t ∆ = (y 1 , . . . , y t ) we denote respectively the collection of state vectors and of observable vectors, up to time t. We denote by x -t ∆ = (x 0 , . . . , x t-1 , x t+1 , . . . , x T ) the collection of all the state vectors without the t-th element. The same notation is used also for the observable variable and for the parameter vectors.</p><p>If the transition density depends on the past, only through the last value of the hidden state vector, the dynamic model is defined first-order Markovian. In this case the system becomes</p><formula xml:id="formula_3">(y t |x t ) ∼ p(y t |x t , y 1:t-1 , θ)<label>(4)</label></formula><formula xml:id="formula_4">(x t |x t-1 ) ∼ p(x t |x t-1 , y 1:t-1 , θ)<label>(5)</label></formula><p>x 0 ∼ p(x 0 |θ) , with t = 1, . . . , T.</p><p>Assuming that the first-order Markov property holds is not restrictive because a Markov model of order p can always be rewritten as a first-order Markovian model. The stochastic volatility model given in Example 1, is a continuous states and discrete time dynamic model, which are now widely used in finance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 1 -(Stochastic Volatility Models)</head><p>Two of the main features of the financial time series are time varying volatility and clustering phenomena in volatility. Thus stochastic volatility models have been introduced, in order to account for these features. An example of stochastic log-volatility model is</p><formula xml:id="formula_6">y t ∼ N 0, e ht<label>(7)</label></formula><formula xml:id="formula_7">h t ∼ N ν + φh t-1 , σ 2<label>(8)</label></formula><formula xml:id="formula_8">h 0 ∼ N 0, σ 2 , with t = 1, . . . , T<label>(9)</label></formula><p>where y t is the observable process, with time varying volatility and h t represents the stochastic log-volatility process. In Fig. <ref type="figure" target="#fig_0">1</ref> we exhibit a simulated path of the observable process y t and of the stochastic volatility process h t .</p><p>In the following we discuss the three main issues which arise when making inference on a dynamic model, i.e.: filtering, predicting and smoothing. We present general solutions to these problems, but note that, without further assumptions on the densities, which characterize the dynamic model, these solutions are not yet analytical. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">State Estimation</head><p>We treat here the problem of estimation of the hidden state vector when parameters are known. We are interested in estimating the density p(x t |y 1:s , θ). If t = s the density of interest is called filtering density, if t &lt; s it is called smoothing density, finally if t &gt; s it is called prediction density.</p><p>For the dynamic model given in equations ( <ref type="formula" target="#formula_3">4</ref>), ( <ref type="formula" target="#formula_4">5</ref>) and <ref type="bibr" target="#b5">(6)</ref> we assume that at time t the density p(x t-1 |y 1:t-1 , θ) is known. Observe that if t = 1 the density p(x 0 |y 0 , θ) = p(x 0 |θ) is the initial distribution of the dynamic model.</p><p>Applying the Chapman-Kolmogorov transition density, we obtain the one step ahead prediction density</p><formula xml:id="formula_9">p(x t |y 1:t-1 , θ) = X p(x t |x t-1 , y 1:t-1 , θ)p(x t-1 |y 1:t-1 , θ)dx t-1<label>(10)</label></formula><p>As the new observation y t becomes available, it is possible, using the Bayes theorem, to update the prediction density and to filter the current state of the system. </p><p>where p(x t |y 1:t-1 , θ) is the prediction density determined at the previous step and the density at the denominator is the marginal of the current state and observable variable joint density</p><formula xml:id="formula_11">p(y t |y 1:t-1 , θ) = X p(y t , x t |y 1:t-1 , θ)dx t = X p(y t |x t , y 1:t-1 , θ)p(x t |y 1:t-1 , θ)dx t .<label>(12)</label></formula><p>At each date t, it is possible to determine the K-steps-ahead prediction density, conditional on the available information y 1:t . Given the dynamic model described by equations ( <ref type="formula" target="#formula_3">4</ref>), ( <ref type="formula" target="#formula_4">5</ref>) and ( <ref type="formula" target="#formula_5">6</ref>), the K-steps-ahead prediction density of the state vector x t can be evaluated iteratively. The first step is</p><formula xml:id="formula_12">p(x t+1 |y 1:t , θ) = X p(x t+1 |x t , y 1:t , θ)p(x t |y 1:t , θ)dx t (<label>13</label></formula><formula xml:id="formula_13">)</formula><p>and the k-th step, with k = 1, . . . , K, is</p><formula xml:id="formula_14">p(x t+k |y 1:t , θ) = X p(x t+k |x t+k-1 , y 1:t , θ)p(x t+k-1 |y 1:t , θ)dx t+k-1<label>(14)</label></formula><p>where</p><formula xml:id="formula_15">p(x t+k |x t+k-1 , y 1:t , θ) = Y k-1 p(x t+k |x t+k-1 , y 1:t+k-1 , θ)p(dy t+1:t+k-1 |y 1:t , θ)<label>(15)</label></formula><p>where </p><formula xml:id="formula_16">Y k = k i=1 Y i is the k-times</formula><p>Due to the high number of integrals that must be solved, previous densities may be difficult to evaluate with general dynamics. From a numerical point of view simulation methods, like MCMC algorithms or Particle Filters allow us to overcome these difficulties; while from an analytical point of view to obtain simpler relations we need to introduce some simplifying hypothesis on the dynamics of the model. For example if we assume that the evolution of the dynamic model does not depend on the past values of the observable variable y 1:t , then equations (4), ( <ref type="formula" target="#formula_4">5</ref>) and ( <ref type="formula" target="#formula_5">6</ref>) become</p><formula xml:id="formula_18">(y t |x t ) ∼ p(y t |x t , θ)<label>(17)</label></formula><formula xml:id="formula_19">(x t |x t-1 ) ∼ p(x t |x t-1 , θ)<label>(18)</label></formula><p>x 0 ∼ p(x 0 |θ) , with t = 1, . . . , T . </p><p>We conclude this section with two important recursive relations. Both these relations can be proved starting from the definition of joint smoothing density and assuming that the Markov property holds.</p><p>The first relation is the sequential filtering equation, which reveals particularly useful when processing data sequentially and becomes fundamental in implementing Particle Filter algorithms. Consider the joint posterior density of the state vectors, conditional on the information available at time T p(x 0:T |y 1:T , θ) = p(x 0:T , y T |y</p><formula xml:id="formula_22">1:T -1 , θ) p(y T |y 1:T -1 , θ) = = p(x 0:T -1 |y 1:T -1 , θ) p(x T , y T |x 0:T -1 , y 1:T -1 , θ) p(y T |y 1:T -1 , θ) = = p(x 0:T -1 |y 1:T -1 , θ) p(y T |x 0:T , y 1:T -1 , θ)p(x T |x 0:T -1 , y 1:T -1 , θ) p(y T |y 1:T -1 , θ) = (24) = p(x 0:T -1 |y 1:T -1 , θ) p(y T |x T , y 1:T -1 , θ)p(x T |x T -1 , y 1:T -1 , θ) p(y T |y 1:T -1 , θ) = = p(x 0:T -1 |y 1:T -1 , θ) p(y T |x T , θ)p(x T |x T -1 , θ) p(y T |y 1:T -1 , θ) .</formula><p>where the last line is due to the Markov property of the measurement and transition densities. Consider again the joint posterior density of the state vectors, x 0:T , given the information, By applying iteratively Bayes theorem and Markov property of the dynamic model we obtain the second recursive relation, which provides a factorization of the state vector smoothing density </p><formula xml:id="formula_23">p(x 0:T |y 1:T , θ) = = p(x T |y 1:T , θ)p(x T -1 |x T , y 1:T -1 , θ) T -2 t=0 p(x t |x t+1 , y 1:T , θ) = = p(x T |y 1:T , θ)p(x T -1 |x T , y 1:T -1 , θ)</formula><p>This factorization of the smoothing density is also relevant when inference is carried out through simulation methods. See for example the multi-move Gibbs sampler of Carter and Köhn <ref type="bibr" target="#b6">[7]</ref> and the particle filter algorithms.</p><p>Only in some well known cases, these filtering densities admit an analytical form. For the normal linear dynamic model, filtering and smoothing density are given by the Kalman filter. See Harrison and West <ref type="bibr" target="#b20">[21]</ref> for a Bayesian analysis of the Kalman filter. See Harvey <ref type="bibr" target="#b19">[20]</ref> for a frequentist approach to the Kalman filter.</p><p>A class of models which do not admit a tractable analytical representation of the filtering, prediction and smoothing densities is the class of conditional normal linear models (also called multi-process models, in Harrison and West <ref type="bibr" target="#b20">[21]</ref>), which are widely used in economic analysis (see <ref type="bibr">Kim and Nelson [24]</ref>). In the next section, we introduce another example of nonlinear dynamic models with jumps, which are used in financial applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Stochastic Volatility Models with Jumps</head><p>Using a Bayesian representation, stochastic volatility model with jumps can be defined as follow</p><formula xml:id="formula_25">(y t |h t ) ∼ N (0, e ht ) (<label>29</label></formula><formula xml:id="formula_26">) (h t |h t-1 , s t ) ∼ N (h t |α st + φ h t-1 , σ 2 ) (<label>30</label></formula><formula xml:id="formula_27">)</formula><p>for t = 1, . . . , T , where s t is the jump process. If s t is a discrete time and finite state Markov chain with transition probabilities i, j = 1, . . . , L, L denoting the number of unobservable states, then the model is called Markov switching. Fig. <ref type="figure" target="#fig_2">3</ref> exhibits simulation paths of 1, 000 observations of the Markov switching process, the latent factor and the observable variable, respectively. In order to simulate the MS stochastic volatility model we use parameters estimated in So, Lam and Li <ref type="bibr" target="#b39">[40]</ref>.</p><formula xml:id="formula_28">P(s t = j|s t-1 = i, s t-2 = i 2 ..., s 0 = i t ) = P(s t = j|s t-1 = i) = p ij<label>(31)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Simulation Based Filtering</head><p>The main aim of this section is to review both some traditional and recently developed inference methods for nonlinear and non-Gaussian models. We focus on the Bayesian approach and on simulation based methods. First Markov Chain Monte Carlo methods are reviewed with particular attention to the single-move Gibbs sampler due to Carlin, Polson and Stoffer <ref type="bibr" target="#b5">[6]</ref> and to the multi-move Gibbs sampler due to Carter and Köhn <ref type="bibr" target="#b6">[7]</ref> and Frühwirth-Schnatter <ref type="bibr" target="#b15">[16]</ref>. Moreover some basic sequential Monte Carlo simulation methods are introduced. We examine the adaptive importance sampling algorithm due to West <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>, the sequential importance sampling algorithm and more advanced sequential Monte Carlo algorithms called Particle Filters (see Doucet, Freitas and Gordon <ref type="bibr" target="#b12">[13]</ref>).</p><p>Finally, note that another important issue in making inference on dynamic models is the estimation of the parameter vector. In a Bayesian MCMC based approach, parameters and hidden states are jointly estimated by simulating from the posterior distribution of the model. Also in a sequential importance sampling approach and following the engineering literature, a common way to solve the parameter estimation problem is to treat parameters θ as hidden state of the system (see Berzuini et al. <ref type="bibr" target="#b2">[3]</ref>). The model is restated assuming time dependent parameter vectors θ t , and imposing a constraint on the evolution: θ t = θ t-1 . The constraint can be expressed also in terms of transition probability as follows</p><formula xml:id="formula_29">θ t ∼ δ θ t-1 (θ t ), t = 0, . . . , T<label>(32)</label></formula><p>where δ x * (x) denotes the Dirac delta function. The Bayesian model is then completed by assuming a prior distribution p(θ 0 ) on the parameter vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Gibbs Sampler</head><p>In previous sections we examine some estimation algorithms for filtering, predicting and smoothing the state vector of a quite general probabilistic dynamic model. In order to examine Gibbs sampling methods, we consider the following dynamic model</p><formula xml:id="formula_30">(y t |x t ) ∼ p(y t |x t , y 1:t-1 , θ)<label>(33)</label></formula><formula xml:id="formula_31">(x t |x t-1 ) ∼ p(x t |x t-1 , y 1:t-1 , θ)<label>(34)</label></formula><formula xml:id="formula_32">x 0 ∼ p(x 0 |θ)<label>(35)</label></formula><p>θ ∼ p(θ) , with t = 1, . . . , T.</p><p>The estimation problem is solved in a Bayesian perspective by evaluating the mean of the joint posterior density of the state and parameter vectors p(x 0:T , θ|y 1:T ). Tanner and Wong <ref type="bibr" target="#b41">[42]</ref> motivates this solution by the data augmentation principle, which consists in considering the hidden state vectors as nuisance parameters.</p><p>If an analytical evaluation of the posterior mean is not possible, then simulation methods and in particular Monte Carlo Markov Chain apply. The most simple solution is to implement a singlemove Gibbs sampler (see Carlin, Polson and Stoffer <ref type="bibr" target="#b5">[6]</ref> and Harrison and West <ref type="bibr" target="#b20">[21]</ref>). This method generates the states one at a time using the Markov property of the dynamic model to condition on the neighboring states. However the first order Markov dependence between adjacent states induces a high correlation between outputs of the Gibbs sampler and causes a slow convergence of the algorithm. To solve this problem Carter and Köhn <ref type="bibr" target="#b6">[7]</ref> and Frühwirth-Schnatter <ref type="bibr" target="#b15">[16]</ref> simultaneously proposes multi-move Gibbs sampler. The main idea of this method is to generate simultaneously all the state vectors using analytical filtering and smoothing relations.</p><p>Their approach is less general than that of Carlin, Polson and Stoffer <ref type="bibr" target="#b5">[6]</ref>, but for linear dynamic models with Gaussian mixture innovations in the observation equation, their approach is more efficient. In particular the multi-move Gibbs sampler has a faster convergence to the posterior distribution and the posterior moment estimates have smaller variance. These results are supported theoretically by Liu, Wong and Kong <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref> and Müller <ref type="bibr" target="#b32">[33]</ref>, who shows that generating variables simultaneously produces faster convergence than generating them one at a time.</p><p>The idea of grouping parameters (or hidden states) when simulating is now commonly in Bayesian inference on stochastic models, with latent factors. For example, multi-move MCMC algorithms have been used for stochastic volatility models by Kim, Shephard and Chib <ref type="bibr" target="#b24">[25]</ref> and extended to generalized stochastic volatility models by Chib, Nardari and Shephard <ref type="bibr" target="#b9">[10]</ref>. Shephard <ref type="bibr" target="#b37">[38]</ref> and Shephard and Pitt <ref type="bibr" target="#b38">[39]</ref> discussed multi-move MCMC algorithms to non-Gaussian time series models . Finally, an alternative way of simulating from the smoothing density of the state vectors is discussed in De Jong and Shephard <ref type="bibr" target="#b11">[12]</ref>.</p><p>In the following we briefly present how to implement the single-move Gibbs sampler for parameters and states estimation. On the time interval {1, . . . , T }, the conditional posterior distributions of the parameter vector and of the state vectors are p(θ|x 0:T , y 1:T ) ∝ p(θ)p(x 0 |θ)</p><formula xml:id="formula_34">T t=1 p(y t |x t , y 1:t-1 , θ)p(x t |x t-1 , y 1:t-1 , θ)<label>(37)</label></formula><p>p(x 0:T |y 1:T , θ) ∝ p(x 0 |θ)</p><formula xml:id="formula_35">T t=1 p(y t |x t , y 1:t-1 , θ)p(x t |x t-1 , y 1:t-1 , θ).<label>(38)</label></formula><p>A basic Gibbs sampler is obtained by simulating sequentially from the parameter vector posterior (parameter simulation step) in equation <ref type="bibr" target="#b36">(37)</ref> and from the state vectors posterior (data augmentation step) in equation ( <ref type="formula" target="#formula_35">38</ref>) conditionally on the parameter vector simulated at the previous step. When conditional distributions cannot be directly simulated, the corresponding steps in the Gibbs algorithm can be replaced by Metropolis-Hastings steps. The resulting algorithms are called hybrid sampling algorithms and they are validated in Tierney <ref type="bibr" target="#b42">[43]</ref>. A generic Gibbs sampler can be used for simulating the posterior of the parameter vector conditional on the simulated state vectors. The single-move Gibbs sampler for the state vectors, conditional on the simulated parameter vector, is then obtained by drawing each state vector conditionally on the other simulated state vectors. Single-move algorithm can be implemented for general dynamic models. Moreover, note that the dynamic model given in equations ( <ref type="formula" target="#formula_30">33</ref>)- <ref type="bibr" target="#b35">(36)</ref> satisfies to the Markov property. For the general model described in Equations ( <ref type="formula" target="#formula_30">33</ref>)- <ref type="bibr" target="#b35">(36)</ref>, with measurement and transition densities depending on past values of the observable variable y 1:t-1 , the full posterior density of the state vector, given in the single-move Gibbs sampler (see the Algorithm 2) can be derived as follow.</p><p>Algorithm 1 -Gibbs sampler for the parameter vector Given simulated vectors θ (i) and x (i) 0:T , generate the parameter vector</p><formula xml:id="formula_36">1. θ (i+1) 1 ∼ p(θ 1 |θ (i) 2 , . . . , θ (i) n θ , x (i) 0:T , y 1:T ) 2. θ (i+1) 2 ∼ p(θ 2 |θ (i+1) 1 , θ (i) 3 , . . . , θ (i) n θ , x (i) 0:T , y 1:T ) 3. . . . 4. θ (i+1) k ∼ p(θ k |θ (i+1) 1 , . . . , θ (i+1) k-1 , θ (i) k+1 , . . . , θ (i) n θ , x (i) 0:t , y 1:T ) 5. . . . 6. θ (i+1) n θ ∼ p(θ n θ |θ (i+1) 1 , . . . , θ (i+1) n θ -1 , x (i) 0:T , y 1:T ) Algorithm 2 -Single-Move Gibbs Sampler - (i) Simulate θ (i) through Algorithm 1; (ii) Given θ (i) and x (i) 0:T , simulate state vectors 7. x (i+1) 0 ∼ p(x 0 |x (i) 2:T , y 1:T , θ (i+1) ) 8. x (i+1) 1 ∼ p(x 1 |x (i+1) 0 , x (i) 2:T , y 1:T , θ (i+1) ) 9. . . . 10. x (i+1) t ∼ p(x t |x (i+1) 0:t-1 , x (i) t+1:T , y 1:T , θ (i+1) ) 11. . . . 12. x (i+1) T ∼ p(x T |x (i+1) 0:T -1 , y 1:T , θ (i+1) )</formula><p>Consider the full posterior density of the t-th state vector and apply the independence assumption between y t+1:T and x t p(x t |x -t , y 1:T , θ) = p(x t |x -t , y 1:t , y t+1:T , θ) then the last density simplifies as follow We illustrate, through this example, how simulation based Bayesian inference applies to dynamic models. In particular, we develop a single-move Gibbs sampler for the stochastic volatility model given in Example 1. Note that the stochastic volatility model can be rewritten as follows</p><formula xml:id="formula_37">= p(x t ,</formula><formula xml:id="formula_38">p(x t |x -t , y 1:t , θ) = p(x t |x 0:t-1 , x t+1:T , y 1:t , θ) = = p(x t:T , y t |x 0:t-1 , y 1:t-1 , θ) p(x t+1:T , y t |x 0:t-1 , y 1:t-1 , θ) = = p(x t+1:T , y t |x 0:t , y 1:t-1 , θ)p(x t |x 0:t-1 , y 1:t-1 , θ) p(x t+1:T , y t |x 0:t-1 , y 1:t-1 , θ) = = p(x t+1:T |x 0:t , y 1:t , θ)p(y t |x 0:t , y 1:t-1 , θ)p(x t |x 0:t-1 , y 1:t-1 , θ) p(x t+1:T , y t |x 0:t-1 , y 1:t-1 , θ) = M arkov = p(</formula><formula xml:id="formula_39">y t = e ht/2 ε t , ε t ∼ N (0, 1)<label>(39)</label></formula><formula xml:id="formula_40">h t = ν + φh t-1 + ση t , η t ∼ N (0, 1)<label>(40)</label></formula><p>with t = 1, . . . , T.</p><p>The completed likelihood function of this model is</p><formula xml:id="formula_42">L(φ, ν, σ 2 |y 1:T , h 0:T ) = = T t=1 1 (2π) 1/2 e ht/2 exp - y 2 t e -ht<label>2</label></formula><formula xml:id="formula_43">1 (2πσ 2 ) 1/2 exp - (h t -ν -φh t-1 ) 2 2σ 2 = = 1 (2π) T (σ 2 ) T 2 exp - 1 2 T t=1 (y 2 t e -ht + h t ) - 1 2σ 2 T t=1 (h t -ν -φh t-1 ) 2<label>(42)</label></formula><p>In order to conclude the description of the Bayesian dynamic model we take the following prior distributions on the parameters φ, ν, σ 2 and h 0</p><formula xml:id="formula_44">φ ∼ N (a, b 2 )I (-1,+1) (φ) (43) ν ∼ N (c, d 2 ) (<label>44</label></formula><formula xml:id="formula_45">)</formula><formula xml:id="formula_46">σ 2 ∼ IG(α, β)<label>(45)</label></formula><formula xml:id="formula_47">h 0 ∼ N (0, σ 2 ) (<label>46</label></formula><formula xml:id="formula_48">)</formula><p>where IG(•, •) indicates the Inverse Gamma distribution. Note that for the parameter φ we use a truncated Normal distribution, but a Uniform distribution U [-1,1] could alternatively be used. In the first part of the single-move Gibbs sampler, the parameters are simulated from the posterior distributions, through the following three steps (i) Simulate φ ∼ π(φ|σ 2 , ν, y 1:T , h 0:T ), where</p><formula xml:id="formula_49">π(φ|σ 2 , ν, y 1:T , h 0:T ) ∝ (47) ∝ exp - 1 2σ 2 T t=1 (h t -ν -φh t-1 ) 2 1 (2π) 1/2 b exp - (φ -a) 2 2b 2 I (-1,+1) (φ) ∝ ∝ exp - 1 2 φ 2 1 b 2 + T t=1 h 2 t-1 σ 2 -2φ a b 2 + T t=1 h t-1 (h t -ν) σ 2 I (-1,+1) ∝ N (ã, b2 )I (-1,+1) (φ) with ã = b2 a b 2 + 1 σ 2 T t=1 h t-1 (h t -ν) , b2 = 1 b 2 + 1 σ 2 T t=1 h 2 t-1 -1</formula><p>(ii) Simulate ν ∼ π(ν|φ, σ 2 , y 1:T , h 0:T ), where</p><formula xml:id="formula_50">π(ν|φ, σ 2 , y 1:T , h 0:T ) ∝ (48) ∝ exp - 1 2σ 2 T t=1 (h t -ν -φh t-1 ) 2 exp - (ν -c) 2 2d 2 1 (2π) 1/2 d ∝ ∝ exp - 1 2 ν 2 ( 1 d 2 + T σ 2 ) -2ν c d 2 + T t=1 (h t -φh t-1 ) σ 2 ∝ ∝ N (c, d2 ) with c = d2 c d 2 + 1 σ 2 T t=1 (h t -φh t-1 ) , d2 = 1 d 2 + T σ 2 -1</formula><p>(iii) Simulate σ 2 ∼ π(σ 2 |φ, ν, y 1:T , h 0:T ), where</p><formula xml:id="formula_51">π(σ 2 |φ, ν, y 1:T , h 0:T ) ∝ (49) ∝ 1 σ 2 (T +1) 2 exp - 1 2σ 2 T t=1 (h t -ν -φh t-1 ) 2 - h 2 0 2σ 2 β α e -β/σ 2 Γ(α)(σ 2 ) α+1 I [0,∞) (σ 2 ) ∝ ∝ exp - 1 2σ 2 (2β + T t=1 (h t -ν -φh t-1 ) 2 + h 2 0 ) 1 σ 2 α+ T +1 2 +1 I [0,∞) (σ 2 ) ∝ ∝ IG(α, β) with α = α + T + 1 2 , β = β + 1 2 T t=1 (h t -ν -φh t-1 ) 2 + h 2 0</formula><p>In the second part of the single-move Gibbs sampler, the hidden variables, {h t } T t=1 , are sampled once at time, from the following posterior distribution</p><formula xml:id="formula_52">π(h t |h -t , y 1:T , ν, φ, σ 2 ) ∝ exp - (y 2 t e -ht + h t ) 2 exp - (h t -ν -φh t-1 ) 2 2σ 2 - (h t+1 -ν -φh t ) 2 2σ 2<label>(50)</label></formula><p>for t = 1, . . . , T . Due to the presence of the quantity e -ht in the exponential any standard simulation method easily applies here. Moreover the posterior distribution is known up to a normalising constant, thus the M.-H. algorithm can be used. The proposal distribution can be obtained by replacing the function y 2 t e -ht + h t in equation ( <ref type="formula" target="#formula_52">50</ref>), with (log y 2 t + 1) + (h tlog y 2 t ) 2 /2, which is its the second order Taylor expansion, around log y 2 t . We simulate h t from the following proposal density</p><formula xml:id="formula_53">q(h t |h -t , y 1:T , ν, φ, σ 2 ) ∝ (51) ∝ exp - (h t -log y 2 t ) 2 4 - (h t -ν -φh t-1 ) 2 2σ 2 - (h t+1 -ν -φh t ) 2 2σ 2 ∝ ∝ exp - h 2 t 2 1 + φ 2 σ 2 + 1 2 + h t ν(1 -φ) + φ(h t-1 + h t+1 ) σ 2 + log y 2 t 2 ∝ ∝ N (µ, σ2 ) with µ = (ν(1 -φ) + φ(h t-1 + h t+1 )) σ -2 + log y 2 t /2 σ2 , σ2 = 1 + φ 2 σ 2 + 1 2 -1</formula><p>We apply the single-move Gibbs sampler to the synthetic dataset exhibited in Fig. <ref type="figure" target="#fig_0">1</ref>. We use a burn-in sample of 10,000 observations to reduce the dependence on the initial conditions of the sampler and take the remaining 40,000 values to calculate the parameter estimates, which are represented in Table <ref type="table" target="#tab_6">1</ref>.  Figure <ref type="figure" target="#fig_3">4</ref> shows the true stochastic log-volatility versus the filtered volatility. Figures <ref type="figure">5</ref> and<ref type="figure">6</ref> show the raw output of the single-move Gibbs sampler and the ergodic means respectively. Figures <ref type="figure">7</ref> and<ref type="figure">8</ref> show the autocorrelation of the simulated values and the histograms of the posterior distributions, respectively.</p><p>Simulations have been carried out on a PC with Intel 2400 MHz processor, using routines implemented in Gauss 3.2.8.</p><p>Although the simplification due to the first order Markov property of the dynamic model makes the single-move Gibbs sampler easier to implement, some problems arise. In particular, the Markovian dependence between neighboring states generates correlation between outputs of the Gibbs sampler and origins slower convergence to the posterior distribution (see Carter and Köhn <ref type="bibr" target="#b6">[7]</ref>). A consequence is that if an adaptive importance sampling is carried out by running parallel single-move Gibbs samplers, the number of replications before convergence of the parameter estimates is high.</p><p>A general method to solve this autocorrelation problem in the output of the Gibbs sampler is to group parameters (or states) and to simulate them simultaneously. This idea has been independently applied by Carter and Köhn <ref type="bibr" target="#b6">[7]</ref> and by Frühwirth-Schnatter <ref type="bibr" target="#b15">[16]</ref> to dynamic models and the resulting algorithm is the multi-move Gibbs sampler. Furthermore Frühwirth-Schnatter  [16] shows how the use of the multi-move Gibbs sampler improves the convergence rate of an adaptive importance sampling algorithm and makes a comparison with a set of parallel singlemove Gibbs samplers. The implementation of the multi-move Gibbs sampler depends on the availability of the analytical form of filtering and smoothing densities.</p><p>We give here a general representation of the algorithm, but its implementation is strictly related to the specific analytical representation of the dynamic model. Given the simulated parameter vector obtained through the Gibbs sampler in the Algorithm 1, the multi-move Gibbs sampler is in Algorithm 3.</p><p>Algorithm 3 -Multi-Move Gibbs Sampler -(i) Simulate θ (i) through Algorithm 1;</p><p>(ii) Given θ (i) and x (i) 0:T , run analytical filtering relations in order to estimate prediction and filtering densities for each t = 0, . . . , T </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">p(x t |y</head><formula xml:id="formula_54">1:t-1 , θ (i+1) ) 8. p(x t |y 1:t , θ (i+1) ) (iii)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="12.">x</head><formula xml:id="formula_55">(i+1) t ∼ p(x t |x (i+1) t+1 , y 1:t , θ (i+1) ) 13. . . . 14. x (i+1) 1 ∼ p(x 1 |x (i+1) 2 , y 1 , θ (i+1) )</formula><p>The algorithm has been derived trough the recursive smoothing relation given in equation <ref type="bibr" target="#b25">(26)</ref>. Moreover, at each simulation step the posterior density is obtained by means of estimated prediction and filtering densities. By applying the fundamental relation given in equation ( <ref type="formula" target="#formula_24">28</ref>) we obtain</p><formula xml:id="formula_56">p(x t |x (i+1) t+1 , y 1:t , θ (i+1) ) = p(x (i+1) t+1 |x t , θ (i+1) )p(x t |y 1:t , θ (i+1) ) p(x (i+1) t+1 |y 1:t , θ (i+1) )<label>(52)</label></formula><p>We stress once more that the multi-move Gibbs sampler does not easily apply to nonlinear and non-Gaussian models. Thus in a Bayesian MCMC approach, the single-move Gibbs sampler remains the only numerical solution to the estimation problem. Moreover estimation performances of both the single-move and multi-move Gibbs samplers depends on the model complexity, the parameter setting and on the specific time series. To overcome these difficulties in the literature adaptive sampling schemes have been proposed. Sequential sampling algorithm represents a first alternative to MCMC methods. Sequential Monte Carlo algorithms allow us to make inference on general dynamic models. One of the early sequential methods proposed in the literature is Adaptive Importance Sampling, which will be discussed in the next section.</p><p>As alternative to MCMC methods, recently Cappé et al. <ref type="bibr" target="#b4">[5]</ref> propose an adaptive importance sampling algorithm, called Population Monte Carlo (PMC). Moreover Guillin et al. <ref type="bibr" target="#b17">[18]</ref> and Celeux, Marin, Robert <ref type="bibr" target="#b8">[9]</ref> also apply both Gibbs sampler and PMC algorithm to latent variables models and in particular also to the basic continuous stochastic volatility model, evidencing how filtering through PMC produces better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Adaptive Importance Sampling</head><p>The adaptive sequential importance sampling scheme is a sequential stochastic simulation method which adapts progressively to the posterior distribution also by means of the information contained in the samples, which are simulated at the previous steps. The adaptation mechanism is based on the discrete posterior approximation and on the kernel density reconstruction of the prior and posterior densities. West <ref type="bibr" target="#b43">[44]</ref> proposed this technique in order to estimate parameters of static models. West <ref type="bibr" target="#b44">[45]</ref> and West and Harrison <ref type="bibr" target="#b20">[21]</ref> successively extended the method in order to estimate parameters and states of dynamic models.</p><p>The first key idea is to use importance sampling (see Robert and Casella <ref type="bibr" target="#b36">[37]</ref>) in order to obtain a weighted random grid of evaluation points in the state space. Let {x i t , w i t } nt t=1 be a sample drawn from the posterior p(x t |y 1:t , θ) through an importance density g t . The prediction density, given in equation <ref type="bibr" target="#b19">(20)</ref>, can be approximated as follow</p><formula xml:id="formula_57">p(x t+1 |y 1:t , θ) ≈ nt i=1 w i t p(x t+1 |x i t , θ)<label>(53)</label></formula><p>The second key idea, implemented in the adaptive importance sampling algorithm of West <ref type="bibr" target="#b44">[45]</ref>, is to propagate points of the stochastic grid by means of the transition density and to build a smoothed approximation of the prior density. This approximation is obtained through a kernel density estimation. West <ref type="bibr" target="#b44">[45]</ref> suggested to use Gaussian or Student-t kernels due to their flexibility in approximating other densities. For example, the Gaussian kernel reconstruction is</p><formula xml:id="formula_58">p(x t+1 |y 1:t , θ) ≈ nt i=1 w i t N (x t+1 |m t a + x i t (1 -a), h 2 V t ) (54)</formula><p>The final step of the algorithm consists in updating the prior density and in producing a random sample, {x i t+1 , w i t+1 } n t+1 i=1 , from the resulting posterior density. The sample is obtained by using the kernel density estimate as importance density. Adaptive importance sampling is represented through Algorithm 4.</p><p>The main advantage of this algorithms relies in the smoothed reconstruction of the prior density. This kernel density estimate of the prior allows to obtain adapting importance densities and to avoid the information loss, which comes from cumulating numerical approximation over time. Furthermore this technique can be easily extended to account for a sequential estimation of the parameter (see the recent work due to Liu and West <ref type="bibr" target="#b26">[27]</ref>).</p><p>Algorithm 4 -Adaptive Sequential Importance Sampling -Given a weighted random sample</p><formula xml:id="formula_59">{x i t , w i t } nt t=1 , for i = 1, . . . , n t 1. Simulate xi t+1 ∼ p(x t+1 |x i t , θ) 2. Calculate m t = nt i=1 w i t xi t+1 , V t = nt i=1 w i t (x i t+1 -m t ) (x i t+1 -m t )</formula><p>3. Generate from the Gaussian kernel</p><formula xml:id="formula_60">x i t+1 ∼ nt i=1 w i t N (x t+1 |(m t a + x i t (1 -a)), h 2 V t ) 4. Update the weights w i t+1 ∝ w i t p(y t+1 |x i t+1 )p(x i t+1 |x i t ) N (x i t+1 |(mta+(1-a)x i t ),h 2 Vt)</formula><p>However adaptive importance sampling requires the calibration of parameters a and h, which determines the behavior of the kernel density estimate. The choice of that shrinkage parameters influences the convergence of the algorithm and heavily depends on the complexity of the model studied.</p><p>Finally, adaptive importance sampling belongs to a more general class of sequential simulation algorithms, which are particulary efficient for on-line data processing and which have some common problems like sensitivity to outliers and degeneracy. In next paragraph we review some general particle filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Particle Filters</head><p>In the following we focus on Particle filters, also referred in the literature as Bootstrap filters, Interacting particle filters, Condensation algorithms, Monte Carlo filters and on the estimation of the states of the dynamic model. See also Doucet, Freitas and Gordon <ref type="bibr" target="#b12">[13]</ref> for an updated review on the particle filter techniques, on their applications and on the main convergence results for this kind of algorithms.</p><p>The main advantages of particle filters are that they can deal with nonlinear and non-Gaussian noise and can be easily implemented, also in a parallel mode. Moreover in contrast to Hidden Markov Model filters, which work on a state space discretised to a fixed grid, particle filters focuse sequentially on the higher probable regions of the state space. This is feature is common to Adaptive Importance Sampling algorithm exhibited in the previous section.</p><p>Assume that the parameter vector θ of the dynamic model given in equations ( <ref type="formula" target="#formula_18">17</ref>), ( <ref type="formula" target="#formula_19">18</ref>) and ( <ref type="formula" target="#formula_20">19</ref>) is known. Different versions of the particle filter exist in the literature and different simulation approaches like rejection sampling, MCMC and importance sampling, can be used for the construction of a particle filter. We introduce particle filters applying the importance sampling reasoning.</p><p>At each time step t + 1, as a new observation y t+1 arrives, we are interested in predicting and filtering the hidden variables and the parameters of a general dynamic model. In particular we search how to approximate prediction an filtering densities given in Equations ( <ref type="formula">20</ref>) and ( <ref type="formula">21</ref>) by means of sequential Monte Carlo methods.</p><p>Assume that the weighted sample {x i t , w i t } N i=1 has been drawn from the filtering density at time t</p><formula xml:id="formula_61">p(x t |y 1:t , θ) = N i=1 w i t δ {x i t } (dx t )<label>(55)</label></formula><p>Each simulated value x i t is called particle and the particles set, {x i t , w i t } N i=1 , can be viewed as a random discretization of the state space X , with associated probabilities weights w i t . It is possible to approximate, by means of this particle set, the prediction density given in Eq. ( <ref type="formula">21</ref>) as follows</p><formula xml:id="formula_62">p(x t+1 |y 1:t , θ) = X p(x t+1 |x t , θ)p(x t |y 1:t , θ)dx t N i=1 w i t p(x t+1 |x i t , θ)<label>(56)</label></formula><p>which is called empirical prediction density and is denoted by p(x t+1 |y 1:t , θ). By applying the Chapman-Kolmogorov equation it is also possible to obtain an approximation of the filtering density given in Eq. ( <ref type="formula">21</ref>) </p><formula xml:id="formula_63">Filtering Initial Particle Set p(xt|y 1:t ) {x i t , wi t } N i=1 u } u u } u £ £ £ £ £ g g g g g £ £ £ £ £ c g g g g g £ £ £ £ £ c Prediction Propagation p(x t+1 |y 1:t ) {x i t+1 , wi t } N</formula><formula xml:id="formula_64">) {x i t+1 , wi t+1 } N i=1 u z } x z } t t t t t g g g g g g g g g g g g f f f f f f x f f f f f f x f f f f f f x c Prediction Propagation p(x t+2 |y 1:t+1 ) {x i t+2 , wi t+1 } N i=1</formula><p>e e e e e e p(x t+1 |y 1:t+1 , θ) ∝ p(y t+1 |x t+1 , θ)p(x t+1 |y 1:t , θ)</p><formula xml:id="formula_65">N i=1 p(y t+1 |x t+1 , θ)p(x t+1 |x i t , θ)w i t<label>(57)</label></formula><p>which is called empirical filtering density and is denoted by p(x t+1 |y 1:t+1 , θ).</p><p>Assume now that the quantity E(f (x t+1 )|y 1:t+1 ) is of interest. It can be evaluated numerically by a Monte Carlo sample {x i t+1 , w i t+1 } N i=1 , simulated from the filtering distribution</p><formula xml:id="formula_66">E(f (x t+1 )|y 1:t+1 ) 1 N N i=1 f (x i t+1 )w i t+1 1 N N i=1 w i t+1 .<label>(58)</label></formula><p>A simple way to obtain a weighted sample from the filtering density at time t + 1 is to apply importance sampling to the empirical filtering density given in equation (57). This step corresponds to propagate the initial particle set (see Fig. <ref type="figure" target="#fig_8">9</ref>) through the importance density q(x t+1 |x i t , y t+1 , θ). Moreover if we propagate each particle of the set through the transition density p(x t |x i t-1 , θ) of the dynamic model, then particle weights update as follows</p><formula xml:id="formula_67">w i t+1 ∝ p(y t+1 |x t+1 , θ)p(x t+1 |y 1:t , θ)w i t q(x t+1 |x i t , y t+1 , θ) = w i t p(y t+1 |x i t+1 , θ)<label>(59)</label></formula><p>This is the natural choice for the importance density, because the transition density represents a sort of prior at time t for the state x t+1 . However, as underlined in Pitt and Shephard <ref type="bibr" target="#b34">[35]</ref> this strategy is sensitive to outliers. See also Crisan and Doucet <ref type="bibr" target="#b10">[11]</ref>, for a discussion on the choice of the importance densities. They focused on the properties of the importance density, which are necessary for the a.s. convergence of the sequential Monte Carlo algorithm.</p><p>The basic particle filter developed through previous equations is called Sequential Importance Sampling (SIS). In Algorithm 5, we give a pseudo-code representation of this method.</p><p>Algorithm 5 -SIS Particle Filter -Given the initial set of particles {x i t , w i t } N i=1 , for i = 1, . . . , N :</p><formula xml:id="formula_68">1. Simulate x i t+1 ∼ q(x t+1 |x i t , y t+1 , θ)</formula><p>2. Update the weights:</p><formula xml:id="formula_69">w i t+1 ∝ w i t p(y t+1 |x i t+1 ,θ) p(x t+1 |x i t ;θ) q(x t+1 |x i t ,y t+1 ,θ)</formula><p>Sequential importance sampling permits to obtain recursive updating of the particles weights and is based on the sequential decomposition of the joint filtering density and on a particular choice of the importance density. To evidence these aspects we consider the following smoothing problem.</p><p>We want to approximate the smoothing density p(x 0:t+1 |y 1:t+1 , θ), of the state vectors as follows p(x 0:t+1 |y 1:t+1 , θ)</p><formula xml:id="formula_70">N i=1 wi t+1 δ {x i 0:t+1 } (dx 0:t+1 )<label>(60)</label></formula><p>by simulating {x i 0:t+1 } N i=1 from a proposal distribution q(x 0:t |y 1:t , θ) and by correcting the weights of the resulting empirical density. The correction step comes from an importance sampling argument, thus the unnormalized particles weights § are defined as follows § Note that importance sampling requires to know the importance and the target distributions up to a proportionality constant, thus the unnormalized weights may not sum to one. However normalized importance sampling weights can be easily obtained as follows wi t = w i t N j=1 w j t i = 1, . . . , N and t = 1, . . . , T.</p><formula xml:id="formula_71">w i t+1 ∆ = p(x i 0:t+1 |y 1:t+1 , θ) q(x i 0:t+1 |y 1:t+1 , θ) . (<label>61</label></formula><formula xml:id="formula_72">)</formula><p>The key idea used in SIS consists in obtaining a recursive relation for the weights updating. This property makes them particulary appealing for on-line applications.</p><p>Assume that the dynamic model of interest is the one described by equations ( <ref type="formula" target="#formula_18">17</ref>), ( <ref type="formula" target="#formula_19">18</ref>) and ( <ref type="formula" target="#formula_20">19</ref>) and choose the importance density to factorize as follows: q(x 0:t+1 |y 1:t+1 , θ) = q(x 0:t |y 1:t , θ)q(x t+1 |x 0:t , y 1:t+1 , θ), then, using the Bayes rule and the Markov property of the system, the weights can be rewritten in a recursive form w t+1 ∆ = p(x 0:t+1 |y 1:t+1 , θ) q(x 0:t+1 |y 1:t+1 , θ) = Bayes = p(x 0:t+1 , y t+1 |y 1:t , θ) q(x 0:t+1 |y 1:t+1 , θ)p(y t+1 |y 1:t , θ) = = p(x 0:t |y 1:t , θ)p(x t+1 , y t+1 |y 1:t , x 0:t , θ) q(x 0:t+1 |y 1:t+1 , θ)p(y t+1 |y 1:t , θ) = = p(x 0:t |y 1:t , θ) q(x 0:t+1 |y 1:t+1 , θ) p(y t+1 |x 0:t+1 , y 1:t , θ) p(y t+1 |y 1:t , θ) p(x t+1 |x 0:t , y 1:t , θ) = (62)</p><p>M arkov = p(x 0:t |y 1:t , θ) q(x 0:t+1 |y 1:t+1 , θ) p(y t+1 |x t+1 , θ) p(y t+1 |y 1:t , θ) p(x t+1 |x t , θ) = = p(x 0:t |y 1:t , θ) q(x 0:t |y 1:t , θ) p(y t+1 |x t+1 , θ)p(x t+1 |x t , θ) p(y t+1 |y 1:t , θ)q(x t+1 |x 0:t , y 1:t+1 , θ) = = w t p(y t+1 |x t+1 , θ)p(x t+1 |x t , θ) p(y t+1 |y 1:t , θ)q(x t+1 |x 0:t , y 1:t+1 , θ) .</p><p>Thus for the i-th particle, the weight updating recursive relation is</p><formula xml:id="formula_73">w i t+1 ∝ w i t p(y t+1 |x i t+1 , θ)p(x i t+1 |x i t , θ) q(x i t+1 |x i t , y t+1 , θ)<label>(63)</label></formula><p>Moreover, if we assume that the importance density for the state x t+1 is the transition density: q(x t+1 |x t , y t+1 , θ) = p(x t+1 |x t , θ), then equation (63) simplifies to</p><formula xml:id="formula_74">w i t+1 ∝ w i t p(y t+1 |x i t+1 , θ). (<label>64</label></formula><formula xml:id="formula_75">)</formula><p>Example 3 -(SV Model and SIS algorithm, Example 1 continued)</p><p>The normalization procedure causes the loss of the unbiasness property because the quantity at the denominator is a random variable.</p><p>The first aim of this example is to show how sequential importance sampling applies to a specific Bayesian dynamic model. We consider the SV model introduced through the example 1. In the following, we assume that the parameters are known, because we want to study how SIS algorithms work just for filtering the log-volatility. The second aim of this example, is to evidence the degeneracy problem, which arises in using SIS algorithms. Given the initial weighted particle set h i t , w i t , the SIS filter performs the following steps By applying the SIS algorithm to the synthetic data, simulated in Example 1, we obtain the filtered log-volatility represented in Fig. <ref type="figure" target="#fig_1">10</ref>. Note that after some iterations the filtered logvolatility does not fit well to the true log-volatility. The Root Mean Square Error (RMSE) defined as</p><formula xml:id="formula_76">(i) Simulate h i t+1 ∼ N h t+1 |ν + φh i t ,</formula><formula xml:id="formula_77">RM SE t = t u=1 ( hu -h u ) 2 t 1 2 ,<label>(65)</label></formula><p>measures the distance between the true and the filtered series. In the Fig. <ref type="figure" target="#fig_1">11</ref> the RMSE cumulates rapidly over time. Moreover, the same figure exhibits the estimated variance of the particle weights. This indicator shows how the SIS algorithm degenerates after 430 iterations. The discrete probability mass concentrates on one particle, the others particle having null probability.</p><p>As evidenced in Example 3 and as it is well known in the literature (see for example Arulampalam, Maskell, Gordon and Clapp <ref type="bibr" target="#b0">[1]</ref>), basic SIS algorithms have a degeneracy problem. After some iterations the empirical distribution degenerates into a single particle, because the variance of ( )  the importance weights is non-decreasing over time (see Doucet et al. <ref type="bibr" target="#b13">[14]</ref>). In order to solve the degeneracy problem, the Sampling Importance Resampling (SIR) algorithm has been introduced by Gordon, Salmond and Smith <ref type="bibr" target="#b16">[17]</ref>. This algorithm belongs to a wider class of bootstrap filters, which use a re-sampling step to generate a new set of particles with uniform weights. This step introduces diversity in particle set, avoiding degeneracy. In Algorithm 6, we give a pseudo-code representation of this method. Note that in the SIR particle filter, we assumed q(x t+1 |x i t , y t+1 , θ) = p(x t+1 |x i t , θ). Moreover, due to the resampling step, the weights are uniformly distributed over the particle set: w i t = 1/N , thus the weights updating relation becomes: wi t+1 ∝ w i t p(y t+1 |x i t+1 , θ) ∝ p(y t+1 |x i t+1 , θ). However, the basic SIR algorithm produces a progressive impoverishment (loss of diversity) of the information contained in the particle set, because of the resampling step and of the fact that particles do not change over filter iterations.</p><p>Many solutions have been proposed in literature. We recall the Regularised Particle Filter proposed by Musso, Oudjane and LeGland <ref type="bibr" target="#b33">[34]</ref>, which is based on a discretisation of the continuous state space. Gilks and Berzuini <ref type="bibr" target="#b3">[4]</ref> propose the SIR-Move algorithm, which moves particles after the re-sampling step. Thus, particle value changes and the impoverishment is partially avoided. Finally, Pitt and Shephard <ref type="bibr" target="#b34">[35]</ref> introduce the Auxiliary Particle Filter (APF) and applied it to a Gaussian ARCH-type stochastic volatility model. They find that the auxiliary particle filter works well and that the sensibility to outliers is lower than in the basic filters. In the following we focus on the APF algorithm. In order to avoid re-sampling, the APF algorithm uses an auxiliary variable to select most representative particles and to mutate them through a simulation step. Then weights of the regenerated particles are updated through an importance sampling argument. In this way particles with low probability do not survive to the selection and the information contained in the particle set is not wasted. In particular the auxiliary variable µ i t contains and resumes the information on the previous particle set and it is used in the selection step to sample the random particle index. The basic idea of the APF is to refresh the particle set while reducing the loss of information due to this operation. Thus, the algorithm generates a new set of particles by jointly simulating the particle index i (selection step) and the selected particle value x t+1 (mutation step) from the reparameterised empirical filtering density, according to the following importance density q(x j t+1 , i j |y 1:t+1 , θ) = q(x j t+1 |y 1:t+1 , θ)q(i j |y 1:t+1 , θ) = p(x j t+1 |x i j , θ)(p(y t+1 |µ i j t+1 , θ)w i j t ) (67) for j = 1, . . . , N . Note that the index is sampled using weights which are proportional to the observation density conditional on a summary statistics on the initial particle set. In this way, less informative particles are discarded. The information contained in each particle is evaluated with respect to both the observable variable and the initial particle set. By following the usual importance sampling argument, the updating relation for the particle weights is   Note that, for simulating auxiliary variables i j , Pitt and Shephard <ref type="bibr" target="#b34">[35]</ref> suggest to use another proposal distributions, based on the Taylor expansion of the measurement distribution. By applying the APF algorithm to the synthetic data, simulated in Example 1, we obtain the filtered log-volatility represented in Fig. <ref type="figure" target="#fig_11">15</ref>. In Fig. <ref type="figure" target="#fig_12">16</ref>, the first graph on the left compares SIS, SIR and APF algorithms in terms of RMSE. Although the variability in the weights of the particle set and the RMSE are greater than in the SIR algorithm, there is not degeneracy and the performance of APF algorithm is superior than that one of the basic SIS algorithm. The poor performance of the APF with respect to the SIR algorithm evidence a well known problem of this kind of algorithm. When the transition density exhibits a high noise variance the use of APF does not improve filtering results.</p><formula xml:id="formula_78">w j t+1 ∆ = p(x j t+1 , i j |y 1:t+1 , θ) q(x j t+1 , i j |y 1:t+1 , θ) = p(x j t+1 |x i j , θ)p(y t+1 |x j t+1 , θ)w i j t p(x j t+1 |x i j , θ)p(y t+1 |µ i j t+1 , θ)w i j t<label>(68)</label></formula><p>We conclude this section another example of application of APF to a stochastic volatility model with jumps. As done in previous examples we assume that parameters are known. One of the main issues in particle filtering is the inclusion of the parameter estimation in the sequential learning process. We refer to Berzuini et al. <ref type="bibr" target="#b2">[3]</ref> and Storvik <ref type="bibr" target="#b40">[41]</ref> for a general discussion of the problem and to Liu and West <ref type="bibr" target="#b26">[27]</ref> for an example of joint use of the adaptive importance sampling and auxiliary particle filter.</p><p>Example 6 -(APF and MSSV Models, example in Section 2.2 continued) The aim of this example is to show how particle filter algorithms apply to Markov switching stochastic volatility models. In these models latent factor represents the log-volatility of observed variable and the switching states are the volatility phases (high or low) of the financial market. We apply APF algorithm to synthetic data in order to show the efficiency of the algorithm and to detect possible degeneracy of the weights. We use a set of N = 3, 000 particles to obtain empirical filtering and prediction densities. All computation have been carried out on a Pentium IV 2.4 Ghz, and the APF algorithm has been implemented in GAUSS 3.2.8. Figure <ref type="figure" target="#fig_1">17</ref> shows on-line estimation of the latent factor x t and of the switching process s t . In order to detect the absence of degeneracy in the output of the APF algorithm we evaluate at each time step particle weights variance. Graph 18 shows the RMSE and the weights variance at each time step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work we describe the Bayesian approach to general dynamic models analysis. We review the literature on the latent factor dynamic models, focusing on the Bayesian approach and discussing general filtering, predicting and smoothing relations. Moreover we recognize the importance of simulation based methods in Bayesian inference. Furthermore, we provide a review of the Bayesian simulation based methods for inference and develop some examples on simulation based filtering for stochastic volatility models. The main features of traditional MCMC methods, like single-move and multi-move Gibbs sampler have been discussed. Moreover, sequential Monte Carlo methods, such as adaptive importance sampling algorithm have been introduced. Finally we compare the basic sequential importance sampling algorithm and other recently developed sequential techniques, like particle filters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Simulated paths of 1,000 observations from the observable process y t , with time varying volatility and of the stochastic volatility process h t . We simulate the model given in Example 1 by setting φ = 0.9, ν = 0.1 and σ 2 = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>y 1 :</head><label>1</label><figDesc>T , available at time T p(x 0:T |y 1:T , θ) = = p(x T |y 1:T , θ)p(x 0:T -1 |x T , y 1:T , θ) = = p(x T |y 1:T , θ)p(x T -1 |x T , y 1:T , θ)p(x 0:T -2 |x T -1:T , y 1:T , θ) = Bayes = p(x T |y 1:T , θ) p(y T |x T -1:T , y 1:T -1 , θ)p(x T -1 |x T , y 1:T -1 , θ) p(y T |x T , y 1:T -1 , θ) p(x 0:T -2 |x T -1:T , y 1:T , θ) = M arkov = p(x T |y 1:T , θ) p(y T |x T , y 1:T -1 , θ)p(x T -1 |x T , y 1:T -1 , θ) p(y T |x T , y 1:T -1 , θ) p(x 0:T -2 |x T -1:T , y 1:T , θ) = (25) = p(x T |y 1:T , θ)p(x T -1 |x T , y 1:T -1 , θ)p(x 0:T -2 |x T -1 , y 1:T , θ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Simulation of the Markov switching stochastic volatility model M 1 (α 1 = -2.5, α 2 = -1, φ = 0.5, σ 2 = 0.1, p 11 = 0.99, p 22 = 0.975). The left upper graph exhibits the evolution of the hidden jump process, the right upper graph shows the log-volatility of the observable process, which is represented in the third graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Sample of 50,000 parameter values simulated from the posterior distributions of the stochastic volatility model, through the single-move Gibbs sampler.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 : 8 :</head><label>78</label><figDesc>Figure 7: The graph exhibits the autocorrelation functions, ρ φ , ρ ν and ρ σ 2 , with lags n = 1, . . . , 100, calculated on the 50,000 parameter values simulated from the posterior distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Simulate state vectors by means of the recursive factorization of the smoothing density 9. x (i+1) T ∼ p(x T |y 1:T , θ (i+1) ) 10. x (i+1) T -1 ∼ p(x T -1 |x (i+1) T , y 1:T -1 , θ (i+1) ) 11. . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>t+1 |y 1:t+1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Particles evolution in the SIS particle filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :Figure 11 :</head><label>1011</label><figDesc>Figure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>FilteringFigure 12 :</head><label>12</label><figDesc>Figure 12: Particles evolution in the SIR particle filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 15 :</head><label>15</label><figDesc>Figure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 16 :.</head><label>16</label><figDesc>Figure 16: The first graph on the left compares SIS, SIR and APF algorithms in terms of Root Means Square Error between true and filtered log-volatility. The second graph shows the estimated particle weight variance, which allows us to detect degeneracy of the filter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>as follow p(y t+K |y 1:t , θ) = Y p(y t+K |x t+K , y 1:t+K-1 , θ)p(dy t+1:t+K-1 |y 1:t , θ)p(dx t+K |y 1:t , θ)</head><label></label><figDesc>product of the state space. Similarly, the K-steps-ahead prediction density of the observable variable y t+K conditional on the information available at time t is determined</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>t+1:T |x -t , y 1:t , θ)p(x t |x -t , y 1:t , θ) p(y t+1:T |x -t , y 1:t , θ) = = p(x t |x -t , y 1:t , θ).</figDesc><table><row><cell></cell><cell>y t+1:T |x -t , y 1:t , θ) p(y t+1:T |x -t , y 1:t , θ)</cell><cell>=</cell></row><row><cell>=</cell><cell cols="2">p(y t+1:T |x 0:T , y 1:t , θ)p(x t |x -t , y 1:t , θ) p(y t+1:T |x -t , y 1:t , θ)</cell><cell>=</cell></row><row><cell>=</cell><cell>p(y</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>due to this property of the posterior density, the implementation of the single-move Gibbs sampling algorithm becomes easier.</figDesc><table><row><cell>and Example 2 -(Stochastic Volatility Model, Example 1 continued)</cell></row></table><note><p><p><p><p>x t+1:T |x 0:t , y 1:t , θ)p(y t |x t , y 1:t-1 , θ)p(x t |x t-1 , y 1:t-1 , θ) p(x t+1:T , y t |x 0:t-1 , y 1:t-1 , θ) .</p>The full posterior density of the t-th state vector is thus proportional to</p>p(x t |x -t ,</p>y 1:t , θ) ∝ ∝ p(x t+1:T |x 0:t , y 1:t , θ)p(y t |x t , y 1:t-1 , θ)p(x t |x t-1 , y 1:t-1 , θ) = = p(x t+2:T |x 0:t+1 , y 1:t , θ)p(x t+1 |x 0:t , y 1:t , θ)p(y t |x t , y 1:t-1 , θ)p(x t |x t-1 , y 1:t-1 , θ) = M arkov = p(x t+2:T |x 0:t+1 , y 1:t , θ)p(x t+1 |x t , y 1:t , θ)p(y t |x t , y 1:t-1 , θ)p(x t |x t-1 , y 1:t-1 , θ) ∝ ∝ p(x t+1 |x t , y 1:t , θ)p(y t |x t , y 1:t-1 , θ)p(x t |x t-1 , y 1:t-1 , θ).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 :</head><label>1</label><figDesc>Bayesian estimates of the parameters φ, ν and σ 2 . We use a burn-in sample of 10,000 observations and calculate the parameter estimates by averaging 40,000 raw values simulated from the posterior distributions, by means of the Gibbs sampler.</figDesc><table><row><cell cols="6">Parameters True Estimates St. Dev. 2.5% percentile 97.5% percentile</cell></row><row><cell>φ</cell><cell>0.9</cell><cell>0.9096</cell><cell>0.0146</cell><cell>0.8813</cell><cell>0.9370</cell></row><row><cell>ν</cell><cell>0.1</cell><cell>0.0754</cell><cell>0.0350</cell><cell>0.0048</cell><cell>0.1382</cell></row><row><cell>σ 2</cell><cell>1</cell><cell>1.0075</cell><cell>0.0313</cell><cell>0.9487</cell><cell>1.0712</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Note that the empirical filtering density given in Eq. (57) is a mixture of distributions, which can be reparameterised by introducing an auxiliary variable i ∈ {1, . . . , N }, which indicates the component of the mixture. The joint distribution of the hidden state and of the index i is</figDesc><table><row><cell>p(x t+1 , i|y 1:t+1 , θ) =</cell><cell cols="4">p(y t+1 |y 1:t , x t+1 , i) p(y t+1 |y 1:t , θ)</cell><cell>p(x t+1 , i|y 1:t , θ) =</cell><cell>(66)</cell></row><row><cell>=</cell><cell cols="4">p(y t+1 |x t+1 , θ) p(y t+1 |y 1:t , θ)</cell><cell>p(x t+1 |i, y 1:t , θ)p(i|y 1:t , θ) =</cell></row><row><cell>=</cell><cell cols="3">p(y t+1 |x t+1 , θ) p(y t+1 |y 1:t , θ)</cell><cell>p(x t+1 |x i t , θ)w i t .</cell></row><row><cell cols="3">Algorithm 6 -SIR Particle Filter -</cell><cell></cell></row><row><cell cols="5">Given the initial set of particles {x i t , w i t } N i=1 , for i = 1, . . . , N :</cell></row><row><cell cols="3">1. Simulate xi t+1 ∼ q(x t+1 |x i t , y t+1 , θ)</cell><cell></cell></row><row><cell cols="3">2. Update the weights: wi t+1 ∝ p(y t+1 |x i t+1 , θ)</cell><cell></cell></row><row><cell cols="3">3. Normalize the weights: wi t+1 = wi t+1 ( N j=1</cell><cell cols="2">wj t+1 ) -1 , for i = 1, . . . , N .</cell></row><row><cell cols="5">4. Simulate {x i t+1 } N i=1 from the empirical density {x i t , wi t } N i=1</cell></row><row><cell cols="3">5. Assign w i t+1 = 1/N , for i = 1, . . . , N .</cell><cell></cell></row><row><cell cols="3">Algorithm 7 -Auxiliary Particle Filter -</cell><cell></cell></row><row><cell cols="5">Given the initial set of particles {x j t , w j t } N j=1 , for j = 1, . . . , N :</cell></row><row><cell>1. Calculate µ j t+1 = E(x t+1 |x j t , θ)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">2. Simulate i j ∼ q(i|y 1:t+1 , θ) ∝ w i t p(y t+1 |µ i t+1 , θ) with i ∈ {1, . . . , N }</cell></row><row><cell>3. Simulate x j t+1 ∼ p(x t+1 |x i j t , θ)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">4. Update particles weights: wj t+1 ∝</cell><cell cols="3">p(y t+1 |x j t+1 ,θ) p(y t+1 |µ i j t+1 ,θ)</cell><cell>.</cell></row><row><cell cols="3">5. Normalize the weights: w i t+1 = wi t+1 ( N j=1</cell><cell cols="2">wj</cell></row></table><note><p>t+1 ) -1 , for i = 1, . . . , N .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>In Algorithm 7 we give a pseudo-code representation of the Auxiliary Particle Filter. In Examples 4 and 5 we show how resampling can improve the performance of the basic SIS algorithm. In particular, we apply SIR and APF algorithms to the stochastic volatility model, illustrated in Example 1 and make a comparison between them, in terms of Root Means Square Error and of variance of the particle weights. Finally in Example 6 we show ho APF applies to the double latent structure of the MSSV model given in sectioin 2.2.</figDesc><table><row><cell cols="4">Example 4 -(SV Model and SIR algorithm, Example 3 continued)</cell></row><row><cell cols="4">In this example we show how the selection (or resampling) step can improve the performance of</cell></row><row><cell cols="4">the basic Sequential Importance Sampling algorithm when applied to the Stochastic Volatility</cell></row><row><cell>model given in Example 1.</cell><cell></cell><cell></cell></row><row><cell cols="4">In order to implement SIR algorithm we introduce a resampling step after the propagation of</cell></row><row><cell cols="2">the initial set of particle h i t , w i t = 1/N</cell><cell cols="2">N i=1 . The steps of the SIR are</cell></row><row><cell cols="3">(i) Simulate hi t+1 ∼ N h t+1 |ν + φh i t , σ 2</cell></row><row><cell>(ii) Update the weights</cell><cell></cell><cell></cell></row><row><cell cols="4">wi t+1 ∝ w i t p(y t+1 | hi t+1 , θ) ∝</cell></row><row><cell cols="3">∝ w i t exp -</cell><cell>1 2</cell><cell>y 2 t+1 e -hi t+1 + hi</cell></row><row><cell>=</cell><cell cols="3">p(y t+1 |x j t+1 , θ) p(y t+1 |µ i j t+1 , θ)</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A Tutorial on Particle Filters for On-line Nonlinear/Non-Gaussian Bayesian Tracking</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arulampalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maskell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Clapp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
		<respStmt>
			<orgName>QinetiQ Ltd., DSTO</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Bauwens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lubrano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Richard</surname></persName>
		</author>
		<title level="m">Bayesian Inference in Dynamic Econometric Models</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic conditional independence models and Markov chain Monte Carlo Methods</title>
		<author>
			<persName><forename type="first">C</forename><surname>Berzuini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Gilks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Larizza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="1403" to="1441" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Following a moving average-Monte Carlo inference for dynamic Bayesian models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Berzuini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Gilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J.R. Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="127" to="146" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Population Monte Carlo for ion channel restoration</title>
		<author>
			<persName><forename type="first">O</forename><surname>Capp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guillin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Monte Carlo Approach to Nonnormal and Nonlinear State-Space Modelling</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Stoffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="493" to="500" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On Gibbs Sampling for State Space Models</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Köhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="541" to="553" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bayesian Inference for Generalised Markov Switching Stochastic Volatility Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Casarin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>working paper, CEREMADE, forthcoming</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Iterated importance sampling in missing data problems</title>
		<author>
			<persName><forename type="first">G</forename><surname>Celeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Cahiers du Ceremade</publisher>
			<biblScope unit="page">326</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Markov chains Monte Carlo methods for stochastic volatility models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nardari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shephard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="281" to="316" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Convergence of sequential Monte Carlo methods</title>
		<author>
			<persName><forename type="first">D</forename><surname>Crisan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno>381</idno>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>CUED-F-INFENG</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Simulation Smoother for Time Series Models</title>
		<author>
			<persName><forename type="first">De</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shephard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="339" to="350" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Sequential Monte Carlo Methods in Practice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On sequential Monte Carlo sampling methods for Bayesian filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Godsill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Andrieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="197" to="208" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Durbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Koopman</surname></persName>
		</author>
		<title level="m">Time Series Analysis by State Space Methods</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Data augmentation and dynamic linear models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Frühwirth-Schnatter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Time Series Analysis</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Novel Approach to Nonlinear and Non-Gaussian Bayesian State Estimation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEE Proceedings-F</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<date type="published" when="1993">1993. 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimation bayesienne approximative par echantillonnage preferentiel</title>
		<author>
			<persName><forename type="first">A</forename><surname>Guillin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Revue de Statistique Applique</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Time Series Analysis</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Harvey</surname></persName>
		</author>
		<title level="m">Forecasting, structural time series models and the Kalman filter</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
		<title level="m">Bayesian Forecasting and Dynamic Models</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A new approach to linear filtering and prediction problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Basic Engineering, Transaction ASME, Series D</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">New results in linear filtering and prediction problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Bucy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transaction of the ASME-Journal of Basic Engineering, Series D</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Nelson</surname></persName>
		</author>
		<title level="m">State-Space Models with Regime Switching</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Stochastic volatility: likelihood inference and comparison with arch models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shephard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review of Economic Studies</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="361" to="393" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sequential Monte Carlo Methods for Dynamical System</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1032" to="1044" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Combined Parameter and State Estimation in Simulation Based Filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
		<editor>Sequential Monte Carlo Methods in Practice eds. Doucet A., Freitas J.G. and Gordon J.</editor>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Covariance structure of the Gibbs sampler with applications to the comparison of estimators and augmentation schemes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="27" to="40" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Correlation structure and convergence rate of the Gibbs sampler with various scans</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society B</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="157" to="169" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Maybeck</surname></persName>
		</author>
		<title level="m">Stochastic Models, Estimation and Control</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Maybeck</surname></persName>
		</author>
		<title level="m">Stochastic Models, Estimation and Control</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Maybeck</surname></persName>
		</author>
		<title level="m">Stochastic Models, Estimation and Control</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Alternatives to the Gibbs sampling scheme</title>
		<author>
			<persName><forename type="first">P</forename><surname>Müller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
		<respStmt>
			<orgName>Institute of Statistics and Decision Sciences, Duke University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Improving Regularised Particle Filters</title>
		<author>
			<persName><forename type="first">C</forename><surname>Musso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oudjane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Legland</surname></persName>
		</author>
		<editor>Doucet A., Freitas J.G. and Gordon J.</editor>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Filtering via Simulation: Auxiliary Particle Filters</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shephard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">446</biblScope>
			<biblScope unit="page" from="590" to="599" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The Bayesian Choice, 2nd ed</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<title level="m">Monte Carlo Statistical Methods</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Partial non-Gaussian state space</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shephard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="115" to="131" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">N</forename><surname>Shephard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Pitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="653" to="667" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A stochastic volatility model with Markow switching</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K P</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business &amp; Economic Statistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="244" to="253" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Particle filters for state space models with the presence of unknown static parameters</title>
		<author>
			<persName><forename type="first">G</forename><surname>Storvik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="281" to="289" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The calculation of posterior distributions by data augmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="528" to="550" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Markov chains for exploring posterior distributions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tierney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. of Statist</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1701" to="1786" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Mixture models, Monte Carlo, Bayesian updating and dynamic models</title>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science and Statistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="325" to="333" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Approximating posterior distribution by mixtures</title>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Royal Statistical Society, B</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="409" to="442" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
