<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Full Event Particle-Level Unfolding with Variable-Length Latent Variational Diffusion</title>
				<funder ref="#_NjQkHMP">
					<orgName type="full">DOE</orgName>
				</funder>
				<funder ref="#_Waj28R2">
					<orgName type="full">ARO</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-01-23">23 Jan 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Shmakov</surname></persName>
							<email>ashmakov@uci.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<country>Irvine</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Greif</surname></persName>
							<email>kgreif@uci.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<country>Irvine</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">James</forename><surname>Fenton</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<country>Irvine</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aishik</forename><surname>Ghosh</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<country>Irvine</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Physics Division</orgName>
								<orgName type="laboratory">Lawrence Berkeley National Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pierre</forename><surname>Baldi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<country>Irvine</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Whiteson</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<country>Irvine</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Full Event Particle-Level Unfolding with Variable-Length Latent Variational Diffusion</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-01-23">23 Jan 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2404.14332v3[hep-ex]</idno>
					<note type="submission">Received Date Accepted Date Published Date</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The measurements performed by particle physics experiments must account for the imperfect response of the detectors used to observe the interactions. One approach, unfolding, statistically adjusts the experimental data for detector effects. Recently, generative machine learning models have shown promise for performing unbinned unfolding in a high number of dimensions. However, all current generative approaches are limited to unfolding a fixed set of observables, making them unable to perform full-event unfolding in the variable dimensional environment of collider data. A novel modification to the variational latent diffusion model (VLD) approach to generative unfolding is presented, which allows for unfolding of high-and variable-dimensional feature spaces. The performance of this method is evaluated in the context of semi-leptonic t t production at the Large Hadron Collider.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Particle interactions can reveal new particles and forces, and allow for measurements of the parameters of theories that explain their dynamics. The detectors that measure the final state particles produced by such interactions have limited resolution and efficiency, introducing detector effects that must be accounted for in any statistical inference, for example via a simulator <ref type="bibr" target="#b0">[1]</ref>. However, high-fidelity simulations of modern detectors are not universally accessible and are extremely computationally expensive <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. An alternative approach, unfolding, is to correct the observed data for the effect of the detectors. This allows for statistical inference without access to the expensive detector simulator, and enables easier comparison of data from different experiments or with new theory predictions.</p><p>Traditional unfolding techniques <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref> simplify this challenging task by binning data in a set of pre-selected quantities. These binned unfolding techniques become unfeasible as the number of dimensions grows beyond one or two, due to the curse of dimensionality <ref type="bibr" target="#b8">[9]</ref>. Recent advances in machine learning (ML) have enabled unbinned unfolding in many dimensions. These methods fall into two categories: discriminative methods that train classifiers to reweight synthetic data distributions to an estimate of the truth level distributions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, and generative methods that model the distribution of a set of truth level observables given the corresponding detector level distributions <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref>. Ideally, these methods would enable full-event unfolding, in which the kinematics of every final state particle are unfolded. The resulting unfolded datasets could be used to measure any observable without the need for expensive detector simulation, and even long after the experiment has been concluded. Since the number of particles in a final state can vary significantly due to inherently random processes, the ability to handle variable dimensionality events is a crucial element of true full-event unfolding. Discriminative methods have successfully performed high-dimensional (up to O(100) target observables) and variable-dimensional unbinned unfolding <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref>. However, these methods may struggle in regions where the number of observed events is small. Because generative approaches require only synthetic data during training, their performance might be less sensitive to the number of observed events<ref type="foot" target="#foot_0">foot_0</ref> -however, handling variable dimensions can be a formidable challenge for existing generative unfolding methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>Recently, Variational Latent Diffusion (VLD) models <ref type="bibr" target="#b17">[18]</ref> were introduced and shown to be a powerful generative approach for unfolding a fixed number of observables. In this paper, the VLD approach to unfolding is extended to a variable dimensional set of observables, enabling full-event unfolding even when the number of observed events is small. Full event unfolding with variable dimensionality is demonstrated for measuring top quark pair production, a common use-case of unfolding algorithms for experiments at the Large Hadron Collider.</p><p>One potential shortcoming of unfolding methods optimized only on simulations is the unfolded distribution's dependence on the prior distribution used to construct training data. If necessary, an iterative method first proposed in Ref. <ref type="bibr" target="#b13">[14]</ref> can be applied to mitigate this dependence on the training set prior. This paper assess the prior dependence of a VLD model by evaluating it over an alternative testing set which contains shifts in the truth particle level distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Unfolding methods aim to sample from a truth distribution f truth (x), where truth refers to an unobserved state of interest to physicists. The observations include distortions introduced by the detector systems, and it is desirable to correct the measured data to remove these effects. Having only access to the observed detector-level data set y = { y i } with distribution f det ( y), an unfolding method aims to learn the response function p( y|x) which connects the two:</p><formula xml:id="formula_0">f det ( y) = d x p( y|x) f truth (x)<label>(1)</label></formula><p>The response function itself is unknown, but (x, y) pairs can be produced through Monte-Carlo (MC) simulation. The truth distribution f truth (x) can be recovered via the corresponding inverse process if one has access to the posterior, a pseudo-inversion of the response function p(x| y):</p><formula xml:id="formula_1">f truth (x) = d y p(x| y) f det ( y)<label>(2)</label></formula><p>The strategy of most generative unfolding methods is to build the posterior as a generative model trained on (x, y) pairs <ref type="foot" target="#foot_1">2</ref> , which can be used to sample from p(x| y) and obtain the truth distribution via Equation <ref type="formula" target="#formula_1">2</ref>. An important issue when choosing to directly model the posterior is that this quantity is itself dependent on the desired distribution f truth (x), the prior in Bayes' theorem:</p><formula xml:id="formula_2">p(x| y) = p( y|x) f truth (x) f det ( y)<label>(3)</label></formula><p>Producing the sample of simulated data used to train the generative model requires choosing a specific f truth (x), which influences the learned posterior. In application to new datasets, this may lead to an unreliable estimate of the posterior density if the assumed prior is far enough from the truth distribution. A common method to overcome this challenge is to apply an iterative procedure, in which the assumed prior is re-weighted to match the approximation to the truth distribution provided by the unfolding algorithm <ref type="bibr" target="#b5">[6]</ref>. Though application of this iterative procedure is not shown in this paper, the principle has been well-established for other generative unfolding methods <ref type="bibr" target="#b22">[23]</ref>, for which the conditions are similar.</p><p>In collider physics, there are multiple truth distributions of interest which could in principle be inferred from the detector level distribution. Ref. <ref type="bibr" target="#b17">[18]</ref> applied VLD to parton-level unfolding; partons are intermediate particles produced directly from the hard scatter process but before the parton shower and hadronization processes <ref type="bibr" target="#b23">[24]</ref>. For parton-level unfolding, the pseudoinversion of the response function p(x| y) then contains the pseudo-inversion of both the detector response and the parton shower and hadronization processes.</p><p>In contrast to the parton showering and hadronization, the response of the detector to the final state particles from a collision event is very well modeled by simulators and generally independent of the hard-scatter process which produced the particles. Therefore it is usually preferable to unfold to particle-level: the set of stable particles directly before interaction with the detector. After identifying the stable leptons, the remaining stable particles can be clustered into jets. VLD is applied to particle-level unfolding in this paper, using the leptons and jets as targets. In contrast to the fixed dimensionality of parton-level unfolding, a particle-level event is of an inherently variable dimensionality since it must also describe jets that result from random processes such as initial-and final-state radiation. In this paper, VLD is modified to accommodate a variable dimension output, making it the first generative unfolding method with this capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>Diffusion models are a class of generative models which have excelled in learning highdimensional probability distributions at high fidelity. They have been applied to a variety of generative tasks within high energy physics (HEP), including event generation <ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref>, calorimeter shower simulation <ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref>, anomaly detection <ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref>, likelihood estimation <ref type="bibr" target="#b42">[43]</ref>, and unfolding <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref> . They involve formulating a diffusion process in which samples from a data distribution are mapped to a pure noise distribution through addition of (usually Gaussian) noise, parameterized by a time step t ∈ [0, 1]. In a standard formulation of the diffusion model <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref>, a neural network is trained to predict the added noise, conditioned on the original data sample and the time step t. The output of this model can then be used to reverse the diffusion process, allowing samples from the pure noise distribution to be mapped to a sample from the underlying distribution from which the training data is sampled. Many recent papers have improved the diffusion process, including a reinterpretation of the diffusion process as a stochastic differential flow <ref type="bibr" target="#b45">[46]</ref>, improvements in the solver used to generate samples from a learned flow <ref type="bibr" target="#b46">[47]</ref>, and moving the diffusion process into an abstract latent space <ref type="bibr" target="#b47">[48]</ref>.</p><p>Ref. <ref type="bibr" target="#b17">[18]</ref> introduced variational latent diffusion models (VLD) which combine the interpretation of a diffusion model as a hierarchical sequence of variational autoencoders (VAEs) <ref type="bibr" target="#b48">[49]</ref> from Ref. <ref type="bibr" target="#b49">[50]</ref> with the latent diffusion <ref type="bibr" target="#b47">[48]</ref> approach of operating the diffusion process within the learned latent space of a pre-trained VAE. The combination of these ideas allowed the construction of a conditional generative model in which both the VAE, which defines the latent space, and the diffusion model can be trained together in an end-to-end variational framework.</p><p>In this section, an extension of the VLD model is introduced, designed to unfold to a variable dimensional truth distribution, conditioned upon a variable dimensional detector-level distribution. Formally, the particle level unfolding problem is learning the distribution of a set of objects X = {x 1 , x 2 , . . . , x N } conditioned on another set of objects Y = { y 1 , y 2 , . . . , y M }. It is crucial to note that the correspondences between entities in these sets are not strictly and detector level (O D ) events are used to train the model using the loss functions introduced in Ref. <ref type="bibr" target="#b17">[18]</ref>. At inference time, a detector level event is used to produce a multiplicity prediction and mapped to a latent embedding through the detector encoder. The multiplicity prediction and the latent representation of the detector level event are then used to condition the diffusion process, resulting in a sample from the latent space of the particle VAE. A particle decoder is then applied to produce a sample from the learned conditional distribution P(X |Y ). During training, the particle encoder is used to produce latent samples instead of the diffusion process. The special vector y 0 is a learnable input vector trained alongside the network weights.</p><p>one-to-one and the cardinalities of these sets may differ: M ̸ = N . VLD is designed to learn the distribution P(X |Y ), which is conditional on all information in the set of objects Y and captures the correlations between the individual elements of X . The latent space of the VAE is adapted to optimize the diffusion process, rather than being held fixed as the noise prediction network is trained. A diagram of the model is shown in Figure <ref type="figure" target="#fig_0">1</ref>, and the individual components are described below.</p><p>Similarly to Ref. <ref type="bibr" target="#b17">[18]</ref>, the distributions are defined over a learned latent space X = f P (O P ), derived from the original particle-level observations O P with the help of a VAE. A similar mapping is learned for the conditioning set, derived from the detector-level observables with the help of a detector encoder Y = f D (O D ). The VAE, detector encoder, and diffusion components are trained as part of an end-to-end training scheme similar to Ref. <ref type="bibr" target="#b17">[18]</ref>, but with the addition of a multiplicity predictor, described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Particle VAE</head><p>The Particle VAE, consisting of an encoder and a decoder, is designed to learn an efficient mapping from the low-level observables of particle-level events into a latent space optimized for the diffusion process. Given the variable length nature of particle level events, a transformer <ref type="bibr" target="#b50">[51]</ref> is used as the underlying architecture for both networks. Each event is comprised of observables associated with individual particle-level objects, along with global observables that encapsulate the entire event's properties. The encoder inputs include a set of N particle-level objects, represented as P P i ∈ D Particle for each object, complemented by a one-hot encoded vector T P i ∈ {0, 1} D Type , which specifies the type of the particle object. Additional event-level observables are denoted as</p><formula xml:id="formula_3">E P ∈ D Event .</formula><p>The set of observables for each particle-level object is denoted ÕP = O P 1 , O P 2 , . . . , O P N , where O P i = (P P i ||T P i ) represents concatenated kinematics and type vectors. The event-level observables are incorporated as an additional input vector, O P 0 = E P , ensuring the encoder receives a complete description of the event O P = O P 0 , O P 1 , . . . , O P N . This input set is processed through a transformer encoder model that is position-equivariant, acknowledging that the particle objects within a collision event possess no intrinsic order. The encoder produces a set X of N elements, each being a D LATENT dimensional latent vector x i , effectively mapping both the variable-length particle objects and fixed-length event observables into a unified latent space.</p><formula xml:id="formula_4">X = {x 0 , x 1 , x 2 , . . . , x N } where x i = TRANSFORMER ENCODER (O P ) i ∈ D LATENT .<label>(4)</label></formula><p>Unlike in Ref. <ref type="bibr" target="#b17">[18]</ref>, the latent space of the VAE is coupled directly to the diffusion process. Instead of predicting an independent σ from the VAE encoder, the learned diffusion noise schedule is used to determine the encoded vectors x 0 (0), and these noisy latent vectors are used for the decoder side of the VAE. The details and notation used to describe the diffusion process are presented below.</p><p>The decoder mirrors the encoder, employing a transformer to pre-process the encoded objects before outputting estimates for both the continuous kinematic features and the discrete object-type labels. Deep feed-forward multi-layer perceptrons (MLPs) are applied per-object to reconstruct these inputs, while the event observables are reconstructed using a separately parameterized MLP. The object-type MLP uses a softmax activation to produce a distribution over predicted object types.</p><formula xml:id="formula_5">w i = TRANSFORMER DECODER ([x 0 (0), x 1 (0), x 2 (0), . . . , x N (0)]) i ∈ D LATENT PP i = M L P P (w i ) for i ≥ 1 ∈ D PARTICLE TP i = Softmax(M L P T (w i )) for i ≥ 1 ∈ D TYPE ÊP = M L P E (w 0 ) ∈ D EVENT (5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Detector Encoder</head><p>The detector encoder employs an identical architecture to the Particle VAE encoder to encode the detector observations into the conditional latent space Y . The inputs are a cardinality M set of detector-level objects, each described by a vector of observables P D i together with a one-hot encoding of the object type T D i . These features are concatenated </p><formula xml:id="formula_6">O D i = (P D i ||T D i ),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multiplicity Predictor</head><p>To accommodate the generation of variable-length particle-level events, a regression network that predicts the distribution of particle multiplicity conditioned on the encoded detector observations is used. This step is critical for determining the appropriate number of objects to generate, as the generative problem is not guaranteed to contain a one-to-one mapping between detector and truth level objects.</p><p>Starting with the encoded detector features Y = { y 1 , y 2 , . . . , y M }, a new learnable vector y 0 ∈ D LATENT is appended, and the set is processed with a transformer to extract multiplicity features z in a manner similar to the class-attention block <ref type="bibr" target="#b51">[52]</ref>. Since the predictions are positive count values, a deep MLP is used to estimate the shape (k) and scale (θ ) parameters of a gamma distribution which can then be sampled from while unfolding an event.</p><formula xml:id="formula_7">z = TRANSFORMER MULTIPLICITY ({ y 0 , y 1 , y 2 , . . . , y M }) 0 N ∼ Gamma (M L P k (z), M L P θ (z))<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Latent Diffusion Process</head><p>The conditional distribution P(X |Y ) is learned via a diffusion model, following the formulation presented in Ref. <ref type="bibr" target="#b17">[18]</ref>, based on the variational diffusion model interpretation first introduced in Ref. <ref type="bibr" target="#b49">[50]</ref>, extended to operate on sets of objects. The intrinsically unordered nature of sets introduces a degree of ambiguity into the definition of the variable-length diffusion model and the training objective of the noise prediction model. These ambiguities are mitigated by imposing an arbitrary ordering on X at the diffusion stage of the network via a total ordering function O(x) ∈ . In the following diffusion definitions, it will be assumed that X is an ordered list of objects following the ordering function O, X = [x 0 , x 1 , x 2 , . . . , x N ], such that for all i &lt; j, O(x i ) &lt; O(x j ). This order will only affect the diffusion network, as all other components of the network are order equivariant.</p><p>The continuous time (t ∈ [0, 1]) diffusion flow is extended to an element-wise generalization of traditional diffusion by defining the list distribution flow as</p><formula xml:id="formula_8">X (t) = [x 0 (t), x 1 (t), x 2 (t), . . . , x n (t)] where x i (t) ∼ N (α i (t)x i , σ i (t) ).<label>(8)</label></formula><p>The traditional noise schedule of diffusion models is extended to multiple objects, with each position in the set defining its own schedule. The correct schedule is applied to the correct object by defining these schedules as a function of the object's position in X , which is fixed by the imposed ordering. A monotonic log signal-to-noise ratio (SNR) function, γ φ (i, t), is learned, where i ∈ and t ∈ [0, 1]. As in Ref. <ref type="bibr" target="#b17">[18]</ref>, the function is parameterized as a positive definite neural network trained to minimize the variance of the diffusion loss term. The flow parameters based on these noise schedules are defined as σ i (t) = sigmoid(-γ φ (i, t)) and α i (t) = sigmoid(γ φ (i, t)).</p><p>As this formulation is an element-wise extension of the traditional diffusion process, the forward and backward dynamics remain identical to the original VLD, although applied elementwise with each position's noise schedule. A system of Stochastic Differential Equations (SDEs) is defined as</p><formula xml:id="formula_9">d x i (t) = f (x i , t)d t + g(t)dw (Forward SDE) d x i (t) = f (x i , t) + g 2 (t) εθ (x i (t), X (t), Y, t) σ i (t) d t + d w (Reverse SDE)</formula><p>for each i ∈ {0, 1, 2, . . . , N }. A noise-prediction formulation is employed for the score network, with ∇ x i log p(x i ) = -1 2 εθ (x i (t), X (t), Y, t) <ref type="bibr" target="#b44">[45]</ref>. A key detail is that the denoising network (detailed below) depends not only on the conditioning Y and the current noisy latent vector x i (t), but on all other noisy latent samples in X (t) as well. This allows different generative components to share information with each other. This contextual information allows the denoising network to adjust its predictions based on the other objects currently being generated. Without these inputs, the denoising network could confuse objects with each other when the signal-to-noise ratio is low.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Particle Denoising Network</head><p>To address the challenges of modeling variable-length data and effectively predicting the noise in the context of diffusion models, a noise prediction function employing transformers, εθ (x i , X , Y, t), is used to learn a novel list-generative and set-conditioned denoising network. This network leverages an encoder-only transformer architecture, processing all noisy latent vectors x i (t) in parallel. By employing attention mechanisms, the network integrates both the Figure <ref type="figure">2:</ref> A simplified block diagram of the particle denoising network and all of the inputs. Each of the inputs is a pre-processed and concatenated collection of various features. We introduce a variable-length conditional noise-prediction model by providing the transformer with both the noisy particles, as well as the detector inputs. The detector outputs are ignored and the particle outputs are interpreted as the noise prediction. particle-level inputs, X , and the conditioning detector-level inputs, Y , enriching the denoising process with comprehensive contextual information.</p><p>For particle-level inputs, X (t) = [x 0 (t), x 1 (t), . . . , x N (t)], Fourier positional features P i are incorporated, following the method introduced in Ref. <ref type="bibr" target="#b50">[51]</ref>. Additionally, a unique learned flag vector, F P ∈ N , is appended to identify these inputs as noisy particle-level data. The network may need to adjust its outputs based on the specific stage of the diffusion process, so the current noise scale, σ i (t), is additionally included in the inputs.</p><p>A parallel pre-processing pipeline is applied to the conditioning set Y , adding position information and the detector-level flag vector to this input, F D ∈ M . Both sets of pre-processed inputs are then transformed via MLPs which map these inputs into the denoising transformer's hidden dimensionality, D DENOISE . This produces two lists of D DENOISE dimensional vectors, one of length N representing the particle level event at a time step t, and the other of length M representing the detector level event, P = [P 0 , P 1 , P 2 , . . . , P N ]</p><p>where</p><formula xml:id="formula_10">P i = M L P P (x i ||F P ||P i ||σ i (t)) , D = [D 1 , D 2 , . . . , D M ]</formula><p>where</p><formula xml:id="formula_11">D i = M L P D ( y i ||F D ||P i ) .</formula><p>The denoising network is then defined as the output of a transformer encoder with the two lists used as inputs. A block diagram of the denoising network and its inputs is shown in Figure <ref type="figure">2</ref>. The noise predictions are extracted by dropping the transformer outputs for the detector-level inputs and indexing the outputs by particle position. εθ (x i , X , Y, t) = TRANSFORMER(P||D) i (9)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Noise Schedule Network</head><p>The noise schedule log SN R is parameterized as a monotonically decreasing function with respect to time, conditioned on position, γ φ (i, t). Following <ref type="bibr" target="#b49">[50]</ref>, this monotonic function is implemented via a neural network with positive weights and monotonic activations. Weights are forced positive by squaring them before computing the linear operation, and sigmoid activations are used for the hidden layers. Inputs are the time as a scalar, t ∈ [0, 1], and the position encoded as learned D SCHEDULE dimensional position vectors P i ∈ D SCHEDULE . The network's hidden layer contains 1, 000 dimensions to allow for nonlinear behaviour, and the final layer outputs a scalar value for the log SN R. Independently, the end-points of the noise schedule γ min and γ max , are learned and held identical across all positions. The network learns an unconstrained schedule which is then rescaled to fit into the γ bounds. Given W 1 ∈ 1000×(D SCHEDULE +1) , W 2 ∈ 1×1000 , and the sigmoid function σ(_), the schedule is defined as:</p><formula xml:id="formula_12">γφ (t, i) = -W 2 2 σ W 2 1 [t||P i ]<label>(10)</label></formula><formula xml:id="formula_13">γ φ (t, i) = (γ ma x -γ min ) γφ (t, i) -γφ (0, i) γφ (1, i) -γφ(0, i) + γ min . (<label>11</label></formula><formula xml:id="formula_14">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training</head><p>The diffusion model is trained with an end-to-end variational inference approach following <ref type="bibr" target="#b17">[18]</ref>.</p><p>All networks are trained simultaneously via a unified loss function known as the evidence lower bound (ELBO). Particle-level unfolding introduces several additional aspects to this diffusion process, notably variable-length outputs and the need for a multiplicity predictor. The reconstruction and prior terms remain from the traditional VAE ELBO <ref type="bibr" target="#b48">[49]</ref>, and the denoising loss is reinterpreted as the diffusion prior as in Ref. <ref type="bibr" target="#b49">[50]</ref>. A final generative distribution is added to account for the multiplicity output. The full generalized ELBO is:</p><formula xml:id="formula_15">L = i∈{0,1,...N } D K L [q(x i (1)|O P , O D ) ∥ p(x i (1))] PRIOR LOSS + i∈{0,1,...N } q(x i (0)|O P ) -log p( ÔP |x i (0) RECONSTRUCTION LOSS + i∈{0,1,...N } ε∼N (0, ),t∼U (0,1) γ ′ φ (t) ∥ε -εθ (x i (t), X (t), Y, t)∥ 2 2 DENOISING LOSS -log p( N = N |O D ) MULTIPLICITY LOSS (12)</formula><p>PRIOR LOSS: The prior loss is an element-wise extension of the regular VDM prior loss <ref type="bibr" target="#b49">[50]</ref>, matching each final-time element to the prior distribution independently. A standard normal prior, p(x i (1)) ∼ N (0, 1), is used for all latent vectors.</p><p>RECONSTRUCTION LOSS: The reconstruction loss is extended to an element-wise version of a regular VAE reconstruction. This is complicated by the fact that there are several different outputs for every element, and a special event-level element which may also have several outputs. A Gaussian likelihood is assumed for the continuous outputs and a multinomial likelihood for the type predictions. We also assume that the event-level observables E P follow a Gaussian likelihood. This sector of the loss function expands to be:</p><formula xml:id="formula_16">i∈{0,1,...N } q(x i (0)|O P ) -log p( ÔP |x i (0)) = ÊP -E P 2 2 + i∈{1,2,...N } PP i -P P i 2 2 + i∈{1,2,...N } D TYPE -T P i log TP i (<label>13</label></formula><formula xml:id="formula_17">)</formula><p>DENOISING LOSS: The denoising loss extends element-wise to the multi-object case. As the signal-to-noise ratio reduces, the noisy inputs x i (t) may become ambiguous with respect to each other, ultimately culminating in all noisy inputs looking identical under the prior distribution at t = 1. Therefore, in order to use the mean squared error loss function in a well defined manner for high values of t, it is required that the inputs remain ordered and labeled, breaking the position equivariance of the VAE encoder and decoder. This symmetry breaking occurs only at the diffusion step, and this identification additionally allows independent noise schedules to be learned for each position.</p><p>MULTIPLICITY LOSS: The multiplicity estimate N follows a gamma distribution (Eq. 7), and employs a gamma likelihood when computing the corresponding loss term. Using k = M L P k (z) and θ = M L P θ (z) ,</p><formula xml:id="formula_18">-log p( N = N |O D ) = -k log θ + log Γ ( k) -k log N + N θ + log N . (<label>14</label></formula><formula xml:id="formula_19">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Inference</head><p>The generative process must be slightly adapted during inference to account for the variable number of outputs. Given only a set of detector observables O D , the generative inference process may be described as follows:</p><p>1. Encode detector observable, Y = TRANSFORMER DETECTOR (O D ).</p><p>2. Extract multiplicity latent vector, z = TRANSFORMER MULTIPLICITY ( y 0 ||Y ) 0 .</p><p>3. Sample a multiplicity, N ∼ Γ (M L P k (z), M L P θ (z)), and round to the nearest integer</p><formula xml:id="formula_20">N = [ N ].</formula><p>4. Sample N standard normal vectors from the prior distribution, for i ∈ {0, 1, . . . , N }, x i (1) ∼ (0, 1).</p><p>5. Perform reverse diffusion process using an ODE solver <ref type="bibr" target="#b52">[53]</ref> to predict the denoised latent x i (0) following the independently learned noise schedule γ φ (i, t) for each element.</p><p>6. Predict the final particle-level observables by decoding the denoised latents following Eq 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Example Use-case: Semi-leptonic t t Unfolding</head><p>As an example of a common use-case, VLD is used to unfold proton-proton collision events containing top quark pairs (t t). The semi-leptonic decay mode is chosen, in which one top quark decays to three quarks via t → W b → qq b and the other to a lepton, neutrino and b-quark via t → W b → ℓνb. A Feynman diagram that contributes to the process is shown in Figure <ref type="figure" target="#fig_1">3</ref>. This decay mode, with a final state containing one lepton, two b-quarks, two light quarks, and missing momentum originating from the neutrino (which escapes the detector without interaction), is an excellent test case due to its complexity and importance for precision measurements and searches for new physics <ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref><ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b63">[64]</ref>. </p><formula xml:id="formula_21">g g b b q q ℓ ν t t W + W -</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>Simulated t t events from proton-proton collisions are generated with the Standard Model (SM) at a centre-of-mass energy of s = 13 TeV using MADGRAPH_AMC@NLO [65] (v3.4.2, NCSA license) for the matrix element calculation and PYTHIA8 <ref type="bibr" target="#b65">[66]</ref> (v8.306, GPL-2) for the parton showering and hadronization. Interaction with the experimental apparatus is simulated with DELPHES [67] (v3.5.0, GPL-3) using the default CMS detector card.</p><p>Electrons and muons are required to have a transverse momentum p T &gt; 25 GeV and absolute pseudo-rapidity |η| &lt; 2.5. The light and b-quarks are reconstructed as jets, collimated energy deposits grouped using the anti-k T <ref type="bibr" target="#b67">[68]</ref> algorithm with a radius parameter of R = 0.5, which must satisfy the same p T and η requirements as the leptons. Jets originating from b-quarks are tagged as such with a p T -dependent efficiency. At particle level, the jet algorithm is applied to stable particles rather than energy deposits, and jets containing b-quarks are directly tagged as such.</p><p>Selected events are required to have one electron or muon and at least four jets, of which at least two are b-tagged, at both particle and detector level. 14M and 1M events are used for training and testing, respectively. Potential adjustments needed to account for events which pass one, but not both, of these selections are discussed in Section 5.</p><p>An additional sample of approximately 2M events is produced to explore the impact of the training sample prior. This sample uses the dim6top_LO_UFO <ref type="bibr" target="#b68">[69]</ref> model to incorporate new physics in the top-gluon vertex via the c t g parameter, which is set to a value of 25. All other settings and the event selection are identical to the SM sample.</p><p>Particle-level observables are represented by the vector P i = (P x , P y , P z , log(E+1), log(M +1)). Both the mass and energy are included in the representation to improve robustness to numerical issues. Particles are categorized into four types: light-quark jets, b-quark jets, electrons, and muons, represented as a four dimensional one-hot type vector, T P i ∈ {0, 1} 4 . The eventlevel observables for a particle-level event are taken to be the magnitude of the missing transverse momentum E miss T and its azimuthal angle φ miss , along with the neutrino kinematics (P ν</p><p>x , P ν y , P ν z , E ν ). At detector level, two coordinate-representations of the four-momentum are provided; P Cart D i = (P x , P y , P z , log(E + 1)) and P Polar D i = (P T , η, sin φ, cos φ, log(M + 1)), as well as the type one-hot vector, T D i , for each object. The event-level observables are only E miss T and φ miss , as the neutrino kinematics are unobserved at detector level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Standard Model Results</head><p>The VLD's learned log signal-to-noise ratio function γ φ (i, t) and corresponding β schedule after training on the SM t t dataset are shown in while the "Event" object corresponds to the event-level observables. Early in the generation process, at high but decreasing values of t, the learned signal-to-noise ratio increases most quickly for the softest objects. This can be understood as the model adjusting the amount of added noise to be correctly proportional to the size of the energy and momentum kinematic quantities for each object. During the bulk of the generation process at intermediate values of t, the model increases the SNR at roughly equal rates for all objects in the event.</p><p>The VLD model performance is evaluated on a testing sample, generated identically to the training sample. Figures <ref type="figure">5</ref> and<ref type="figure">6</ref> show the kinematic distributions of the leptons and jets respectively <ref type="foot" target="#foot_2">3</ref> . The distributions are inclusive over all leptons or jets in the events. Distributions labelled "truth" are from events without detector effects, the target of the unfolding. Distributions labeled "detector" are from events which include simulated effects of the detector and are used to condition generation. The distributions labelled "unfolded" are from particle level events generated by the VLD unfolding algorithm, and the shaded error bands on the unfolded distributions are obtained by sampling each event 128 times. The ability to sample the generative model multiple times for a single detector-level event is an additional benefit of the generative approach <ref type="bibr" target="#b69">[70]</ref>. However in this application, the uncertainties obtained from sampling the model are strictly larger than the statistical uncertainties in the distributions.</p><p>In general, there is excellent agreement between the unfolded and truth distributions for the inclusive lepton and jet kinematics. This is expected, as the network is trained to directly predict these quantities. Some disagreement is found at the kinematic edges, for example at low p T and mass or at extreme values of η, due to a lack of examples of events migrating across the selection requirements from particle to detector level. This could be mitigated by imposing a tighter selection in generation than in training, avoiding the need to learn sharp cut-offs in the target distributions. Table <ref type="table" target="#tab_1">1</ref> displays three measures of distance between the truth distributions and the corresponding detector and unfolded distributions for the jet and lepton kinematics. The definitions of these measures are presented in Appendix B. In most cases, the distance to the truth distribution is smaller for the unfolded distributions than the detector distributions. One exception is in the jet η observable, due to events migrating across the event selection between particle and detector levels at high |η|.</p><p>Distributions of the event-level observables E miss T , φ miss , and the neutrino pseudo-rapidity η ν are shown in Fig. <ref type="figure">7</ref>. These show good closure except for a slight peak near zero in η ν . Since η ν is not measurable at detector level, it must be inferred by examining the kinematics of the Figure <ref type="figure">5</ref>: Inclusive kinematic distributions for jets in the SM testing dataset, comparing the true particle-level jets (dashed blue), the unfolded particle-level jets (solid red), and the detector-level jets (dotted green). The unfolded distributions include error bounds estimated by sampling each event 128 times. Figure <ref type="figure">6</ref>: Inclusive kinematic distributions of leptons in the SM testing dataset, comparing the true particle-level leptons (dashed blue), the unfolded particle-level leptons (red solid), and the detector-level leptons (dotted green). Unfolded distributions include error bounds estimated by sampling each event 128 times. Figure <ref type="figure">7</ref>: Event-level quantities in the SM testing dataset, comparing the true particlelevel (dashed blue), the unfolded particle-level (solid red), and the detector-level (dotted green). Unfolded distributions include error bounds estimated by sampling each event 128 times. Figure <ref type="figure">8</ref>: Distributions of (a) jet multiplicity and (b) H T comparing the true particlelevel events (dashed blue), the unfolded particle-level events (red solid), and the detector-level events (dotted green). Unfolded distributions include error bounds estimated by sampling each event 128 times. directly measured objects in the event. The excess density predicted by the model at η ν = 0 can be understood as the model returning the mean value of the distribution when the conditioning provided by the rest of the event is particularly weak.</p><p>A crucial requirement for full-event unfolding is the capacity to accommodate variable object multiplicities, such as the number of reconstructed jets. Four jets are expected from the quarks produced from the t t decay (see Fig. <ref type="figure" target="#fig_1">3</ref>), but some jets may fail the selection requirements and additional jets can be generated from other activity such as initial-or final-state radiation. Figure <ref type="figure">8</ref> shows the distribution of the jet multiplicity for the truth-level, detector-level, and unfolded events, along with H T , the scalar sum of all p T in the event. There is excellent agreement in the jet multiplicity distribution, indicating that the network is correctly accounting for the variable dimensionality of the unfolding task. However, a slight disagreement between the unfolded and truth distributions is seen at low H T . To further interrogate the robustness of the jet multiplicity prediction, Fig. <ref type="figure" target="#fig_7">9</ref> shows the H T , jet p T , and jet mass distributions binned in jet multiplicity, with consistent performance shown in all bins including the mis-modeling at low values of H T . The network's ability to reproduce the truth-level kinematic distributions is therefore found to be independent of the jet multiplicity. The mis-modeling at low H T may be a consequence of the limited number of training examples in this region of phase space. Possible solutions to this issue are discussed in Section 5.</p><p>The defining feature of full-event unfolding is the capacity to obtain an unfolded distribution of an arbitrary new observable, such as those defined on reconstructed objects like top quarks, which are functions of the lower-level jet and lepton observables. The pseudo-top algorithm [71, 72] is used to reconstruct hadronically-and leptonically-decaying top quark candidates, and check the performance of our unfolding on the kinematics of these reconstructed systems. Unlike for classical unfolding algorithms, a change in the reconstruction algorithm does not obsolete the results, as these can be simply recalculated with the new algorithm. Log Ratio (i)</p><p>Figure <ref type="figure" target="#fig_0">10</ref>: Distributions of reconstructed top quark and t t system kinematics in the SM testing dataset. Shown are true particle-level (dashed blue), the unfolded particlelevel (solid red), and the detector-level (dotted green). Unfolded distributions include error bounds estimated by sampling each event 128 times.</p><p>Figure <ref type="figure" target="#fig_0">10</ref> shows the kinematic distributions for the reconstructed hadronically-decaying top quark, leptonically-decaying top quark, and the t t system. Closure in these distributions is not as good as for the kinematics of the jets and leptons, though it is not surprising that these observables are more difficult to model as they were not directly used to optimize the networks. In particular, the top quark mass distributions are very difficult to unfold, with the sharp peaks at truth level not reproduced after unfolding. This is an illustration of the well known difficulty in modeling sharp features with generative models <ref type="bibr" target="#b11">[12]</ref>. Corner plots illustrating correlations between these observables in the truth and predicted distributions are provided in Appendix E. These show that correlations between arbitrary observables are faithfully captured by VLD, despite the difficulty in modeling some of the marginal distributions.</p><p>Table <ref type="table" target="#tab_2">2</ref> shows the distance metrics computed for the kinematics of the hadronically-decaying top quark, the leptonically-decaying top quark, and the t t system. In some cases, the unfolded distributions are slightly further from the truth distributions than the detector-level distributions, suggesting the unfolding is not correctly modeling the subtle correlations between the objects in particle-level events. For the p T of the hadronically-decaying top quark and the t t system, the distance between the unfolded and truth distributions is larger than the distance between the detector-level and truth distributions, while for the corresponding energy distributions, it is smaller. Meanwhile, the opposite is observed for the leptonically-decaying top quark. These distributions are highly correlated with the top quark mass, so a promising avenue for future work would be to incorporate physics constraints, such as knowledge of the expected top mass value, in order to improve these observables. In Ref. <ref type="bibr" target="#b17">[18]</ref>, in which the parton-level top quark kinematics were directly included in the training objective, the modeling of the top quark mass peaks is improved through use of a physics-inspired consistency loss. Unfortunately this strategy is not immediately applicable in particle-level unfolding, where the network does not directly predict the top kinematics. Such considerations are discussed further in Section 5.</p><p>To further probe the performance of VLD based unfolding, additional event-level observables of interest in t t production <ref type="bibr" target="#b59">[60]</ref> are constructed, shown in Figure <ref type="figure" target="#fig_0">11</ref>  <ref type="foot" target="#foot_3">4</ref> . There is remarkably good agreement between truth and unfolded in most of these complex observables, with agreement within uncertainties almost everywhere.</p><p>To probe the source of the non-closure in the top quark kinematics, the top quark<ref type="foot" target="#foot_4">foot_4</ref> p T and t t mass distributions are reconstructed in bins of jet multiplicity in Figure <ref type="figure" target="#fig_0">12</ref>, along with the top quark p T in bins of the t t mass. The disagreement of the top quark p T seen in Figure <ref type="figure" target="#fig_0">10</ref> is reproduced in all jet multiplicity bins, indicating that this disagreement is not being produced by the variable-length nature of the unfolding. In contrast, the disagreement of the top quark p T gets worse as a function of increasing t t mass. High-mass events are rare in the training set (see Fig. <ref type="figure" target="#fig_0">10i</ref>), so this non-closure may be due to limited training examples, as with the non-closure at low H T . Effects due to the choice of prior distributions could be overcome via specific choices in training dataset construction, which need not match the observed data. This is an important feature, not only for coverage of extreme regions of phase space, but also to ensure a model trained on SM events does not simply reproduce SM truth distributions and wash away any new physics that might be present in data. The latter point is investigated in the following section. Figure <ref type="figure" target="#fig_0">11</ref>: Distributions of reconstructed event-level observables related to the top quarks and t t system in the SM testing dataset. Shown are true particle-level (dashed blue), the unfolded particle-level (solid red), and the detector-level (dotted green). Unfolded distributions include error bounds estimated by sampling each event 128 times.   Figure <ref type="figure" target="#fig_0">12</ref>: Distributions of (a) p T of the top quarks and (b) mass of the t t system in bins of jet multiplicity. Distributions of the p T of the top quarks in bins of t t mass is shown in (c). Shown are true particle-level (dashed blue), the unfolded particle-level (solid red), and the detector-level (dotted green). Unfolded distributions include error bounds estimated by sampling each event 128 times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance on Dataset with BSM Physics Injection</head><p>To estimate the extent to which the posterior density modeled by VLD, p(x| y), is dependent on the prior used to construct the training set f truth in Equation <ref type="formula" target="#formula_2">3</ref>, the VLD network trained on the SM dataset is evaluated on the alternative sample containing BSM physics parametrized with a non-zero EFT operator (described in Section 4.1). The alternative sample contains a modified top-gluon vertex, leading to differences in the kinematic distributions used as unfolding targets as well as in the reconstructed distributions related to the top quarks, and is therefore a good probe of potential bias in the unfolding model due to the choice of SM prior.</p><p>Figure <ref type="figure" target="#fig_1">13</ref> shows the truth, detector, and unfolded lepton and jet kinematics and multiplicity in the SM and EFT samples. There is good agreement almost everywhere between the unfolded and truth distributions for the EFT sample despite large differences with the SM training sample. The reconstructed top quark and t t system kinematics are shown in Fig. <ref type="figure" target="#fig_0">14</ref>. They show similar disagreements in top p T and mass as was observed in unfolding the SM sample, which are much smaller than the differences between the SM and EFT truth distributions. This indicates that the choice of prior training sample has not induced a significant bias in the unfolding derived using VLD, at least in this test case. Nonetheless, it may be necessary to apply the iterative method proposed in <ref type="bibr" target="#b13">[14]</ref> to remove all dependence on the prior when applying to real data. A full set of comparisons between the EFT and SM samples can be found in Appendix C. Figure <ref type="figure" target="#fig_1">13</ref>: Distributions of lepton kinematic quantities in the EFT testing dataset, comparing the true particle-level leptons (dashed purple), the unfolded particle-level leptons (solid orange), and the detector-level leptons (dotted green). Also shown are the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution. Figure <ref type="figure" target="#fig_0">14</ref>: Reconstructed top quark and t t system kinematics in the EFT testing dataset. Shown are true particle-level (dashed purple), the unfolded particle-level (solid orange), and the detector-level (dotted green). Also shown are the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Outlook and Discussion</head><p>This paper demonstrates the first application of generative ML models to full-event unfolding at particle-level, which requires a mechanism for unfolding the variable number of particles produced in collision events. No performance comparison to other generative approaches is provided, as none are yet capable of variable-length full-event unfolding. A comparison of VLD to the discriminative Omnifold method <ref type="bibr" target="#b9">[10]</ref> on a variable-and high-dimensional unfolding task is left to future work. In this paper, all final state particles not identified as leptons were clustered into jets before unfolding. A more ambitious approach to full-event unfolding would be to instead unfold before clustering. While the precise modeling of O(100) final state particles presents a greater challenge, there is no fundamental reason that the VLD approach would not scale to such a task. Exploring this possibility is also left to future work.</p><p>VLD was able to accurately predict truth-level distributions in the vast majority of phase space. However, mis-modelling was observed in regions where the truth-level distributions had sharp features or limited statistics in the training data. Previous work <ref type="bibr" target="#b17">[18]</ref> accounted for the sharply peaked partonic top-quark mass distributions using a physics-inspired consistency loss term that ensured the predicted 4-vector components maintained the correct correlations. Here, this loss was not necessary to ensure consistency in the predicted 4-vectors for the particle-level leptons and jets. Mis-modelling was however observed in the sharply peaked particle-level top quark mass distributions. Since the particle-level top quark masses are reconstructed post-unfolding and VLD is not directly optimized to generate these distributions, applying a similar physics consistency loss is non-trivial. Other physics constraints, such as those enforcing symmetries or conversation laws, could also be incorporated into the objective in principle. Such physics constraints can easily be added to the loss function used to optimize the VAE; however adding such loss terms to the diffusion process would require performing computationally expensive inference at training time. Table <ref type="table">3</ref> shows the distance metrics between detector and unfolded distributions for a selection of observables, distinguishing between the contributions to post-unfolding distance from the VAE or the diffusion parts of the network. The majority of the error comes from the diffusion process, and so an investigation of how best to utilize physics constraints is left to future work. Full error breakdown tables can be found in Appendix D.</p><p>There are several possibilities to improve performance where the truth-level distributions have few training samples. One is to simply avoid these regions, constructing the training sample with boundaries sufficiently far from the region to be unfolded. Another is to increase the number of training samples in these regions, as long as the unfolding remains insensitive to the prior distribution.</p><p>The presence of background events, which may complicate the unfolding, is not treated here. These background events are typically estimated using simulated data, and then subtracted before the unfolding step of the analysis. This subtraction could be achieved in an unbinned fashion with the addition of negative-weighted simulated background events in the training samples. These can be used directly in the training of the generative model <ref type="bibr" target="#b71">[73]</ref>, or after re-weighting the training sample to positive event weights <ref type="bibr" target="#b72">[74]</ref>.</p><p>Additionally the samples of simulated events used in realistic physics analyses typically contain events that pass one of the particle level or detector level event selections but not both. Events that pass the detector-level event selection but not the particle-level event selection (often called fakes) can be accounted for by simply including these events in the training data sets. At inference time, the events which migrate out of the particle level event selection are then not included in the final unfolded dataset. Events which pass the particle level event selection but not the detector level event selection (often called inefficiencies) are more problematic, since there is no detector level event on which to condition the model. The number of these Table <ref type="table">3</ref>: An examination of the source for the error in unfolding. Presented are the distribution-free distance metrics from particle-level truth for the detector-level and unfolded distributions. The distances for the unfolded distributions are further subdivided into the distance produced by the VAE, evaluated by encoding and decoding the particle-level truth events and comparing the resulting distributions to particlelevel truth, as well as the distance produced by the diffusion process, evaluated by calculating the distance metrics in the latent space of the VAE. Unfolding 1.02 ± 0.15 0.17 ± 0.02 0.57 ± 0.12 VAE 0.13 ± 0.03 0.02 ± 0.00 0.25 ± 0.05 Diffusion 0.89 ± 0.11 0.16 ± 0.02 0.32 ± 0.06 events could be reduced by defining a signal region at detector level that avoids regions of phase space with poor detector efficiency.</p><p>Finally, realistic physics analyses must also account for sources of statistical and systematic uncertainty. The statistical uncertainties resulting from the finite size of the training sets can be estimated using bootstrapping methods <ref type="bibr" target="#b73">[75]</ref>. One approach to propagating systematic uncertainties is to parameterize the model on these uncertainties <ref type="bibr" target="#b74">[76]</ref> and unfold the data for several assumed values of the nuisance parameter, perhaps including constraints from auxiliary measurements. Exploration of this possibility is left to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This paper presents the first application of generative unfolding techniques to a variabledimensional unfolding task. Several modifications to the original VLD model made it possible for the model to naturally accommodate the variable-dimensional nature of the task of unfolding full experimental particle physics events.</p><p>In general, there is excellent closure between truth and unfolded distributions, both for a sample similar to the training sample, and an alternative. Some mis-modeling of kinematic distributions is seen near edges of the selection, due to a lack of training samples. Potential mitigation strategies were discussed in Section 5. Observables not included in the VLD training, such as the reconstructed top quark kinematics, showed larger mis-modeling. Most significant is the mis-modeling of the top quark mass distributions, which are sharply peaked at particle-level and not well reconstructed at detector level. Future work may incorporate additional physics constraints to better handle these kinds of observables.</p><p>The results demonstrate the possibility of performing full-event unfolding with a generative model, where the kinematics of all reconstructed jets, leptons, and the missing transverse momentum are unfolded to particle level, including handling a variable number of final state objects. Such measurements would be of great value to the high energy physics community, allowing results to be easily re-used and re-interpreted many years later, including the ability to construct event-level quantities not defined at the time of the original measurement. This would ensure a substantially longer lasting impact for all unfolded that utilize VLD, and significantly reduce the number of individual efforts required to measure a large number of different observables.</p><p>To encourage further development in generative unfolding methods, the datasets used are made publicly available <ref type="bibr" target="#b75">[77]</ref>. The code base is available at <ref type="url" target="https://github.com/Alexanders101/LVD/tree/main">https://github.com/Alexanders101/ LVD/tree/main</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Variable Definitions</head><p>The observables displayed in Figures <ref type="figure" target="#fig_0">11</ref> and<ref type="figure" target="#fig_7">19</ref> are designed to be sensitive to various physics effects in t t production and decay. They were measured by the ATLAS collaboration <ref type="bibr" target="#b59">[60]</ref> using traditional unfolding methods, and the distributions from this analysis are routinely used to test new theory predictions and tune relevant MC settings. These are included here to demonstrate the power of VLD unfolding, which would allow such variables (and any other that could be thought of) to be post-unfolding. The definitions of these variables are as follows: </p><formula xml:id="formula_22">y tt boost =<label>1</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Distance Metrics</head><p>As the parton global distributions do not have a known family of distributions to describe their components, model-free measures of distribution distance must be used to evaluate the models. Three different families of distance measures are used. These non-parametric distances are only defined for 1-dimensional distributions. As there is no commonly accepted way of measuring distance for N -dimensional distributions, the 1-dimensional distances are simply summed across the components. Although not ideal, it is enough to compare different models and rank them based on performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Wasserstein Distance</head><p>The Wasserstein distance, often referred to as the earth-mover distance, quantifies the amount of work it takes to reshape one distribution into another. This concept originated from the field of optimal transport and has found wide applications in many areas, including machine learning. An equivalent definition defines this distance as the minimum cost to move and transform the mass of one distribution to match another distribution. For a pair of 1-dimensional distribution samples, denoted u and v, the Wasserstein distance can be computed in a bin-independent manner. This is achieved by computing the integral of the absolute difference between their empirical cumulative distribution functions (CDFs), U(x) and V (x).</p><formula xml:id="formula_23">D Wasserstein (u, v) = ∞ -∞ |U(x) -V (x)|d x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Energy Distance</head><p>Energy distance is another statistical measure used to quantify the difference between two probability distributions based on empericial CDFs. It compares the expected distance between random variables drawn from the same distribution (intra-distribution) with the expected distance between random variables drawn from different distributions (inter-distribution). The Energy distance may be defined as the squared variant of the Wasserstein distance.</p><formula xml:id="formula_24">D Energy (u, v) = 2 ∞ -∞ (U(x) -V (x)) 2 d x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Kolmogorov-Smirnov Test</head><p>The two-sample Kolmogorov-Smirnov (K-S) test is a non-parametric statistical hypothesis test used to compare the underlying probability distributions of two independent samples. It is particularly useful in machine learning applications where the goal is to assess whether two datasets come from the same distribution or if they differ significantly, without making any assumptions about the underlying distribution shape. It is also based on empirical CDFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 KL-Divergence</head><p>An alternative approach to empirical CDF approaches is to bin the data into histograms and compute discrete distribution distances from these histograms. The common Kullback-Leibler distance is used with three different bin sizes. After finding the histograms with N bins for 1 ≤ i ≤ N , P N (i) and Q N (i), the discrete KL divergence is computed as</p><formula xml:id="formula_25">D K L,N = N i=1 P N (i) log P N (i) Q N (i)</formula><p>C Full set of EFT Distributions Figure <ref type="figure" target="#fig_0">15</ref>: Kinematic distributions of leptons in the EFT testing dataset, comparing the true particle-level leptons (dashed purple), the unfolded particle-level leptons (solid orange), and the detector-level leptons (dotted green). Also shown are the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution. Figure <ref type="figure" target="#fig_0">16</ref>: Kinematic distributions of all hadronic jets in the EFT testing dataset, comparing the true particle-level jets (dashed purple), the unfolded particle-level jets (solid orange), and the detector-level jets (dotted green). Also shown are the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution. Figure <ref type="figure" target="#fig_0">17</ref>: Event-level quantities in the EFT testing dataset, comparing the true particle-level events (dashed purple), the unfolded particle-level events (solid orange), and the detector-level events (dotted green). Also shown are the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution.  </p><p>Figure <ref type="figure" target="#fig_0">18</ref>: The event-level observable H T , and the inclusive jet p T and mass, in the EFT testing dataset and binned by jet multiplicity. Shown are true particle-level jets (dashed purple), the unfolded particle-level jets (solid orange), and the detector-level jets (dotted green). Also shown are the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution. Figure <ref type="figure" target="#fig_7">19</ref>: Reconstructed high-level observables related to the top quarks and t t system in the EFT testing dataset. Shown are true particle-level (dashed purple), the unfolded particle-level (solid orange), and the detector-level jets (dotted green). Also shown are the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution.    <ref type="table">Table 4:</ref> An examination of the source for the error in unfolding. Presented are the distribution-free distance metrics from particle-level truth for the detector-level and unfolded distributions. The distances for the unfolded distributions are further subdivided into the distance produced by the VAE, evaluated by encoding and decoding the particle-level truth events and comparing the resulting distributions to particlelevel truth, as well as the distance produced by the diffusion process, evaluated by calculating the distance metrics in the latent space of the VAE. .67 ± 0.12 0.12 ± 0.01 0.03 ± 0.01 Diffusion 5.78 ± 0.43 0.39 ± 0.02 0.17 ± 0.02 Table <ref type="table">5</ref>: An examination of the source for the error in unfolding. Presented are the distribution-free distance metrics from particle-level truth for the detector-level and unfolded distributions. The distances for the unfolded distributions are further subdivided into the distance produced by the VAE, evaluated by encoding and decoding the particle-level truth events and comparing the resulting distributions to particlelevel truth, as well as the distance produced by the diffusion process, evaluated by calculating the distance metrics in the latent space of the VAE.  <ref type="table">6</ref>: An examination of the source for the error in unfolding. Presented are the distribution-free distance metrics from particle-level truth for the detector-level and unfolded distributions. The distances for the unfolded distributions are further subdivided into the distance produced by the VAE, evaluated by encoding and decoding the particle-level truth events and comparing the resulting distributions to particlelevel truth, as well as the distance produced by the diffusion process, evaluated by calculating the distance metrics in the latent space of the VAE. Unfolding 0.01 ± 0.00 0.00 ± 0.00 13.03 ± 1.18 VAE 0.00 ± 0.00 0.00 ± 0.00 2.51 ± 0.37 Diffusion 0.00 ± 0.00 0.00 ± 0.00 10.52 ± 0.81 Detector 0.00 0.00 0.02 φ Jet Unfolding 0.00 ± 0.00 0.00 ± 0.00 0.01 ± 0.01 VAE 0.00 ± 0.00 0.00 ± 0.00 0.00 ± 0.01 Diffusion 0.00 ± 0.00 0.00 ± 0.00 0.01 ± 0.01 Unfolding 0.01 ± 0.01 0.01 ± 0.00 0.08 ± 0.05 VAE 0.00 ± 0.00 0.00 ± 0.00 0.01 ± 0.01 Diffusion 0.01 ± 0.00 0.01 ± 0.00 0.07 ± 0.04     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Full Error Breakdown Tables</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Corner Plots of Top-Quark Kinematics</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A Flow diagram of the components of Particle VLD. Pairs of particle level (O P )and detector level (O D ) events are used to train the model using the loss functions introduced in Ref.<ref type="bibr" target="#b17">[18]</ref>. At inference time, a detector level event is used to produce a multiplicity prediction and mapped to a latent embedding through the detector encoder. The multiplicity prediction and the latent representation of the detector level event are then used to condition the diffusion process, resulting in a sample from the latent space of the particle VAE. A particle decoder is then applied to produce a sample from the learned conditional distribution P(X |Y ). During training, the particle encoder is used to produce latent samples instead of the diffusion process. The special vector y 0 is a learnable input vector trained alongside the network weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A representative Feynman diagram of t t production in the semi-leptonic decay mode.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .Figure 4 :</head><label>44</label><figDesc>Figure 4: Example learned noise schedule for each object. Independent noise schedules are learned for each unfolded object, ordered by true p T . The "Event" represents the event level observables. Shown are (a) the signal-to-noise ratio (SNR) learned during training and (b) the equivalent β schedule used during inference, following the DDPM framework [45].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure9: Distributions of (a) H T , (b) the inclusive jet p T and (c) jet mass, each in bins of jet multiplicity in the SM testing dataset. Shown are true particle-level jets (dashed blue), the unfolded particle-level jets (solid red), and the detector-level jets (dotted green). Unfolded distributions include error bounds estimated by sampling each event 128 times.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 20 :</head><label>20</label><figDesc>Figure20: Distributions of the p T of the top quarks and mass of the t t system in bins of jet multiplicity are shown in (a) and (b). The distribution of the p T of the top quarks in bins of t t mass is shown in (c). The true particle-level (dashed purple), the unfolded particle-level (solid orange), and the detector-level (dotted green) distributions from the EFT dataset are shown, as are the the unfolded and truth SM distributions (solid red and dashed blue respectively). Unfolded distributions include error bounds estimated by sampling each event 128 times. The bottom pad shows the ratio with respect to the EFT truth distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 21 :</head><label>21</label><figDesc>Figure 21: Corner plot illustrating the correlations between six dimensions that characterise the predicted hadronic top quark kinematics for the SM dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>-η 74 - 74 -</head><label>7474</label><figDesc>mtop,had [GeV] = 218.82 +188.99 top,had ηtop,had = -0.01 +1.Etop,had [GeV] = 373.80 +281.ytop,had = 0.64 +0.63 -0.45</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 22 : 16 -</head><label>2216</label><figDesc>Figure 22: Corner plot illustrating the correlations between six dimensions that characterise the truth hadronic top quark kinematics for the SM dataset.mtop,had [GeV] = 213.06 +196.16 -54.75</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 23 :-y</head><label>23</label><figDesc>Figure 23: Corner plot illustrating the correlations between six dimensions that characterise the predicted leptonic top quark kinematics for the SM dataset. mtop,had [GeV] = 164.84 +45.07 -33.37</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 24 : 10 -η 39 -</head><label>241039</label><figDesc>Figure 24: plot the correlations between six dimensions that characterise the truth leptonic top quark kinematics for the SM dataset.mtop,had [GeV] = 167.45 +29.10 -33.35</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and passed through the detector encoder. The output of this network is a set Y of cardinality M containing D LATENT dimensional latent detector vectors y i Y = { y 1 , y 2 , . . . , y M } where y i = TRANSFORMER DETECTOR ( O D 1 , O D 2 , . . . , O D M ) i .</figDesc><table><row><cell>(6)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Wasserstein, Energy, and Kulback-Leibler distance measures between truth and detector or truth and unfolded distributions for the jet kinematics (top), lepton kinematics (middle), and event-level observables (bottom). The unfolded distribution uncertainties are estimated by sampling each event 128 times.</figDesc><table><row><cell cols="2">Observable Level</cell><cell>Wasserstein</cell><cell>Energy</cell><cell>KL</cell></row><row><cell>p Jet T</cell><cell>Unfolded Detector</cell><cell>0.36 ± 0.08 2.30</cell><cell>0.04 ± 0.01 0.27</cell><cell>0.02 ± 0.01 0.26</cell></row><row><cell>η Jet</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.00 0.01</cell><cell>0.00 ± 0.00 0.01</cell><cell>13.03 ± 1.18 3.44</cell></row><row><cell>φ Jet</cell><cell>Unfolded Detector</cell><cell>0.00 ± 0.00 0.00</cell><cell>0.00 ± 0.00 0.00</cell><cell>0.01 ± 0.01 0.02</cell></row><row><cell>m Jet</cell><cell>Unfolded Detector</cell><cell>0.03 ± 0.01 1.52</cell><cell>0.01 ± 0.00 0.52</cell><cell>0.17 ± 0.05 61.66</cell></row><row><cell>E Jet</cell><cell>Unfolded Detector</cell><cell>0.66 ± 0.26 2.05</cell><cell>0.05 ± 0.02 0.20</cell><cell>0.01 ± 0.00 0.06</cell></row><row><cell>Lepton T p</cell><cell>Unfolded Detector</cell><cell>0.27 ± 0.10 3.89</cell><cell>0.05 ± 0.02 0.53</cell><cell>0.17 ± 0.05 2.64</cell></row><row><cell>η Lepton</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.00 0.03</cell><cell>0.01 ± 0.00 0.02</cell><cell>16.72 ± 3.27 56.01</cell></row><row><cell>φ Lepton</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.01 0.01</cell><cell>0.01 ± 0.00 0.01</cell><cell>0.08 ± 0.05 0.02</cell></row><row><cell>E miss T</cell><cell>Unfolded Detector</cell><cell>0.31 ± 0.06 3.03</cell><cell>0.04 ± 0.01 0.41</cell><cell>0.04 ± 0.01 0.95</cell></row><row><cell>H T</cell><cell>Unfolded Detector</cell><cell>7.45 ± 0.54 8.54</cell><cell>0.51 ± 0.03 0.59</cell><cell>0.20 ± 0.02 0.20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Wasserstein, Energy, and Kulback-Leibler distance measures between truth and detector or truth and unfolded top quark kinematic distributions. The unfolded distribution uncertainties are estimated by sampling each event 128 times.</figDesc><table><row><cell cols="2">Observable Level</cell><cell cols="2">Wasserstein Energy</cell><cell>KL</cell></row><row><cell>top,had T p</cell><cell>Unfolded Detector</cell><cell>5.71 ± 0.40 4.25</cell><cell>0.49 ± 0.03 0.39</cell><cell>0.34 ± 0.05 0.25</cell></row><row><cell>η top,had</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.00 0.01</cell><cell>0.01 ± 0.00 0.01</cell><cell>6.76 ± 2.34 8.40</cell></row><row><cell>φ top,had</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.01 0.01</cell><cell>0.00 ± 0.00 0.01</cell><cell>3.74 ± 1.35 5.44</cell></row><row><cell>E top,had</cell><cell>Unfolded Detector</cell><cell>2.51 ± 1.14 10.92</cell><cell>0.10 ± 0.05 0.60</cell><cell>0.02 ± 0.01 0.08</cell></row><row><cell>m top,had</cell><cell>Unfolded Detector</cell><cell>4.63 ± 0.32 4.05</cell><cell>0.55 ± 0.04 0.50</cell><cell>4.46 ± 0.25 2.37</cell></row><row><cell>top,had Out p</cell><cell>Unfolded Detector</cell><cell>0.82 ± 0.15 0.48</cell><cell>0.14 ± 0.02 0.06</cell><cell>0.42 ± 0.10 0.28</cell></row><row><cell>top,lep T p</cell><cell>Unfolded Detector</cell><cell>4.07 ± 0.30 8.12</cell><cell>0.36 ± 0.03 0.73</cell><cell>0.28 ± 0.04 0.82</cell></row><row><cell>η top,lep</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.00 0.05</cell><cell>0.01 ± 0.00 0.04</cell><cell>5.79 ± 2.00 51.77</cell></row><row><cell>φ top,lep</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.01 0.01</cell><cell>0.01 ± 0.01 0.00</cell><cell>3.36 ± 1.17 4.54</cell></row><row><cell>E top,lep</cell><cell>Unfolded Detector</cell><cell>7.41 ± 0.88 4.88</cell><cell>0.40 ± 0.04 0.36</cell><cell>0.08 ± 0.02 0.12</cell></row><row><cell>m top,lep</cell><cell>Unfolded Detector</cell><cell>4.50 ± 0.19 4.56</cell><cell>0.55 ± 0.01 0.60</cell><cell>7.99 ± 0.31 7.80</cell></row><row><cell>top,lep Out p</cell><cell>Unfolded Detector</cell><cell>1.02 ± 0.15 0.27</cell><cell>0.17 ± 0.02 0.03</cell><cell>0.57 ± 0.12 0.26</cell></row><row><cell>m tt</cell><cell>Unfolded Detector</cell><cell>7.58 ± 1.58 16.11</cell><cell>0.33 ± 0.08 0.92</cell><cell>0.04 ± 0.01 0.15</cell></row><row><cell>p tt T</cell><cell>Unfolded Detector</cell><cell>1.63 ± 0.15 1.24</cell><cell>0.26 ± 0.02 0.14</cell><cell>0.95 ± 0.14 0.26</cell></row><row><cell>η tt</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.01 0.01</cell><cell>0.01 ± 0.01 0.01</cell><cell>13.56 ± 5.91 27.63</cell></row><row><cell>φ tt</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.01 0.01</cell><cell>0.01 ± 0.01 0.00</cell><cell>5.75 ± 1.76 7.67</cell></row><row><cell>χ tt</cell><cell>Unfolded Detector</cell><cell>0.11 ± 0.02 0.09</cell><cell>0.05 ± 0.01 0.04</cell><cell>5.41 ± 1.47 4.52</cell></row><row><cell>y tt boost</cell><cell>Unfolded Detector</cell><cell>0.01 ± 0.00 0.02</cell><cell>0.01 ± 0.00 0.03</cell><cell>22.50 ± 6.51 80.18</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>± 0.00 0.01 ± 0.00 6.70 ± 2.46 VAE 0.01 ± 0.00 0.00 ± 0.00 8.47 ± 1.35 Diffusion 0.01 ± 0.00 0.00 ± 0.00 -1.77 ± 1.11 ± 0.01 0.00 ± 0.00 3.76 ± 1.35 VAE 0.00 ± 0.00 0.00 ± 0.00 4.23 ± 1.08 Diffusion 0.00 ± 0.00 0.00 ± 0.00 -0.47 ± 0.27 ± 0.00 0.01 ± 0.00 8.29 ± 3.34 VAE 0.00 ± 0.00 0.00 ± 0.00 10.79 ± 1.05 Diffusion 0.01 ± 0.00 0.00 ± 0.00 -2.50 ± 2.29 ± 0.20 0.61 ± 0.02 9.16 ± 0.44 VAE 1.13 ± 0.08 0.13 ± 0.01 0.53 ± 0.04 Diffusion 3.90 ± 0.13 0.48 ± 0.01 8.63 ± 0.40</figDesc><table><row><cell>Observable Stage Detector p top,had T Unfolding VAE Diffusion 3.97 ± 0.26 0.33 ± 0.02 0.25 ± 0.02 Wasserstein Energy KL 4.25 0.39 0.25 5.62 ± 0.39 0.48 ± 0.03 0.33 ± 0.05 1.65 ± 0.13 0.15 ± 0.01 0.08 ± 0.02 Detector 0.01 0.01 8.40 η top,had Unfolding 0.01 Detector 0.01 0.01 5.44 φ top,had Unfolding 0.01 Detector 10.92 0.60 0.08 E top,had Unfolding 2.50 ± 1.14 0.10 ± 0.05 0.02 ± 0.01 VAE 0.52 ± 0.08 0.03 ± 0.01 0.01 ± 0.00 Diffusion 1.98 ± 1.06 0.08 ± 0.05 0.01 ± 0.01 Detector 4.05 0.50 2.37 m top,had Unfolding 4.62 ± 0.32 0.55 ± 0.04 4.45 ± 0.26 VAE 1.24 ± 0.05 0.15 ± 0.01 0.43 ± 0.04 Diffusion 3.37 ± 0.26 0.40 ± 0.02 4.02 ± 0.22 Detector 7.48 0.66 0.66 p top,lep T Unfolding 4.59 ± 0.41 0.41 ± 0.04 0.32 ± 0.05 VAE 1.14 ± 0.08 0.11 ± 0.01 0.07 ± 0.02 Diffusion 3.45 ± 0.32 0.31 ± 0.03 0.25 ± 0.03 Detector 0.05 0.04 51.12 η top,lep Unfolding 0.01 Detector 0.01 0.01 6.15 φ top,lep Unfolding 0.01 ± 0.01 0.01 ± 0.01 4.89 ± 1.84 VAE 0.01 ± 0.00 0.00 ± 0.00 4.32 ± 0.81 Diffusion 0.01 ± 0.01 0.00 ± 0.01 0.57 ± 1.03 Detector 4.71 0.32 0.13 E top,lep Unfolding 8.32 ± 1.16 0.45 ± 0.06 0.09 ± 0.02 VAE 1.19 ± 0.09 0.07 ± 0.00 0.03 ± 0.01 Diffusion 7.13 ± 1.07 0.39 ± 0.06 0.06 ± 0.01 Detector 4.64 0.61 8.25 m top,lep Unfolding 5.03 Table</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>While generative methods alone do not require using the observed events for training, applying an iterative procedure<ref type="bibr" target="#b13">[14]</ref> to reduce prior dependence would. The extent to which a limited number of observed events would limit performance in this scenario is unclear.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>A method for detector-simulation-free training is presented in Ref.<ref type="bibr" target="#b16">[17]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The predicted lepton mass distributions are not shown since the true lepton masses are precisely determined. In what follows, the model's lepton mass predictions are dropped and replaced with the true values.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Full definitions of these variables are given in Appendix A.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>In these p T distributions, both the leptonically-and hadronically-decaying top quarks are included.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors thank <rs type="person">Vinicius Mikuni</rs>, <rs type="person">Ben Nachman</rs>, and <rs type="person">Tilman Plehn</rs> for fruitful discussions on unfolding methods. FUNDING INFORMATION DW, KG, AG, and MF are supported by <rs type="funder">DOE</rs> grant <rs type="grantNumber">DE-SC0009920</rs>. The work of AS and PB in part supported by <rs type="funder">ARO</rs> grant <rs type="grantNumber">76649-CS</rs> to PB.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_NjQkHMP">
					<idno type="grant-number">DE-SC0009920</idno>
				</org>
				<org type="funding" xml:id="_Waj28R2">
					<idno type="grant-number">76649-CS</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Frontier of Simulation-Based Inference</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Louppe</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1912789117</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">48</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">GEANT4-a simulation toolkit</title>
		<author>
			<persName><forename type="first">S</forename><surname>Agostinelli</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0168-9002(03)01368-8</idno>
	</analytic>
	<monogr>
		<title level="j">Nucl. Instrum. Meth. A</title>
		<imprint>
			<biblScope unit="volume">506</biblScope>
			<biblScope unit="page">250</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recent developments in Geant4</title>
		<author>
			<persName><forename type="first">J</forename><surname>Allison</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nima.2016.06.125</idno>
	</analytic>
	<monogr>
		<title level="j">Nucl. Instrum. Meth. A</title>
		<imprint>
			<biblScope unit="volume">835</biblScope>
			<biblScope unit="page">186</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geant4 developments and applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Allison</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNS.2006.869826</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Nucl. Sci</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The ATLAS Experiment at the CERN Large Hadron Collider</title>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1088/1748-0221/3/08/S08003</idno>
	</analytic>
	<monogr>
		<title level="j">JINST</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unfolding Method based on Bayes&apos; Theorem</title>
		<author>
			<persName><forename type="first">G</forename><surname>D'agostini</surname></persName>
		</author>
		<idno type="DOI">10.1016/0168-9002(95)00274-X</idno>
	</analytic>
	<monogr>
		<title level="j">Nucl. Instrum. Meth. A</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="page">487</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">TUnfold: an Algorithm for Correcting Migration Effects in High Energy Physics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schmitt</surname></persName>
		</author>
		<idno type="DOI">10.1088/1748-0221/7/10/T10003</idno>
	</analytic>
	<monogr>
		<title level="j">JINST</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">10003</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SVD Approach to Data Unfolding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kartvelishvili</surname></persName>
		</author>
		<idno type="DOI">10.1016/0168-9002(95)01478-0</idno>
		<idno>hep-ph/9509307</idno>
	</analytic>
	<monogr>
		<title level="j">Nucl. Instrum. Meth. A</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="page">469</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dynamic programming</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.153.3731.34</idno>
		<ptr target="https://www.science.org/doi/pdf/10.1126/science.153.3731.34" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">3731</biblScope>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">OmniFold: A Method to Simultaneously Unfold All Observables</title>
		<author>
			<persName><forename type="first">A</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Komiske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Metodiev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thaler</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.124.182001</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page">9107</biblScope>
			<date type="published" when="1911">2020. 1911</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Preserving New Physics while Simultaneously Unfolding all Observables</title>
		<author>
			<persName><forename type="first">P</forename><surname>Komiske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Mccormack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.104.076027</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">76027</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">How to GAN away Detector Effects</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellagente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasieczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Winterhalder</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhys.8.4.070</idno>
	</analytic>
	<monogr>
		<title level="j">SciPost Phys</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">70</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Invertible Networks or Partons to Detector and Back Again</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bellagente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasieczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rousselot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Winterhalder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ardizzone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Köthe</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhys.9.5.074</idno>
	</analytic>
	<monogr>
		<title level="j">SciPost Phys</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">6685</biblScope>
			<date type="published" when="2006">2020. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An unfolding method based on conditional invertible neural networks (cINN) using iterative training</title>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dunford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Malaescu</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhysCore.7.1.007</idno>
	</analytic>
	<monogr>
		<title level="j">SciPost Phys. Core</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Event-by-event Comparison between Machine-Learning-and Transfer-Matrix-based Unfolding Methods</title>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dunford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Malaescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2310" to="17037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving generative model-based unfolding with Schrödinger bridges</title>
		<author>
			<persName><forename type="first">S</forename><surname>Diefenbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mikuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Nie</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.109.076011</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">76011</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whiteson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-10966-7</idno>
	</analytic>
	<monogr>
		<title level="m">Learning to Simulate High Energy Particle Collisions from Unlabeled Data</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">End-to-end latent variational diffusion models for inverse problems in high energy physics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shmakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Greif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fenton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whiteson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="2305" to="10399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Measurement of Lepton-Jet Correlation in Deep-Inelastic Scattering with the H1 Detector Using Machine Learning for Unfolding</title>
		<author>
			<persName><forename type="first">V</forename><surname>Andreev</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevLett.128.132002</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2108" to="12376" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unbinned deep learning jet substructure measurement in high Q2ep collisions at HERA</title>
		<author>
			<persName><forename type="first">V</forename><surname>Andreev</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physletb.2023.138101</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. B</title>
		<imprint>
			<biblScope unit="volume">844</biblScope>
			<biblScope unit="page">138101</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multidifferential study of identified charged hadron distributions in Z-tagged jets in proton-proton collisions at s =13 TeV</title>
		<author>
			<orgName type="collaboration">LHCb Collaboration</orgName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.108.L031103</idno>
	</analytic>
	<monogr>
		<title level="m">L031103</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">108</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Disentangling Quarks and Gluons in CMS Open Data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Komiske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kryhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thaler</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.106.094021</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">94021</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generative networks for precision enthusiasts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Heimel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hummerich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Krebs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rousselot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vent</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhys.14.4.078</idno>
	</analytic>
	<monogr>
		<title level="j">SciPost Phys</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">78</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Introduction to parton-shower event generators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Höche</surname></persName>
		</author>
		<idno type="DOI">10.1142/9789814678766_0005</idno>
		<idno>1411.4085</idno>
	</analytic>
	<monogr>
		<title level="m">Journeys Through the Precision Frontier: Amplitudes for Colliders</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="235" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Kicking it Off(-shell)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Klasen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kuschick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Palacios</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<idno>2311.17175</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>with Direct Diffusion</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Huetsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Palacios</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sorrenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Spinner</surname></persName>
		</author>
		<title level="m">Jet Diffusion versus JetGPT -Modern Networks for the LHC</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2305" to="10475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Diffusion for particle cloud generation in high energy physics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quétant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Raine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Golling</surname></persName>
		</author>
		<author>
			<persName><surname>Pc-Jedi</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhys.16.1.018</idno>
	</analytic>
	<monogr>
		<title level="j">SciPost Phys</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Faster diffusion model with improved quality for particle cloud generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Raine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quétant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Golling</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.109.012010</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">12010</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ewen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Faroughy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Golling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasieczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Quétant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Raine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shih</surname></persName>
		</author>
		<idno>2310.00049</idno>
		<title level="m">EPiC-ly Fast Particle Cloud Generation with Flow-Matching and Diffusion</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast point cloud generation with diffusion models in high energy physics</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mikuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pettee</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.108.036025</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">36025</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno>2401.13162</idno>
		<title level="m">Choose Your Diffusion: Efficient and flexible ways to accelerate the diffusion model in fast high energy physics simulation</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Score-based generative models for calorimeter shower simulation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mikuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.106.092009</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2206" to="11898" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CaloScore v2: single-shot calorimeter shower simulation with diffusion models</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mikuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<idno type="DOI">10.1088/1748-0221/19/02/P02001</idno>
	</analytic>
	<monogr>
		<title level="j">JINST</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page">2001</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Diefenbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mikuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<title level="m">Refining Fast Calorimeter Simulations with a Schrödinger Bridge</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2308" to="12339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">CaloClouds: fast geometry-independent highly-granular calorimeter simulation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Diefenbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Eren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gaede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasieczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Korol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Korcari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mckeown</surname></persName>
		</author>
		<idno type="DOI">10.1088/1748-0221/18/11/P11025</idno>
	</analytic>
	<monogr>
		<title level="j">JINST</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">11025</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gaede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasieczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Korol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Korcari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mckeown</surname></persName>
		</author>
		<idno>2309.05704</idno>
		<title level="m">CaloClouds II: Ultra-Fast Geometry-Independent Highly-Granular Calorimeter Simulation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fast Simulation of Highly Granular Calorimeters with Generative Models: Towards a First Physics Application</title>
		<author>
			<persName><forename type="first">E</forename><surname>Buhmann</surname></persName>
		</author>
		<idno type="DOI">10.22323/1.449.0568</idno>
	</analytic>
	<monogr>
		<title level="j">PoS EPS-HEP</title>
		<imprint>
			<biblScope unit="volume">2023</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Denoising diffusion models with geometry adaptation for high fidelity calorimeter simulation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Amram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pedro</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.108.072014</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">72014</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">CaloGraph: Graph-based diffusion model for fast shower generation in calorimeters with irregular geometry</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kobylianskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Soybelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dreyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gross</surname></persName>
		</author>
		<idno>2402. 11575</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Full phase space resonant anomaly detection</title>
		<author>
			<persName><forename type="first">E</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ewen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasieczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mikuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shih</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.109.055015</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">55015</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Improving new physics searches with diffusion models for event observables and jet constituents</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Raine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Golling</surname></persName>
		</author>
		<idno>2312.10130</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">High-dimensional and Permutation Invariant Anomaly Detection, SciPost Phys</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mikuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhys.16.3.062</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">62</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Heimel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Huetsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Winterhalder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<idno>2310.07752</idno>
		<title level="m">Precision-Machine Learning for the Matrix Element Method</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<idno>1907.05600</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2006">2020. 2006.11239</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<title level="m">Score-based generative modeling through stochastic differential equations</title>
		<imprint>
			<date type="published" when="2011">2021. 2011.13456</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Elucidating the design space of diffusion-based generative models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<idno>2206.00364</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="26565" to="26577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2112" to="10752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Auto-encoding variational bayes</title>
		<imprint>
			<biblScope unit="page" from="1312" to="6114" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Variational diffusion models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<idno>2107.00630</idno>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">21696</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno>1706.03762</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Going deeper with image transformers</title>
		<author>
			<persName><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<idno>2206.00927</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1140/epjc/s10052-012-2261-1</idno>
	</analytic>
	<monogr>
		<title level="m">Measurements of top quark pair relative differential cross-sections with ATLAS in pp collisions at s = 7 TeV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page">2261</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Measurements of normalized differential cross sections for t t production in pp collisions at s = 7 TeV using the ATLAS detector</title>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.90.072004</idno>
		<idno>1407.0371</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">72004</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Measurements of top-quark pair differential cross-sections in the lepton+jets channel in pp collisions at s = 8 TeV using the ATLAS detector</title>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1140/epjc/s10052-016-4366-4</idno>
	</analytic>
	<monogr>
		<title level="j">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Measurements of top-quark pair differential cross-sections in the lepton+jets channel in pp collisions at s = 13 TeV using the ATLAS detector</title>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1007/JHEP11(2017)191</idno>
	</analytic>
	<monogr>
		<title level="j">JHEP</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">191</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1140/epjc/s10052-019-6757-9</idno>
		<idno>1810.01772</idno>
	</analytic>
	<monogr>
		<title level="m">Measurement of the top quark mass in the t t → lepton+jets channel from s = 8 TeV ATLAS data and combination with previous results</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">290</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Measurements of differential cross sections of top quark pair production in association with jets in pp collisions at s = 13 TeV using the ATLAS detector</title>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1007/JHEP10(2018)159</idno>
	</analytic>
	<monogr>
		<title level="j">JHEP</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Measurements of top-quark pair differential and double-differential cross-sections in the ℓ+jets channel with pp collisions at s = 13 TeV using the ATLAS detector</title>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1140/epjc/s10052-019-7525-6</idno>
		<idno>1908.07305</idno>
	</analytic>
	<monogr>
		<title level="j">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1092</biblScope>
			<date type="published" when="2019">2019. 2020</date>
		</imprint>
	</monogr>
	<note>Eur.Phys.J.C</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Measurement of Differential Top-Quark Pair Production Cross Sections in pp collisions at s = 7 TeV</title>
		<author>
			<orgName type="collaboration">CMS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1140/epjc/s10052-013-2339-4</idno>
	</analytic>
	<monogr>
		<title level="j">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">2339</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Measurement of the differential cross section for top quark pair production in pp collisions at s = 8 TeV</title>
		<author>
			<orgName type="collaboration">CMS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1140/epjc/s10052-015-3709-x</idno>
	</analytic>
	<monogr>
		<title level="j">Eur. Phys. J. C</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">542</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Measurement of the integrated and differential t t production cross sections for high-p t top quarks in pp collisions at s = 8 TeV</title>
		<author>
			<orgName type="collaboration">CMS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.94.072002</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">72002</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Measurement of differential cross sections for top quark pair production using the lepton+jets final state in proton-proton collisions at 13 TeV</title>
		<author>
			<orgName type="collaboration">CMS Collaboration</orgName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.95.092001</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">92001</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The Automated Computation of Tree-level and Next-to-leading Order Differential Cross Sections, and Their Matching to Parton Shower Simulations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Alwall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frederix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Frixione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Hirschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maltoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mattelaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stelzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Torrielli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaro</surname></persName>
		</author>
		<idno type="DOI">10.1007/JHEP07(2014)079</idno>
	</analytic>
	<monogr>
		<title level="j">JHEP</title>
		<imprint>
			<biblScope unit="volume">07</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><surname>Sjöstrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ask</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Corke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ilten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mrenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Prestel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">Z</forename><surname>Skands</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cpc.2015.01.024</idno>
		<idno>1410.3012</idno>
	</analytic>
	<monogr>
		<title level="j">Comput. Phys. Commun</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>An introduction to PYTHIA 8.2</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A Modular Framework for Fast Simulation of a Generic Collider Experiment</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Favereau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delaere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Demin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giammanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lemaître</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Selvaggi</surname></persName>
		</author>
		<idno type="DOI">10.1007/JHEP02(2014)057</idno>
	</analytic>
	<monogr>
		<title level="j">DELPHES</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1307" to="6346" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>JHEP</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The Anti-k t Jet Clustering Algorithm</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cacciari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Salam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soyez</surname></persName>
		</author>
		<idno type="DOI">10.1088/1126-6708/2008/04/063</idno>
	</analytic>
	<monogr>
		<title level="j">JHEP</title>
		<imprint>
			<biblScope unit="volume">04</biblScope>
			<biblScope unit="page">63</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Aguilar-Saavedra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Degrande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Durieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maltoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vryonidou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barducci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Brivio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cirigliano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dekens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Englert</surname></persName>
		</author>
		<idno>1802.07237</idno>
		<title level="m">Interpreting top-quark LHC measurements in the standard-model effective field theory</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">GANplifying event samples</title>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Diefenbacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kasieczka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhys.10.6.139</idno>
	</analytic>
	<monogr>
		<title level="j">SciPost Phys</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">6545</biblScope>
			<date type="published" when="2008">2021. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Study of methods of resolved top quark reconstruction in semileptonic t t decay</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kvita</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nima.2018.05.059</idno>
		<idno>1806.05463</idno>
	</analytic>
	<monogr>
		<title level="j">Erratum: Nucl.Instrum.Meth.A</title>
		<imprint>
			<biblScope unit="volume">900</biblScope>
			<biblScope unit="page">167172</biblScope>
			<date type="published" when="2018">2018. 2022</date>
		</imprint>
	</monogr>
	<note>Nucl. Instrum. Meth. A</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Butter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Plehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Winterhalder</surname></persName>
		</author>
		<idno type="DOI">10.21468/SciPostPhys.10.4.089</idno>
	</analytic>
	<monogr>
		<title level="j">How to GAN Event Unweighting, SciPost Phys</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">89</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Neural resampler for Monte Carlo reweighting with preserved uncertainties</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thaler</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.102.076004</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">76004</biblScope>
			<date type="published" when="2007">2020. 2007.11586</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Evaluating statistical uncertainties and correlations using the bootstrap method</title>
		<author>
			<orgName type="collaboration">ATLAS Collaboration</orgName>
		</author>
		<ptr target="https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PUBNOTES/ATL-PHYS-PUB-2021-011" />
	</analytic>
	<monogr>
		<title level="m">All figures including auxiliary figures are</title>
		<meeting><address><addrLine>Geneva</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
		<respStmt>
			<orgName>CERN</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Uncertainty-aware machine learning for high energy physics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whiteson</surname></persName>
		</author>
		<idno type="DOI">10.1103/PhysRevD.104.056026</idno>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. D</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">56026</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Semi-leptonic ttbar full-event unfolding R&amp;D dataset</title>
		<author>
			<persName><forename type="first">K</forename><surname>Greif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fenton</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.13364827</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
