<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Boosting Probabilistic Graphical Model Inference by Incorporating Prior Knowledge from Multiple Sources</title>
				<funder>
					<orgName type="full">B-IT Research School</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2013-06-24">June 24, 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Paurush</forename><surname>Praveen</surname></persName>
							<email>praveen@bit.uni-bonn.de</email>
						</author>
						<author>
							<persName><forename type="first">Holger</forename><surname>Fro</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Aachen International Center for IT</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<settlement>Bonn Bonn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Semmelweis University</orgName>
								<address>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Boosting Probabilistic Graphical Model Inference by Incorporating Prior Knowledge from Multiple Sources</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-06-24">June 24, 2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1371/journal.pone.0067410</idno>
					<note type="submission">Received March 26, 2013; Accepted May 17, 2013;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Inferring regulatory networks from experimental data via probabilistic graphical models is a popular framework to gain insights into biological systems. However, the inherent noise in experimental data coupled with a limited sample size reduces the performance of network reverse engineering. Prior knowledge from existing sources of biological information can address this low signal to noise problem by biasing the network inference towards biologically plausible network structures. Although integrating various sources of information is desirable, their heterogeneous nature makes this task challenging. We propose two computational methods to incorporate various information sources into a probabilistic consensus structure prior to be used in graphical model inference. Our first model, called Latent Factor Model (LFM), assumes a high degree of correlation among external information sources and reconstructs a hidden variable as a common source in a Bayesian manner. The second model, a Noisy-OR, picks up the strongest support for an interaction among information sources in a probabilistic fashion. Our extensive computational studies on KEGG signaling pathways as well as on gene expression data from breast cancer and yeast heat shock response reveal that both approaches can significantly enhance the reconstruction accuracy of Bayesian Networks compared to other competing methods as well as to the situation without any prior. Our framework allows for using diverse information sources, like pathway databases, GO terms and protein domain data, etc. and is flexible enough to integrate new sources, if available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Probabilistic graphical models, like (Dynamic) Bayesian Networks and Gaussian Graphical Models, have turned out to be useful for extracting meaningful biological insights from experimental data in life science research. These models can infer features of cellular networks in a data driven manner <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. However, network inference from experimental data is challenging because of the typical low signal to noise ratio <ref type="bibr" target="#b4">[5]</ref>. High throughput data like microarray is very high dimensional coupled with a typical low number of replicates and noisy measurements. Reverse engineering of regulatory network on the basis of such data is hence challenging and often fails to reach the desired level of accuracy. To deal with this problem one can either work at experimental level by increasing the sample size, which is practically difficult, or at the inference level by embedding biological background knowledge.</p><p>Integrating known information from databases and biological literature as prior knowledge thus appears to be beneficial. However, biological knowledge covers many different aspects and is widely distributed across multiple knowledge resources, such as pathway databases <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>, Gene Ontology <ref type="bibr" target="#b8">[9]</ref> and others. Hence, integrating this heterogenous information into the learning process is not straight forward.</p><p>In the past most authors have concentrated on integrating one particular information resource into the learning process <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>: E.g. gene regulatory networks were inferred from a combination of gene expression data with transcription factor binding motifs in promoter sequences <ref type="bibr" target="#b10">[11]</ref>, protein-protein interactions <ref type="bibr" target="#b11">[12]</ref>, evolutionary information <ref type="bibr" target="#b12">[13]</ref>, KEGG pathways <ref type="bibr" target="#b13">[14]</ref> and GO anotation <ref type="bibr" target="#b14">[15]</ref>.</p><p>On the technical side several approaches for integrating prior knowledge into the inference of probabilistic graphical models have been published: In <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b16">[17]</ref> the authors only generate candidate structures with significance above a certain threshold according to prior knowledge. Another idea is to introduce a probabilistic Bayesian prior over network structures. E.g. Fro ¨hlich et al. <ref type="bibr" target="#b17">[18]</ref> introduced a prior for individual edges based on an apriori assumed degree of belief. Mukherjee et al. <ref type="bibr" target="#b18">[19]</ref> describes a more general set of priors, which can also capture global network properties, such as scale-free behavior. Wehrli and Husmeier <ref type="bibr" target="#b19">[20]</ref> use a similar form of prior as Fro ¨hlich et al., but additionally combine multiple information sources via a linear weighting scheme. The weights are sampled together with the rest of the parameters and the network structure in a specifically designed Markov Chain Monte Carlo algorithm for Bayesian Network inference. In contrast, Gao and Wang <ref type="bibr" target="#b20">[21]</ref> treat different information sources as statistically independent, and consequently the overall prior is just the product over the priors for the individual information sources. The advantage of the approach is that it is independent from a particular class of probabilistic network models (e.g. Bayesian Networks). The limitation is its strong assumption of non-conditional statistical independence of information sources, which in reality is unlikely, since biological knowledge in different databases is not orthogonal to each other.</p><p>The focus of this paper is on construction of consensus priors from multiple, heterogenous knowledge sources. These consensus priors can then be incorporated for learning probabilistic graphical models (e.g. Bayesian Networks) from experimental data. We are at this point aware of the fact that there is a broad literature on (probabilistic) data integration <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>, which goes beyond our specific question and covers a large variety of different aspects <ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref>.</p><p>In this paper we propose two alternative ways to integrate heterogenous information from multiple knowledge sources into a consensus prior. Our first model, which we call Latent Factor Model (LFM), relies on the idea of a generative process for the individual information sources and uses Bayesian inference to estimate a consensus prior. The second model integrates different information sources via a Noisy-OR gate. Both models are very general and do neither rely on a specific probabilistic model nor on a specific inference procedure. We exemplify the benefit of our consensus priors for the inference of Bayesian Networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Edge-wise Priors for Data Driven Network Inference</head><p>Let D denote our experimental data and W the network graph (represented by an m|m adjacency matrix), which we would like to infer from this data. According to Bayes' rule the probability of network W given data D is given as</p><formula xml:id="formula_0">P(WDD)~P (DDW)P(W) P(D)<label>ð1Þ</label></formula><p>where P(W) is the prior. We assume that P(W) can be decomposed into</p><formula xml:id="formula_1">P(W)~P m i,j P(W ij )<label>ð2Þ</label></formula><p>e.g.</p><formula xml:id="formula_2">P(W ij )~1 n exp { 1 n DW ij { Ŵ W ij D<label>ð3Þ</label></formula><p>where Ŵ W is a matrix of prior edge confidences <ref type="bibr" target="#b17">[18]</ref>. A value of Ŵ W ij close to 1 indicates a high prior degree of belief in the existence of the edge i?j. Our purpose is to compile Ŵ W in a consistent manner from n available information sources. We suppose that each of these sources allows for obtaining an edge confidence matrix by itself, i.e. altogether with n information sources we have n edge confidence matrices X (1) ,X (2) , . . . ,X (n) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Latent Factor Model (LFM)</head><p>The Latent Factor Model is based on the idea that the prior information encoded in matrices X (1) , X (2) , . . . ,X (n) all originate from the true but unknown network W (Figure <ref type="figure">1a</ref>). This specifically implies that direct correlations between edge confidences across matrices can be explained by this hidden dependency. In other words W is a latent factor explaining correlations between the X (k) (k~1,:::,n). We use this notion to conduct joint Bayesian inference on W as well as additional parameters h~(a,b) given X (1) ,X (2) , . . . ,X (n) : P(W,hjX (1) ,X (2) ,:::,X (n) )~P n k~1 P(X (k) jW,h)P(W)P(h) P(X (1) ,X (2) , . . . ,X (n) ) ð4Þ</p><p>The idea behind this equation is that we can identify Ŵ W with the posterior P(W,hDX (1) ,X (2) , . . . ,X (n) ). In other words the prior edge confidences Ŵ W are identical to the posterior edge probabilities learned from our n information sources X (1) , . . . ,X (n) .</p><p>The entries of each matrix X (k) can be assumed to follow beta distributions. More specifically we have:</p><formula xml:id="formula_3">P(X (k) ij Dh,W ij ~1)*Be(X (k) ij ,a k ,1)<label>ð5Þ</label></formula><formula xml:id="formula_4">P(X (k) ij Dh,W ij ~0)*Be(X (k) ij ,1,b k )<label>ð6Þ</label></formula><p>and P(X (k) Dh,W)~P m i,j P(X (k) ij Dh,W ij ) Please note that a and b are vectors and a k and b k are the specific values for source k. If the values in matrix X (k) all either very high (close to 1) or low (close to 0) parameters a k and b k will have a large magnitude. Consequently, P(X (k)  ij Dh,W ij ) will be large, i.e. source k has a large impact. On the other hand, if values in X (k) are rather uniformly distributed, parameters a k and b k will be close to 1, which implies P(X (k)  ij Dh,W ij ) to be close to 0. Thus such an information source has only small impact. By introducing source specific beta distribution parameters we are hence able to weight these source individually.</p><p>We employ an adaptive Markov Chain Monte Carlo (MCMC) strategy <ref type="bibr" target="#b27">[28]</ref> to learn the latent variable W together with parameters h~(a,b). For this purpose we define MCMC moves in network space as well as in parameter space. More specifically, in network space MCMC moves are edge insertion, deletion and reversal. In parameter space a and b are adapted on log-scale using a multivariate Gaussian transition kernel. This is done every 10th iteration. The covariance matrix of the Gaussian transition kernel is initialized to the identity matrix and every 100th iteration updated to the empirical covariance matrix. The number of burnin steps used is 100000 and number of sampling iterations is 500000 for our MCMC algorithm here (see example convergence plot in Figure <ref type="figure">S2</ref> in File S1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Noisy-OR Model (NOM)</head><p>The Noisy-OR represents a non-deterministic disjunctive relation between an effect and its possible causes and has been extensively used in artificial intelligence <ref type="bibr" target="#b28">[29]</ref>. The Noisy-OR model assumes that the relation among the causes and the effect is not-deterministic, allowing the presence of the effect in absence of any of the modeled causes. The Noisy-OR principle is governed by two hallmarks: First, each cause has a probability to produce the effect and second, the probability of each cause being sufficient to produce the effect is independent of the presence of other causes (Figure <ref type="figure">1b</ref>).</p><p>In our case</p><formula xml:id="formula_5">X (1) ij , X (2) ij , …, X (n)</formula><p>ij are interpreted as causes and Ŵ W ij as effect. The link between both is given by</p><formula xml:id="formula_6">Ŵ W ij ~1{ P k (1{X (k) ij )<label>ð7Þ</label></formula><p>In consequence Ŵ W ij becomes close to 1, if the edge i?j has a high confidence in at least one information source, because then the product gets close to 0. Hence, in the Noisy-OR model high edge confidences in one information source can overrule low confidences in other information sources. This is in contrast to the LFM model, where a high level of agreement between information sources is required in order to achieve high values in Ŵ W. In addition to the above described Noisy-OR model, which integrates edge confidences directly into the consensus prior, we also experimented with a variant based on relative ranks, which is in the spirit of Marbach et al. <ref type="bibr" target="#b25">[26]</ref>: Within each matrix X (k) we first assigned each edge confidence X (k) ij to its rank R (k) ij in descending order. Then we converted these absolute ranks into relative ranks by dividing each rank value by the maximum rank:</p><formula xml:id="formula_7">R (k) ij / R (k) ij max ij R (k) ij ð8Þ Matrices R (1) ij , R (2) ij , …, R (n)</formula><p>ij consisting of relative ranks were then considered in Eq. ( <ref type="formula" target="#formula_6">7</ref>) rather than the original matrices X (1)  ij , X (2)  ij , …, X (n) ij . We call this method NOM.RNK in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Information Sources</head><p>In this work we employed GO annotation, two pathways databases (KEGG, PathwayCommons), protein domain annotation (InterPro - <ref type="bibr" target="#b29">[30]</ref>) and protein domain interactions (DOMINE - <ref type="bibr" target="#b30">[31]</ref>) as sources of prior information. According to each of these information sources we calculated for a pair of proteins (a,b) a [0, 1] normalized similarity, which we interpreted as edge confidence. Briefly, for GO annotation we used the default similarity measure for gene products implemented in the R-package GOSim <ref type="bibr" target="#b31">[32]</ref>, which resembles the functional similarity proposed by Schlicket et al. <ref type="bibr" target="#b32">[33]</ref> on the basis of the information theoretic GO term proximity measure by Lin <ref type="bibr" target="#b33">[34]</ref>. Protein domain annotation was compared on the basis of a binary vector representation via the cosine similarity. The relative frequency of interacting protein domain pairs was taken as another confidence measure for an edge a{b. Finally, network information was integrated by computing shortest path distances between pairs of proteins. Details about our similarity measures and their calculation can be found in the supplemental material (Supplement text and Figure <ref type="figure">S1</ref> in File S1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Correlation of Prior Edge Confidences with True Biological Network</head><p>Network Sampling: In a first series of validation experiments we looked, in how far the true network could be recovered purely from the inferred prior edge confidence matrix Ŵ W after a applying a certain threshold. For this purpose we generated 10 networks with 10, 20, 40 and 60 nodes each. These networks later on served as our ground truth. To obtain our ground truth networks we parsed XML files of all KEGG signaling pathways and converted them into graphs via the R-package KEGGgraph <ref type="bibr" target="#b34">[35]</ref>. Then we randomly picked one of these graphs and performed a random walk starting from a randomly selected core node. The random walk was stopped once a predefined number of distinct nodes had been visited, and the corresponding sub-network was returned as a ground truth network (Figure <ref type="figure">S9</ref> in File S1).</p><p>To evaluate the performance of a prior relative to the ground truth network we looked at sensitivity and specificity at different cutoffs for edge confidences. In addition we also computed the balanced accuracy ( = average of sensitivity and specificity) at each cutoff. We then defined the optimal balanced accuracy (oBAC) to be the maximum balanced accuracy over all these cutoffs.</p><p>Simulated Information Sources: In order to better understand the principal behavior of our LFM, NOM and NOM.RNK methods we first simulated matrices X (1) , X (2) , . . . ,X (n) by sampling from Be(1,b) and Be(a,1) distributions according Eq. 6. The whole simulation was repeated 10 times for different parameter combinations and network sizes m. We compared our LFM, NOM and NOM.RNK approaches against a set of other proposed priors namely.</p><p>1. an independent prior (IP), which just takes the product of all matrices X (k) (mimicking the method by Gao et al. <ref type="bibr" target="#b20">[21]</ref>) 2. a variant of IP working on relative ranks (IP.RNK) in the same way as described for the NOM method 3. an unweighted average prior (MP), which takes the arithmetic mean of all matrices X (k) 4. a variant of MP, which works on relative ranks (MP.RNK) and is thus identical with the approach proposed by Marbach et al. <ref type="bibr" target="#b25">[26]</ref> To understand the dependency on a and b we first varied both parameters in the range 2,3,4 and fixed n~6 for networks with m~20 nodes. Our results (Figures <ref type="figure" target="#fig_1">S3,</ref><ref type="figure" target="#fig_2">S4</ref>) indicate a dependency of the priors, on the beta distribution shape parameters. Under most parameter settings the methods using relative ranks performed better than their counterparts using raw edge confidences. This was not true for NOM versus NOM.RNK, however, were the opposite behavior was observed: NOM.RNK compared to NOM lacks specificity. Almost all the models performed better for highly correlated sources (i.e. higher a and b values -see Figure <ref type="figure" target="#fig_3">S5</ref> in File S1). However, the LFM model performed well even with an overall low correlation among sources, which can be interpreted by the ability of the approach to down-weight uninformative/weakly correlated sources. The same held true for MP.RNK. IP was comparable to the other methods for only two parameter combinations (a~4,b~2) and (a~4,b~4). In both cases numerically the beta distribution yields relatively high values in the X (k) matrices, hence the product does not as quickly tend to 0 as with lower values. NOM could beat LFM only for a~2,b~4. In this case confidence values for nonexisting edges are relatively concentrated around 0, and LFM lacks sensitivity. On the other hand LFM performed significantly better than NOM for a~2,b~2 and a~3,b~2 and a~3,b~2. In these cases confidence values for existing edges are relatively high, and NOM lacks specificity. In general it was observable that LFM, MP, MP.RNK, IP and IP.RNK are extremely specific methods, whereas NOM is highly sensitive. Consequently LFM gives the best results in terms of balanced accuracy at low edge probability cut-offs whereas, the NOM does the same at higher cut-offs. The correlation of entries in matrices X (k) were dependent on the beta distribution parameters (Figure <ref type="figure" target="#fig_3">S5</ref> in File S1). For example a~4, b~4 yielded high correlations (median 0 0:7),whereas a~2,b~2 lead to much weaker ones (median 0.2). We also simulated the network reconstruction performance for different number n of sources for networks with m~20 nodes and a~2,b~2. In this situation we could observe that increasing the number of sources helped to improve the accuracy for most methods (Figure <ref type="figure" target="#fig_4">S6</ref> in File S1). The oBAC of our methods were similar to those of the other approaches for a low number of sources (1, 2 and 3 sources). However, with an increasing number of sources (4, 5 and 6) the performance of LFM increased constantly. For NOM an optimum was reached for n~4 sources, after which the performance declined again, suggesting an increasing loss of specificity.</p><p>Decreasing the number of network nodes from m~20 to m~10 yielded a drastic performance loss of LFM (Figure <ref type="figure" target="#fig_5">S7</ref> in File S1). This may be explained be the fact that the LFM method learns from the entries in the matrices X (k) . The larger these matrices, the more independent observations LFM has to learn from. In contrast, increasing the number of network nodes from m~20 to 40 and m~60 for n~6 sources and a~2,b~2 did not influence the previously observed good performance of LFM significantly.</p><p>Weighting of Information Sources: We tested, in how far the automatic weighting of sources provided by the LFM method was able to filter out irrelevant/noisy information. For this purpose we added an additional artificial source, which contained values sampled uniform randomly between 0 and 1. Figure <ref type="figure">2</ref> depicts the posterior expectations for a and b parameters, which were retrieved for individual information sources for 10 sampled networks with m~20 nodes. The picture clearly reveals that the posterior expectation of parameters for the noise source was always close to 1, which indicates an influence close to 0 in the likelihood function (Eq. 6). Hence, the noise source was filtered out effectively.</p><p>Real Information Sources: In a second round of experiments we constructed prior information for our 10 sampled networks from existing biological knowledge encoded in GO, PathwayCommons, KEGG, InterPro and DOMINE (see section ''Information Sources'' and Supplements). We ran the whole simulation for networks of different sizes (m~10,20,40,60).</p><p>Our studies revealed a significant improvement of our suggested methods (LFM, NOM, NOM.RNK) compared to the other models in all cases (Figure <ref type="figure" target="#fig_1">3</ref> together with Figure <ref type="figure">S8</ref> and Table <ref type="table">S4</ref> in File S1). These findings were underlined by a pairwise Wilcox signed rank test to assess the statistical significance of the observed differences (Table <ref type="table" target="#tab_0">1</ref>). At the same time no statistically significant differences between NOM, LFM and NOM.RNK could be observed in terms of oBAC here. The IP prior revealed a oBAC which was almost constantly at 0.5. The reason for this behavior is that multiplicative nature of the IP method often yields numerically very small values, hence making IP close to a pure sparsity prior.</p><p>We also compared the reconstruction performance of our priors to a reconstruction with confidence scores from the STRING database <ref type="bibr" target="#b35">[36]</ref>. The comparison showed a clear and significant advantage of our priors over the STRING in terms of higher oBAC (Figure <ref type="figure" target="#fig_1">3</ref>, Table <ref type="table" target="#tab_0">1</ref> and Tables <ref type="table" target="#tab_0">S1-S3</ref>).</p><p>Most methods showed a very low dependency on the network size, except for the LFM method, which tended to improve the more nodes the network had. The reason for this behavior could be that the LFM method essentially learns from the entries of the edge confidence matrices. Having larger matrices implies more independent observations to learn from, hence the performance increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Enhancement of Data Driven Network Reconstruction Accuracy</head><p>Simulated Data: We next investigated, in how far our priors could enhance the reconstruction performance of Bayesian Networks learned from data. This serves as an example for the ability to enhance probabilistic graphical model inference using our informative priors. For the purpose of this simulation we used the R-package catnet. The catnet package implements a dynamic programming approach to exhaustively search through the space of possible network structures and returns a set of best fitting models. The maximum number of parents per network node can be limited to a user specified number (here: 5). From the set of best fitting network structures the one with minimum BIC value was selected. catnet allows to specify a Bernoulli distribution prior over network structures:</p><formula xml:id="formula_8">P(W)~P m i,j:i=j Ŵ W W ij ij : (1{ Ŵ W ij ) 1{W ij<label>ð9Þ</label></formula><p>Please note that the prior is specified in terms of arbitrarily chosen edge-wise probabilities. In any case, network structures learned by catnet are directed acyclic graphs.</p><p>In order to conduct our simulation we sampled 10 graphs (Figure <ref type="figure">S10</ref> in File S1) with 10 nodes from KEGG signaling pathways (see description in section ''Network Sampling''). While doing so, we specifically ensured that only directed acyclic graph structures were generated (others were discarded). For each generated network multinomially distributed data with 3 catego- ries were sampled using the appropriate functions in R-package catnet. This was repeated 10 times with different numbers of data points (5, 10, 20, 50, 100, 500, 1000 and 5000 data points per variable). We then tested Bayesian Network inference using the LFM, NOM, IP, MP, IP.RNK, MP.RNK, NOM.RNK priors as well as without any prior (no prior -NP). Performance evaluation of learned network structures was done in terms of sensitivity (true positive rate), specificity (1 -false positive rate) and balanced accuracy (average of sensitivity and specificity). paragraph The results showed a clear positive effect of our priors for biologically relevant sample sizes (Figure <ref type="figure" target="#fig_2">4</ref>, rest in S11). Specifically for sample sizes between 20 and 100 LFM, NOM and NOM.RNK were superior to all other methods (FDR v 5% for comparison against IP, IP.RNK, MP, NP for all sample sizes) (See Table <ref type="table">S5</ref> and<ref type="table">S6</ref>). The MP.RNK method was the best competing method, but was significantly outperformed by LFM for all sample sizes w 20. The independence prior (IP) in all cases yielded numerical problems, because for Ŵ W ij values close to 0 the prior in Eq. 9 on log scale tends to minus infinity. Therefore, IP in all cases produced the same constant results. As expected, for larger sample sizes (1000, 5000 data points) the effect of using an informative prior compared to using no prior at all vanished.</p><p>Overall, our proposed methods allowed for a significant improvement in the network reconstruction process compared to using no prior and compared to using the IP, IP.RNK, MP and MP.RNK priors.</p><p>Application to Breast Cancer: We applied our tested approaches to build informative priors for a sub-sample of the well known breast cancer microarray data set by van't Veer et al. <ref type="bibr" target="#b36">[37]</ref> contained in catnet. The data consists of 1214 genes for 98 patient samples: 34 patients developed distant metastases within 5 years, 44 patients remained disease-free after a period of at least 5 years, 18 patients had BRCA1 germline mutations, and 2 were BRCA2 carriers. We selected 173 differentially expressed genes (FDR cutoff 5%) from this dataset via SAM analysis <ref type="bibr" target="#b37">[38]</ref>. From this set of genes we further selected a cluster consisting of 37 genes for network inference via complete linkage clustering.</p><p>Bayesian Network inference via catnet was run with restricting the maximal number of parents per network node to 5. This was done once without using any prior and then with the LFM, NOM, NOM.RNK, IP, IP.RNK, MP and MP.RNK priors (Figure <ref type="figure" target="#fig_3">5a</ref> and 5b). To compare, we also retrieved a network for these 37 genes purely from literature known interactions via the commercial software MetaCore. The literature network consisted of all shortest paths between the 37 genes, which can be computed purely via literature known interactions (Figure <ref type="figure" target="#fig_0">S12</ref> in File S1). That means the literature network mainly consists of indirect interactions.</p><p>We asked (i) in how far inferred edges between two nodes could be explained by shortest paths in the literature network (so-called model view) and (ii) in how far shortest paths between the 37 genes in the literature network corresponded to paths in the inferred network (so-called knowledge view). These two performance measures capture the situation that a) the literature network consists of indirect interactions only and b) there could exist edges in the data, which are so far unknown in the literature for human.</p><p>The results showed that Bayesian Network reconstructions using LFM and NOM priors were significantly closer to the established biological knowledge than without using any prior (Figure <ref type="figure" target="#fig_3">5c</ref>). On the other hand usage of the other priors did not yield any significant overlap with the literature. With the NOM and NOM.RNK priors more than 60% of the inferred edges could be explained by the literature and around 30% of the literature known paths corresponded to pathways in the inferred network. The fact that the latter percentage is much lower than the fraction of literature explainable edges in the inferred network has several reasons: First, a Bayesian Network can only infer a directed acyclic graph, but literature based networks are typically highly cyclic. Second, Bayesian Networks try to uncover conditional independence relationships in the data. However, not all existing molecular interactions might manifest in such relationships on gene expression level. Third, not all literature reported interactions are guaranteed to exist in the specific cells under investigation.</p><p>Application to Yeast Heat-Shock Network: In second application we used our method to infer a network of nine transcription factors (TFs) related to yeast heat-shock response. We used microarray data from GEO (GSE3316), which contains 12 samples. We considered two different sources of established knowledge to compute a consensus prior, namely Gene Ontology (GO) and protein-protein interactions for Yeast obtained from PathwayCommons <ref type="bibr" target="#b6">[7]</ref>. Bayesian Network inference was done in a similar manner as described above. After network reconstruction we compared the resulting network against the gold standard network from the YEASTRACT database <ref type="bibr" target="#b38">[39]</ref> (Figure <ref type="figure" target="#fig_4">6</ref>). Knowledge integration via the NOM prior lead to an improvement of 10% in terms of balanced accuracy compared to using no prior (Figure <ref type="figure" target="#fig_5">7</ref>). The other prior methods (including LFM) did not yield any significant increase in reconstruction performance. The reason for the bad performance of LFM is probably the low number of available knowledge sources combined with a relatively small network size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We proposed two methods to integrate different, heterogenous sources of biological information in form of a consistent structure prior for probabilistic network inference. Our approach takes into consideration diverse information sources, such as e.g. GO, pathway and protein domain data. Our latent factor model (LFM) is based on the assumption of relatedness of biological information across these data sources. In contrast the Noisy-OR model (NOM) picks up the the strongest support for an interaction from any of the knowledge sources.</p><p>Our computational experiments revealed that both of our models yielded priors which were significantly closer to the true biological network than competing methods. Moreover, they could significantly enhance the reconstruction performance of Bayesian Networks compared to a situation without any prior, an independent as well as a mean prior approach. This was true, even if relative ranks were employed, which generally appeared to be beneficial for IP and MP, but not necessarily for NOM. Our methods were also superior to purely using STRING edge confidence scores as prior information. Furthermore, we found that LFM particularly worked particular well, if networks were not too small (Figure <ref type="figure">2</ref>). Therefore, in case of very small networks and/or sparse prior knowledge NOM appears to be a more robust choice. Moreover, NOM is clearly the computationally cheaper approach and thus should be favored for very large (e.g. genomescale) networks. Taken together LFM thus appears to be a recommendable choice mainly for medium sized networks, if a sufficient degree of correlation between information sources can be observed.</p><p>The current framework allows to include a number of heterogenous information sources and is flexible enough to include new ones. As databases for biological information and annotation grow, a larger amount of correlated information can be compiled into prior knowledge, which ultimately can be utilized to more realistic probabilistic model inference from experimental data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Figure 1. Graphical models representing approaches. (a) A general Latent Factor Model (LFM). The random variables x 1 , x 2 and x 3 are highly related variables (left) and an assumption that these related random variables originate from a common, true but unknown variable w results a bayesian network (right) in case of networks w is the true but unknown network. (b) A generalized view of a Noisy-OR model showing the relation between causes x 1:n and effect w through a Noisy-OR function. doi:10.1371/journal.pone.0067410.g001</figDesc><graphic coords="3,58.05,60.78,495.62,138.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Boxplot of posterior expectation parameters learned for individual information sources in 10 randomly sampled subgraphs of KEGG pathways of size m = 20. doi:10.1371/journal.pone.0067410.g003</figDesc><graphic coords="5,58.05,60.77,448.60,462.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Optimally balanced accuracy for reconstructing networks from simulated categorical data with different kinds of prior (# nodes = 10). doi:10.1371/journal.pone.0067410.g004</figDesc><graphic coords="6,58.05,60.78,400.00,379.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Network reconstruction for the breast cancer data (van't Veer et.al.). (a) The reconstructed network from data without using any prior. (b) Reconstructed network using the NOM prior. Black edges in the network could be verified with established literature knowledge, whereas the grey edges could not be verified. (c) The plot shows the edge recovery of the network from two points of view points: knowledge view = literature network mapped onto reconstructed network; model view = reconstructed edges mapped onto literature network. doi:10.1371/journal.pone.0067410.g005</figDesc><graphic coords="7,58.05,60.77,495.20,501.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Yeast (Saccharomyces cerevisiae) heat-shock response network obtained via Bayesian network reconstruction. (a) Network without any prior knowledge, (b) The gold standard network from YEASTRACT database (c) Network reconstructed with prior knowledge (here: NOM). doi:10.1371/journal.pone.0067410.g006</figDesc><graphic coords="8,58.05,60.78,495.60,165.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Reconstruction performance of Yeast (Saccharomyces cerevisiae) heat-shock response network with Bayesian Networks and different priors (NP = No Prior). doi:10.1371/journal.pone.0067410.g007</figDesc><graphic coords="9,58.05,60.78,419.40,432.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Pairwise Wilcoxon test for model performance comparison (false discovery rates) for m~60.</figDesc><table><row><cell cols="2">Methods IP</cell><cell cols="2">IP.RNK LFM</cell><cell>MP</cell><cell cols="3">MP.RNK NOM NOM.RNK</cell></row><row><cell>IP.RNK</cell><cell cols="2">0.0091 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>LFM</cell><cell cols="3">0.0036 0.0036 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MP</cell><cell cols="4">0.2503 0.0249 0.0036 -</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MP.RNK</cell><cell cols="5">0.0036 0.6953 0.0036 0.0036 -</cell><cell>-</cell><cell>-</cell></row><row><cell>NOM</cell><cell cols="5">0.0036 0.0433 0.0137 0.0036 0.0091</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">NOM.RNK 0.0036 0.0333 0.0182 0.0036 0.0137</cell><cell cols="2">0.3889 -</cell></row><row><cell>STRING</cell><cell cols="5">0.0036 0.0068 0.0036 0.1466 0.0036</cell><cell cols="2">0.0036 0.0036</cell></row></table><note><p>For m~10, 20 and 40 see tables S1, S2, and S3 in file S1.). doi:10.1371/journal.pone.0067410.t001</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>PLOS ONE | www.plosone.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>June 2013 | Volume 8 | Issue 6 | e67410</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>PP is supported by a <rs type="funder">B-IT Research School</rs> Grant. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supporting Information</head><p>File S1. Additional plots and tables for the studies on prior knowledge integration. (PDF)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>Conceived and designed the experiments: PP HF. Performed the experiments: PP. Analyzed the data: PP HF. Contributed reagents/ materials/analysis tools: PP HF. Wrote the paper: PP HF.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inferring cellular networks using probabilistic graphical models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friednan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">303</biblScope>
			<biblScope unit="page" from="799" to="805" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bayesian network approach to cell signaling pathway modeling</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sorger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Lauffenburger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Signaling</title>
		<imprint>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Causal proteinsignaling networks derived from multiparameter single-cell data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pe'er</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Lauffenburger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Nolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="page" from="523" to="529" />
			<date type="published" when="2005">2005</date>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Aracne: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Margolin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nemenman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Basso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wiggins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stolovitzky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Suppl 1: S7</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Boosting signal-to-noise in complex biology: prior knowledge is power</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ideker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dutkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="860" to="863" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Human protein reference database and human proteinpedia as discovery tools for systems biology</title>
		<author>
			<persName><forename type="first">Tsk</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pandey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Mol Biol</title>
		<imprint>
			<biblScope unit="volume">577</biblScope>
			<biblScope unit="page" from="67" to="79" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pathway commons, a web resource for biological pathway data</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Cerami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rodchenkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Babur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="685" to="D690" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Kegg for linking genomes to life and the environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kanehisa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Araki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hattori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hirakawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="480" to="D484" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The gene ontology (GO) database and informatics resource</title>
	</analytic>
	<monogr>
		<title level="j">The Gene Ontology Consortium</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="258" to="D261" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>Nucleic Acids Research</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Estimation of genetic networks and functional structures between genes by using bayesian networks and nonparametric regression</title>
		<author>
			<persName><forename type="first">S</forename><surname>Imoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miyano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Estimating gene networks fom gene expression data by combining with bayesian network models with promoter element detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bannai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Imoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tashiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="227" to="236" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using protein-protein interaction for refining gene networks estimated from microarray data by bayesian networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Nariai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Imoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miyano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Utilizing evolutionary information and gene expression data for estimating gene networks with bayesian network models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Banai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Imoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Katayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kanehisa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Bioinform Comput Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1295" to="1313" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computational strategy for discovering druggable gene networks from genome wide rna expression profile</title>
		<author>
			<persName><forename type="first">S</forename><surname>Imoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miyano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yashuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Print</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="559" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Integration of Full-Coverage Probabilistic Functional Networks with Relevance to Specific Biological Processes. DILS &apos;09</title>
		<author>
			<persName><forename type="first">K</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wipat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hallinan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="31" to="46" />
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A statistical method to incorporate biological knowledge for generating testable novel gene regulatory interactions from microarray experiments</title>
		<author>
			<persName><forename type="first">P</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Almasri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">317</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Incorprating literatureknowledge in baysian network for inferring gene networks with gene expression data</title>
		<author>
			<persName><forename type="first">Eyad</forename><surname>Almasri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guanrao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 4th International Symposium on Bioinformatics Research and Applications</title>
		<meeting>eeding of the 4th International Symposium on Bioinformatics Research and Applications</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large scale statistical inference of singnaling pathways from rnai and microarray data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fro ¨hlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fellman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>?ultman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Poustka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beissbarth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Network inference using informative priors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Speed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="14313" to="14318" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reconstructing gene regulatory networks with bayesian networks by combining expression data with multiple sources of prior knowledge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Werhli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Husmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat Appl Genet Mol Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Quantitative utilization of prior biological knowledge in the bayesian network modeling of gene expression data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">359</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A probabilistic functional network of yeast genes</title>
		<author>
			<persName><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Date</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Adai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Marcotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">306</biblScope>
			<biblScope unit="page" from="1555" to="1558" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discovery of biological networks from diverse functional genomic data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Robson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wible</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hibbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chiriac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Integrating largescale functional genomic data to dissect the complexity of yeast regulatory networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Drees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Brem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Genet</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="854" to="861" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Detailing regulatory networks through large scale data integration</title>
		<author>
			<persName><forename type="first">C</forename><surname>Huttenhower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Mutungu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Indik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3267" to="3274" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Wisdom of crowds for robust gene network inference</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName><surname>Ku ¨ffner R</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Vega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Prill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Weile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hallinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Cockell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian integration of networks without gold standards</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<title level="m">Monte Carlo statistical methods</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Probabilistic reasoning in intelligent systems: networks of plausible inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
	<note>1 edition</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interpro: an integrated documentation resource for protein families, domains and functional sites</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Mulder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Apweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Attwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bairoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bateman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief Bioinform</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="225" to="235" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Domine: a database of protein domain interactions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Raghavachari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tasneem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Przytycka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jothi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="656" to="661" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gosim-an r-package for computation of information theoretic go similarities between terms and gene products</title>
		<author>
			<persName><forename type="first">H</forename><surname>Fro ¨hlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Poustka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Beissbarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A new measure for functional similarity of gene products based on gene ontology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schlicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Domingues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rahnenfhrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lengauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">302</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An information-theoretic definition of similarity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Kaufmann</surname></persName>
		</editor>
		<meeting>the 15th International Conference on Machine Learning<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="296" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Kegggraph: a graph approach to kegg pathway in r and bioconductor</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1470" to="1471" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">String: a database of predicted functional associations between proteins</title>
		<author>
			<persName><forename type="first">C</forename><surname>Von Mering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huynen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jaeggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="258" to="261" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Gene expression profiling predicts the outcome of breast cancer</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Van't Veer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van De Vijver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="page" from="530" to="536" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Significance analysis of microarrays applied to the ionizing radiation response</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">G</forename><surname>Tusher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="5116" to="5121" />
			<date type="published" when="2001">2001</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Yeastract: providing a programmatic access to curated transcriptional regulatory associations in saccharomyces cerevisiae through a web services interface</title>
		<author>
			<persName><forename type="first">D</forename><surname>Abdulrehman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Mira</surname></persName>
		</author>
		<author>
			<persName><surname>Lourenc ¸o Ab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="136" to="D140" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
