<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">nature human behaviour Article</title>
				<funder ref="#_2nQKCNK">
					<orgName type="full">European Research Council</orgName>
					<orgName type="abbreviated">ERC</orgName>
				</funder>
				<funder ref="#_hYX7ddP">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-01-19">19 January 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Eleanor</forename><surname>Spens</surname></persName>
							<email>eleanor.spens.20@ucl.ac.uk</email>
							<idno type="ORCID">0000-0002-9327-6342</idno>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UCL Institute of Cognitive Neuroscience</orgName>
								<orgName type="institution" key="instit2">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Neil</forename><surname>Burgess</surname></persName>
							<email>n.burgess@ucl.ac.uk</email>
							<idno type="ORCID">0000-0003-0646-6584</idno>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">UCL Institute of Cognitive Neuroscience</orgName>
								<orgName type="institution" key="instit2">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">UCL Queen Square Institute of Neurology</orgName>
								<orgName type="institution" key="instit2">University College London</orgName>
								<address>
									<region>London, UK</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">nature human behaviour Article</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-01-19">19 January 2024</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1038/s41562-023-01799-z</idno>
					<note type="submission">Received: 30 May 2023 Accepted: 5 December 2023</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Research involving human participants, their data, or biological material Policy information about studies with human participants or human data. See also policy information about sex, gender (identity/presentation), and sexual orientation and race, ethnicity and racism.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Episodic memories are (re)constructed, share neural substrates with imagination, combine unique features with schema-based predictions and show schema-based distortions that increase with consolidation.</p><p>Here we present a computational model in which hippocampal replay (from an autoassociative network) trains generative models (variational autoencoders) to (re)create sensory experiences from latent variable representations in entorhinal, medial prefrontal and anterolateral temporal cortices via the hippocampal formation. Simulations show effects of memory age and hippocampal lesions in agreement with previous models, but also provide mechanisms for semantic memory, imagination, episodic future thinking, relational inference and schema-based distortions including boundary extension. The model explains how unique sensory and predictable conceptual elements of memories are stored and reconstructed by efficiently combining both hippocampal and neocortical systems, optimizing the use of limited hippocampal storage for new and unusual information. Overall, we believe hippocampal replay training generative models provides a comprehensive account of memory construction, imagination and consolidation.</p><p>Episodic memory concerns autobiographical experiences in their spatiotemporal context, whereas semantic memory concerns factual knowledge <ref type="bibr" target="#b0">1</ref> . The former is thought to rapidly capture multimodal experience via long-term potentiation in the hippocampus, enabling the latter to learn statistical regularities over multiple experiences in the neocortex <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref> . Crucially, episodic memory is thought to be constructive; recall is the (re)construction of a past experience, rather than the retrieval of a copy <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7</ref> . But the mechanisms behind episodic (re)construction and its link to semantic memory are not well understood.</p><p>Old memories can be preserved after hippocampal damage despite amnesia for recent ones <ref type="bibr" target="#b7">8</ref> , suggesting that memories initially encoded in the hippocampus end up being stored in neocortical areas, an idea known as 'systems consolidation' <ref type="bibr" target="#b8">9</ref> . The standard model of systems consolidation involves transfer of information from the hippocampus to the neocortex <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b9">10</ref> , whereas other views suggest that episodic and semantic information from the same events can exist in parallel <ref type="bibr" target="#b10">11</ref> . Hippocampal 'replay' of patterns of neural activity during rest <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13</ref> is thought to play a role in consolidation <ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15</ref> . However, consolidation does not just change which brain regions support memory traces; it also converts them into a more abstract representation, a process sometimes referred to as semanticization <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17</ref> .</p><p>Generative models capture the probability distributions underlying data, enabling the generation of realistic new items by sampling from these distributions. Here we propose that consolidated memory takes the form of a generative network, trained to capture the statistical structure of stored events by learning to reproduce them (see also refs.  18,19). As consolidation proceeds, the generative network supports both the recall of 'facts' (semantic memory) and the reconstruction of experience from these 'facts' (episodic memory), in conjunction with additional information from the hippocampus that becomes less necessary as training progresses.</p><p>This builds on existing models of spatial cognition in which recall and imagination of scenes involve the same neural circuits <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> , and is supported by evidence from neuropsychology that damage to the Article <ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> to affect the degree of compression of representations in memory <ref type="bibr" target="#b60">60</ref> to make efficient use of limited HF capacity <ref type="bibr" target="#b41">42</ref> . 9. Memory traces in the hippocampus appear to involve a mixture of sensory and conceptual features, with the latter encoded by concept cells <ref type="bibr" target="#b61">61</ref> , potentially bound together by episode-specific neurons <ref type="bibr" target="#b62">62</ref> . Few models explore how this could happen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consolidation as the training of a generative model</head><p>Our model simulates how the initial representation of memories can be used to train a generative network, which learns to reconstruct memories by capturing the statistical structure of experienced events (or 'schemas'). First, the hippocampus rapidly encodes an event; then, generative networks gradually take over after being trained on replayed representations from the hippocampus. This makes the memory more abstracted, more supportive of generalization and relational inference, but also more prone to gist-based distortion.</p><p>The generative networks can be used to reconstruct (for memory) or construct (for imagination) sensory experience, or to support semantic memory and relational inference directly from their latent variable representations (see Fig. <ref type="figure" target="#fig_0">1</ref>). Before consolidation, the hippocampal autoassociative network encodes the memory. A modern Hopfield network (MHN) <ref type="bibr" target="#b63">63</ref> is used, which can be interpreted such that the feature units activated by an event are bound together by a memory unit <ref type="bibr" target="#b64">64</ref> (see Methods and Supplementary Information). Teacher-student learning <ref type="bibr" target="#b28">29</ref> allows transfer of memories from one neural network to another during consolidation <ref type="bibr" target="#b29">30</ref> . Accordingly, we use outputs from the autoassociative network to train the generative network: random inputs to the hippocampus result in the reactivation of memories, and this reactivation results in consolidation. After consolidation, generative networks encode the information contained in memories. Reliance on the generative networks increases over time as they learn to reconstruct a particular event.</p><p>Specifically, the generative networks are implemented as variational autoencoders (VAEs), which are autoencoders with special properties such that the most compressed layer represents a set of latent variables, which can be sampled from to generate realistic new examples corresponding to the training dataset <ref type="bibr" target="#b65">65,</ref><ref type="bibr" target="#b66">66</ref> . Latent variables can be thought of as hidden factors behind the observed data, and directions in the latent space can correspond to meaningful transformations (see Methods). The VAE's encoder 'encodes' sensory experience as latent variables, while its decoder 'decodes' latent variables back to sensory experience. In psychological terms, after training on a class of stimuli, VAEs can reconstruct such stimuli from a partial input according to the schema for that class, and generate novel stimuli consistent with the schema. (Our use of VAEs is illustrative, and we would expect a range of other generative latent variable models, such as predictive coding networks <ref type="bibr" target="#b67">[67]</ref><ref type="bibr" target="#b68">[68]</ref><ref type="bibr" target="#b69">[69]</ref> , to show similar behaviour.) See Methods and Supplementary Information for further details.</p><p>Generative networks capture the probability distributions underlying events, or 'schemas'. In other words, here 'schemas' are rules or priors (expected probability distributions) for reconstructing a certain type of stimulus (for example, the schema for an office predicts the presence of co-occurring objects such as desks and chairs, facilitating episode generation), whereas concepts represent categories but not necessarily how to reconstruct them. However, schemas and concepts are closely related, and their meanings can overlap, with conflicting definitions in the psychology literature <ref type="bibr" target="#b70">70,</ref><ref type="bibr" target="#b71">71</ref> .</p><p>During perception, the generative model provides an ongoing estimate of novelty from its reconstruction error (also known as 'prediction error', the difference between input and output representations). Aspects of an event that are consistent with previous experience (that is, with low reconstruction error) do not need to be encoded in detail in the autoassociative 'teacher' network <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref> . Once the generative network's reconstruction error is sufficiently low, the hippocampal trace is unnecessary, freeing up capacity for new encodings. However, we have hippocampal formation (HF) leads to deficits in imagination <ref type="bibr" target="#b22">23</ref> , episodic future thinking <ref type="bibr" target="#b23">24</ref> , dreaming <ref type="bibr" target="#b24">25</ref> and daydreaming <ref type="bibr" target="#b25">26</ref> , as well as by neuroimaging evidence that recall and imagination involve similar neural processes <ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28</ref> .</p><p>We model consolidation as the training of a generative model by an initial autoassociative encoding of memory through 'teacher-student learning' <ref type="bibr" target="#b28">29</ref> during hippocampal replay (see also ref. 30). Recall after consolidation has occurred is a generative process mediated by schemas representing common structure across events, as are other forms of scene construction or imagination. Our model builds on: (1) research into the relationship between generative models and consolidation <ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19</ref> , (2) the use of variational autoencoders to model the hippocampal formation <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref> and (3) the view that abstract allocentric latent variables are learned from egocentric sensory representations in spatial cognition <ref type="bibr" target="#b21">22</ref> .</p><p>More generally, we build on the idea that the memory system learns schemas which encode 'priors' for the reconstruction of input patterns <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35</ref> . Unpredictable aspects of experience need to be stored in detail for further learning, while fully predicted aspects do not, consistent with the idea that memory helps to predict the future <ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref> . We suggest that familiar components are encoded in the autoassociative network as concepts (relying on the generative network for reconstruction), while novel components are encoded in greater sensory detail. This is efficient in terms of memory storage <ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref> and reflects the fact that consolidation can be a gradual transition, during which the autoassociative network supports aspects of memory not yet captured by the generative network. In other words, the generative network can reconstruct predictable aspects of an event from the outset on the basis of existing schemas, but as consolidation progresses, the network updates its schemas to reconstruct the event more accurately until the formerly unpredictable details stored in HF are no longer required.</p><p>Our model draws together existing ideas in machine learning to suggest an explanation for the following key features of memory, only subsets of which are captured by previous models:</p><p>1. The initial encoding of memory requires only a single exposure to the event and depends on the HF, while the consolidated form of memory is acquired more gradually <ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b9">10</ref> , as in the complementary learning systems (CLS) model 4 . 2. The semantic content of memories becomes independent of the HF over time <ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref> , consistent with CLS. 3. Vivid, detailed episodic memory remains dependent on HF <ref type="bibr" target="#b45">46</ref> , consistent with multiple trace theory <ref type="bibr" target="#b10">11</ref> (but not with CLS). 4. Similar neural circuits are involved in recall, imagination and episodic future thinking <ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28</ref> , suggesting a common mechanism for event generation, as modelled in spatial cognition <ref type="bibr" target="#b21">22</ref> . 5. Consolidation extracts statistical regularities from episodic memories to inform behaviour <ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48</ref> , and supports relational inference and generalization <ref type="bibr" target="#b48">49</ref> . The Tolman-Eichenbaum machine (TEM) <ref type="bibr" target="#b30">31</ref> simulates this in the domain of multiple tasks with common transition structures (see also ref.  <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b51">52</ref> , consistent with the behaviour of generative models <ref type="bibr" target="#b31">32</ref> . 7. Neural representations in the entorhinal cortex (EC) such as grid cells <ref type="bibr" target="#b52">53</ref> are thought to encode latent structures underlying experiences <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b53">54</ref> , and other regions of the association cortex, such as the medial prefrontal cortex (mPFC), may compress stimuli to a minimal representation <ref type="bibr" target="#b54">55</ref> . 8. Novelty is thought to promote encoding within HF <ref type="bibr" target="#b56">56</ref> , while more predictable events consistent with existing schemas are consolidated more rapidly <ref type="bibr" target="#b57">57</ref> . Activity in the hippocampus can reflect prediction error or mismatch novelty <ref type="bibr" target="#b58">58,</ref><ref type="bibr" target="#b59">59</ref> , and novelty is thought</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Article</head><p><ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> not simulated decay, deletion or capacity constraints in the autoassociative memory part of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Combining conceptual and sensory features in episodic memory</head><p>Consolidation is often considered in terms of fine-grained sensory representations updating coarse-grained conceptual representations, for example, the sight of a particular dog updating the concept of a dog.</p><p>Modelling hippocampal representations as sensory-like is a reasonable simplification, which we make in simulations of the 'basic' model in Fig. <ref type="figure" target="#fig_0">1</ref>. However, memories probably bind together representations along a spectrum from coarse-grained and conceptual to fine-grained and sensory. For example, the hippocampal encoding of a day at the beach is likely to bind together coarse-grained concepts such as 'beach' and 'sea' along with sensory representations such as the melody of an unfamiliar song or the sight of a particular sandcastle, consistent with the evidence for concept cells in the hippocampus <ref type="bibr" target="#b61">61</ref> . (This also fits with the observation that ambiguous images 'flip' between interpretations in perception but are stable when held in memory <ref type="bibr" target="#b72">72</ref> , reflecting how the conceptual content of memories constrains recall.)  </p><formula xml:id="formula_0">[v 1 , v 2 , v 3 , ... v n ] [v 1 , v 2 , v 3 , ... v n ] [v 1 , v 2 , v 3 , ...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Article</head><p><ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> Furthermore, encoding every sensory detail in the hippocampus would be inefficient (elements already predicted by conceptual representations being redundant); an efficient system should take advantage of shared structure across memories to encode only what is necessary <ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41</ref> . Accordingly, we suggest that predictable elements are encoded as conceptual features linked to the generative latent variable representation, while unpredictable elements are encoded in a more detailed and veridical form as sensory features.</p><p>Suppose someone sees an unfamiliar animal in the forest (Fig. <ref type="figure">2b</ref>). Much of the event might be consistent with an existing forest schema, but the unfamiliar animal would be novel. In the extended model (Fig. <ref type="figure">2</ref> and section 'Combining conceptual and unpredictable sensory features'), the reconstruction error per element of the experience is calculated by the generative model during perception, and elements with high reconstruction error are encoded in the autoassociative network as sensory features, along with conceptual features linked to the generative model's latent variable representation. In other words, each pattern is split into a predictable component (approximating the generative network's prediction for the pattern), plus an unpredictable component (elements with high prediction error). This produces a sparser vector than storing every element in detail, increasing the capacity of the network <ref type="bibr" target="#b41">42</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural substrates of the model</head><p>Which brain regions do the components of this model represent? The autoassociative network involves the hippocampus binding together the constituents of a memory in the neocortex, whereas the generative network involves neocortical inputs projecting to latent variable representations in the higher association cortex, which then project back to the neocortex via the HF. The entorhinal (EC), medial prefrontal cortex (mPFC) and anterolateral temporal lobe (alTL) are all prime candidates for the site of latent variable representations. First, the EC is the main route between the hippocampus and the neocortex, and is where grid cells, which are thought to be a latent variable representation of spatial or relational structure <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b53">54</ref> , are most often observed <ref type="bibr" target="#b73">73</ref> . Second, mPFC and its connections to HF play a crucial role in episodic memory processing <ref type="bibr" target="#b70">70,</ref><ref type="bibr" target="#b74">[74]</ref><ref type="bibr" target="#b75">[75]</ref><ref type="bibr" target="#b76">[76]</ref><ref type="bibr" target="#b77">[77]</ref><ref type="bibr" target="#b78">[78]</ref> , are thought to encode schemas <ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b71">71</ref> , are implicated in transitive inference <ref type="bibr" target="#b79">79</ref> and the integration of memories <ref type="bibr" target="#b80">80</ref> , and perform dimensionality reduction by compressing irrelevant features <ref type="bibr" target="#b54">55</ref> . Third, the anterior and lateral temporal cortices associated with semantic memory <ref type="bibr" target="#b81">81</ref> and retrograde amnesia <ref type="bibr" target="#b82">82</ref> probably contain latent variable representations capturing semantic structure. This might correspond to the 'anterior temporal network' associated with semantic dementia <ref type="bibr" target="#b83">83</ref> , while the first network (between sensory and entorhinal cortices) might correspond to the 'posterior medial network' <ref type="bibr" target="#b83">83</ref> , and to the network mapping between visual scenes and allocentric spatial representations <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> .</p><p>Which regions constitute the generative network's decoder? The decoder converts latent variable representations in the higher association cortex back to sensory neocortical representations via HF. Patients with damage to the hippocampus proper but not the EC can generate simple scenes (or fragments thereof), but an intact hippocampus is required for more coherent imagery of complex ones <ref type="bibr" target="#b22">23</ref> . We hypothesize that conceptual units in the hippocampus proper help to generate complex, conceptually coherent scenes (perhaps through a recurrent 'clean up' mechanism), but that an intact EC and its return pathway to the sensory neocortex (the ventral visual stream for images) can still decode representations to some extent in their absence.</p><p>Multiple generative networks can be trained concurrently from a single autoassociative network through consolidation, with different networks optimized for different tasks. In other words, multiple networks could update their parameters to minimize prediction error on the basis of the same replayed memories. This could consist of a primary VAE with latent variables in the EC, plus additional parallel pathways from the higher sensory cortex to the EC via latent variables in the mPFC or the alTL. (Computationally, the shared connections could be fixed as the alternative pathways are trained.) Note that in all cases, return projections to the sensory neocortex via HF are required to decode latent variables into sensory experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling encoding and recall</head><p>Each new event is encoded as an autoassociative trace in the hippocampus, modelled as an MHN. Two properties of this network are particularly important: memorization occurs with only one exposure, and random inputs to the network retrieve stored memories sampled from the whole set of memories (modelling replay).</p><p>We model recall as (re)constructing a scene from a partial input. First, we simulate encoding and replay in the autoassociative network. The network memorizes a set of scenes, representing events, as described above. When the network is given a partial input, it retrieves the closest stored memory. Even when the network is given random noise, it retrieves stored memories (see Fig. <ref type="figure" target="#fig_0">1c</ref>). Second, we simulate recall in the generative network trained on reactivated memories from the autoassociative network, which is able to reconstruct the original image when presented with a partial version of an item from the training data (Fig. <ref type="figure" target="#fig_0">1d</ref>).</p><p>In the basic model (Fig. <ref type="figure" target="#fig_0">1a</ref>), the prediction error could be calculated for each event so that only the unpredictable events are stored in the hippocampus, as the predictable ones can already be retrieved by the generative network (however, this is not simulated explicitly).</p><p>In the extended model (Fig. <ref type="figure">2</ref> and section 'Combining conceptual and unpredictable sensory features'), prediction error is calculated for each element of an event, determining which sensory details are stored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling semantic memory</head><p>Existing semantic memory survives when the hippocampus is lesioned <ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref> , and hippocampal amnesics can describe remote memories more successfully than recent ones <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b84">84</ref> , even if they might not recall them 'episodically' <ref type="bibr" target="#b10">11</ref> . This temporal gradient indicates that the semantic component of memories becomes HF-independent. In the model, EC lesions impair all truly episodic recollection since the return projections from the HF are required for the generation of sensory experiences. Here we describe how remote memories could be retrieved 'in semantic form' despite lesions including the hippocampus and the EC.</p><p>The latent variable representation of an event in the generative network encodes the key facts about the event and can drive semantic memory directly without decoding the representation back into a sensory experience (Fig. <ref type="figure" target="#fig_0">1g</ref>). The output route via HF is necessary for turning latent variable representations in mPFC or alTL into a sensory experience, but the latent variables themselves could support semantic retrieval. Thus, when the HF (including the EC) is removed, the model can still support retrieval of semantic information (see section 'Modelling brain damage' for details). To show this, we trained models to predict attributes of each image from its latent vector. Figure <ref type="figure" target="#fig_1">3a</ref> shows that semantic 'decoding accuracy' increases as training progresses, reflecting the learning of semantic structure as a by-product of learning to reconstruct the sensory input patterns (r s (48) = 0.997, P &lt; 0.001,  95% confidence interval (CI) = 0.987, 1.000). While semantic memory is much more complex than simple classification, richer 'semantic' outputs such as verbal descriptions can also be decoded from latent variable representations of images <ref type="bibr" target="#b85">85,</ref><ref type="bibr" target="#b86">86</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Imagination, episodic future thinking and relational inference</head><p>Here we model the generation of events that have not been experienced from the generative network's latent variables. Events can be generated either by external specification of latent variables (imagination) or by transforming the latent variable representations of specific events (relational inference). The former is simulated by sampling from categories in the latent space then decoding the results (Fig. <ref type="figure" target="#fig_1">3d</ref>). The latter is simulated by interpolating between the latent representations of events (Fig. <ref type="figure" target="#fig_1">3c</ref>) or by doing vector arithmetic in the latent space (Fig. <ref type="figure" target="#fig_1">3b</ref>). This illustrates that the model has learnt some conceptual structure to the data, supporting reasoning tasks of the form 'what is to A as B is to C?', and provides a model for the flexible recombination of memories thought to underlie episodic future thinking <ref type="bibr" target="#b23">24</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling schema-based distortions</head><p>The schema-based distortions observed in human episodic memory increase over time <ref type="bibr" target="#b5">6</ref> and with sleep <ref type="bibr" target="#b51">52</ref> , suggesting an association with consolidation. Recall by the generative network distorts memories towards prototypical representations. Figure <ref type="figure" target="#fig_2">4a</ref>-d shows that handwritten digits from the MNIST dataset <ref type="bibr" target="#b87">87</ref> 'recalled' by a VAE become more prototypical (MNIST is used for this because each image has a single category). Recalled pairs from the same class become more similar, that is, intra-class variation decreases (paired samples t-test t(7,839) = 60.523, P &lt; 0.001, Cohen's d = -0.684, 95% CI = 0.021, 0.022). The pixel space of MNIST digits before and after recall and the latent space of their encodings also show this effect. In summary, recall with a generative network distorts stimuli towards more prototypical representations even when no class information is given during training. As reliance on the generative model increases, so does the level of distortion. Boundary extension and contraction exemplify this phenomenon. Boundary extension is the tendency to remember a wider field of view than was observed <ref type="bibr" target="#b88">88</ref> , while boundary contraction is the opposite <ref type="bibr" target="#b89">89</ref> . Unusually close-up views appear to cause boundary extension, and unusually far away ones boundary contraction <ref type="bibr" target="#b89">89</ref> , although this is debated <ref type="bibr" target="#b90">90,</ref><ref type="bibr" target="#b91">91</ref> . We modelled this by giving the generative network a range of new scenes that were artificially 'zoomed in' or 'zoomed out' compared with those in its training set; its reconstructions are distorted towards the 'typical view' (Fig. <ref type="figure" target="#fig_2">4e</ref>), as in human data. Figure <ref type="figure" target="#fig_2">4g</ref> shows the change in the object size in memory quantitatively, mirroring the  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Combining conceptual and unpredictable sensory features</head><p>In the extended model, memories stored in the hippocampal autoassociative network combine conceptual features (derived from the generative network's latent variables) and unpredictable sensory features (those with a high reconstruction error during encoding) (Fig. <ref type="figure">2</ref>). In these simulations, the conceptual features are simply a one-to-one copy of latent variable representations. (Since latent variable representations are not stable as the generative network learns, concepts derived from latent variables seem more likely to be stored than the latent variables themselves, so this is a simplification; see section 'Extended model' for further details.) Figure <ref type="figure" target="#fig_4">5a</ref>,b shows the stages of recall in the extended model after encoding with a lower or higher prediction error threshold. After decomposing the input into its predictable (conceptual) and unpredictable (sensory) features, the autoassociative network performs pattern completion on the combined representation. The prototypical (that is, predicted) image corresponding to the retrieved conceptual features must then be obtained by decoding the associated latent variable representation into an experience via the return projections to the sensory neocortex. Next, the predictable and unpredictable elements are recombined, simply by overwriting the prototypical prediction with any unpredictable elements, via the connections from the sensory features to the sensory neocortex. The extended model is therefore able to exploit the generative network to reconstruct the predictable aspects of the event from its latent variables, storing only those sensory details that were poorly predicted in the autoassociative network. Equally, as the generative network improves, sensory features stored in the hippocampus may no longer differ significantly from the initial schematic reconstruction in the sensory neocortex, signalling that the hippocampal representation is no longer needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Schema-based distortions in the extended model</head><p>The schema-based distortions shown in the basic model result from the generative network and increase with dependence on it, but memory distortions can also have a rapid onset <ref type="bibr" target="#b93">93,</ref><ref type="bibr" target="#b94">94</ref> . In the extended model, even immediate recall involves a combination of conceptual and sensory features, and the presence of conceptual features induces distortions before consolidation of that specific memory.</p><p>In general, recall is biased towards the 'mean' of the class soon after encoding due to the influence of the conceptual representations (Fig. <ref type="figure" target="#fig_4">5a,</ref><ref type="figure">b</ref>). This is more pronounced when the error threshold for encoding is high, as there is more reliance on the 'prototypical' representations, resulting in the recall of fewer novel features. At a lower error threshold, more sensory detail is encoded, that is, the dimension of the memory trace is higher (r s (3) = -1, P &lt; 0.001). This results in a lower reconstruction error (r s (3) = 1, P &lt; 0.001), indicating lower distortion but at the expense of efficiency.</p><p>External context further distorts memory. Reference 95 asked participants to reproduce ambiguous sketches. A context was established by telling the participants that they would see images from a certain category. After a delay, drawings from memory were distorted to look more like members of the context category. Figure <ref type="figure" target="#fig_6">6b</ref> shows the result of encoding the same ambiguous image with two different externally provided concepts (a cube in the top row, a sphere in the bottom row), represented by the latent variables for each concept, as opposed to the latent variables predicted by the image itself as in Fig. <ref type="figure" target="#fig_4">5a,</ref><ref type="figure">b</ref>. During recall, the encoded concept is retrieved in the autoassociative network, determining the prototypical scene reconstructed by the generative network. This biases recall towards the class provided as context, mirroring Fig. <ref type="figure" target="#fig_6">6a</ref>.</p><p>We also simulate the Deese-Roediger-McDermott (DRM) task <ref type="bibr" target="#b93">93,</ref><ref type="bibr" target="#b94">94</ref> in the extended model to demonstrate its applicability to non-image stimuli. In the DRM task, participants are shown lists of words that are semantically related to 'lure words' not present in the list; there is a robust finding that false recognition and recall of the lure words occur <ref type="bibr" target="#b93">93,</ref><ref type="bibr" target="#b94">94</ref> . In the extended model, gist-based semantic intrusions arise as a consequence of learning the co-occurrence statistics of words. First, the VAE is trained to reconstruct the sets of words in simple stories <ref type="bibr" target="#b96">96</ref> converted to vectors of word counts, representing background knowledge. The system then encodes the experimental lists as the combination of an 'id_n' term capturing unique spatiotemporal context, and the VAE's latent representation of each word list (respectively analogous to the stimulus-unique pixels and the VAE's latent representation of each image in Fig. <ref type="figure" target="#fig_4">5</ref>). As in the human data, lure words are often but not always recalled when the system is presented with 'id_n' (Fig. <ref type="figure">7a</ref>), since the latent variable representations that generate the words in the list also tend to generate the lure word. The system also forgets some words and produces additional semantic intrusions. In addition, the chance of recalling the lure word is higher for longer lists, as in human </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Article</head><p><ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> data from ref. 97, as more related words provide a stronger 'prior' for the lure (Fig. <ref type="figure">7b</ref>) (r s (10) = 0.998, P &lt; 0.001, 95% CI = 0.982, 1.000).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling brain damage</head><p>Recent episodic memory is impaired following damage to the HF, whereas semantic memory, including the semantic content of remote episodes, appears relatively spared. In the model, the semantic form of a consolidated memory survives damage to the HF due to latent variable representations in the mPFC or the alTL (even if those in the EC are lesioned); Fig. <ref type="figure" target="#fig_1">3a</ref> demonstrates how semantic recall performance improves with the age of a memory, reflecting the temporal gradient of retrograde amnesia (see section 'Modelling semantic memory'). However, these semantic 'facts' cannot be used to generate an experience 'episodically' without the generative network's decoder, in agreement with multiple trace theory <ref type="bibr" target="#b10">11</ref> .</p><p>The extent of retrograde amnesia can vary greatly depending in part on which regions of the HF are damaged <ref type="bibr" target="#b98">98,</ref><ref type="bibr" target="#b99">99</ref> . The dissociation of retrograde and anterograde amnesia in some cases suggests that the circuits for encoding memories and the circuits for recalling them via the HF only overlap partially <ref type="bibr" target="#b99">99</ref> . For example, if the autoassociative network is damaged but not the generative network's decoder, the generative network can still perform reconstruction of fully consolidated memories. This could explain varying reports of the gradient of retrograde amnesia when assessing episodic recollection (as opposed to semantic memory), if the generative network's decoder is intact in patients showing spared episodic recollection of early memories <ref type="bibr" target="#b44">45</ref> . Note that the location of damage within the generative network's decoder also affects the resulting deficit in our model. In particular, patients with damage restricted to the hippocampus proper can (re) construct simple scenes but not more complex ones <ref type="bibr" target="#b22">23</ref> .</p><p>Our model also shows the characteristic anterograde amnesia after hippocampal damage, as the hippocampus is required to initially bind features together and support off-line training of the generative model. Anterograde semantic learning would also be impaired by hippocampal damage (as the generative network is trained by hippocampal replay). While hippocampal replay need not be the only mechanism for schema acquisition, it would probably be much slower without the benefit of replay. However, semantic learning over short timescales may be relatively unimpaired, as it is less dependent on extracting regularities from long-term memory <ref type="bibr" target="#b100">100</ref> .</p><p>In semantic dementia, semantic memory is impaired, and remote episodic memory is impaired more than recent episodic memory <ref type="bibr" target="#b101">101</ref> . This would be consistent with lesions to the generative network, as recent memories can rely more on the hippocampal autoassociative network. However, the exact effects would depend on the distribution of damage across the various potential generative networks in the EC, mPFC and alTL. Of these, the alTL network is associated with semantic dementia, and the posterior medial network (corresponding to the generative network between the sensory areas and the EC) with Alzheimer's disease <ref type="bibr" target="#b83">83</ref> .</p><p>Finally, neuropsychological evidence suggests a distinction between familiarity and recollection, and furthermore a partial dissociation between different tests of familiarity; patients with selective hippocampal damage can exhibit recognition memory deficits in a simple 'yes/no' task with similar foils, but not in a 'forced choice' variant involving choosing the more familiar stimulus from a set <ref type="bibr" target="#b102">102</ref> . This is consistent with the idea that lower prediction error in the neocortical generative network indicates familiarity, but retrieval of unique details from the hippocampus is required for more definitive recognition memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We have proposed a model of systems consolidation as the training of a generative neural network, which learns to support episodic memory, and also imagination, semantic memory and inference. This occurs through teacher-student learning. The hippocampal 'teacher' rapidly encodes an event, which may combine unpredictable sensory elements (with connections to and from the sensory cortex) and predictable conceptual elements (with connections to and from latent variable representations in the generative network). After exposure to replayed representations from the 'teacher', the generative 'student' network supports reconstruction of events by forming a schematic representation in the sensory neocortex from latent variables via the HF, with unpredictable sensory elements added from the hippocampus.</p><p>In contrast to the relatively veridical initial encoding, the generative model learns to capture the probability distributions underlying experiences, or 'schemas'. This enables not just efficient recall, reconstructing memories without the need to store them individually, but also imagination (by sampling from the latent variable distributions) and inference (by using the learned statistics of experience to predict Fig. <ref type="figure">7</ref> | Modelling the DRM task. a, First, the VAE is trained to reconstruct simple stories <ref type="bibr" target="#b96">96</ref> converted to vectors of word counts, representing background knowledge. The system then encodes the lists as the combination of an 'id_n' term capturing unique spatiotemporal context, and the VAE's latent variable representation of the word list. In each plot, recalled stimuli when the system is presented with 'id_n' are shown, with output scores treated as probabilities so that words with a score &gt;0.5 (above dashed lines) are recalled. Words from the stimulus list are shown in blue, and lures in red. See Fig. <ref type="figure" target="#fig_0">1</ref> of Supplementary Information for results for the remaining DRM lists. b, The chance of recalling the lure word is higher when longer lists are encoded (blue). Each measurement is averaged across 400 trials (20 random subsets of each of the 20 DRM lists), and error bars give the s.e.m. This qualitatively resembles human data from ref. 97 (grey).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Article</head><p><ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> the values of unseen variables). In addition, semantic memory (that is, factual knowledge) develops as a by-product of learning to predict sensory experience. As the generative model becomes more accurate, the need to store and retrieve unpredicted details in the hippocampus decreases (producing a gradient of retrograde amnesia in cases of hippocampal damage). However, the generative network necessarily introduces distortion compared to the initial memory system. Multiple generative networks can be trained in parallel, and we expect this to include networks with latent variables in the EC, mPFC and alTL.</p><p>We now compare the model's performance to the list of key findings from the introduction:</p><p>1. Gradual consolidation follows one-shot encoding: A memory is encoded in the hippocampal 'teacher' network after a single exposure, and transferred to the generative 'student' network after being replayed repeatedly (Fig. <ref type="figure" target="#fig_0">1c,</ref><ref type="figure">d</ref>). 2. Semantic memory becomes hippocampus-independent: The latent variable representations learned by the generative networks constitute the 'key facts' of an episode, supporting semantic memory (Fig. <ref type="figure" target="#fig_1">3a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Episodic memory remains hippocampus-dependent: Return</head><p>projections to the sensory neocortex via the HF are required to decode the latent variable representations into a sensory experience (Fig. <ref type="figure" target="#fig_0">1</ref>). (EC is required for even simple (re)construction, while the hippocampus proper helps to generate complex conceptually coherent scenes and retrieves unpredictable details that are not yet consolidated into the generative network; see section 'Neural substrates of the model'.) 4. Shared substrate for episode generation: Generative models are a common mechanism for episode generation. Familiar scenes can be reconstructed and new ones can be generated by sampling or transforming existing latent variable representations (Fig. <ref type="figure" target="#fig_1">3b-d</ref>), providing a model for imagination, scene construction and episodic future thinking. 5. Consolidation promotes inference and generalization: Relational inference corresponds to vector arithmetic applied to the generative network's latent variables (Fig. <ref type="figure" target="#fig_1">3b</ref>). 6. Episodic memories are distorted: We show how memory distortions arise from the generative network (Figs. 4, 6 and 7). This extends the model of ref. 32 to relate memory distortion to consolidation. 7. Association cortex encodes latent structure: Latent variable representations in the EC, mPFC, and alTL provide schemas for episodic recollection and imagination (via HF) and for semantic retrieval and inference. 8. Prediction error affects memory processing: The generative network is constantly calculating the reconstruction error of experiences <ref type="bibr" target="#b58">58,</ref><ref type="bibr" target="#b59">59</ref> . Events that are consistent with the existing generative model require less encoding in the autoassociative hippocampal network (Fig. <ref type="figure" target="#fig_4">5</ref>). 9. Episodic memories include conceptual features: When an experience combines a mixture of familiar and unfamiliar elements, both concepts and poorly predicted sensory elements are stored in the hippocampus via association to a specific memory unit.</p><p>Our model can be seen as an update to the complementary learning systems (CLS) <ref type="bibr" target="#b3">4</ref> framework to better account for points 3 to 9 above, reconciling the development of semantic representations in the neocortex (as in CLS) with the continued dependence on the hippocampal formation for episodic recall (as in multiple trace theory <ref type="bibr" target="#b10">11</ref> ). Furthermore, it provides a unified view of: (1) episode generation, (2) how episodic memories change over time and exhibit distortions and (3) how semantic and episodic information are combined in memory. We build on previous work exploring the role of generative networks in consolidation <ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19</ref> , as models of the hippocampal formation <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref> , as priors for episodic memory <ref type="bibr" target="#b34">35</ref> and as models of spatial cognition <ref type="bibr" target="#b21">22</ref> .</p><p>A key aspect of the model is that multiple generative networks can be trained concurrently from a single autoassociative network (Fig. <ref type="figure">2a</ref>) and may be optimized for different tasks. Thus, the latent representations in the mPFC and the alTL may be more closely linked to value or language than those in the EC <ref type="bibr" target="#b103">103,</ref><ref type="bibr" target="#b105">104</ref> . These differences may arise from differences in network structure (for example, the degree of compression) or from additional training objectives that shape their representations <ref type="bibr" target="#b106">105</ref> (for example, the generative network with latent variables in the mPFC might be trained to predict task-relevant value in addition to the EC representations). We expect the generative networks to overlap closer to their sensory inputs/outputs, where general-purpose features are more useful, and diverge as the representations become more abstract (or task-specific if there are additional training objectives) <ref type="bibr" target="#b107">106</ref> . This may involve a primary VAE with latent variables in the EC, with additional pathways from the higher sensory cortex to the EC routed via latent variables in the mPFC or the alTL.</p><p>Our model raises some fundamental questions: Does true episodic memory require event-unique detail, and does this require the hippocampus? Or can prototypical predictions qualify as memory rather than imagination? In the model, event-unique details are initially provided by the hippocampus but can also be provided by the generative network. For example, if you know that someone attended your 8th birthday party and gave you a particular gift, these personal semantic facts need not be hippocampal-dependent but could generate a scene with the right event-specific details, which would seem like episodic memory. The increasingly sophisticated generation of images from text using generative models <ref type="bibr" target="#b108">107</ref> suggests that episode construction from semantic facts is computationally plausible.</p><p>Episodic memories are defined by their unique spatiotemporal context <ref type="bibr" target="#b0">1</ref> . In the model, spatial and temporal context correspond to conceptual features captured by place <ref type="bibr" target="#b109">108,</ref><ref type="bibr" target="#b110">109</ref> or time <ref type="bibr" target="#b111">110,</ref><ref type="bibr" target="#b112">111</ref> cells in the hippocampus and might be linked to latent variable representations formed in the EC, such as grid cells in the medial EC, which form an efficient basis for locations in real <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b113">112,</ref><ref type="bibr" target="#b114">113</ref> or cognitive spaces <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b53">54</ref> , or temporal context representations in the lateral EC <ref type="bibr" target="#b115">114,</ref><ref type="bibr" target="#b116">115</ref> . Events with specific spatial and temporal context can be generated from these latent variable representations, as has been modelled in detail for space <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> .</p><p>More generally, this work builds on the spatial cognition literature, in which place and head direction cells act as latent variables in a generative model <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> , allowing the generation of a scene from a specific viewpoint. References <ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref> explore how egocentric sensory representations could be transformed into allocentric latent variables before storage in the medial temporal lobe and conversely, how egocentric representations could be reconstructed from allocentric ones to support imagery. The latent representations learned through consolidation in our model correspond loosely to the allocentric representations, and the sensory representations produced by HF to the egocentric ones; only egocentric and sensory representations are directly experienced, whereas allocentric and semantic representations are useful abstractions that can also be exploited for efficient hippocampal encoding.</p><p>Our model simplifies the true nature of mnemonic processing in several ways. First, the interaction of sensory and conceptual features in the hippocampus and latent variables in the EC during retrieval could be more complex, with each type of representation contributing to pattern completion of the other as in interactions between items and contextual representations in the Temporal Context Model <ref type="bibr" target="#b117">116</ref> , and might iterate over retrievals from both hippocampal and generative networks <ref type="bibr" target="#b49">50</ref> . Second, our model distinguishes between 'sensory' and 'conceptual' representations in the hippocampus, respectively linked to the sensory neocortex at the input/output of the generative network and to the latent variable layer in the middle. In reality, a gradient of levels of representation in the hippocampus is more likely, from detailed sensory representations to coarse-grained conceptual ones, respectively linked to lower or higher neocortical areas <ref type="bibr" target="#b118">117</ref> , and might map onto Article <ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> the observed functional gradients along the longitudinal axis of the hippocampus <ref type="bibr" target="#b119">118</ref> . Third, our generative network uses back-propagation of the prediction error between output and input patterns to learn. Generative networks with more plausible (if less efficient) learning rules exist <ref type="bibr" target="#b67">[67]</ref><ref type="bibr" target="#b68">[68]</ref><ref type="bibr" target="#b69">[69]</ref> , which have the advantage of producing a prediction error signal at each layer (between top-down prediction and bottom-up recognition), potentially allowing learning of concepts and exceptions at all levels of description. Fourth, considering consolidation as a continual lifelong process rather than during encoding of a single dataset introduces new complexities; these include the instability of latent representations and the prevention of catastrophic forgetting of already consolidated memories as new memories are assimilated into the generative network. The model could be extended to address this, for example, by using replay from the generative network as well as from the hippocampal network, which could reduce catastrophic forgetting and stabilize latent variable representations in both networks <ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b120">119,</ref><ref type="bibr" target="#b121">120</ref> , building on previous research on sleep and learning <ref type="bibr" target="#b122">121</ref> . Fifth, we model semantic memory as prediction of categorical information for an 'event', but future work should model more complex semantic knowledge, for example, by decoding language from latent representations of multimodal stimuli <ref type="bibr" target="#b85">85,</ref><ref type="bibr" target="#b86">86</ref> . In particular, the relationship between semantic memory for specific 'events' and the broader 'web' of general knowledge should be considered.</p><p>Episodic memories contain important sequential structure not modelled by our encoding and reconstruction of simple scenes. Future work could expand the model's scope to sequential information as follows. A range of stimuli could be represented as sequences of arbitrary symbols (including language, spatial trajectories and transitions on a graph). A heteroassociative variant of an MHN, which is better suited to sequential data, could be used to store such stimuli. Specifically, the interpretation of an MHN that we use <ref type="bibr" target="#b64">64</ref> can capture sequential information if the projections from feature units to memory units correspond to the current state, but the projections from memory units back to feature units correspond to the next state so that one state retrieves the next <ref type="bibr" target="#b123">[122]</ref><ref type="bibr" target="#b124">[123]</ref><ref type="bibr" target="#b125">[124]</ref> . With certain modifications based on previous work involving the role of temporal context in memory <ref type="bibr" target="#b117">116,</ref><ref type="bibr" target="#b126">125</ref> , asymmetric MHNs can store sequences with complex repetitions and temporal correlations, such as language. We could then implement the student model as a sequential generative network trained to predict the next input during sequential replay (for example, GPT-2 (ref. 126)). Such networks capture relational structure, developing grid-like latent representations in spatial tasks <ref type="bibr" target="#b30">31</ref> , and learn the gist of narratives. The sequential model could also be applied to phenomena such as event segmentation <ref type="bibr" target="#b128">127</ref> and memory distortions in narratives <ref type="bibr" target="#b5">6</ref> . (Note that for more complex sequential data such as videos, pattern completion of both the current stimulus and the next stimulus would be required, potentially needing a combination of autoassociative and heteroassociative connectivity in the hippocampal network.)</p><p>Our model makes testable predictions. First, if participants learn stimuli generated from known latent variables, it predicts that these specific latent variable representations should develop in the association cortex over time (and that this representation would support, for example, vector arithmetic and interpolation). This could be tested by representational similarity analysis, which should reveal a more conceptual similarity structure developing in the association cortex through consolidation, as opposed to a similarity structure reflecting the sensory stimuli in earlier sensory cortices. If the stimuli also contained slight variation, that is, they were not entirely described by the latent variables, the development of a latent variable representation should be correlated with gist-based distortions in memory and anti-correlated with hippocampal processing of unpredictable elements.</p><p>Second, the model makes multiple predictions about the effects of brain damage. Just as boundary extension is reduced in patients with damage to the HF <ref type="bibr" target="#b129">128</ref> or the vmPFC <ref type="bibr" target="#b130">129</ref> , we predict that other biases towards the 'canonical view' would be attenuated in such patients; for example, healthy controls would distort images with an atypical viewing angle towards a more typical angle in memory, but this would be reduced in, for example, hippocampal patients. Similarly, ambiguous images such as the duck/rabbit drawing 'flip' between interpretations in perception but are stable when held in imagery <ref type="bibr" target="#b72">72</ref> , presumably due to maintained hippocampal conceptual representations. We predict that this conceptual stability in imagery would also be reduced in such patients. This could also extend to non-scene stimuli: if the ref. 95 task were tested with both healthy controls and patients with damage to the generative decoder, we would predict reduced contextual distortion in the latter. Furthermore, patients with an inaccurate generative model, for example, due to semantic dementia, might rely more on sensory features to compensate. (Note that the pattern of deficits would depend on both the nature of the priors encoded in the generative network and the error threshold for encoding. In some cases, damage to the generative network could produce atypical 'priors' rather than suppressing them. Thus, if the generative network is inaccurate but the error threshold for encoding is high, atypical distortions will be observed rather than a reduction in conceptual distortions.)</p><p>Third, the model suggests that the error threshold for encoding could vary depending on the importance of the stimuli or the amount of attentional resource available. For example, emotional salience could lower this threshold, with traumatic memories being encoded in greater sensory detail and with less contextual coherence <ref type="bibr" target="#b131">130,</ref><ref type="bibr" target="#b132">131</ref> . Equally, conditions such as autism spectrum disorder, which are potentially attributable to hypo-priors <ref type="bibr" target="#b133">132</ref> , might be associated with a lower prediction error threshold for veridical storage (and thus reduced conceptual influence on memory and increased sensory detail). In addition, reality monitoring deficits would change the perceived prediction error relative to reality, leading to atypical memory storage (for example, a reduced ability to compensate for prediction errors by storing sensory details).</p><p>Fourth, biological intelligence excels at generalizing from only a small number of examples. The model predicts that learning to generalize rapidly benefits from having a generative model that can create new examples, for example, by inferring variants (as in Fig. <ref type="figure" target="#fig_1">3b</ref>) (see also ref. 133). Finally, the model suggests a link between latent spaces and cognitive maps <ref type="bibr" target="#b135">134</ref> . For example, one might predict that the position of a memory in latent space is reflected in place and grid cell firing, as observed for other conceptual representations <ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b135">134,</ref><ref type="bibr" target="#b136">135</ref> .</p><p>In summary, our proposed model takes inspiration from recent advances in machine learning to capture many of the intriguing phenomena associated with episodic memory, its (re)constructive nature, its relationship to schemas, and consolidation, as well as aspects of imagination, inference and semantic memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>In the simulations, images represent events (except for the DRM <ref type="bibr" target="#b93">93,</ref><ref type="bibr" target="#b94">94</ref> task stimuli). The Shapes3D dataset <ref type="bibr" target="#b137">136</ref> was used throughout, except for the use of MNIST <ref type="bibr" target="#b87">87</ref> to explore certain distortions. Note that one MHN was used per dataset, and one generative model was trained per dataset from the corresponding MHN's outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic model</head><p>In our model, the hippocampus rapidly encodes an event, modelled as one-shot memorization in an autoassociative network (an MHN). Then, generative networks are trained on replayed representations from the autoassociative network, learning to reconstruct memories by capturing the statistical structure of experienced events.</p><p>The generative networks used are variational autoencoders, a type of autoencoder with special properties such that randomly sampling values for the latent variables in the model's 'bottleneck' layer generates valid stimuli <ref type="bibr" target="#b65">65</ref> . Figure <ref type="figure" target="#fig_1">3</ref> of Supplementary Information, adapted Article <ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> from ref. 137, shows how directions in the latent space can correspond to meaningful transformations. While most diagrams show the VAE's input and output layers in the sensory neocortex as separated (in line with conventions for visualizing neural networks), it is important to note that the input and output layers are in fact the same, as shown in Fig. <ref type="figure" target="#fig_0">1b</ref>. There may be considerable overlap between the encoder and decoder, especially closer to the sensory neocortex, but we did not model this explicitly. The autoassociative model is an MHN, with the property that even random input values will retrieve one of the stored patterns via pattern completion. Specifically, we considered the biological interpretation of the MHN as feature units and memory units suggested by ref. 64 (see Supplementary Information for details).</p><p>We modelled consolidation as teacher-student learning, where the autoassociative network is the 'teacher' and the generative network is the 'student' trained on replayed representations from the 'teacher'. We gave random noise (consisting of uniformly sampled values in each channel for each pixel) as an input to the MHN, then used the outputs of the network to train the VAE. (These outputs represent the high-level sensory representations activated by hippocampal pattern completion, via return projections to the sensory cortex.) The noise input to the autoassociative network could potentially represent random activation during sleep <ref type="bibr" target="#b139">[138]</ref><ref type="bibr" target="#b140">[139]</ref><ref type="bibr" target="#b141">[140]</ref> . Attributes such as reward salience might also influence which memories are replayed but were not modelled here <ref type="bibr" target="#b142">141</ref> .</p><p>During the encoding state in our simulations, images were stored in a continuous MHN with high inverse temperature, , set to 20 (higher values of  produce attractor states corresponding to individual memories, while lower values of  make metastable states more likely). Reference <ref type="bibr" target="#b63">63</ref> provides an excellent Python implementation of MHNs that we used in our code. During the 'rest' state, random noise was given as an input N times to the MHN, retrieving N attractor states from the network. (The distribution of retrieved attractor states was not tested but was approximately random, and very few spurious attractors were observed with sufficiently high inverse temperature.) In the main simulations, 10,000 items from the Shapes3D dataset were encoded in the MHN, and 10,000 replayed states were used to train the VAE (that is, N is 10,000). (Rather than replaying new samples from the MHN at each epoch of the VAE's training, a single set of samples was used for efficiency and simplicity.)</p><p>A VAE was then trained on the 'replayed' images from the MHN, using the Keras API for TensorFlow <ref type="bibr" target="#b143">142</ref> . The loss function (that is, the error minimized through training) is the sum of two terms, the reconstruction error and the Kullback-Leibler divergence <ref type="bibr" target="#b65">65</ref> ; the former encourages accurate reconstruction, while the latter (which measures the divergence between the latent variables and a Gaussian distribution) encourages a latent space one can sample from. Specifically, the reconstruction loss in our model is a mean absolute error loss. (Note that the terms reconstruction error and prediction error are used interchangeably throughout.)</p><p>The stochastic gradient descent method used was the AMSGrad variant of the Adam optimizer with early stopping enabled, for a maximum of 50 epochs (where an epoch is a complete pass through the training set). A latent variable vector length of 20, learning rate of 0.001 and Kullback-Leibler weighting of 1 were used in the main results. The variational autoencoders were not optimized for performance, as their purpose is illustrative (more data and hyperparameter tuning would be likely to improve reconstruction accuracy). Architectural choices within the VAE were not principled but were based on successful architectures for similar stimuli in the literature. See Supplementary Information for details of the VAE's architecture. The VAEs were trained using gradient descent and back-propagation as usual; while this method is biologically implausible due to its non-local nature, more plausible learning algorithms might be feasible <ref type="bibr" target="#b144">143</ref> .</p><p>While this was not modelled explicitly, once the generative network's reconstruction error is sufficiently low, the hippocampal trace is unnecessary. As a result, it could be 'marked for deletion' or overwritten in some way, freeing up capacity for new encodings. However, we did not simulate decay, deletion or capacity constraints in the autoassociative memory part of the model. In these simulations, the main cause of forgetting would be interference from new memories in the generative model.</p><p>Note that throughout the simulations, the input to recall was a noisy version of the encoded stimulus image. Specifically, noise was added by replacing a random fraction (0.1 unless stated otherwise) of values in the image array with zero.</p><p>While we used only one modality at a time (imagery for the majority of simulations, text for the DRM task), our model is compatible with the multimodal nature of experience, as multimodal inputs to VAEs are possible, which result in a multimodal latent space <ref type="bibr" target="#b145">144</ref> . This could reflect the multimodal nature of concept cells in the hippocampus <ref type="bibr" target="#b61">61</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling semantic memory</head><p>We modelled semantic memory as the ability to decode latent variables into semantic information without the need to reconstruct the event episodically.</p><p>Decoding accuracy was measured by training a support vector machine to classify the central object's shape from the network's latent variables, using 200 examples at the end of each epoch and measuring classification accuracy on a held-out test set. (Notably, there was good performance with only a small amount of training data when decoding the latent variables, compared with decoding alternative representations such as the sensory input or intermediate layer activations, that is, few-shot learning is possible by making use of compressed 'semantic' representations. See Fig. <ref type="figure">2</ref> of Supplementary Information.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling imagination and inference</head><p>In the generative network, new items can either be generated from externally specified (or randomly sampled) latent variables (imagination), or by transforming the latent variable representations of specific events (relational inference). The former was simulated by sampling from categories in the latent space, then decoding the results (Fig. <ref type="figure" target="#fig_1">3d</ref>). The latter was simulated by interpolating between the latent representations of events (Fig. <ref type="figure" target="#fig_1">3c</ref>) or by doing vector arithmetic in the latent space (Fig. <ref type="figure" target="#fig_1">3b</ref>).</p><p>Examples of the four different object shapes were generated by Monte Carlo sampling for simplicity, that is, samples from the latent space were classified by the semantic decoding classifier, and examples that activate each category are displayed. (Note that there are many alternative ways to do this, for example, by extracting the decision boundaries from the classifier and sampling within the region corresponding to each class.) Generating imagined scenes from more naturalistic inputs, for example, natural language descriptions, would require a much more sophisticated text to the latent space model, but recent machine learning advances suggest that this is possible <ref type="bibr" target="#b146">145</ref> .</p><p>To demonstrate interpolation, each row of Fig. <ref type="figure" target="#fig_1">3c</ref> shows items generated from latent variables along a line in the latent space between two real items from the training data. To demonstrate vector arithmetic, each equation in Fig. <ref type="figure" target="#fig_1">3b</ref> shows 'result = vector A + (vector B - vector C )' (reflecting relational inference problems of the form 'what is to A as B is to C?'), where the result is produced by taking the relation between vector B and vector C , applying that to vector A and decoding the result. In other words, the three items on the right of each equation in Fig. <ref type="figure" target="#fig_1">3b</ref> are real items from the training data. Their latent variable representations are combined as vectors according to the equation shown, giving the latent variable representation from which the first item is generated. Thus, the pair in brackets describes a relation that is applied to the first item on the right to produce the new item on the left of the equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling schema-based distortions</head><p>Items recalled by the generative network become more prototypical, a form of schema-based distortion. This can be shown simply in the basic Article <ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> model, using the MNIST digits dataset <ref type="bibr" target="#b87">87</ref> to exemplify ten clearly defined classes of items (Fig. <ref type="figure" target="#fig_2">4</ref>). To show this quantitatively, we calculated the intra-class variation, measured as the mean variance per pixel, within each MNIST class before and after recall, for 5,000 images from the test set. As expected, the intra-class variation was smaller for the recalled items than for the original inputs. (See Supplementary Information for details of the model architecture.)</p><p>To visualize this, we projected the pixel and latent spaces before and after recall (of 2,000 images from the MNIST test set) into two dimensions (2D) with uniform manifold approximation and projection (UMAP) <ref type="bibr" target="#b147">146</ref> , a dimensionality reduction method, and colour-coded them by class (Fig. <ref type="figure" target="#fig_2">4c,</ref><ref type="figure">d</ref>). The pixel space of MNIST digits (bottom row) and the latent space of their encodings (top row) showed more compact clusters for the generative network's outputs (Fig. <ref type="figure" target="#fig_2">4d</ref>) than for its inputs (Fig. <ref type="figure" target="#fig_2">4c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling boundary extension and contraction</head><p>Boundary extension is the tendency to remember a wider field of view than was observed for certain stimuli <ref type="bibr" target="#b88">88</ref> , while boundary contraction is the tendency to remember a narrower one <ref type="bibr" target="#b89">89</ref> . Whether boundaries are extended or contracted seems to depend on the perceived distance of the central object, with unusually close-up (that is, 'object-oriented') views causing boundary extension, and unusually far away (that is, 'scene-oriented') views causing boundary contraction <ref type="bibr" target="#b89">89</ref> .</p><p>We tested boundary extension and contraction in the basic model by giving it a range of artificially 'zoomed in' or 'zoomed out' images, adapted from Shapes3D scenes not seen during training, and observing the outputs. The 'zoomed in' view was produced by removing n pixels from the margin. The 'zoomed out' view was produced by extrapolating the pixels at the margin outwards by n additional pixels. (In both cases, the new images were then resized to the standard size.) The zoom level is the ratio of the central object size in the output image to the size in the original image, given as a percentage; for example, an image with a zoom level of 80% or a ratio of 0.8 was produced by adding a margin so that the object size is 80% of the original size. As the Shapes3D images are of width and height 64, the number of pixels to add or remove was calculated as 'margin = (32/ratio) - 32'.</p><p>In Fig. <ref type="figure" target="#fig_2">4g</ref>, the change in object size between the noisy input and output was estimated as follows: first the image was converted to a few colours by k-means clustering of pixels. Then, the colour of the central object was determined by finding the predominant colour in a particular central region of the image. A 1D array of pixels corresponding to a vertical line at the horizontal midpoint of the image was processed to identify the fraction of pixels of the central object colour. This enabled us to calculate the change in object size, which we plotted against the degree of 'zoom'. (For this object size estimation approach to work, we filtered the Shapes3D dataset to images where the object colour was different from both the wall and floor colour, and additionally to cubes to minimize shadow.)</p><p>Note that the measure of boundary extension vs contraction displayed in Fig. <ref type="figure" target="#fig_2">4f</ref>, reproduced from ref. 92, was not based on the degree of distortion, but was produced by averaging 'closer' vs 'further' judgements of an identical stimulus image in comparison to the remembered image. This differs from our measure in Fig. <ref type="figure" target="#fig_2">4g</ref>, which instead corresponds to the drawing-based measure in ref. 89; however, these measures have been shown to be correlated <ref type="bibr" target="#b89">89</ref> .</p><p>Figure <ref type="figure" target="#fig_2">4e</ref> shows a few examples of boundary extension and contraction. In the left-and right-hand images of each set, the margin n is chosen such that the central object is 80% and 120% of the original size, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extended model</head><p>The extended model was designed to capture the fact that memory traces in the hippocampus bind together a mixture of sensory and conceptual elements, with the latter encoded by concept cells <ref type="bibr" target="#b61">61</ref> , and the fact that schemas shape the reconstruction of memories even before consolidation, as shown by the rapid onset of schema-based distortions <ref type="bibr" target="#b93">93,</ref><ref type="bibr" target="#b94">94</ref> .</p><p>In the extended model, each scene was initially encoded as the combination of a predictable and an unpredictable component. The predictable component consisted of concepts captured by the latent variables of the generative network, and the unpredictable component consisted of parts of the stimuli that were poorly predicted by the generative network. Thus, the MHN model has both conceptual and sensory feature units, which store the predictable and unpredictable aspects of memory, respectively. While memories may eventually become fully dependent on the generative model, consolidation can be a prolonged process during which the generative network provides schemas for reconstruction and the autoassociative network supports new or detailed information not yet captured by schemas. (The VAE trained in the basic model simulations was used in the extended model simulations described below.)</p><p>How did encoding work in our simulations? For a new image, the prediction error of each pixel was calculated by the VAE (simply the magnitude of the difference between the VAE's input and output). Those pixels with a reconstruction error above the threshold constituted the unpredictable component, while the VAE's latent variables constituted the predictable component, and these components were combined into a single vector and encoded in the MHN. Note that when the threshold is zero, the reconstruction is guaranteed to be perfect, but as the threshold increases, the reconstruction decreases in accuracy.</p><p>How did recall work before full consolidation? After decomposing the input into its predictable (conceptual) and unpredictable (sensory) components, as described above, the autoassociative network could retrieve a memory. The image corresponding to the conceptual component was then obtained by decoding the stored latent variables. Next, the predictable and unpredictable elements were recombined, simply by overwriting the initial schematic reconstruction in the sensory neocortex with any stored (that is, non-zero) sensory features in the hippocampus. Figure <ref type="figure" target="#fig_4">5a</ref>,b shows this process. The lower the error threshold for encoding sensory details, the more information was stored in the autoassociative network, reducing the reconstruction error of recall (see also section 'Modelling schema-based distortions').</p><p>How did replay work? When the autoassociative network was given random noise, both the unpredictable elements and the corresponding latent variables were retrieved. In Fig. <ref type="figure" target="#fig_4">5d</ref>, the square images show the unpredictable elements of MNIST images and the rectangles below these display the vector of latent variables. (As the generative model improves, the presence of hippocampal sensory features that no longer differ from the initial reconstruction indicates that the hippocampal representation is no longer needed, but this was not simulated explicitly.)</p><p>We note that the latent variable representation is not stable as the generative network learns. If some latent variables are stored in the autoassociative network while the VAE continues to change, the quality of the VAE's reconstruction will gradually worsen; this is also a feature of previous models <ref type="bibr" target="#b41">42</ref> . Some degree of degradation may reflect forgetting, but consolidation can be a prolonged process and hippocampal representations can persist in this time. Therefore, we think that concepts derived from latent variables are more likely to be stored than the latent variables themselves, promoting the stability of hippocampal representations. (For example, in humans, language provides a set of relatively persistent concepts, stabilized by the need to communicate.) Projections from the latent variables can classify attributes with only a small amount of training data (see section 'Modelling semantic memory'); we suggest that there could be a two-way mapping between latent variables and concepts, which supports categorization of incoming experience as well as semantic memory. However, for simplicity, the conceptual features were simply a one-to-one copy of latent variable Article <ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> representations in these simulations. It may also be possible to stabilize the latent variable representations by reducing catastrophic forgetting in the generative network, for example, by using generative as well as hippocampal replay <ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b120">119,</ref><ref type="bibr" target="#b121">120</ref> , with the generative network trained on its own self-generated representations in addition to new memories. This builds on previous research suggesting that certain stages of sleep are optimized to preserve remote memories, while others consolidate new ones <ref type="bibr" target="#b122">121</ref> . This could reduce interference of new learning with remote memories in the generative network, as well as make hippocampal representations in the extended model more stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modelling schema-based distortions in the extended model</head><p>Carmichael experiment. We demonstrated the contextual modulation of memory (as in ref. 95) in the extended model by manipulating the conceptual component of an 'event'. To model an external conceptual context being encoded, the original image was stored in the autoassociative network along with activation of a given concept (a cube or a sphere), represented as the latent variables for that class. While in most simulations the latent variables stored in the MHN were simply the output of the VAE's encoder, here an external context activated the conceptual representation, consistent with activity in the EC, mPFC or alTL driven by extrinsic factors.</p><p>During recall, a noisy input was processed by the generative network to produce a predicted conceptual feature and the sensory features not predicted by the prototype for that concept, for input to the autoassociative MHN. Pattern completion in the MHN produced the originally encoded sensory and conceptual features, and these were recombined to produce the final output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRM experiment.</head><p>The DRM task is a classic way to measure gist-based memory distortion <ref type="bibr" target="#b93">93,</ref><ref type="bibr" target="#b94">94</ref> . Here we demonstrated the rapid onset of semantic intrusions in the extended model, coming about as a consequence of learning the co-occurrence statistics of words in a text dataset representing 'background knowledge'. This followed on from previous work showing that VAEs produce semantic intrusions <ref type="bibr" target="#b31">32</ref> .</p><p>In brief, the DRM task involved showing participants a list of words that were semantically related to a 'lure word', which was not present in the list. There was a tendency for both false recognition and false recall of the lure word. We focused on modelling the recall task, but the same model could be extended to recognition (with recognition memory measured by the reconstruction error of the network).</p><p>The generative network was pre-trained on a set of word lists extracted from simple stories <ref type="bibr" target="#b96">96</ref> , representing learning from replayed memories before the DRM stimuli (although replay was not simulated explicitly). Words occurring in &lt;0.05% or &gt;10% of documents were discarded to keep the vocabulary to a manageable size of 4,206 words (this meant that some rarer words in the DRM lists were removed). The word lists were converted to vectors of word counts of length 4,206, in which the value at index i of the vector for a given list indicated the count of word i in the document. As these representations ignore word order, a sequential model was not required (however, this prevented exploring the effect of list position on recall).</p><p>Specifically, the variational autoencoder used for this simulation consisted of an input layer followed by a dropout layer <ref type="bibr" target="#b148">147</ref> projecting to 300 latent variables (sampled from representations of the mean and log variance vectors as usual), and then to an output layer with a sigmoid activation so that predictions were between 0 and 1, with L1 regularization to promote sparsity in this layer. As above, this was implemented using the Keras API for the TensorFlow library <ref type="bibr" target="#b143">142,</ref><ref type="bibr" target="#b149">148</ref> , with the VAE trained to reconstruct input vectors in the usual way.</p><p>Following pre-training of the generative network, the system encoded the DRM stimuli, with each of the 20 word lists represented as vectors of word counts. One important detail was the addition of a term, given by 'id_n' for the nth document in the corpus, representing the unique spatiotemporal context of each word list. (Note that this is a highly simplified representation of the spatiotemporal context <ref type="bibr" target="#b117">116</ref> for illustration.) This enabled recall to be modelled by presenting the network with the 'id_n' term, and seeing which terms were retrieved.</p><p>In the extended model, the latent representation of the word list was encoded in the MHN as the conceptual component, while the unique 'id_n' terms were encoded veridically (as vectors of word counts of length 4,226-the original vocabulary size plus the 20 new 'id_n' terms-with 1 at 'id_n' and 0 elsewhere). The sparse vector representing the unexpected 'id_n' term is analogous to the sparse arrays of poorly predicted pixels in the main simulations of the extended model.</p><p>When the MHN was given 'id_n' as an input, it retrieved the hippocampal trace consisting of 'id_n' together with the latent representation of the word list. The latent representation was then decoded to produce the outputs shown in Fig. <ref type="figure">7a</ref> (a dashed line shows the threshold for recall, interpreting the output as a probability so that words with an output &gt;0.5 are recalled). As in the human data, lure words were often but not always recalled. The system also forgot some words and produced additional semantic intrusions, for example, 'vet' in the case of the 'doctor' list.</p><p>To test the effect of varying the number of associates, as in ref. 97, subsets of the DRM lists were encoded in the way described above. Specifically, to test the probability of lure recall with n associates studied, n items from each DRM list were encoded. For each list, this was repeated for 20 randomly sampled combinations of n items. Once again, recall was tested by giving the system 'id_n' as an input.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 |</head><label>1</label><figDesc>Fig. 1 | Architecture of the basic model. a, First, the hippocampus rapidly encodes an event, modelled as one-shot memorization in an autoassociative network (an MHN). Then, generative networks are trained on replayed representations from the autoassociative network, learning to reconstruct memories by capturing the statistical structure of experienced events. b, A more detailed schematic of the generative network to indicate the multiple layers of, and overlap between, the encoder and decoder (where layers closer to the sensory neocortex overlap more). The generation of a sensory experience, for example, visual imagery, requires the decoder to the sensory neocortex via HF. c, Random noise inputs to the MHN (top row) reactivate its memories (bottom row) after 10,000 items from the Shapes3D dataset are encoded, with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 |</head><label>3</label><figDesc>Fig. 3 | Learning, relational inference and imagination in the generative model. a, Reconstruction error (red) and decoding accuracy (blue) improve during training of the generative model. Decoding accuracy refers to the performance of a support vector classifier trained to output the central object's shape from the latent variables, using 200 examples at the end of each epoch of generative model training. An epoch is one presentation of the training set of 10,000 samples from the hippocampus. b, Relational inference as vector arithmetic in the latent space. The three items on the right of each equation are items from the training data.Their latent variable representations are combined as vectors according to the equation, giving the latent variable representation from which the first item is generated. The pair in brackets describes a relation which is applied to the second item to produce the first. In the top row, the object shape changes from a cylinder to a sphere. In the second, the object shape changes from a cylinder to a cube, and the object colour from red to blue. In the third and fourth, more complex transitions change the object colour and shape, wall colour and angle. c, Imagining new items via interpolation in latent space. Each row shows points along a line in the latent space between two items from the training data, decoded into images by the generative network's decoder. d, Imagining new items from a category. Samples from each of the shape categories of the support vector classifier in a are shown.</figDesc><graphic coords="5,315.19,181.58,238.32,70.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 |</head><label>4</label><figDesc>Fig. 4 | Generative network shows schema-based distortions. a, MNIST digits (top) and the VAE's output for each (bottom). Recalled pairs from the same class become more similar. A total of 10,000 items from the MNIST dataset were encoded in the MHN, and 10,000 replayed samples were used to train the VAE. b, The variation within each MNIST class is smaller for the recalled items than for the original inputs. For each of the 10 classes, the variance per pixel is calculated across 500 images, and the 784 pixel variances are then plotted for each class before and after recall. In each boxplot, the box gives the interquartile range, its central line gives the median, and its whiskers extend to the 10th and 90th percentiles of the data. c,d, The pixel spaces of MNIST digits (bottom row) and the latent space of their encodings (top row) show more compact clusters for the generative network's outputs (d) than for its inputs (c). Pixel and latent spaces are shown projected into 2D with UMAP 146 and colour-coded by class. e, Examples of boundary extension and contraction. Top row: the noisy input images (from a held-out test set), with an atypically 'zoomed out' or 'zoomed in' view (by 80% and 120% on the left and right, respectively) for three original images. Bottom row: the predicted images for each input image, which are distorted towards the 'typical view' in each case. f, Adapted figure from ref. 92, showing the distribution of boundary extension vs contraction as a function of the viewpoint of an image. Specifically, the values are the average of 'closer' vs 'further' judgements, assigned -1 and 1, respectively, of an identical stimulus image in comparison with the remembered image (with 900 trials per position). Error bars give the standard error of the mean. Example stimuli are shown at the bottom. g, In our model, the VAE increases the estimated size of the central object in atypically 'zoomed out' views compared with the training data, and decreases it in atypically 'zoomed in' views, as in ref. 92. Two hundred images are used at each 'zoom level'. See b for a description of boxplot elements.</figDesc><graphic coords="6,144.47,375.48,150.49,113.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Article https://doi.org/10.1038/s41562-023-01799-z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 |</head><label>5</label><figDesc>Fig. 5 | Retrieval dependence on reconstruction error threshold and replay in the extended model. a, The stages of recall are shown from left to right (see Fig.2d), where each row represents an example scene. Each scene consists of a standard Shapes3D image with the addition of novel features (several white squares overlaid on the image with varying opacity). b, Repeating this process with a higher error threshold for encoding (with the same events and partial inputs) means fewer poorly predicted sensory features are stored in the autoassociative MHN, leading to more prototypical recall with increased</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Articlehttps://doi.org/10.1038/s41562-023-01799-z findings in ref.92 (Fig.4f). (Note that the measure of boundary extension vs contraction used by ref.92 is produced by averaging 'closer' vs 'further' judgements of an identical stimulus image in comparison with the remembered image, rather than the drawing-based measure we use, but the two measures are significantly correlated89 .)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 |</head><label>6</label><figDesc>Fig. 6 | Schema-based distortions: effects of conceptual context in the extended model. a, Adapted figure from ref. 95 showing that recall of an ambiguous item (stimulus figure, centre) depends on its context at encoding (word from list 1, left; or list 2, right), as shown by drawing from memory (reproduced figure, far left and far right). b, Memory distortions in the extended model, when the original scene (containing an ambiguous blurred shape) is encoded with a given concept (cube, top; sphere, bottom), represented by the latent variables for that class. Then, a partial input is processed by the generative network to produce predicted conceptual features and the sensory features not predicted by the prototype for that concept (in this case, a white square) for input to the autoassociative MHN. However, pattern completion in the MHN reproduces the originally encoded sensory and conceptual features (cube, top; sphere, bottom), and these are recombined to produce the final output, which is distorted towards the encoded conceptual context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>. 2 | Architecture of the extended model. a, Each scene is initially encoded as a combination of predictable conceptual features related to the latent variables of the generative network and unpredictable sensory features that were poorly predicted by the generative network. An MHN (in red) encodes both sensory and conceptual features (with connections to the sensory neocortex and latent variables in EC, respectively), binding them together via memory units. Memories may eventually be learned by the generative model (in blue), but consolidation</head><label></label><figDesc>can be a prolonged process, during which time the generative network provides schemas for reconstruction and the autoassociative network supports new or detailed information not yet captured by these schemas. Multiple generative networks can be trained concurrently, with different networks optimized for different tasks. This includes networks with latent variables in EC, mPFC and alTL, each with its own semantic projections. However, in all cases, return projections to the sensory neocortex are via HF.</figDesc><table><row><cell></cell><cell></cell><cell>a</cell><cell></cell><cell cols="3">Hippocampus</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Memory</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>units</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Sensory</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Legend:</cell><cell></cell><cell></cell><cell>Feature</cell></row><row><cell></cell><cell></cell><cell cols="2">Autoassociative</cell><cell cols="2">Conceptual</cell><cell>units</cell></row><row><cell></cell><cell></cell><cell></cell><cell>network</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>('teacher')</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Generative</cell><cell></cell><cell>EC</cell></row><row><cell></cell><cell></cell><cell></cell><cell>network</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>('student')</cell><cell cols="2">alTL/mPFC</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Sensory</cell><cell></cell><cell>Sensory</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">neocortex</cell><cell></cell><cell>neocortex</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Semantic</cell><cell>Semantic</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>memory</cell><cell>memory</cell></row><row><cell>b</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Generative network:</cell><cell></cell><cell>Autoassociative network:</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Latent</cell><cell></cell><cell></cell></row><row><cell cols="3">An episode, for example, encountering an</cell><cell>variables</cell><cell>Prediction error per element</cell><cell cols="2">Novel (poorly predicted) sensory data</cell><cell>Sensory features</cell><cell>Memory units</cell></row><row><cell></cell><cell cols="2">unfamiliar animal in a forest</cell><cell>Concepts</cell><cell></cell><cell cols="2">Existing concepts, for example,</cell><cell>Conceptual features</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">'forest'</cell></row><row><cell>c</cell><cell cols="2">Encoding</cell><cell>d</cell><cell></cell><cell cols="2">Recall</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recombined</cell></row><row><cell></cell><cell>Original</cell><cell>Decomposed</cell><cell>Noisy input</cell><cell>Decomposed</cell><cell cols="2">Autoassociative</cell><cell>output</cell></row><row><cell></cell><cell>event</cell><cell>event</cell><cell></cell><cell>input</cell><cell cols="2">network output</cell><cell>Generative</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>network output</cell></row><row><cell>Fig</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>b, An illustration of encoding in the extended model. c, Encoding 'scenes' from the Shapes3D dataset, with each 'scene' decomposed into unpredicted sensory features (top) and conceptual features linked to the generative network's latent variables (bottom). Novel features (white squares overlaid on the image with varying opacity) are added to each 'scene'. d, Recalling 'scenes' (with novel features) from the Shapes3D dataset</head><label></label><figDesc>. First, the input is decomposed; then, the MHN performs pattern completion on both sensory and conceptual features. The conceptual features (which in these simulations are simply the generative network's latent variables) are then decoded into a schema-based prediction, onto which any stored sensory features are overwritten. Diagrams were created using BioRender.com.</figDesc><table><row><cell>Article</cell><cell>https://doi.org/10.1038/s41562-023-01799-z</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">T. Behrens</rs>, <rs type="person">B. Love</rs> and <rs type="person">D. Bush</rs> for useful discussions, and <rs type="person">K. Norman</rs> for constructive comments on an earlier version. Funding support for this work was received from a <rs type="grantName">Wellcome Principal Research Fellowship</rs> 'Neural mechanisms of memory and prediction: Finding structure in experience' (<rs type="grantNumber">222457/Z/21/Z</rs>) (N.B.), a <rs type="institution">Wellcome Collaborative Award 'Organising knowledge</rs> for flexible behaviour in the prefrontal-hippocampal circuitry' (<rs type="grantNumber">214314/Z/18/Z</rs>) (N.B.), and an <rs type="funder">ERC</rs> advanced grant NEUROMEM (N.B.). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hYX7ddP">
					<idno type="grant-number">222457/Z/21/Z</idno>
					<orgName type="grant-name">Wellcome Principal Research Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_2nQKCNK">
					<idno type="grant-number">214314/Z/18/Z</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p>The following datasets (all covered by the Creative Commons Attribution 4.0 License) were used in the simulations: MNIST <ref type="bibr" target="#b88">88</ref> : <ref type="url" target="https://www.tensorflow.org/datasets/catalog/mnist">https://www.tensorflow.org/datasets/catalog/mnist</ref> Shapes3D 137 : <ref type="url" target="https://www.tensorflow.org/datasets/catalog/shapes3d">https://www.tensorflow.org/datasets/catalog/shapes3d</ref> ROCStories 97 : <ref type="url" target="https://cs.rochester.edu/nlp/rocstories">https://cs.rochester.edu/nlp/rocstories</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability</head><p>Code for all simulations can be found at <ref type="url" target="https://github.com/ellie-as/generative-memory">https://github.com/ellie-as/ generative-memory</ref>. Some diagrams were created using BioRender. com.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Article</head><p><ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis</head><p>Code for all simulations, as well as instructions to replicate the results, can be found at <ref type="url" target="https://github.com/ellie-as/generative-memory">https://github.com/ellie-as/generative-memory</ref>. A list of all Python libraries used and their versions can be found at <ref type="url" target="https://github.com/ellie-as/generative-memory/blob/main/requirements.txt">https://github.com/ellie-as/generative-memory/blob/main/requirements.txt</ref>. Diagrams were created using BioRender.com.</p><p>For manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, software must be made available to editors and reviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Portfolio guidelines for submitting code &amp; software for further information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Policy information about availability of data</head><p>All manuscripts must include a data availability statement. This statement should provide the following information, where applicable:</p><p>-Accession codes, unique identifiers, or web links for publicly available datasets -A description of any restrictions on data availability -For clinical datasets or third party data, please ensure that the statement adheres to our policy</p><p>The following datasets (all covered by the Creative Commons Attribution 4.0 License) were used in the simulations: 1) MNIST (LeCun et al., 2010) https://</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reporting summary</head><p>Further information on research design is available in the Nature Portfolio Reporting Summary linked to this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p>E.S. and N.B. designed the research and wrote the paper. E.S. performed the computational modelling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary information</head><p>The online version contains supplementary material available at <ref type="url" target="https://doi.org/10.1038/s41562-023-01799-z">https://doi.org/10.1038/s41562-023-01799-z</ref>.</p><p>Correspondence and requests for materials should be addressed to Eleanor Spens or Neil Burgess.</p><p>Peer review information Nature Human Behaviour thanks Gido van de Ven and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reprints and permissions information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reporting Summary</head><p>Nature Portfolio wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency in reporting. For further information on Nature Portfolio policies, see our Editorial Policies and the Editorial Policy Checklist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistics</head><p>For all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>n/a Confirmed</head><p>The exact sample size (n) for each experimental group/condition, given as a discrete number and unit of measurement A statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly</p><p>The statistical test(s) used AND whether they are one-or two-sided Only common tests should be described solely by name; describe more complex techniques in the Methods section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A description of all covariates tested</head><p>A description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons A full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regression coefficient) AND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals) For null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted Give P values as exact values whenever suitable.</p><p>For Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings For hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes Estimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated Our web collection on statistics for biologists contains articles on many of the points above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Software and code</head><p>Policy information about availability of computer code Data collection Code for data collection (i.e. the retrieval and pre-processing of datasets from online repositories) can be found at <ref type="url" target="https://github.com/ellie-">https://github.com/ellie-</ref>as/generative-memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reporting on sex and gender</head><p>This is a computational study using only secondary data, with no modelling related to sex and/or gender.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reporting on race, ethnicity, or other socially relevant groupings</head><p>This is a computational study using only secondary data, with no modelling related to race/ethnicity/other socially relevant groupings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Population characteristics</head><p>The manuscript discusses how several neurological conditions relate to our model, but data relating to these conditions is not used directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recruitment</head><p>Computational study using only secondary data -not applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics oversight</head><p>This study is in accordance with the ethics regulations at the Institute of Cognitive Neuroscience.</p><p>Note that full information on the approval of the study protocol must also be provided in the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Field-specific reporting</head><p>Please select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Life sciences</head><p>Behavioural &amp; social sciences Ecological, evolutionary &amp; environmental sciences</p><p>For a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Life sciences study design</head><p>All studies must disclose on these points even when the disclosure is negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sample size</head><p>In this computational study, sample sizes sufficient to give statistically significant results were chosen.</p><p>Data exclusions We did not exclude any outliers in our analysis. Where our analysis was restricted to a subset of a particular dataset, this is stated in the Methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Replication</head><p>The code provided on Github (see above) allows the findings to be replicated.</p><p>Randomization Randomisation in the usual sense does not apply as this is a computational study using only secondary data. However in several cases we took repeated random samples from datasets to ensure our results were robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Blinding</head><p>Computational study using only secondary data -not applicable.</p><p>Reporting for specific materials, systems and methods</p><p>We require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How many memory systems are there?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tulving</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Psychol</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="385" to="398" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory for cerebral neocortex</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. R. Soc. Lond. B</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="161" to="234" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simple memory: a theory for archicortex</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phil. Trans. R. Soc. Lond. B</title>
		<imprint>
			<biblScope unit="volume">262</biblScope>
			<biblScope unit="page" from="23" to="81" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Mcnaughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="419" to="457" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The hippocampal memory indexing theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Teyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Discenna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav. Neurosci</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="147" to="154" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Remembering: A Study</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Experimental and Social Psychology</title>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1932">1932</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Constructive memory: past and future</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogues Clin. Neurosci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="7" to="18" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Loss of recent memory after bilateral hippocampal lesions</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Scoville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Milner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurol. Neurosurg. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Retrograde amnesia and memory consolidation: a neurobiological perspective</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Alvarez</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01799-z</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01799-z" />
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="169" to="177" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Memory consolidation and the medial temporal lobe: a simple network model</title>
		<author>
			<persName><forename type="first">P</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="7041" to="7045" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Memory consolidation, retrograde amnesia and the hippocampal complex</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nadel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="217" to="227" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reactivation of hippocampal ensemble memories during sleep</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Mcnaughton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">265</biblScope>
			<biblScope unit="page" from="676" to="679" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Forward and reverse hippocampal placecell sequences during ripples</title>
		<author>
			<persName><forename type="first">K</forename><surname>Diba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Buzski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1241" to="1242" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Selective suppression of hippocampal ripples impairs spatial memory</title>
		<author>
			<persName><forename type="first">G</forename><surname>Girardeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Benchenane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Wiener</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Buzski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Zugaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1222" to="1223" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Disruption of ripple-associated hippocampal activity during rest impairs spatial learning in the rat</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ego-Stengel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Memory transformation and systems consolidation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Winocur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Int. Neuropsychol. Soc</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="766" to="780" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hippocampal ripples and their coordinated dialogue with the default mode network during recent and remote recollection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Raccah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Parvizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="2767" to="2780" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hippocampally-dependent consolidation in a hierarchical model of neocortex</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="24" to="30" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Replay, repair and consolidation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="19" to="26" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modelling spatial recall, mental imagery and neglect</title>
		<author>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="96" to="102" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Remembering the past and imagining the future: a neural model of spatial memory and imagery</title>
		<author>
			<persName><forename type="first">P</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="340" to="375" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A neural-level model of spatial memory and imagery</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bicanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">33752</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Patients with hippocampal amnesia cannot imagine new experiences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Vann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Maguire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="1726" to="1731" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Episodic future thinking: mechanisms and functions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Szpunar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Behav. Sci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="41" to="50" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dreaming with hippocampal damage</title>
		<author>
			<persName><forename type="first">G</forename><surname>Span</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mind-wandering in people with hippocampal damage</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Maguire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2745" to="2754" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Remembering the past and imagining the future: common and distinct neural substrates during event construction and elaboration</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Addis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1363" to="1377" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deconstructing episodic memory with construction</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Maguire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="299" to="306" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1503.02531" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Organizing memories for generalization in complementary learning systems</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Advani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Spruston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Fitzgerald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1438" to="1448" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The Tolman-Eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C R</forename><surname>Whittington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="1249" to="1263" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Optimal forgetting: semantic compression of episodic memories</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Nagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Trk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Orbn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">1008367</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Brain-inspired replay for continual learning with artificial neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Van De Ven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Siegelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Tolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">4069</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Bayesian account of reconstructive memory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hemmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Top. Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="189" to="202" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A model of semantic completion in generative episodic memory</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fayyaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1841" to="1870" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Remembering the past to imagine the future: the prospective brain</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Addis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Buckner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="657" to="661" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">What are memories for? The hippocampus bridges past experience with future decisions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bakkour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="542" to="556" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mnemonic prediction errors promote detailed memories</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Plotkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learn. Mem</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="422" to="434" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Temporal dynamics of competition between statistical learning and episodic memory in intracranial recordings of human visual cortex</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Sherman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="9053" to="9068" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Barlow</surname></persName>
			<affiliation>
				<orgName type="collaboration">in Sensory Communication</orgName>
			</affiliation>
		</author>
		<editor>Rosenblith, W. A.</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="217" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised learning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Barlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="295" to="311" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Place cells may simply be memory cells: memory compression leads to spatial tuning and history dependence</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Benna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fusi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<date type="published" when="2021">2018422118. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Differential effects of early hippocampal pathology on episodic and semantic memory</title>
		<author>
			<persName><forename type="first">F</forename><surname>Vargha-Khadem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">277</biblScope>
			<biblScope unit="page" from="376" to="380" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semantic memory and the human hippocampus</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Manns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="127" to="133" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Memory consolidation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Genzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cold Spring Harb. Perspect. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">21766</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Consolidation and reconsolidation: two lives of memories?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mckenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Eichenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="224" to="233" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sleep-dependent consolidation of statistical learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Durrant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cairney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1322" to="1331" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Patterns across multiple memories are identified over time</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="981" to="986" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Human relational memory requires time and sleep</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Ellenbogen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Titone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="7723" to="7728" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">What learning systems do intelligent agents need? Complementary learning systems theory updated</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="512" to="534" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Complementary learning systems within the hippocampus: a neural network modelling approach to reconciling episodic memory with statistical learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Schapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phil. Trans. R. Soc. B</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="page">20160049</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The role of sleep in false memory formation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Payne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurobiol. Learn. Mem</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="327" to="334" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Microstructure of a spatial map in the entorhinal cortex</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hafting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fyhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Molden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Moser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">436</biblScope>
			<biblScope unit="page" from="801" to="806" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Organizing conceptual knowledge in humans with a gridlike code</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Constantinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Behrens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">352</biblScope>
			<biblScope unit="page" from="1464" to="1468" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Ventromedial prefrontal cortex compression during concept learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Mack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">46</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<idno type="DOI">10.1038/s41562-023-01799-z</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01799-z" />
		<title level="m">Article</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Encoding and retrieval of episodic memories: role of cholinergic and GABAergic modulation in the hippocampus</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hasselmo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Wyble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">V</forename><surname>Wallenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="693" to="708" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Schemas and memory consolidation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page" from="76" to="82" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An unexpected sequence of events: mismatch detection in the human hippocampus</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Maguire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">424</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Associative retrieval processes in the human medial temporal lobe: hippocampal retrieval success and CA1 mismatch detection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Glover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learn. Mem</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="523" to="528" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A model of working memory for latent representations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hedayati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>O'donnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wyble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Hum. Behav</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="709" to="719" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Concept cells: the building blocks of declarative memory functions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Q</forename><surname>Quiroga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="587" to="597" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Hippocampal neurons code individual episodic memories in humans</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Kolibius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Hum. Behav</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1968" to="1979" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Hopfield networks is all you need</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Large associative memory problem in neurobiology and machine learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Krotov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1312.6114" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">An introduction to variational autoencoders</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="307" to="392" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The Helmholtz machine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The free-energy principle: a unified brain theory?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="127" to="138" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Neurobiology of schemas and schema-mediated memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Marlatte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="618" to="631" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">What is a memory schema? A historical perspective on current neuroscience literature</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gilboa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="104" to="114" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Can mental images be ambiguous?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reisberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Hum. Percept. Perform</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Place cells, grid cells, and the brain&apos;s spatial representation system</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kropff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Moser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. of Neurosci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="69" to="89" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Declarative memory consolidation in humans: a prospective functional magnetic resonance imaging study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Takashima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="756" to="761" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Sleep transforms the cerebral trace of declarative memories</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="18778" to="18783" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The organization of recent and remote memories</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Frankland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bontempi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="119" to="130" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Persistent schema-dependent hippocampal-neocortical connectivity during memory encoding and postencoding rest in humans</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T R</forename><surname>Van Kesteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fernndez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hermans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="7550" to="7555" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Coherent theta oscillations and reorganization of spike timing in the hippocampal-prefrontal network upon learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Benchenane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="921" to="936" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">The human ventromedial prefrontal cortex is critical for transitive inference</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Koscik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tranel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cogn. Neurosci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1191" to="1204" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Ventromedial prefrontal cortex is necessary for normal associative inference and memory integration</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Spalding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="3767" to="3775" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Patterns of temporal lobe atrophy in semantic dementia and Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">D</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Neurol</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="433" to="442" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Retrograde amnesia in patients with hippocampal, medial temporal, temporal lobe, or frontal pathology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learn. Mem</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="545" to="557" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Two cortical systems for memory-guided behaviour</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ritchey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="713" to="726" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Spiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Maguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><surname>Amnesia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocase</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="357" to="382" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Show and tell: a neural image caption generator</title>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">ClipCap: CLIP prefix for image captioning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mokady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Hertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Bermano</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2111.09734" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<title level="m">MNIST Handwritten Digit Database</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>AT&amp;T Labs</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Wide-angle memories of close-up scenes</title>
		<author>
			<persName><forename type="first">H</forename><surname>Intraub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Learn. Mem. Cogn</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="179" to="187" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Boundaries extend and contract in scene memory depending on image properties</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="537" to="543" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Searching for boundary extension</title>
		<author>
			<persName><forename type="first">H</forename><surname>Intraub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1463" to="R1464" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Reply to Intraub</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1465" to="R1466" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Systematic transition from boundary extension to contraction along an object-to-scene continuum</title>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Josephs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Konkle</surname></persName>
		</author>
		<idno type="DOI">10.1167/jov.21.9.2124</idno>
		<ptr target="https://doi.org/10.1167/jov.21.9.2124" />
	</analytic>
	<monogr>
		<title level="j">J. Vis</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">On the prediction of occurrence of particular verbal intrusions in immediate recall</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="17" to="22" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Creating false memories: remembering words not presented in lists</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Roediger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Mcdermott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Lear. Mem. Cogn</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="803" to="814" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">An experimental study of the effect of language on the reproduction of visually perceived form</title>
		<author>
			<persName><forename type="first">L</forename><surname>Carmichael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="73" to="86" />
			<date type="published" when="1932">1932</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mostafazadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Knight</surname></persName>
		</editor>
		<meeting>2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Associative processes in false recall and false recognition</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Roediger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="231" to="237" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Long-term retrograde amnesia the crucial role of the hippocampus</title>
		<author>
			<persName><forename type="first">L</forename><surname>Cipolotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="151" to="172" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Human amnesia and the medial temporal region: enduring memory impairment following a bilateral lesion limited to field CA1 of the hippocampus</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zola-Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Amaral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2950" to="2967" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Probabilistic classification learning in amnesia</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Knowlton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learn. Mem</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="106" to="120" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Episodic memory: insights from semantic dementia</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phil. Trans. R. Soc. Lond. B</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="page" from="1423" to="1434" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">The contribution of familiarity to recognition memory is a function of test format when using similar foils</title>
		<author>
			<persName><forename type="first">E</forename><surname>Migo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Montaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quamme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Q. J.Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1198" to="1215" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Strategic retrieval and the frontal lobes: evidence from confabulation and amnesia</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1017" to="1034" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<idno type="DOI">10.1038/s41562-023-01799-z</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01799-z" />
		<title level="m">Article</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Ventromedial prefrontal cortex, adding value to autobiographical memories</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Horner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">28630</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Hippocampal mediation of stimulus representation: a computational theory</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gluck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Myers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="491" to="516" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Understanding neural networks through deep visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1506.06579" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Hierarchical text-conditional image generation with CLIP latents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2204.06125" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">The hippocampus as a spatial map: preliminary evidence from unit activity in the freely-moving rat</title>
		<author>
			<persName><forename type="first">J</forename><surname>O'keefe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dostrovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="171" to="175" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Human hippocampal theta activity during virtual navigation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Ekstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="881" to="889" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Time cells in the hippocampus: a new dimension for mapping memories</title>
		<author>
			<persName><forename type="first">H</forename><surname>Eichenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="732" to="744" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Time cells in the human hippocampus and entorhinal cortex support episodic memory</title>
		<author>
			<persName><forename type="first">G</forename><surname>Umbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="28463" to="28474" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dordek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Meir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Derdikman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">10094</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">The hippocampus as a predictive map</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Stachenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1643" to="1653" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Integrating time from experience in the lateral entorhinal cortex</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tsao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">561</biblScope>
			<biblScope unit="page" from="57" to="62" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">A temporal record of the past with a spectrum of time constants in the monkey entorhinal cortex</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Bright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="20274" to="20283" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">A distributed representation of temporal context</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kahana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Psychol</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="269" to="299" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Episodic memory and beyond: the hippocampus and neocortex in transformation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cabeza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Winocur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nadel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Review Psychol</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="105" to="134" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Functional organization of the hippocampal longitudinal axis</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Strange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Witter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Lein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Moser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="655" to="669" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Off-line replay maintains declarative memories in a model of hippocampal-neocortical interactions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="286" to="294" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title level="m" type="main">Generative replay with feedback connections as a general strategy for continual learning</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Van De Ven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Tolias</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1809.10635" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">A model of autonomous interactions between hippocampus and neocortex driving sleep-dependent memory consolidation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Schapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">2123432119</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Universal Hopfield networks: a general framework for single-shot associative memory models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Millidge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salvatori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning 15561-15583</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">Long sequence Hopfield memory</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Zavatone-Veth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krotov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pehlevan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2306.04532" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Sequential memory with temporal predictive coding</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Memory for serial order: a network model of the phonological loop and its timing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Hitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="551" to="581" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<ptr target="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" />
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">How do we remember events?</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Behav. Sci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="120" to="125" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Attenuated boundary extension produces a paradoxical memory advantage in amnesic patients</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Mullally</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Intraub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Maguire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Biol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="261" to="268" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Boundary extension is attenuated in patients with ventromedial prefrontal cortex damage</title>
		<author>
			<persName><forename type="first">F</forename><surname>De Luca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">The psychobiology of traumatic memory. Clinical implications of neuroimaging studies</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Van Der Kolk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Burbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Suzuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. N. Y. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">821</biblScope>
			<biblScope unit="page" from="99" to="113" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Reduced memory coherence for negative events and its relationship to posttraumatic stress disorder</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bisby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Brewin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Dir. Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="267" to="272" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">When the world becomes &apos;too real&apos;: a Bayesian explanation of autistic perception</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pellicano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Burr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="504" to="510" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">A neural network account of memory replay and knowledge consolidation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="83" to="95" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">What is a cognitive map? Organizing knowledge for flexible behavior</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Behrens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="490" to="509" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Geometry of abstract learned knowledge in the hippocampus</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Nieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">595</biblScope>
			<biblScope unit="page" from="80" to="84" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Burgess</surname></persName>
			<affiliation>
				<orgName type="collaboration">D Shapes dataset</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
			<affiliation>
				<orgName type="collaboration">D Shapes dataset</orgName>
			</affiliation>
		</author>
		<ptr target="https://github.com/google-deepmind/3d-shapes" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Deep feature consistent variational autoencoder</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1133" to="1141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Hippocampal reactivation of random trajectories resembling Brownian diffusion</title>
		<author>
			<persName><forename type="first">F</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baracskay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Csicsvari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="450" to="461" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Can sleep protect memories from catastrophic forgetting?</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">C</forename><surname>Gonzlez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Delanois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bazhenov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">51005</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">The secret life of predictive brains: what&apos;s spontaneous activity for?</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zorzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Corbetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="730" to="743" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Prioritized experience replays on a hippocampal predictive map for learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Igata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ikegaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<date type="published" when="2021">2011266118. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">TensorFlow: a system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI)</title>
		<imprint>
			<publisher>USENIX Assoc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Theories of error back-propagation in the brain</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C R</forename><surname>Whittington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bogacz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn. Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="235" to="250" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Mvae: multimodal variational autoencoder for fake news detection</title>
		<author>
			<persName><forename type="first">D</forename><surname>Khattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Goud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference 2915-2921</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Zero-shot text-to-image generation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">8821</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">UMAP: uniform manifold approximation and projection for dimension reduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Melville</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1802.03426" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Keras Documentation (GitHub</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
