<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Complex Dialogue Mappings via Sentence Semantic Segmentation Guided Conditional Variational Auto-Encoder</title>
				<funder ref="#_ySBhczn #_XBZKFBn">
					<orgName type="full">Beijing Natural Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
							<email>binsun@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shaoxiong</forename><surname>Feng</surname></persName>
							<email>shaoxiongfeng@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yiwei</forename><surname>Li</surname></persName>
							<email>liyiwei@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weichao</forename><surname>Wang</surname></persName>
							<email>wangweichao9@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="department">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fei</forename><surname>Mi</surname></persName>
							<email>mifei2@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="department">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yitong</forename><surname>Li</surname></persName>
							<email>liyitong3@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="department">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Huawei Technologies Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
							<email>likan@bit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Complex Dialogue Mappings via Sentence Semantic Segmentation Guided Conditional Variational Auto-Encoder</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Complex dialogue mappings (CDM), including one-to-many and many-to-one mappings, tend to make dialogue models generate incoherent or dull responses, and modeling these mappings remains a huge challenge for neural dialogue systems. To alleviate these problems, methods like introducing external information, reconstructing the optimization function, and manipulating data samples are proposed, while they primarily focus on avoiding training with CDM, inevitably weakening the model's ability of understanding CDM in human conversations and limiting further improvements in model performance. This paper proposes a Sentence Semantic Segmentation guided Conditional Variational Auto-Encoder (SegCVAE) method which can model and take advantages of the CDM data. Specifically, to tackle the incoherent problem caused by one-tomany, SegCVAE uses response-related prominent semantics to constrained the latent variable. To mitigate the non-diverse problem brought by many-to-one, SegCVAE segments multiple prominent semantics to enrich the latent variables. Three novel components, Internal Separation, External Guidance, and Semantic Norms, are proposed to achieve SegCVAE. On dialogue generation tasks, both the automatic and human evaluation results show that SegCVAE achieves new state-of-the-art performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In open-domain conversations, complex dialogue mappings (CDM) between contexts and responses commonly exist in the real-world data, which bring considerable modeling challenges for neural dialogue models <ref type="bibr" target="#b2">(Csaky et al., 2019;</ref><ref type="bibr" target="#b31">Sun et al., 2021)</ref>: one-to-many mapping can cause models to generate incoherent responses, while many-to-one mapping makes the model produce non-diverse responses. For example, CornellMovie (Danescu-Niculescu-Mizil and <ref type="bibr" target="#b3">Lee, 2011)</ref> and Opensubtitles <ref type="bibr" target="#b18">(Lison and Tiedemann, 2016)</ref> dialogue datasets contain 10.29% (4.18% + 6.11%) and 9.10% (4.79% + 4.31%) CDM data (one-to-many + many-to-one mappings) accordingly. Many existing efforts tried identifying CDM and avoiding training on them to facilitate the dialogue learning. <ref type="bibr">Luong et al.; Li et al. introduce</ref> external information to detach oneto-many pairs into one-to-one pairs, thus reducing the difficulty of model training. Some works reconstruct the optimization functions, allowing model to learn from self-generated qualified responses instead of the ground-truth, thereby avoiding the directly training on many-to-one pairs <ref type="bibr">(Li et al., 2016c;</ref><ref type="bibr">Zhang et al., 2018b;</ref><ref type="bibr" target="#b20">Liu et al., 2020)</ref>. Others train the model through filtered corpora, which usually contains few one-to-many and many-toone dialogue pairs <ref type="bibr">(Xu et al., 2018b;</ref><ref type="bibr" target="#b2">Csaky et al., 2019;</ref><ref type="bibr" target="#b0">Akama et al., 2020)</ref>. For an instance, <ref type="bibr" target="#b2">Csaky et al. (2019)</ref> reported the improvement of a dialogue model with high entropy dialogue pairs (i.e. CDM) filtered out for training, which is consistent with our preliminary experiments in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Table <ref type="table" target="#tab_0">1</ref> shows the comparison results of the same Seq2Seq dialogue model trained with/without CDM. We can observe that the Seq2Seq trained without CDM improves the BLEU <ref type="bibr" target="#b24">(Papineni et al., 2002)</ref>, Emb.Aver. <ref type="bibr" target="#b19">(Liu et al., 2016)</ref> and Coherence <ref type="bibr">(Xu et al., 2018c)</ref> but reduce the Distinct <ref type="bibr">(Li et al., 2016a)</ref> (metrics detailed in Appendix A.1). Moreover, the gains on BLEU are big, but the gains Coherence one-to-many many-to-one 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9</p><p>The Ratio of Samples with CDM 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9</p><p>The Ratio of Samples with CDM 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9</p><p>The Ratio of Samples with CDM on Emb.Aver. and Coherence are small. This result proves the idea that reducing the CDM of the dataset is beneficial for increasing the scores of some automatic evaluation metrics. However, these methods simply ignore the CDM data (10% of the dataset), and in this paper, we argue that these CDM dialogue pairs are still valuable for dialogue training. To explore this, we conduct further experimental investigation by training two Sequence-to-Sequence dialogue models (Seq2Seq) <ref type="bibr" target="#b27">(Shang et al., 2015)</ref> over the "clean" Opensubtitles dataset which does not contain any one-to-many or many-to-one pairs, respectively, and then we gradually introduce one-tomany/many-to-one pairs to fine-tune these models.</p><p>From Figure <ref type="figure" target="#fig_1">1</ref>, we observe that one-to-many and many-to-one dialogue pairs have conflicting effects on Distinct, Emb.Aver. and Coherence, which explains why simply removing them together yields smaller gains. Therefore, instead of staying away from CDM, our primary study of interest is to enable model to effectively learn useful knowledge from these dialogue pairs while avoiding being affected by the disadvantages.</p><p>To achieve this goal, we take inspirations from Conditional Variational AutoEncoder (CVAE) based dialogue generation methods <ref type="bibr" target="#b28">(Shen et al., 2017;</ref><ref type="bibr" target="#b43">Zhao et al., 2017;</ref><ref type="bibr" target="#b1">Chen et al., 2018;</ref><ref type="bibr">Gao et al., 2019a;</ref><ref type="bibr" target="#b31">Sun et al., 2021)</ref> and model the manyto-one and one-to-many from the latent space. However, previous study shows that due to lack of the prior knowledge, latent variable hardly involves semantic relationships, resulting in semantically irrelevant responses <ref type="bibr" target="#b31">(Sun et al., 2021)</ref>. Therefore, we propose a Sentence Semantic Segmentation guided Bring me a cup of coffee, please.</p><p>I do not know.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Same Semantics</head><p>Prominent Semantics The response in a many-to-one mapping has a high proportion in dataset, which deceives models into increasing the generation probability of it, reducing the diversity of generated responses. We promote the same prominent semantics to be associated with the same response, thus extending the response space to enhance the diversity.</p><p>CVAE (SegCVAE), using the sentence semantic segmentation to constrain the latent variable, which models the CDM naturally.</p><p>The complex and ambiguous context semantics can be reduced when segmented into multiple different sub-semantics, so that each sub-semantics may focus on different perspectives of the context. We refer these sub-semantics to as prominent semantics, which can explain CDM naturally (see Figure <ref type="figure" target="#fig_2">2</ref>): When the semantics of a context being segmented into multiple prominent semantics, each of them corresponds to a response (i.e. one-tomany mapping); vice versa, when the prominent semantics is segmented by different contexts semantics, the same prominent semantics can correspond to the same response (i.e. many-to-one mapping). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The open-domain dialogue generation has received dramatic attention recently <ref type="bibr" target="#b33">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b27">Shang et al., 2015;</ref><ref type="bibr" target="#b30">Sordoni et al., 2015)</ref>. <ref type="bibr" target="#b33">Sutskever et al. (2014)</ref> identified that "noisy" data, including one-to-many and many-to-one dialogue pairs, can affect the performance of dialogue systems. To address such "noisy" data, many methods have been proposed in recent years. For instance, a large body of work on introducing external information for reducing the number of noisy data <ref type="bibr" target="#b21">(Luong et al., 2015;</ref><ref type="bibr">Li et al., 2016b;</ref><ref type="bibr">Serban et al., 2016;</ref><ref type="bibr" target="#b43">Zhao et al., 2017;</ref><ref type="bibr" target="#b10">Huber et al., 2018;</ref><ref type="bibr" target="#b8">Ghazvininejad et al., 2018;</ref><ref type="bibr" target="#b34">Tao et al., 2018;</ref><ref type="bibr" target="#b1">Chen et al., 2018;</ref><ref type="bibr">Feng et al., 2020b)</ref>, and a rich line of work reconstructs the objective function to avoid training models directly on such noisy data <ref type="bibr">(Li et al., 2016c;</ref><ref type="bibr" target="#b39">Xu et al., 2017;</ref><ref type="bibr">Zhang et al., 2018a;</ref><ref type="bibr">Xu et al., 2018a;</ref><ref type="bibr">Zhang et al., 2018b;</ref><ref type="bibr">Feng et al., 2020a;</ref><ref type="bibr" target="#b20">Liu et al., 2020;</ref><ref type="bibr" target="#b9">He and Glass, 2020;</ref><ref type="bibr" target="#b22">Mi et al., 2022;</ref><ref type="bibr" target="#b32">Sun et al., 2022;</ref><ref type="bibr">Li et al., 2022a)</ref>. Others design a scoring approach to filter noisy data <ref type="bibr">(Xu et al., 2018b;</ref><ref type="bibr" target="#b2">Csaky et al., 2019;</ref><ref type="bibr" target="#b0">Akama et al., 2020;</ref><ref type="bibr">Li et al., 2022b)</ref>; However, CDM data in human conversations impels valuable information that can help models generate better responses, and these methods cannot learn the valuable information of one-to-many and many-to-one dialogue pairs, nor can they make full use of the advantages of these data. For example, <ref type="bibr">Li et al. (2016b)</ref> uses personal information to reduce the one-to-many dialogue pairs. The Reinforcement Learning based dialogue generation methods <ref type="bibr">(Li et al., 2016c;</ref><ref type="bibr">Zhang et al., 2018a)</ref> only require the generated response to get high reward rather than similar with the ground-truth, which means that some many-to-one dialogue pairs are ignored during training. <ref type="bibr" target="#b2">Csaky et al. (2019)</ref> uses conditional entropy to assess the dialogue pairs, which easily filters one-to-many and many-to-one dialogue pairs.</p><p>In addition to the methods above, CVAE-based dialogue generation methods <ref type="bibr" target="#b28">(Shen et al., 2017;</ref><ref type="bibr" target="#b43">Zhao et al., 2017;</ref><ref type="bibr" target="#b1">Chen et al., 2018;</ref><ref type="bibr">Gao et al., 2019a;</ref><ref type="bibr" target="#b35">Wang et al., 2019;</ref><ref type="bibr" target="#b31">Sun et al., 2021)</ref> provide an idea to learn the essential knowledge of the oneto-many and many-to-one mappings. They try to encode knowledge into a latent space, a posterior probability distribution, and a prior probability distribution. By sampling latent variables, the model can easily generate multiple responses for one context. We follow this rich line of work to explore their applicability in modeling CDM, and we propose new state-of-the-art SegCVAE in dialogue generation task. Compared with the vanilla CVAE, SegCVAE uses sentence semantic segmentation to regularize and guide the latent variables, which avoids the gap between context and latent variables. Different from knowledge-guide CVAE, SegCVAE does not require additional information. Meanwhile, SegCVAE uses the segmented prominent semantics instead of manually-created orthogonal vectors, which is more reasonable than SepaCVAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SegCVAE</head><p>SegCVAE is proposed to model CDM (including one-to-many and many-to-one mappings) through sentence semantic segmentation guided latent variables. As discussed above, different prominent semantics can be segmented from one context semantics, and similar prominent semantics can be segmented from different context semantics, which help latent variables learn the semantic relations, thus modeling one-to-many and many-to-one naturally. In this section, we provide detailed descriptions of the proposed SegCVAE method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>SegCVAE uses multiple prominent semantics (x 1 , x 2 , x 3 , . . .) to learn the probability distribution over response with latent variables, and x i denotes the representation of one prominent semantics. To train SegCVAE, we derive the Stochastic Gradient Variational Bayes framework (Kingma and Welling, 2014; <ref type="bibr" target="#b29">Sohn et al., 2015;</ref><ref type="bibr" target="#b40">Yan et al., 2016)</ref> and gradient blocking trick <ref type="bibr" target="#b31">(Sun et al., 2021)</ref>:</p><formula xml:id="formula_0">L(r, x + ) = max i=1,2,3,... L(r, x i ),<label>(1)</label></formula><formula xml:id="formula_1">L(r, x i ) = E q ϕ (z|re,x i ) (log p Ω (r|z, x i )) -KL(q ϕ (z|r e , x i )||p θ (z|x i )),<label>(2)</label></formula><p>where q ϕ (z|r e , x i ) and p θ (z|x i ) are the recognition network and the prior network that used for sampling latent variable z, respectively. The r e = enc(r) is the semantic vector computed by model's encoder enc based on the response r. The p Ω denotes the model's decoder, which generates the output token based on the conditional probability p Ω (r|z, x i ). Following the gradient blocking trick, x + ∈ (x 1 , x 2 , x 3 , . . .) denotes the prominent semantics vector that makes the variational lower bound largest, and only L(r, x + ) is used to optimize the model.</p><p>To obtain the prominent semantics (x 1 , x 2 , . . .), SegCVAE employs the INTERNAL SEPARATION (IS) and EXTERNAL GUIDANCE (EG). To further capture the relationship among context, prominent semantics, and response, we propose three novel semantic norms: SEMANTIC ALIENATION NORM, SEMANTIC CENTRALIZATION NORM, and SEMAN-TIC DISTILLATION NORM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Internal Separation</head><p>The IS processes sentences through multiple triggers and extracts multiple sets of different words, which can be used to compute different prominent semantics. Each trigger consists of a convolution network Conv and a dense network Dense. The input of a trigger is an embedded matrix representation C of a context with a shape (max_clen, N ), where max_clen represents the maximum length of a context that can be received and N is the dimension of the word-embedding. The C is processed by Conv whose kernel K and stride S are (m, N, 1, chan) and (1, 1, 1, 1), respectively. The chan is the number of channels of the convolution operation, and (m, N ) denotes the shape of convolution kernel.</p><formula xml:id="formula_2">F c = Conv(C, K, S)<label>(3)</label></formula><p>After that, we get the semantic features F c . We squeeze and transpose the F c from (max_clenm + 1, 1, chan) to (chan, max_clenm + 1), and put it into the Dense. The weight of Dense is W with a shape (max_clenm + 1, max_clen).</p><p>We use Sof tM ax function to handle the last dimension of the input (F c • W).</p><formula xml:id="formula_3">F d = Sof tM ax(F c • W) (4)</formula><p>Hence, the shape of F d is (chan, max_clen), which represents the probability of words in the context of attention in different channels. Then, we select the word with highest probability in each channel, which is processed by encoder enc to extract certain semantic information. However, this discrete process will hamper the optimization of model. To ensure the gradient back-propagation, we introduce Gumbel SoftMax (GS; <ref type="bibr" target="#b11">Jang et al. (2017)</ref>) to replace the Sof tM ax (Eq. 4) and selection process:</p><formula xml:id="formula_4">F ′ d = GS(F c • W), GS(Input) = (5)      e input 11 /τ n k=1 e input 1k /τ • • • e input 1n /τ n k=1 e input 1k /τ . . . . . . . . . e input m1 /τ n k=1 e input mk /τ • • • e input m1 /τ n k=1 e input mk /τ      ,</formula><p>where input ij ∈ Input and τ is the temperature parameter. We control τ to be as small as possible, so that the output of GS is as close as possible to the result of argmax(F d ). Thence, we can get the embedded matrix representation of extracted words</p><formula xml:id="formula_5">C IS = F ′ d • C</formula><p>with the shape of (chan, N ). Finally, we randomly initialize M trigger networks in IS to extract M embedded matrix representations (C 1 IS , C 2 IS , . . . , C M IS ) of different wordcombinations from a context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">External Guidance</head><p>The EG is responsible for extracting instructive information from the outside of the sentence (i.e. the vocabulary) according to the context semantics. To achieve this goal, we change the hyper-parameter of the dense network in the trigger defined in the previous section. The new weight matrix of the dense in EG is W ′ , whose shape is changed from (max_clenm + 1, max_clen) to (max_clenm + 1, vocab_size), where vocab_size is the size of the vocabulary. Hence, the results of the dense network denote the probability of words in the vocabulary of attention in different channels. Therefore, the output of EG is a matrix representation V EG of chan words in vocabulary related to the semantics of the input :</p><formula xml:id="formula_6">V EG = GS(F c • W ′ ) • W emb (6)</formula><p>where W emb is the word-embedding matrix whose shape is (vocab_size, N ). Finally, we can also ran-</p><formula xml:id="formula_7">domly initializes M new triggers in EG to extract V 1 EG , V 2 EG , . . ., V M EG .</formula><p>Therefore, the C IS and the V EG are used together to calculate multiple different prominent semantics of a context:</p><formula xml:id="formula_8">x i = enc([C i IS , V i EG ]) | i = 1, 2, . . . , M,<label>(7</label></formula><p>) where enc denotes the model's encoder, x i represents i-th prominent semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Semantic Norms</head><p>We consider self-supervise learning methods and propose SEMANTIC ALIENATION NORM (L san ), SEMANTIC CENTRALIZATION NORM (L scn ), and SEMANTIC DISTILLATION NORM (L sdn ), to constrain the relations among the context, prominent semantics and response. L san and L scn are responsible for promoting the multiple prominent semantics to be closely connected with the context on the basis of maintaining their own independence, which leverages the diversity and coherence of generated responses. L sdn is used to facilitate the construction of semantic relations among prominent semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Semantic Alienation Norm</head><p>We first propose L san to make each prominent semantics as different as possible from other prominent semantics, which is computed by:</p><formula xml:id="formula_9">L san = |I -SoftMax(X • X ⊤ )| (8) X = concatenate([x 1 , x 2 , . . . , x M ])</formula><p>The SoftMax function handles the last dimension of the input matrix X whose shape is M × N . The I is an identity matrix with shape (M × M), and x i is the i-th prominent semantics vector calculated by the enc. X • X ⊤ represents the correlation between a certain prominent semantic vector and other prominent semantic vectors. Figure <ref type="figure">3</ref> shows a schematic of the SEMANTIC ALIENATION NORM.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Semantic Centralization Norm</head><p>Then we propose the L scn to ensure the ensemble result M i x i of these prominent semantic vectors (x 1 , x 2 , . . . , x M ) is similar with the semantics of the original context, which is shown in Figure <ref type="figure">4</ref>.</p><formula xml:id="formula_10">L scn = 1 -cosine(enc(C), M i x i ), (9)</formula><p>where enc(C) represents the vector representation of the original semantics, C is the vector representation of the original context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Semantic Distillation Norm</head><p>Finally, we propose L sdn , which uses the relationship among the ground-truth responses to teach our model to learn the semantic relation of these prominent semantics. That is, with L sdn , the connections between prominent semantics and groundtruth responses can be further established, which  can improve the consistency of response generation and the potential meaning of prominent semantics. In addition, since the representation is performed by enc, L sdn can further adjust its semantic representation capability. The schematic of SEMANTIC DISTILLATION NORM is shown in Figure <ref type="figure" target="#fig_5">5</ref> and L sdn is defined as:</p><formula xml:id="formula_11">L sdn = KL(SoftMax(R gt • R ⊤ gt || SoftMax(R + gen • R +⊤ gen )),<label>(10)</label></formula><p>where R gt with the shape (B × N ) represents the semantic matrix (vector representation) of batch size B ground-truth responses obtained by the model's encoder enc. And R + gen is the concatenated result of the vector representations of B generated responses, which are obtained through the positive prominent semantics x + . Note that the SoftMax function is also used to handle the last dimension of the input matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Objective Function</head><p>The final objective function for training our model is to maximize:</p><formula xml:id="formula_12">L all = L(r, x + ) -λ(L san + L scn + L sdn ), (11)</formula><p>where L(r, x + ) is shown in Eq (1), and λ increases linearly from 0 to 1 in the first snorm_step batches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Setting</head><p>Two well-established open domain dialogue datasets are conducted for experiment: CornellMovie and Opensubtitles. We derived a processed version of Opensubtitles released by <ref type="bibr" target="#b31">Sun et al. (2021)</ref>, which has 5M, 100K, and 50K single-turn dialogue pairs in training, validation, and test sets, respectively. We follow the same process for CornellMovie and we obtain 51,108, 6,358 and 6,249 single-turn dialogue pairs for training, validation, and test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Models</head><p>We compare our model with state-of-the-art dialogue models: A GRU-based Seq2Seq <ref type="bibr" target="#b27">(Shang et al., 2015;</ref><ref type="bibr" target="#b30">Sordoni et al., 2015)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metrics and Training Details</head><p>In addition to the Distinct-n, BLEU, Emb.Aver and Coherence, we also use Perplexity (ppl) <ref type="bibr" target="#b23">(Neubig, 2017)</ref> and Length <ref type="bibr" target="#b2">(Csaky et al., 2019)</ref> to evaluate the performance of all models. For human evaluation, we hired three annotators to rank all models based on their generated responses. Please see Appendix A for more details on experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automatic Evaluation Results</head><p>Table <ref type="table" target="#tab_3">2</ref> reports the automatic results on test data of CornellMovie and Opensubtitles. These results show that our SegCVAE achieves a better performance in terms of most metrics. Specifically, our SegCVAE achieves the best Length, BLEU, Emb.Aver. and Coherence scores on both datasets, which demonstrates the superior performance of our model on generating coherent and related responses. In addition, the SegCVAE has a competitive ppl and Distinct results. Generally speaking, the Distinct metric is easily affect by the length of generated responses. Therefore, as the SegC-VAE generates longest responses, the proportion of repeated words will increase, resulting in a decrease in the distinct score. In a nutshell, these results shows the ability of SegCVAE to handle the general dialogue generation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Human Evaluation Results</head><p>The results of the human evaluation are shown in  <ref type="table" target="#tab_3">2</ref>). When the response lengths are similar on the Opensubtitles, SegCVAE can also achieve the best fluency score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study</head><p>Table <ref type="table" target="#tab_7">4</ref> reports the results of the ablation study.</p><p>It can be seen from the table that after removing IS, L scn and L sdn , respectively, the results all decreased. And the results decreased the most after removing IS, indicating that IS has the most important role in model performance. In addition, we found that after removing EG, the Diversity of the model increased, but the Emb.Aver. and Coherence decreased. This is because EG is mainly responsible for regulating the prominent semantics in the model without deviating from the original semantics. Therefore, by removing EG, the prominent semantics obtained by IS lacks constraints and can become more diverse, but the connection with the context is weaker. Similarly, L san is used to make multiple prominent semantic information segmented to be different from each other, so removing L san will reduce Diversity and increase Emb.Aver. and Coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Case Study</head><p>We use the prominent semantics to guide the generation of responses, which requires the SegCVAE to learn the relations among the contexts, the prominent semantics, and the responses. To illustrate the connection among prominent semantics, context and generated responses, we report three samples and their related words that extract by EG and IS, which are shown in Table <ref type="table" target="#tab_8">5</ref>. Note that the words extracted by EG and IS are used for calculating prominent semantics through the encoder.</p><p>In Table <ref type="table" target="#tab_8">5</ref>, we can notice that the output of EG is difficult to relate to the response. We suppose Model Distinct-1 Distinct-2 Distinct-3 BLEU-1 BLEU-2 BLEU-3 BLEU-4 Emb.Aver. Coherence SegCVAE 0.021±.00 0.323±.01 0.781±.02 0.437±.01 0.364±.01 0.310±.01 0.249±.01 0.836±.00 0.707±.01 -wo. IS 0.010±.00 0.179±.02 0.570±.05 0.348±.10 0.291±.09 0.248±.07 0.199±.06 0.693±.16 0.519±.20 -wo. EG 0.022±.00 0.353±.03 0.816±.03 0.396±.02 0.328±.02 0.277±.02 0.222±.01 0.815±.01 0.673±.03 -wo. Lsan 0.018±.01 0.289±.07 0.731±.08 0.432±.02 0.358±.01 0.302±.01 0.239±.01 0.843±.01 0.727±.02 -wo. Lscn 0.021±.00 0.313±.03 0.755±.05 0.421±.00 0.349±.00 0.296±.00 0.238±.00 0.833±.00 0.703±.00 -wo. L sdn 0.020±.00 0.320±.01 0.774±.01 0.433±.00 0.358±.00 0.302±.00 0.243±.00 0.836±.01 0.703±.02  that this would blame the poor interpretability of neural models and the lack of annotations. Note that EG is trained by self-supervised learning without any explicit-knowledge annotations. Therefore, it learns to minimise the designed loss, which may produce some unrecognised results or intermediate features for human. We speculate that introducing annotations or knowledge that consistent with human cognition will help the model to produce more interpretable and better performance. We consider it as an important future work and require more efforts on this topic.</p><p>We also collect the generated responses and show them in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Effectiveness Analysis</head><p>To further study the effectiveness of CDM, we conduct experiments over these mappings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Tasks</head><p>We collect two particular datasets (named as O2M and M2O) from the Opensubtitles, and define two new tasks (oneto-many and many-to-one dialogue learning task) to analyse the ability of generative dialogue models in handling CDM.  Evaluation Settings Different from the previous settings, we conduct a new human evaluation strategy. First, each model received 50 contexts randomly extracted from O2M and M2O, respectively, and generated 400 responses. Then, three annotators were invited to rank all models with respect to "Suitability" and "Erudition" of their responses. Ties are allowed. Suitability indicates how many diverse and relevant responses are generated by the model. Erudition specifies whether multiple generated responses have the same semantics as the ground-truth responses. We design Suitability to validate whether the model can learn the diversity and relevance from CDM samples, and we use Erudition to assess whether the semantic information of multiple ground-truths is involved in multiple responses generated by the model. On the contrary, our SegCVAE generates multiple responses corresponding to multiple prominent semantics, which easily captures the semantics of multiple responses in O2M dataset and achieves the best Erudition on O2M dataset. However, due to the trade-off between diversity and relevance, the Erudition of SegCVAE on M2O dataset is a little poor. We also use the Pearson's correlation coefficient to evaluate the consistency of the ranking results. The coefficient is 0.64 on Suitability, and 0.51 on Erudition, with p&lt;0.0001 and below 0.001, which indicates high correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper proposes a novel SegCVAE to model complex dialogue mappings (CDM) in human conversations. SegCVAE parses the CDM from a semantic perspective: Using multiple prominent semantics segmented from the context to establish relationships with the responses, multiple prominent semantics can correspond to multiple responses, and multiple contexts can also segment similar prominent semantics. In this way, prominent semantics can constrain latent variables to learn semantic relations to tackle incoherent problem, while enriching them to mitigate the non-diverse problem. To realize SegCVAE, we propose three novel modules: Internal Separation (IS), External Guidance (EG), and Semantic Norms (i.e. L san , L scn , and L sdn ). IS is used to get the basic information for computing prominent semantics, EG is used to constrain the prominent semantics not to deviate too far from the original semantics, and three Semantic Norms are proposed to establish relationships for contexts, prominent semantics and responses. The experimental results show the superiority of our model in dialogue generation, one-tomany and many-to-one dialogue learning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The limitations of our paper are as follow:</p><p>• The SegCVAE model is proposed to model the serious complex dialogue mappings (i.e. oneto-many and many-to-one) phenomena in opendomain dialogue generation task. Therefore, the SegCVAE is suitable for generative tasks where non-one-to-one mappings exist in the dataset. If the task does not require modeling non-one-to-one mappings, our model has little advantage.</p><p>• The hyper-parameters (e.g.the number of extracted words chan, the number of triggers M and so on) need to be determined through multiple experiments, which cannot be set adaptively. These initial promising results for segmenting context into multiple prominent semantics for modeling complex dialogue mappings will hopefully lead to future work in this interesting direction.</p><p>• We provide further analysis on One-to-Many and Many-to-One dialogue learning task, and propose a new human evaluation strategy to directly valid the performance of models on processing non-oneto-one dialogue samples. However, we do not provide results on automatic evaluation of modeling one-to-many and many-to-one mappings. This is primarily because there are no publicly recognized metrics for the evaluation of the performance on modeling one-to-many and many-to-one dialogue mappings directly. In addition, it is also difficult to propose the automatic metrics to achieve the evaluation process due to the lack of supervised information. Automatically evaluating the generative dialogue model's ability to model the complex mappings is a challenging problem and we leave that for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Automatic Evaluation Metrics</head><p>Our primary metrics of interest are Distinct-n, BLEU, Embedding Average (Emb.Aver.), and Coherence. The Distinct-n is responsible for evaluating the diversity of generated responses, which is calculated through the ratio of distinct n-grams and all generated n-grams. The BLEU is used to evaluate the degree of the word-overlap between the generated response and the ground truth response. The Emb.Aver. is introduced to evaluate the semantic relationship of generated responses and groundtruth responses. The Coherence is applied to assess the coherence and relevance between contexts and generated responses. In addition, we also employ the Perplexity (ppl) and Length to validate all models. The ppl is an indicator commonly used in dialogue generation tasks, which is usually used to assess the degree of convergence of the model. The Response length is the average number of words of all generated responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Human Evaluation</head><p>We conduct a human evaluation to further validate our model and baseline models for their ability to generate proper responses. First, we randomly extracted 200 samples from the test sets of the two dialogue datasets, respectively. Each sample contains one context and the response generated by different models. Then, we hired three annotators to rank all responses of all experimented models concerning three aspects of the generated responses: Diversity, Relevance and Fluency. Ties are allowed. Diversity indicates how much the generated response provides specific and diverse information. The more diverse the information, the higher the ranking of the model on Diversity. Relevance specifies how likely the generated response is relevant to the context, which requires annotators to consider whether the response is suitable for the context at a semantic level. Fluency represents how likely the generated response is produced by human. The fewer syntactic errors, the higher the model will rank in terms of Fluency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Training Details</head><p>For fair comparison, we used the 300-dimensional GloVe embeddings as the word-embedding matrix for all models. The hidden size of all models is set to 300. The maximum length of context and response is set to 25. The m, chan and  M are set to 3, 3 and 8, respectively. We set the batch sizes to 64 and 32 for CornellMovie and Opensubtitles, respectively. Adam is utilized for optimization. The initial learning rate is set to 0.001. The snorm s tep is set to 20000 for CornellMovie, but for Opensubtitles, the λ is constant at 1.0. We also introduce KL annealing trick to leverage the KL divergence during the training. The KL weight increases linearly from 0 to 1 in the first 10000 batches. We train all models in 50 epochs on a RTX 2080Ti GPU card with Tensorflow, and save the generated responses when the ppl reaching minimum. The random seed is set as 123456. Greedy search is used to generate responses for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Case Study</head><p>We collected the generated responses from the test set of CornellMovie and showed them in Table 7. In the first example, we found that SegCVAE gave a response of "they're throwing the company." considering "they lying" in the context. Compared with the responses generated by other models, the response of SegCVAE is more specific and more relevant to the context. As for the second sample, only the Seq2seq only generates a general and short reply "I don't know."; the others all generate diverse responses. However, considering the coherence between the generated responses and the context, our model is more advantageous. This result shows the superiority of SegCVAE in solving the dialogue context and generating diverse the generated response.</p><p>In our experiments, all models are trained on D 1n or D n1 to accomplish the One-to-Many Dialogue Learning Task or Many-to-One Dialogue Learning Task. The training and validation procedures are the same as for general dialogue generation task. In inference stage, every model should generate N responses for each context in test set of D 1n or D n1 . Note that N is set to 8 in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Case Study</head><p>We collected the generated responses of contexts in test set of O2M dataset and showed a sample in Table 9. We can observe that the SegCVAE generates "Calm down." and "No-no,", which are corresponding to the "Relax!" and "Stop" in true responses. This result illustrates that the SegCVAE can effectively build the relations between the multiple prominent semantics and the multiple responses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: Four metrics of Seq2Seq models fine-tuned by increasing one-to-many and many-to-one dialogue pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: The schematic of CDM and our primary idea for modeling CDM. (a) Multiple responses in an oneto-many mapping can disrupt model's ability to address the dialogue context. We associate different responses with the segmented different prominent semantics, so as to avoid the interference of multiple responses and to enhance the coherence. (b) The response in a many-to-one mapping has a high proportion in dataset, which deceives models into increasing the generation probability of it, reducing the diversity of generated responses. We promote the same prominent semantics to be associated with the same response, thus extending the response space to enhance the diversity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure3: A Schematic of SEMANTIC ALIENATION NORM. Note that the "push arrow" indicates that the semantic similarity between the Prominent Semantics at both ends is decreased.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: A Schematic of SEMANTIC DISTILLATION NORM. Note that the "Self Dot" operation is to make each Generated or Ground-Truth Response Representation perform an inner product with itself and other representations, and then perform SoftMax to get the correlation between each representation and all representations. KL means the KL divergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Preliminary experiments of Seq2Seq models trained with and without CDM on CornellMovie (up) and Opensubtitles (down).</figDesc><table><row><cell>Setting</cell><cell cols="4">Distinct-3 BLEU Emb.Aver. Coherence</cell></row><row><cell>w. CDM w/o. CDM</cell><cell>0.033 0.028</cell><cell>0.157 0.192</cell><cell>0.853 0.859</cell><cell>0.828 0.828</cell></row><row><cell>w. CDM w/o. CDM</cell><cell>0.031 0.027</cell><cell>0.131 0.149</cell><cell>0.465 0.469</cell><cell>0.281 0.282</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>To achieve this goal, we propose INTERNAL SEP-ARATION (IS) and EXTERNAL GUIDANCE (EG) to model the prominent semantics together. The IS extracts multiple different words from the context to obtain the prominent semantics. The EG extracts the instructive words from the vocabulary to constrain the prominent semantics not far from the original semantics. Furthermore, to make the prominent semantics capture the relationship with responses and latent variables, we propose SEMAN-</figDesc><table><row><cell>TIC ALIENATION NORM, SEMANTIC CENTRAL-</cell></row><row><cell>IZATION NORM, and SEMANTIC DISTILLATION</cell></row><row><cell>NORM to regularise the learning of CVAE.</cell></row><row><cell>Our contributions are as follow:</cell></row><row><cell>• We propose SegCVAE to model CDM through</cell></row><row><cell>using sentence semantics segmentation (IS and EG)</cell></row><row><cell>guided latent variables. SegCVAE constructs the</cell></row><row><cell>relationships between multiple responses and mul-</cell></row><row><cell>tiple prominent semantics, thereby naturally ex-</cell></row><row><cell>plaining CDM. Hence, prominent semantics can</cell></row><row><cell>constrain latent variables to involve semantic rela-</cell></row><row><cell>tions when modeling CDM.</cell></row><row><cell>• We present SEMANTIC ALIENATION NORM, SE-</cell></row><row><cell>MANTIC CENTRALIZATION NORM, and SEMAN-</cell></row><row><cell>TIC DISTILLATION NORM to regularize promi-</cell></row><row><cell>nent semantics and facilitate semantic segmenta-</cell></row><row><cell>tion without supervised labels.</cell></row><row><cell>• We conduct extensive experiments to show the</cell></row><row><cell>superior performance of SegCVAE in modeling</cell></row><row><cell>CDM and dealing with the open-domain dialogue</cell></row><row><cell>generation task.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>8±.22 0.045±.00 0.337±.01 9.7±.33 0.338±.01 0.275±.00 0.231±.00 0.838±.00 0.796±.00 SpaceFusion 24.3±.59 0.018±.00 0.087±.01 7.3±.21 0.335±.01 0.264±.01 0.217±.01 0.851±.00 0.825±.00 SepaCVAE 5.6±.07 0.041±.00 0.367±.02 15.6±.75 0.425±.01 0.357±.01 0.306±.01 0.859±.00 0.833±.00 SegCVAE 6.1±.12 0.038±.00 0.341±.01 17.4±.27 0.453±.00 0.384±.00 0.330±.00 0.865±.00 0.836±.00 Results over the test data of CornellMovie (up) and Opensubtitles (down). The best score in each column is in bold. Note that our BLEU-1,2,3 scores are normalized to [0, 1]. We run all models 5 times.</figDesc><table><row><cell>Model</cell><cell></cell><cell>ppl</cell><cell cols="5">Distinct-1 Distinct-2 Length</cell><cell>BLEU-1</cell><cell>BLEU-2</cell><cell>BLEU-3 Emb.Aver. Coherence</cell></row><row><cell cols="8">Seq2Seq CVAE K-CVAE 9.Seq2Seq 52.6±.10 0.006±.00 0.019±.00 6.8±.63 0.310±.02 0.243±.02 0.199±.02 0.853±.00 0.828±.00 12.2±.13 0.035±.01 0.268±.02 9.7±.16 0.347±.00 0.282±.00 0.236±.00 0.842±.00 0.798±.00 45.9±.13 0.003±.00 0.015±.00 11.8±.82 0.236±.04 0.193±.03 0.163±.03 0.465±.08 0.281±.05 CVAE 12.2±.17 0.009±.00 0.131±.00 13.1±.24 0.172±.02 0.144±.02 0.123±.02 0.285±.04 0.195±.03 K-CVAE 12.1±.20 0.010±.00 0.135±.00 13.1±.10 0.202±.02 0.169±.02 0.144±.01 0.308±.06 0.198±.05 SpaceFusion 8.2±.02 0.006±.00 0.017±.00 9.7±.22 0.365±.01 0.292±.01 0.243±.00 0.808±.00 0.697±.00 SepaCVAE 2.0±.06 0.025±.00 0.330±.03 13.5±.58 0.395±.01 0.326±.01 0.276±.01 0.807±.02 0.677±.01 SegCVAE 3.2±.08 0.021±.00 0.323±.01 14.4±.80 0.437±.01 0.364±.01 0.310±.01 0.836±.00 0.707±.01</cell></row><row><cell>Positive Prominent</cell><cell></cell><cell></cell><cell>Generated Response</cell><cell></cell><cell>KL</cell><cell></cell><cell>Ground-Truth Response</cell></row><row><cell>Semantics 1</cell><cell></cell><cell cols="2">Representation 1</cell><cell></cell><cell></cell><cell></cell><cell>Representation 1</cell></row><row><cell>Positive Prominent Semantics 2</cell><cell>Decoder</cell><cell cols="2">Generated Response Representation 2</cell><cell>Self Dot</cell><cell>KL</cell><cell>Dot Self</cell><cell>Ground-Truth Representation 2 Response</cell></row><row><cell>Positive Prominent</cell><cell></cell><cell></cell><cell>Generated Response</cell><cell></cell><cell>KL</cell><cell></cell><cell>Ground-Truth Response</cell></row><row><cell>Semantics B</cell><cell></cell><cell cols="2">Representation B</cell><cell></cell><cell></cell><cell></cell><cell>Representation B</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Human evaluation results on test data. The best score in each column is in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table 3 (refer to Appendix A.2 for detailed setups). To evaluate the consistency of the ranking results assessed by three annotators, we use Pearson's correlation coefficient. This coefficient is 0.80 on Diversity, 0.62 on Relevance, and 0.77 on Fluency, with p &lt; 0.0001 and below 0.001, which indicates high correlation and agreement.</figDesc><table><row><cell>This result shows that our model significantly out-</cell></row><row><cell>performs baselines in terms of diversity, relevance,</cell></row><row><cell>and fluency. Except for the ground-truth responses,</cell></row><row><cell>our model achieves the best scores of relevance</cell></row><row><cell>and diversity metrics on both datasets. The flu-</cell></row><row><cell>ency result of SegCVAE on the CornellMovie</cell></row><row><cell>is slightly worse than that of baselines, which is</cell></row><row><cell>mainly due to the length of responses generated</cell></row><row><cell>by SegCVAE being longer than that of baselines</cell></row><row><cell>(see Table</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Ablation results on test data of Opensubtitles. The best score in each column is in bold.</figDesc><table><row><cell>Context</cell><cell>I'm sorry, you're mistaken.</cell></row><row><cell cols="2">EG IS SegCVAE So, I'll help my mate and you. listen, one Confided Confided I Mistaken day to tell me to go from the fields together.</cell></row><row><cell>Context</cell><cell>Move! What have you done?</cell></row><row><cell cols="2">EG IS SegCVAE Hey, please. relax. Rendezvous Humiliate Move !</cell></row><row><cell>Context</cell><cell>Not this year, dani. Mom said you have to.</cell></row><row><cell cols="2">EG IS SegCVAE I'm compounded you talk about our great Tying Tying Said Not Said &lt;unk&gt; in the other times.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Generated responses and their corresponding keyword combinations of SegCVAE. EG and IS represent the External Guidance and the Internal Separation.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>In our experiments, all models</figDesc><table><row><cell>model</cell><cell>Suitability</cell><cell>Erudition</cell></row><row><cell>CVAE K-CVAE SepaCVAE SegCVAE</cell><cell>2.69 2.75 2.15 2.03</cell><cell>2.33 2.35 2.21 1.89</cell></row><row><cell>CVAE K-CVAE SepaCVAE SegCVAE</cell><cell>2.42 2.48 2.16 2.05</cell><cell>1.96 1.89 1.92 1.92</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Evaluation results on test data of O2M (up) and M2O (down). The best score in each column is bold.</figDesc><table /><note><p>are trained on O2M or M2O to accomplish the two tasks. The training and validation procedures are the same as for general dialogue generation task. In inference stage, every model should generate N responses for each context in test set of O2M or M2O. Note that N is set to 8 in this paper (See Appendix C for detail).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Table 6 reports the result.We observe that SegCVAE achieves the best Suitability on both O2M and M2O datasets, which we believe stems from the model's superior ability to model the CDM. We also observe that SegCVAE achieves the best Erudition on O2M dataset but poor Erudition on M2O dataset, and K-CVAE achieves best Erudition on M2O dataset but worst Erudition on O2M dataset. This finding is in line with the characteristics of these models: (1) Due to the cluster information, the K-CVAE samples latent</figDesc><table><row><cell>variables from a concentrated prior distribution,</cell></row><row><cell>resulting in generating multiple similar responses</cell></row><row><cell>easily. (2) The SepaCVAE uses the orthogonal vec-</cell></row><row><cell>tors for sampling latent variables, which increases</cell></row><row><cell>the diversity but decreases the number of relevant</cell></row><row><cell>responses. (3) Our SegCVAE uses multiple promi-</cell></row><row><cell>nent semantics to capture the diverse and relevant</cell></row><row><cell>features, resulting in generating different but co-</cell></row><row><cell>herent responses. Therefore, the similar responses</cell></row><row><cell>generated by K-CVAE are easily hit the only "one" response in M2O dataset but hardly hit multiple</cell></row><row><cell>responses in O2M dataset, which leads the best Eru-</cell></row><row><cell>dition on M2O but worst Erudition on O2M.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Context That's what your crew said. Are they lying? or are you? Seq2Seq I'm not going to be a long time. CVAE Great. You've brought us before that's ten o'clock. K-CVAE You played the maximum? SpaceFusion I'm not a couple of firing. SepaCVAE These're what ... to now you? SegCVAE Well, We know it's twenty, new york, they're throwing the company. Mrs. Webster. You don't wanna put the police and he's dead. K-CVAE Now it's something i want to know that. SpaceFusion What do you think they were going to do? SepaCVAE Do you see of what stupid well here? SegCVAE What the matter? You think we understand anything to that, anything?</figDesc><table><row><cell>Context</cell><cell>We don't know.</cell></row><row><cell>Seq2Seq CVAE</cell><cell>I don't know. I told you,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 :</head><label>7</label><figDesc>Generated responses from the baseline and SegCVAE on test set of CornellMovie.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank the anonymous reviewers for their constructive comments. This research is supported by <rs type="funder">Beijing Natural Science Foundation</rs> (No. <rs type="grantNumber">4222037</rs> and <rs type="grantNumber">L181010</rs>). <rs type="person">Kan Li</rs> is the corresponding author.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ySBhczn">
					<idno type="grant-number">4222037</idno>
				</org>
				<org type="funding" xml:id="_XBZKFBn">
					<idno type="grant-number">L181010</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>C Further Analysis on One-to-Many and Many-to-One Dialogue Learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Data Settings</head><p>We extract two particular datasets from the raw Opensubtitles: One-to-Many and Many-to-One, for the One-to-Many and Many-to-One dialogue learning, respectively. To build these two datasets, we first extract single-turn dialogues from the Opensubtitles:</p><p>can be extracted from one multi-turn dialogue (u 1 , u 2 , ..., u T ), where u represents an utterance in each dialogue. Then, we selected and collected a large collection of one-to-many dialogue pairs as the One-to-Many (O2M) dataset, and another large collection of many-to-one dialogue pairs as the Many-to-One (M2O) dataset. Finally, we use the token-list of GloVe <ref type="bibr" target="#b25">(Pennington et al., 2014)</ref> to filter the O2M and M2O datasets. For each dialogue pair (context c i , response r i ), we first obtain its tokens after word segmentation, and then judge whether its tokens are all contained in GloVe's token-list. If the GloVe do not contain any tokens of (c i , r i ), we drop all dialogue pairs containing the c i or r i from the dataset.  (c, r 1 ), (c, r 2 ), . . . , (c, r n ). Let D 1n represent the dataset that only contains such one-to-many dialogue pairs. This task requires a dialogue generation model to learn the one-to-many knowledge, and to generate multiple coherent and informative responses for every context sentence.</p><p>Many-to-One Dialogue Learning Task Relatively speaking, let cs=c 1 , c 2 , . . . , c n denote the contexts, and r denote a response to the cs. Correspondingly, we use D n1 to represent a dataset that only contains many-to-one dialogue pairs (c 1 , r), (c 2 , r), . . . , (c n , r). This task requires the dialogue generation model to learn the many-toone knowledge, and to distinguish which of the contexts can give the same response, and then increase the diversity while keeping the coherence of</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Filtering noisy dialogue corpora by connectivity and content relatedness</title>
		<author>
			<persName><forename type="first">Reina</forename><surname>Akama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sho</forename><surname>Yokoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="941" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hierarchical variational memory network for dialogue generation</title>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1653" to="1662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improving neural conversational models with entropy-based data filtering</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Csaky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrik</forename><surname>Purgai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gábor</forename><surname>Recski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5650" to="5669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Posterior-gan: Towards informative and coherent response generation with posterior generative adversarial network</title>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="7708" to="7715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Regularizing dialogue generation by imitating implicit scenarios</title>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Xuancheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6592" to="6604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">2019a. A discrete CVAE for response generation on short-text conversation</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1898" to="1908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Jointly optimizing diversity and relevance in neural response generation</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT (1)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1229" to="1238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A knowledge-grounded neural conversation model</title>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5110" to="5117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Negative training for neural dialogue response generation</title>
		<author>
			<persName><forename type="first">Tianxing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2044" to="2058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Emotional dialogue generation using image-grounded language models</title>
		<author>
			<persName><forename type="first">Bernd</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Mcduff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">277</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR (Poster)</title>
		<imprint>
			<publisher>OpenReview</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>net</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Autoencoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">2016a. A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">2016b. A persona-based neural conversation model</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georgios</forename><forename type="middle">P</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">2022a. Diversifying neural dialogue generation via negative distillation</title>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022</title>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022<address><addrLine>Seattle, WA, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">July 10-15, 2022</date>
			<biblScope unit="page" from="407" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">2022b. Stop filtering: Multi-view attribute-enhanced dialogue learning</title>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
		<idno>CoRR, abs/2205.11206</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Opensubtitles2016: Extracting large parallel corpora from movie and TV subtitles</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Lison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">You impress me: Dialogue generation via mutual persona perception</title>
		<author>
			<persName><forename type="first">Qian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1417" to="1427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">PANGUBOT: efficient generative dialogue pre-training from pre-trained language model</title>
		<author>
			<persName><forename type="first">Fei</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<idno>CoRR, abs/2203.17090</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Neural machine translation and sequence-to-sequence models: A tutorial</title>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno>CoRR, abs/1703.01619</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A conditional variational framework for dialog generation</title>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuzi</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="504" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3483" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of responses</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generating relevant and coherent dialogue responses using self-separated conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiamou</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL/IJCNLP</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5624" to="5637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">THINK: A novel conversation model for generating grammatically correct and coherent responses</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiamou</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Based Syst</title>
		<imprint>
			<biblScope unit="volume">242</biblScope>
			<biblScope unit="page">108376</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Get the point of my utterance! learning towards effective responses with multi-head attention mechanism</title>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shen</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyue</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4418" to="4424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Answer-guided and semantic coherent question generation in open-domain conversation</title>
		<author>
			<persName><forename type="first">Weichao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5065" to="5075" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Diversity-promoting GAN: A cross-entropy based generative adversarial network for diversified text generation</title>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="3940" to="3949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ioannis Konstas, and Verena Rieser. 2018b. Better conversations by modeling, filtering, and optimizing for coherence and diversity</title>
		<author>
			<persName><forename type="first">Xinnuo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondrej</forename><surname>Dusek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="3981" to="3991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ioannis Konstas, and Verena Rieser. 2018c. Better conversations by modeling, filtering, and optimizing for coherence and diversity</title>
		<author>
			<persName><forename type="first">Xinnuo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondrej</forename><surname>Dusek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="3981" to="3991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neural response generation via GAN with an approximate embedding layer</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="617" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attribute2image: Conditional image generation from visual attributes</title>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">9908</biblScope>
			<biblScope unit="page" from="776" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Reinforcing coherence for sequence to sequence model in dialogue generation</title>
		<author>
			<persName><forename type="first">Hainan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4567" to="4573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Generating informative and diverse conversational responses via adversarial information maximization</title>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1815" to="1825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskénazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
