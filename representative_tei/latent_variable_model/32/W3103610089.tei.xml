<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Focus-Constrained Attention Mechanism for CVAE-based Response Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-09-25">25 Sep 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Zhi</forename><surname>Cui</surname></persName>
							<email>cuizhi@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="department">Xiaomi AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanran</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiayi</forename><surname>Zhang</surname></persName>
							<email>zhangjiayi3@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="department">Xiaomi AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jianwei</forename><surname>Cui</surname></persName>
							<email>cuijianwei@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="department">Xiaomi AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chen</forename><surname>Wei</surname></persName>
							<email>weichen@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="department">Xiaomi AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bin</forename><surname>Wang</surname></persName>
							<email>wangbin11@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="department">Xiaomi AI Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Focus-Constrained Attention Mechanism for CVAE-based Response Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-09-25">25 Sep 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2009.12102v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To model diverse responses for a given post, one promising way is to introduce a latent variable into Seq2Seq models. The latent variable is supposed to capture the discourse-level information and encourage the informativeness of target responses. However, such discourselevel information is often too coarse for the decoder to be utilized. To tackle it, our idea is to transform the coarse-grained discourselevel information into fine-grained word-level information. Specifically, we firstly measure the semantic concentration of corresponding target response on the post words by introducing a fine-grained focus signal. Then, we propose a focus-constrained attention mechanism to take full advantage of focus in well aligning the input to the target response. The experimental results demonstrate that by exploiting the fine-grained signal, our model can generate more diverse and informative responses compared with several state-of-the-art models. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays, developing intelligent open-domain conversational systems has become an active research field <ref type="bibr" target="#b14">(Perez-Marin and Pascual-Nieto, 2011;</ref><ref type="bibr" target="#b19">Shum et al., 2018)</ref>.</p><p>Compared with rule-based and retrieval-based methods, neural generative models have attracted increasing attention because they do not need extensive feature engineering and have achieved promising results recently with large-scale conversational data <ref type="bibr" target="#b26">(Vinyals and Le, 2015;</ref><ref type="bibr" target="#b21">Sordoni et al., 2015;</ref><ref type="bibr" target="#b17">Shang et al., 2015)</ref>.</p><p>Typically, neural generative models are trained to learn the post-response mappings based on the Seq2Seq architecture using maximum likelihood (MLE) training objective. This kind of objective induces the model to treat the postresponse relationship as one-to-one mappings. However, the conversations in the real world often embodies one-to-many relationships, where a post is often associated with multiple valid responses <ref type="bibr" target="#b31">(Zhou et al., 2017)</ref>. Due to this discrepancy, standard Seq2Seq models tend to generate high-frequency but trivial responses such as "I don't know" or "I'm ok" <ref type="bibr" target="#b10">(Li et al., 2016)</ref>.</p><p>To address this issue, one promising research line resorts to Conditional Variational Autoencoder (CVAE), which introduces a latent variable to Seq2Seq models through variational learning. The latent variable is supposed to capture the discourse-level semantics of target response and in turn encourage the response informativeness. Recent literature along this line attempted to improve the model performance by putting extra control on the latent variable <ref type="bibr" target="#b30">(Zhao et al., 2017;</ref><ref type="bibr" target="#b8">Gu et al., 2018;</ref><ref type="bibr" target="#b6">Gao et al., 2019)</ref>. Despite the control, these methods still relied on the discourse-level latent variable, which is too coarse for the decoders to mine sufficient guiding signals at each generation step. As a result, these variational models are observed to ignore the latent variable <ref type="bibr" target="#b30">(Zhao et al., 2017;</ref><ref type="bibr" target="#b8">Gu et al., 2018;</ref><ref type="bibr" target="#b6">Gao et al., 2019)</ref> and to generate semantically irrelevant or grammatically disfluent responses <ref type="bibr" target="#b15">(Qiu et al., 2019)</ref>.</p><p>In this paper, we propose a novel CVAE-based model, which exploits fine-grained word-level information for diverse response generation. Firstly, we transform the discourse-level information into word-level signals, i.e., focus. By attending the la-tent variable to the post words, the focus weight measures the response's correlation with the post words. The higher the weight, the semantics is more likely to concentrate on the corresponding word. To utilize the focus, we develop a focus-constrained attention mechanism which better aligns the post words with the response according to the fine-grained signals. In this way, the model is able to produce a semantically different response directed by a different focus.</p><p>Our contributions can be summarized as three folds: 1) We propose a novel CVAE-based model for diverse response generation, by directing the decoder with fine-grained information. 2) We introduce focus to represent the fine-grained information, and propose a focus-constrained attention mechanism to make full use of it. 3). Experimental results demonstrate our model outperforms several state-of-the-art models in terms of response's diversity as well as appropriateness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The attention mechanism <ref type="bibr" target="#b0">(Bahdanau et al., 2014;</ref><ref type="bibr" target="#b12">Luong et al., 2015)</ref> has become a widely-used component for Seq2Seq <ref type="bibr" target="#b22">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b4">Cho et al., 2014)</ref> to model Short-Text Conversation <ref type="bibr" target="#b17">(Shang et al., 2015;</ref><ref type="bibr" target="#b26">Vinyals and Le, 2015;</ref><ref type="bibr" target="#b21">Sordoni et al., 2015)</ref>. Although promising results have been achieved, attention-based Seq2Seq models still tend to generate generic and trivial responses <ref type="bibr" target="#b10">(Li et al., 2016)</ref>.</p><p>There have been many approaches attempted to address this problem. <ref type="bibr" target="#b10">Li et al. (2016)</ref> reranked the n-best generated responses based on Maximum Mutual Information (MMI). <ref type="bibr" target="#b18">Shao et al. (2017)</ref> adopted segement-level reranking to encourage diversity during early decoding steps. However, these reranking-based methods only introduce a few variants of decoded words. Another group of researches attempted to encourage diversity by incorporating extra information. <ref type="bibr" target="#b27">Xing et al. (2017)</ref> injected topic words and <ref type="bibr" target="#b29">Yao et al. (2017)</ref> introduced a cue word based on Point-wise Mutual Information (PMI) into generation models. <ref type="bibr" target="#b7">Ghazvininejad et al. (2018)</ref> grounded on knowledge bases to provide factual information for the decoder. However, it is difficult to ensure these external information are always appropriate to the conversation context.</p><p>Another line of research introduced a set of latent responding mechanisms and gener-ated responses based on a selected mechanism. <ref type="bibr" target="#b31">Zhou et al. (2017)</ref> learned the post-response mappings as a mixture of the mechanisms, but it is questionable that they only relied on one single mechanism when generating responses given a new post. <ref type="bibr" target="#b3">Chen et al. (2019)</ref> adopted posterior selection to build one-to-one mapping relationship between the mechanisms and target responses. Since the target response is missing during testing, it is hard to ensure a satisfactory generated response by a randomly picked mechanism.</p><p>Our work centers in the research line of conditional response generation through variational learning <ref type="bibr" target="#b16">(Serban et al., 2017;</ref><ref type="bibr" target="#b30">Zhao et al., 2017)</ref>. However, the variational methods inevitably suffer from bypassing the latent variable and generating disfluent responses. <ref type="bibr" target="#b30">Zhao et al. (2017)</ref> combined CVAE with dialog acts to learn meaningful latent variable, however the discourse-level dialog act is hard to be captured from short conversation. <ref type="bibr" target="#b8">Gu et al. (2018)</ref> introduced Gaussian mixture prior network, but it is hard to determine the number of mixtures and the optimization is complicated. <ref type="bibr" target="#b6">Gao et al. (2019)</ref> assumed the response generation is driven by a single word, and connected each latent variable with words in the vocabulary. Nevertheless, the difficulty is how to target the driving word for a specific post-response pair. More importantly, all of these methods rely on the coarse-grained discourse-level information, which might be insufficient in leading to a satisfactory response.</p><p>Notably, our work induces the response generation with focus, a fine-grained feature extracted from the discourse-level latent variable. Compared with the variational attention that models the alignment as latent variable <ref type="bibr" target="#b1">(Bahuleyan et al., 2018;</ref><ref type="bibr" target="#b5">Deng et al., 2018)</ref>, we are mainly inspired by the idea of coverage vector <ref type="bibr" target="#b24">(Tu et al., 2016)</ref> to dynamically adjust the attention based on the attention history and the proposed focus. The difference is that <ref type="bibr" target="#b24">Tu et al. (2016)</ref> addressed the under/over translation problem and the decoder in their work pays equal attention to the source words. In contrast, our work constrains the decoder to align the decoding attention with the finegrained focus to generate diverse responses.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KL(qR||pP</head><formula xml:id="formula_0">) SOS y 4 y 1 y 3 y 2 h ′ x D t Lfoc = || 1 |y| D -F ||2 x = {x i } 5 i=1 y = {y i } 5</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries and Model Overview</head><p>A neural generative model is trained on a collection of post-response pairs {(x, y)}, and aimed to generate a response y word-by-word given an input x. At the basis of our approach is CVAE where a latent variable z is considered to capture discourse-level diversity. To extract fine-grained information, we design focus F = {f i } |x| i=1 over the post words, where f i measures to what extent the latent variable z is concentrating on the post word x i , and |x| is the length of input x. Besides, we introduce a coverage vector D t = {d i,t } |x| i=1 , where d i,t accumulates the attention weights over the post word x i up until t-th decoding step.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> illustrates the whole framework of our model consisting of three components: CVAE basis, focus generator and response generator. Based on the CVAE framework, we firstly introduce a probabilistic distribution over the latent variable z to model potential responses for a given x. Then, focus generator produce the focus F by attending the latent variable z to hidden representation h x of the input. The obtained F is then concatenated with h x to obtain h ′</p><p>x for word prediction. Specifically, the decoder attentively refers to h ′</p><p>x and accumulates decoding attention weights through the coverage vector D t . To direct response generation using the focus F , we not only optimize the variational lower bound on response generation, but also optimize a regularization term named as focus constraint by minimizing the divergence D and F .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Background of CVAE</head><p>Typically, the conditional variational autoencoder (CVAE) introduces a probabilistic distribution over the latent variable to model response diversity. Following CVAE, we firstly encode x and y by the post and response encoder, respectively. The two encoders are constructed by the shared bidirectional GRUs <ref type="bibr" target="#b4">(Cho et al., 2014)</ref> which generate a series of hidden states {h In training phase, we sample a latent variable z from the posterior distribution q R (z|x, y). The distribution is modeled as a multivariate Gaussian distribution N (µ, Σ), where Σ is a diagonal covariance. We parameterize µ and Σ by the recognition network through a fully connected layer conditioned on the concatenation [h x ; h y ]:</p><formula xml:id="formula_1">µ log(Σ) = W q h x h y + b q (1)</formula><p>where W q and b q are learnable parameters. To mitigate the gap in encoding of latent variables between train and testing <ref type="bibr" target="#b20">(Sohn et al., 2015;</ref><ref type="bibr" target="#b28">Yan et al., 2015)</ref>, CVAE requires the posterior distribution q R (z|x, y) to be close to the prior distribution p P (z|x). Notably, p P (z|x) is parameterized by the prior network and also follows a multivariate Gaussian distribution N (µ ′ , Σ ′ ) in a similar way but only conditioned on h x . As usual, we minimize the discrepancy between the two distributions by the Kullback-Leibler divergence:</p><formula xml:id="formula_2">L kl = KL(q R (z|x, y)||p P (z|x))<label>(2)</label></formula><p>By sampling different z, the model is supposed to output semantically different responses. However, such latent variable is too coarse to guide a satisfactory response generation, as discussed previously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Focus Generator</head><p>The core is how to better exploit indicative information from the discourse-level variable for diverse response generation. In this work, we transform the discourse-level latent variable z into finegrained signal using a focus generator g(h x , z) as shown in the middle of Figure <ref type="figure" target="#fig_0">1</ref>. To be specific, the focus generator attends the latent variable z to the post representation h x , and produces the focus distribution F = {f } |x| i=1 . Similar to the standard attention <ref type="bibr" target="#b0">(Bahdanau et al., 2014;</ref><ref type="bibr" target="#b12">Luong et al., 2015)</ref>, the generated focus F measures the response concentration a specific post word, which is calculated by:</p><formula xml:id="formula_3">g(h x , z) = F = { exp(f (h x i , z)) |x| k=1 exp(f (h x k , z)) } |x| i=1 (3) where f (h x i , z) = v ⊤ f tanh(W f h x i + U f z)</formula><p>and W f and U f are learnable parameters. This focus captures to what extent the response semantics is related to the post words, which will serve as fine-grained signals for the decoder. Notably, the higher the focus, the response is more likely to pay attention to the corresponding word. Compared with the coarse-grained z, the word-level focus is of great guiding significance when generating responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Focus-Guided Generation</head><p>The remaining is to properly incorporate the finegrained focus into response generation. Since the focus weights imply the semantics of the target response, they are beneficial signals indicating whether a word is attended properly during decoding.</p><p>Concretely, we develop a focus-guided mechanism to facilitate the decoder adjust the attention during the generation. To notify the decoder of the focus, we concatenate h x and F to obtain a series of combined hiddens of the post h</p><formula xml:id="formula_4">′ x = {h ′ x i } |x| i=1</formula><p>(the green and yellow vectors in Figure <ref type="figure" target="#fig_0">1</ref>). After integrating the extra feature f i , the devised representations h ′ x are then used to calculate the attention weights. Inspired by <ref type="bibr" target="#b24">Tu et al. (2016)</ref>, we borrow the idea of coverage attention and introduce the coverage vector D t = {d i,t } |x| i=1 that records the attention history, where d i,t = t k=1 α i,k accumulates the decoding attention weights on the post word x i . Here, α i,t stands for the attention weight on the post word x i at t-th decoding step (t ∈ [1, |y|]), which is calculated as:</p><formula xml:id="formula_5">α i,t = exp(e i,t ) |x| k=1 exp(e k,t )<label>(4)</label></formula><formula xml:id="formula_6">e i,t = v ⊤ a tanh(W a h ′ x i + U a s t-1 + V a a t-1 ) (5) a t-1 = |x| i=1 d i,t-1 h ′ x i (6)</formula><p>where s t-1 is decoder's hidden state at (t -1)-th step, and a t-1 takes into account the attention history before t-th step. At the end of each decoding step, a predicted word ŷt is obtained by:</p><formula xml:id="formula_7">ŷt = softmax(W d [s t ; |x| i=1 α i,t h x i ] + d d ) (7)</formula><p>where W d and d d are learnable parameters. Since the focus suggests how much attention should be paid to during each decoding step, the devised focus-guided mechanism is able to globally determine a word based on the attention history as well as the current state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Focus Constraint</head><p>Nevertheless, one potential drawback is that the decoder could still ignore the focus signals even equipped with the focus-guided mechanism. Considering that focus measures the response's significance on a specific post word, it is also essential for the decoder to concentrate on the word with higher focus weight, and vice versa.</p><p>To prevent the decoder bypassing the focus signal, we design a focus constraint to regulate the learning of post-response pairs by taking into account the focus weights. As shown in the right side of Figure <ref type="figure" target="#fig_0">1</ref>, the focus constraint requires the model to minimize the discrepancy between the focus weight distribution F and decoding attention distribution D. To implement it, we define the focus constraint L f oc as the Euclidean norm distance between D and F :</p><formula xml:id="formula_8">L f oc = || 1 |y| D -F || 2<label>(8)</label></formula><p>where D sums up all the decoding attention weights over the post words and |y| is the total number of decoding steps. Considering |x| i=1 f i = 1, a division of |y| from D makes the two terms being compared at the same magnitude. We name this constrained decoding attention as Focus-Constrained Attention Mechanism. Such a constraint will make the decoder draw attention by globally consulting the focus F and distribute the attention dynamically. For example, given a distribution F , if the hidden output h x i has been attended to a certain degree d i,t-1 ≈ f i , the model will discourage the decoder to overly emphasize on h x i after the t-th step. In contrast, if the hidden output h x i has been hardly attended compared with its focus weight (d i,t-1 ≪ f i ), the model will encourage the decoder to pay more attention onto h x i afterwards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Optimization and Testing</head><p>Overall, all the modules described above are jointly trained in an end-to-end way by minimizing the total loss:</p><formula xml:id="formula_9">L total = L seq + L f oc + γL kl + L bow (9)</formula><p>Here, L seq is the sequence cross entropy between the generated response ŷ and the corresponding ground truth y. L f oc is the proposed focus constraint as described above. To address the problem of vanishing latent variable, we follow <ref type="bibr" target="#b2">Bowman et al. (2015)</ref> and adopt the annealing weight γ for KL divergence L kl , where γ is gradually increased during training phase. We also employ the auxiliary bag-of-word loss L bow to further alleviate the vanishing issue <ref type="bibr" target="#b30">(Zhao et al., 2017)</ref>.</p><p>At testing phase, an intermediate focus F will be obtained with the prior network and focus generator. Notably, this enables us to generate diverse responses by sampling multiple latent variables from the prior network, where each sampled z leads to a semantically distinct response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We conduct experiments on the Weibo benchmark 2 <ref type="bibr" target="#b17">(Shang et al., 2015)</ref>, a single-round conversational dataset where a post is associated with 2 <ref type="url" target="https://www.weibo.com/">https://www.weibo.com/</ref> multiple responses. We follow the default preprocessing step, and obtain 205,164 unique posts and 4,142,299 training post-response pairs in total. After random spilt, we acquire 101,794 postresponse pairs for evaluation, and 1,000 distinct posts for testing. Here, each testing post has 5 reference responses for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We implement our model with Tensorflow and run it on NVIDIA Telsa V100. Specifically, the vocabulary size is 50,003 including PAD, UNK and EOS. The word embedding size is 720 as same as the size of latent variable. We build two-layer GRUs for the two parameter-shared encoders as well as for the decoder. In all, our model contains around 130M parameters, which are all randomly initialized with a uniform distribution [-1, 1]. We train our model with a batch size of 1,024 by Adam optimizer (Kingma and Ba, 2014). We increase the learning rate from 0 up to 0.0008 within the first 8,000 warmup steps and proportionally decrease it to the inverse square root of step number <ref type="bibr" target="#b25">(Vaswani et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baseline Models</head><p>To demonstrate the necessity and effectiveness of our proposed mechanism alone, we build it on Seq2Seq and exclude as many other interferences as possible when comparing with the following state-of-the-art baseline models: S2S <ref type="bibr" target="#b0">(Bahdanau et al., 2014)</ref>: It trains a Seq2Seq model with the standard attention and adopts beam search decoding to generate responses. MMI <ref type="bibr" target="#b10">(Li et al., 2016)</ref>: It is a backward Seq2Seq trained from response to post, and reranks the beam searched candidates under MMI criterion. MARM <ref type="bibr" target="#b31">(Zhou et al., 2017)</ref>: It is a Seq2Seq model which additionally contains a diverter that consists of 5 latent responding mechanisms. During training, these mechanisms are learned as a mixture by the weighted average. CMHAM <ref type="bibr" target="#b23">(Tao et al., 2018)</ref>: It is a Seq2Seq model, which is augmented with Constrained-Multi-Head-Attention-Mechanism. The attention heads are constrained by orthogonality and each of them is expected to attend a certain aspect of the post. We set the head number as 5. CVAE <ref type="bibr" target="#b30">(Zhao et al., 2017)</ref>: It is a vanilla CVAE Seq2Seq trained along with the bag-of-word loss. During testing phase, we take 3 samplings from the prior network to generate each response. Ours-Foc introduces the focus F , but it does not incorporate the coverage vector D t , and the decoding attention at each step is calculated with only the first two terms in Equation <ref type="formula">5</ref>. 2) Ours-FocCoverage involves both of the focus F and the coverage vector D t , where the only difference from Ours-FocConstrain is that it is optimized without the focus constraint L f oc in Equation <ref type="formula">9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Metrics</head><p>All models are required to generate 3 responses and are evaluated using both automatic metrics and human judgements: Multi-BLEU: BLEU <ref type="bibr" target="#b13">(Papineni et al., 2002)</ref> 3 is a common automatic metric to evaluate the response quality. It measures word overlaps between the generated responses and references. We report Multi-BLEU scores where each generated response is compared with 5 references.</p><p>Dist-1/2: Dist-1/2 measures the diversity of generated responses by counting the distinct uni-grams and bi-grams <ref type="bibr" target="#b10">(Li et al., 2016)</ref>. In our setting, both Intra-Dist and Inter-Dist are evaluated on the results to calculate Dist of responses for a post and the whole testing set, respectively.</p><p>3 <ref type="url" target="http://www.nltk.org/py-modindex.html">http://www.nltk.org/py-modindex.html</ref> </p><p>Human Labeling: Since there is a gap between automatic metrics and human annotation <ref type="bibr" target="#b11">(Liu et al., 2016)</ref>, we also consider human labeling to further validate the experiment results. We randomly sample 150 posts and generate 3 responses by each method. Then, we ask 3 professional annotators to label the responses from the aspects of Quality and Diversity, respectively. Quality: We examine the generated responses from the aspects of informativeness (which measures whether the generated response is informative and interesting), relevance (which measures whether the generated response is relevant to the input post) and fluency (which measures whether the quality of the generated response). Each generated response will be categorized into bad, normal or good (scaled as 0, 1, 2). Note that a generated response will be labled as bad, if it is irrelevant to the post or has grammar mistakes. Besides, a good generated response is more than just fluent but also informative compared with a normal one. We report acceptable ratio for responses that are labeled as 1 or 2, and good ratio only for responses that just are labeled as 2. Diversity: It measures the number of semantically distinct generated responses for a post. The higher the better, the maximum scale is 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparison Against Baselines</head><p>Results of automatic metrics and human labelings are shown in Table <ref type="table" target="#tab_3">2</ref>. The Kappa score is 0.45 and 0.70 for quality and diversity labeling, indicating that the annotators share a satisfactory agreement in the labeling. We firstly examine the significance of latent  variable. Generally speaking, the compared models without any latent variable (the first 4 rows in Table <ref type="table" target="#tab_1">1</ref>) perform the worst. As shown in Table 1, S2S and MMI achieve the lowest scores.</p><p>Comparing the 3 generated responses by S2S and MMI shown in Table <ref type="table" target="#tab_3">2</ref> (the 3 columns), they share similar semantics with only a few word variants.</p><p>As MMI has to rerank the candidates generated by S2S, their performances are similarly disappointing. This result supports that Seq2Seq is limited in modeling diverse responses for a given post even combined with the reranking strategy. Moreover, MARM performs similarly with S2S and MMI in terms of the automatic scores, human judgments as well as the generated responses shown in Table <ref type="table" target="#tab_3">2</ref>. Despite that MARM introduces a set of latent embeddings, its poor performance is attributed to the lack of extra disentanglement control on the mixture learning of latent mechanisms, as analyzed in the previous section. Things become interesting when we examine the performance of CMHAM. It seems that CMHAM effectively improves the diversity over other Seq2Seq models if we only checked the indicators in Table <ref type="table" target="#tab_1">1</ref>. However, the responses generated by CMHAM from We then examine the variational models equipped with latent variable (the fourth to sixth rows) to investigate which method(s) are more effective in utilizing the latent information. From Table <ref type="table" target="#tab_1">1</ref>, CVAE brings obvious improvements on Dist and Diversity as compared with the nonvariational models (the first four rows). However, the responses generated by CVAE in Table <ref type="table" target="#tab_3">2</ref> are of low quality. It is because that the vanilla CVAE has no extra control on the latent variable, and the stochasticity injected in the latent variable is too overwhelming for the decoder when generating responses. In turn, hardly the decoder is able to balance the latent semantics with the response fluency. As a result, the latent variable fails to effectively direct a high-quality response generation. When comparing DCVAE with CVAE, we can see noticeable increases especially on Quality and Diversity. This is not surprising in that DCVAE introduces additional control on each latent variable and connects the variables with the words in the vocabulary. Though it is more meaningful to incorporate the latent variable in this way, DCVAE is still insufficient. Take the 2nd generated response from DCVAE in Table <ref type="table" target="#tab_3">2</ref> as an example where the driving word is "夏天(summer)". In this case, DC-VAE is unable to adjust the attention, and thus directs the flawed response to overly emphasize on "夏天(summer)". This example partially proves that even though DCVAE has taken control over the latent variable, it is still problematic to guide response generation through a coarse-grained signal.</p><p>On the contrary, the proposed model and its variants Ours-FocCoverage Ours-FocConstrain base on the fine-grained focus signal and successfully improve the overall generation quality as well as response diversity. Especially, our full model Ours-FocConstrain performs the best in terms of almost every metric except BLEU-1. The highest scores of human evaluations in Table <ref type="table" target="#tab_1">1</ref> and the responses in Table <ref type="table" target="#tab_3">2</ref> together show that our proposed method Ours-FocConstrain is able to generate high-quality and diverse responses. In brief, our model introduces a performance boost as it fully leverages the word-level information for response generation.  <ref type="table" target="#tab_3">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation Study and Analysis</head><p>To verify the effectiveness of each proposal in our work, we conduct ablation studies by comparing with several variants of our model, Ours-Foc, Ours-FocCoverage and Ours-FocConstrain. The ablation results are summarized in the last three rows in Table <ref type="table" target="#tab_1">1</ref> and<ref type="table" target="#tab_4">Table 2</ref>.</p><p>Clearly, the performance gap among our variants indicate that all the three modules in the pro-posed model are of great importance. One thing to note in Table <ref type="table" target="#tab_1">1</ref> is the unsatisfactory performance achieved by the bare-bone variant Ours-Foc that it performs similarly with the vanilla Seq2Seq. Ours-Foc solely contains the focus generator which dissembles the discourse-level latent variable into word-level guiding signalsfocus-for each decoding step. This setting is insufficient because the model is prone to bypass the guiding signals. We observe such unexpected phenomenon in Table <ref type="table" target="#tab_3">2</ref> where the three responses from Ours-Foc are generated with one single model and thus they are similar to each other. This phenomenon is further validated in Figure <ref type="figure">2</ref>, where we plot the focus distributions that are correlated with the three responses from Table <ref type="table" target="#tab_3">2</ref>. From this experiment, we can see that the generated responses do not attach much attention to the word "口味(flavor)" even though the word is assigned with the highest focus weight. This verifies that, despite that Ours-Foc incorporates the finegrained focus, it still lacks mechanism(s) and strategy(s) to make full use of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Upon</head><p>the bare-bone model, Ours-FocCoverage incorporates the proposed focusguided mechanism and increases the metric scores a lot especially on the metric Dist and Diversity. We attribute this increase to the use of coverage vector. In such way, the model is able to adjust attention based on attention history as well as the focus, rather than simply considering the current relevant words as in the standard attention mechanism. Therefore, the focus tends to show guiding significance for the decoder to generate qualified responses. From Table <ref type="table" target="#tab_3">2</ref> we can see, the responses generated by Ours-FocCoverage differ from each other with respect to both semantic meaning and their expressions.</p><p>More importantly, Ours-FocConstrain further employs the novel focus constraint to properly align the target response with input post according to the focus. To examine in detail, we plot both focus and decoding attention distribution of the test cases by Ours-FocCoverage and Ours-FocConstrain. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, the latent variable of Ours-FocCoverage addresses the highest focus to the word "吃(eat)". However, the decoder does not follow such guidance and pays more attention to the word "冰淇淋(ice-cream)", resulting in an improper response. In contrast, the latent variable in Ours-FocConstrain concen-trates more on the word "口味(flavor)" than the others. With the help of focus constraint, the decoder of Ours-FocConstrain makes it to direct the generated response embody the meaning of "口味(flavor)". In other words, though Ours-FocCoverage introduces the coverage vector and potentially encourages the diversity using different sampled latent variables, Ours-FocConstrain steps further and kills the chance of generating responses regardless of the focus by using the constraint L f oc . Drawing on the highest scores achieved by Ours-FocConstrain, we conclude that the proposed focus constraint is an indispensable design and is potentially beneficial for CAVEbased response generation models.</p><p>Overall speaking, the proposed Focus-Constrained Attention Mechanism consists of: (1) focus generator to produce fine-grained signals; and (2) focus-guided mechanism and focus constraint to fully utilize the signal. This ablation study validates the necessity of fine-grained latent information, and demonstrates the effectiveness of each component in the proposed method. By leveraging the proposed Focus-Constrained Attention Mechanism, the decoder is able to tell the importance of each word and start a holistic-planned response generation under the fine-grained focus guidance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we identify the insufficiency of discourse-level latent variable in response generation. To address this, we develop a novel CVAEbased model, which exploits a fine-grained wordlevel feature to generate diverse responses. On a real-world benchmarking dataset, we demonstrate that our proposed model is able to fully leverage the fine-grained feature, and generate better responses as compared to several SOTA models. Based on the ablation studies, we verify the contribution of each proposal in our method and highlight the significance of fine-grained signal in response generation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A framework of our proposed model, where the operation ⊕ denotes concatenation, the dashed arrow lines are absent during testing, and the proposed focus-constrained mechanism is represented by the red lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>x i } |x| i=1 for x and {h y i } |y| i=1 for y. Then, we obtain the sentence representation h x for the post x by averaging {h x i } |x| i=1 . The sentence representation h y for the response y is calculated from {h y i } |y| i=1 in the same way.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 2: The focus distributions of the 3 test cases by Ours-Foc from Table 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The results from automatic and human evaluations. The Kappa score is 0.45 and 0.70 for quality and diversity labeling</figDesc><table><row><cell>Method</cell><cell cols="7">Multi-BLEU BLEU-1 BLEU-2 Dist-1 Dist-2 Dist-1 Dist-2 Acceptable Good Intra-Dist Inter-Dist Quality</cell><cell>Diversity</cell></row><row><cell>S2S</cell><cell>26.63</cell><cell>9.07</cell><cell>45.90 60.12</cell><cell>9.75</cell><cell>34.31</cell><cell>61.33</cell><cell>2.88</cell><cell>1.66</cell></row><row><cell>MMI</cell><cell>26.67</cell><cell>9.08</cell><cell>46.17 60.49</cell><cell>9.74</cell><cell>34.43</cell><cell>60.22</cell><cell>3.33</cell><cell>1.68</cell></row><row><cell>MARM</cell><cell>26.70</cell><cell>9.30</cell><cell cols="3">47.00 60.90 10.92 37.88</cell><cell>61.77</cell><cell>4.22</cell><cell>1.72</cell></row><row><cell>CMHAM</cell><cell>26.18</cell><cell>7.58</cell><cell>60.28 76.36</cell><cell>5.83</cell><cell>26.61</cell><cell>59.33</cell><cell>2.88</cell><cell>2.26</cell></row><row><cell>CVAE</cell><cell>28.88</cell><cell>8.78</cell><cell cols="3">75.57 92.66 13.59 49.68</cell><cell>36.88</cell><cell>2.88</cell><cell>2.62</cell></row><row><cell>DCVAE</cell><cell>30.44</cell><cell>8.98</cell><cell cols="3">73.33 90.45 14.43 53.28</cell><cell>58.67</cell><cell>4.67</cell><cell>2.72</cell></row><row><cell>Ours-Foc</cell><cell>27.12</cell><cell>9.01</cell><cell cols="3">44.68 59.75 10.02 35.21</cell><cell>60.67</cell><cell>4.67</cell><cell>1.26</cell></row><row><cell>Ours-FocCoverage</cell><cell>29.50</cell><cell>9.11</cell><cell cols="3">66.71 85.17 15.25 54.16</cell><cell>62.66</cell><cell>3.33</cell><cell>2.36</cell></row><row><cell>Ours-FocConstrain</cell><cell>30.32</cell><cell>9.39</cell><cell cols="3">80.24 95.53 16.89 59.67</cell><cell>65.33</cell><cell>9.33</cell><cell>2.82</cell></row><row><cell cols="4">DCVAE (Gao et al., 2019): It is a CVAE-based</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Seq2Seq model trained with discrete latent vari-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">ables, where the latent variables are connected</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">with words in the vocabulary. To follow their pa-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">per, we use their original implementation and pre-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">train the model with extracted keywords. During</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">testing phase, we adopt their two-stage sampling</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">strategy to generate each response.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>Ours: In addition, we implement two variants of our proposed model Ours-FocConstrain, i.e., 1)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The gold and generated responses by each method.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>are either too short</cell></row><row><cell>or ungrammatical. Such inconsistency between</cell></row><row><cell>the results from Table 1 and Table 2 might be re-</cell></row><row><cell>sulted from several causes. We conjecture one pri-</cell></row><row><cell>mary reason is the gap between model training and</cell></row><row><cell>testing. During training, the semantic representa-</cell></row><row><cell>tion in CMHAM is learned as a mixture of all at-</cell></row><row><cell>tention heads. While during testing, CMHAM is</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/cuizhi555/Focus-Constrained-Attention-Mechanism-for-CVAE-based-Response-Generation.</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank anonymous reviewers for their helpful comments and suggestions to improve our work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Variational attention for sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">Hareesh</forename><surname>Bahuleyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1672" to="1682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Luke</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06349</idno>
		<title level="m">Generating sentences from a continuous space</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Generating multiple diverse responses with multi-mapping and posterior mapping selection</title>
		<author>
			<persName><forename type="first">Chaotao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01781</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Latent alignment and variational attention</title>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Demi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="9712" to="9724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A discrete cvae for response generation on short-text conversation</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1898" to="1908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A knowledge-grounded neural conversation model</title>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Dialogwae: Multimodal response generation with conditional wasserstein autoencoder</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.12352</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter</title>
		<meeting>the 2016 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">Diana</forename><surname>Perez-Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ismael</forename><surname>Pascual-Nieto</surname></persName>
		</author>
		<title level="m">Conversational agents and natural language interaction: Techniques and effective</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Are training samples correlated? learning to generate dialogue responses with multiple references</title>
		<author>
			<persName><forename type="first">Lisong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juntao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3826" to="3835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generating high-quality and informative conversation responses with sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">Yuanlong</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Britz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2210" to="2219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">From eliza to xiaoice: challenges and opportunities with social chatbots</title>
		<author>
			<persName><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao-Dong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Information Technology &amp; Electronic Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="26" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3483" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Get the point of my utterance! learning towards effective responses with multi-head attention mechanism</title>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shen</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyue</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4418" to="4424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Modeling coverage for neural machine translation</title>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Topic aware neural response generation</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yalou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Attribute2image: Conditional image generation from visual attributes</title>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.00570</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards implicit contentintroducing for generative short-text conversation systems</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2190" to="2199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mechanism-aware neural machine for dialogue response generation</title>
		<author>
			<persName><forename type="first">Ganbin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongyu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
