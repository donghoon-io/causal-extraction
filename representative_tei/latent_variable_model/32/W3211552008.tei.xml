<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Constructing Emotion Consensus and Utilizing Unpaired Data for Empathetic Dialogue Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lei</forename><surname>Shen</surname></persName>
							<email>shenlei17z@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinchao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Pattern Recognition Center</orgName>
								<address>
									<addrLine>WeChat AI</addrLine>
									<region>Tencent Inc</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiao</forename><surname>Ou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaofang</forename><surname>Zhao</surname></persName>
							<email>zhaoxf@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Pattern Recognition Center</orgName>
								<address>
									<addrLine>WeChat AI</addrLine>
									<region>Tencent Inc</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Constructing Emotion Consensus and Utilizing Unpaired Data for Empathetic Dialogue Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Researches on dialogue empathy aim to endow an agent with the capacity of accurate understanding and proper responding for emotions. Existing models for empathetic dialogue generation focus on the emotion flow in one direction, that is, from the context to response. We argue that conducting an empathetic conversation is a bidirectional process, where empathy occurs when the emotions of two interlocutors could converge on the same point, i.e., reaching an emotion consensus. Besides, we also find that the empathetic dialogue corpus is extremely limited, which further restricts the model performance. To address the above issues, we propose a dual-generative model, Dual-Emp, to simultaneously construct the emotion consensus and utilize some external unpaired data. Specifically, our model integrates a forward dialogue model, a backward dialogue model, and a discrete latent variable representing the emotion consensus into a unified architecture. Then, to alleviate the constraint of paired data, we extract unpaired emotional data from open-domain conversations and employ Dual-Emp to produce pseudo paired empathetic samples, which is more efficient and low-cost than the human annotation. Automatic and human evaluations demonstrate that our method outperforms competitive baselines in producing coherent and empathetic responses.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Empathy, a fundamental trait of humans, describes the ability to place oneself in another person's position and share his/her feelings or emotions. Besides, it has been considered to be one of the most valuable affective phenomena for improving human-machine interactions <ref type="bibr">(Zech and Rimé,</ref> Joint work with Pattern Recognition Center, WeChat AI, Tencent Inc, China. * Xiaofang Zhao is the corresponding author. 2005). The studies of empathy in natural language processing mainly include detecting empathy in spoken language or text <ref type="bibr" target="#b2">(Buechel et al., 2018;</ref><ref type="bibr" target="#b24">Sharma et al., 2020)</ref>, generating empathetic dialogue responses <ref type="bibr" target="#b12">(Lin et al., 2019;</ref><ref type="bibr" target="#b17">Majumder et al., 2020)</ref>, and constructing empathy lexicons <ref type="bibr" target="#b22">(Sedoc et al., 2020)</ref> or datasets <ref type="bibr" target="#b21">(Rashkin et al., 2019)</ref>.</p><p>The empathetic dialogue generation task has been regarded as a unidirectional process from the context to response, and is modeled as a multi-task learning that combines the emotion understanding and the emotion-enhanced response generation. Therefore, existing work <ref type="bibr" target="#b21">(Rashkin et al., 2019;</ref><ref type="bibr" target="#b12">Lin et al., 2019;</ref><ref type="bibr" target="#b11">Li et al., 2020;</ref><ref type="bibr" target="#b17">Majumder et al., 2020)</ref> mainly focuses on improving the accuracy of emotion classification or enhancing response generation via integrating the detected emotion factor.</p><p>Conducting an empathetic conversation is naturally a bidirectional process: the speaker conveys his/her emotion by describing a certain situation, then the listener receives that emotion and feeds his/her feeling back to the listener via a response. Then, the empathy is triggered when two interlocutors link similar experiences and their emotions could converge on the same point, i.e., reaching an emotion consensus. Take the case in Figure <ref type="figure" target="#fig_0">1</ref> as an example. The emotion consensus "Sad" works as an intersection that connects both the speaker and listener, and it is a high-level abstraction behind the content, i.e., both two responses convey their acknowledgment of the sad feeling even with different expressions. Therefore, a unidirectional model is not enough to model the relationship between the context and response. Besides, previous models for this task only utilize paired data with limited capacity in a benchmark dataset, EMPATHETICDIA-LOGUES. Rather than manually annotating a larger empathetic dataset, we find that in open-domain conversations, there is large-scale emotional data that can be used to improve the performance. Compared with recognizing whether a context-response pair is empathetic, obtaining either an emotional context or response (named as unpaired data in this paper) can be easier with a well-trained classifier.</p><p>In this paper, we propose a Dual-Generative model for the Empathetic dialogue generation task (Dual-Emp), which simultaneously constructs emotion consensus and utilizes unpaired data. Dual-Emp combines a forward dialogue model (generating a response based on its context) and a backward dialogue model (generating a context based on its responses) with a discrete latent variable. Specifically, the forward and backward encoders convert the context and response into vectors at the same time, and then a discrete latent variable is used to capture the high-level emotion consensus shared in each context-response pair. Moreover, the latent variable and an emotion-enhanced attention mechanism are integrated into both forward and backward decoders to better express proper empathy. To utilize unpaired emotional data, we firstly extract them from open-domain conversations with emotions. Then we can get pseudo pairs by feeding either emotional responses or contexts to the backward or forward model. A joint training process is introduced to promote the semantic coherence between contexts and responses. Furthermore, two types of optimization methods are applied to better train the entire model with paired and unpaired data. Experimental results on a benchmark dataset EMPATHETICDIALOGUES show that Dual-Emp significantly outperforms competitive baselines in generating meaningful and related responses while expressing an appropriate empathy.</p><p>Our main contributions can be summarized as:</p><p>(1) We point out that the empathetic dialogue generation contains bidirectional processes, and highlight the importance of constructing emotion consensus. Besides, we propose a novel dualgenerative model that couples a forward and a backward dialogue model with a discrete latent variable capturing the shared emotion consensus. (2) We utilize unpaired emotional data to break the constraint of paired empathetic data in the widely-used benchmark dataset EMPATHETICDIALOGUES. (3) Automatic and human evaluations show that our model outperforms competitive baselines in terms of fluency, coherence, and empathy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Emotion-Controllable Response Generation.</p><p>Infusing emotions into dialogue systems can make conversational agents more human-like and benefit the interactions between human and machine <ref type="bibr" target="#b20">(Prendinger and Ishizuka, 2005)</ref>. Emotioncontrollable response generation aims to generate emotional responses conditioning on a manuallyprovided label. Existing work <ref type="bibr">(Zhou et al., 2018;</ref><ref type="bibr" target="#b42">Zhou and Wang, 2018;</ref><ref type="bibr" target="#b3">Colombo et al., 2019;</ref><ref type="bibr" target="#b27">Song et al., 2019;</ref><ref type="bibr" target="#b25">Shen and Feng, 2020)</ref> focused on obtaining responses that are not only meaningful, but also in accordance with the desired emotion. Empathetic Response Generation. Rashkin et al.</p><p>(2019) considered a richer and evenly distributed set of emotions, and released a dataset EMPA-THETICDIALOGUES. <ref type="bibr" target="#b26">Shin et al. (2020)</ref> formulated a reinforcement learning problem to maximize user's sentimental feelings towards the generated responses. <ref type="bibr" target="#b12">Lin et al. (2019)</ref> presented an encoder-decoder model with each emotion having a dedicated decoder. <ref type="bibr" target="#b17">Majumder et al. (2020)</ref> introduced emotion grouping, emotion mimicry, and stochasticity to generate empathetic and various responses. <ref type="bibr" target="#b11">Li et al. (2020)</ref> integrated knowledge to better understand dialogue contexts, and also designed an emotion-focused attention mechanism for emotional dependencies. Dual Learning in NLP. <ref type="bibr" target="#b7">He et al. (2016)</ref> proposed Dual Learning (DL) for machine translation first, which considered the source to target language translation and target to source language translation as a dual task. After that, <ref type="bibr" target="#b28">Tang et al. (2017)</ref> implemented a dual framework for the questionanswering system. Both <ref type="bibr">Zhang et al. (2018a)</ref> and <ref type="bibr" target="#b4">Cui et al. (2019)</ref> used similar idea in dialogue generation task to produce coherent but not safe responses. <ref type="bibr" target="#b25">Shen and Feng (2020)</ref> applied DL for emotion-controllable response generation with three awards for emotions and semantics. Some researchers also exploited DL to relieve the need of paired data and make use of unpaired data in several areas, such are style transfer <ref type="bibr">(Luo et al., 2019a,b)</ref>, semantic understanding <ref type="bibr" target="#b30">(Tseng et al., 2020)</ref>, stylized response generation <ref type="bibr">(Zheng et al., 2020a)</ref>, and machine translation <ref type="bibr">(Zheng et al., 2020b)</ref>.</p><p>The differences between our model and previous methods are: (1) To improve the empathy understanding, we introduce a backward model to represent the response and a discrete latent variable to capture the emotion consensus shared by contexts and responses. (2) Our forward and backward models are connected by a latent variable, and both of them can be updated at each iteration, while traditional DL can only fix one to update another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>For empathetic dialogue generation, a dialogue consists of utterances from a speaker and a listener. Given context c = {S 1 , L 1 , S 2 , L 2 ., ..., S t }, where</p><formula xml:id="formula_0">S i = {w i j } |S i | j=1 denotes speaker and L i = {w i j } |L i | j=1</formula><p>denotes listener, the goal is to track the speaker's emotion state from c, and generate a response y = L t that is meaningful and empathetic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The architecture of Dual-Emp is shown in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Dual-Emp has five modules, the forward encoder f enc , forward decoder f dec , backward encoder b enc , backward decoder b dec , and z e indicating a discrete latent variable. z e can be inferred from both c and y and is used to capture emotion consensus shared in each c, y pair. Because of the existence of z e , other modules are correlated and can better model both the semantic relation and the emotion connection between c and y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Architecture</head><p>Since the backward dialogue model has the same architecture as the forward one, we specify the components of forward dialogue model below and omit those of backward model for space limitation.</p><p>Encoder. Following the work of <ref type="bibr" target="#b12">Lin et al. (2019)</ref>, we firstly concatenate utterances in c into a long sequence with length n and add a special token CTX to the beginning of c inspired by BERT <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref>. Then, each token w in c is calculated as the sum of three embeddings: where E w (•), E p (•), and E r (•) ∈ R |V |×d emb represent word embedding space, positional embedding space and role embedding space<ref type="foot" target="#foot_0">foot_0</ref> , respectively. Finally, a transformer encoder <ref type="bibr" target="#b31">(Vaswani et al., 2017)</ref> f enc is applied to get the context representation:</p><formula xml:id="formula_1">E c (w) = E w (w) + E p (w) + E r (w),<label>(1)</label></formula><formula xml:id="formula_2">H = f enc (E c ([CTX; c])),<label>(2)</label></formula><p>where ";" represents the concatenation operation, and</p><formula xml:id="formula_3">H ∈ R (n+1)×d mod . The contextualized encod- ing of CTX, i.e., H 0 ∈ R d mod , is used as the final representation of the entire context. Emotion Consensus Construction. A K-way cat- egorical latent variable z e ∈ [1, K] (Bao et al.,<label>2020</label></formula><p>) is used to capture the emotion consensus shared by c and y. Inspired by <ref type="bibr" target="#b38">Zhao et al. (2019)</ref>, we define the prior distribution where we sample z e from to be uniform<ref type="foot" target="#foot_1">foot_1</ref> , i.e., p(z e ) = 1/K. Correspondingly, the approximate posterior distribution is defined as follows:</p><formula xml:id="formula_4">q(z e |c) = softmax(FFN(H 0 )) ∈ R K ,<label>(3)</label></formula><p>where FFN(•) represents a feedforward network. This part can be considered as the emotion understanding on c.</p><p>Here z e has its own embedding space</p><formula xml:id="formula_5">E z ∈ R K×d mod to convert it into a vector, i.e., E [z] = E z (z e ) ∈ R d mod . To supervise the emo- tion expression in E [z]</formula><p>, we train a classifier using the cross-entropy loss between E [z] and groundtruth emotion label e * :</p><formula xml:id="formula_6">p e = softmax(W e E [z] ),<label>(4)</label></formula><formula xml:id="formula_7">L emo = -e * log p e ,<label>(5)</label></formula><p>where W e is a trainable weight matrix.  Decoder. Existing work <ref type="bibr" target="#b13">(Lin et al., 2020;</ref><ref type="bibr" target="#b11">Li et al., 2020)</ref> mainly integrates the obtained emotion factor to either the first decoding position or all steps. To focus on emotion consensus dynamically, we apply an emotion-enhanced attention mechanism in the cross-attention layer of transformer decoder. We firstly concatenate E [z] with token embeddings of the decoder input</p><formula xml:id="formula_8">{y i } t-1 i=1 to get representations Y = {y i } t-1 i=0 with y 0 = E [z]</formula><p>. Then we feed Y into decoder f dec .</p><p>Our decoder has similar structure to the transformer decoder. The input Y is converted to D by the self-attention layer. As H and E [z] serve different purposes, we design a cross-attention layer with two separate key-value matrices, and the encoderdecoder vectors are computed as follows:</p><formula xml:id="formula_9">C H = MultiHead(D, H, H), (6) C Z = MultiHead(D, E [z] , E [z] ),<label>(7)</label></formula><p>where MultiHead(Q, K, V) is a multi-head attention function taking a query matrix Q, a key matrix K, and a value matrix V as inputs. The fully connected feedforward layer is defined as:</p><formula xml:id="formula_10">Ŷ = FFN([C H ; C Z ]),<label>(8)</label></formula><p>where Ŷ = {ŷ i } t i=1 . Finally, the decoding distribution over the vocabulary of the next token is computed as:</p><formula xml:id="formula_11">p(y t |y &lt;t , c, z e ) = softmax(W o ŷt ),<label>(9)</label></formula><p>where W o is a trainable weight matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training and Inference</head><p>We firstly describe how Dual-Emp can be trained with the paired data c, y , and also the unpaired data c or y. Then a combined objective is derived to optimize Dual-Emp using the paired and unpaired data at the same time.</p><p>Training with Paired Data. Given c, y , we aim to maximize the log-likelihood of a joint probability p(c, y): L 1 =E q(ze|c) log p(y|z e , c) + E q(ze|c) log p(c|z e , y)</p><formula xml:id="formula_12">log p(c, y) = log</formula><formula xml:id="formula_13">-D KL [q(z e |c)||p(z e )],<label>(11)</label></formula><p>where the first term denotes the forward dialogue model, q(z e |c) is the approximate posterior distribution of z e , and is computed by the forward encoding process (red x in Figure <ref type="figure" target="#fig_2">3(c)</ref>). p(y|z e , c) is the forward decoding process (green y in Figure <ref type="figure" target="#fig_2">3(c</ref>)); the second term denotes the reconstruction of c, and p(c|z e , y) is the backward decoding process (blue y in Figure <ref type="figure" target="#fig_2">3(c</ref>)); the third term is a Kullback-Leibler (KL) divergence between two distributions.</p><p>Analogously, the posterior distribution of z e can be approximated by q(z e |y), and the objective can be converted as follows:</p><p>L 2 =E q(ze|y) log p(c|z e , y) + E q(ze|y) log p(y|z e , c)</p><formula xml:id="formula_14">-D KL [q(z e |y)||p(z e )],</formula><p>(12) where terms have similar meanings to those in Eq. 11, and we only need to interchange "forward" and "backward". Besides, the forward encoding process (red x in Figure <ref type="figure" target="#fig_2">3(c)</ref>) is replaced with the backward encoding process (gray x in Figure <ref type="figure" target="#fig_2">3</ref>). Detailed derivations can be found in Appendix. Therefore, the final loss function for the paired data is:</p><formula xml:id="formula_15">L cy = L 1 + L 2 + αL emo . (<label>13</label></formula><formula xml:id="formula_16">)</formula><p>where α is a hyper-parameter.</p><p>Training with Unpaired Data. Given unpaired data c (c is an emotional context), we need to maximize the log-likelihood of a marginal probability p(c):</p><formula xml:id="formula_17">log p(c) = log y ze p(c, y, z e ).<label>(14)</label></formula><p>Then, we can get the evidence lower bound for the marginal probability:</p><formula xml:id="formula_18">L 3 =E q(y|ze,c) E q(ze|c) log p(c|z e , y) -D KL [q(z e |c)||p(z e )],<label>(15)</label></formula><p>where the first term is the reconstruction of c, q(z e |c) is computed by the forward encoding process (x in Figure <ref type="figure" target="#fig_2">3</ref> The forward generation process q(y|z e , c) is similar to the back-translation in machine translation <ref type="bibr">(Zhang et al., 2018b)</ref>, and we use f dec to generate pseudo y' given c and z e . Since the ground-truth y is unobserved here, we apply reinforcement learning and policy gradient method <ref type="bibr" target="#b33">(Williams, 1992)</ref> for training. The reward is designed as the probability of the model to reconstruct c based on the generated ŷ and z e : r = p(c|ŷ, z e ).</p><p>(16)</p><p>Similarly, we can get an objective when utilizing unpaired y (the emotional response):</p><formula xml:id="formula_19">L 4 =E q(c|ze,y) E q(ze|y) log p(y|z e , c) -D KL [q(z e |y)||p(z e )],<label>(17)</label></formula><p>where the first term is the reconstruction of y, and the process is symmetrical to that of L 3 . Detailed derivations can be found in Appendix. The final loss functions for unpaired data c and y are:</p><formula xml:id="formula_20">L c = L 3 + βL emo ,<label>(18)</label></formula><formula xml:id="formula_21">L y = L 4 + γL emo ,<label>(19)</label></formula><p>where β and γ are two hyper-parameters.</p><p>Total Training Loss. During training, the paired empathetic data in EMPATHETICDIALOGUES and the unpaired emotional data from open-domain conversations are used simultaneously. Then, the total loss can be summarized as:</p><formula xml:id="formula_22">L = L cy + L c + L y .<label>(20)</label></formula><p>Inference. During inference, given the input c, only the forward dialogue model is applied. We use f enc to encode c and infer z e , then employ f dec to generate ŷ based on c and z e .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we conduct experiments to evaluate our proposed method. We firstly introduce some empirical settings. Then we illustrate our results on both automatic and human evaluations. Finally, we show some cases generated by different models and do further analyses over our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We conduct our experiments on the EMPATHET-ICDIALOGUES <ref type="bibr" target="#b21">(Rashkin et al., 2019)</ref> dataset that consists of 24,850 conversations between two interlocutors. Each conversation in the dataset contains one emotion label, a situation where the speaker feels the exact emotion, and utterances about the speaker's descriptions of the situation or the listener's empathetic replies. There are 32 evenlydistributed emotion labels in the dataset. We apply the data provided by the original paper with the split ratio of 8:1:1 for training/validation/test set, and use the script released by <ref type="bibr" target="#b12">Lin et al. (2019)</ref> to preprocess the data. Emotion labels are given as supervised signals in the training process, while during inference, they are predicted to evaluate the accuracy of emotion understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We optimize the models using Adam (Kingma and Ba, 2015) with a mini-batch size of 16. The learning rate is initialized to 1e-4 and we vary the learning rate following <ref type="bibr" target="#b31">Vaswani et al. (2017)</ref> To get unpaired emotional data, we utilize two large-scale datasets of open-domain conversations provided by <ref type="bibr" target="#b40">Zhong et al. (2020)</ref>, namely Reddit and Twitter. Following <ref type="bibr">Zhou et al. (2018)</ref> and <ref type="bibr" target="#b25">Shen and Feng (2020)</ref>, an emotion classifier is applied to obtain the ground-truth emotion label for each context and response. Here, we use the pre-trained classifier provided by <ref type="bibr" target="#b21">Rashkin et al. (2019)</ref> to predict labels among 32 emotions. The classifier could return one emotion label with the highest probability. We firstly keep contexts or responses with the probability larger than a threshold s = 0.60. Then, we remove contexts or responses with length smaller than 3. Finally, 155,059 contexts and 149,672 responses are obtained as unpaired emotional data.</p><p>We use Pytorch<ref type="foot" target="#foot_2">foot_2</ref> to implement the codes, and our model is trained on a Titan Xp GPU with an average running time of 2 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>We compare our approach with five representative baselines: (1) Multi-TRS (Rashkin et al., 2019): A transformer-based model trained with emotion classification loss in addition to MLE loss, and the emotion label is classified from the encoder output; (2) MoEL <ref type="bibr" target="#b12">(Lin et al., 2019)</ref>: An extension to Multi-TRS, which softly combines the output states of the appropriate decoders and generates an empathetic response. Each decoder is optimized to focus on a specific emotion; (3) EmpDG <ref type="bibr" target="#b11">(Li et al., 2020)</ref>: A model that exploits coarse-and finegrained emotions and introduces an interactive adversarial learning framework to use user feedbacks; (4) DualVAE <ref type="bibr" target="#b29">(Tran and Nguyen, 2018</ref>): A model with two decoders: one is for CVAE, and the other is for response auto-encoding; ( <ref type="formula" target="#formula_7">5</ref>) MIME <ref type="bibr" target="#b17">(Majumder et al., 2020)</ref>: A model that integrates emotion grouping, emotion mimicry, and stochasticity strategies to generate varied responses. MIME is also the state-of-the-art model for empathetic response generation. To make fair comparisons, we do not apply methods based on pre-trained models here, as both Dual-Emp and the above mentioned ones are not based on pre-trained models. Note that model ( <ref type="formula" target="#formula_1">1</ref>) to ( <ref type="formula" target="#formula_7">5</ref>) can only utilize the paired data.</p><p>Additionally, we also design following models for ablation study: ( <ref type="formula">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Measures</head><p>Automatic Metrics. For automatic evaluation, we use followings metrics: (1) BLEU <ref type="bibr" target="#b18">(Papineni et al., 2002)</ref>; (2) Embedding-based scores (Average, Greedy, and Extrema)<ref type="foot" target="#foot_3">foot_3</ref>  <ref type="bibr" target="#b14">(Liu et al., 2016;</ref><ref type="bibr" target="#b23">Serban et al., 2017)</ref>; (3) Perplexity (PPL) <ref type="bibr" target="#b32">(Vinyals and Le, 2015)</ref>; (4) Dist-1/2 <ref type="bibr" target="#b10">(Li et al., 2016)</ref>; (5) Emotion accuracy (the agreement between the ground-truth emotion labels and the predicted ones from Eq. 5). Emotion accuracy can be used to measure the ability of emotion understanding. Human Evaluation. Firstly, we randomly sample 100 contexts and their corresponding responses from our model as well as the baselines. Next, we send pairs of the context and generated response from different models to three professional annotators without order. Annotators are asked to evaluate each pair independently based on three distinct metrics: Empathy, Relevance, and Fluency <ref type="bibr" target="#b21">(Rashkin et al., 2019;</ref><ref type="bibr" target="#b12">Lin et al., 2019;</ref><ref type="bibr" target="#b17">Majumder et al., 2020)</ref>. Empathy measures the degree of emotional understanding of context shown by the response; Relevance evaluates whether the generated responses are relevant on topic with the context; Fluency assesses the grammatical correctness and readability of the generated responses. Each metric is rated on five-scale with "5" represents the best performance. Human A/B Test. In this part, we try to directly compare Dual-Emp with other baselines. We randomly sample 100 dialogues each for Dual-Emp vs. {Multi-TRS, MoEL, EmpDG, DualVAE, MIME}. Three annotators are given generated responses from either Dual-Emp or {Multi-TRS, MoEL, Em-pDG, DualVAE, MIME} in random order, and are asked to choose the better response. They can either choose one of the responses or select "Tie" when the provided options are either both good or both bad. The result of each sample is determined by majority voting. Finally, we calculate the percentage of samples where the first or second model generates the better response and where these two models perform similarly.  <ref type="table" target="#tab_2">1</ref> shows the results of our ablation study. Comparisons between Sing-Emp-Paired and Dual-Emp-Paired show the effectiveness of capturing emotion consensus with the assistance of both backward model and discrete latent variable. Especially, the noticeable improvement of Emotion accuracy indicates the discrete latent variable used for emotion prediction can help better model the emotion consensus by taking contexts and responses into consideration. In addition, we can find that with the support of unpaired emotional data, Dual-Emp achieves better results than Dual-Emp-Paired. Human Evaluation Results. Human evaluation in Table <ref type="table" target="#tab_2">1</ref> illustrates that Dual-Emp obtains the best performance (t-test, p-value &lt; 0.05) on all scores. This suggests that our bidirectional model with latent variable helps construct emotion consensus shared by contexts and responses, thus improving the topic consistency and evoking more empathetic expressions. Besides, as more unpaired emotional data is utilized, Dual-Emp can achieve better Fluency. Additionally, we carry out pairwise comparisons to directly compare the response quality in Table <ref type="table" target="#tab_3">2</ref>. The results confirm that responses from Dual-Emp are more preferred by humans. Agreements to measure the consistency among three annotators are calculated with Fleiss' kappa <ref type="bibr" target="#b6">(Fleiss and Cohen, 1973)</ref>, and the kappa values indicate "moderate agreement" in our cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Case Study</head><p>Table <ref type="table" target="#tab_5">3</ref> shows two examples generated by Dual-Emp and other baselines. In the first case, Dual-Emp generates the most context-consistent response with a proper "apprehensive" emotion by replying with words "scary" and "what happened", whereas baselines fail to understand the negative emotion or express inappropriate contents. In the second case, Dual-Emp generates a coherent and informative response, which corresponds to a subtle emotion change of the context from "lost a job" to "hoping he can find a full time job soon". The response is not only emotion-related, but also contains the correct personal pronoun "he" and keyword "job".     As we can see, for Sing-Emp-Paired, some emotion categories can achieve pretty high accuracy, but in general, the accuracy is unbalanced among all emotions, which indicates that z e cannot construct the emotion consensus well by only considering the contexts. In contrast, Dual-Emp-Paired not only improves the overall Emotion accuracy, but also exhibits a relatively even performance over all 32 emotions. Therefore, z e can better understand the emotion via capturing emotion consensus with both forward and backward dialogue models. Choices of the Unpaired Data. The threshold s we use in previous experiments equals to 0.60.</p><p>Here, we choose different options to show their influence on the empathetic dialogue generation task.</p><p>Table <ref type="table" target="#tab_6">4</ref> shows that more unpaired emotional data does not lead to better results as some labels are not adequate with a low confidence. The emotion classifier we applied to label the utterances from Reddit and Twitter is based on a 32-category classification task, thus it is hard to get very accurate results. Though the predicted emotion labels are noisy, these samples are good enough to train our model in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we propose a dual-generative model, Dual-Emp, to generate the empathetic response given a context. We point out that conducting an empathetic conversation is a bidirectional process, and empathy is mainly reflected by emotion consensus between the context and response. Then we couple forward and backward dialogue models with a discrete latent variable denoting the emotion consensus. Moreover, we integrate unpaired emotional data from open-domain conversations into Dual-Emp to relieve the need of paired data. Experimental results on a benchmark dataset show that Dual-Emp can generate fluent, related, informative, and empathetic responses. As the future work, we will prove the effectiveness of our method based on pre-trained models, and analyze how classification errors in unpaired data affect the generation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of conducting an empathetic conversation. Both responses show empathy to the speaker.</figDesc><graphic coords="1,306.14,212.60,218.27,141.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The architecture of Dual-Emp. It couples forward and backward dialogue models with a discrete latent variable z e denoting emotion consensus.</figDesc><graphic coords="3,317.06,70.87,196.44,102.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of the training process. (a) shows the inference of z e . Both c and y are used to infer z e that represents the emotion consensus shared by c and y. (b)shows the graphical model of (c), and (c) depicts procedures to compute L 1 (Eq. 11)/L 2 (Eq. 12). (d) represents procedures to compute L 3 (Eq. 15).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>ze p(c, y, z e ). (10) Following the derivations from Zhao et al. (2018), Zhao et al. (2019), Tseng et al. (2020), and the variational inference (Kingma and Welling, 2014), an objective based on the evidence lower bound can be derived as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(d)), q(y|z e , c) is the forward generation process (y in Figure 3(d)), and p(c|z e , y) is the backward decoding process (z in Figure 3(d)); the second term is a KL divergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>) Sing-Emp-Paired: A variation of Dual-Emp with only the forward model and paired empathetic data; (7) Dual-Emp-Paired: Dual-Emp with only paired empathetic data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>4. 7</head><label>7</label><figDesc>Further Analysis Effects of Backward Model and z e . To gain an insight into the effectiveness of backward dialogue model and the latent variable z e , we plot the Emotion accuracy score of each emotion label based on Sing-Emp-Paired and Dual-Emp-Paired in Figure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Emotion accuracy over 32 emotions of Sing-Emp-Paired and Dual-Emp-Paired. The accuracy of Sing-Emp-Paired is unbalanced among all emotions, while Dual-Emp-Paired can not only improve the overall accuracy, but also exhibit a relatively even performance.</figDesc><graphic coords="8,70.87,281.28,453.54,109.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>During inference, we use greedy decoding strategy and the maximum decoding step is set to 30. K equals to 32. α, β, and γ are simply set to 1. The running epoch is set to 30 with early stopping.</figDesc><table><row><cell>. Similar to</cell></row><row><cell>Lin et al. (2019), Li et al. (2020), and Majumder</cell></row><row><cell>et al. (2020), we use pre-trained GloVe vectors</cell></row><row><cell>(Pennington et al., 2014) to initialize the word em-</cell></row><row><cell>beddings. Besides, all common hyper-parameters</cell></row></table><note><p><p><p><p><p>are set the same as previous work, e.g., the hidden size d mod and embedding size d emb are set to 300. In order to alleviate the degeneration problem of variational framework, we apply KL annealing</p><ref type="bibr" target="#b1">(Bowman et al., 2016)</ref> </p>that is the same as in</p>Zhou  et al. (2018)</p>.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Automatic and human evaluation results. The metrics BLEU, Average, Greedy, Extrema, Dist-1, Dist-2, Emotion accuracy, Empathy, Relevance, and Fluency are abbreviated as B, Avg, Gre, Ext, D1, D2, EA, Emp, Rel, and Flu, respectively. Results show that Dual-Emp achieves the best performance on all metrics, especially a large improvement in Dist-1/2, Emotion accuracy, and Empathy.</figDesc><table><row><cell>Method</cell><cell>B</cell><cell>Avg</cell><cell>Gre</cell><cell cols="3">Automatic Evaluation Ext PPL D1 (%) D2 (%) EA (%) Emp Human Evaluation Rel Flu</cell></row><row><cell>Multi-TRS</cell><cell cols="4">2.56 0.938 0.786 0.541 33.82</cell><cell>0.68</cell><cell>2.62</cell><cell>35.17</cell><cell>3.08 3.21 3.14</cell></row><row><cell>MoEL</cell><cell cols="4">2.80 0.945 0.793 0.537 37.81</cell><cell>0.56</cell><cell>2.70</cell><cell>35.38</cell><cell>3.35 3.65 3.26</cell></row><row><cell>Emp-DG</cell><cell cols="4">2.79 0.935 0.788 0.532 34.31</cell><cell>0.47</cell><cell>2.10</cell><cell>34.35</cell><cell>3.27 3.54 3.38</cell></row><row><cell>DualVAE</cell><cell cols="4">2.76 0.941 0.791 0.540 33.46</cell><cell>0.77</cell><cell>3.21</cell><cell>35.36</cell><cell>3.36 3.62 3.45</cell></row><row><cell>MIME</cell><cell cols="4">2.82 0.946 0.794 0.536 37.53</cell><cell>0.51</cell><cell>2.68</cell><cell>34.88</cell><cell>3.40 3.79 3.41</cell></row><row><cell cols="5">Sing-Emp-Paired 2.77 0.944 0.790 0.533 32.71</cell><cell>0.75</cell><cell>2.91</cell><cell>28.75</cell><cell>3.57 3.77 3.49</cell></row><row><cell cols="5">Dual-Emp-Paired 2.86 0.950 0.792 0.542 32.56</cell><cell>0.80</cell><cell>3.09</cell><cell>36.82</cell><cell>3.62 3.86 3.57</cell></row><row><cell>Dual-Emp</cell><cell cols="4">2.91 0.957 0.796 0.545 31.01</cell><cell>1.08</cell><cell>3.23</cell><cell>37.53</cell><cell>3.82 4.08 3.62</cell></row><row><cell cols="3">Dual-Emp vs. Win Loss</cell><cell>Tie</cell><cell>Kappa</cell><cell></cell></row><row><cell>Multi-TRS</cell><cell cols="3">43% 27% 30%</cell><cell>0.563</cell><cell></cell></row><row><cell>MoEL</cell><cell cols="3">37% 32% 31%</cell><cell>0.548</cell><cell></cell></row><row><cell>Emp-DG</cell><cell cols="3">40% 28% 32%</cell><cell>0.506</cell><cell></cell></row><row><cell>DualVAE</cell><cell cols="3">39% 30% 31%</cell><cell>0.527</cell><cell></cell></row><row><cell>MIME</cell><cell cols="3">36% 32% 32%</cell><cell>0.569</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results of human A/B test. Pairwise comparisons show that responses from Dual-Emp are more preferred by humans than those from baselines.</figDesc><table><row><cell>4.5 Experimental Results</cell></row><row><cell>Automatic Evaluation Results. The automatic</cell></row><row><cell>evaluation results are shown in the left part of Table</cell></row><row><cell>1. The top part is the results of all baseline models,</cell></row><row><cell>and we can see that Dual-Emp outperforms other</cell></row><row><cell>methods on all metrics (t-test, p-value &lt; 0.05). The</cell></row><row><cell>improvements of Dual-Emp on PPL, Dist-1/2, and</cell></row><row><cell>Emotion accuracy are significant, indicating that</cell></row><row><cell>it can improve emotion understanding, and also</cell></row><row><cell>enhance content fluency and diversity simultane-</cell></row><row><cell>ously. MoEL, Emp-DG, and MIME have similar</cell></row><row><cell>performance, as they try to either improve the emo-</cell></row><row><cell>tion understanding or intensify the emotion-based</cell></row><row><cell>response generation.</cell></row><row><cell>The bottom part of Table</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Emotion Hopeful Context My husband lost a job, but I am hoping he can find a full time job soon. Ground-truth Response He will, I have faith. MoEL I am sorry to hear that. I am sure he will be fine. Emp-DG I am sorry to hear that. I hope you have a good time! MIME That is a good thing to do. I hope you have a good job! Dual-Emp That is unfortunate. I hope he gets a new job.</figDesc><table><row><cell></cell><cell>Emotion</cell><cell>Apprehensive</cell></row><row><cell></cell><cell>Context</cell><cell>I went skydiving last summer with my partner. It was so scary !</cell></row><row><cell></cell><cell cols="2">Ground-truth Response Wow, that is scary. Were you nervous?</cell></row><row><cell>1</cell><cell>MoEL</cell><cell>I am so sorry to hear that. I am glad you are okay!</cell></row><row><cell></cell><cell>Emp-DG</cell><cell>Did you go check it out?</cell></row><row><cell></cell><cell>MIME</cell><cell>Oh no! I am sorry to hear that. I hope you get it!</cell></row><row><cell></cell><cell>Dual-Emp</cell><cell>That is scary! What happened to you?</cell></row><row><cell>2</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Generated responses from MoEL, Emp-DG, MIME, and Dual-Emp. In Case 1, Dual-Emp generates the most context-consistent response with a proper "apprehensive" emotion by replying with words "scary" and "what happened". In Case 2, Dual-Emp captures a subtle emotion change of the context from "lost a job" to "hoping he can find a full time job soon". Besides, it contains the correct personal pronoun "he" and keyword "job".</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Automatic evaluation results based on the number of unpaired data with different s values. Results show that more unpaired data does not lead to better results as some labels are not adequate with a low confidence.</figDesc><table><row><cell>s</cell><cell cols="2">#context #response</cell><cell>B</cell><cell>Avg</cell><cell>Gre</cell><cell>Ext</cell><cell>PPL</cell><cell>D1 (%) D2 (%) EA (%)</cell></row><row><cell>0.50</cell><cell>324,243</cell><cell>314,070</cell><cell cols="5">2.25 0.937 0.791 0.549 31.22</cell><cell>0.90</cell><cell>2.90</cell><cell>35.62</cell></row><row><cell>0.55</cell><cell>224,324</cell><cell>216,839</cell><cell cols="5">2.69 0.933 0.784 0.537 32.63</cell><cell>1.87</cell><cell>4.32</cell><cell>36.06</cell></row><row><cell>0.60</cell><cell>155,059</cell><cell>149,672</cell><cell cols="5">2.91 0.957 0.795 0.545 31.01</cell><cell>1.08</cell><cell>3.23</cell><cell>37.53</cell></row><row><cell>0.65</cell><cell>107,189</cell><cell>103,192</cell><cell cols="5">2.25 0.934 0.783 0.539 32.61</cell><cell>1.70</cell><cell>4.80</cell><cell>35.66</cell></row><row><cell>0.70</cell><cell>73,132</cell><cell>70,200</cell><cell cols="5">2.60 0.938 0.791 0.540 31.66</cell><cell>0.70</cell><cell>2.40</cell><cell>37.51</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The roles in c is an alternating set of "speaker" and "listener", while in y, the role is "listener" only.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Since emotion labels in EMPATHETICDIALOGUES are evenly-distributed, we set the prior distribution to be uniform.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://pytorch.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>We employ a popular NLG evaluation project available at https://github.com/Maluuba/nlg-eval.</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank all the reviewers for their insightful and valuable comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">PLATO: Pre-trained dialogue generation model with discrete latent variable</title>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.9</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K16-1002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>The 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="10" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling empathy and distress in reaction to news stories</title>
		<author>
			<persName><forename type="first">Sven</forename><surname>Buechel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anneke</forename><surname>Buffone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Slaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><surname>Sedoc</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1507</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4758" to="4765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Affect-driven dialog generation</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Witon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashutosh</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1374</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3734" to="3743" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DAL: Dual adversarial learning for dialogue generation</title>
		<author>
			<persName><forename type="first">Shaobo</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongzhong</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-2302</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation</title>
		<meeting>the Workshop on Methods for Optimizing and Evaluating Neural Language Generation<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The equivalence of weighted kappa and the intraclass correlation coefficient as measures of reliability</title>
		<author>
			<persName><forename type="first">L</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Fleiss</surname></persName>
		</author>
		<author>
			<persName><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="619" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dual learning for machine translation</title>
		<author>
			<persName><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05">2016. 2016. December 5-10, 2016</date>
			<biblScope unit="page" from="820" to="828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations, ICLR 2015</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07">2015. May 7-9, 2015</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Autoencoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations, ICLR 2014</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14">2014. April 14-16, 2014</date>
		</imprint>
	</monogr>
	<note>Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1014</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Em-pDG: Multi-resolution interactive empathetic dialogue generation</title>
		<author>
			<persName><forename type="first">Qintong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.394</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4454" to="4466" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">MoEL: Mixture of empathetic listeners</title>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamin</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1012</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Variational transformers for diverse response generation</title>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno>abs/2003.12738</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1230</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Towards fine-grained text sentiment transfer</title>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutong</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1194</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2013" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A dual reinforcement learning framework for unsupervised text style transfer</title>
		<author>
			<persName><forename type="first">Fuli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/711</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-10">2019. 2019. August 10-16, 2019</date>
			<biblScope unit="page" from="5116" to="5122" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">MIME: MIMicking emotions for empathetic response generation</title>
		<author>
			<persName><forename type="first">Navonil</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shanshan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiankun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.721</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8968" to="8979" />
		</imprint>
	</monogr>
	<note>Alexander Gelbukh, Rada Mihalcea, and Soujanya Poria</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The empathic companion: A character-based interface that addresses users&apos;affective states</title>
		<author>
			<persName><forename type="first">Helmut</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="267" to="285" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards empathetic opendomain conversation models: A new benchmark and dataset</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Boureau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1534</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5370" to="5381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning word ratings for empathy and distress from documentlevel user responses</title>
		<author>
			<persName><forename type="first">João</forename><surname>Sedoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Buechel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yehonathan</forename><surname>Nachmany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anneke</forename><surname>Buffone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1664" to="1673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017-02-04">2017. February 4-9, 2017</date>
			<biblScope unit="page" from="3295" to="3301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A computational approach to understanding empathy expressed in text-based mental health support</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Althoff</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5263" to="5276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">CDL: Curriculum dual learning for emotion-controllable response generation</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Feng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.52</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="556" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generating empathetic responses by looking ahead the user&apos;s sentiment</title>
		<author>
			<persName><forename type="first">Jamin</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP40776.2020.9054379</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020-05-04">2020. May 4-8, 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="7989" to="7993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generating responses with a specific emotion in dialog</title>
		<author>
			<persName><forename type="first">Zhenqiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1359</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3685" to="3695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Question answering and question generation as dual tasks</title>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno>abs/1706.02027</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dual latent variable model for low-resource natural language generation in dialogue systems</title>
		<author>
			<persName><forename type="first">Van-Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le-Minh</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K18-1003</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A generative model for joint natural language understanding and generation</title>
		<author>
			<persName><forename type="first">Bo-Hsiang</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yimai</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Vandyke</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.163</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1795" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">2017. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A neural conversational model</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1506.05869</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">Williams</forename><surname>Ronald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Is talking about an emotional experience helpful? effects on emotional recovery and perceived benefits</title>
		<author>
			<persName><forename type="first">Emmanuelle</forename><surname>Zech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Rimé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychology &amp; Psychotherapy: An International Journal of Theory &amp; Practice</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="270" to="287" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Reinforcing coherence for sequence to sequence model in dialogue generation</title>
		<author>
			<persName><forename type="first">Hainan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2018/635</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-13">2018. 2018. July 13-19, 2018</date>
			<biblScope unit="page" from="4567" to="4573" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Joint training for neural machine translation models with monolingual data</title>
		<author>
			<persName><forename type="first">Zhirui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans<address><addrLine>Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018-02-02">2018. February 2-7, 2018</date>
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised discrete sentence representation learning for interpretable neural dialog generation</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyusong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1101</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1098" to="1107" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rethinking action spaces for reinforcement learning in end-to-end dialog agents with latent variable models</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaige</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1123</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1208" to="1218" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Stylized dialogue response generation using stylized unpaired texts</title>
		<author>
			<persName><forename type="first">Yinhe</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zikai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongsheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shilei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoxi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang ; Zaixiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin-Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
		<idno>abs/2009.12719</idno>
	</analytic>
	<monogr>
		<title level="m">th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26">2020. 2020. April 26-30, 2020</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
	<note>Mirrorgenerative neural machine translation</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Care: Commonsense-aware emotional response generation with latent concepts</title>
		<author>
			<persName><forename type="first">Peixiang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
		<idno>abs/2012.08377</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018-02-02">2018. February 2-7, 2018</date>
			<biblScope unit="page" from="730" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mo-jiTalk: Generating emotional responses at scale</title>
		<author>
			<persName><forename type="first">Xianda</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1104</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1128" to="1137" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
