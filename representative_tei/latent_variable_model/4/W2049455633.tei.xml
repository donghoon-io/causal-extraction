<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Latent Semantic Models for Collaborative Filtering</title>
				<funder ref="#_H3yAVn6">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Latent Semantic Models for Collaborative Filtering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-information filtering; I.5.3 [Pattern Recognition]: Clustering-algorithms Collaborative filtering</term>
					<term>recommender systems</term>
					<term>machine learning</term>
					<term>mixture models</term>
					<term>latent semantic analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Collaborative filtering aims at learning predictive models of user preferences, interests or behavior from community data, that is, a database of available user preferences. In this article, we describe a new family of model-based algorithms designed for this task. These algorithms rely on a statistical modelling technique that introduces latent class variables in a mixture model setting to discover user communities and prototypical interest profiles. We investigate several variations to deal with discrete and continuous response variables as well as with different objective functions. The main advantages of this technique over standard memory-based methods are higher accuracy, constant time prediction, and an explicit and compact model representation. The latter can also be used to mine for user communitites. The experimental evaluation shows that substantial improvements in accucracy over existing methods and published results can be obtained.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Content-based filtering and retrieval builds on the fundamental assumption that users are able to formulate queries that express their interests or information needs in term of intrinsic features of the items sought. In some cases, however, it may be difficult to identify suitable descriptors such as keywords, topics, genres, etc. that can be used to accurately describe interests. Yet in other cases, for example, in electronic commerce, users may be unaware or at least inattentive of their interest. In both cases, one would like to predict user preferences and recommend items without requiring the user to explicitly formulate a query.</p><p>Collaborative filtering is a technology that is complementray to contentbased filtering and that aims at learning predictive models of user preferences, This work was sponsored by NSF-ITR grants, award numbers IIS-0085836 and IIS-0085940. Author's address: Department of Computer Science, Box 1910, Brown University, Providence, RI 02912. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 1515 Broadway, New York, NY 10036 USA, fax: +1 (212) 869-0481, or permissions@acm.org. C 2004 ACM 1046-8188/04/0100-0089 $5.00</p><p>• Thomas Hofmann interests or behavior from community data, that is, a database of available user preferences. Ideally, additional user input or interaction beyond the profile generated from previous interactions and observations is not necessary. Up to now, the dominant paradigm for performing collaborative filtering in recommender systems has been based on nearest neighbor regression or memory-based techniques. Virtually all first generation recommender systems have used the same fundamental two-step approach of first identifying users that are similar to some active user for which a recommendation has to be made, and then computing predictions and recommendations based on the preferences and judgments of these similar or like-minded users. The latter includes <ref type="bibr" target="#b10">[Goldberg et al. 1992</ref>], the GroupLens (and MovieLens) project <ref type="bibr" target="#b22">[Resnik et al. 1994;</ref><ref type="bibr" target="#b18">Konstan et al. 1997]</ref>, <ref type="bibr">Ringo [Shardanand and Maes 1995]</ref> as well as a number of commercial systems, most notably the systems deployed at Amazon.com and CDNow.com.</p><p>Memory-based methods have reached this level of popularity, because they are simple and intuitive on a conceptual level while avoiding the complications of a potentially expensive model-building stage. At the same time, they are deemed sufficient for many real-world problems. Yet there are a number of shortcomings, four of which we would like to point out here: (i) The accuracy obtained by memory-based methods may be suboptimal. Since recommendation accuracy is perhaps the most crucial factor from a user's perspective, improving accuracy is very important for most recommendation systems. (ii) Since no explicit statistical model is constructed, nothing is actually learned form the available user profiles and no general insight is gained. Hence, memory-based methods are only of limited use as data mining tools. (iii) Memory-based methods do not scale well in terms of their resource requirements (memory and computer time), unless further approximations-like subsampling-are made. (iv) It is difficult to systematically tailor memory-based algorithms to maximize the objective associated with a specfic task.</p><p>This article deals with a model-based approach that addresses the above shortcomings and (i) achieves higher prediction accuracies, (ii) compresses the data into a compact statistical model that automatically identifies user communities, (iii) enables to compute preference predictions in constant time, and (iv) gives the system designer more flexibility in specifing the objectives of the application.</p><p>Model-based techniques have been investigated before, most notably Bayesian and non-Bayesian clustering techniques <ref type="bibr" target="#b2">[Breese et al. 1998;</ref><ref type="bibr" target="#b25">Ungar and Foster 1998;</ref><ref type="bibr" target="#b0">Basu et al. 1998;</ref><ref type="bibr" target="#b4">Chien and George 1999]</ref>, Bayesian networks <ref type="bibr" target="#b2">[Breese et al. 1998</ref>], and dependency networks <ref type="bibr" target="#b12">[Heckerman et al. 2000</ref>]. The approach proposed in this paper is a generalization of a statistical technique called probabilistic Latent Semantic Analysis (pLSA) <ref type="bibr">[Hofmann 2001a</ref>] which was originally developped in the context of information retrieval <ref type="bibr" target="#b14">[Hofmann 1999</ref>]. It bears some similarity with clustering methods such as distributional clustering <ref type="bibr" target="#b21">[Pereira et al. 1993]</ref> in that latent variables for user communities are introduced, yet the communities can be overlapping and users are not partitioned into groups, not even probabilistically (cf. <ref type="bibr" target="#b17">Hofmann and Puzicha [1999]</ref>). In fact, the probabilistic latent semantic models are in many ways closer related to dimension reduction methods and matrix decomposition techniques such as Singular Value Decomposition (SVD) and Principal Component Analysis (PCA), which have been applied in information retrieval <ref type="bibr" target="#b6">[Deerwester et al. 1990</ref>] as well as in the context of recommender systems <ref type="bibr" target="#b23">[Sarwar et al. 2000;</ref><ref type="bibr" target="#b11">Goldberg et al. 2001;</ref><ref type="bibr" target="#b3">Canny 2002]</ref>.</p><p>The main difference between our work and Bayesian or dependency networks is the fact that the latter learn a dependency structure directly on the observables, while our approach is based on a latent cause model that introduces the notion of user communities or groups of items. The main difference compared to PCA and SVD-based dimension reduction methods is that pLSA offers a probabilistic semantics and can build on statistical techniques for inference and model selection. However, our approach shares with all of the above techniques the assumption that predictions are computed in a "user-centric" view, whereas some more recent work has investigated item-based recommendation methods <ref type="bibr" target="#b24">[Sarwar et al. 2001</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MODEL-BASED COLLABORATIVE FILTERING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Implicit and Explicit Ratings</head><p>The domains we consider consist of a set of persons or users U = {u 1 , . . . , u n }, a set of items Y = { y 1 , . . . , y m } and a set of possible ratings V. We assume observations are available for person/object pairs (u, y), where u ∈ U and y ∈ Y. In the most basic case, an observation will just be the co-occurrence of u and y, representing events like "person u buys product y" or "person u clicks on link y", which is also sometimes called implicit preference data. Other cases may also provide an explicit rating v ∈ V as part of an observation. In the simplest case, this will be a binary response variable v ∈ {-1, 1}, modeling events like "person x likes/dislikes object y". In general, V may be discrete or continuous, equipped with an ordinal or numerical (absolute) scale. For example, a five-or six-star rating scale as commonly used in movie recommendation systems such as MovieLens or EachMovie.</p><p>Rating data can be concisely summarized in table format as a n by m matrix A, where each row will correspond to a user and each column to an item. In the case of implicit ratings, each entry a ij represents a count variable of how often user u i has selected item item y j or, more generally, how many pairs (u i , y j ) have been observed. In the case of explicit ratings, each entry a ij ∈ V ∪ {∅} will either correspond to a rating, a ij ∈ V or will be unobserved, a ij = ∅. Notice that the data matrix A will typically be sparse in the sense that only a small fraction of pairs (u, y) are actually ever observed. Hence, the vast majority of entries a ij will be 0 (implicit ratings) or ∅ (explicit ratings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prediction Problems</head><p>We will consider two type of prediction problems. The first setting that we call forced prediction involves predicting a preference value for a particular item given the identity of the user, that is, one would like to learn a mapping g : U × Y → V. More generally, one may be interested in the conditional probability P (v|u, y) that user u will rate item y with v. Based on the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thomas Hofmann</head><p>conditional probability one may also define a deterministic prediction function by g (u, y) = arg max v P (v|u, y). If v possesses a numerical scale, then it is more appropriate to define g via the expected rating, g (u, y) = v∈V vP <ref type="bibr">(v|u, y)</ref> or g (u, y) = V v P(v|u, y) dv. <ref type="foot" target="#foot_2">1</ref> We call this setting forced prediction, because it mimics an experimental setup in which a user response is solicited for a particular item and the user has no choice on which item to vote. This is the relevant prediction mode in scenarios in which an item is presented to a user as a recommendation and one is interested in anticipating the user's response.</p><p>In the second setting, which we call free prediction, the item selection process is part of the predictive model and the goal is to learn probabilities P (v, y|u) in order to predict both, the selected item y and (optionally) the associated rating v. By virtue of the chain rule, this can be rewritten as P (v, y|u) = P (v| y, u)P ( y|u), thus decomposing the problem into the prediction of the selected item (irrespective of the rating) and a prediction of the rating conditioned on the (hypothetically) selected item. This mimics a scenario in which the user is free to select an item of her or his choice and-in the case of explicit ratings-also provides a rating for it. The free prediction case is a generalization of what is commonly referred to as the "recommend" task. i.e. selecting a set of items to present to the user.</p><p>In the forced prediction case, the user is presented with a particular item and provides a rating for it. Here the selection of the item on which a user vote or response is solicitated is part of the experimental design. In the free prediction case, the user is in control of the item selection and one is interested in prediciting both, what a user will select and (optionally) how s/he will rate the item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Loss and Risk Functions</head><p>Since we are pursuing a model-based approach to collaborative filtering, we will assume the availability of an adequate loss function. A loss function L is a function that quantifies how good or bad the predicition of a model is compared to a true outcome. We will denote the (parameterized) model space by H and use a generic parameter θ to refer to a particular model in H. Then, a loss function can be formally defined as a function L : X × H → where X = U × V × Y. Here V is treated as void in the case of implicit ratings. Hence, for a given observation (u, v, y), a loss function L will assign a score to every hypothesis θ under consideration. The smaller L <ref type="bibr">((u, v, y)</ref>, θ ), the more compatible θ is believed to be with the observation.</p><p>In statistical inference, one often uses the (log-)likelihood as a criterion corresponding to a (negative) logarithmic loss</p><formula xml:id="formula_0">L lg1 ((u, v, y), θ ) = -log P (v|u, y; θ), or L lg2 ((u, v, y), θ ) = -log P (v, y|u; θ). (1)</formula><p>The first loss function in Eq. ( <ref type="formula">1</ref>) is appropriate for the forced prediction scenario, since it conditions on the selected item y, while the second one corresponds to the free prediction mode in which y is part of the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latent Semantic Models for Collaborative Filtering</head><p>• 93 Another popular choice for the case of discrete response variables and for models that make deterministic predictions is the zero-one loss,</p><formula xml:id="formula_1">L zo ((u, v, y), θ) = 1 -[[v = g (u, y; θ )]],<label>(2)</label></formula><p>where <ref type="bibr">[[•]</ref>] denotes the indicator function of the enclosed predicate. If the prediction is correct, no loss is incurred, otherwise the loss is one. This loss function is also commonly used in supervised classification or pattern recognition. It can be generalized to the case of probabilistic models where one may define a loss via the probability of making an incorrect prediction, that is, the probability of error</p><formula xml:id="formula_2">L pe ((u, v, y), θ) = v =v P (v |u, y; θ ) = 1 -P (v|u, y; θ )<label>(3)</label></formula><p>The logarithmic loss provides an upper bound on the probability of error, since</p><formula xml:id="formula_3">L pe ((u, y, v), θ ) = 1 -P (v|u, y; θ) ≤ 1 -log P (v|u, y; θ) = 1 + L lg1 ((u, y, v), θ ). (<label>4</label></formula><formula xml:id="formula_4">)</formula><p>The zero-one loss is sometimes difficult to optimize directly, because it is a non-differentiable function of θ , in which case the use of the logarithmic loss can be advantageous for computational reasons. In fact, in this article, we focus exclusively on the use of logarithmic loss functions, which can be optimized (in approximation) with the well-known Expectation-Maximization (EM) algorithm for the proposed latent class models. For numeric response variables, it is more common to use a metric-based loss function, for example, the absolute loss</p><formula xml:id="formula_5">L abs ((u, v, y), θ ) = |v -g (u, y; θ )| (5)</formula><p>or the squared loss</p><formula xml:id="formula_6">L sqr ((u, v, y), θ ) = (v -g (u, y; θ )) 2 . (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>These loss functions have been used extensively for evaluating the accuracy of collaborative filtering methods, in particular memory-based methods, and we will also use them in our experiments. For completeness, we would like to mention the RankBoost method <ref type="bibr" target="#b9">[Freund et al. 1998</ref>] which aims at minimizing an upper bound on the ranking loss. The latter uses a purely ordinal scale for the ratings and can be defined via the number of misordered item pairs. A loss function scores models based on a single observation; however, we need to specify how to combine data consisting of several observations. Put differently, we need a sampling model to specify under which distribution P (u, v, y) we would like to minimize the loss. This is usually called a risk function or functional, R(θ) ≡ u,v, y P (u, v, y)L <ref type="bibr">((u, v, y)</ref>; θ ), where part of the sum has to be replaced by an integral in the case of continuous response variables v. A typical choice is to minimize the empirical loss, that is,</p><formula xml:id="formula_8">R emp (θ ) = 1 N u,v, y L((u, v, y), θ), (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>where angular brackets under a summation symbol are used as a shorthand notation to refer to all observation triplets and N denotes the total number of observed triplets. However, in collaborative filtering, it is a conceivable alternative to give the same weight to every user, irrespective of the number of implicit or explicit ratings available for that user. If we denote by n u the number of observation triplets for user u, then this would correspond to the normalized empirical risk function</p><formula xml:id="formula_10">Remp (θ ) = 1 n u L u (θ), L u (θ) = 1 n u u ,v, y :u =u L((u, v, y), θ ). (<label>8</label></formula><formula xml:id="formula_11">)</formula><p>The choice of a normalized vs. nonnormalized risk function depends on the application. If we assume that users for which more data is available are more important, in the sense that it is more likely that we will have to make predictions for them again, then the unnormalized risk function in Eq. ( <ref type="formula" target="#formula_8">7</ref>) may be more appropriate. Notice also that Remp may put a lot of weight on individual observations, just because the data for some users may be sparse. Hence, we expect the normalized risk function to be more susceptible to overfitting, which has turned out to be disadvantageous in our experiments (cf. Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CO-OCCURRENCE LATENT SEMANTIC MODEL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Definition</head><p>We would like to discuss a simple model for co-occurrence data first, which is known as probabilistic latent semantic analysis (pLSA) <ref type="bibr">[Hofmann 2001a;</ref><ref type="bibr" target="#b14">Hofmann 1999</ref>]. This can be thought of as a special case of collaborative filtering with implicit preference data <ref type="bibr" target="#b17">[Hofmann and Puzicha 1999]</ref>. The data thus consists of a set of user-item pairs (u, y) which are assumed to be generated independently. The key idea of our approach is to introduce hidden variables Z with states z for every user-item pair, so that user u and item y are rendered conditionally independent. The possible set of states z is assumed to be finite and of size k. The resulting model is a mixture model that can be written in the following way</p><formula xml:id="formula_12">P (u, y; θ ) = z P (u, y, z) = z P ( y|z)P (z|u)P (u),<label>(9)</label></formula><p>where sums over z run over all possible k states. By applying Bayes' rule, one can alternatively use the equivalent parameterizations P (u, y; θ ) = z P (z)P (u|z)P ( y|z) and P (u, y; θ ) = z P (u|z)P (z| y)P ( y). Since the more typical situation in collaborative filtering is to make personalized, that is, userspecific recommendations, we will mainly work with the conditional model</p><formula xml:id="formula_13">P ( y|u; θ ) = z P ( y|z)P (z|u). (<label>10</label></formula><formula xml:id="formula_14">)</formula><p>In this model, the parameter vector θ summarizes the probabilities P (z|u) which can be described by (k -1) × n independent parameters as well as P ( y|z) which requires (m -1) × k independent parameters, where again k denotes the number of possible states of the hidden variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latent Semantic Models for Collaborative Filtering</head><p>• 95</p><p>Notice that if k = 1, then the model simply assumes that the selection of an item y does not depend on the identity of the user, P ( y|u) = P ( y), resulting in non-personalized predictions. The user identity and the item identity are assumed to be marginally independent in this case. As the number of hidden states increases, the set of representable joint distribution over user-item pairs becomes less and less constrained until a fully saturated model is obtained, which can represent any probability mass function over user-item pairs. In practice, k has to be chosen in a way that adjusts model complexity in the light of the amount and sparseness of available data. Standard model selection techniques like cross-validation are available to that extend.</p><p>While we have not associated any a priori meaning with the states of the hidden variables, the hope though is to recover interesting structure in the data about user communities and groups of related items. Intuitively, the state z of a hidden variable Z associated with an observation (u, y) is supposed to model a hidden cause, that is, the fact that a person u selects item y "because of " z. Each z is intended to offer a hypothetical explanation for an implicit rating that is itself not directly observable. Since the number of possible states k is typically much smaller than the number of items and users, the model encourages to group users into user communities and items into groups of related items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Expectation Maximization Algorithm</head><p>Following the maximum likelihood approach to statistical inference, we propose to fit the model parameters θ by maximizing the (conditional) log-likelihood, or equivalently, by minimizing the empirical logarithmic loss</p><formula xml:id="formula_15">R(θ ) = - 1 N u, y log P ( y|u; θ ) = - 1 N n i=1 m j =1 a ij log P ( y j |u i ; θ ) (11)</formula><p>where a ij counts the number of times each pair (u i , y j ) has been observed. Notice that for user-items pairs that have never been observed one gets a ij = 0 and hence the number of terms in the double sum in Eq. ( <ref type="formula">11</ref>) depends on the number of nonzero entries in the data matrix A which is upper bounded by N and which can be far less than n × m. The Expectation Maximization (EM) algorithm <ref type="bibr" target="#b7">[Dempster et al. 1977</ref>] is a standard method for statistical inference that can be used to (approximately) maximize the log-likelihood in mixture models like pLSA <ref type="bibr">[Hofmann 2001a</ref>]. The first step in deriving an EM algorithm is to specify a complete data model. A complete data model treats the hidden variables as if they were actually observed, which in our case amounts to the assumption that for every observed pair (u, y), we would in fact observe a triplet (u, y, z). The complete data model corresponding to Eq. ( <ref type="formula" target="#formula_13">10</ref>) is given by P ( y, z|u) = P ( y|z)P (z|u) and the corresponding (negative) log-likelihood function can be written as</p><formula xml:id="formula_16">R c (θ ) = - 1 N u, y,z log P ( y|z) + log P (z|u) . (<label>12</label></formula><formula xml:id="formula_17">)</formula><p>Since the states of the latent variables are not known, we introduce a so-called variational probability distribution Q(z; u, y) <ref type="bibr" target="#b20">[Neal and Hinton 1998</ref>] for every • Thomas Hofmann observed user item pair. Intuitively, the Q distribution will model our best knowledge about the states of the latent variables given the current parameters.</p><p>If we identify the latter with user communities, then Q(z; u, y) will denote the probability that the co-occurrence of (u, y), that is, the selection of item y by user u, will be attributed to the fact that u is a member of community z.</p><p>Using Q one can define a family of risk functions (one risk function for every choice of Q)</p><formula xml:id="formula_18">R(θ, Q) = - 1 N u, y z Q(z; u, y) log P ( y|z) + log P (z|u) . (<label>13</label></formula><formula xml:id="formula_19">)</formula><p>Exploiting the concavity of the logarithm and using Jensen's inequality (cf. <ref type="bibr" target="#b5">Cover and Thomas [1991]</ref>), it can be shown that every R(•, Q) defines an upper bound on R(•) (up to a constant that only depends on Q),</p><formula xml:id="formula_20">R(θ ) = - 1 N u, y log z Q(z; u, y) P ( y|z)P (z|u) Q(z; u, y) (14a) ≤ - 1 N u, y z Q(z; u, y) log P ( y|z)P (z|u) Q(z; u, y) (14b) = R(θ, Q) - 1 N u, y H(Q(•; u, y)) ,<label>(14c)</label></formula><p>where H(Q) refers to the entropy of a probability distribution Q.</p><p>The EM algorithm now consists of two steps that are performed in alternation: (i) computing the tightest bound for given parameters θ and (ii) optimizing this bound with respect to θ . The first step consists of minimizing Eq. (14c) with respect to the variational distribution Q. This is called the E-step and amounts to computing the posterior probabilities of the hidden variables. Thus, for given parameters θ , the optimal Q-denoted by Q * -is given by Q * (z; u, y; θ) = P (z|u, y; θ ) = P ( y|z) P (z|u)</p><formula xml:id="formula_21">z P ( y|z ) P (z |u) . (<label>15</label></formula><formula xml:id="formula_22">)</formula><p>A formal derivation using the technique of Lagrange multipliers is included in the appendix. The hat on probabilities in Eq. ( <ref type="formula" target="#formula_21">15</ref>) denotes quantities parameterized by θ. Obviously, the posterior probabilities need only to be computed for user-item pairs (u, y) that have actually been observed. Averaging R c with respect to the posterior distribution calculated from Eq. ( <ref type="formula" target="#formula_21">15</ref>) then yields the following upper bound on the negative log-likelihood function </p><formula xml:id="formula_23">R(θ, θ) ≡ R(θ, Q * ) = - 1 N u, y z Q * (z; u, y, θ ) log P ( y|z) + log P (z|u) (16a) = - 1 N u,</formula><formula xml:id="formula_24">P ( y|z) = u, y : y = y Q * (z; u, y, θ) u, y Q * (z; u, y, θ )<label>(17a)</label></formula><formula xml:id="formula_25">P (z|u) = u , y :u =u Q * (z; u, y, θ ) z u , y :u =u Q * (z ; u, y, θ ) = u , y :u =u Q * (z; u, y, θ ) |{ u , y : u = u}| . (<label>17b</label></formula><formula xml:id="formula_26">)</formula><p>The complete EM algorithm now proceeds by alternating the E-step in Eq. ( <ref type="formula" target="#formula_21">15</ref>) with the M-step in Eq. ( <ref type="formula" target="#formula_24">17</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Regularized Risk Functions</head><p>Learning statistical models with many parameters from a limited amount of data bears the risk of overfitting. Traditional model selection techniques would fit models by maximum likelihood and then determine the generalization performance of the model either analytically (typically in an asymptotic approximation) or via empirical evaluation using hold-out data or cross-validation.</p><p>As an alternative approach we have proposed a technique called tempered EM <ref type="bibr">[Hofmann 2001a</ref>] which minimizes a regularized risk function instead of the empirical risk (i.e. the negative log-likelihood in the case of maximum likelihood estimation). Formally, a β-parameterized family of regularized risk functions can be obtained by generalizing the upper bound in Eq. ( <ref type="formula" target="#formula_20">14c</ref>)</p><formula xml:id="formula_27">Rβ (θ, Q) ≡ R(θ, Q) - 1 β u, y H(Q(•; u, y)) (<label>18</label></formula><formula xml:id="formula_28">)</formula><p>Notice that for β = 1 this reduces to maximum likelihood estimation via EM.</p><p>For β &lt; 1 more weight is put on the entropy of Q which avoids "over-confidence" in computing the posterior probabilities as can be seen from the solution of the generalized E-step (cf. appendix)</p><formula xml:id="formula_29">Q * (z; u, y, θ ) ∝ P (z|u) P ( y|z) β . (<label>19</label></formula><formula xml:id="formula_30">)</formula><p>As a result, the optimal Q-distributions will be more smeared-out or fuzzy which counteracts overfitting as we will demonstrate in the experiments. Similar "tricks" have been used in speech recognition and other applications involving high-dimensional statistical models, in particular to compensate for simplifying assumptions about statistical independence. Notice that one of the advantages of tempered EM is the fact that the M-step is unaffected by the choice of β, hence one only has to modify the E-step.</p><p>A more rigorous framework is offered by the framework of Bayesian learning. As has been proposed in <ref type="bibr" target="#b1">Blei et al. [2002]</ref> one can put Dirichlet priors on the multinomial distributions P (z|u) and integrate them out, resulting in a model that has been called latent Dirichlet allocation (LDA) model. However, inference is significantly harder in this setting and further approximation are necessary to derive a tractable algorithm <ref type="bibr" target="#b1">[Blei et al. 2002;</ref><ref type="bibr" target="#b19">Minka and Lafferty 2002]</ref>.</p><p>• Thomas Hofmann</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Mixture Models, Clustering, and Dimension Reduction</head><p>It is important not to confuse the pLSA model with probabilistic or Bayesian clustering models <ref type="bibr" target="#b2">[Breese et al. 1998;</ref><ref type="bibr" target="#b4">Chien and George 1999]</ref> in which it is assumed that each user belongs to exactly one user group. In a standard user clustering model, one introduces a single latent cluster membership variable for every user u, while the pLSA model associates a latent variable with every observation triplet (u, v, y). Hence, different ratings of the same user can be explained by different latent causes in pLSA, whereas a user clustering model assumes that all ratings involving the same user are linked to the same underlying community. This can be stated more formally by computing and comparing the probability of a set of observations involving a particular user. The clustering model yields the following probability for the ratings of a fixed user u P ((v 1 , y 1 ), . . . , (v l , y l ))</p><formula xml:id="formula_31">= z P (z) i P (v i , y i |z) . (<label>20</label></formula><formula xml:id="formula_32">)</formula><p>In contrast, in the pLSA model each user is characterized by a distribution P (z|u) and one gets a user-specific expression</p><formula xml:id="formula_33">P u ((v 1 , y 1 ), . . . , (v l , y l )) = i z P (z|u)P (v i , y i |z) . (<label>21</label></formula><formula xml:id="formula_34">)</formula><p>By integrating out the mixture proportions P (z|u) in a Bayesian manner, one can also define a generative model that does not have any reference to a specific user,</p><formula xml:id="formula_35">P ((v 1 , y 1 ), . . . , (v l , y l )) = i z θ z P (v i , y i |z) p(θ) d θ. (<label>22</label></formula><formula xml:id="formula_36">)</formula><p>Here, θ z with θ z ≥ 0 and z θ z = 1 takes the role of a latent parameter, which is averaged over using a prior probability density function p(θ ). If the latter is chosen to be a Dirichlet distribution, one gets the LDA model of <ref type="bibr" target="#b1">Blei et al. [2002]</ref>. In this article, we have focused on maximum likelihood estimation of P (z|u), because statistical inference turns out to be significantly easier than in the fully Bayesian model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">LATENT SEMANTIC MODELS WITH RATINGS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Definition and Dependency Structures</head><p>Since many applications of collaborative filtering involve explicit user ratings, the pLSA model needs to be extended appropriately. We will focus first on the case, where ratings are predicted for fixed items (forced prediction). There are two different ways to augment the pLSA model with an additional random variable v for explicit ratings, as shown in Figures <ref type="figure" target="#fig_0">1(e</ref>) and 1(f). The predicted rating will depend on the latent variable z and it will either depend directly on the item (variant (e)) or the user (variant (f)). The augmented pLSA model is hence no longer symmetric in the sense that both types of entities, users and items, are treated differently. We call the first variant the community version, since the user only influences the prediction mediated by z, but not directly.</p><p>Correspondingly, the second variant will be called the categorized version, since items only impact the prediction through z which is supposed to model item categories or types. Similarly, two models can be derived for the free prediction mode. They are depicted in Figures <ref type="figure" target="#fig_0">1(c</ref>) and 1(d). The model in Figure <ref type="figure" target="#fig_0">1</ref>(b) is too restrictive to be useful for collaborative filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Class Conditional Distributions</head><p>The proposed model has two ingredients, mixture coefficients-which in the community variant correspond to probabilities P (z|u)-and class-conditional probability distributions P (v| y, z). While the variables u and y are naturally assumed to be categorical, one of the key questions is how to take possible scales of the response variable v into account and how to parameterize the class-conditional distributions. In what follows, we will for concreteness focus on the community model, but the same argumentation applies to the categorized model variant.</p><p>If v is itself a categorical variable, for example, only taking binary values, v ∈ {-1, 1}, then one can simply introduce success probability parameters π y,z ∈ [0; 1] and define P (v| y, z) ≡ π y,z . More generally, one can parameterize the conditional probability for categorical variables in the following manner (cf. <ref type="bibr">Hofmann [2001b]</ref>)</p><formula xml:id="formula_37">P (v| y, z) = π v y,z , where v∈V π v y,z = 1 . (<label>23</label></formula><formula xml:id="formula_38">)</formula><p>In working with numerical (absolute) scales, we propose to introduce a location parameter µ y,z ∈ and a scale parameter σ y,z ∈ + for every community z and every item y which defines a Gaussian mixture model with user-specific mixing weights</p><formula xml:id="formula_39">P (v|u, y) = z P (z|u) P (v; µ y,z , σ y,z ), (<label>24a</label></formula><formula xml:id="formula_40">) P (v; µ, σ ) = 1 √ 2πσ exp - (v -µ) 2 2σ 2 . (<label>24b</label></formula><formula xml:id="formula_41">)</formula><p>The assumption is that within each community the rating for each item possesses a typical value µ y,z , but that the observed ratings for individual users are noisy versions corrupted by normally distributed noise with variance σ 2 y,z .</p><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thomas Hofmann</head><p>Finally, notice that the expected response can be computed as</p><formula xml:id="formula_42">E[v|u, y] = V v P(v|u, y) dv = z P (z|u) V v P(v| y, z) dv = z P (z|u)µ y,z . (<label>25</label></formula><formula xml:id="formula_43">)</formula><p>It may be helpful to point out that Eq. ( <ref type="formula" target="#formula_39">24</ref>) reduces to a standard Gaussian mixture model, in the degenerate case of a single user. In general, mixture proportions are user-specific though and the Gaussian pLSA model is very different from a standard Gaussian mixture model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">User Normalization</head><p>The models presented so far assume that all users express their ratings on a common scale. However, it is known that different users may associate subjectively different meanings with ratings and, for instance, a five-star rating may mean different things for different people. In memory-based methods, this is taken into account by similarity measures such as the Pearson or Spearman correlation coefficient <ref type="bibr" target="#b13">[Herlocker et al. 1999</ref>]. One way to accommodate this in model-based approaches with numerical ratings is to normalize the raw user ratings appropriately. To that extend, we propose to transform ratings by (i) subtracting the user-specific mean rating µ u and by (ii) normalizing the variance of ratings for each user to one. The first step accounts for individual differences in the overall "enthusiasm" of users and calibrates what should be considered as the neutral vote for every user. The second step makes the ratings more comparable across users by adjusting their dynamic range. Formally, this is accomplished by performing the user-specific transformation of ratings</p><formula xml:id="formula_44">(u, v, y) → (u, v , y), with v = v -µ u σ u (26)</formula><p>and where</p><formula xml:id="formula_45">µ u = E[v|u], σ 2 u = E (v -µ u ) 2 |u . (<label>27</label></formula><formula xml:id="formula_46">)</formula><p>For users with a small number of ratings, one has to be careful to perform appropriate smoothing in estimating the standard deviations (and to a lesser extend the means), since the empirical estimates derived from sample averages may be very unreliable due to sampling noise. We have thus used the following scheme to smooth the estimates of the variances,</p><formula xml:id="formula_47">σ 2 u = u,v, y (v -µ u ) 2 + q σ 2 n u + q , (<label>28</label></formula><formula xml:id="formula_48">)</formula><p>where σ 2 denotes the overall variance of ratings, n u is the number of ratings available for user u and q is a free parameter controlling the smoothing strength (set to q = 5 in our experiments). </p><formula xml:id="formula_49">. (<label>30</label></formula><formula xml:id="formula_50">)</formula><p>The resulting M-step equations are Eq. ( <ref type="formula" target="#formula_24">17</ref>) and</p><formula xml:id="formula_51">P (v| y, z) ∝ u,v , y : v =v, y = y Q * (z; u, v, y, θ) . (<label>31</label></formula><formula xml:id="formula_52">)</formula><p>The details of the derivation can be found in the appendix. Comparing these equations with the standard pLSA equations in Section 3 shows little differences on a qualitative level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Maximum Likelihood Estimation: Continuous Case</head><p>In the continuous case with Gaussian distributions, both the E-step and M-step need to be modified. The E-step equation can be obtained by replacing P (v| y, z) with a Gaussian probability density function P (v; µ y,z , σ y,z ). The M-step update equations can be obtained by differentiating Eq. ( <ref type="formula">16</ref>) with respect to the parameters µ y,z and σ 2 µ,z (cf. appendix) which results in</p><formula xml:id="formula_53">µ y,z = u,v, y : y = y v Q * (z; u, v, y, θ) u,v, y : y = y Q * (z; u, v, y, θ ) (32a) σ 2 y,z = u,v, y : y = y (v -µ y,z ) 2 Q * (z; u, v, y, θ) u,v, y : y = y Q * (z; u, v, y, θ) . (<label>32b</label></formula><formula xml:id="formula_54">)</formula><p>These are essentially the standard M-step equations of a Gaussian mixture model. The fact that mixing proportions are user-specific only enters in the computation of the posterior probabilities in the E-step. On an intuitive level, the community means µ y,z and variances σ 2 y,z are obtained by averaging over votes available for item y. The relative weight of the vote cast by user u though depends on the posterior probability of the latent "community" variable z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Computational Complexity</head><p>The amount of data available in many practical applications of recommender systems can be enormous and the scalability of collaborative filtering • Thomas Hofmann algorithms is a crucial factor for a successful system deployment. One has to distinguish between the offline and online computational complexity of an algorithm. The former accounts for computations that can be performed beforehand, that is, before actual predictions or recommendations for specific users have to be made. The latter deals with those computations that can only be performed in real-time during the interaction with a specific user, either because it is intractable to precompute all possible predictions or recommendations in advance, or because user profiles are changing dynamically in the course of an on-line session. 4.6.1 Offline Complexity. Analyzing the offline complexity of proposed EM algorithm requires first of all to calculate the complexity of the E-step and M-step respectively. In the E-step, one needs to compute the optimal variational probability Q * for each of the N observed user ratings. Each such Q * consists of k numbers and requires a constant number of arithmetic operations to be computed, resulting in O(k • N ) operations for a single E-step. In the M-step, the posterior probabilities for each rating are accumulated to form the new estimates for P (z|u), P (v| y, z) and (in the free prediction model) P ( y|z). Notice that each Q * (z; u, v, y) is added to the accumulators for exactly one P (z|u) and P ( y|z) as well as one of the accumulators for P (v| y, z) (multinomial model) or µ y,z and σ 2 y,z (Gaussian model). Thus, the M-step also requires O(k • N ) operations. Typical values of k in our experiments have been in the range between 20 and 200. As far as memory requirements are concerned, we would like to point out that the E-steps and M-steps can be interleaved so that at any point we need to store the old value of the parameters, summarized in θ , as well as the same number of accumulator variables which are used internally to compute the new estimate of θ.</p><p>The number of EM-iterations that need to be performed cannot be easily estimated a priori, since it depends on properties of the specific data set. In the experiments, we have found that between 30-100 iterations are usually sufficient. 4.6.2 Online Complexity. More important for many applications is the online complexity of computing predictions in a dynamic environment. First of all, let us analyze the computational effort for computing a prediction g (u, y), focusing on the Gaussian pLSA case for concreteness. From Eq. ( <ref type="formula" target="#formula_42">25</ref>), we have that g (u, y) = z P (z|u)µ y,z . Since µ y,z and P (z|u) are assumed to be explicitly available as part of the statistical model, this requires 2k arithmetic operations. Moreover, since the number of communities k does not depend on the number of users n nor the number of items m, this amounts to a constant time prediction algorithm which has a computational complexity of O(k).</p><p>For new users u, we also have to compute P (z|u) in the first place. Similarly, if additional ratings for user u become available, we would like to update the parameters P (z|u) accordingly. We propose to ignore the effect on the communityspecific parameters, since we expect the notion of a community to change on a much smaller time-scale. These changes can be taken into account by regular offline incremental EM updates or model retraining. From Eq. (17b), one sees that computing P (z|u) only involves posterior probabilities P (v|u, y) for ratings of the same user u. Hence we propose to perform a limited EM iteration in which the E-step computes the posterior probabilities for all n u ratings of the active user, which can be done in O(n u • k) operations and the M-step updates are restricted to the P (z|u) parameters, which can also be carried out in time O(n u • k). This operation has also been called fold-in <ref type="bibr">[Hofmann 2001a</ref>]. Typically, 20-40 restricted EM iterations are sufficient to compute P (z|u). Notice that the computational complexity is independent of the number of users and items, but depends on the number of items that have been rated by the active user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Set</head><p>The data we have used in our experiments is the EachMovie data set <ref type="bibr">[EachMovie ]</ref>. The data has been collected by Digital Equipment Research Center from 1995 through 1997. There are 1,623 items (movies) in this data set and 61,265 user profiles with a total of over 2.1 million ratings. Consequently, the average number of ratings per user is about 35. The rating scale is discrete, taking values from 0 (no star) to 5 (five stars),<ref type="foot" target="#foot_5">foot_5</ref> with 5 being the highest rating and 0 being the lowest rating. The average rating over all observed votes is ≈ 3.03 and the overall rating variance is ≈ 1.48.</p><p>The EachMovie data set is to our knowledge the largest publicly available data set for collaborative filtering and possesses the advantage of offering explicit user ratings. The latter fact allows us to study both, item selection and rating prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metric</head><p>A thorough empirical analysis of collaborative filtering algorithms has been presented in <ref type="bibr" target="#b2">Breese et al. [1998]</ref> and we have adapted most of the proposed evaluation metrics. The effectiveness of collaborative filtering techniques can be measured in various ways dependent on how the recommender system is used and how results are presented to the user.</p><p>The first setting we have investigated assumes that the goal of the system is to predict user ratings. Hence, we assume that an item y is presented to a user u and the goal is to predict the rating v = g (u, y). We have used two loss functions to measure the deviation between the predicted rating v and the observed rating v: the absolute deviation |v -v| and the squared error (vv) 2 . Empirical risks based on these loss functions are summarized as the mean absolute error (MAE) and the rooted mean square (RMS) error. In addition we have also measured the zero-one loss, in which case the predictions have been quantized by rounding v to the closest integer.</p><p>In the second setting, the goal is to predict both, the selected item and the corresponding rating. Here we have used the score for ranked lists proposed  <ref type="bibr" target="#b2">[Breese et al. 1998]</ref> 0.994 -----BC <ref type="bibr" target="#b2">[Breese et al. 1998]</ref> 1.103 -----BN <ref type="bibr" target="#b2">[Breese et al. 1998]</ref> 1.066 -----</p><p>As far as different sampling models for the ratings are concerned, one can make the following observations: First of all, the multinomial sampling model is quite competitive, yielding an improvement over the correlation-based method for all three loss functions and achieving the best overall performance for the zero-one loss. Second, the Gaussian model without user-specific normalization does much worse and is clearly not competitive. Third, performing the userspecific scale transformation in the Gaussian rating model leads to a substantial gain in prediction accuracy, yielding the best achieved results with respect to MAE and RMS error. It is also quite remarkable that this result is obtained with a model involving a much smaller number of communities (k = 40) compared to the multinomial model (k = 200). We conclude from this that the assumption of user-specific rating scales encodes useful prior knowledge.</p><p>As can be seen, the proposed Gaussian pLSA outperforms the memory-based method in terms of MAE and achieves a relative accuracy gain over the baseline of 17.8% as opposed to 12.9% for the Pearson correlation. This corresponds to a relative performance gain of approximately 6% when taking the Pearson correlation method as the baseline. In absolute terms, the MAE difference between the memory-based method based on the Pearson correlation coefficient and the normalized Gaussian pLSA model with k = 40 has a mean of 0.053 and a standard deviation of 0.0036. This is statistically highly significant, for example, using a paired t-test on the differences this corresponds to a t-value of ≈50, which means that Gaussian pLSA outperforms the Pearson correlation method with confidence approaching certainty.</p><p>Notice that the results are overall better than the results published in <ref type="bibr" target="#b2">Breese et al. [1998]</ref>. With respect to the latter results one has to acknowledge a somewhat different setup though, which has lead to overall better performance results in our experiments. However, an approximate comparison seems to be possible by identifying our implementation of a correlation-based filtering method with the one implemented in <ref type="bibr" target="#b2">Breese et al. [1998]</ref>.</p><p>We have further investigated the effect of M on the prediction accuracy obtained by the correlation-based method and the Gaussian pLSA approach. It has to be expected that the prediction accuracy improves with growing M for all methods, since predictions should be more reliable for users for which a larger number of ratings is available. Figure <ref type="figure">2</ref> shows the result in terms of MAE for M = 2, <ref type="bibr">5,</ref><ref type="bibr">10,</ref><ref type="bibr">20,</ref><ref type="bibr">50,</ref><ref type="bibr">100,</ref><ref type="bibr">200</ref>. It shows that the relative advantage of pLSA over  the correlation-based method increases for larger M . Gaussian pLSA seems to be capable of using additional ratings more effectively in order to improve the average prediction accuracy, whereas the correlation-based methods shows only a small improvement for larger M compared to the M = 2 case. At M = 200 the relative improvement of Gaussian pLSA over the correlation-based method is more than 10% and the relative improvement over the baseline popularity prediction approach is 23%.</p><p>We have also investigated the prediction accuracy obtained by models with varying number of user communities. Figure <ref type="figure" target="#fig_2">3</ref> shows the results obtained for the multinomial model. It can be seen that the performance improves steadily with the number of communities, but levels off towards the end. This is not true however in the case of models with Gaussian distributions for community ratings. Figure <ref type="figure" target="#fig_3">4</ref> shows a clear optimum around k = 40 communities, after which the performance slowly degrades with model size. This seems to indicate that the multinomial rating model needs to introduce a larger number of communities to account for the user-specific shift in the rating scale, which is incorporated a priori in the Gaussian model. The latter therefore requires fewer communities to model the correlations between the normalized user ratings.</p><p>Our next comparison (Figure <ref type="figure" target="#fig_4">5</ref>) evaluates the effectiveness and importance of the tempered regularization with early stopping. We have used 10% hold-out data to determine the optimal stopping point and β-value, respectively. In the case of early stopping, one more EM training iterations using all data (training plus hold-out) is performed after stopping. Since the results are comparable for different sampling models, we only report and discuss the results for the multinomial case using the MAE criterion. As can be seen from the graph, the models obtained via tempered EM consistently outperform the ones trained by plain EM with early stopping. It is important to notice though that the number of EM iterations performed in early stopping EM is much smaller, typically between 30 and 40, compared to approximately 100-120 in the tempered version. On the other hand, for the same performance level, the tempered models need fewer parameters and are hence more compact. Tempering also requires to determine the optimal inverse temperature β which further increases the computational burden. In practice, the scalability-accuracy tradeoff may be decided with regard to the specific application and the available computational resources.</p><p>• Thomas Hofmann  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Results: Ranking Scenario</head><p>The second scenario we have experimentally investigated is the free prediction mode. Since the prediction accuracy in predicting votes is no longer adequate, we have used the ranking loss in Eq. ( <ref type="formula">34</ref>) to benchmark different algorithms. Again, we have used the leave-one-out protocol. The results are summarized in Table <ref type="table" target="#tab_4">II</ref>.</p><p>The best ranking scores are obtained by the multinomial and the normalized Gaussian pLSA model. The difference between these two models is not statistically significant, while the performance gain relative to the Pearson correlation method is significant. The relative performance gain with respect to the popularity baseline is overall higher than in the forced prediction mode-more than 40% relative improvement are achieved. Notice however that the actual prediction error of these models is higher than for the models that have been trained in forced mode. In fact the absolute error of the Gaussian pLSA model is slightly higher than with the correlation-based approach, although the difference is not statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latent Semantic Models for Collaborative Filtering</head><p>• 109</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Runtime</head><p>We have implemented the Gaussian and multinomial pLSA algorithms in C++ and ran our experiments on a standard PC with a 2GHZ CPU. The computer time needed to perform a single EM step using all 61,265 users for a Gaussian model with k = 40 is about 30 seconds. The number of iterations required when using early stopping is around 30-40 while up to 100-120 iterations are required when using tempered EM. In the latter case, the off-line training of the model takes thus slightly less than 1 hour, while off-line training using earlystopping takes less than 20 minutes. For models with larger k, the training time grows proportionally in k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Miscellaneous</head><p>In the above experiments, we have always used the community variant of the latent class models, that is, models involving P (v| y, z) instead of P (v|u, z). We have also run experiments with the latter though, which has consistently led to worse results. For example, the best MAE obtained in forced prediction was 0.971 compared to an absolute error of 0.927 for the multinomial community model.</p><p>We have also not been able to obtain competitive results using the normalized risk function of Eq. ( <ref type="formula" target="#formula_10">8</ref>) for training. In fact, we have even experimented with various interpolated versions of the risk functions in Eq. ( <ref type="formula" target="#formula_8">7</ref>) and Eq. ( <ref type="formula" target="#formula_10">8</ref>) without much success. It thus seems that a uniform weighting of each rating is the best choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Mining User Communities</head><p>Finally, we would like to illustrate that the decomposition of user ratings may lead to the discovery of interesting patterns and regularities that describe user interests as well as disinterest. To that extent, we have to find a mapping of a quantitative pLSA model into a more qualitative description suitable for visualization. We propose to summarize and visualize each user community, corresponding to one of the k possible states of the latent variable Z , in the following way. We sort items within each community or interest group according to their popularity within the community as measured by the probability P ( y|z). The most popular items are used to characterize a community and we expect these items to be descriptive for the types of items that are relevant to the user community. Figures <ref type="figure" target="#fig_5">6</ref> and<ref type="figure" target="#fig_6">7</ref> display the interest groups extracted by a multinomial pLSA model with k = 40, ordered according to the average "positiveness" of each group, computed as g ( y, z) = y,v vP(v| y, z)P ( y|z). For example, in Figure <ref type="figure" target="#fig_5">6</ref>, interest group 6 has romantic movies like "The Remains of the Day", "The Piano", "Like Water for Chocolate" and "Much Ado About Nothing" top ranked. Interest group 18 seems to be formed around musicals like "Mary Poppins", "Cinderella", "The Sound of Music" and "Dumbo". With each top-ranked item, we also suggest to display the average rating the item receives in the community, computed as v = v vP(v| y, z). These numbers are displayed in rectangular brackets and enclosed by stars in Figures <ref type="figure" target="#fig_5">6</ref> and<ref type="figure" target="#fig_6">7</ref>.</p><p>Looking at the average ratings obtained by the top movies in each of the interest groups extracted from the EachMovie data set, it is interesting to see that communities seem to constitute themselves around items of either common interest or disinterest. This is indicated by the fact that movies with highest selection probabilities P ( y|z) within a community z seem to have similar ratings. Notice that the latter fact is nowhere enforced by any means in the model and is a property that emerges from the data. While some of the dis-interest groups like the one formed around the movies "Mighty Morphin Power Rangers" and "The Brady Bunch Movie" are certainly not useful to derive recommendations, they are however important to model and predict negative ratings and to prevent that certain items end up as recommendations where they should not. Some of the extracted "communities" may thus not correspond to interest groups in the usual sense, which are formed around a common interest. Rather, communities are characterized by a commonality that can also be a shared depreciation for certain items. Overall, we believe that patterns and regularities extracted with pLSA models can be helpful in understanding shared interests of users and correlations among ratings for different items. The ability to automatically discover communities as part of the collaborative filtering process is a trait which pLSA shares with only few other methods such as clustering approaches, but which is absent in all memory-based techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>We have presented a powerful method for collaborative filtering and mining of user data based on a statistical latent class model. The method achieves competitive recommendation and prediction accuracies, is highly scalable, and extremely flexible. Conceptionally, the decomposition of user preferences using overlapping user communities is a novel idea that clearly distinguishes this approach from traditional memory-based approaches as well as previous modelbased methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Graphical model representation of possible extensions of the pLSA model to include a rating variable v. (a) Depicts the co-occurrence pLSA model. In (b), the rating only depends on the latent variable. (c) and (d) correspond to the free prediction mode with users and items interchanging their roles. (e) and (f) are derived from (c) and (d), respectively, by removing one arc, which is the manipulation corresponding to forced prediction.</figDesc><graphic coords="11,134.85,119.46,354.00,58.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig</head><label></label><figDesc>Fig. 2. MAE for the Pearson correlation method and Gaussian pLSA for different values of M (corresponding to the minimal number of ratings required for test users).</figDesc><graphic coords="18,169.69,119.14,276.00,182.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Predictive performance in terms of MAE and RMS for the multinomial pLSA model as a function of the number of user communities k.</figDesc><graphic coords="18,170.69,343.26,275.00,190.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Predictive performance in terms of MAE and RMS for the Gaussian pLSA model as a function of the number of user communities k.</figDesc><graphic coords="19,174.35,118.74,275.00,191.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Predictive performance in terms of MAE for tempered EM (TEM) vs. early stopping EM (EM).</figDesc><graphic coords="20,169.69,118.74,276.00,191.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. User communities 1-20 (of 40) extracted from the EachMovie data set with a multinomial pLSA model.</figDesc><graphic coords="22,127.69,118.90,360.00,327.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. User communities 21-40 (of 40) extracted from the EachMovie data set with a multinomial pLSA model.</figDesc><graphic coords="23,131.85,119.14,360.00,326.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table I .</head><label>I</label><figDesc>Prediction Accuracy of Various Methods in forced Prediction Mode Averaged</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Over 20 Runs</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Error</cell><cell></cell><cell cols="3">Relative improvement</cell></row><row><cell>Method</cell><cell>MAE</cell><cell>RMS</cell><cell>0/1 loss</cell><cell>MAE</cell><cell>RMS</cell><cell>0/1 loss</cell></row><row><cell>Baseline</cell><cell>1.089</cell><cell>1.371</cell><cell>71.2</cell><cell>±0</cell><cell>±0</cell><cell>±0</cell></row><row><cell>Pearson correlation</cell><cell>0.948</cell><cell>1.237</cell><cell>64.7</cell><cell>12.9%</cell><cell>9.7%</cell><cell>9.1%</cell></row><row><cell>Multinomial</cell><cell>0.925</cell><cell>1.209</cell><cell>59.2</cell><cell>15.1%</cell><cell>11.8%</cell><cell>16.8%</cell></row><row><cell>Gaussian</cell><cell>0.974</cell><cell>1.251</cell><cell>67.2</cell><cell>10.5%</cell><cell>8.8 %</cell><cell>5.6%</cell></row><row><cell>Gaussian, normalized</cell><cell cols="2">0.895 1.165</cell><cell>63.4</cell><cell>17.8%</cell><cell>15.0%</cell><cell>10.9%</cell></row><row><cell>CR</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table II .</head><label>II</label><figDesc>Performance of Different Methods in Free Prediction Mode According to Ranking Criterion</figDesc><table><row><cell>Method</cell><cell>rank gain</cell><cell>rel. improv.</cell><cell>abs</cell><cell>rms</cell></row><row><cell>Baseline</cell><cell>16.76</cell><cell>±0</cell><cell>1.091</cell><cell>1.371</cell></row><row><cell>Pearson correlation</cell><cell>21.14</cell><cell>26.1</cell><cell>0.951</cell><cell>1.231</cell></row><row><cell>Multinomial</cell><cell>24.41</cell><cell>45.6</cell><cell>0.981</cell><cell>1.245</cell></row><row><cell>Gaussian</cell><cell>21.80</cell><cell>30.0</cell><cell>1.020</cell><cell>1.290</cell></row><row><cell>Gaussian, normalized</cell><cell>24.28</cell><cell>44.8</cell><cell>0.955</cell><cell>1.211</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Transactions on Information Systems,Vol. 22, No. 1, January 2004, Pages 89-115.   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>ACM Transactions on InformationSystems, Vol. 22, No. 1, January 2004.   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2"><p>For notational convenience, P (v|u, y) denotes a probability mass function (discrete case) or a conditional probability density function (continuous case) dependent on the context. ACM Transactions on Information Systems, Vol.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>22, No. 1, January 2004.   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>ACM Transactions Information Systems, Vol. 22, No. 1, January 2004.   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_5"><p>The original ratings have been multiplied by a factor of 5.ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.   </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>The <rs type="projectName">EachMovie data set is by courtesy of Digital Equipment Corporation and was generously provided by Paul McJones</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_H3yAVn6">
					<orgName type="project" subtype="full">EachMovie data set is by courtesy of Digital Equipment Corporation and was generously provided by Paul McJones</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Thomas Hofmann</head><p>in <ref type="bibr" target="#b2">Breese et al. [1998]</ref>. Let us denote a permutation of the items by τ and the rank of an item y with respect to τ by τ ( y). The top ranked item y will have τ ( y) = 1, the second item τ ( y) = 2, and so forth. Items whose ratings have been used for training are not included in the ranking. We then use the following rank score for τ ,</p><p>with v denoting the overall mean vote. The rationale behind this score is that when presented with a ranked list of items, users will sift through the list starting at the top, until they find a relevant item or simply give up. The probability that a user will ever take notice of an item at rank r is modeled as an exponential distribution with a half-life constant α (set to 4 in our experiments). The total score for a population of users is then measured by (cf. <ref type="bibr" target="#b2">Breese et al. [1998]</ref>)</p><p>This normalizes the sum of the achieved score with what could have optimally achieved, if for every user all relevant items would appear at the very top of the ranked list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation Protocols</head><p>We have used the leave-one-out protocol to evaluate the obtained prediction accuracies. This means we randomly leave out exactly one rating for every user possessing at least a minimal number M ≥ 2 of observed ratings and then average the loss function over this set of users to obtain an estimate of the risk. This protocol has been called AllBut1 in <ref type="bibr" target="#b2">Breese et al. [1998]</ref>. More precisely, we have eliminated one vote for every user from the training set and trained models on this reduced set. Notice that this uses somewhat less data than required, but allows us to use a single model to evaluate the leave-oneout performance averaged over all users. We have varied M to investigate the prediction accuracy for users for which a minimal number of M ratings are available. In order to establish statistical significance of the findings, we have repeated the leave-one-out procedure 20 times with different random seeds.</p><p>The reported numbers are the mean performance averaged over these 20 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results: Prediction Scenario</head><p>Table <ref type="table">I</ref> summarizes experimental results obtained by different variants of the proposed method (multinomial, Gaussian, Gaussian with normalized votes), a memory-based method using the Pearson correlation coefficient, and results published in <ref type="bibr" target="#b2">Breese et al. [1998]</ref> for various methods (Bayesian clustering = BC, Bayesian networks = BN, correlation = CR). The baseline is simply defined by the overall mean vote for each item. The test votes have been selected by leaveone-out with M = 2.</p><p>• Thomas Hofmann</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>A.1 Derivation of the Generalized E-step</p><p>We derive the solution of minimizing the following objective function</p><p>with respect to the variational distribution Q.</p><p>Notice first that F β can be rewritten as a sum over contributions from all (u, v, y) pairs,</p><p>where</p><p>Here S(u, v, y, z) = P ( y|z)P (z|u) in the co-occurrence model, whereas S(u, v, y, z) = P (v| y, z)P ( y|z)P (z|u) in the free prediction case and S(u, v, y, z) = P (v| y, z)P (z|u) for forced prediction. Hence, one can minimize every F β (u, v, y, Q) separately. Introducing a Lagrange multiplier λ to enforce the normalization constraint z Q(z; u, v, y) = 1, one forms the Lagrangian function</p><p>Computing the partial derivative of L β with respect to Q(z; u, v, y) and setting to zero results in the necessary conditions</p><p>Exponentiating both sides of the equality yields</p><p>Apparently, λ needs to be chosen such that</p><p>Plugging this value for the Lagrange multiplier λ back into the Lagrangian function results in the general optimality condition for Q which leads to the special cases of Eq. ( <ref type="formula">15</ref>) and the tempered version in Eq. ( <ref type="formula">19</ref>) for the co-occurrence model and Eq. ( <ref type="formula">29</ref>) and Eq. ( <ref type="formula">30</ref>) for the model including rating variables.</p><p>Latent Semantic Models for Collaborative Filtering</p><p>The most general case is the free prediction case, where one has to minimize</p><p>with respect to the parameters P ( y|z), P (z|u) and the parameters representing P (v| y, z), respectively. In order to ensure the normalization y P ( y|z) = 1 for all z and z P (z|u) = 1 for all u, we introduce Lagrange multipliers λ z and λ u and form the Lagrangian</p><p>Taking derivatives with respect to P ( y|z) and setting to zero results in</p><p>Similarly one obtains for P (z|u) 1</p><p>Plugging these results back into Eq. ( <ref type="formula">43</ref>) yields the following expressions for the Lagrange multipliers</p><p>which in turn lead to the M-step equations in Eq. ( <ref type="formula">17</ref>).</p><p>In the multinomial pLSA model, one uses the same approach for P (v| y, z), introducing additional Lagrange multipliers λ y,z to ensure that v P (v| y, z) = 1. Augmenting the Lagrangian function by a term y,z λ y,z v P (v| y, z) -1 and solving as before leads to equation Eq. ( <ref type="formula">31</ref>). Notice that the M-step equations for the co-occurrence model and the forced prediction case can be obtained by dropping the equations for P (v| y, z) and P ( y|z), respectively.</p><p>In </p><p>and a similar equation for σ 2 y,z .</p><p>• Thomas Hofmann</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recommendation as classification: Using social and content-based information in recommendation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hirsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Recommender System Workshop</title>
		<meeting>the Recommender System Workshop</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="11" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, Mass</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Empiricial analysis of predictive algorithms for collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference on Uncertainity in Aritificial Intelligence</title>
		<meeting>the 14th Conference on Uncertainity in Aritificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Collaborative filtering with privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy</title>
		<meeting>the IEEE Symposium on Security and Privacy<address><addrLine>Los Alamitos, Calif</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="45" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Bayesian model for collaborative filtering</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Online Proceedings of the Seventh International Workshop on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Information Theory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Indexing by latent semantic analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ASIS</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><surname>Eachmovie</surname></persName>
		</author>
		<ptr target="www.research.digital.com/src/eachmovie/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An efficient boosting algorithm for combining preferences</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML-98, 15th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Shavlik</surname></persName>
		</editor>
		<meeting>ICML-98, 15th International Conference on Machine Learning<address><addrLine>San Francisco, Calif</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan-Kaufmann</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="170" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using collabrorative filtering to weave an information tapestry</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Oki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Eigentaste: A constant-time collaborative filtering algorithm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Perkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="133" to="151" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dependency networks for inference, collaborative filtering, and data visualization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rounthwaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Kadie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="75" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An algorithmic framework for performing collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borchers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM-SIGIR International Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22nd ACM-SIGIR International Conference on Research and Development in Information Retrieval<address><addrLine>Berkeley, Calif; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM-SIGIR International Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22nd ACM-SIGIR International Conference on Research and Development in Information Retrieval<address><addrLine>Berkeley, Calif; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised learning by probabilistic latent semantic analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn. J</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="177" to="196" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">What people (don&apos;t) want</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning (ECML)</title>
		<meeting>the European Conference on Machine Learning (ECML)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Latent class models for collaborative filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference in Artificial Intelligence</title>
		<meeting>the International Joint Conference in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Grouplens: Applying collaborative filtering to usenet news</title>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Expectation-propagation for the generative aspect model</title>
		<author>
			<persName><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 18th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A view of the EM algorithm that justifies incremental, sparse, and other variants</title>
		<author>
			<persName><forename type="first">R</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning in Graphical Models</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Jordan</surname></persName>
		</editor>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributional clustering of English words</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="183" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Grouplens: An open architecture for collaborative filtering of netnews</title>
		<author>
			<persName><forename type="first">P</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Iacovou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suchak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bergstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM, Conference on Computer Supported Cooperative Work</title>
		<meeting>the ACM, Conference on Computer Supported Cooperative Work</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Application of dimensionality reduction in recommender system-A case study</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM WebKDD 2000 Web Mining for E-Commerce Workshop</title>
		<meeting>the ACM WebKDD 2000 Web Mining for E-Commerce Workshop<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Social information filtering: Algorithms for automating &quot;word of mouth</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reidl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shardanand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM CHI&apos;95 Conference on Human Factors in Computing Systems</title>
		<meeting>ACM CHI&apos;95 Conference on Human Factors in Computing Systems<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995">2001. 1995</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="210" to="217" />
		</imprint>
	</monogr>
	<note>Proceedings of the World Wide Web Conference</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Clustering methods for collaborative filtering</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Recommendation Systems</title>
		<meeting>the Workshop on Recommendation Systems<address><addrLine>Menlo Park, Calif</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">July</title>
		<imprint>
			<date type="published" when="2003-01">January 2003. 2003. 2003</date>
		</imprint>
	</monogr>
	<note>accepted September</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
