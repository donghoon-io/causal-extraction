<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distilling vector space model scores for the assessment of constructed responses with bifactor Inbuilt Rubric method and latent variables</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-01-11">11 January 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">José</forename><surname>Ángel Martínez-Huertas</surname></persName>
							<email>joseangel.martinezhuertas@gmail.com</email>
							<idno type="ORCID">0000-0002-6700-6832</idno>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Psychology</orgName>
								<orgName type="institution">Universidad Autónoma de Madrid</orgName>
								<address>
									<addrLine>Calle Iván Pavlov, 6 Ciudad Universitaria de Cantoblanco</addrLine>
									<postCode>28049</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Human and Social Sciences</orgName>
								<orgName type="institution">Universidad Pontificia de Comillas</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ricardo</forename><surname>Olmos</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Psychology</orgName>
								<orgName type="institution">Universidad Autónoma de Madrid</orgName>
								<address>
									<addrLine>Calle Iván Pavlov, 6 Ciudad Universitaria de Cantoblanco</addrLine>
									<postCode>28049</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guillermo</forename><surname>Jorge-Botana</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Faculty of Psychology</orgName>
								<orgName type="institution">Universidad Complutense de Madrid</orgName>
								<address>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">José</forename><forename type="middle">A</forename><surname>León</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Psychology</orgName>
								<orgName type="institution">Universidad Autónoma de Madrid</orgName>
								<address>
									<addrLine>Calle Iván Pavlov, 6 Ciudad Universitaria de Cantoblanco</addrLine>
									<postCode>28049</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">José Ángel Martínez-Huertas</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Distilling vector space model scores for the assessment of constructed responses with bifactor Inbuilt Rubric method and latent variables</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-01-11">11 January 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3758/s13428-021-01764-6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Inbuilt Rubric</term>
					<term>Vector space models</term>
					<term>Bifactor</term>
					<term>Measurement models</term>
					<term>Validity</term>
					<term>Constructed responses</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we highlight the importance of distilling the computational assessments of constructed responses to validate the indicators/proxies of constructs/trins using an empirical illustration in automated summary evaluation. We present the validation of the Inbuilt Rubric (IR) method that maps rubrics into vector spaces for concepts' assessment. Specifically, we improved and validated its scores' performance using latent variables, a common approach in psychometrics. We also validated a new hierarchical vector space, namely a bifactor IR. 205 Spanish undergraduate students produced 615 summaries of three different texts that were evaluated by human raters and different versions of the IR method using latent semantic analysis (LSA). The computational scores were validated using multiple linear regressions and different latent variable models like CFAs or SEMs. Convergent and discriminant validity was found for the IR scores using human rater scores as validity criteria. While this study was conducted in the Spanish language, the proposed scheme is language-independent and applicable to any language. We highlight four main conclusions: (1) Accurate performance can be observed in topic-detection tasks without hundreds/thousands of pre-scored samples required in supervised models. (2) Convergent/discriminant validity can be improved using measurement models for computational scores as they adjust for measurement errors. (3) Nouns embedded in fragments of instructional text can be an affordable alternative to use the IR method. (4) Hierarchical models, like the bifactor IR, can increase the validity of computational assessments evaluating general and specific knowledge in vector space models. R code is provided to apply the classic and bifactor IR method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction 1</head><p>Computational semantic measures are relevant to obtain indicators of different psychological constructs (e.g., <ref type="bibr" target="#b45">Kjell et al., 2019)</ref>. The general purpose of these methods is to detect indicators in the utterances of the people being assessed. This is especially valuable in academic assessment (e.g., <ref type="bibr" target="#b4">Bejar et al., 2016;</ref><ref type="bibr" target="#b49">Landauer et al., 2007;</ref><ref type="bibr">McNamara, 2007;</ref><ref type="bibr">Shermis &amp; Burstein, 2013;</ref><ref type="bibr" target="#b110">Yan et al., 2020)</ref>. The automation of this assessment has caused a significant shift from traditional or classical approaches to psychological assessment using written materials. An efficient automatic system should identify some relevant constructs or trins (the object of the assessment) from some indicators or proxies (observable features in text). This consideration is analogous to the psychometric process of creating a psychological task or test where one should evaluate (a) whether the constructs can be a relevant instance of the object of assessment, and (b) whether the indicators are appropriate to infer such constructs. These considerations are in line with the need to gain reliability and validity in the computational assessment of texts (e.g., <ref type="bibr" target="#b3">Attali, 2014;</ref><ref type="bibr" target="#b4">Bejar et al., 2016;</ref><ref type="bibr" target="#b46">Koskey &amp; Shermis, 2014;</ref><ref type="bibr" target="#b92">Rupp, 2018)</ref>.</p><p>While several possible indicators can be retrieved from a text (including pattern detection, syntactic and logical sequences, etc.), we are going to focus on the semantic cues that arise from vector space models. In any case, these semantic cues can also be merged within a larger model taking advantage of several indicators. As is known, vector space models allow us to represent words and texts in a multidimensional vector space that maps the knowledge of a specific linguistic corpus (see <ref type="bibr" target="#b30">Günther et al., 2019;</ref><ref type="bibr" target="#b35">Jones et al., 2018;</ref><ref type="bibr" target="#b40">or Jorge-Botana et al., 2020</ref>, for a recent review on vector space models). In the evaluation of constructed responses, as in automated summary evaluation, text responses are represented in the vector space. Here, the semantic dimensions of those vectors are the indicators of the text responses. In vector space models, the evaluation of constructed responses is usually made by comparing the latent vector that represents the text response to be assessed with the latent vectors of "ideal" responses or parts of those ideal responses<ref type="foot" target="#foot_0">foot_0</ref> . It is important to highlight that these vectors are latent in the sense that their coordinates (dimensions) have no meaning themselves (that is, vectors are just comparable but not interpretable). Nonetheless, some proposals have been made to transform the latent nature of these vector spaces into semantic spaces whose coordinates could have a priori explicit semantic meanings, such as the meaning of the important concepts we want to identify and evaluate in texts (e.g., <ref type="bibr" target="#b33">Hu et al., 2007)</ref>. One of these proposals is the Inbuilt Rubric method, named for its capacity to transform some coordinates of the original vector space into a rubric to evaluate semantic concepts. This method endows the dimensions of the vector space with semantic meanings determined a priori by the designer of the rubric. This method further makes vectors more than a meaningless set of coordinates as it generates comparable and interpretable coordinates in the vector space <ref type="bibr" target="#b39">(Jorge-Botana et al., 2019;</ref><ref type="bibr" target="#b61">Martínez-Huertas et al., 2018</ref><ref type="bibr">, 2019</ref><ref type="bibr" target="#b111">, 2021;</ref><ref type="bibr" target="#b79">Olmos et al., 2014</ref><ref type="bibr" target="#b80">Olmos et al., , 2016))</ref>.</p><p>Based on the previous theoretical background, the present study aims to make a formal proposal about the combination of computational scores and standard psychometrics <ref type="foot" target="#foot_1">3</ref> . In this respect, this study illustrates how standard psychometric procedures can validate and even improve the performance of computational methods like Inbuilt Rubric using a latent variable framework. Specifically, we will combine the strengths of semantic measures from vector space models (and some algebraic manipulation of them) and their underlying measurement models to validate computational psychoeducational assessments. In sum, this study defends the necessity of using a validity-centered approach to gather evidence in favor of computational scores to measure constructs from written materials (see a similar rationale in <ref type="bibr" target="#b3">Attali, 2014;</ref><ref type="bibr" target="#b4">Bejar et al., 2016;</ref><ref type="bibr" target="#b46">Koskey &amp; Shermis, 2014;</ref><ref type="bibr" target="#b92">Rupp, 2018)</ref>. Classic psychometric tools like latent variable models (e.g., structural equation models <ref type="bibr">[SEMs]</ref>) can be used to isolate and validate the constructs suggested by the rubric designers and the scores of the Inbuilt Rubric method. This paper is organized as follows: first, we provide a brief introduction to vector space models and psychoeducational assessment; second, we present the fundamentals of the assessment by means of Inbuilt Rubric in some of its configurations; and third, the combination of latent models with Inbuilt Rubric is proposed and empirically tested in a study on automated summary evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automated summary evaluation for psychoeducational assessments</head><p>Different studies have shown the relevance of summarizing in evaluating comprehension and text-based learning (e.g., <ref type="bibr" target="#b23">Franzke et al., 2005;</ref><ref type="bibr" target="#b32">Hong, 2016;</ref><ref type="bibr" target="#b51">León et al., 2006;</ref><ref type="bibr" target="#b94">Saddler et al., 2017;</ref><ref type="bibr" target="#b100">Stevens et al., 2019;</ref><ref type="bibr" target="#b101">Sung et al., 2016;</ref><ref type="bibr" target="#b108">Wade-Stein &amp; Kintsch, 2004)</ref>. Summarizing requires the capacity to generalize, synthesize, and write coherently, which implies profound comprehension, incorporating previous knowledge and active processes such as inference-making <ref type="bibr" target="#b104">(van Dijk &amp; Kintsch, 1983</ref>). This theoretical model assumes that summarizing is essential for comprehension since it supposes the extraction and elaboration of text content to generate rich representations of concepts. In this vein, some authors have argued that multiple-choice tests based on recognition memory cause less deep learning than constructed responses based on memory recall (e.g., <ref type="bibr" target="#b71">Millis et al., 2007;</ref><ref type="bibr" target="#b96">Shapiro &amp; McNamara, 2000)</ref>. However, the evaluation of constructed responses such as student summaries requires much effort and time recourses for the evaluators. That is why developing automated assessments of computational models of language is so important. Summary Street, Write-ToLearn, and G-Rubric are some examples of applications employing latent semantic analysis (LSA) in psychoeducational assessment. They all teach how to make a summary from expository texts providing individualized feedback to students <ref type="bibr" target="#b22">(Foltz et al., 2013;</ref><ref type="bibr" target="#b42">Kintsch et al., 2007;</ref><ref type="bibr" target="#b80">Olmos et al., 2016)</ref>. Many other applications of automated summary evaluation can be found in the literature (e.g., <ref type="bibr" target="#b13">Crossley et al., 2019;</ref><ref type="bibr" target="#b14">Dascalu et al., 2015;</ref><ref type="bibr" target="#b57">Li et al., 2018;</ref><ref type="bibr" target="#b53">Li &amp; Graesser, 2020;</ref><ref type="bibr" target="#b72">Mintz et al., 2014;</ref><ref type="bibr" target="#b93">Ruseti et al., 2018)</ref>.</p><p>In <ref type="bibr" target="#b22">Foltz et al. (2013)</ref>, there is an extensive description of the indicators of the student summaries to be evaluated. Among others, the main constructs (indicators appear within parentheses) are grammar (grammatical errors, error types, etc.), style (topic development, organization, etc.), mechanism (punctuation, spelling, capitalization, etc.), lexical sophistication (word variety, technical words, etc.), and content (presence of topics). As stated previously, this study is focused on content, where vector space models have been preeminently used. One of the most popular vector space models to determine the content of texts, especially for the assessment of constructed responses, is LSA <ref type="bibr" target="#b16">(Deerwester et al., 1990;</ref><ref type="bibr" target="#b49">Landauer et al., 2007;</ref><ref type="bibr" target="#b48">Landauer &amp; Dumais, 1997)</ref>. LSA extracts and represents the meaning of words in a multidimensional space. The semantic representations are obtained after applying dimensionality-reduction algebraic methods (like singular value decomposition-SVD) to large corpora to represent the meaning of words in a reduced number of dimensions (usually in a 300-dimensional space). The LSA model has been studied extensively for more than 20 years in a variety of tasks, and it shows great ability to emulate semantic human behavior (involving semantic judgments, classification tasks, search engines, relevant elements in texts, etc.). See <ref type="bibr" target="#b48">Landauer and Dumais (1997)</ref> or <ref type="bibr" target="#b49">Landauer et al. (2007)</ref> for a complete description of LSA.</p><p>A key aspect of vector space models like LSA is that one can represent texts as vectors by means of a simple projection in the semantic space. Thus, similarities among vector representations are computed with distance metrics. In psychoeducational assessments, distances between the vectors of student summaries and gold summaries (ideal summaries written by experts) are computed. Golden summaries can be different depending on the method used, as they can be whole gold summaries (ideal summaries to compare with) or partial summaries (paragraphs or sentences extracted from whole gold summaries describing different topics; <ref type="bibr" target="#b17">Dessus &amp; Lemaire, 1999;</ref><ref type="bibr" target="#b23">Franzke et al., 2005;</ref><ref type="bibr" target="#b42">Kintsch et al., 2007;</ref><ref type="bibr" target="#b58">Magliano &amp; Graesser, 2012;</ref><ref type="bibr" target="#b63">Martínez-Huertas et al., 2021)</ref>, or a set of gold summaries pre-rated with scores from different expert <ref type="bibr" target="#b76">(Olmos et al., 2009b)</ref>. In the field of automated summary evaluation, <ref type="bibr" target="#b51">León et al. (2006)</ref> analyzed six different LSA methods. These methods were holistic, such as the cosine between student summaries and instructional texts, or componential, such as the mean cosine between each sentence from student summaries and some representative sentences from instructional texts. <ref type="bibr" target="#b51">León et al. (2006)</ref> found that holistic methods were more accurate than componential methods. Later, <ref type="bibr" target="#b76">Olmos et al. (2009b)</ref> extended those results by comparing more complex holistic LSA methods such as best-dimension reduction that computes the cosine (a measure of distance) using only the relevant LSA dimensions to evaluate summaries or the Euclidean distance that combines cosine and vector length measures. <ref type="bibr" target="#b76">Olmos et al. (2009b)</ref> discovered that the performance of LSA could be increased using just the relevant dimensions of the latent semantic space like the best-dimension reduction method <ref type="bibr" target="#b33">(Hu et al., 2007)</ref>. These results showed that LSA methods were accurate for measuring the overall quality of student summaries, especially when the LSA's semantic space was honed. Similarly, other studies refined the parameters of the latent semantic space for automated summary evaluation (e.g., <ref type="bibr" target="#b37">Jorge-Botana et al., 2010;</ref><ref type="bibr" target="#b75">Olmos et al., 2009a)</ref>, and its applicability has been widely tested (e.g., <ref type="bibr">Li et al., 2016b, b;</ref><ref type="bibr" target="#b57">Li et al., 2018;</ref><ref type="bibr" target="#b59">Malladi et al., 2010;</ref><ref type="bibr" target="#b77">Olmos et al., 2011</ref><ref type="bibr" target="#b78">Olmos et al., , 2013))</ref>.</p><p>Nevertheless, this previous research was all conducted using latent semantic spaces. Inspired by the proposal by <ref type="bibr" target="#b33">Hu et al. (2007)</ref>, <ref type="bibr" target="#b79">Olmos et al. (2014)</ref> proposed the Inbuilt Rubric method, which transforms the latent semantic space into a meaningful one. As we will see in the next section, its logic is based on the mapping of an assessment rubric's items into vector space dimensions. Thus, the simple projection of constructed responses can provide information about the presence and absence of content without comparing vectors with latent meanings<ref type="foot" target="#foot_3">foot_3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mapping assessment rubrics into vector spaces using the Inbuilt Rubric method</head><p>Inbuilt Rubric is a recently developed LSA method that converts the latent meaning of some dimensions of LSA's vector space into the meaning of an academic assessment rubric's items <ref type="bibr" target="#b79">(Olmos et al., 2014</ref><ref type="bibr" target="#b80">(Olmos et al., , 2016))</ref>. The main advantage of this method is that the meaning of a text is estimated with a simple projection in that new meaningful vector space. The resulting vector of the projection of a constructed response has information about the presence or absence of the items of the rubric. The scores or coordinates of each dimension show the extent to which a text covers the knowledge domain pertaining to each item. Inbuilt Rubric method can be considered a model that maps assessment rubrics into vector space models (a more specific explanation of this method can be found in <ref type="bibr" target="#b79">Olmos et al., 2014</ref><ref type="bibr">, 2016</ref><ref type="bibr" target="#b63">, or in Martínez-Huertas et al., 2021)</ref>. Previous research has shown that the overall scores of the Inbuilt Rubric method demonstrate better performance than the Golden Summary method using the same original LSA semantic space <ref type="bibr" target="#b61">(Martínez-Huertas et al., 2018</ref><ref type="bibr">, 2019;</ref><ref type="bibr" target="#b80">Olmos et al., 2016)</ref>. Similar results have been observed for the specific concept scores of Inbuilt Rubric compared to the partial content similarity method <ref type="bibr" target="#b63">(Martínez-Huertas et al., 2021)</ref>. A brief description of this method shall now be provided.</p><p>In the psychoeducational assessment of constructed responses, the Inbuilt Rubric method requires different sequential steps: (1) A "rubric" is established to define the target concepts whose relevance in the student texts is to be scored (for an example, see the Instruments section). Although this is done to evaluate constructed responses, we could select other target concepts to study other types of stimuli. (2) A semantic space of LSA is generated using standard procedures. (3) Different lexical descriptors are chosen by consensus to make a representation of each target concept of the "rubric" (e.g., for the target concept "Darwin's expedition," lexical descriptors such as "Beagle" or "Galapagos Islands" are good candidates to adequately represent the concept). Therefore, these lexical descriptors must be words represented in the LSA space that are brought together to form each target concept. Each word has its own vector in the LSA space, so adding them together results in the vector that represents the concept. These vectors of target concepts are collected in the first columns in a matrix called β. To complete the β matrix up to the number of dimensions of the original space (usually 300), it is randomly filled with column vectors from the standard basis. As a result, this matrix contains the basis of the new meaningful semantic space (wherein the first columns are meaningful); and (4) To change the space to have the new meaningful basis, a matrix computation of the β matrix is performed. Such a matrix computation involves just a matrix rotation where the US matrix of the original vector space whose first k dimensions pretend to evaluate the target concepts. This operation transforms the original "latent" semantic space into a new "meaningful" one.</p><p>Let us examine this procedure in detail using an example from the present study. As previously stated, the Inbuilt Rubric method requires the generation of matrix β that represents k target concepts or items of the designed assessment rubric (one item corresponds to one vector). These dimensions are computed as the sum of the vectors pertaining to each set of lexical descriptors of each concept (later, these vectors are normalized). For example, the dimension "Darwin's theory" that will be used in the present study is computed as the sum of the vector depicting its set of lexical descriptors-"selection," "natural," and "evolution"-which would ideally represent such a concept. The evaluation of five concepts would require a matrix with five vectors that should be complemented with p-k vectors of the original latent semantic space to equal the number of dimensions, p, of the original vector space (this is done by adding vectors from the standard basis) (see <ref type="bibr">Hu et al., 2007, p. 414)</ref>. As previously stated, the generation of these k vectors of the matrix β requires the selection of some lexical descriptors to represent the target concepts from the instructional text. This selection calls for a systematic and exhaustive consensus between researchers to have a good definition of each concept in the initial latent semantic space. For example, if one wants to evaluate "the journey that Darwin made around the world," the word "Beagle" may appropriately represent part of that concept. Therefore, it is a requirement to check what is understood by "Beagle" in the semantic space before including such a lexical descriptor in a vector that maps that concept. Thus, this process is not automatic and is, in some sense, arbitrary as it depends on the knowledge of the designer. This is why we are also proposing an alternative procedure in this study to automatically generate the vectors of matrix β.</p><p>Such a new version of the Inbuilt Rubric method uses nouns 5 embedded in fragments of the instructional text in matrix β. While the classic β matrix is generated through the selection of lexical descriptors, this alternative procedure avoids such selection and adopts a more automatic process. Figure <ref type="figure" target="#fig_0">1</ref> represents a hypothetical example of the extraction 5 Nouns were chosen here as an accurate representation of the semantic context of the target concepts to be evaluated. This is because the two versions of the Inbuilt Rubric method aim to generate the same semantic context (the one wherein the target concepts appear). As the present study was conducted using three expository texts involving very concrete and specific concepts, the semantic context of the concepts was basically determined by the nouns (not the verbs, which were common and unspecific). For example, a representative sentence of Text 1 is "En 1809 presentó Lamarck su teoría de la evolución en un libro titulado Filosofía Zoológica." ["In 1809, Lamarck presented his theory of evolution in a book entitled 'Zoological Philosophy'"]. This semantic context is basically defined by nouns and seems to be sufficient for the assessment of concepts. Thus, while there are theoretical perspectives that highlight the role of information different from that of nouns (e.g., verbal information), we think that it would be more useful to explain ecological phenomena in narrative texts or texts with natural language. Future research has been proposed in the Discussion section about the use of different types of information (e.g., related to verbs, adverbs, determinants, etc.) to transform vector spaces.</p><p>of such text fragments. The essence of this procedure is similar to other previous methods performing content-detection tasks such as partial content similarity or partial golden summaries (explained previously) that select relevant fragments of the original text stimuli <ref type="bibr" target="#b17">(Dessus &amp; Lemaire, 1999;</ref><ref type="bibr" target="#b23">Franzke et al., 2005;</ref><ref type="bibr" target="#b42">Kintsch et al., 2007;</ref><ref type="bibr" target="#b58">Magliano &amp; Graesser, 2012;</ref><ref type="bibr" target="#b63">Martínez-Huertas et al., 2021)</ref>, but it only uses nouns embedded in those fragments of the instructional text. In this version, a β matrix is created using different k vectors that are compounded by different number of nouns for each concept to be evaluated. This version is more automatic and does not require decision-making about the lexical descriptors to be used to transform the latent semantic space. Fundamentally, this version of the Inbuilt Rubric method only requires the selection of different text fragments that represent the target concepts to be evaluated. Such fragments can be part of the instructional text or other materials that are longer and more complex than the lexical descriptors.</p><p>As previously mentioned, the Inbuilt Rubr ic method follows a confirmatory strategy that imposes the conceptual structure of a rubric on the vector space, transforming some of its dimensions into concepts. To do this, Inbuilt Rubric uses a new basis, the aforementioned β matrix, with vectors that represent the concepts of the rubric. Matrix β is used to transform the latent vector space into a one in which some dimensions capture the meaning of some target concepts. While this transformation involves a simple rotation that makes simple projections possible (i.e., the original semantic distances remain), it is necessary to orthogonalize the vectors of matrix β before. Thus, the dimensions of matrix β (that is, the target concepts to be evaluated and the rest of the matrix β) are artificially forced to have no common variance between them. This aspect has been considered one of the main advantages of the Inbuilt Rubric method as it avoids multicollinearity (Mar tínez-Huer tas et al., 2021). However, recent proposals have tried to analyze the common variance that exists between the evaluated concepts in the Inbuilt Rubric method <ref type="bibr" target="#b39">(Jorge-Botana et al., 2019)</ref>. In the next section, we will introduce how it is possible to create a general factor of knowledge in the vector space, and we will also raise some questions about the meaning of such a general factor.</p><p>It is worth mentioning that the concepts of the vector space are established a priori by means of the Inbuilt Rubric method. Other proposals have used varimax rotations in the term loadings of the vector space to interpret the meaning of some dimensions of the LSA semantic space <ref type="bibr" target="#b19">(Evangelopoulos, 2013;</ref><ref type="bibr">Evangelopoulos et al., 2012;</ref><ref type="bibr" target="#b20">Evangelopoulos &amp; Visinescu, 2012;</ref><ref type="bibr" target="#b41">Kallens &amp; Dale, 2018;</ref><ref type="bibr" target="#b47">Kundu et al., 2015;</ref><ref type="bibr" target="#b106">Visinescu &amp; Evangelopoulos, 2014)</ref>. While these authors also projected documents in rotated semantic spaces and could interpret the meaning of some dimensions, their strategy was more exploratory, and it is thus not possible to determine what concepts to evaluate. On the contrary, the Inbuilt Rubric method imposes concepts onto the vector space, and it can be used as a map for knowledge representations of different concepts established a priori.</p><p>The lack of a general factor in vector space models: A measure of general knowledge?</p><p>In some sense, the concept dimensions used in the Inbuilt Rubric method can be considered orthogonal specific/group factors in a confirmatory bifactor model. As previously explained, the concept dimensions of the vector space are orthogonal, so they do not share common variance. <ref type="bibr" target="#b39">Jorge-Botana et al. (2019)</ref> assumed that such common variance could be a valuable measure of general knowledge and studied how to manage the common variance that remains between the concepts of the rubric after Inbuilt Rubric manipulation. The authors introduced a complement into the classic Inbuilt Rubric in which an additional vector is estimated in matrix β that represents the common variance of the individual vectors of the rubric concepts. That new (general) vector is extracted through an exploratory factor analysis of the vector representations of the lexical descriptors. In this parametrization of the Inbuilt Rubric method, the lexical descriptors of each concept are split into i sets (here, i = 1, 2) and are represented in the semantic Note: Instructional texts of this study had clear divisions for the different conceptual axes latent space. For example, if a rubric has four concepts, then eight vectors would be involved in this procedure (Jorge-Botana et al., 2019 also suggested other potentially useful methods for this purpose). An exploratory factor analysis is carried out, and the factor scores of the one-dimensional solution are estimated. Thus, the general factor is computed by weighting such vector representations by their respective factor loadings (λ ki ):</p><p>where k is the number of concepts to be evaluated, and i is the number of the partitions of the lexical descriptors of each concept (in this parametrization: i = 1, 2). This general factor is included in the k+1th position of matrix β before the vectors of the rubric concepts, and it represents the common variance between the vectors of the rubric concepts. Finally, the vectors of matrix β are also orthogonalized.</p><p>At the end of this process, it is possible to obtain an orthogonalized vector space in which some dimensions denote the concepts to be evaluated, and other dimension acts as a general factor. This is very similar to bifactor modeling as the concepts' dimensions and the general factor do not share common variance. This is one of the main similarities of this method with bifactor models based on orthogonalization procedures such as the Schmid-Leiman orthogonalization <ref type="bibr" target="#b95">(Schmid &amp; Leiman, 1957</ref>; see also <ref type="bibr" target="#b86">Reise, 2012;</ref><ref type="bibr" target="#b87">Reise et al., 2007;</ref><ref type="bibr" target="#b90">Rodriguez et al., 2016;</ref><ref type="bibr" target="#b112">Zhang et al.,</ref> (1)</p><formula xml:id="formula_0">General factor = 1i * Dim 1i + 2i * Dim 2i + ⋯ + ki * Dim ki + error 2020)</formula><p>. This procedure allows one to estimate the presence or absence of the assessment rubric's concepts in constructed responses with a simple projection in that new meaningful space, but we can also estimate a general factor of common variance in the vector space. Figure <ref type="figure" target="#fig_1">2</ref> illustrates the β matrix of the bifactor Inbuilt Rubric method. As it can be seen, the dimensions of the Inbuilt Rubric method have k meaningful dimensions representing the target concepts (e.g., k = 5, C 1 -C 5 ) and other p-k latent dimensions of the original semantic space (Fig. <ref type="figure" target="#fig_1">2a</ref>). As previously stated, the dimensions of the original semantic space are added to matrix β using a standard basis (see also <ref type="bibr">Hu et al., 2007, p. 414)</ref>. In this study, the meaningful dimensions represent concepts like "Earth's age," "Lamarck," "Darwin's expedition," "Darwin's theory," and "Transcendence" (see the description of the first instructional text for a more complete description of this example). On the contrary, the dimensions of the bifactor Inbuilt Rubric method have the same structure, except for one of the p-k latent dimensions of the original semantic space has been replaced by a general factor (Fig. <ref type="figure" target="#fig_1">2b</ref>). In this specific case, there would be five meaningful dimensions in the semantic space that represent the target concepts (e.g., "Earth's age," "Lamarck," "Darwin's expedition," "Darwin's theory," and "Transcendence"), an additional general factor that is supposed to represent the general knowledge common to these concepts (see the G dimension in Fig. <ref type="figure" target="#fig_1">2b</ref>) and different latent dimensions of the original semantic space to preserve the dimensionality of the original semantic space.</p><p>The present study will test the reliability and consistency of the general and specific factors of the bifactor Inbuilt Rubric method. For this purpose, the scores of these versions of the Inbuilt Rubric method will be compared with the bifactor structure of human raters' scores from a psychometric perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Using psychometrics to infer constructs from computational indicators</head><p>It is good practice in psychological research to empirically test the reliability and validity of psychological tests. This is why different psychometric approaches have been developed by means of classic theory tests, item response theory, or newer approaches (e.g., <ref type="bibr" target="#b0">Abad et al., 2011;</ref><ref type="bibr">Maydeu-Olivares &amp; McArdle, 2005;</ref><ref type="bibr" target="#b85">Raykov &amp; Marcoulides, 2008;</ref><ref type="bibr" target="#b103">van der Linden &amp; Hambleton, 2013)</ref>. Thus, we need to provide evidence that every human or computational evaluation is valid. In classical psychometrics, testing the factor structure of observable variables lets researchers evaluate their hypothetical measurement models. In this way, researchers assume a model in which the observed indicators (e.g., test items) configure some unobserved constructs (such as academic skills). Factor analysis allows researchers to infer these constructs from the observed indicators when their models present a good fit to the data. Otherwise, researchers must review their indicators, models, or both. In psychoeducational tests, different statistical approaches, like structural equation models, can combine the measurement models of computational scores and the relations to be analyzed from a substantive point of view. We think that promoting the use of psychometrics to evaluate computational assessments is also a good practice. Specifically, the same scheme could be applied to observable measures derived from constructed responses; computational indicators (textual properties) are related to constructs, and such relations have an underlying measurement model. <ref type="bibr" target="#b10">Chapelle and Voss (2017)</ref> remarked that the technological advances in language testing and other natural language-processing evaluations need to show their comparability with other classic psychoeducational tests to improve the current approaches to language assessment (note a similar rationale behind how the term "validity" changed for language assessment in <ref type="bibr" target="#b8">Chapelle, 1999)</ref>. While there is an important relation between technological advances and language assessment (e.g., <ref type="bibr" target="#b9">Chapelle &amp; Voss, 2016</ref><ref type="bibr" target="#b111">, 2021)</ref>, it needs to continuously improve the design of computer-assisted language tests and the ways to demonstrate their validity. In this regard, natural language processing (NLP) research and other advances in language testing systematically lack empirical tests of measurement models. Usually, single computational measures are used as predictors in NLP research as direct indicators of constructs. However, even in a more suitable scenario where different computational scores are added to generate a sum score, researchers would be losing statistical power due to strict constraints imposed on their underlying measurement models (e.g., <ref type="bibr" target="#b69">McNeish &amp; Wolf, 2020;</ref><ref type="bibr" target="#b89">Rhemtulla, 2016)</ref>. Thus, finding evidence in favor of the underlying measurement model of the computational indicators is a way to not only validate the measures of an automatic system but also set the cornerstone of the measurement with important advantages compared with, for example, the sum of the scores due to their strict constraints <ref type="bibr" target="#b69">(McNeish &amp; Wolf, 2020)</ref>. Furthermore, from a theoretical standpoint, it may not be possible to justify the use of computational scores to measure academic skills in the absence of a clear measurement model (e.g., the sum of computational scores could only be justified if there is an underlying unidimensional model or a similar factor structure). Among all the decisions that can be made to design psychoeducational assessment tasks involving automated scoring, <ref type="bibr" target="#b7">Carr (2008)</ref> remarked that the most important one is to stay focused on the target constructs. Accordingly, measurement models can provide different validity evidence supporting the use of different computational methods, like Inbuilt Rubric, for evaluating various general and specific skills. As previously stated, to the best of our knowledge, only some works have recognized that it is mandatory to gain reliability and validity for the development of computational methods and other computermediated technologies (e.g., <ref type="bibr" target="#b3">Attali, 2014;</ref><ref type="bibr" target="#b4">Bejar et al., 2016;</ref><ref type="bibr" target="#b8">Chapelle, 1999;</ref><ref type="bibr">Chapelle &amp; Voss, 2021;</ref><ref type="bibr" target="#b46">Koskey &amp; Shermis, 2014;</ref><ref type="bibr" target="#b92">Rupp, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The present study</head><p>In summary, topics can be imposed a priori onto vector space models using techniques such as the Inbuilt Rubric method. It transforms the original vector space into a semantic space that maps the content of an assessment rubric designed by human raters. This method is used to create a system that identifies indicators from constructed responses and infers constructs of the student knowledge on these topics. In this regard, we aim to extend two different approaches for this method. First, we aim to validate a new hierarchical LSA vector space, generated using the bifactor Inbuilt Rubric method, to evaluate constructed responses in psychoeducational assessments. It is hypothesized that hierarchical models, like the bifactor Inbuilt Rubric, can increase the validity of computational assessments evaluating general and specific knowledge in vector space models. Thus, the general dimension in the vector space model is presumed to distill the semantic meaning of the specific concept dimensions. Second, we seek to evaluate a new approach that uses nouns embedded in the fragments of the instructional text, which is less demanding and more automatic than selecting lexical descriptors by consensus. For this purpose, two parallel processes of validation for the assessment of constructed responses will be conducted for the rubric assessments of human raters and the computational scores of the Inbuilt Rubric method. Both measurements were designed to fulfill the same task, and we will evaluate (a) whether they present similar factor structures (i.e., to evaluate the underlying measurement models, namely related factors and bifactor structure), and (b) the convergent and discriminant validity of computational scores from a substantive point of view.</p><p>To do so, we aim to combine psychometrics, e.g., the use of measurement models, with the remarkable potential of computational assessment. It is known that computational methods can be affordable predictors of some behaviors or psychological phenomena. However, we need to provide empirical evidence for their validity. We think that promoting the use of psychometric techniques to evaluate computational assessments is a good practice for validating computational methods.</p><p>Thus, the objective of the present study is to validate the computational scores of different versions of the Inbuilt Rubric method, showing how common psychometric approaches can present different validity evidence for psychoeducational computational assessments. The specific objectives of this study are threefold: (1) to validate an alternative version of the Inbuilt Rubric method that does not require the selection of lexical descriptors (taking advantage of the vector representation of all the nouns within fragments of the instructional text), (2) to test whether the bifactor Inbuilt Rubric method is capable of increasing the convergent and discriminant validity of the computational scores as it distills the meaning of target concepts in the vector space, and (3) to show how psychometric measurement models can properly validate the automatic assessment of constructed responses. All these objectives are put to the test using human rater assessments as validity criteria. In the present study, we will analyze the construct validity of human rater scores using exploratory factor analyses (EFAs). Then, the human measurement models will be imposed onto the computational scores of the Inbuilt Rubric method using confirmatory factor analyses (CFAs). Both human and computational measurement methods were designed to fulfill the same topicdetection task, and they have the same hypothetical factor structures. Moreover, convergent and discriminant validity will be tested considering the measurement model of computational scores by means of SEM. A higher convergent and discriminant validity is expected using SEM and the bifactor Inbuilt Rubric as these procedures are supposed to distil the raw computational assessments of the target concepts. It is worth mentioning that, although this study was conducted in the Spanish language, the proposed scheme is language-independent and applicable to any language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>A total of 205 Spanish undergraduate students (including 175 women; the average age was 20 years) took part in this study. They were tasked with summarizing three texts in approximately 250 words each (the mean length was 251 words per summary). Students were recruited voluntarily and received course credit for their participation in the present study. While the number of women was larger than that of men in the sample, no relevant differences were found between them concerning the length of their summaries or their performance (see the first section of "Results"). The open data set including student summaries and human rater evaluations are available in the OSF repository of this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruments</head><p>Texts Three Spanish expository texts were selected for the present study. The difficulty levels of the instructional texts were evaluated using two different criteria. First, they were evaluated according to the Spanish descriptors of each mastery skill from the Curriculum Plan of the Cervantes Institute (established by the Common European Framework of Reference for Languages, CEFR). Second, they were evaluated using different readability indices of Coh-Metrix-Esp <ref type="bibr" target="#b83">(Quispesaravia et al., 2016)</ref>, which is a Spanish adaptation of Coh-Metrix <ref type="bibr" target="#b26">(Graesser et al., 2004</ref><ref type="bibr" target="#b27">(Graesser et al., , 2011;;</ref><ref type="bibr" target="#b68">McNamara et al., 2014)</ref>. The 45 readability indices of Coh-Metrix-Esp for each text are available in the OSF repository of this study.</p><p>Text 1 is called Darwin's Theory of Evolution <ref type="bibr" target="#b2">(Asimov, 1969)</ref>. This text is approximately 1300 words long and describes how Darwin was influenced by other authors and how he developed his theory of evolution. Its difficulty corresponds to level B2 in the CEFR. Text 2 is titled Strangler Trees <ref type="bibr" target="#b82">(Peiro, 1972)</ref>. This text is approximately 500 words long and discusses how species of trees compete for alimentary resources to survive. The text's difficulty was level B1-B2 in the CEFR. Text 3, called Language Evolution (Martín-Loeches, 2016), is approximately 900 words long and presents different theories of the evolution of language. Its difficulty corresponded to level C1 in the CEFR.</p><p>In the Results section, it is noted that Text 1 and Text 3 did not present important differences in terms of their difficulty. However, the performance of Text 2 was higher than that of the other texts. This could be a substantive result, as Text 2 would be an easy instructional text for undergraduate students since it was originally designed for secondary education students as part of a standardized evaluation test <ref type="bibr" target="#b52">(León et al., 2012)</ref>.</p><p>Assessment rubrics Assessment rubrics were designed by following inductive criteria. First, different human raters read the instructional texts and generated ideal summaries. These ideal summaries were then used to extract common and necessary topics from each instructional text by consensus (these conceptual axes have been previously validated in <ref type="bibr" target="#b61">Martínez-Huertas et al., 2018</ref><ref type="bibr">, 2019</ref><ref type="bibr" target="#b111">, 2021)</ref>. Thereafter, an assessment rubric with different conceptual axes was created for each instructional text. Each conceptual axis considered the inclusion of some sub-topics and a coherent discourse following the criteria established by <ref type="bibr" target="#b36">Jonsson and Svingby (2007)</ref> and <ref type="bibr" target="#b51">León et al. (2006)</ref>. These scores of the conceptual axes ranged from 0 (indicating the absence of the target concept) to 2 (representing coherent and comprehensive explanation of the concept). For example, the evaluation of a conceptual axis (concept) of an instructional text would be as follows: a summary that does not mention the concept would receive a zero along the conceptual axis; a summary that gives a full explanation for it-summarizing all the relevant aspects of the original text-would receive the maximum score; and that which provides an incomplete or incoherent explanation of the concept would receive an intermediate score. The total score can be computed for each assessment rubric by adding all the scores of the conceptual axes. The conceptual axes (concepts) that should be included in good summaries were used to compound the following assessment rubrics:</p><p>The rubric for Text 1 comprised five concepts: Earth's age (with a maximum score of 2 points in the rubric), Lamarck (max = 2), Darwin's expedition (max = 2), Darwin's theory (max = 3), and Transcendence (max = 1). The rubric for Text 2 included four concepts: Contextualization of the text (max = 2), Process of strangulation (max = 2), Competition between the trees for reaching sunlight (max = 2), and Strategy of survival (max = 2). The rubric for Text 3 was composed of five concepts: Debate (max = 2), Phonology (max = 2), Syntax (max = 2), Semantics (max = 2), and Symbol (max = 2).</p><p>Note that two concepts, namely Darwin's theory and Transcendence of Text 1, received a different score range due to their differential representativeness in the instructional text, but it did not compromise the results of the present study, as they are based on factor scores. <ref type="bibr" target="#b15">Dawson (2017)</ref> provided a synthesis of the diversity of rubrics to frame the instrument in each study. According to Dawson's design elements, the assessment rubrics employed in this study would be task-specific (it assesses specific instances in particular course units), with an analytic scoring strategy (using individual criteria, combined to generate overall scores), evaluative criteria (distinguishing acceptable responses from unacceptable responses), and different levels of quality based on quality definitions (descriptors define the performance of individuals). Designed to conduct evaluation within experimental research, ensuring its reliability and validity, other characteristics of these rubrics are secrecy (the rubric was only shared with the participants after the evaluation) and high judgement complexity without exemplars or accompanying feedback information. We propose that the Inbuilt Rubric method scores could have the same characteristics (but both the human rater and computational scores could also be used to provide accompanying feedback information).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LSA´s semantic space</head><p>The initial linguistic corpus was composed of 455,969 documents (paragraphs) from a random sample of the Spanish Wikipedia. A total of 70,244 unique terms were processed to generate a latent semantic space. Log-entropy was used as the weighted function (see <ref type="bibr" target="#b73">Nakov et al., 2001</ref>, for the use of this measure in LSA), and a total of 300 dimensions were imposed onto the latent semantic space following standard criteria <ref type="bibr">(Evangelopoulos et al., 2012)</ref>. This latent semantic space was later transformed using different versions of the Inbuilt Rubric method (the version with predefined lexical descriptors and the one with nouns embedded in the fragments of the instructional text). Both versions are generated by filling the first columns of matrix β with four or five meaningful vectors (representing sets of descriptors or fragments in Text 2 and Texts 1 and 3, respectively) and the remaining columns with 295 or 296 dimensions of the original latent semantic space to obtain the original dimensionality (in this case, 300 dimensions). Then, matrix β is orthogonalized via the Gram-Schmidt method to obtain a new basis. A correlation is calculated in the orthogonalization process to confirm that the orthogonalized meaningful vectors of β correlate with their non-orthogonalized version (0.80 or more was considered reliable). After this, a change of basis from the original latent standard basis to the basis represented by β is carried out (it is a simple rotation). The objective is to have all the words of the space (the term matrix) expressed in the β basis<ref type="foot" target="#foot_4">foot_4</ref> .</p><p>Afterward, the concepts of the constructed responses are identified and projected onto the new meaningful space. Gallito Studio software <ref type="bibr" target="#b38">(Jorge-Botana et al., 2013)</ref> was used to implement both corpus training and the Inbuilt Rubric method. It is worth mentioning that the bifactor Inbuilt Rubric method incorporates an additional vector in the meaningful part of the β matrix. This additional vector is the vector denoting the general factor of a factor analysis with the descriptors or the nouns embedded in the fragments of the instructional text (see Jorge-Botana et al., 2019, for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Students were recruited and tasked with summarizing three expository texts. The order of presenting the instructional texts was randomized for each participant. Then, two human raters evaluated the summaries made by the students using the rubrics described in the Instruments section. Human assessments were performed before any computational evaluation, and both human raters independently rated the student summaries (blind assessment). These human rater evaluations are available in the OSF repository of this study (see the Open Practices Statement).</p><p>As mentioned, two different versions of the Inbuilt Rubric method were tested in the present study. The first version is the original one that involves transforming the latent semantic space using lexical descriptors predefined by human raters. Table <ref type="table" target="#tab_0">1</ref> presents the lexical descriptors for each conceptual axis (these lexical descriptors were proposed by human raters who participated in other studies and were previously validated in <ref type="bibr" target="#b61">Martínez-Huertas et al., 2018</ref><ref type="bibr">, 2019</ref><ref type="bibr" target="#b111">, 2021)</ref>. Besides previous empirical validation, the quality of the lexical descriptors was evaluated by analyzing the semantic neighborhood of their vector representation, and usually three descriptors per concept are enough to accurately represent the concept for automated summary evaluation <ref type="bibr" target="#b61">(Martínez-Huertas et al., 2018)</ref>. The second version of Inbuilt Rubric is more automatic and does not require decision-making concerning the lexical descriptors. In this case, the latent semantic space was transformed using all the nouns embedded in the fragments of the instructional texts (see Fig. <ref type="figure" target="#fig_0">1</ref>). This method is similar to other previous methods for content-detection tasks such as partial content similarity or partial golden summaries <ref type="bibr" target="#b17">(Dessus &amp; Lemaire, 1999;</ref><ref type="bibr" target="#b23">Franzke et al., 2005;</ref><ref type="bibr" target="#b42">Kintsch et al., 2007;</ref><ref type="bibr" target="#b58">Magliano &amp; Graesser, 2012;</ref><ref type="bibr" target="#b63">Martínez-Huertas et al., 2021)</ref>. This procedure results in a vector having different numbers of nouns for each concept to be evaluated. The latent semantic space was then transformed into a new meaningful one using both versions of the Inbuilt Rubric method (i.e., the version with predefined lexical descriptors and the one with nouns embedded in the fragments of the instructional text). In addition, a vector that represents a general factor was added to matrix β of both versions in the bifactor Inbuilt Rubric method. This means that we put to test four configurations of Inbuilt Rubric defined by the following dyads: descriptors/ fragments and with/without general factor. All the student summaries and lexical descriptors were lemmatized before conducting the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis</head><p>Different statistical analyses were performed to present validity evidence for the scores given by human raters and different versions of the Inbuilt Rubric method. The analyses of the human rater scores were conducted to demonstrate the reliability and validity of the human evaluations, which are the dependent variables of the study. The analyses of the scores of different versions of the Inbuilt Rubric method were performed to show the validity of the raw computational scores. Subsequently, different approaches were used to test both the underlying measurement models of the computational scores and their convergent and discriminant validity predicting the human rater scores. All the statistical analysis were performed in R software (R Development Core Team, 2019). First, the inter-rater reliability was estimated through intraclass correlation coefficients (ICCs) <ref type="bibr" target="#b98">(Shrout &amp; Fleiss, 1979)</ref>, using a two-way mixed effects model in the psych package <ref type="bibr" target="#b88">(Revelle, 2018)</ref>. The inter-rater reliability was estimated for both the evaluation of concepts and the total scores of the rubrics of human raters. ICC results were assessed based on classic criteria <ref type="bibr" target="#b12">(Cicchetti, 1994)</ref>. Second, additional analyses were carried out to show the equivalence of the instructional texts. Different paired t tests and Cohen's d were conducted to compare the mean length (number of words) of the student summaries between texts, and the same analyses were performed comparing the mean performance. These results were replicated in the comparison of women and men. Also, both dependent variables were related with the Pearson correlation coefficients. Third, Horn's parallel analyses (scree plots) were conducted to retain the optimal number of factors of human rater scores using R's psych package. The empirical eigenvalues (using principal components) were compared with those simulated via Monte Carlo simulation. We retained the factors whose empirical eigenvalues exceeded the 95th percentile of the simulated ones (PA 95 ) <ref type="bibr" target="#b24">(Glorfeld, 1995;</ref><ref type="bibr" target="#b109">Weng &amp; Cheng, 2005)</ref>. Fourth, once the number of factors was determined by parallel analyses (scree plots), EFAs were carried out using R's psych package to analyze the factor structure of human rater scores. Maximum likelihood (ML) estimator and oblimin rotations were used to estimate these models to ease the interpretability of the factor loadings. These analyses were done for each text to validate the human rater scores, the validity criteria for computational scores in this study.</p><p>After the human assessments were done and validated, the computational scores were calculated, and different statistical analyses were performed to test their performance. In this way, different multiple linear regression models were estimated with R's lm base function to analyze the convergent and discriminant validity of the raw Inbuilt Rubric method scores using human rater scores as criteria (human criteria were computed here as the factor score of EFAs). These results were used to validate the version of the Inbuilt Rubric method with nouns embedded in the fragments of the instructional text. Finally, SEMs were applied to test the convergent and discriminant validity of computational scores, considering their measurement models using the lavaan package <ref type="bibr" target="#b91">(Rosseel, 2011)</ref>. CFAs and SEMs were estimated using unweighted least squares 7 (ULS), and standard cutoff criteria were applied to evaluate models' fit to the data. Recommendations from <ref type="bibr" target="#b6">Byrne (2012)</ref> were followed: first, we tested the measurement models of the scores given by the human raters and the two versions of the Inbuilt Rubric method using CFAs for each instructional text; second, we tested the whole SEM model for each instructional text. In this study, two different measurement models were used with human rater scores, namely correlated factors for concepts and the bifactor model. Inbuilt Rubric's validity was evaluated using the correlated factors in human rater assessments, whereas the bifactor Inbuilt Rubric's validity was evaluated with the bifactor model in human rater assessments. The model fit of all the factor analyses was assessed using standard criteria for χ 2 tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Validation of human rater scores</head><p>The following analyses were performed using the human rater assessments to present validity evidence in favor of their use as dependent variables of the study. Table <ref type="table" target="#tab_1">2</ref> provides inter-rater reliability (ICCs) for human raters. According to classic criteria <ref type="bibr" target="#b12">(Cicchetti, 1994)</ref>, all ICCs are good to excellent (except for C4 of Text 3 that only obtained a moderate ICC). The most common use of these ICCs is to evaluate the total assessment scores, but we also wanted to show that the assessments of the concepts were reliable even when the variance of these scores was much smaller. Inter-rater reliability can be considered appropriate for both the total scores and different concepts of each instructional text. This result shows that the human rater assessments were reliable.</p><p>Additional analyses were conducted to test potential differences in the results due to the different lengths of the instructional texts. Although the participants were asked to make summaries of 250 words, the length (number of words) of the student summaries was found to be different for each instructional text. The mean length per summary was 279 words (SD = 58.7) for Text 1, 213 words (SD = 49.5) for Text 2, and 261 words (SD = 59.2) for Text 3. The length of the summaries of Texts 1 and 3 was similar (t(204) = 4.86, p &lt;.001, Cohen's d = .34). On the contrary, Text 2 had significantly shorter summary lengths than Text 1 (t(204) = 15.41, p &lt;.001, Cohen's d = 1.08) 7 Maximum likelihood estimator showed appropriate model fit for CFAs of human rater scores, but the models did not converge for the Inbuilt Rubric method scores. Some differences between maximum likelihood and ordinary least squares methods have been associated with weak common factors, and the latter is recommended when substantial differences are found (e.g., <ref type="bibr" target="#b5">Briggs &amp; MacCallum, 2003)</ref>. This lack of common factors for the computational scores could be attributed to the Gram-Schmidt algorithm used to generate Inbuilt Rubric scores. The mean performance was higher for Text 2 because it was an easier instructional text (see the Instruments section), but this was not the case with summary length, as it had shorter student summaries. It was also found that the larger summaries tended to obtain higher total scores than the shorter ones (the Pearson correlation coefficient between the summary length and the total score was .59 for Text 1, .57 for Text 2, and .58 for Text 3).</p><p>Additionally, given that the number of women was larger than that of men in the sample, their differences were examined in terms of their summary length and performance. The mean number of words per summary by women was 278 (SD = 60. ). Thus, no relevant differences were found between their summary length or performance.</p><p>To show and validate the measurement model of the human rater assessments, a parallel analysis (scree plot) and an EFA were performed. The former analysis was conducted to extract the appropriate number of factors for the human rater assessments, while the latter was done to present the actual factor structure of the latent factors. Parallel analysis (scree plots) results for human rater scores are provided in Fig. <ref type="figure">3</ref>. The number of underlying factors of human rater scores corresponds with the number of evaluated concepts in Text 1 and Text 2 according to the number of components and the number of factors of parallel analyses (that is, five and four factors were underlying their variance structure respectively). On the other hand, results for Text 3 showed a discrepancy: the number of underlying factors was five, and the number of components was three. In Text 3, three factors were retained using a more conservative criterion to avoid spurious factors/components.   Fig. <ref type="figure">3</ref> Parallel analysis (scree plots) for the scores of human raters in each text. Note: The comparisons of factor analysis (FA) actual data and factor analysis (FA) simulated data in scree plots revealed the underlying factor structures of human rater scores for each text Table <ref type="table" target="#tab_3">3</ref> presents the standardized factor loadings (pattern matrix) for EFAs of human rater scores. A good factor structure was found with regard to the concepts of the instructional text (which is in accordance with the hypothetical factors suggested by the design of the measurement model). The fit of the models was good for Text 1 (root mean square error of approximation-RMSEA [90% confidence interval-CI] = .033 [.000-107], Tucker-Lewis index-TLI = .99, root mean square of residuals RMSR = .01), and Text 2 (RMSEA [90% CI] = .061 [.000-.164], TLI = .957). On the contrary, the model fit for Text 3 was poor (RMSEA [90% CI] = .197 <ref type="bibr">[.170-.226</ref>], TLI = .549). These analyses were interpreted as a description of the factor structure of the measures. The standardized factor loadings show that the concept evaluations by the human raters have sufficient factorial validity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple linear regressions to evaluate the raw scores of the Inbuilt Rubric method</head><p>In this section, we tested the convergent and discriminant validity of the raw computational scores obtained by the Inbuilt Rubric method 8 . For this purpose, a multiple linear regression was computed for each concept. Here, the mean human rater assessment for each concept was used as a dependent variable (HR C1-HR C5), and the performance of the different meaningful dimension scores of the Inbuilt Rubric method were included as covariates and evaluated through the standardized β coefficients (β 1 -β 5 ). Table <ref type="table" target="#tab_4">4</ref> lists the standardized β coefficients of different multiple linear regressions predicting the scores by human raters using the computational scores. Good convergent and discriminant validity was observed for both versions of Inbuilt Rubric in Text 1 and Text 2. It is worth mentioning here that, although they correct measure the target concepts, some standardized β coefficients are not very high (e.g., standardized β = .06). In Text 3, the first human concept (HR C1) was mainly measured by the first dimension (β 1 ), whereas the third human concept (HR C3) was mainly measured by the last dimension (β 5 ). The rest of the dimensions (β 2 , β 3 , β 4 ) measured the second human concept (HR C2). These results are useful to validate and show the equivalence of the performance of the Inbuilt Rubric method with nouns embedded in the fragments of the instructional text, compared with the classic Inbuilt Rubric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural equation models to evaluate the scores of the Inbuilt Rubric method</head><p>Previous section showed the convergent and discriminant validity of the raw computational scores of the two versions of the Inbuilt Rubric method. In this section, we examine whether it is possible to improve the performance of these computational scores considering their measurement models by means of SEMs. SEMs are a multivariate statistical technique that allows one to analyze multiple and interrelated dependencies between the measured 8 Additionally, we computed Pearson correlation coefficients between the Inbuilt Rubric method scores generated with two random partitions of the original semantic space as a proxy of their reliability. For this purpose, we generated two linguistic corpora randomly splitting the Spanish Wikipedia corpus. We transformed each of these semantic spaces into its corresponding meaningful semantic space, namely classic/bifactor and descriptors/fragments for each of the three instructional texts. This makes a total of 24 new semantic spaces that were used to compute the reliability estimates as Pearson correlation coefficients between the Inbuilt Rubric method scores. We evaluated the summaries using these new meaningful semantic spaces and then we correlated the scores of both random semantic spaces. Pearson correlation coefficients showed reliable Inbuilt Rubric method scores. These results can be found in the OSF project of this paper.</p><p>constructs in their structural part. In this study, such multiple and interrelated dependencies were used to evaluate the convergent and discriminant validity of the Inbuilt Rubric method scores, taking into account their measurement models. Here, the endogenous factors were measured by the human rater assessments (HR C1-HR C5), and the exogenous ones were measured by the Inbuilt Rubric method scores (IR C1-IR C5). Recommendations from Byrne (2012) were followed to test these SEMs. First, the measurement models of the human raters and the Inbuilt Rubric method scores were tested using CFAs. Second, the convergent and discriminant validity of the computational scores was evaluated with SEM by estimating all the crossloading parameters between the Inbuilt Rubric and human rater concept factors. Specifically, measurement models were tested with CFAs for human raters and the Inbuilt Rubric method scores in each text. Table <ref type="table" target="#tab_5">5</ref> presents the model fit of CFAs. As expected from the EFA results, model fits for all human rater scores were excellent. Also, model fits for the Inbuilt Rubric method scores were good. Text 3 had a relatively worse model fit than that of the other instructional texts for both human rater and computational scores.</p><p>Then, a SEM was fitted to analyze the convergent and discriminant validity of the Inbuilt Rubric method scores for each instructional text. A good model fit was found for Text 1 (χ 2 (135) = 186.206, CFI = .976, TLI = .967, RMSEA [90% CI] = .043 [.026-.058], SRMR = .066), Text 2 (χ 2 (84) = 65.427, CFI = 1.00, TLI = 1.00, RMSEA [90% CI] = .000 [.000-.011], SRMR = .049), and Text 3 (χ 2 (159) = 452.593, CFI = .876, TLI = .852, RMSEA [90% CI] = .095 [.085-.105], SRMR = .103). Figure <ref type="figure" target="#fig_6">4</ref> shows the standardized results regarding the structural part of each SEM. As it can be seen, the convergent and discriminant validity was very good across all instructional texts (that is, the highest regression weights were the expected ones, and the other cross-loadings were not large). Moreover, an increase in effect sizes was observed for some concepts compared with the results of raw computational scores. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural equation models to evaluate the scores of the bifactor Inbuilt Rubric method</head><p>The previous section tested the convergent and discriminant validity of computational scores of the two versions of Inbuilt the Rubric method within a latent framework. In this section, we examine the convergent and discriminant validity of the computational scores of the bifactor Inbuilt Rubric method. While the measurement model of the classic Inbuilt Rubric method has a first-order factor structure, the measurement model of the bifactor Inbuilt Rubric method has a bifactor structure. Again, the endogenous factors were measured by the human rater assessments (HR C1-HR C5), and the exogenous ones were measured by the Inbuilt Rubric method scores (IR C1-IR C5). The observed measures or indicators load onto a general factor representing their common variance, and the correlations between specific factors were imposed to be zero. We also followed the recommendations from <ref type="bibr" target="#b6">Byrne (2012)</ref> for testing SEMs. First, we tested the bifactor structure for human rater scores. Then, we generated a SEM for each text where we included the latent factors of the specific factors and the observed variables of the general factor of this version of Inbuilt Rubric. In this model, the observed general scores of the bifactor Inbuilt Rubric method were used to predict the general latent factor of the human rater scores, and a covariance parameter was included between the general scores of the computational scores. Thus, we evaluated the convergent and discriminant validity of the bifactor Inbuilt Rubric method scores with SEM by estimating all the cross-loading parameters between the bifactor Inbuilt Rubric and human rater concept   Table <ref type="table">6</ref> presents the results concerning the structural part of each SEM. The convergent and discriminant validity was excellent across all instructional texts (that is, the highest regression weights were the expected ones). An increase in effect sizes can be observed for some concepts 9 . promising proposal is to make the technological advances in language testing and other natural language-processing tasks comparable to classic psychoeducational tests (see, for example, different rationales behind how the term "validity" have changed for language assessment scheme: <ref type="bibr" target="#b8">Chapelle, 1999;</ref><ref type="bibr" target="#b10">Chapelle &amp; Voss, 2017)</ref>. In this line, the automatic assessment of constructed responses can be useful to infer different constructs from a big set of indicators (e.g., <ref type="bibr" target="#b22">Foltz et al., 2013)</ref>. It also can have different levels of analysis supported by highly complex predictive models. For instance, in the case of topic detection, good performance has been achieved with supervised models in different tasks (e.g., <ref type="bibr" target="#b31">Hashimoto et al., 2016;</ref><ref type="bibr" target="#b50">Lee et al., 2006;</ref><ref type="bibr" target="#b54">Li et al., 2015;</ref><ref type="bibr">Li et al., 2016b, b)</ref>. However, supervised models cannot be implemented without having training sets of hundreds or thousands of pre-scored samples, and this is a time-demanding task <ref type="bibr" target="#b18">(Dronen et al., 2015)</ref>. In this regard, the main advantage of the Inbuilt Rubric method is that it does not need such pre-scored samples of constructed responses <ref type="bibr" target="#b39">(Jorge-Botana et al., 2019;</ref><ref type="bibr" target="#b61">Martínez-Huertas et al., 2018</ref><ref type="bibr">, 2019</ref><ref type="bibr" target="#b111">, 2021;</ref><ref type="bibr" target="#b79">Olmos et al., 2014</ref><ref type="bibr" target="#b80">Olmos et al., , 2016))</ref>. In this method, a rational expert criterion (here, an assessment rubric in psychoeducational assessment) is imposed onto the vector space. For this reason, it is cheaper and more versatile than supervised models. It is cheaper since it is not time-demanding and versatile since rubric designers can change the concepts and descriptors of the rubric. In addition, the Inbuilt Rubric is well suited for feedback systems in which part of the feedback information could be a function of the scores in each concept dimension of the vector space. For these reasons, it enables early deployment with further refinements. Nonetheless, it is suggested to test the Inbuilt Rubric configurations to gather validity evidence to ensure that these non-supervised implementations are consistent. Accordingly, one aim of this study was to use a standard psychometric approach like SEM to validate the assessments of the Inbuilt Rubric method by testing their measurement models and performance within a latent framework. Good convergent and discriminant validity evidence with human rater scores was observed for these computational assessments. It was also noted that the factor structures of the scores given by human raters and the Inbuilt Rubric method were equivalent. This is a very important construct validity evidence for computational scores. In fact, the measurement models of computational scores were found to improve the convergent and discriminant validity of the raw computational scores by means of SEM (as the raw computational scores lead to attenuated relationships by not adjusting for measurement errors). While different validity evidence, like fitting the underlying factor structure, is usually required to verify the scores of psychological tests, many NLP psychoeducational research does not consider their measurement models. In fact, to the best of our knowledge, it is not very common to empirically test them when using computational scores. In this way, much NLP research use computational measures as direct indicators of constructs imposing strict concerns on them as they do not consider their factor structure. This study exemplifies the potential of classic psychometrics to sort computational scores within a coherent frame with observable properties and inferred skills. The direct consequence is that we can jointly obtain reliability and validity evidence, with the latter being one of the most important objectives in validating computational assessments <ref type="bibr" target="#b3">(Attali, 2014;</ref><ref type="bibr" target="#b4">Bejar et al., 2016;</ref><ref type="bibr" target="#b46">Koskey &amp; Shermis, 2014;</ref><ref type="bibr" target="#b92">Rupp, 2018)</ref>. Testing the measurement models in relation to empirical data allows one to obtain guarantees about the constructs that are intended to be measured. Even more importantly, they can improve methods' performance for further deployments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note</head><p>Another aim of the present work was to validate an alternative version of the Inbuilt Rubric method that uses nouns embedded in fragments of instructional text. This alternative procedure does not require the selection of lexical descriptors, thus avoiding a very systematic and thorough task wherein lexical descriptors are established by consensus. It was found that nouns embedded in the fragments of the instructional text can be an affordable alternative to use in the Inbuilt Rubric method when one wants to avoid decisions about the selection of lexical descriptors by consensus (it is a more automatic procedure). Selecting text fragments that represent the target concepts to be evaluated generates different possibilities, including using text fragments or definitions of concepts, that should be evaluated in future research. One limitation of this study is that, while there are many other potential ways of using the Inbuilt Rubric method, only text fragments were used to illustrate it. In any case, these text fragments can be part of the instructional text or other educational materials, allowing the generation of meaningful semantic spaces using more complex information than lexical descriptors. In this regard, these findings could complement extractive summarization in the future. Given that fragments from the source text are automatically extracted using some crucial parameters <ref type="bibr" target="#b81">(Ozsoy et al., 2011;</ref><ref type="bibr" target="#b99">Steinberger &amp; Jezek, 2004)</ref>, the Inbuilt Rubric method could determine whether, for example, the selected fragments are important and sufficiently non-redundant <ref type="bibr" target="#b44">(Kireyev, 2008;</ref><ref type="bibr" target="#b105">Vargas-Campos &amp; Alva-Manchego, 2016)</ref>. This would be a fully automatic procedure to use in this computational method. In this vein, the present study only used nouns as representative information conveying the semantic context of the target concepts within expository texts. However, other types of information (e.g., concerning verbs, adverbs, determinants) can also be used to transform the vector space. A clear example of the importance of verbs and similar types of information for construct representations within narratives, among others, is the event-indexing model <ref type="bibr" target="#b113">(Zwaan et al., 1995)</ref>. The evidence in favor of this model showed how multilevel and multidimensional memory representations of narratives are indexed based on time, space, protagonist, causality, and intentionality <ref type="bibr" target="#b113">(Zwaan et al., 1995)</ref>. Transforming vector spaces using these multidimensional models opens the door for future research into the representations of different types of texts, like narrative texts or natural language conversations, from a computational point of view. In fact, verbal and other types of measures already play a crucial role in systems such as Coh-Metrix to automatically score texts and essays <ref type="bibr" target="#b27">(Graesser et al., 2011)</ref>, with verbs being an especially relevant indicator of text difficulty <ref type="bibr" target="#b67">(McNamara et al., 2012</ref><ref type="bibr" target="#b68">(McNamara et al., , 2014))</ref>. Thus, while nouns embedded in fragments of instructional text seem to be an affordable means of assessing expository texts using the Inbuilt Rubric method, it is worth examining other substantive approaches from a theoretical perspective.</p><p>A third aim was to test whether the bifactor Inbuilt Rubric method (Jorge-Botana et al., 2019) could increase the convergent and discriminant validity of the computational scores with a general knowledge factor in the vector space. Results showed that this general factor can distill the common variance of the concepts of the vector space. Thus, the bifactor Inbuilt Rubric method is well suited for the assessment of general knowledge and could increase the validity of these computational scores. It presented higher convergent and discriminant validity than the raw computational scores and the original Inbuilt Rubric method in some concepts. In this context, imposing a general factor in the vector space increased the "distillation" of specific scores. It seems that the use of hierarchical models, such as bifactor models <ref type="bibr" target="#b86">(Reise, 2012;</ref><ref type="bibr" target="#b87">Reise et al., 2007;</ref><ref type="bibr" target="#b90">Rodriguez et al., 2016;</ref><ref type="bibr" target="#b112">Zhang et al., 2020)</ref>, could generate honed vector space models by means of the general knowledge factors. In any case, further research is needed on the interpretation of general knowledge factors in vector spaces, as the actual relation between the general factor of the bifactor Inbuilt Rubric and the general factor of the human raters was dependent on the version of the Inbuilt Rubric method and the instructional text. All these conclusions are directly related to psychoeducational assessments of constructed responses. However, such general dimensions may provide substantive variance to distill the modeling of other cognitive processes working as a proxy of general semantic noise to distill compositional processes (e.g., <ref type="bibr" target="#b29">Günther &amp; Marelli, 2020;</ref><ref type="bibr" target="#b60">Marelli et al., 2017)</ref> or modulate similarity judgments of concepts (e.g., <ref type="bibr" target="#b34">Ichien et al., 2021;</ref><ref type="bibr" target="#b74">Netisopakul et al., 2021)</ref>.</p><p>Various studies have tried to interpret the meaning of the vector space dimensions from an exploratory means <ref type="bibr" target="#b19">(Evangelopoulos, 2013;</ref><ref type="bibr">Evangelopoulos et al., 2012;</ref><ref type="bibr" target="#b20">Evangelopoulos &amp; Visinescu, 2012;</ref><ref type="bibr" target="#b41">Kallens &amp; Dale, 2018;</ref><ref type="bibr" target="#b47">Kundu et al., 2015;</ref><ref type="bibr" target="#b106">Visinescu &amp; Evangelopoulos, 2014)</ref>. Their approaches are interesting in promoting the use of meaningful scores from the vector space, but they are qualitatively different from the Inbuilt Rubric method, as the latter imposes the meaning of concepts onto the vector space a priori. Of course, the performance of these methods could be enhanced by machine learning approaches such as neural networks or support vector machines. In fact, machine learning and other algorithms are improving current educational schemes in different ways (e.g., <ref type="bibr" target="#b1">Alenezi &amp; Faisal, 2020;</ref><ref type="bibr" target="#b102">Vaishnavi &amp; Ravichandran, 2021;</ref><ref type="bibr" target="#b111">Zhai, 2021)</ref>. For example, one of the most popular psychoeducational technologies is AutoTutor, an intelligent tutoring system <ref type="bibr" target="#b25">(Graesser et al., 1999)</ref>. This system has been evolving over the past decade by the implementation of multiple learning resources (e.g., see ElectronixTutor by <ref type="bibr" target="#b28">Graesser et al., 2018)</ref>. Thus, machine learning and other algorithms can handle different computational assessments to generate fine-grained scores for the assessment of constructed responses. In this paper, we tried to promote the use of computational scores, like that of vector space models, for the assessment of constructed responses, considering their validity from a psychometric standpoint. This means that different psychometric properties, such as the measurement model of computational scores, should also be evaluated prior to their use in psychoeducational assessments regardless of whether they are used as direct indicators of constructs or as a part of a machine learning-based algorithm. While this study aimed to validate a method focused on the detection of semantic concepts to promote the use of meaningful semantic spaces, we would like to note that these computational methods have the potential to complement other higher-order intelligent systems for improving the evaluation of different target concepts. This is because the main facet of the Inbuilt Rubric method and other similar procedures is the validity-centered approach of its multi-vector representations. As shown in the present study, such multi-vector representations can provide useful information for psychoeducational assessments using meaningful semantic spaces with or without general factors in the hierarchical vector space.</p><p>Although the different distributional semantic models could be conceived as different parameterizations with the same capacity to model cognitive processes (e.g., <ref type="bibr" target="#b30">Günther et al., 2019;</ref><ref type="bibr" target="#b35">Jones et al., 2018;</ref><ref type="bibr" target="#b40">or Jorge-Botana et al., 2020)</ref>, future research should aim to validate the Inbuilt Rubric and the bifactor Inbuilt Rubric methods in other vector space models, as it has only been validated in the LSA. This opens the door for examining whether it is possible to impose concepts a priori without mandatory orthogonal vector spaces like that of the popular Google word2vec (e.g., <ref type="bibr" target="#b70">Mikolov et al., 2013)</ref>. Future studies should analyze the differences that could be expected between vector space models regarding both the distillation of their scores and their measurement models. The dimensions of oblique vector spaces, like the word2vec model, could have large covariances, and the general factor could thus capture a large part of substantive variance. The dimensions of orthogonal vector spaces, like those of the LSA model, do not covary, and they are expected to partially reduce such a problem. Thus far, the generation of matrix β would be the same in both types of vector space models where the resulting vector space is expected to retain the semantic properties of the original vector space even with oblique dimensions. This would be translated into a differential performance of the general factor depending on the properties of the original vector space.</p><p>Another limitation of this study is the lack of model fit for the ML estimator in the models of computational scores. While the models for human rater scores achieved appropriate model fit using the ML estimator, the models for computational scores presented multiple convergence problems when they were fitted with ML. The ULS estimator did not produce relevant differences in terms of convergence. The ML estimation method occasionally leads to convergence problems when there are several local maxima in the log-likelihood function. This is likely to occur in Pearson correlation matrices from computational methods due to their orthogonal nature. Differences between the ML and OLS methods have been associated with weak common factors, and the latter is recommended when relevant differences are found (e.g., <ref type="bibr">Briggs &amp; Mac-Callum, 2003)</ref>. Future research should investigate the performance of common estimators using different types of computational measures.</p><p>Also, it should be noted that the present study is just an illustration of the potential of the Inbuilt Rubric and bifactor Inbuilt Rubric methods in a specific educational setting. Such an illustration was made with a sample of undergraduate students who summarized three different instructional texts covering academic topics. First, only undergraduate students participated in this study. Given that the general scores of the original Inbuilt Rubric method could discriminate between different educational levels <ref type="bibr" target="#b62">(Martínez-Huertas et al., 2019)</ref>, it would have been interesting to test whether the general factor of the bifactor Inbuilt Rubric method could have different meanings in different educational levels. For example, such a general factor could reflect general knowledge in higher educational levels and a lack of knowledge in lower educational levels. Future research should experimentally test which variables affect the meaning of the general dimension. Second, only three instructional texts were used to illustrate the performance of these computational methods. While all the participants summarized the three instructional texts to gain internal validity, these computational scores were validated in an artificial educational setting, so future research should evaluate them in ecological contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>One of the main contributions of this study is that it showed how standard psychometric procedures can validate and hone computational psychoeducational assessments. This creates an opportunity to fully combine computational semantics and standard psychometrics. This approach could increase the performance of the current measurement approaches using computational semantic measures to study their relations with different psychological constructs. Future research should test other potential advantages of the combination of computational methods and psychometrics from a validity-centered approach. One of our predictions is that hierarchical models, such as bifactor models, could generate important shifts in the use of computational scores from a theoretical and a methodological point of view. Our findings using the bifactor Inbuilt Rubric method, which is a hierarchical vector space, support such conclusions and further show that there is room for improvement in the current automatic assessments of constructed responses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Example of text fragments of a hypothetical instructional text. Note: Instructional texts of this study had clear divisions for the different conceptual axes</figDesc><graphic coords="5,53.86,57.76,232.44,196.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Graphical representations of three meaningful dimensions of a Inbuilt Rubric and b bifactor Inbuilt Rubric methods. Note. C 1 -C 5 are the rubric concepts, G is the general factor, and L-L p are latent dimensions of the original vector space. Dimensionality of the result-</figDesc><graphic coords="6,53.86,57.76,487.56,220.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>and</head><label></label><figDesc>Text 3 (t(204) = 13.23, p &lt;.001, Cohen's d = .92). Similar results were found for the mean performance in each text. Mean performance was 1.16 (SD = .287) in Text 1, 1.40 (SD = .218) in Text 2, and 1.12 (SD = .253) in Text 3. The difficulty of Texts 1 and 3 was similar (t(204) = 2.08, p = .039, Cohen's d = .145). Text 2 had significantly higher performance in comparison with Text 1 (t(204) = -10.30, p &lt;.001, Cohen's d = -.719) and Text 3 (t(204) = -14.64, p &lt;.001, Cohen's d = -1.022).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>3) for Text 1, 215 (SD = 50.3) for Text 2, and 259 (SD = 56.8) for Text 3. The mean number of words per summary among men was 282 (SD = 49.2) for Text 1, 204 (SD = 44.1) for Text 2, and 275 (SD = 71.1) for Text 3. No relevant differences were observed between them in terms of Text 1 (t(203) = -.307, p = .759, Cohen's d = -.06), Text 2 (t(203) = 1.072, p = .285, Cohen's d = .211), or Text 3 (t(203) = -1.401, p = .163, Cohen's d = -.276). Regarding their performance, the mean performance of women was 1.15 (SD = .292) for Text 1, 1.41 (SD = .207) for Text 2, and 1.12 (SD = .254) for Text 3. The mean performance of men was 1.20 (SD = .254) for Text 1, 1.33 (SD = .268) for Text 2, and 1.10 (SD = .252) for Text 3. No relevant differences were noted in their performance for Text 1 (t(203) = -.804, p = .422, Cohen's d = -.158), Text 2 (t(203) = 1.849, p = .066, Cohen's d = .365), or Text 3 (t(203) = .519, p = .605, Cohen's d = .102</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Note. All ICCs were statistically significant (p&lt;.01). Reliability measures were established through ICCs using a two-way mixed effects model. Text 1 = Darwin's Theory of Evolution. Text 2 = Strangler Trees. Text 3 = Theory of the Evolution of Language. C1-C5 = Concepts 1 to 5. C5 is not available for Text 2 as only four concepts were considered for it</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>factors and adding paths to connect the observed measures or indicators of the general factor of the bifactor Inbuilt Rubric methods (IR1G, IR2G) with the general latent factor of the human rater assessments (here, HRG). The bifactor measurement models achieved appropriate model fit for Text 1 (χ 2 (39) = 93.972, CFI = .928, TLI = .917, RMSEA [90% CI] = .083 [.062-.105], SRMR = .092), Text 2 (χ 2 (23) = 49.575, CFI = .936, TLI = .922, RMSEA [90% CI] = .075 [.046-.104], SRMR = .082), and Text 3 (χ 2 (32) = 77.531, CFI = .943, TLI = .920, RMSEA [90% CI] = .084 [.060-.107], SRMR = .083). A SEM was fitted to analyze the convergent and discriminant validity of the Inbuilt Rubric method scores for each instructional text. A good model fit was found for Text 1 (χ 2 (182) = 452.178, CFI = .893, TLI = .864, RMSEA [90% CI] = .085 [.075-.095],</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Structural equation model (SEM) results (standardized solution) for each instructional text. a Text 1, b Text 2, c Text 3. Note: Only the structural part of the SEM is reported in the figure. IR C1-IR C5 = Inbuilt Rubric concept factors. HR C1-HR C5 = Human</figDesc><graphic coords="15,53.86,207.96,487.56,175.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>. IR1-IR5 = Bifactor Inbuilt Rubric concept factors. HR C1-HR C5 = Human rater concept factors. IR1G = General factor of bifactor Inbuilt Rubric with lexical descriptors. IR2G = General factor of bifactor Inbuilt Rubric with nouns embedded in fragments of the instructional text. HRG = Human rater general (bifactor) factor. HR C5 is not available for Text 2 as only four concepts were considered for it. HR C4 and HR C5 is not available for Text 3 as only three concepts were considered for it. ** = p &lt; .01. * = p &lt; .05. In bold = Best predictions (largest standardized factor loadings)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Lexical descriptors per text used to transform the latent semantic space Note. Text 1 = Darwin's Theory of Evolution. Text 2 = Strangler Trees. Text 3 = Theory of the Evolution of Language. C1-C5 = Concepts 1 to 5. Lexical descriptors were lemmatized before transforming the semantic space. These lexical descriptors were translated from Spanish</figDesc><table><row><cell></cell><cell>Concepts</cell><cell>Lexical descriptors</cell></row><row><cell>Text 1</cell><cell>Earth's age (C1)</cell><cell>Hutton Buffon earth</cell></row><row><cell></cell><cell>Lamarck (C2)</cell><cell>Lamarck characteristics acquired</cell></row><row><cell></cell><cell>Darwin's expedition (C3)</cell><cell>Beagle Galapagos finches</cell></row><row><cell></cell><cell>Darwin's theory (C4)</cell><cell>selection natural evolution</cell></row><row><cell></cell><cell>Transcendence (C5)</cell><cell>polemic biology modern</cell></row><row><cell>Text 2</cell><cell>Contextualization of the text (C1)</cell><cell>tree strangle Brasil</cell></row><row><cell></cell><cell>Process of strangulation (C2)</cell><cell>kill asphyxiation roots</cell></row><row><cell></cell><cell>Competition between the trees for reaching sunlight (C3)</cell><cell>competition lights sun</cell></row><row><cell></cell><cell>Strategy of survival (C4)</cell><cell>adaptation survival survive</cell></row><row><cell>Text 3</cell><cell>Debate (C1)</cell><cell>Evolution Neuroscience Paleontology</cell></row><row><cell></cell><cell>Phonology (C2)</cell><cell>Phonetics Articulation Deafness</cell></row><row><cell></cell><cell>Syntax (C3)</cell><cell>Syntax Sentence Macromutation</cell></row><row><cell></cell><cell>Semantics (C4)</cell><cell>Semantics Meaning Sign</cell></row><row><cell></cell><cell>Symbol (C5)</cell><cell>Symbol Abstraction Flexibility</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Inter-rater reliability (intraclass correlation coefficients; ICCs) for each concept in the assessment rubrics</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Standardized factor loadings (OBLIMIN rotation) for exploratory factor analyses of the scores of human raters in each text Note: HR1-HR2 = Human raters 1 and 2. C1-C5 = Evaluation of concepts of each instructional text. F1-F5 = Empirical factors for each text. C5 is not available for Text 2 as only four concepts were considered for it</figDesc><table><row><cell></cell><cell></cell><cell>Text 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Text 2</cell><cell></cell><cell></cell><cell></cell><cell>Text 3</cell><cell></cell><cell></cell></row><row><cell>Variables</cell><cell></cell><cell>F1</cell><cell>F2</cell><cell>F3</cell><cell>F4</cell><cell>F5</cell><cell>F1</cell><cell>F2</cell><cell>F3</cell><cell>F4</cell><cell>F1</cell><cell>F2</cell><cell>F3</cell></row><row><cell>HR1</cell><cell>C1</cell><cell>.83</cell><cell>.00</cell><cell>.08</cell><cell>-.02</cell><cell>.03</cell><cell>.64</cell><cell>.02</cell><cell>-.02</cell><cell>-.06</cell><cell>.99</cell><cell>.06</cell><cell>.03</cell></row><row><cell></cell><cell>C2</cell><cell>-.02</cell><cell>1.00</cell><cell>-.02</cell><cell>.03</cell><cell>.03</cell><cell>.12</cell><cell>.71</cell><cell>.03</cell><cell>.02</cell><cell>-.04</cell><cell>.17</cell><cell>-.04</cell></row><row><cell></cell><cell>C3</cell><cell>.03</cell><cell>.02</cell><cell>.90</cell><cell>-.03</cell><cell>.02</cell><cell>.00</cell><cell>-.03</cell><cell>1.00</cell><cell>.02</cell><cell>.03</cell><cell>.96</cell><cell>.14</cell></row><row><cell></cell><cell>C4</cell><cell>-.10</cell><cell>-.01</cell><cell>.04</cell><cell>.85</cell><cell>-.01</cell><cell>.00</cell><cell>-.01</cell><cell>.01</cell><cell>1.00</cell><cell>.06</cell><cell>.21</cell><cell>.28</cell></row><row><cell></cell><cell>C5</cell><cell>.00</cell><cell>-.02</cell><cell>.01</cell><cell>.00</cell><cell>1.00</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>.08</cell><cell>.20</cell><cell>.78</cell></row><row><cell>HR2</cell><cell>C1</cell><cell>.98</cell><cell>.00</cell><cell>-.04</cell><cell>.02</cell><cell>-.01</cell><cell>1.00</cell><cell>.00</cell><cell>.00</cell><cell>.01</cell><cell>.68</cell><cell>.04</cell><cell>.08</cell></row><row><cell></cell><cell>C2</cell><cell>.05</cell><cell>.64</cell><cell>.07</cell><cell>-.10</cell><cell>-.12</cell><cell>-.06</cell><cell>.87</cell><cell>-.01</cell><cell>.00</cell><cell>.00</cell><cell>.14</cell><cell>-.05</cell></row><row><cell></cell><cell>C3</cell><cell>-.02</cell><cell>-.02</cell><cell>.99</cell><cell>.03</cell><cell>-.01</cell><cell>-.01</cell><cell>.08</cell><cell>.72</cell><cell>-.06</cell><cell>.08</cell><cell>.63</cell><cell>.15</cell></row><row><cell></cell><cell>C4</cell><cell>.14</cell><cell>.02</cell><cell>-.02</cell><cell>.80</cell><cell>.01</cell><cell>-.01</cell><cell>.06</cell><cell>-.04</cell><cell>.69</cell><cell>.10</cell><cell>.08</cell><cell>.04</cell></row><row><cell></cell><cell>C5</cell><cell>.00</cell><cell>.01</cell><cell>.00</cell><cell>.00</cell><cell>1.00</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>.06</cell><cell>.11</cell><cell>.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>Standardized β coefficients from multiple linear regressions to detect concepts using raw scores of two different versions of the Inbuilt Rubric (IR) method Note. IR1 = Inbuilt Rubric method with lexical descriptors. IR2 = Inbuilt Rubric method with nouns embedded in fragments of the instructional text. HR C1-HR C5 = Human rater concept scores. HR C5 is not available for Text 2 as only four concepts were considered for it. ** = p&lt;.01. * = p&lt;.05. In bold = Best predictions (largest standardized β coefficients). Dependent variables were estimated factor scores of EFAs</figDesc><table><row><cell>Standardized β coefficients</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>Confirmatory factor analyses (CFAs) of human raters and Inbuilt Rubric method scores for instructional texts Note. Measurement models were fitted with ULS estimator</figDesc><table><row><cell>Text</cell><cell>Scores</cell><cell>χ 2</cell><cell>df</cell><cell>CFI</cell><cell>TLI</cell><cell>RMSEA [90% CI]</cell><cell>SRMR</cell></row><row><cell>Text 1</cell><cell>Human raters</cell><cell>17.284</cell><cell>30</cell><cell>1.00</cell><cell>1.00</cell><cell>.000 [.000-.000]</cell><cell>.039</cell></row><row><cell></cell><cell>Inbuilt Rubric</cell><cell>84.72</cell><cell>30</cell><cell>.925</cell><cell>.887</cell><cell>.095 [.071-.119]</cell><cell>.087</cell></row><row><cell>Text 2</cell><cell>Human raters</cell><cell>7.842</cell><cell>18</cell><cell>1.00</cell><cell>1.00</cell><cell>.000 [.000-.000]</cell><cell>.033</cell></row><row><cell></cell><cell>Inbuilt Rubric</cell><cell>34.738</cell><cell>18</cell><cell>.975</cell><cell>.962</cell><cell>.068 [.032-.101]</cell><cell>.069</cell></row><row><cell>Text 3</cell><cell>Human raters</cell><cell>145.436</cell><cell>34</cell><cell>.860</cell><cell>.815</cell><cell>.127 [.106-.148]</cell><cell>.114</cell></row><row><cell></cell><cell>Inbuilt Rubric</cell><cell>138.359</cell><cell>34</cell><cell>.904</cell><cell>.873</cell><cell>.123 [.102-.144]</cell><cell>.111</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>There are methods based on supervised learning algorithms using the vector representation from Bag of Words or dimensionality reduced vectors as input, but they require a reasonable large sample of text responses evaluated by human raters to train the model. For this reason, these methods are time-demanding and thus more expensive.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>There is a discipline called computational psychometrics that is, basically, a prediction-centered approach. von Davier (2015) defined it as a mix of data-driven computer science methods (such as machine learning) that are focused on the scoring of real-time abilities. Moreover, computational psychometrics does not usually apply computational models of language. Thus, this approach is significantly different from the one that we propose here, namely the combination of computational semantics and psychometrics with a validity-centered approach.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Behavior Research Methods (2022) 54:2579-2601   </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>The term "latent meaning" indicates that the semantic space and its vector representations do not have directly interpretable meanings.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>Notably, the dimensions of the original semantic space present different properties-for example, their eigenvalues. Thus, the R script of the Inbuilt Rubric method has the possibility of implementing it sequentially or non-sequentially. In the first scenario, the dimensions of matrix β are filled sequentially, that is, from the first to the kth dimension. In the second scenario, the k dimensions of matrix β are filled non-sequentially; in other words, they are randomly ordered, and a final average β matrix is computed to avoid potential bias. The performance of the sequential and non-sequential Inbuilt Rubric method versions is very similar.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors would like to thank <rs type="person">Fernando Alva-Manchego</rs> (<rs type="affiliation">University of Sheffield</rs>) for his help in computing the Coh-Metrix-Esp readability indices of our instructional texts, and <rs type="person">Olga Jastrzebska</rs> for her help in evaluating the student summaries.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>There is an important relation between technological advances and language assessment, but it needs to continually improve the design of computer-assisted language tests and the ways to demonstrate their validity. A 9 Additional analyses were conducted to determine whether the general factor of the bifactor Inbuilt Rubric method had a transverse relation with all the specific human rater factors. In these analyses, factor loadings between the general factor of the Inbuilt Rubric method and both the general and specific human rater factors were specified. These models did not converge. This could mean that the common variance is well distilled in both the Inbuilt Rubric and the human rater general factors, and that the specific factors have remarkable topic-identity.</p><p>Funding Open Access funding provided thanks to the CRUE-CSIC agreement with Springer Nature. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Access</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Abad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Olea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ponsoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>García</surname></persName>
		</author>
		<title level="m">Medición en Ciencias Sociales y de la Salud</title>
		<imprint>
			<publisher>Síntesis</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Measurement in Social and Health Sciences</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Utilizing crowdsourcing and machine learning in education: Literature review. Education and Information Technologies</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Alenezi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Faisal</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10639-020-10102-w</idno>
		<ptr target="https://doi.org/10.1007/s10639-020-10102-w" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2971" to="2986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Great Ideas of Science</title>
		<author>
			<persName><forename type="first">I</forename><surname>Asimov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
			<pubPlace>Houghton Mifflin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Validity and Reliability of Automated Essay Scoring</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Attali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Automated Essay Evaluation: Current applications and new directions</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Shermis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Burnstein</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="181" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automated Scoring with Validity in Mind</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Bejar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mislevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781118956588.ch10</idno>
		<ptr target="https://doi.org/10.1002/97811" />
	</analytic>
	<monogr>
		<title level="m">The Wiley Handbook of Cognition and Assessment: Frameworks, Methodologies, and Applications</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rupp</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Leighton</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley Blackwell</publisher>
			<date type="published" when="2016">2016. 18956</date>
			<biblScope unit="page">588</biblScope>
		</imprint>
	</monogr>
	<note>ch10</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recovery of weak common factors by maximum likelihood and ordinary least squares estimation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Briggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15327906MBR3801_2</idno>
		<ptr target="https://doi.org/10.1207/S15327906MBR3801_2" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="56" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Structural equation modeling with Mplus: Basic concepts, applications, and programming</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Byrne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Taylor &amp; Francis/ Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Decisions about automated scoring: What they mean for our constructs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Towards adaptive CALL: Natural language processing for diagnostic language assessment</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Chapelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y.-R</forename><surname>Chung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="82" to="101" />
		</imprint>
		<respStmt>
			<orgName>Iowa State University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Validity in language assessment</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Chapelle</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0267190599190135</idno>
		<ptr target="https://doi.org/10.1017/S0267" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="254" to="272" />
			<date type="published" when="1999">1999. 19059 91901 35</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Voss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20 years of technology and language assessment in Language Learning &amp; Technology. Language Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="116" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Utilizing technology in language assessment</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Voss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of language and education</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Shohamy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Or</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Science + Business Media LLCPaIn</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="149" to="161" />
		</imprint>
	</monogr>
	<note>rd Ed</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Validity Argument in Language Testing: Case Studies of Validation Research</title>
		<editor>Chapelle, C.A., &amp; Voss, E.</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Guidelines, criteria, and rules of thumb for evaluating normed and standardized assessment instruments in psychology</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Cicchetti</surname></persName>
		</author>
		<idno type="DOI">10.1037/1040-3590.6.4.284</idno>
		<ptr target="https://doi.org/10.1037/1040-3590.6.4.284" />
	</analytic>
	<monogr>
		<title level="j">Psychological Assessment</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="284" to="290" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Crossley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcnamara</surname></persName>
		</author>
		<title level="m">Automated Summarization Evaluation (ASE) Using Natural Language Processing Tools. International Conference on Artificial Intelligence in Education</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-06">2019. June</date>
			<biblScope unit="page" from="84" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Dascalu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Stavarache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dessus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Trausan-Matu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bianco</surname></persName>
		</author>
		<title level="m">Predicting comprehension from students&apos; summaries. International Conference on Artificial Intelligence in Education</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015-06">2015. June</date>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Assessment rubrics: towards clearer and more replicable design, research and practice</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dawson</surname></persName>
		</author>
		<idno type="DOI">10.1080/02602938.2015.1111294</idno>
		<idno>1080/ 02602 938. 2015. 11112 94</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Assessment &amp; Evaluation in Higher Education</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="347" to="360" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Indexing by latent semantic analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Harshman</surname></persName>
		</author>
		<idno type="DOI">10.1002/(SICI)1097-4571(199009)41:6%3C391::AID-ASI1%3E3.0.CO;2-9</idno>
		<ptr target="https://doi.org/10.1002/" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1097" to="4571" />
			<date type="published" when="1990">1990. 199009</date>
		</imprint>
	</monogr>
	<note>6% 3C391:: AID-ASI1% 3E3.0. CO;2-9</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Apex, un système d&apos;aide à la préparation d&apos;examens</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dessus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lemaire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sciences et Techniques éducatives</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="409" to="415" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective sampling for large-scale automated writing evaluation systems</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dronen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Foltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Habermehl</surname></persName>
		</author>
		<idno type="DOI">10.1145/2724660.2724661</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second (2015) ACM Conference on Learning@Scale</title>
		<meeting>the Second (2015) ACM Conference on Learning@Scale</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1145">2015. March. 1145/ 27246 60. 27246</date>
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Latent semantic analysis</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Evangelopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1002/wcs.1254</idno>
		<ptr target="https://doi.org/10.1002/wcs.1254" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="683" to="692" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Wiley Interdisciplinary Reviews</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Text-mining the voice of the people</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Evangelopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Visinescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="62" to="69" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Latent semantic analysis: five methodological recommendations</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Evangelopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Prybutok</surname></persName>
		</author>
		<idno type="DOI">10.1057/ejis.2010.61</idno>
		<ptr target="https://doi.org/10.1057/ejis.2010.61" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Information Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="86" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Implementation and applications of the intelligent essay assessor</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Foltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Lochbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Automated Essay Evaluation: Current applications and new directions</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Shermis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="68" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Summary street: computer support for comprehension and writing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Franzke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kinstch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Caccamise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dooley</surname></persName>
		</author>
		<idno type="DOI">10.2190/DH8F-QJWM-J457-FQVB</idno>
		<ptr target="https://doi.org/10.2190/DH8F-QJWM-J457-FQVB" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Computing Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="80" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An improvement on Horn&apos;s parallel analysis methodology for selecting the correct number of factors to retain</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Glorfeld</surname></persName>
		</author>
		<idno type="DOI">10.1177/0013164495055003002</idno>
		<idno>1177/ 00131 64495 05500 3002</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="393" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">AutoTutor: A simulation of a human tutor</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wiemer-Hastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wiemer-Hastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kreuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tutoring</forename><forename type="middle">Research</forename><surname>Group</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1389-0417(99)00005-4</idno>
		<ptr target="https://doi.org/10.1016/S1389-0417" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Systems Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="9" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Coh-Metrix: Analysis of text on cohesion and language</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Louwerse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03195564</idno>
		<ptr target="https://doi.org/10.3758/BF03195564" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Coh-Metrix: Providing multilevel analyses of text characteristics</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kulikowich</surname></persName>
		</author>
		<idno type="DOI">10.3102/0013189X11413260</idno>
		<idno>3102/ 00131 89X11 413260</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Educational Researcher</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="223" to="234" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ElectronixTutor: an intelligent tutoring system with multiple learning resources for electronics</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vanlehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Heffernan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Andrasik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<idno type="DOI">10.1186/s40594-018-0110-y</idno>
		<ptr target="https://doi.org/10.1186/s40594-018-0110-y" />
	</analytic>
	<monogr>
		<title level="j">International Journal of STEM Education</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Trying to make it work: Compositional effects in the processing of compound &quot;nonwords</title>
		<author>
			<persName><forename type="first">F</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marelli</surname></persName>
		</author>
		<idno type="DOI">10.1177/1747021820902019</idno>
		<ptr target="https://doi.org/10.1177/" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1082" to="1091" />
			<date type="published" when="2020">2020. 17470 21820 902019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Vector-space models of semantic representation from a cognitive perspective: A discussion of common misconceptions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rinaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marelli</surname></persName>
		</author>
		<idno type="DOI">10.1177/1745691619861372</idno>
		<ptr target="https://doi.org/10.1177/" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1006" to="1033" />
			<date type="published" when="2019">2019. 17456 91619 861372</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Topic detection using paragraph vectors to support active learning in systematic reviews</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kontonatsios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbi.2016.06.001</idno>
		<ptr target="https://doi.org/10.1016/j.jbi.2016.06.001" />
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="59" to="65" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Effect of Summarizing Task and Interaction on Korean Middle School Students&apos; Reading Comprehension</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in English Education</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="71" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Strengths, limitations, and extensions of LSA</title>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wiemer-Hastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203936399.ch20</idno>
		<ptr target="https://doi.org/10.4324/97802" />
	</analytic>
	<monogr>
		<title level="m">Handbook of Latent Semantic Analysis</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Dennis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">W</forename><surname>Kintsch</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3936" to="03399" />
		</imprint>
	</monogr>
	<note>ch20</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Predicting patterns of similarity among abstract semantic relations</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ichien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0001010</idno>
		<ptr target="https://doi.org/" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">In defense of spatial models of semantic representation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Gruenenfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Recchia</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.newideapsych.2017.08.001</idno>
		<idno>2017. 08. 001</idno>
		<ptr target="https://doi.org/10.1016/j" />
	</analytic>
	<monogr>
		<title level="m">New Ideas in Psychology</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="54" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The use of scoring rubrics: Reliability, validity and educational consequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Svingby</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.edurev.2007.05.002</idno>
		<ptr target="https://doi.org/10.1016/j.edurev.2007.05.002" />
	</analytic>
	<monogr>
		<title level="j">Educational Research Review</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="130" to="144" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Latent semantic analysis parameters for essay evaluation using smallscale corpora</title>
		<author>
			<persName><forename type="first">Jorge-Botana</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
		<idno type="DOI">10.1080/09296170903395890</idno>
		<ptr target="https://doi.org/10.1080/09296" />
	</analytic>
	<monogr>
		<title level="j">Journal of Quantitative Linguistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">90</biblScope>
			<date type="published" when="2010">2010. 17090</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Jorge-Botana</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barroso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<title level="m">Gallito 2.0: A Natural Language Processing tool to support Research on Discourse. Proceedings of the Twenty-third Annual Meeting of the Society for Text and Discourse</title>
		<meeting><address><addrLine>Valencia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-07">2013. July</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Could LSA become a &quot;Bifactor&quot; model? Towards a model with general and group factors</title>
		<author>
			<persName><forename type="first">Jorge-Botana</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luzón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2019.04.055</idno>
		<ptr target="https://doi.org/10.1016/j.eswa.2019.04.055" />
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="71" to="80" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bridging the theoretical gap between semantic representation models without the pressure of a ranking: some lessons learnt from LSA</title>
		<author>
			<persName><forename type="first">Jorge-Botana</forename></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luzón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
		<idno type="DOI">10.1007/s10339-019-00934-x</idno>
		<ptr target="https://doi.org/10.1007/s10339-019-00934-x" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Exploratory mapping of theoretical landscapes through word use in abstracts</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Kallens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11192-018-2811-x</idno>
		<ptr target="https://doi.org/10.1007/s11192-018-2811-x" />
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1641" to="1674" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Kintsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Caccamise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franzke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dooley</surname></persName>
		</author>
		<title level="m">Summary street: computer-guided summary writing</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<idno type="DOI">10.4324/9780203936399.ch14</idno>
		<ptr target="https://doi.org/10.4324/97802" />
		<title level="m">The Handbook of Latent Semantic Analysis</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Mcnamara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Dennis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Kintsch</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<biblScope unit="page" from="3936" to="03399" />
		</imprint>
	</monogr>
	<note>ch14</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Beyond words: Semantic representation of text in distributional models of language</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kireyev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ESSLLI workshop on distributional lexical semantics: Bridging the gap between semantic theory and computational simulations</title>
		<meeting>the ESSLLI workshop on distributional lexical semantics: Bridging the gap between semantic theory and computational simulations</meeting>
		<imprint>
			<publisher>ESSLLI</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="25" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Semantic measures: Using natural language processing to measure, differentiate, and describe psychological constructs</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">N</forename><surname>Kjell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kjell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sikström</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000191</idno>
		<ptr target="https://doi.org/" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="115" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Scaling and Norming for Automated Essay Scoring</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L K</forename><surname>Koskey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Shermis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Automated Essay Evaluation: Current applications and new directions</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Shermis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="199" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A journey from normative to behavioral operations in supply chain management: A review using Latent Semantic Analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chandra</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2014.08.035</idno>
		<ptr target="https://doi.org/10.1016/j.eswa.2014.08.035" />
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="796" to="809" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A solution to Plato&apos;s problem: The Latent Semantic Analysis theory of the acquisition, induction, and representation of knowledge</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.104.2.211</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.104.2.211" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="211" to="240" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kintsch</surname></persName>
		</author>
		<title level="m">The Handbook of Latent Semantic Analysis</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Exploring supervised and unsupervised methods to detect topics in biomedical text</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2105-7-140</idno>
		<ptr target="https://doi.org/10.1186/1471-2105-7-140" />
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">140</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Assessing short summaries with human judgments procedure and latent semantic analysis in narrative and expository texts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Cañas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Salmerón</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193894</idno>
		<ptr target="https://doi.org/10.3758/BF03193894" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="616" to="627" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">ECOMPLEC. Evaluación de la comprensión lectora</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Reading Comprengesion Assessment]. TEA Ediciones</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Impact of Conversational Formality on the Quality and Formality of Written Summaries</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence in Education</title>
		<imprint>
			<date type="published" when="2020-07">2020, July</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Supervised topic models for multi-label classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2014.07.053</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2014.07.053" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="811" to="819" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Online web video topic detection and tracking with semi-supervised learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00530-014-0402-0</idno>
		<idno>1007/ s00530-014-0402-0</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="125" />
			<date type="published" when="2016">2016a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<title level="m">How good is popularity? Summary grading in crowdsourcing. 9th International Conference on Educational Data Mining</title>
		<imprint>
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Computerized summary scoring: crowdsourcing-based latent semantic analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-017-0982-7</idno>
		<ptr target="https://doi.org/10.3758/s13428-017-0982-7" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2144" to="2161" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Computer-based assessment of student-constructed responses</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Magliano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-012-0211-3</idno>
		<ptr target="https://doi.org/10.3758/s13428-012-0211-3" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="608" to="621" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Malladi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Levinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Boonthum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magliano</surname></persName>
		</author>
		<title level="m">Summarization: Constructing an Ideal Summary and Evaluating a Student&apos;s Summary using LSA. Twenty-Third International FLAIRS Conference</title>
		<imprint>
			<date type="published" when="2010-05">2010. May</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Compounding as Abstract Operation in Semantic Space: Investigating relational effects through a large-scale, data-driven computational model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Gagné</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Spalding</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2017.05.026</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2017.05.026" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="207" to="224" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Analyzing two automatic assessment LSA´s methods (Golden Summary vs Inbuilt Rubric) in summaries extracted from expository texts</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Martínez-Huertas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Jastrzebska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mencu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Moraleda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<idno type="DOI">10.5093/psed2048a9</idno>
		<ptr target="https://doi.org/10.5093/psed" />
	</analytic>
	<monogr>
		<title level="j">Psicología Educativa</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="49" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Automated Summary Evaluation with Inbuilt Rubric method: An alternative to constructed responses and multiplechoice tests assessments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Martínez-Huertas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Jastrzebska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<idno type="DOI">10.1080/02602938.2019.1570079</idno>
		<ptr target="https://doi.org/" />
	</analytic>
	<monogr>
		<title level="j">Assessment &amp; Evaluation in Higher Education</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1029" to="1041" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Enhancing topic-detection in computerized assessments of constructed responses with distributional models of language. Expert Systems with Applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Martínez-Huertas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.eswa.2021.115621</idno>
		<ptr target="https://doi.org/10.1016/j.eswa.2021.115621" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Origen y evolución del lenguaje humano: Una perspectiva neurocognitiva</title>
		<author>
			<persName><forename type="first">M</forename><surname>Martín-Loeches</surname></persName>
		</author>
		<ptr target="http://www.atapuerca.org/ficha/ZE7D1307E-A298-9B9E-5CF101F70223C275/origen-y-evolucion-del-lenguaje-humano-una-perspectiva" />
		<imprint>
			<date type="published" when="2016-09-25">2016. 25 September 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m">Contemporary psychometrics</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Maydeu-Olivares</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcardle</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m">Reading comprehension strategies: Theories, interventions, and technologies</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</editor>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Assessing reading in the 21st century: Aligning and applying advances in the reading and measurement sciences</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Louwerse</surname></persName>
		</author>
		<editor>J.P. Sabatini &amp; E. Albo</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Sources of text difficulty: Across the ages and genres. R&amp;L Education</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Automated evaluation of text and discourse with Coh-Metrix</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Thinking twice about sum scores</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcneish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-020-01398-0</idno>
		<idno>13428-020-01398-0</idno>
		<ptr target="https://doi.org/10.3758/s" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Assessing and improving comprehension with latent semantic analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Millis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magliano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wiemer-Hastings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Todaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203936399.ch11</idno>
		<ptr target="https://doi.org/10.4324/97802" />
	</analytic>
	<monogr>
		<title level="m">Handbook of Latent Semantic Analysis</title>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Dennis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">W</forename><surname>Kintsch</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="3936" to="03399" />
		</imprint>
	</monogr>
	<note>ch11</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Automatic assessment of student reading comprehension from short summaries</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stefanescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>D'mello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-07">2014, July. 2014</date>
			<publisher>Educational Data Mining</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Weight Functions Impact on LSA Performance. EuroConference Recent Advances in Natural Language Processing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Popova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mateev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-09">2001. September</date>
		</imprint>
	</monogr>
	<note>RANLP&apos;01</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Improving the state-of-the-art in Thai semantic similarity using distributional semantics and ontological information</title>
		<author>
			<persName><forename type="first">P</forename><surname>Netisopakul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wohlgenannt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pulich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">Z</forename><surname>Hlaing</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0246751</idno>
		<ptr target="https://doi.org/10.1371/journal.pone" />
	</analytic>
	<monogr>
		<title level="j">Plos one</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2021">2021. 02467</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Análisis del tamaño y especificidad de los corpus en la evaluación de resúmenes mediante el LSA: Un análisis comparativo entre LSA y jueces expertos</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jorge-Botana</surname></persName>
		</author>
		<idno type="DOI">10.4067/S0718-09342009000100004</idno>
		<ptr target="https://doi.org/" />
	</analytic>
	<monogr>
		<title level="j">Revista signos</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">69</biblScope>
			<biblScope unit="page" from="71" to="81" />
			<date type="published" when="2009">2009a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">New algorithms assessing short summaries in expository texts using latent semantic analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jorge-Botana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Escudero</surname></persName>
		</author>
		<idno type="DOI">10.3758/BRM.41.3.944</idno>
		<ptr target="https://doi.org/10.3758/BRM.41.3.944" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="944" to="950" />
			<date type="published" when="2009">2009b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Using latent semantic analysis to grade brief summaries: some proposals</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jorge-Botana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Continuing Engineering Education and Life Long Learning</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="192" to="209" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Using latent semantic analysis to grade brief summaries: A study exploring texts at different academic levels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jorge-Botana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Escudero</surname></persName>
		</author>
		<idno type="DOI">10.1093/llc/fqs065</idno>
		<ptr target="https://doi.org/10.1093/llc/fqs065" />
	</analytic>
	<monogr>
		<title level="j">Literary and Linguistic Computing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="388" to="403" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Transforming Selected Concepts Into Dimensions in Latent Semantic Analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jorge-Botana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Escudero</surname></persName>
		</author>
		<idno type="DOI">10.1080/0163853X.2014.913416</idno>
		<idno>1080/ 01638 53X. 2014. 913416</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Discourse Processes</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="494" to="510" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Transforming LSA space dimensions into a rubric for an automatic assessment and feedback system</title>
		<author>
			<persName><forename type="first">R</forename><surname>Olmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jorge-Botana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Luzón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cordero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>León</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm2015.12.002</idno>
		<ptr target="https://doi.org/10.1016/j.ipm2015.12.002" />
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Text summarization using latent semantic analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Ozsoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">N</forename><surname>Alpaslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Cicekli</surname></persName>
		</author>
		<idno type="DOI">10.1177/0165551511408848</idno>
		<idno>1177/ 01655 51511 408848</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="405" to="417" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Ciencias de la Naturaleza 6° EGB</title>
		<author>
			<persName><forename type="first">A</forename><surname>Peiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Anaya</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Coh-Metrix-Esp: A complexity analysis tool for documents written in Spanish</title>
		<author>
			<persName><forename type="first">A</forename><surname>Quispesaravia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Cabezudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alva-Manchego</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<orgName type="collaboration">R Development Core Team</orgName>
		</author>
		<ptr target="http://www.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-02-01">2019. 1 February 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">An Introduction to Psychometric Theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Marcoulides</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">The rediscovery of bifactor measurement models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2012.715555</idno>
		<idno>1080/ 00273 171. 2012. 715555</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="667" to="696" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morizot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hays</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11136-007-9183-7</idno>
		<ptr target="https://doi.org/10.1007/s11136-007-9183-7" />
	</analytic>
	<monogr>
		<title level="m">The role of the bifactor model in resolving dimensionality issues in health outcomes measures</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="19" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">psych: Procedures for personality and psychological research</title>
		<author>
			<persName><forename type="first">W</forename><surname>Revelle</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=psych" />
		<imprint>
			<date type="published" when="2018-02-01">2018. 1 February 2020</date>
			<pubPlace>Evanston, Illinois, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
	<note>R package version 1.8.12.</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Population performance of SEM parceling strategies under measurement and structural model misspecification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rhemtulla</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000072</idno>
		<idno>1037/ met00 00072</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="348" to="368" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Applying bifactor statistical indices in the evaluation of psychological measures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Haviland</surname></persName>
		</author>
		<idno type="DOI">10.1080/00223891.2015.1089249</idno>
		<idno>1080/ 00223 891. 2015. 10892 49</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality Assessment</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="223" to="237" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">lavaan: An R Package for Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v048.i02</idno>
		<ptr target="https://doi.org/10.18637/jss.v048.i02" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Designing, evaluating, and deploying automated scoring systems with validity in mind: Methodological design decisions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rupp</surname></persName>
		</author>
		<idno type="DOI">10.1080/08957347.2018.1464448</idno>
		<ptr target="https://doi.org/10.1080/08957347" />
	</analytic>
	<monogr>
		<title level="j">Applied Measurement in Education</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">48</biblScope>
			<date type="published" when="2018">2018. 2018. 14644</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Scoring summaries using recurrent neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ruseti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dascalu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Trausan-Matu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Tutoring Systems</title>
		<imprint>
			<date type="published" when="2018-06">2018. June</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Effects of a summarizing strategy on written summaries of children with emotional and behavioral disorders</title>
		<author>
			<persName><forename type="first">B</forename><surname>Saddler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asaro-Saddler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moeyaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ellis-Robinson</surname></persName>
		</author>
		<idno type="DOI">10.1177/0741932516669051</idno>
		<ptr target="https://doi.org/10.1177/07419" />
	</analytic>
	<monogr>
		<title level="j">Remedial and Special Education</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="32516" to="669051" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">The development of hierarchical factor solutions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Leiman</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02289209</idno>
		<ptr target="https://doi.org/10.1007/BF02289209" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="61" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">The use of latent semantic analysis as a tool for the quantitative assessment of understanding and knowledge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Mcnamara</surname></persName>
		</author>
		<idno type="DOI">10.2190/M811-G475-WKMX-X0JH</idno>
		<ptr target="https://doi.org/10.2190/M811-G475-WKMX-X0JH" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Computing Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m">Handbook of Automated Essay Evaluation: Current applications and new directions</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Shermis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Intraclass correlations: Uses in assessing rater reliability</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shrout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fleiss</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.86.2.420</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.86.2.420" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="420" to="428" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Using latent semantic analysis in text summarization and summary evaluation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jezek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th international conference ISIM</title>
		<meeting>the 7th international conference ISIM</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">A review of summarizing and main idea interventions for struggling readers in Grades 3 through 12: 1978-2016</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vaughn</surname></persName>
		</author>
		<idno type="DOI">10.1177/0741932517749940</idno>
		<ptr target="https://doi.org/" />
	</analytic>
	<monogr>
		<title level="j">Remedial and Special Education</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="131" to="149" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">The effect of online summary assessment and feedback system on the summary writing on 6th graders: The LSA-based technique</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compedu.2015.12.003</idno>
		<ptr target="https://doi.org/10.1016/j.compedu.2015.12.003" />
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Implementation of Machine Learning in Higher Education</title>
		<author>
			<persName><forename type="first">N</forename><surname>Vaishnavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Research in Engineering</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="182" to="185" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Science and Management</note>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Van Der Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Hambleton</surname></persName>
		</author>
		<title level="m">Handbook of Modern Item Response Theory</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Strategies of Discourse Comprehension</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Van Dijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kintsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Sciesp: Structural analysis of abstracts written in spanish</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vargas-Campos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Alva-Manchego</surname></persName>
		</author>
		<idno type="DOI">10.13053/cys-20-3-2463</idno>
		<ptr target="https://doi.org/10.13053/cys-20-3-2463" />
	</analytic>
	<monogr>
		<title level="j">Computación y Sistemas</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="551" to="558" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Orthogonal rotations in latent semantic analysis: An empirical study</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Visinescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Evangelopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dss.2014.03.010</idno>
		<ptr target="https://doi.org/10.1016/j.dss.2014.03.010" />
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="131" to="143" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m">WORKSHOP: Computational Psychometrics &amp; Data Mining in Assessment: An Introduction. ITC 2016 Conference</title>
		<editor>
			<persName><forename type="first">Von</forename><surname>Davier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2015-10">2015, October</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Summary Street: Interactive computer support for writing</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wade-Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kintsch</surname></persName>
		</author>
		<idno type="DOI">10.1207/s1532690xci2203_3</idno>
		<ptr target="https://doi.org/" />
	</analytic>
	<monogr>
		<title level="j">Cognition and Instruction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="362" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Parallel analysis with unidimensional binary data</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1177/0013164404273941</idno>
		<ptr target="https://doi.org/10.1177/00131" />
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">273941</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Handbook of Automated Scoring: Theory into practice</title>
		<author>
			<persName><forename type="first">D</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><surname>Foltz</surname></persName>
		</author>
		<editor>P.W.</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Practices and Theories: How Can Machine Learning Assist in Innovative Assessment Practices in Science Education</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10956-021-09901-8</idno>
		<ptr target="https://doi.org/10.1007/s10956-021-09901-8" />
	</analytic>
	<monogr>
		<title level="j">Journal of Science Education and Technology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="149" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Using bifactor models to examine the predictive validity of hierarchical constructs: Pros, cons, and solutions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Drasgow</surname></persName>
		</author>
		<idno type="DOI">10.1177/1094428120915522</idno>
		<ptr target="https://doi.org/10.1177/" />
	</analytic>
	<monogr>
		<title level="j">Organizational Research Methods</title>
		<imprint>
			<date type="published" when="2020">2020. 10944 28120 915522</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">The construction of situation models in narrative comprehension: An eventindexing model</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Langston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Graesser</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.1995.tb00513.x</idno>
		<idno>1467-9280. 1995. tb005 13.x</idno>
		<ptr target="https://doi.org/10.1111/j" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="292" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
