<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A VARIATIONAL BAYESIAN APPROACH TO LEARNING LATENT VARIABLES FOR ACOUSTIC KNOWLEDGE TRANSFER</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-02-20">20 Feb 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hu</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sabato</forename><forename type="middle">Marco</forename><surname>Siniscalchi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering School</orgName>
								<orgName type="institution">University of Enna Kore</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chao-Han</forename><forename type="middle">Huck</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A VARIATIONAL BAYESIAN APPROACH TO LEARNING LATENT VARIABLES FOR ACOUSTIC KNOWLEDGE TRANSFER</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-02-20">20 Feb 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2110.08598v2[eess.AS]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Variational inference</term>
					<term>Bayesian adaptation</term>
					<term>knowledge distillation</term>
					<term>latent variable</term>
					<term>device mismatch</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a variational Bayesian (VB) approach to learning distributions of latent variables in deep neural network (DNN) models for cross-domain knowledge transfer, to address acoustic mismatches between training and testing conditions. Instead of carrying out point estimation in conventional maximum a posteriori estimation with a risk of having a curse of dimensionality in estimating a huge number of model parameters, we focus our attention on estimating a manageable number of latent variables of DNNs via a VB inference framework. To accomplish model transfer, knowledge learnt from a source domain is encoded in prior distributions of latent variables and optimally combined, in a Bayesian sense, with a small set of adaptation data from a target domain to approximate the corresponding posterior distributions. Experimental results on device adaptation in acoustic scene classification show that our proposed VB approach can obtain good improvements on target devices, and consistently outperforms 13 state-of-the-art knowledge transfer algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Recent advances in machine learning are largely due to an evolution of deep learning combined with an availability of massive amounts of data. Deep neural networks (DNNs) have demonstrated state-of-the-art results in building acoustic systems <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr" target="#b3">3]</ref>. Nonetheless, audio and speech systems still highly depend on how close the training data used in model building covers the statistical variation of the signals in testing environments. Acoustic mismatches, such as changes in speakers and recording devices, usually cause an unexpected and severe performance degradation <ref type="bibr" target="#b4">[4,</ref><ref type="bibr">5,</ref><ref type="bibr" target="#b6">6]</ref>. For example, as for acoustic scene classification (ASC), device mismatch is an inevitable problem in real production scenarios <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b10">10]</ref>. Moreover, the amount of data for the specific target domain is often not sufficient to train a good deep target model to achieve a similar performance to the source model. A key issue is to design an effective adaptation procedure to transfer knowledge from the source to target domains, while avoiding catastrophic forgetting and curse of dimensionality <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b14">14,</ref><ref type="bibr" target="#b15">15]</ref> often encountered in deep learning.</p><p>Bayesian learning provides a mathematical framework to model uncertainties and incorporate prior knowledge. It usually performs estimation via either maximum a posteriori (MAP) or variational Bayesian (VB) approaches. By leveraging upon target data and prior belief, a posterior belief can be obtained by optimally combining them. In the MAP solution, a point estimate can be obtained, which has been proven effective in handling acoustic mismatches in hidden Markov models (HMMs) <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b17">17]</ref> and DNNs <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b13">13]</ref> by assuming a distribution on the model parameters. On the other hand, the VB approach performs an estimation on the entire posterior distribution via a stochastic variational inference method <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b24">24]</ref>. Bayesian learning can facilitate building an adaptive system for specific target conditions in a particular environment. Thus the mismatches between training and testing can be reduced, and the overall system performance is greatly enhanced.</p><p>Traditional Bayesian formulations usually impose uncertainties on model parameters, like Bayesian neural networks [?]. However, for commonly used DNNs, the number of parameters is usually much larger than the available training samples, making an accurate estimation difficult. Moreover, a feature based knowledge transfer framework, namely teacherstudent learning (TSL, also called knowledge distillation) <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b26">26]</ref> has been investigated in recent years. The basic TSL transfers knowledge acquired by the source / teacher model and encoded in its softened outputs (model outputs after softmax), to the target / student model, where the target model directly mimics the final prediction of the source model through a KL divergence loss. The idea is then extended to hidden embedding of intermediate layers <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b29">29]</ref>, where different embedded representations are proposed to encode and transfer knowledge. However, instead of considering the whole distribution of latent variables, they only perform point estimation as in MAP, potentially leading to sub-optimal results and may lose distributional information.</p><p>In this work, we aim at establishing a Bayesian adaptation framework based on latent variables of DNNs, where the knowledge is transferred in the form of distributions of deep latent variables. Thus, a novel variational Bayesian knowl- edge transfer (VBKT) approach is proposed. We take into account of the model uncertainties and perform distribution estimation on latent variables. In particular, by leveraging upon variational inference, the distributions of the source latent variables (prior) are combined with the knowledge learned from target data (likelihood) to yield the distributions of the target latent variables (posterior). Prior knowledge from the source domain is thus encoded and transferred to the target domain, by approximating the posterior distributions of latent variables. An extensive and thorough experimental comparison against 13 recent cut-edging knowledge transfer methods is carried out. Experimental evidence demonstrates that our proposed VBKT approach outperforms all competing algorithms on device adaptation tasks of ASC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BAYESIAN INFERENCE OF LATENT VARIABLES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Knowledge Transfer of Latent Variables</head><p>Suppose we are given some data observations D, and let</p><formula xml:id="formula_0">D S = {x (i) S , y<label>(i)</label></formula><p>S } N S i=1 and D T = {x</p><formula xml:id="formula_1">(i) T , y<label>(i)</label></formula><p>T } N T i=1 indicate the source and target domain data, respectively. Our framework requires parallel data, e.g., for each target data sample x S share the same audio content but recorded by different devices. Consider a DNN based discriminative model with parameters λ to be estimated, where λ usually represents network weights. Starting from the classical Bayesian approach, a prior distribution p(λ) is defined over λ, and the posterior distribution after seeing the observations D can be obtained by the Bayes Rule as follows,</p><formula xml:id="formula_2">p(λ|D) = p(D|λ)p(λ) p(D) .<label>(1)</label></formula><p>Figure <ref type="figure" target="#fig_0">1</ref> illustrates the overall framework of our proposed knowledge transfer approach. Parallel input features of X S and X T are firstly extracted and then fed into neural networks. In addition to network weights, we introduce the latent variables Z to model the intermediate hidden embedding of DNNs. Here Z refers to the unobserved intermediate representations, encoding transferable distributional information. We then decouple the network weights into two independent subsets, θ and ω, as illustrated by the subnets in the 4 squares in Figure <ref type="figure" target="#fig_0">1</ref>, to represent weights before and after Z is generated, respectively. Thus we have</p><formula xml:id="formula_3">p(λ) = p(Z, θ, ω) = p(Z|θ)p(θ)p(ω).</formula><p>(</p><formula xml:id="formula_4">)<label>2</label></formula><p>Note that the relationship in Eq. ( <ref type="formula" target="#formula_4">2</ref>) holds for both prior p(λ) and posterior p(λ|D). Here we focus on transferring knowledge in a distribution sense via the latent variables Z. With parallel data, we thus assume that there exists Z retaining the same distributions across the source and target domains. Specifically, for the target model we have p(Z T |θ T ) = p(Z S |θ S , D S ), as the prior knowledge learnt from the source encoded in p(Z S |θ S , D S ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Variational Bayesian Knowledge Transfer</head><p>Denoting λ in the target model as λ T , typically, the posterior p(λ T |D T ) is often intractable, and an approximation is required. In this work, we propose a variational Bayesian approach to approximate the posterior; therefore, a variational distribution q(λ T |D T ) is introduced. For the target domain model, the optimal q * (λ T |D T ) is obtained by minimizing KL divergence between the variational distribution and the real one, over a family of allowed approximate distributions Q:</p><formula xml:id="formula_5">q * (λ T |D T ) = argmin q∈Q KL(q(λ T |D T ) p(λ T |D T )). (3)</formula><p>In this work, we focus on latent variables, Z, and we assume a non-informative prior over θ T and ω T . Next, by substituting Eqs. ( <ref type="formula" target="#formula_2">1</ref>), <ref type="bibr" target="#b2">(2)</ref>, and the prior distribution into Eq. (3), we arrive, after re-arranging the terms, to the following variational lower bound L(λ T ; D T ) as</p><formula xml:id="formula_6">L(λ T ; D T ) = E Z T ∼q(Z T |θ T ,D T ) log p(D T |Z T , θ T , ω T ) -KL(q(Z T |θ T , D T ) p(Z S |θ S , D S )).<label>(4)</label></formula><p>Simply put, a Gaussian mean-field approximation is used to specify the distribution forms for both the prior and posterior over Z. Specifically, each latent variable z in Z follows an M -dimension isotropic Gaussian, where M is the hidden embedding size. Given a parallel data set, we can approximate the KL divergence term in Eq. ( <ref type="formula" target="#formula_6">4</ref>) by establishing a mapping of each pair of Gaussian distributions across domains via sample pairs. We denote the Gaussian mean and variance for the source and target domains as µ S ; σ 2 S and µ T ; σ 2 T , respectively. A stochastic gradient variational Bayesian (SGVB) estimator <ref type="bibr" target="#b21">[21]</ref> is then used to approximate the posterior, with the network hidden outputs being regarded as the mean of the Gaussian. Moreover, we assign a fixed value σ 2 to both σ 2 S and σ 2 T , as the variance for all individual Gaussian components. We can now obtain a close-form solution for the KLD term in Eq. ( <ref type="formula" target="#formula_6">4</ref>). Furthermore, by adopting Monte Carlo to generate N T -pairs of sample, the lower bound in Eq. ( <ref type="formula" target="#formula_6">4</ref>) can be approximated empirically as:</p><formula xml:id="formula_7">L(λ T ; D T ) = N T i E z (i) T ∼N (µ (i) T ,σ 2 ) log p(y (i) T |x (i) T , z (i) T , θ T , ω T ) - 1 2σ<label>2</label></formula><formula xml:id="formula_8">N T i µ (i) T -µ (i) S 2 2 ,<label>(5)</label></formula><p>where the first term is the likelihood, and the second term is deduced from the KL divergence between prior and posterior of the latent variables. Each instance of z</p><formula xml:id="formula_9">(i)</formula><p>T , is sampled from the posterior distribution as z</p><formula xml:id="formula_10">(i) T |θ T , D T ∼ N (µ (i)</formula><p>T , σ 2 ), thus the expectation form in the first term can be reduced. To flow the gradients of sampling operation through deep neural nets, a reparameterization trick <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b21">21]</ref> is adopted during the network training. In the inference stage, as it's a classification task, we directly take z</p><formula xml:id="formula_11">(i) T = µ (i)</formula><p>T to simplify the computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental Setup</head><p>We evaluate our proposed VBKT approach on the acoustic scene classification (ASC) task of DCASE2020 challenge task1a <ref type="bibr" target="#b31">[31]</ref>. The training set contains ∼10K scene audio clips recorded by the source device (device A), and 750 clips for each of the 8 target devices (Device B, C, s1-s6). Each target audio is paired with a source audio, and the only difference between the two audios is the recording device. The goal is to solve the device mismatch issue for one specific target device at a time, i.e., device adaptation, which is a common scenario in real applications. For each audio clip, log-mel filter bank (LMFB) features are extracted, and scaled to [0,1] before feeding into the classifier.</p><p>Two state-of-the-art models, namely: a dual-path resnet (RESNET) and a fully convolutional neural network with channel attention (FCNN), are tested according to the challenge results <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b32">32]</ref>. We use the same models for both the source and target devices. Mix-up <ref type="bibr" target="#b33">[33]</ref> and SpecAugment <ref type="bibr" target="#b34">[34]</ref> are used in the training stage. Stochastic gradient descent (SGD) with a cosine-decay restart learning rate scheduler is used to train all models. Maximum and minimum learning rates are 0.1, and 1e-5, respectively. The latent variables are based on the hidden outputs before the last layer. Specifically, the hidden embedding after batch-normalization but before ReLU activation of the second last convolutional layer is utilized. As stated in Section 2, a deterministic value is set for σ.</p><p>In our experiments, we generate extra data <ref type="bibr" target="#b35">[35]</ref> and compute the average standard deviation over each audio clip, where we finally set σ = 0.2. For the other 13 tested cut-edging TSL based methods, we mostly follow the recommended setups and hyper-parameter settings in their original papers. The temperature parameter is set to 1.0 for all when computing KL divergence with soft labels. <ref type="foot" target="#foot_0">1</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Evaluation Results on Device Adaptation</head><p>Evaluation results of device adaptation on the DCASE2020 ASC task are shown in Table <ref type="table" target="#tab_0">1</ref>. The source models are trained on data recorded by Device A, where we can get a classification accuracy of 79.09% for RESNET and 79.70% for FCNN, on the source test set, respectively. There are 8 target devices, i.e., Device B, C, s1-s6. The accuracy reported in each cell of Table <ref type="table" target="#tab_0">1</ref> is obtained by averaging among 32 experimental results, from 8 target devices and 4 trails for each. The first and third columns represent results by directly using the knowledge transfer methods; whereas the second and fourth columns list accuracies obtained when further combined with the basic TSL method. We look at the results without the combination of TSL at first. The 1st row gives results by directly testing the source model on target devices. We can observe a huge degradation (from ∼79% to ∼37%) when compared with the results on source test set. That shows the device mismatch is indeed a critical aspect in acoustic scene classification, as the device changing causing a serve performance drop. The 2nd and 3rd rows in Table <ref type="table" target="#tab_0">1</ref> give results of target model trained by target data either from the scratch or fine-tuned on source model. By comparing them we can argue the importance of knowledge transfer when building a target model. The 4th to 16th rows in Table <ref type="table" target="#tab_0">1</ref> show the evaluated results of 13 recent top TSL based methods. The result of basic TSL <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b26">26]</ref>, which minimizes KL divergence between model outputs and soft labels, is shown in the 4th row. We can observe a gain obtained by TSL when compared with one-hot fine-tuning. If we compare the other methods (5th to 16th rows) with basic TSL, they only show small advantages on this task. The bottom row of Table <ref type="table" target="#tab_0">1</ref> shows results of our proposed VBKT approach. It not only outperforms one-hot finetuning by a large margin (69.58% vs. 63.76% for RESNET, and 69.12% vs. 61.54% for FCNN), but also attains superior classification results to those obtained with other algorithms.</p><p>We further investigate the combination of the proposed approach and the basic TSL. The experimental results are shown in the 2nd and 4th columns of Table <ref type="table" target="#tab_0">1</ref>, for RESNET and FCNN models, respectively. Specifically, the original cross entropy (CE) loss is replaced by an addition of 0.9 × KL loss with soft labels and 0.1 × CE loss with hard labels. There is no change to basic TSL so results remain the same in the 4th row. For the other tests (from 5th to 16th rows), when combining with basic TSL, most tested methods can attain further gains. Indeed, such a combination is recommended by some studies <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b42">42]</ref>. Finally, we compare our proposed VBKT approach with others, when combined with TSL, the accuracy can be further boosted, and it still outperforms other tested methods under the same setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Effects of Hidden Embedding Depth</head><p>In our basic setup, the hidden embedding before the last convolutional layer is utilized for modeling latent variables. Ablation experiments are further carried out to investigate the effects of using different-layer hidden embedding. Experiments are performed on FCNN since it has a sequential architecture with stacked convolutional layers, namely 8 convolutional layers and 1×1 convolutional layer for outputs. Results are shown in Figure <ref type="figure" target="#fig_2">2</ref>. Methods use all hidden layers, like COFD, are not covered here. We don't have results for RKD and NST on Conv2 due to they exceeds the available memory on our machine. From the results we can see that the best performance is obtained from last layer for most of the assessed approaches. Moreover, the hidden embedding closer to the model output allows for a higher accuracy than that closer to the input. Therefore we can argue that late features are better than early features in transferring knowledge across domains. That is in line with what is observed in <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b43">43]</ref>. Finally, VBKT attains a very competitive ASC accuracy and consistently outperforms other methods independently of the selected hidden layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Visualization of Intra-class Discrepancy</head><p>To better understand the effectiveness of the proposed VBKT approach, we compare the intra-class discrepancy between target model outputs (before softmax). The visualized heatmap results are shown in (a)-(f) of Figure <ref type="figure" target="#fig_3">3</ref>. Here we randomly select 30 samples from the same class and compute L 2 distance between model outputs of each two. Thus each cell in subnets of Figure <ref type="figure" target="#fig_3">3</ref> represents the discrepancy between two outputs, as the darker color means bigger intraclass discrepancy. From these visualization results we can argue that the one obtained by our proposed VBKT approach in Figure <ref type="figure" target="#fig_3">3f</ref> has consistently smaller intra-class discrepancy than those produced by others, implying that VBKT brings up more discriminative information and results in a better cohesion of instances from the same class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>In this study, we propose a variational Bayesian approach to address the cross-domain knowledge transfer issues when deep models are used. Different from previous solutions, we propose to transfer knowledge via prior distributions of deep latent variables from the source domain. We cast the problem into learning distributions of latent variables in deep neural networks. In contrast to conventional maximum a posteriori estimation, a variational Bayesian inference algorithm is then formulated to approximate the posterior distribution in the target domains. We assess the effectiveness of our proposed VB approach on the device adaptation tasks for the DCASE2020 ASC data set. Experimental evidence clearly demonstrate that the target model obtained with our proposed approach outperforms all other tested methods in all tested conditions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Illustration of the proposed knowledge transfer framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Evaluation results for using different hidden layers of FCNN model, on two target devices: (a) Device s3 and (b) Device s5. The basic TSL is combined with all methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Visualized heatmaps of the intra-class discrepancy between target outputs. FCNN on target device s5 is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of average evaluation accuracies (in %) on recordings of the DCASE2020 ASC data set. Each method is tested with and without the combination of the basic TSL method. Each cell represents the average value over 32 experimental results for 8 target devices × 4 repeated trails.</figDesc><table><row><cell>Method</cell><cell>RESNET avg. (%)</cell><cell>RESNET w/ TSL avg. (%)</cell><cell>FCNN avg. (%)</cell><cell>FCNN w/ TSL avg. (%)</cell></row><row><cell>Source model</cell><cell>37.70</cell><cell>-</cell><cell>37.13</cell><cell>-</cell></row><row><cell>No transfer</cell><cell>54.29</cell><cell>-</cell><cell>49.97</cell><cell>-</cell></row><row><cell>One-hot</cell><cell>63.76</cell><cell>-</cell><cell>64.45</cell><cell>-</cell></row><row><cell>TSL [26]</cell><cell>68.04</cell><cell>68.04</cell><cell>66.27</cell><cell>66.27</cell></row><row><cell>NLE [36]</cell><cell>65.64</cell><cell>67.76</cell><cell>64.47</cell><cell>64.53</cell></row><row><cell>Fitnet [27]</cell><cell>66.73</cell><cell>69.89</cell><cell>67.29</cell><cell>69.06</cell></row><row><cell>AT [28]</cell><cell>63.73</cell><cell>68.06</cell><cell>64.16</cell><cell>66.35</cell></row><row><cell>AB [37]</cell><cell>65.34</cell><cell>68.69</cell><cell>66.21</cell><cell>66.91</cell></row><row><cell>VID [38]</cell><cell>63.90</cell><cell>68.56</cell><cell>63.79</cell><cell>65.75</cell></row><row><cell>FSP [39]</cell><cell>64.44</cell><cell>68.94</cell><cell>65.33</cell><cell>66.01</cell></row><row><cell>COFD [29]</cell><cell>64.92</cell><cell>68.57</cell><cell>66.69</cell><cell>68.63</cell></row><row><cell>SP [40]</cell><cell>64.57</cell><cell>68.45</cell><cell>65.74</cell><cell>67.36</cell></row><row><cell>CCKD [41]</cell><cell>65.59</cell><cell>69.47</cell><cell>66.52</cell><cell>68.29</cell></row><row><cell>PKT [42]</cell><cell>64.65</cell><cell>65.43</cell><cell>64.84</cell><cell>67.25</cell></row><row><cell>NST [43]</cell><cell>68.35</cell><cell>68.51</cell><cell>67.13</cell><cell>68.84</cell></row><row><cell>RKD [44]</cell><cell>65.28</cell><cell>68.46</cell><cell>65.63</cell><cell>67.27</cell></row><row><cell>VBKT</cell><cell>69.58</cell><cell>69.90</cell><cell>69.96</cell><cell>70.50</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code available: https://github.com/MihawkHu/ASC_ Knowledge_Transfer</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal processing magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Conversational speech transcription using context-dependent deep neural networks</title>
		<author>
			<persName><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A regression approach to speech enhancement based on deep neural networks</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li-Rong</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="19" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On adaptive decision rules and decision parameter adaptation for automatic speech recognition</title>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Huo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1241" to="1269" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An overview of noise-robust automatic speech recognition</title>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reinhold</forename><surname>Haeb-Umbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="745" to="777" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adaptation algorithms for speech recognition: An overview</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joachim</forename><surname>Fainberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondrej</forename><surname>Klejch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pawel</forename><surname>Swietojanski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06580</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A multidevice dataset for urban acoustic scene classification</title>
		<author>
			<persName><forename type="first">Annamaria</forename><surname>Mesaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toni</forename><surname>Heittola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuomas</forename><surname>Virtanen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.09840</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unsupervised adversarial domain adaptation for acoustic scene classification</title>
		<author>
			<persName><forename type="first">Shayan</forename><surname>Gharib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantinos</forename><surname>Drossos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emre</forename><surname>Cakir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Serdyuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuomas</forename><surname>Virtanen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.05777</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Low-complexity models for acoustic scene classification based on receptive field regularization and frequency damping</title>
		<author>
			<persName><forename type="first">Khaled</forename><surname>Koutini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Henkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Eghbal-Zadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Widmer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.02955</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Relational teacher student learning with neural label embedding for device adaptation in acoustic scene classification</title>
		<author>
			<persName><forename type="first">Hu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabato</forename><surname>Marco Siniscalchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An empirical investigation of catastrophic forgetting in gradient-based neural networks</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6211</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Maximum a posteriori adaptation of network parameters in deep models</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabato</forename><surname>Marco Siniscalchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I-Fan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiadong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Approximate Dynamic Programming: Solving the curses of dimensionality</title>
		<author>
			<persName><forename type="first">B</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><surname>Powell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">703</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Why and when can deep-but not shallownetworks avoid the curse of dimensionality: a review</title>
		<author>
			<persName><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrushikesh</forename><surname>Mhaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brando</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianli</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Automation and Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="503" to="519" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Maximum a posteriori estimation for multivariate gaussian mixture observations of markov chains</title>
		<author>
			<persName><forename type="first">J-L</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on speech and audio processing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="291" to="298" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint maximum a posteriori adaptation of transformation and hmm parameters</title>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Siohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Chesta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="428" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bayesian unsupervised batch and online speaker adaptation of activation function parameters in deep models for automatic speech recognition</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabato</forename><surname>Marco Siniscalchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="75" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Variational bayesian estimation and clustering for speech recognition</title>
		<author>
			<persName><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasuhiro</forename><surname>Minami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="365" to="381" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Practical variational inference for neural networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2348" to="2356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Variational continual learning</title>
		<author>
			<persName><forename type="first">Yingzhen</forename><surname>Cuong V Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thang</forename><forename type="middle">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><surname>Turner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10628</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Scalable factorized hierarchical variational autoencoder training</title>
		<author>
			<persName><forename type="first">Wei-Ning</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03201</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Variational information bottleneck for effective low-resource audio classification</title>
		<author>
			<persName><forename type="first">Shijing</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianzong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huiming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhan</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.04803</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning smallsize dnn with output-distribution-based criteria</title>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jui-Ting</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samira</forename><forename type="middle">Ebrahimi</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlo</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03928</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A comprehensive overhaul of feature distillation</title>
		<author>
			<persName><forename type="first">Byeongho</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeesoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyojin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nojun</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Young</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1921" to="1930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fixed-form variational posterior approximation through stochastic linear regression</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="837" to="882" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Acoustic scene classification in dcase 2020 challenge: generalization across devices and low complexity solutions</title>
		<author>
			<persName><forename type="first">Toni</forename><surname>Heittola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annamaria</forename><surname>Mesaros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuomas</forename><surname>Virtanen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14623</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Devicerobust acoustic scene classification based on two-stage categorization and data augmentation</title>
		<author>
			<persName><forename type="first">Hu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao-Han Huck</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianjun</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Bai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08389</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Specaugment: A simple data augmentation method for automatic speech recognition</title>
		<author>
			<persName><forename type="first">William</forename><surname>Daniel S Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung-Cheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekin</forename><forename type="middle">D</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08779</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A two-stage approach to device-robust acoustic scene classification</title>
		<author>
			<persName><forename type="first">Hu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao-Han Huck</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianjun</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="845" to="849" />
			<date type="published" when="2021">2021</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">L-vector: Neural label embedding for domain adaptation</title>
		<author>
			<persName><forename type="first">Zhong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="7389" to="7393" />
			<date type="published" when="2020">2020</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Knowledge transfer via distillation of activation boundaries formed by hidden neurons</title>
		<author>
			<persName><forename type="first">Byeongho</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minsik</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Young</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3779" to="3787" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Variational information distillation for knowledge transfer</title>
		<author>
			<persName><forename type="first">Shell</forename><forename type="middle">Xu</forename><surname>Sungsoo Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Damianou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenwen</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="9163" to="9171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A gift from knowledge distillation: Fast optimization, network minimization and transfer learning</title>
		<author>
			<persName><forename type="first">Junho</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donggyu</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jihoon</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4133" to="4141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Similarity-preserving knowledge distillation</title>
		<author>
			<persName><forename type="first">Frederick</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Correlation congruence for knowledge distillation</title>
		<author>
			<persName><forename type="first">Baoyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunfeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoning</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5007" to="5016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning deep representations with probabilistic knowledge transfer</title>
		<author>
			<persName><forename type="first">Nikolaos</forename><surname>Passalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Tefas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="268" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Like what you like: Knowledge distill via neuron selectivity transfer</title>
		<author>
			<persName><forename type="first">Zehao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01219</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Relational knowledge distillation</title>
		<author>
			<persName><forename type="first">Wonpyo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongju</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3967" to="3976" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
