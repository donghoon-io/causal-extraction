<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Neural Aspect Extraction with Sememes</title>
				<funder>
					<orgName type="full">Ant Financial Science Funds for Security Research</orgName>
				</funder>
				<funder>
					<orgName type="full">Youth Innovation Promotion Association CAS</orgName>
				</funder>
				<funder>
					<orgName type="full">Ant Financial</orgName>
				</funder>
				<funder ref="#_uzWRvTf">
					<orgName type="full">National Key Research and Development Program of China</orgName>
				</funder>
				<funder ref="#_xbb4zCH">
					<orgName type="full">CCF-Tencent RhinoBird Young Faculty Open Research Fund</orgName>
				</funder>
				<funder ref="#_QgEcnSx #_cURRbc2 #_BG54Xfu #_kyXmDda">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ling</forename><surname>Luo</surname></persName>
							<email>luoling18s@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Ao</surname></persName>
							<email>aoxiang@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Song</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinyao</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>4 David R. Cheriton</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaopeng</forename><surname>Yang</surname></persName>
							<email>x335yang@uwaterloo.ca</email>
						</author>
						<author>
							<persName><forename type="first">Qing</forename><surname>He</surname></persName>
							<email>heqing@ict.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="laboratory">Key Lab of Intelligent Information Processing</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dong</forename><surname>Yu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">School of Computer Science</orgName>
								<orgName type="department" key="dep2">Faculty of Mathematics</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Neural Aspect Extraction with Sememes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T18:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Aspect extraction relies on identifying aspects by discovering coherence among words, which is challenging when word meanings are diversified and processing on short texts. To enhance the performance on aspect extraction, leveraging lexical semantic resources is a possible solution to such challenge. In this paper, we present an unsupervised neural framework that leverages sememes to enhance lexical semantics. The overall framework is analogous to an autoenoder which reconstructs sentence representations and learns aspects by latent variables. Two models that form sentence representations are proposed by exploiting sememes via (1) a hierarchical attention; (2) a context-enhanced attention. Experiments on two real-world datasets demonstrate the validity and the effectiveness of our models, which significantly outperforms existing baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Aspect extraction is an essential component for aspect level sentiment analysis which is an important natural language processing task to identify peoples' opinions towards aspects of entities <ref type="bibr" target="#b9">[Liu, 2012]</ref>. In general, there are two sub-tasks in aspect extraction, extracting aspect terms from an opinion corpus, e.g. identifying "seaweed" from "The seaweed was chewy like gum", and grouping subtle aspect terms into categories where each category denotes an individual aspect, e.g. cluster "steak" and "seaweed" into aspect "food".</p><p>Unsupervised approaches are one of the mainstream solutions. Among them, the common choices are latent Dirichlet allocation (LDA) based methods <ref type="bibr" target="#b11">[Titov and McDonald, 2008;</ref><ref type="bibr">Brody and Elhadad, 2010;</ref><ref type="bibr" target="#b14">Zhao et al., 2010;</ref><ref type="bibr" target="#b9">Mukherjee and Liu, 2012]</ref>. However, their performance is limited for two reasons. First, by exploiting word co-occurrences, it is hard to predict aspects from word topic (aspect) distributions because they are not highly differentiated. Second, the inaccurate topic distribution estimations from LDA-based models limit the performance on concise reviews. To this end, deep learning based models <ref type="bibr" target="#b12">[Wang et al., 2015;</ref><ref type="bibr">He et al., 2017]</ref> were proposed. Yet they are still restrained from the following issues. First, a word in different contexts may have various senses, e.g., "roll" in two reviews "This roll of Kodak film is of good quality" and "California rolls are awesome" is different while it should be extracted as an aspect term in the latter review. Existing models do not explicitly distinguish different meanings of a word mainly because each word is equipped with a fixed embedding that is usually built upon word co-occurrences without considering its semantic information. Second, aspects might be represented in implicit manners. For example, "my cellphone really fits my hand" describes a positive sentiment on the "size" aspect, where the word "fit" is more indicative to "size". However, previous models are more likely to focus on words like "cellphone" because it is a domain-specific word while "fit" is more general. Third, most aspect terms are infrequent. Figure <ref type="figure" target="#fig_0">1</ref> exhibits the frequencies of the aspect terms on the dataset from SemEval Challenge 2014 task 4<ref type="foot" target="#foot_0">foot_0</ref> , and we observe an obvious long-tailed distribution on aspect terms' frequencies. However, existing neural models favor extracting frequent aspect terms instead of long-tailed ones.</p><p>Considering the manual process on aspect extraction, human being is skilled at solving these issues with exter- </p><formula xml:id="formula_0">S i S i A A h h P (h|S i ) P (h|S i ) Figure 2: The Overall Framework.</formula><p>nal semantic knowledge. To present such knowledge, sememes <ref type="bibr" target="#b0">[Bloomfield, 1926]</ref> are minimum semantic units of word meanings and usually annotated in lexical semantic resources. It could be effective to find the real aspect terms especially infrequent ones by utilizing such semantic resources to obtain latent semantic information and get the meaning of the context behind the obscure and various expressions.</p><p>In doing so, in this paper, we leverage sememes from external lexical semantic resources and introduce an unsupervised neural framework to incorporate neural models and unlabeled data effectively. The overall framework is analogous to an autoencoder, which takes a sentence representation as input. The sentence representation is then reconstructed by a linear combination of aspect embeddings and a latent variable sampling from a learnt distribution. Based on the framework, we propose two models which leverage sememes to form the input sentence representations in different ways. The first model, namely, Aspect Extraction with Sememe Attentions (AE-SA), has a hierarchical sememe attention layer that obtains a sentence representation by emphasizing correlated word senses on the lexical level. The second model, namely, Aspect Extraction via Contextenhanced Sememe Attentions (AE-CSA) adopts an RNN to perform global encoding of sentences and concatenates with the sememe attention layer to effectively explore related word senses. Experiments on two large public review datasets have verified the effectiveness of our models. and also show that sememes can greatly help discover infrequent aspects, where AE-SA and AE-CSA outperform the previous state-of-the-art models. The contributions can be summarized as follows,</p><p>• Our models utilize lexical semantics to discover latent semantic information behind implicit and various expressions for aspect extraction. • We propose a sememe attention structure to represent word meanings and such structure is proved to be useful in aspect extraction, especially for extracting infrequent aspects. • We add an RNN structure to the sememe attention, which learns the sequential information of the contexts and help the explorations of real aspect terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Proposed Model</head><p>In this section, we describe our models incorporating sememes for unsupervised aspect extraction. First, we detail the overall framework. Then, we present our two models AE-SA and AE-CSA, which consist of different network structures to get sentence representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Overall Framework</head><p>The overall framework illustrated in Figure <ref type="figure">2</ref> consists of an encoding and a decoding process. In the encoding process, the input sentence representation S i is firstly reduced to a compressed latent variable h ∈ R K , where K is the number of pre-defined aspects<ref type="foot" target="#foot_2">foot_2</ref> . During decoding, the output sentence representation S o is constructed by a linear combination of the latent variable h and an aspect embedding matrix A ∈ R K×d , where d is the embedding size. The aspect embedding is aligned with the word embeddings so as to be inferred by performing the nearest neighbor search in the embedding space.</p><p>Encoder. S i is encoded to a latent variable h ∈ R K and h can be seen as a probability vector over K aspects. We sample h from a continuous latent distribution, which is assumed as a Gaussian N (h|µ, σ 2 ) in our models where µ = l 1 (S i ) and logσ = l 2 (S i ). l 1 , l 2 can be any type of neural network and we simply use Multi-Layer Perceptrons (MLP) in our implementation. h ∼ N (µ, σ 2 ) is sampled as the output of the encoder (c.f. Eq. 1) where is a random value from a normal distribution.</p><formula xml:id="formula_1">h = µ + σ<label>(1)</label></formula><p>Decoder. A reconstructed sentence representation S o is derived by a linear combination of the aspect embedding matrix A ∈ R K×d with the latent variable h (c.f. Eq. 2) in the decoding process. A is learned during the training process with each row representing an aspect embedding. As shown in Figure <ref type="figure">2</ref>, the semantic meaning of each aspect can be inferred by its nearest words from the embedding space since the aspect embedding is aligned with the word embeddings.</p><formula xml:id="formula_2">So = A T • h,<label>(2)</label></formula><p>Training and test. The loss function L of our models consists of a training objective function J and a regularization term U . J is designed to minimize the reconstruction error of S i and S o and differ S o from q randomly selected negative samples {N 1 , . . . , N q }. We compute the sum of fixed word embeddings as the j-th negative sample representation N j . We utilize contrastive max-margin for J [Rush et al., 2015], meanwhile U is aimed to enhance the diversity and avoid redundancy of aspect embeddings. In detail,</p><formula xml:id="formula_3">L = J + λU,<label>(3)</label></formula><formula xml:id="formula_4">J = m∈D q j=1 max (0, 1 -S m o S m i + S m o N m j ),<label>(4)</label></formula><formula xml:id="formula_5">U = An • A T n -I ,<label>(5)</label></formula><p>where D represents the training dataset and λ is a hyperparameter. A n represents the normalization on each row of A, while I is the identity matrix. During the test, a sentence S i is encoded to h , then we perform topical aspect inference by analyzing the weights in h since it indicates the probability over the pre-defined topical aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Aspect Extraction with Sememe Attentions (AE-SA)</head><p>Sememes <ref type="bibr" target="#b0">[Bloomfield, 1926]</ref> annotated on lexical semantic resources are minimum semantic units of word meanings.</p><p>In detail, a word may have multiple senses and a senses consists of several sememes. See Figure <ref type="figure" target="#fig_1">3</ref> for an example. The word "published" has more than one senses ("publish","print", etc.), and the sense "publish" is composed of some sememes ("bring out","put out","release"). AE-SA adopts a hierarchical sememe attention layer to form a better word and sentence representations by deemphasizing irrelevant sememes and focusing on more correlative ones. Figure <ref type="figure" target="#fig_2">4</ref> details its sememe attention layers.</p><p>Given a sentence s = {w 1 , . . . , w m }, we compute the average of word embeddings as E avg and construct an initial sentence representation S by,</p><formula xml:id="formula_6">S = m i=1 softmax(tanh(e T i • Eavg))ei,<label>(6)</label></formula><p>where e i ∈ R d is the word embedding of w i . The following is a hierarchical sememe attention mechanism driven by S.</p><p>Through this, we derive a new sentence representation S i by,</p><formula xml:id="formula_7">xt,i = l i j=1 softmax(tanh(x t i,j T • S))x t i,j ,<label>(7)</label></formula><formula xml:id="formula_8">e t = n i=1 softmax(tanh( x T t,i • S)) xt,i,<label>(8)</label></formula><formula xml:id="formula_9">Si = m t=1 softmax(tanh(e t T • M • S))e t .<label>(9)</label></formula><p>The representation of the i-th sense in the t-th word is a weighted sum of its sememes {x t i,1 , . . . , x t i,li } (c.f. Eq. 7). Then, the new embedding of the t-th word in sentence s is computed by aggregating different senses { x t,1 , . . . , x t,n } with an attention mechanism (c.f. Eq. 8). Such hierarchical sememe attention attempts to expand senses of each word and capture its meaning within specific contexts. Next, we construct a new sentence representation S i by strengthening relevant words with another attention mechanism (c.f. Eq. 9) where M ∈ R d×d is a trainable transformation matrix and d is the dimension of word and sentence vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Aspect Extraction via Context-enhanced</head><p>Sememe Attentions (AE-CSA) x t 2,l2</p><p>x t 1,1</p><p>x t 1,1</p><p>x t 1,l1</p><p>x t 1,l1</p><p>x t 2,1 upgraded model, AE-CSA. Compared with AE-SA, AE-CSA utilize lexical semantic information to construct the input sentence with the help of words' sequential relations.</p><formula xml:id="formula_10">x t 2,1 x t n,1 x t n,1 xt,1 xt,1 xt,2 xt,2 xt,n xt,n</formula><p>In particular, apart from getting a sentence representation S i via the sememe attention layer (c.f. Eq. 9), the original sentence s = {w 1 , . . . , w m } is also fed into an RNN to generate the hidden representation h rnn . Then h rnn and S i jointly generate a new sentence S i via an MLP (c.f. Eq. 10). S i can be regarded as a kind of distorted sentence representation represented via the sememe attention, which is guided by the sequential and semantic constraints of the sentence. The new input sentence is then reconstructed in AE-CSA.</p><formula xml:id="formula_11">S i = tanh(W T • (Si ⊕ hrnn) + b)<label>(10)</label></formula><p>where W ∈ R (d+d )×d and b are parameters to be learned. ⊕ stands for vector concatenation,</p><formula xml:id="formula_12">h rnn ∈ R d , S i , S i ∈ R d ,</formula><p>where d and d are dimension of the hidden vector of RNN and the sentence vector, respectively. Intuitively, h rnn may suggest the sememe attention layer which words are more important and should be determined as the appropriate word senses by influencing the training of the transformation matrix M (c.f. Eq. 9). S i is the derived sentence representation which is fed to the auto-encoder as Section 2.1.</p><p>3 Experiment Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We conduct extensive experiments on two real-world datasets to evaluate our model. The statistics are shown in Table <ref type="table" target="#tab_2">1</ref>.</p><p>Citysearch corpus. It contains over 50, 000 restaurant reviews from Citysearch New York. An annotated subset with 3, 400 sentences are used for evaluation <ref type="bibr" target="#b3">[Ganu et al., 2009]</ref> with six manually defined aspect labels: Food, Staff, Ambience, Price, Anecdotes and Miscellaneous. We name this corpus Restaurant dataset hereafter.</p><p>BeerAdvocate. This is a beer review corpus provided in <ref type="bibr" target="#b8">[McAuley et al., 2012]</ref> containing more than 1.5 million reviews. A subset of 1, 000 reviews consisting of 9, 245 sentences, are annotated as five aspect labels Feel, Look, Smell, Taste, and Others. We name this dataset Beer hereafter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baselines</head><p>The baselines include representative unsupervised models. SAS [Mukherjee and <ref type="bibr" target="#b9">Liu, 2012]</ref>  For a fair comparison, we extend ABAE and derive ABAE-SEM by averaging sememes embeddings to initialize the corresponding word embeddings. We also degrade our model by removing the attentions on sememes for ablation test. We denote it as AE-S, where the sentence embedding is an average of word embeddings, every word embedding is the mean of its sense embeddings and each sense is the mean of corresponding sememes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementation</head><p>In the preprocessing, punctuations, stop words and words appearing less than 10 times in the corpus are removed. The NLTK pos-tagger 3 is used to annotate part-of-speech information for each word within specific contexts. We initialize the word embedding matrix by word2vec <ref type="bibr" target="#b9">[Mikolov et al., 2013]</ref> trained on the experimental datasets, and the embedding size is set to 200. The word vocabulary size is set to 9, 000 for Restaurant and 11, 000 for Beer, which can cover 96.64% and 98.84% contents on these two datasets, respectively. We utilize WordNet <ref type="bibr" target="#b9">[Miller, 1995]</ref> to obtain word sememes. Specifically, each word is aggregated by 2 senses consisting of 5 sememes. Each sememe is represented by a set of words in their lemma forms, and its embedding is computed by averaging the corresponding word vectors in our experiments. The words in the two vocabularies can be fully covered by WordNet, hence every word can be expanded with ten sememes. 66.81% and 68.07% words representing sememes can be found in our vocabularies, respectively, and the rest OOV sememe words are padded with the original word itself. Following <ref type="bibr">[He et al., 2017]</ref>, we set the number of aspects for both datasets to 14 and utilize the centroids of k-means clusters to initialize aspect embedding matrix A.</p><p>Word embeddings are fixed during training. Adam <ref type="bibr" target="#b5">[Kingma and Ba, 2014]</ref> is employed as the optimizer with learning rate of 0.001. Orthogonality penalty weight λ is set to 2 on Restaurant and 2.5 on Beer, respectively. For both datasets, the number of negative samples q is 20, the dimensions of S, S i , S i are 200 and the hidden size of RNN structure h rnn is 500 . LSTM is adopted as the RNN structure for AE-CSA and our models use the same set of parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>As aspect embeddings are aligned with the word embedding space, we can infer the label of each aspect from its neighbor words in the embedding space and then manually build a mapping from the inferred aspects to the gold-standard labels following <ref type="bibr" target="#b14">[Zhao et al., 2010;</ref><ref type="bibr">Brody and Elhadad, 2010;</ref><ref type="bibr" target="#b12">Wang et al., 2015;</ref><ref type="bibr">He et al., 2017]</ref>. Remember that 14 distinct aspect embeddings are learnt on each dataset. Hence we infer these 14 aspects on the two datasets and map them to 6 and 5 gold-standard labels, respectively. For example, if an aspect embedding's nearest surrounding words in the embedding space are "espresso", "martini", "sangria", we can infer it as "Drinks" and then generalize it to "Food" in the Restaurant dataset. The results of SAS and SERBM are taken from <ref type="bibr" target="#b12">[Wang et al., 2015]</ref>, and the results of BTM and ABAE are taken from <ref type="bibr">[He et al., 2017]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Quantitative Analysis on Aspect Inference</head><p>We first conduct on a quantitative analysis to evaluate the performance on sentence-level aspect inference. With the annotated sentences in both datasets, we can compute how well the predictions match the true labels. To perform the prediction, we first assign an inferred aspect label according to the highest weight in h. Then, we generalize this inferred aspect to a gold-standard label according to a manually created mapping.</p><p>Table <ref type="table" target="#tab_3">2</ref> exhibits the results on Restaurant. Following <ref type="bibr">[He et al., 2017]</ref>, we only evaluate on aspects {Food, Staff, Ambi-ence} out of {Food, Staff, Ambience, Price, Anecdotes, Mis-cellaneous} and use sentences with single label to avoid ambiguity. AE-SA as well as AE-CSA significantly outperform the compared models on the Recall and F 1 measures. It proves the effectiveness of the proposed models structured with sememes on sentence-level aspect inference.</p><p>Table <ref type="table" target="#tab_5">3</ref> displays the results on Beer dataset. In addition to the 5 gold-standard aspect labels {Feel, Taste, Smell, Look, Others}, we follow <ref type="bibr">[He et al., 2017]</ref> to form a combined aspect "Taste+Smell" for a fair comparison. In Table <ref type="table" target="#tab_5">3</ref>, we observe that AE-CSA outperforms the previous models on 5 out of the 6 aspects on F 1 scores. Though AE-CSA cannot surpass the compared methods on every aspect, we still find the following interesting observations. As "Taste" and "Smell" are very similar and many words can be used interchangeably to describe both aspects, e.g., "bitter", "spicy" "sweet", etc. can describe either "Taste" or "Smell" of beer. So previous studies perform not very well on "Taste" and "Smell", and no one can exceed 0.6 on F 1 scores. While for our AE-CSA, since it perceives the fine-grained semantics with the context-  enhanced sememe attentions, it achieves 0.641 on F 1 on the "Taste" aspect. By looking closer to the top representative words from the results of AE-CSA on "Taste" and "Smell", we observe "smell, aroma" in "Smell" and "mouthfeel, wellcarbonated" in "Taste", which are clearly different. Moreover, ABAE-SEM performs slightly better than original ABAE with the help of sememes. Without the attention layers, AE-S exhibits imperfects compared with our proposed models. It runs even worse than ABAE on some aspects. These observations could also give insights on the effectiveness of the proposed sememe attentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Qualitative Analysis on Aspect Embeddings</head><p>As AE-CSA generally achieves the best performance on aspect inference among all the compared methods in the quantitative analysis, next we conduct a qualitative analysis to look closer to its aspect embeddings. In particular, we demonstrate all the 14 inferred aspects from the results of AE-CSA on Restaurant with their representative words, and the corresponding gold-standard aspect labels in Table <ref type="table" target="#tab_7">4</ref>. We observe the inferred aspects are fine-grained and their representative words are coherent and coupled. For example, it can discover the aspect terms like "brooklyn", "houston" and "manhattan" which are "Location" names and distinguish them from the words describing conceptual "Place" such as "balcony", "sta-  tion" and "entrance". Meanwhile, concrete and infrequent representative words can be retrieved, e.g. "risotto"<ref type="foot" target="#foot_4">foot_4</ref> . We conjecture it is because the context-enhanced sememe attentions that can discover fine-grained and latent information which contribute to better exploring aspect terms.</p><p>Next we design another experiment to testify the effectiveness of sememe attentions w.r.t different term frequencies. Specifically, we extract the highest attended word as the aspect term from each sentence in the test set. Then we get the inferred aspect for that sentence by querying the nearest aspect with the extracted word in the embedding space, and map them to the gold-standard labels. Finally, these aspect terms are divided into several intervals by their frequencies.</p><p>We measure the average F 1 score of 3 aspects on Restaurant and 6 aspects on Beer for each interval, and investigate the performances of some compared models. Figure <ref type="figure">5</ref> displays the results. First, AE-CSA performs better than the compared models on either frequent or infrequent aspect terms on both datasets. Meanwhile, the performance gap between AE-CSA and ABAE is getting smaller with aspect term frequency increasing. It exactly reflects the benefits of lexical semantic resources because frequent words usually have enough samples to learn effective representations while the low-frequent ones need external supports. As frequency increases, the effect of this support becomes insubstantial. Second, AS-SA performs worse than ABAE as frequency grows. It might be that though the exploitation of sememes attention is helpful for discovering the infrequent aspect terms, the performance may decrease without the constraint of the se-  quential encoding of the original sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Case Study</head><p>Finally we visualize the weight allocations of AE-SA vs ABAE, AE-CSA vs AE-SA and attentions in sense layer.</p><p>AE-SA vs ABAE. Given sentence shown as Fig. <ref type="figure" target="#fig_3">6</ref> (a), ABAE mainly focuses on the word "kids" and incorrectly infers the aspect as "Staff ". While AE-SA correctly assigns "Ambience" to it with the highly attended word "fit". Though "fit" seems not to be an explicit aspect term, one group of its sememes "suit, accommodate" in the WordNet may facilitate its correlation to the correct aspect.</p><p>AE-CSA vs AE-SA. Given sentence shown as Fig. <ref type="figure" target="#fig_3">6</ref> (b), it shows that AE-CSA focuses more on "minutes" while AE-SA attends to extract "appetizer". The sentence generally describes the service is slow, so the ground truth is supposed to be "Service" which is mapped to the gold-standard aspect label as "Staff ". The major reason for the difference is that the transformation matrix M of these two approaches are different. Note that M is trainable in our model as shown in Eq. 9.</p><p>We argue it is the RNN-based structure of AE-CSA that improves the aspect inference task by influencing the training of M to assign more weights to the appropriate words.</p><p>Attention in sense layer. Sememes can extend semantics but bring noise as well. The balance between semantic injection and word sense disambiguation can be underpinned by the RNN structure in AE-CSA that captures the overall sentence meaning and helps the attention layers to explore exact sememes. As shown in Figure <ref type="figure" target="#fig_3">6</ref> (c) and (d), the word "roll" has various attended senses in sentence. Specifically, word "roll" mostly consists of the "seethe" meaning in "carbonation roll around mouth", while it represents a kind of food as a noun in sentence "tootsie roll flavor is really nice". We argue it is sememes constructed with RNN encoder that discover fine-grained information based on right meaning of the context and contribute to better exploring aspect terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Aspect extraction. Aspect Extraction is important for sentiment analysis <ref type="bibr">[Wang et al., 2017a;</ref><ref type="bibr" target="#b7">Luo et al., 2018]</ref>, and existing work can be categorized into three types: rule-based, supervised, and unsupervised approaches. Rule-based methods <ref type="bibr">[Somasundaran and Wiebe, 2009;</ref><ref type="bibr" target="#b10">Qiu et al., 2011]</ref> exploited frequent pattern to extract product features. Supervised methods <ref type="bibr" target="#b4">[Jin et al., 2009;</ref><ref type="bibr" target="#b6">Li et al., 2010;</ref><ref type="bibr" target="#b2">Choi and Cardie, 2010;</ref><ref type="bibr" target="#b12">Wang et al., 2016;</ref><ref type="bibr" target="#b7">Wang and Pan, 2018]</ref> were typically built based on sequence labeling methods such as hidden Markov models (HMM) and conditional random fields (CRF), which required large amounts of labeled data for training. LDA-based methods <ref type="bibr" target="#b11">[Titov and McDonald, 2008;</ref><ref type="bibr">Brody and Elhadad, 2010;</ref><ref type="bibr" target="#b14">Zhao et al., 2010;</ref><ref type="bibr" target="#b9">Mukherjee and Liu, 2012;</ref><ref type="bibr" target="#b1">Chen et al., 2014]</ref> were representative methods of unsupervised solutions. <ref type="bibr" target="#b12">[Wang et al., 2015]</ref> proposed Restricted Boltzmann Machines based model to extract aspects and relevant sentiments simultaneously. <ref type="bibr" target="#b13">[Yin et al., 2016]</ref> used dependency path embeddings and <ref type="bibr">[Wang et al., 2017b]</ref> proposed multi-layer attentions while exploiting indirect relations between terms. <ref type="bibr" target="#b5">[Li and Lam, 2017]</ref>   <ref type="bibr">et al., 2018]</ref> encoded it to improve Chinese word representations and lexicon expansion. <ref type="bibr" target="#b6">[Li et al., 2018;</ref><ref type="bibr" target="#b9">Qi et al., 2018;</ref><ref type="bibr" target="#b5">Jin et al., 2018]</ref> study the lexical sememe prediction task with external resources. In this paper, we devise different sememe structures and investigate their effectiveness for aspect extraction. To the best of our knowledge, we are the first to apply sememes in unsupervised aspect extraction tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed unsupervised neural models incorporating sememes from lexical semantic resources for aspect extraction, where sememes are utilized by a hierarchical attention mechanism and a context-enhanced attention mechanism, respectively. Experiments showed that all models utilizing sememes improve aspect extraction in contrast to existing models because sememes help explore latent semantic information behind implicit and various expressions of sentences. Particularly, the context-enhanced sememe attention model performs better on identifying real aspects within the specific contexts and raising on the long-tail aspect terms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Statistics on aspect term frequency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The structure of sememes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The structure of sememe attention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Visualization of weight allocations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the two datasets.are variants of LDA-based models. Deep neural models are SERBM<ref type="bibr" target="#b12">[Wang et al., 2015]</ref> andABAE [He et al., 2017].</figDesc><table><row><cell>Dataset</cell><cell>Reviews #</cell><cell>Labeled Sentences #</cell></row><row><cell>Restaurant</cell><cell>52,574</cell><cell>3,400</cell></row><row><cell>Beer</cell><cell>1,586,259</cell><cell>9,245</cell></row></table><note><p>and BTM [Yan et al., 2013]   </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Aspect inference results on the Restaurant dataset.</figDesc><table><row><cell>Aspect</cell><cell>Model</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell></row><row><cell></cell><cell>SAS</cell><cell>0.867</cell><cell>0.772</cell><cell>0.817</cell></row><row><cell></cell><cell>BTM</cell><cell>0.933</cell><cell>0.745</cell><cell>0.816</cell></row><row><cell></cell><cell>SERBM</cell><cell>0.891</cell><cell>0.854</cell><cell>0.872</cell></row><row><cell></cell><cell>ABAE</cell><cell>0.953</cell><cell>0.741</cell><cell>0.828</cell></row><row><cell></cell><cell>ABAE-SEM</cell><cell>0.870</cell><cell>0.914</cell><cell>0.892</cell></row><row><cell>Food</cell><cell>AE-S (Ours)</cell><cell>0.846</cell><cell>0.914</cell><cell>0.879</cell></row><row><cell></cell><cell>AE-SA (Ours)</cell><cell>0.883</cell><cell>0.923</cell><cell>0.902</cell></row><row><cell></cell><cell>AE-CSA (Ours)</cell><cell>0.903</cell><cell>0.926</cell><cell>0.914</cell></row><row><cell></cell><cell>SAS</cell><cell>0.774</cell><cell>0.556</cell><cell>0.647</cell></row><row><cell></cell><cell>BTM</cell><cell>0.828</cell><cell>0.579</cell><cell>0.677</cell></row><row><cell></cell><cell>SERBM</cell><cell>0.819</cell><cell>0.582</cell><cell>0.680</cell></row><row><cell></cell><cell>ABAE</cell><cell>0.802</cell><cell>0.728</cell><cell>0.757</cell></row><row><cell></cell><cell>ABAE-SEM</cell><cell>0.793</cell><cell>0.730</cell><cell>0.760</cell></row><row><cell>Staff</cell><cell>AE-S (Ours)</cell><cell>0.757</cell><cell>0.653</cell><cell>0.701</cell></row><row><cell></cell><cell>AE-SA (Ours)</cell><cell>0.844</cell><cell>0.705</cell><cell>0.768</cell></row><row><cell></cell><cell>AE-CSA (Ours)</cell><cell>0.804</cell><cell>0.756</cell><cell>0.779</cell></row><row><cell></cell><cell>SAS</cell><cell>0.780</cell><cell>0.542</cell><cell>0.640</cell></row><row><cell></cell><cell>BTM</cell><cell>0.813</cell><cell>0.599</cell><cell>0.685</cell></row><row><cell></cell><cell>SERBM</cell><cell>0.805</cell><cell>0.592</cell><cell>0.682</cell></row><row><cell></cell><cell>ABAE</cell><cell>0.815</cell><cell>0.698</cell><cell>0.740</cell></row><row><cell></cell><cell>ABAE-SEM</cell><cell>0.769</cell><cell>0.713</cell><cell>0.740</cell></row><row><cell>Ambience</cell><cell>AE-S (Ours)</cell><cell>0.759</cell><cell>0.677</cell><cell>0.716</cell></row><row><cell></cell><cell>AE-SA (Ours)</cell><cell>0.771</cell><cell>0.715</cell><cell>0.742</cell></row><row><cell></cell><cell>AE-CSA (Ours)</cell><cell>0.768</cell><cell>0.773</cell><cell>0.770</cell></row></table><note><p>3 https://www.nltk.org/ modules/nltk/tag.html</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Aspect inference results on the Beer dataset.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Example aspects inferred by AE-CSA on the Restaurant dataset, with their representative words and the corresponding goldstandard aspect labels. The left column shows 14 manually labeled inferred aspects. The middle column shows the representative words selected from top 5 nearest words of each aspect embedding. The right column presents the gold-standard aspects.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AE-CSA</cell><cell></cell><cell>AE-SA</cell><cell>ABAE</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Restaurant Dataset</cell><cell></cell><cell>0.81</cell><cell></cell><cell></cell><cell cols="2">Beer Dataset</cell></row><row><cell></cell><cell>0.84</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.80</cell><cell></cell><cell></cell><cell></cell></row><row><cell>F1 score</cell><cell>0.82</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.78 0.79</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.80</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.77</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>&lt;1</cell><cell>1-2</cell><cell>2-3</cell><cell>3-4</cell><cell>4-5</cell><cell>5-6</cell><cell>&gt;7</cell><cell>&lt;3</cell><cell>3-6</cell><cell>6-9</cell><cell>9-12 12-15 15-18 &gt;18</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">frequency(*100)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">frequency(*100)</cell></row><row><cell cols="12">Figure The F1 score of different frequency intervals of aspect</cell></row><row><cell cols="5">terms on both datasets.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>utilized a memory interaction structure[He et al., 2017]  adopted attention mechanism with word embeddings to improve aspect coherence. Sememe representation learning. Recently, sememes from lexical semantic resources are utilized to recognize different word senses in various contexts and applied in many NLP tasks.<ref type="bibr" target="#b9">[Niu et al., 2017]</ref>,<ref type="bibr" target="#b10">[Song et al., 2017]</ref> and [Zeng</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>This dataset, a benchmark for aspect-based sentiment classification task, includes the reviews from restaurant and laptop domain with 1,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="288" xml:id="foot_1"><p>and 1, 042 different annotated aspect terms, respectively.Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>Here the aspect indicates topical aspect category, which is distinct from aspect term. For example, "seaweed" is an aspect term in "The seaweed was chewy like gum", and "Food" could be its topical aspect category. We will continue to use the notion of "aspect" as topical aspect category hereafter unless other specified.Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Proceedings of the Twenty-Eighth Joint Conference on Artificial Intelligence </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4"><p>Rice cooked usually in meat or seafood stock and seasoned.Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is partially supported by the <rs type="funder">National Key Research and Development Program of China</rs> under Grant No. <rs type="grantNumber">2017YFB1002104</rs>, the <rs type="funder">National Natural Science Foundation of China</rs> under Grant No. <rs type="grantNumber">91846113</rs>, <rs type="grantNumber">U1811461</rs>, <rs type="grantNumber">61602438</rs>, <rs type="grantNumber">61573335</rs>, <rs type="funder">CCF-Tencent RhinoBird Young Faculty Open Research Fund</rs> No. <rs type="grantNumber">RAGR20180111</rs>. This work is also funded in part by <rs type="funder">Ant Financial</rs> through the <rs type="funder">Ant Financial Science Funds for Security Research</rs>. Xiang Ao is also supported by <rs type="funder">Youth Innovation Promotion Association CAS</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uzWRvTf">
					<idno type="grant-number">2017YFB1002104</idno>
				</org>
				<org type="funding" xml:id="_QgEcnSx">
					<idno type="grant-number">91846113</idno>
				</org>
				<org type="funding" xml:id="_cURRbc2">
					<idno type="grant-number">U1811461</idno>
				</org>
				<org type="funding" xml:id="_BG54Xfu">
					<idno type="grant-number">61602438</idno>
				</org>
				<org type="funding" xml:id="_kyXmDda">
					<idno type="grant-number">61573335</idno>
				</org>
				<org type="funding" xml:id="_xbb4zCH">
					<idno type="grant-number">RAGR20180111</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Brody and Elhadad, 2010] Samuel Brody and Noemie Elhadad. An unsupervised aspect-sentiment model for online reviews</title>
		<author>
			<persName><forename type="first">Leonard</forename><surname>Bloomfield</surname></persName>
		</author>
		<author>
			<persName><surname>Bloomfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1926">1926. 1926. 2010</date>
		</imprint>
	</monogr>
	<note>A set of postulates for the science of language. Language</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Aspect extraction with automated prior knowledge learning</title>
		<author>
			<persName><forename type="first">Chen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical sequential learning for extracting opinions and their attributes</title>
		<author>
			<persName><forename type="first">Cardie</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ruidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel Dahlmeier. An unsupervised neural attention model for aspect extraction</title>
		<author>
			<persName><surname>Ganu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WebDB</title>
		<imprint>
			<date type="published" when="2009">2009. 2009. 2017</date>
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A novel lexicalized hmm-based learning framework for web opinion mining</title>
		<author>
			<persName><forename type="first">Jin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep multi-task learning for aspect term extraction with memory interaction</title>
		<author>
			<persName><forename type="first">Jin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Li and Lam</publisher>
			<date type="published" when="2014">2018. 2018. 2014. 2014. 2017. 2017</date>
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Structure-aware review mining and summarization</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.05437</idno>
	</analytic>
	<monogr>
		<title level="m">Sememe prediction: Learning semantic knowledge from unstructured textual wiki descriptions</title>
		<editor>
			<persName><surname>Li</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2010">2010. 2010. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>COLING</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Beyond polarity: Interpretable financial sentiment analysis with hierarchical querydriven attention</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2012">2012. 2012. 2018. 2018</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="167" />
		</imprint>
	</monogr>
	<note>Synthesis lectures on human language technologies</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning attitudes and attributes from multi-aspect reviews</title>
		<author>
			<persName><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<editor>
			<persName><forename type="first">Ruobing</forename><surname>Niu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zhiyuan</forename><surname>Xie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Maosong</forename><surname>Liu</surname></persName>
		</editor>
		<editor>
			<persName><surname>Sun</surname></persName>
		</editor>
		<imprint>
			<publisher>Mukherjee and Liu</publisher>
			<date type="published" when="1995">2013. 2013. 1995. 1995. 2012. 2012. 2017. 2017. 2018</date>
			<biblScope unit="volume">38</biblScope>
		</imprint>
	</monogr>
	<note>NIPS</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Opinion word expansion and target extraction through double propagation</title>
		<author>
			<persName><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Swapna Somasundaran and Janyce Wiebe</title>
		<imprint>
			<publisher>Somasundaran and Wiebe</publisher>
			<date type="published" when="2009">2011. 2011. 2015. 2009. 2009. 2017. 2017</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="9" to="27" />
		</imprint>
	</monogr>
	<note>CoNLL</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wang and Pan, 2018] Wenya Wang and Sinno Jialin Pan. Transition-based adversarial network for cross-lingual aspect extraction</title>
		<author>
			<persName><forename type="first">Mcdonald</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2008">2008. 2008. 2018</date>
		</imprint>
	</monogr>
	<note>WWW</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining knowledge with deep convolutional neural networks for short text classification</title>
		<author>
			<persName><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>Wenya Wang</publisher>
			<date type="published" when="2015">2015. 2015. 2016. 2016. 2017. 2017. 2017. 2017</date>
			<biblScope unit="page" from="3316" to="3322" />
		</imprint>
		<respStmt>
			<orgName>Sinno Jialin Pan, Daniel Dahlmeier, and Xiaokui Xiao</orgName>
		</respStmt>
	</monogr>
	<note>AAAI</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Chinese liwc lexicon expansion via hierarchical classification of word embeddings with sememe attention</title>
		<author>
			<persName><forename type="first">Yan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<editor>
			<persName><surname>Zeng</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013. 2013. 2016. 2016. 2018</date>
		</imprint>
	</monogr>
	<note>Unsupervised word and dependency path embeddings for aspect term extraction</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects and opinions with a maxent-lda hybrid</title>
		<author>
			<persName><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
