<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Detection of Two-Way Outliers in Multivariate Data and Application to Cheating Detection in Educational Tests</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yunxiao</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">London School of Economics and Political Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yan</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">London School of Economics and Political Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Irini</forename><surname>Moustaki</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">London School of Economics and Political Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Detection of Two-Way Outliers in Multivariate Data and Application to Cheating Detection in Educational Tests</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T18:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian hierarchical model</term>
					<term>outlier detection</term>
					<term>false discovery rate</term>
					<term>compound decision</term>
					<term>test fairness</term>
					<term>item response theory</term>
					<term>latent class analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper proposes a new latent variable model for the simultaneous (two-way) detection of outlying individuals and items for item-response-type data. The proposed model is a synergy between a factor model for binary responses and continuous response times that captures normal item response behaviour and a latent class model that captures the outlying individuals and items. A statistical decision framework is developed under the proposed model that provides compound decision rules for controlling local false discovery/nondiscovery rates of outlier detection. Statistical inference is carried out under a Bayesian framework, for which a Markov chain Monte Carlo algorithm is developed. The proposed method is applied to the detection of cheating in educational tests due to item leakage using a case study of a computer-based nonadaptive licensure assessment. The performance of the proposed method is evaluated by simulation studies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Factor models <ref type="bibr" target="#b4">(Bartholomew et al., 2011)</ref> are widely used to analyse multivariate data, especially item-response-type data which involve individuals' responses to a set of items.</p><p>For example, in educational testing, unidimensional and multidimensional factor models, which are also known as Item Response Theory (IRT) models <ref type="bibr" target="#b25">(Embretson and Reise, 2000;</ref><ref type="bibr" target="#b54">Reckase, 2009)</ref>, are commonly used to model test takers' responses to test items. In these applications, a latent factor is often interpreted as the ability that the test is designed to assess. In psychology, multidimensional factor models are typically used to describe respondents' answers to items in a psychological questionnaire <ref type="bibr" target="#b76">(Wirth and Edwards, 2007)</ref>, where the factors are interpreted as psychological traits (e.g., personality traits). In political science, similar models, which are often known as idea point models, are used to describe voting behaviours <ref type="bibr" target="#b3">(Bafumi et al., 2005)</ref>, where the factors are typically interpreted as voters' political standing.</p><p>It is often the case that real data contain outliers among both the individuals and the items. Such outliers can lead to a substantial deviation from a carefully specified factor model which may be supported by substantive theory and historical data. These outliers often provide insights about the data and it is thus of substantive interest to detect them. One example is Differential Item Functioning (DIF; <ref type="bibr" target="#b33">Holland and Wainer, 1993;</ref><ref type="bibr" target="#b43">Millsap, 2012)</ref>, a phenomenon that is widely observed in educational testing, psychological measurement, as well as other related areas. It happens when a subset of items do not measure subgroups (e.g., gender, race) in the same way. Specifically, in educational testing, it might be the case that a subset of items are "easier" or "more difficult" for a certain subgroup than the others. In this case, the subgroup of test takers and the subset of items may be viewed as outliers, for whom a factor model that fits the rest of the data may fail. A related, while more challenging, problem is the detection of latent DIF <ref type="bibr" target="#b16">(Cho et al., 2016)</ref>, for which not only the DIF items but also the group membership of individuals are not known a priori (two-way detection of outliers). One such example is the detection of cheating in educational tests due to item leakage that benefits test takers through the preknowledge of leaked items <ref type="bibr" target="#b17">(Cizek and Wollack, 2017)</ref>. Latent DIF may also exist in educational tests due to other reasons; see <ref type="bibr" target="#b16">Cho et al. (2016)</ref> for a review. Similar problems also occur in other areas besides educational testing. For example, in political science, it has been well recognised that roll call voting data of the United States Congress can largely be described by a liberal-conservative latent dimension with some minor deviations <ref type="bibr">(Poole and Rosenthal, 1991;</ref><ref type="bibr">Poole et al., 1991)</ref>. Through a two-way outlier-detection formulation, i.e., by detecting outlying legislators and roll calls that do not fit the unidimensional model, one may obtain a better understanding of the patterns of roll call voting that cannot be explained by the liberal-conservative dimension. Latent DIF may also exist in psychological measurement data in which a two-way outlier-detection formulation can facilitate the discovery of minor psychological traits and the relevant groups.</p><p>While statistical methods have been well established for the detection of DIF <ref type="bibr" target="#b43">(Millsap, 2012)</ref>, models and procedures for detecting latent DIF (two-way outliers) remain to be developed. We therefore propose a two-way outlier detection model to fill the gap that adds a latent class model component upon a factor model. The factor model component serves as a baseline model for data without outliers, and a latent class model component is used to capture the two-way outliers. Specifically, the proposed model imposes latent class structures among both the individuals and the items, rather than only assuming latent classes among the individuals as in the classical latent class analysis <ref type="bibr" target="#b1">(Allman et al., 2009;</ref><ref type="bibr" target="#b31">Goodman, 1974;</ref><ref type="bibr" target="#b38">Lazarsfeld and Henry, 1968</ref>). The proposed model is closely related to, but also substantially different from, existing statistical models and methods for the detection of outliers in multivariate data (see e.g., <ref type="bibr" target="#b10">Candès et al., 2011;</ref><ref type="bibr" target="#b32">Hadi, 1992;</ref><ref type="bibr">Mavridis and Moustaki, 2008,0;</ref><ref type="bibr" target="#b55">Reiser, 1996;</ref><ref type="bibr" target="#b73">Wang and Xu, 2015;</ref><ref type="bibr" target="#b74">Wang et al., 2018;</ref><ref type="bibr">Zhou et al., 2010)</ref> Under the proposed model, statistical decision theory is established for the detection of two-way outliers. Motivated by compound decision theory for multiple testing <ref type="bibr" target="#b6">(Benjamini and Hochberg, 1995;</ref><ref type="bibr">Efron, 2004,0,1;</ref><ref type="bibr" target="#b24">Efron et al., 2001;</ref><ref type="bibr" target="#b57">Robbins, 1951;</ref><ref type="bibr" target="#b69">Sun and Cai, 2007;</ref><ref type="bibr" target="#b80">Zhang, 2003)</ref>, we propose the local False Discovery Rate (FDR) and local False Non-discovery Rate (FNR) as compound risk measures for the detection of two-way outliers. Decision rules are developed based on these measures, for which optimality results are established. The statistical inference and decision making are performed under a fully Bayesian framework, for which a Markov chain Monte Carlo (MCMC) algorithm is developed. Since our model involves many discrete latent variables, standard MCMC algorithms such as Gibbs and Metropolis-Hastings can suffer from slow mixing (e.g., <ref type="bibr" target="#b13">Celeux et al., 2000;</ref><ref type="bibr" target="#b56">Richardson and Green, 1997)</ref>. We tackle this problem by applying the parallel tempering technique <ref type="bibr" target="#b29">(Geyer, 2011)</ref>.</p><p>The proposed method is applied to cheating detection based on data from the single administration of a non-adaptive test. It simultaneously detects outlying test takers and items as potential cheaters and compromised items. The proposed method uses item response data and item response time data, which are often collected in computer-based testing, for improving outlier detection. As shown via our real data analysis and simulation studies, incorporating response time information can improve outlier detection accuracy. Our simulation results further suggest that the proposed model is quite robust against various forms of model misspecification, even though it relies on some parametric assumptions that may not be satisfied perfectly in practice.</p><p>The detection of test takers who benefit from item preknowledge (cheaters) and compromised items has received much attention among quantitative researchers in education. <ref type="bibr">Specifically, McLeod et al. (2003)</ref> proposed a person-fit index for the detection of cheaters in computerised adaptive testing, under an IRT model. For non-adaptive testing, <ref type="bibr" target="#b5">Belov (2013)</ref> proposed a person-fit index for characterising the outperformance of a student on the compromised items, assuming that the set of compromised items is known. Under a similar setting, <ref type="bibr">Sinharay (2017a)</ref> proposed likelihood-ratio and score tests for the detection of cheaters, and <ref type="bibr" target="#b61">Segall (2002)</ref> and <ref type="bibr" target="#b63">Shu et al. (2013)</ref> proposed IRT models for item preknowledge and developed Bayesian classification procedures. For the detection of compromised items, O' <ref type="bibr">Leary and Smith (2017)</ref> and <ref type="bibr" target="#b75">Wang and Liu (2020)</ref> proposed methods based on data from the single administration of a non-adaptive test. These approaches require knowledge of a subset of non-compromised items to first identify a set of potential cheaters. The detection of compromised items relies on the identified cheaters in the first stage. Under an online setting where data from multiple tests are sequentially collected, <ref type="bibr" target="#b71">Veerkamp and Glas (2000)</ref>, <ref type="bibr" target="#b81">Zhang (2014)</ref>, <ref type="bibr">Chen and</ref><ref type="bibr" target="#b15">Li (2019), and</ref><ref type="bibr" target="#b14">Chen et al. (2020)</ref> formulated the detection of compromised items as a sequential change detection problem and proposed sequential procedures. We refer the readers to three edited volumes, <ref type="bibr" target="#b77">Wollack and Fremer (2013)</ref>, <ref type="bibr" target="#b36">Kingston and Clark (2014)</ref> and <ref type="bibr" target="#b17">Cizek and Wollack (2017)</ref>, for a comprehensive review of related works. Note that most of the existing methods focus on the detection of either cheaters or compromised items, and often require prior information which is not always available, for example a given subset of non-compromised items. In contrast, the proposed method can simultaneously detect both test takers with item preknowledge and compromised items without such prior information.</p><p>The rest of the paper is organised as follows. In Section 2, we propose a statistical model for detecting two-way outliers in multivariate data and discuss its application to cheating detection. Statistical decision theory is developed under a Bayesian framework in Section 3, and Bayesian inference procedures are given in Section 4. The proposed method is applied to a real dataset from a licensure test in Section 5. Simulation studies are presented in Section 6 to further evaluate the performance of the proposed method under various situations. Concluding remarks are provided in Section 7. The appendix contains the proof of a theoretical result, the details of the developed MCMC algorithm, and additional simulation results.</p><p>2 Proposed Two-Way Outlier Detection Model 2.1 A Two-Way Outlier Detection Model for Multivariate Data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Background and Notation</head><p>Consider N individuals responding to J items. Let Y ij be individual i's response to item j. We focus on binary responses, i.e., Y ij = 0, 1, where the two types of responses may correspond to incorrect and correct answers in educational testing, and "no" and "yes" responses in psychological measurement, among others. We use Y i = (Y i1 , ..., Y iJ ) to denote the response vector from individual i and use Y = (Y ij ) N ×J to denote the response matrix.</p><p>When item-response data are collected digitally rather than by paper and pencil, which is becoming more and more popular these days, response time data may also be collected. Let T ij denote the amount of time individual i spends to answer item j and T = (T ij ) denote the data matrix for response times.</p><p>In what follows, we discuss the two-way outlier detection model for (Y, T). We introduce a latent binary variable ξ i that takes the value 1 when individual i is an outlier and 0 otherwise. Similarly, η j is a latent binary variable that takes the value 1 when item j is an outlier and 0 otherwise. Figure <ref type="figure" target="#fig_0">1</ref> illustrates how data are affected by the two-way outliers in the proposed model. (Y ij , T ij ) are modelled with the outlier model if, and only if, both ξ i = 1 and η j = 1, which represents a typical phenomenon of latent DIF. In the cheating detection application, items with η j = 1 correspond to the leaked/compromised items and individuals with ξ i = 1 correspond to test takers who have preknowledge about all the compromised items before taking the test. In this context, a baseline model will capture the normal itemresponse behaviour, and the outlier model will capture the behaviour of the test takers with preknowledge when responding to the compromised items. In particular, the outlier model will allow test takers to have a higher probability of answering leaked items correctly and with a shorter response time (see, e.g. <ref type="bibr" target="#b74">Wang et al., 2018)</ref>. The proposed model is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Proposed model</head><p>We start with a relatively more general model and then give specific examples. We introduce θ i and τ i as the person-specific parameters, also known as the factors, that drive the item responses and the response times, respectively. Both θ i and τ i can be unidimensional or multidimensional, but their dimensions are typically assumed to be much smaller than J. We also introduce β j and α j to denote the item-specific parameters for the item responses and the response times, respectively. To simplify the notation, we use Θ i = (θ i , ξ i , τ i ) and ∆ j = (β j , η j , α j ) to denote the person-and item-specific parameter vectors, respectively.</p><p>The proposed model consists of two submodels, one for binary item responses and one for continuous response times. The item-response submodel takes the following logistic form</p><formula xml:id="formula_0">P (Y ij = 1|Θ i , ∆ j , δ) := p(Θ i , ∆ j , δ) = exp(h 1 (θ i , β j ) + ξ i η j δ) 1 + exp(h 1 (θ i , β j ) + ξ i η j δ) ,</formula><p>where δ is a non-negative parameter and h 1 (•, •) is a pre-specified function. Given ξ i = 0 or</p><formula xml:id="formula_1">η j = 0, p(Θ i , ∆ j , δ) = exp(h 1 (θ i , β j )) 1 + exp(h 1 (θ i , β j ))</formula><p>is the baseline item-response submodel for non-outlying item responses. When ξ i = η j = 1, the term ξ i η j δ = 0 captures the deviation from the baseline model. In particular, for our application, the parameter δ is set to be non-negative to let the probability of providing a correct answer (i.e., Y ij = 1) increase when individual i and item j are outliers. In this context, δ may be interpreted as the advantage that a test taker gains from item pre-knowledge.</p><p>In other applications, this sign constraint can be removed if such prior information is not available. To keep the model parsimonious, the parameter δ is assumed to be the same across all the outlying individuals and items. As will be discussed in Section 2.2, this assumption can be relaxed.</p><p>The function h 1 should be chosen based on knowledge about the baseline model from substantive theory and/or historical data. We give two parametric examples of h 1 below, but point out that h 1 can also take a non-parametric form as in non-parametric IRT models <ref type="bibr" target="#b18">(Douglas, 1997;</ref><ref type="bibr" target="#b19">Duncan and MacEachern, 2008;</ref><ref type="bibr" target="#b52">Ramsay and Winsberg, 1991)</ref>.</p><p>Example 1. The Rasch model <ref type="bibr" target="#b53">(Rasch, 1960)</ref> is one of the most popular IRT models in educational testing, and is also widely used in many other areas. In particular, the licensure test to be studied in Section 5 is designed and scored under this model. The Rasch model assumes that both θ i and β j are unidimensional. With slight abuse of notation, we denote them by non-bold typeface θ i and β j , respectively. This model assumes that h 1 (θ i , β j ) = θ i -β j , which leads to</p><formula xml:id="formula_2">p(Θ i , ∆ j , δ) = exp(θ i -β j + ξ i η j δ) 1 + exp(θ i -β j + ξ i η j δ)</formula><p>.</p><p>(1)</p><p>In the context of educational testing, θ i and β j are interpreted as the ability of test taker i and the difficulty of item j, respectively. When there are no outliers, the probability of correctly answering an item is monotone increasing with one's ability θ i and monotone decreasing with the item's difficulty β j . When ξ i = 1 and η j = 1, logit(P</p><formula xml:id="formula_3">(Y ij = 1|Θ i , ∆ j , δ)) = θ i -β j + δ.</formula><p>That is, the item response function still takes a Rasch form, but the log odds increases by a constant drift δ. This Rasch-type item-response submodel (1) will be further discussed in the rest of the paper, given its suitability for our case study in Section 5.</p><p>Example 2. It may be the case that the J items simultaneously measure K factors, θ i = (θ i1 , ..., θ iK ), for which a multidimensional factor model is needed. In that situation, we</p><formula xml:id="formula_4">may set h 1 (θ i , β j ) = β j0 + β j1 θ i1 + • • • + β jK θ iK , where β j = (β j0 , ..., β jK ) contains K + 1</formula><p>item-specific parameters. The item-response submodel then becomes</p><formula xml:id="formula_5">p(Θ i , ∆ j , δ) = exp(β j0 + β j1 θ i1 + • • • + β jK θ iK + ξ i η j δ) 1 + exp(β j0 + β j1 θ i1 + • • • + β jK θ iK + ξ i η j δ) .<label>(2)</label></formula><p>When ξ i = 0 or η j = 0, (2) becomes the multidimensional two-parameter logistic model <ref type="bibr" target="#b54">(Reckase, 2009)</ref> which includes the two-parameter logistic model <ref type="bibr" target="#b7">(Birnbaum, 1968</ref>) as a special case when K = 1.</p><p>The response-time submodel is specified similarly to the item-response submodel. Specifically, we consider a log-normal model which assumes that</p><formula xml:id="formula_6">log(T ij )|Θ i , ∆ j , γ, κ ∼ N (h 2 (τ i , α j ) -ξ i η j γ, κ) ,</formula><p>where γ is another non-negative parameter that plays a similar role to δ in the item-response submodel, h 2 (•, •) is a pre-specified function, and κ &gt; 0 is the variance of the normal distribution. In our application, the parameter γ is set to be non-negative to allow the response time for outlying individuals and items to be shorter (test takers with preknowledge tend to answer the compromised items faster). That is, when ξ i = 1 and η j = 1, the mean log-time is reduced from the baseline level h 2 (τ i , α j ) to h 2 (τ i , α j ) -γ. In that context, γ may be interpreted as the reduction in response time due to item preknowledge. Similar to the discussion about parameter δ, the sign constraint on γ can also be removed if there is no such prior knowledge about the response times. We assume that the same γ and κ are shared by all the individuals and items for model parsimony, which can be relaxed.</p><p>The choice of function h 2 is similar to the choice of function h 1 in the item-response submodel. In what follows, we give a specific example, but also point out that other choices of h 2 are possible. In particular, one can choose h 2 so that the baseline response-time submodel is consistent with the one proposed in van der Linden (2007).</p><p>Example 3. Similar to the Rasch-type model in Example 1, we let both τ i and α j be unidimensional and denote them by non-bold typeface τ i and α j . We let function h 2 take the form h 2 (τ i , α j ) = α j -τ i , which leads to</p><formula xml:id="formula_7">log(T ij )|Θ i , ∆ j , γ, κ ∼ N (α j -τ i -ξ i η j γ, κ) .<label>(3)</label></formula><p>When ξ i = 0 or η j = 0, we obtain the baseline model for response times</p><formula xml:id="formula_8">log(T ij )|Θ i , ∆ j , γ, κ ∼ N (α j -τ i , κ) .</formula><p>In the context of educational testing, τ i can be interpreted as the speed factor of test taker i and α j can be interpreted as the time-consumingness of item j. When there are no outliers, the mean response time is monotone increasing with the item-specific time-consumingness α j and monotone decreasing with the person-specific speed factor τ i . This response-time submodel will be applied to our case study in Section 5.</p><p>Like many other latent variable models, conditional independence assumptions are imposed. We first assume that (Y ij , T ij ), j = 1, ..., J, are conditionally independent given Θ i , ∆ j , δ, γ, and κ. Such a conditional independence assumption across items is often known as the local independence assumption. We further assume that Y ij and T ij are conditionally independent given Θ i , ∆ j , δ, γ, and κ, meaning that all the person effects on the response and response time distribution are captured by the person parameters. Such conditional independence assumptions are commonly made in latent variable models for item responses and response times. We refer the readers to van der Linden (2007) for the substantive justifications.</p><p>We further adopt a Bayesian hierarchical modelling framework, under which parameters Θ i , ∆ j , δ, γ, and κ are treated as random variables. Specifically, we let Θ i , i = 1, ..., N , be independent and identically distributed (i.i.d.) samples from distribution g 1 (Θ|ν 1 ) and ∆ j , j = 1, ..., J, be i.i.d. samples from distribution g 2 (∆|ν 2 ), respectively, where g 1 and g 2 characterise the population of individuals and the domain of items, respectively. Both g 1 and g 2 are taken to be parametric distributions and use ν 1 and ν 2 as generic notations for the hyperparameters of the two distributions, respectively. This hierarchical modelling structure is visualised in Figure <ref type="figure" target="#fig_1">2</ref> using a graphical model representation. We showcase the specification of g 1 , g 2 , and the priors for ν 1 , ν 2 , δ, γ, and κ in Section 4.1 under the specific model with item-response submodel (1) and response-time submodel (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Model without response time data</head><p>Sometimes, response time information is not collected, for example, in paper-and-pencilbased educational tests. In that case, response times are missing completely at random and the proposed model reduces to a model for item responses. This reduced model only contains parameters from the item-response submodel and the corresponding hyperpriors.</p><p>The graphical representation of this reduced model is given in Figure <ref type="figure" target="#fig_2">3</ref>, where the reduced person and item parameters are denoted by Θ i = (θ i , ξ i ) and ∆ j = (β j , η j ), respectively, and the corresponding hyperparameters are still denoted by ν 1 and ν 2 , respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Application to the detection of item preknowledge</head><p>The proposed model framework requires that the baseline model is correctly specified. Any deviation from it is solely attributed to item preknowledge and not to other aberrant situations, such as more than one latent dimension (multidimensionality) needed to explain the associations among the items. Although this assumption might appear to be strong, it can still be examined using historical test data with no leaked items and test takers from the same population.</p><p>Furthermore, the validity of the model interpretation also depends on the extent to which our parametric assumptions hold. Section 2.2 discusses how some of those parametric assumptions can be violated in practice and can be also relaxed. In addition, as shown via simulation studies in Section 6, the proposed two-way outlier detection model tends to be robust against several forms of model misspecification.</p><p>Finally, we emphasise that, given the sensitivity of decisions regarding cheating in tests and the relatively strong assumptions of the proposed model, the latent classes resulting from the two-way detection should be interpreted with caution (i.e. leaked items and test takers with pre-knowledge). Results from our model can provide warnings to the test administrators, but the detected outlying cases should be further investigated and verified using additional sources of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model Generalisations</head><p>Key components of the proposed two-way outlier detection model are the interaction terms ξ i η j δ and ξ i η j γ in the item-response and response-time submodels, respectively. Specifically, the effects of the two-way outliers are characterised by the parameters δ and γ in the two submodels, respectively, and they are assumed to be the same across all the outliers. This assumption can be relaxed to allow for heterogeneity among the outliers. One way to relax this assumption is by assuming each drift parameter to be the sum of a person-specific parameter and an item-specific parameter. For example, one may replace ξ i η j δ by ξ i η j (δ i +δ j )</p><p>in the item-response submodel, where δ i and δ j are non-negative person-and item-specific drift parameters, respectively.</p><p>Moreover, in the current framework, the outlier model is essentially unidimensional, as a result of the imposed two-way latent class structure. In the application to the detection of item preknowledge, it means that a test taker has preknowledge of either all or none of the leaked items. However, when there are multiple sources of item leakage and test takers with item preknowledge have access to one or more of those sources, this assumptions can be relaxed by assuming multiple latent classes among both the individual and item outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Related Works</head><p>Factor analysis in the presence of outliers has received much attention in the literature, but mainly focuses on the detection of outlying cases/individuals rather than items as well. One line of research is on the robust estimation of factor models <ref type="bibr" target="#b44">(Moustaki and Victoria-Feser, 2006;</ref><ref type="bibr" target="#b47">Pison et al., 2003;</ref><ref type="bibr">Yuan and</ref><ref type="bibr">Bentler, 1998, 2001)</ref>. Another line of research focuses on the detection of outliers among the individuals who do not fit a baseline factor model, using residual-based procedures <ref type="bibr" target="#b55">(Reiser, 1996)</ref> or forward search procedures <ref type="bibr" target="#b32">(Hadi, 1992;</ref><ref type="bibr">Mavridis and Moustaki, 2008,0)</ref>. All these works only consider outlying individuals. The proposed two-way outlier detection method is among the very few attempts to simultaneously classify individuals and items as outliers.</p><p>Although several models that combine factor and latent class modeling have been proposed for detecting aberrant behaviours <ref type="bibr" target="#b8">(Bolt et al., 2002;</ref><ref type="bibr" target="#b9">Boughton and Yamamoto, 2007;</ref><ref type="bibr" target="#b30">Goegebeur et al., 2008;</ref><ref type="bibr" target="#b63">Shu et al., 2013;</ref><ref type="bibr" target="#b73">Wang and Xu, 2015;</ref><ref type="bibr" target="#b74">Wang et al., 2018)</ref>, none of them is about two-way classification of individuals and items.</p><p>Another feature of our model is that it does not require any prior knowledge about the outlying individuals and items (e.g. a subset of compromised items). <ref type="bibr" target="#b63">Shu et al. (2013)</ref> proposed a Deterministic, Gated item response theory Model (DGM) for data consisting only of item responses. This model makes similar assumptions to our item-response submodel, except that (1) the DGM assumes the known status of each item (i.e., whether each item is compromised or not), and (2) the drift parameter for cheating (i.e., δ in the current model) is assumed to be person-specific in the DGM. Our model is more closely related to <ref type="bibr" target="#b73">Wang and Xu (2015)</ref> and <ref type="bibr" target="#b74">Wang et al. (2018)</ref> who also assume a mixture of log-normal distribution for response times from normal and aberrant response behaviours. Like the proposed method, these works also do not require prior knowledge about the test takers with preknowledge or the leaked items. The main difference is that <ref type="bibr" target="#b73">Wang and Xu (2015)</ref> and <ref type="bibr" target="#b74">Wang et al. (2018)</ref> focus on identifying person-item pairs for which aberrant behaviours are involved, rather than directly classifying test takers and items. Therefore, they allow aberrance in any person-item combination, by introducing a person-and-item specific latent variable to indicate the status of each response. By having person-and-item specific latent variables, the models of <ref type="bibr" target="#b73">Wang and Xu (2015)</ref> and <ref type="bibr" target="#b74">Wang et al. (2018)</ref> tend to be more flexible than the proposed model, in the sense that these models allow data to deviate from the baseline model along more directions. Consequently, these models may be preferred when data involve multiple types of aberrant behaviours, such as rapid guessing and cheating. On the other hand, unlike the proposed method, the models of <ref type="bibr" target="#b73">Wang and Xu (2015)</ref> and <ref type="bibr" target="#b74">Wang et al. (2018)</ref> do not directly lead to classifications of the test takers and items, let alone quantifying the uncertainty of the classifications. To detect test takers with preknowledge and leaked items, follow-up analysis is needed based on the posterior distributions of the person-and-item specific latent variables. Therefore, these methods are not as straightforward as the proposed one, if the main goal is to perform the two-way detection of individuals with preknowledge and leaked items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Statistical Decision Theory</head><p>In what follows, we provide statistical decision theory for the detection of two-way outliers under the proposed model, assuming the model is correctly specified. We start with the classical Bayesian decision theory and then develop compound decision rules for the detection of outlying individuals and items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bayesian Decision Theory</head><p>As individuals and items are essentially mathematically exchangeable, we only discuss the Bayesian decision theory for the detection of outlying individuals. We denote D i as the decision on individual i, where D i = 1 means flagging the individual as an outlier and D i = 0 otherwise. A false positive error happens when D i = 1 and ξ i = 0 and a false negative error happens when D i = 0 and ξ i = 1. Decisions on the detection of outlying individuals involve a trade-off between these two types of errors, whose importance may be asymmetric. For example, in the application to the detection of item preknowledge, a false positive error corresponds to an innocent test taker being flagged as a cheater and a false negative error corresponds to a cheater not being flagged. These two types of errors have substantially different consequences <ref type="bibr" target="#b66">(Skorupski and Wainer, 2017)</ref>.</p><p>To apply Bayesian decision theory to this classification problem, we need to specify the relative cost of a false positive error, denoted by ζ ∈ (0, 1), which further implies that the relative cost of a false negative error is 1 -ζ. Then the Bayes risk is defined as</p><formula xml:id="formula_9">R(D i ) := ζP (D i = 1, ξ i = 0) + (1 -ζ)P (D i = 0, ξ i = 1). (<label>4</label></formula><formula xml:id="formula_10">)</formula><p>Following the classical Bayesian decision theory (see, e.g., Chapter 2, <ref type="bibr" target="#b62">Shao, 2003)</ref>, the optimal decision rule which minimises the Bayes risk is obtained by comparing the posterior probabilities with the relative cost ζ. That is, an individual is classified as an outlier if the posterior probability is larger than ζ.</p><p>This Bayesian decision rule depends on the relative cost ζ. However, this parameter may not be easy to specify in practice, as the relative importance of a false positive error is often hard to quantify. In what follows, we discuss how this parameter may be chosen adaptively based on a compound risk which is obtained by aggregating information from the entire set of individuals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Compound Decision for Detecting Outlying Individuals</head><p>We evaluate decision making at an aggregated level for all individuals. This involves solving N decision problems simultaneously and thus is called a compound decision problem <ref type="bibr" target="#b57">(Robbins, 1951;</ref><ref type="bibr" target="#b69">Sun and Cai, 2007;</ref><ref type="bibr" target="#b80">Zhang, 2003)</ref>. Given a decision rule, hypothetically, the results can be classified into four categories, as summarised in Suppose that the consequence of a false positive error is more severe than that of a false negative error, which may be the case for the detection of cheaters in educational testing.</p><p>Then a sensible decision criterion is to minimise the local FNR, while controlling the local FDR to be below a pre-specified threshold ρ. Given the practical meaning of local FDR, the threshold ρ should be much easier to specify than the relative cost in the Bayesian decision rule discussed previously. For instance, by setting ρ = 0.01, we approximately control the proportion of non-outliers to be below 1% among those who are detected as outliers.</p><p>Now consider a Bayesian decision rule with a relative cost ζ. We discuss how the optimal ζ is determined by the above decision criterion based on the local FDR and local FNR with a given threshold ρ. For ease of exposition, we use Z as a generic notation for the data, where Z = Y when only item responses are collected and Z = (Y, T) when both item responses and response times are available. Specifically, given relative cost ζ, the Bayesian decision for each test taker i can be written as</p><formula xml:id="formula_11">D i (ζ) = 1 {P (ξ i =1|Z)&gt;ζ} .<label>(5)</label></formula><p>Under our fully Bayesian setting and given threshold ζ, the local FDR becomes</p><formula xml:id="formula_12">fdr ζ (Z) = N i=1 D i (ζ)P (ξ i = 0|Z) max { N i=1 D i (ζ), 1} ,<label>(6)</label></formula><p>which only depends on the posterior probabilities P (ξ i = 1|Z), i = 1, ..., N . The local FNR can be obtained similarly as</p><formula xml:id="formula_13">fnr ζ (Z) = N i=1 (1 -D i (ζ))P (ξ i = 1|Z) max { N i=1 (1 -D i (ζ)), 1}</formula><p>.</p><p>As summarised in Proposition 1 below, the optimal relative cost is given by ζ * = inf{ζ : </p><formula xml:id="formula_14">fdr ζ (Z) ≤ ρ}. That is,</formula><p>The corresponding optimal decision rule is</p><formula xml:id="formula_16">D i (ζ * ) = 1 {P (ξ i =1|Z)&gt;ζ * } .</formula><p>Given posterior probabilities P (ξ i = 1|Z), the optimal decision is easy to obtain. The computation is described in Algorithm 1.</p><p>Algorithm 1 (Optimal compound decision). Let the posterior probabilities P (ξ i = 1|Z) and threshold ρ for local FDR be given. The optimal relative cost ζ * is given by the following steps.</p><p>1. Sort the posterior probabilities in an increasing order. Denote the sorted values as</p><formula xml:id="formula_17">p (1) ≤ p (2) ≤ • • • ≤ p (N ) . 2. Compute the cumulative means c (0) ≤ c (1) ≤ c (2) ≤ • • • ≤ c (N )</formula><p>, where</p><formula xml:id="formula_18">c (0) = 0, and c (i) = i j=1 p (j) i , i = 1, ..., N. 3. Let i * = max {i : c (i) ≤ ρ}.</formula><p>Then the optimal relative risk is given by</p><formula xml:id="formula_19">ζ * = p (i * ) , if i * &gt; 0, and ζ * = 0, if i * = 0.</formula><p>This local FDR control procedure can be viewed as the Bayesian version of the wellknown Benjamini-Hochberg (BH) procedure <ref type="bibr" target="#b6">(Benjamini and Hochberg, 1995)</ref> for multiple hypothesis testing. The BH procedure is designed to control the FDR, which is defined as the unconditional expectation of the FDP. Unlike the proposed procedure that is based on posterior probabilities, the BH procedure achieves the control of FDR using p-values from multiple testing. Under the proposed Bayesian framework, it seems more straightforward to control local FDR as in the proposed procedure. Also note that the FDR is automatically controlled by controlling local FDR, due to the relationship between conditional and unconditional expectations.</p><p>Another possible decision criterion is to control the posterior probability of making at least one false discovery, which corresponds to the Family-Wise Error Rate (FWER) under the frequentist setting. This FWER-type criterion exerts a more stringent control over false discovery than the proposed one by its definition. Therefore, the proposed procedure has greater power at the cost of increased rates of false positives. In this sense, the proposed local FDR control procedure is more suitable when having a large number of individuals and thus a large number of decisions need to be made simultaneously.</p><p>For certain applications, false negatives may have a more significant consequence than false positives. Then it may be more suitable to minimise the local FDR while controlling local FNR. As the definitions of local FDR and local FNR are mathematically symmetric, the above procedure can be easily adapted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Compound Decision for Detecting Outlying Items</head><p>The compound decision theory developed above can be adapted to the detection of outlying items, based on the posterior probabilities for the item-specific binary indicators η j . In the application to the detection of item preknowledge, when there is sufficient evidence suggesting that an item is compromised, it should be removed to maintain the quality of the item pool. This decision problem faces a trade-off between the financial cost for item pool replenishment and the need of maintaining the quality of the item pool. For high-stake tests, test fairness is usually the first priority and thus false negatives may have a more significant consequence than false positives. In that case, it becomes more sensible to minimise the local FDR, under the constraint that the local FNR is below a suitable threshold (e.g., 1%).</p><p>4 Bayesian Inference 4.1 Prior and Hyperprior Specification</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Prior and hyperprior specification</head><p>We showcase the specification of prior and hyperprior distributions under the specific model with item-response submodel (1) and response-time submodel (3). We start with the specification of g 1 , the joint distribution of Θ i = (θ i , ξ i , τ i ). It is assumed that (θ i , τ i ) follows a bivariate normal distribution N (0, Σ), where Σ = (σ ij ) 2×2 . Note that a person's ability and speed are typically correlated, which is why we assume a bivariate normal distribution for (θ i , τ i ). Similar settings are adopted in existing models for item responses and response times; see e.g., <ref type="bibr" target="#b70">van der Linden (2007)</ref>. We further assume that the latent indicator ξ i is independent of (θ i , τ i ), following a Bernoulli distribution Bern(π 1 ). This independence as-sumption can be relaxed by modelling the conditional distribution of ξ i given (θ i , τ i ), for example, by a logistic regression model. This relaxation is left for future investigation.</p><p>We now specify g 2 , the joint distribution of ∆ j = (β j , η j , α j ). Similar to that of g 1 , we first let (β j , α j ) follow a bivariate normal distribution N (µ, Ω), where µ = (µ 1 , µ 2 ) and Ω = (ω ij ) 2×2 . It is further assumed that η j is an independent Bernoulli random variable, Bern(π 2 ).</p><p>It remains to specify the prior for positive parameters δ, γ, κ, as well as the priors for hyperparameters π 1 , π 2 , µ 1 , µ 2 , Ω, and Σ.</p><p>1. As δ is positive, we assume a half-Cauchy prior distribution with scale 2.5. This is regarded a weakly informative prior, following the suggestions given in Gelman ( <ref type="formula">2006</ref>), <ref type="bibr" target="#b27">Gelman et al. (2008)</ref> and <ref type="bibr" target="#b48">Polson and Scott (2012)</ref>.</p><p>2. γ is assumed to follow the same half-Cauchy prior distribution as δ .</p><p>3. κ is assumed to follow an inverse Gamma distribution, IG(0.001, 0.001), where the shape and scale parameters are both set to 0.001. This choice follows the suggestion in Chapter 5, <ref type="bibr" target="#b39">Lunn et al. (2012)</ref>.</p><p>4. π 1 and π 2 are assumed to be i.i.d., following a beta distribution Beta(2, 2). This prior distribution can be regard as a weakly informative prior given the sample and item sizes in our application. It is suggested in <ref type="bibr" target="#b0">Agresti and Coull (1998)</ref> and <ref type="bibr" target="#b11">Carlin and Louis (2000)</ref>, Chapter 2, as the prior for a proportion parameter. We choose this distribution rather than a uniform distribution, because π 1 and π 2 are believed to not locate on the boundaries of the interval [0, 1].</p><p>5. µ 1 and µ 2 are assumed to be i.i.d., following a normal distribution N (0, 5 2 ). The standard deviation 5 is chosen based on the scales of µ 1 and µ 2 in the current application, under which this prior may be regarded as weakly informative.</p><p>6. Σ and Ω are assumed to be i.i.d., following an inverse Wishart distribution where the scale matrix, IW(Ψ, ν), Ψ = ((2, 0) , (0, 2) ), and the degree of freedom ν = 2.</p><p>This choice follows the suggestion in Chapter 6, <ref type="bibr" target="#b39">Lunn et al. (2012)</ref>. Under this prior distribution, σ 11 , σ 22 , ω 11 , and ω 22 marginally follow an inverse Gamma distribution IG(1/2, 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Induced priors and hyper-priors for reduced model</head><p>For the reduced model of item response data, the priors and hyperpriors are induced by those for the full model. For completeness, we list the induced priors and hyperpriors below.</p><p>1. For Θ i = (θ i , ξ i ), θ i and ξ i are independent, following normal distribution N (0, σ 11 )</p><p>and Bernoulli distribution Bern(π 1 ), respectively.</p><p>2. Similarly, for ∆ j = (β j , η j ), β j and η j are independent, following normal distribution N (µ 1 , ω 11 ) and Bernoulli distribution Bern(π 2 ), respectively.</p><p>3. δ follows a half-Cauchy prior distribution with scale 2.5.</p><p>4. π 1 and π 2 are i.i.d., following a beta distribution Beta(2, 2).</p><p>5. µ 1 follows a normal distribution N (0, 5 2 ).</p><p>6. σ 11 and ω 11 are i.i.d. IG(1/2, 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bayesian Inference</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Computation</head><p>Statistical inference is carried out under a full Bayesian setting. An MCMC algorithm is developed for the computation 1 . This computation is non-trivial, due to the presence of many discrete variables and the interactions between them. More specifically, the model involves person-and item-specific binary latent variables ξ i and η j . The complexity of simulating these variables by MCMC is similar to the simulation of discrete systems like mixture models and Ising-type models. Such systems typically involve many well-separated local modes and thus suffer from the issue of slow mixing (e.g., <ref type="bibr" target="#b13">Celeux et al., 2000;</ref><ref type="bibr" target="#b35">Katzgraber et al., 2006;</ref><ref type="bibr" target="#b56">Richardson and Green, 1997)</ref>. Tempering methods <ref type="bibr" target="#b29">(Geyer, 2011)</ref>  (c) the temperature values. For (a), we follow the suggestion given by <ref type="bibr" target="#b59">Roberts and Rosenthal (2001)</ref>; that is, we tune the step sizes to achieve an acceptance rate around 2.3. For (b) and</p><p>(c), it is suggested to follow the theoretical guidance given in <ref type="bibr" target="#b2">Atchadé et al. (2011)</ref>. Further details of this algorithm are given in Appendix B. For the implementation of the decision procedures in Section 3, the posterior distributions of ξ i and η j are approximated by the posterior samples from this MCMC algorithm.</p><p>Instead of taking a fully Bayesian setting, it is also possible to adopt an empirical Bayes framework <ref type="bibr" target="#b12">(Casella, 1985;</ref><ref type="bibr" target="#b23">Efron, 2014;</ref><ref type="bibr" target="#b58">Robbins, 1956)</ref>, under which ν 1 , ν 2 , δ, γ, and κ are treated as fixed parameters and estimated by maximum likelihood estimation, while the person-and item-specific parameters Θ i and ∆ j are treated as random variables. However, due to the complex structure of the current model, the expectation-maximisation algorithm, which is the standard tool for empirical Bayes inference, is computationally infeasible. A tailored stochastic optimisation algorithm needs to be developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Model comparison</head><p>We use model comparison methods to answer the following questions that may be of substantive interest in specific applications. That is, does our item response data show evidence of the existence of outlying individuals and items? If so, does item response time information help detect these outliers? These questions may be answered by Bayesian model comparison.</p><p>To answer the first question, we compare the proposed model for item responses with the baseline item-response model which does not contain outliers. These two models are the same, including the specification of the priors and hyperpriors, except that the hyperparameters π 1 and π 2 are set to be 0 and thus ξ i η j δ = 0 for all i and j in the baseline model. The preference of the proposed model against the baseline model suggests the existence of the outliers.</p><p>To answer the second question, we compare the proposed model for item responses and response times with a null model for the same data. This null model is the same as the proposed model, except that the drift parameter γ in the response-time submodel is set to be zero. When γ = 0, it means that there is no difference between the outlying and nonoutlying individuals in their response-time distributions. If the proposed model is preferred to the null model, it suggests that response times contain information about the outliers thus incorporating response time information may improve the detection of outliers.</p><p>These models are compared by the deviance information criterion (DIC; <ref type="bibr" target="#b67">Spiegelhalter et al., 2002)</ref>, more specifically, a marginalised DIC in which the person-and item-specific parameters are treated as latent variables and integrated out. In comparing two models, the one with a smaller DIC value is preferred. We choose the marginalised DIC, instead of the conditional DIC that incorporates the person-and item-specific variables in the focus of the analysis, because the marginalised DIC often performs better in comparing hierarchical models (e.g., <ref type="bibr" target="#b51">Quintero and Lesaffre, 2018)</ref>. The marginalised DIC is computed by MCMC sampling.</p><p>While computationally convenient, the DIC suffers from several caveats, including the lack of model selection consistency and the possibility of selecting overfitted models (see <ref type="bibr">Spiegelhalter et al., 2014, and references therein)</ref>. Therefore, we note that the results based on the DIC need to be interpreted with caution. In future research, other model comparison criteria will be investigated and compared with the DIC, including the Bayes factor <ref type="bibr" target="#b34">(Kass and Raftery, 1995)</ref> and the Bayesian information criterion (BIC; <ref type="bibr" target="#b60">Schwarz, 1978)</ref> that approximates the logarithm of the Bayes factor. The Bayes factor and BIC may be theoretically more attractive because they yield consistent model selection under suitable regularity conditions. However, their computation tends to be less straightforward than the DIC. Algorithms remain to be developed for computing them under the current modelling framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">An Application to Licensure Test</head><p>We apply the proposed method to a dataset from a computer-based non-adaptive licensure test. The test is designed and operated under the Rasch model, which is consistent with the proposed baseline item-response submodel. This dataset has also been analysed for the detection of cheating in several chapters of <ref type="bibr" target="#b17">Cizek and Wollack (2017)</ref> and journal articles including <ref type="bibr">Sinharay (2017a)</ref> and <ref type="bibr">Sinharay (2017b)</ref>. We point out that the methods in these analyses require prior information about the items' statuses. For example, <ref type="bibr">Sinharay (2017a)</ref> and <ref type="bibr">Sinharay (2017b)</ref> require to know the compromised items a priori and focus on the detection of cheaters. Unlike these existing analyses, we focus on the simultaneous detection of cheaters and compromised items, without requiring such prior knowledge.</p><p>The test contains 170 binary-scored items (J = 170), for which test takers' item responses and response times are available. The dataset is preprocessed by removing 12 test takers with zero response time in one or multiple items, which is believed to be data recording error.</p><p>This leads to a final dataset containing 1,624 test takers (N = 1, 624). The testing program flagged 41 among these 1,624 test takers as likely cheaters, through a combination of data analysis and a careful investigative process which brought in other pieces of information.</p><p>By a similar investigation process, the testing program also believed that 64 among the 170 items were compromised. These labels will be used as partial truth for validating our data analysis results, but they are not used in our model. It is worth noting that these labels are not the ground truth and it is possible that there were test takers and items which ought to have been flagged but were not (Chapter 1, <ref type="bibr" target="#b17">Cizek and Wollack, 2017)</ref>. It is believed that the given labels are of good quality, so that they can be used for the evaluation of detection methods. On the other hand, evaluation criteria based on these labels are not perfect, due to possible labelling errors.</p><p>The purpose of this analysis is twofold. First, it is used to show the effectiveness of the proposed method, through a comparison between our results and the partial truth given by the testing program. Second, it is used to demonstrate the use of the proposed method in real tests, which may be of interest to practitioners.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Descriptive Analysis</head><p>We start with descriptive analysis to give an overview of the dataset. Panel (a) of Figure <ref type="figure" target="#fig_5">4</ref> shows the histogram of test takers' total scores by the testing program's cheating labels.</p><p>Similarly, Panel (b) of Figure <ref type="figure" target="#fig_5">4</ref> gives the histogram of items' correct rates by the testing program's compromisation labels. Similarly, the two panels of Figure <ref type="figure" target="#fig_6">5</ref> show the histograms of the mean response time in logarithm scale for test takers and items, respectively.</p><p>From these plots, it is not difficult to see that the corresponding summary statistics do not have much information about the labels on the test takers and items. In fact, the area under the curves (AUC) of the corresponding receiver operating characteristic (ROC) curves are 55.2% and 71.7% for the classification of the cheating labels based on total score and mean log-time, respectively. Similarly, the corresponding AUCs for the classification of items are 52.4% and 60.6%, respectively. As we will see in the sequel, the proposed method substantially improves upon these benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Detection based on Item Responses</head><p>We start with analysing item responses using the reduced model (i.e. only analyse item responses and not time responses). Using the algorithm given in Appendix B, three MCMC chains were run with random starting points. Their convergence was assessed by trace plots and the Gelman and Rubin (GR) diagnostic statistic <ref type="bibr" target="#b28">(Gelman and Rubin, 1992)</ref>. The Gelman-Rubin R statistics applied to the parameters which are not person-or item-specific (see Table <ref type="table">3</ref> for the list of these parameters) are below 1.20, suggesting that the chains converged to their equilibrium distributions after 10,000 iterations.</p><p>Inference is drawn based on 24,000 posterior samples from the three converged chains, where each contributes 8,000 samples. We first compare the fitted model with its null version using the DIC measure described in Section 4.2, to answer the question "does our item response data show evidence of cheating?". Recall that π 1 = π 2 = 0 in the null model, meaning that there are no cheaters or compromised items. The DIC value for the null model is also based on 24,000 posterior samples from an MCMC algorithm. The DIC values for the proposed and the null models are <ref type="bibr">138,282.6 and 218,308.4</ref>, respectively. The smaller DIC for the proposed model suggests that item preknowledge is likely to exist among the test takers.</p><p>We then examine the classification results. Panel (a) of Figure <ref type="figure" target="#fig_7">6</ref> gives the box plots of the posterior means of ξ i for the cheating and non-cheating groups (defined by the testing program), respectively. As we can see, the posterior means of ξ i for the cheating group tend to be close to 1 and those for the non-cheating group tend to be close to 0, with some exceptions. Panel (b) of Figure <ref type="figure" target="#fig_7">6</ref> gives box plots of the posterior means of η j for the compromised and non-compromised items (defined by the testing program), respectively. Similarly, the posterior means of η j for the compromised items tend to be close to 1 and those for the non-compromised items tend to be close to 0. The corresponding ROC curves for the classification of the cheating and compromisation labels are presented in Figure <ref type="figure" target="#fig_8">7</ref>.</p><p>The AUCs for these two ROC curves are 0.868 and 0.836, respectively. They are substantially larger than the ones given by the summary statistics discussed in Section 5.1. We remark that these results on the detection accuracy should be interpreted with caution, due to possible labelling errors.</p><p>Moreover, Panel (a) of Figure <ref type="figure" target="#fig_9">8</ref>   <ref type="table">3</ref>, where the global parameters refer to the parameters that are not personspecific or item-specific. In particular, the posterior mean of the proportion of cheaters is 2.8%, with 95% credible interval (2.0%, 3.6%). This estimate is close to the proportion of 2.5% calculated based on the cheating labels from the testing program. The posterior mean of the proportion of compromised items is 40.1%, with 95% credible interval (38.7%, 43.3%). 1% 5% 10% Test takers 25 46 61 Items 100 91 71</p><p>Table <ref type="table">2</ref>: Applying the reduced model for item responses. The first row shows the numbers of detections for test takers, when controlling the corresponding local FDR at 1%, 5%, and 10% levels, respectively. The second row shows the numbers of detections for items, when controlling the corresponding local FNR at 1%, 5%, and 10% levels, respectively.  Table <ref type="table">3</ref>: Applying the reduced model for item responses. The row labelled "EAP" shows the posterior means of the global parameters, where EAP represents the Expected A Posteriori, and the row labelled "95% CI" provides the corresponding 95% credible intervals.</p><p>This estimate is close to, but slightly higher than, the proportion of 37.6% given by the testing program. It may be the case that the testing program missed several compromised items during its labelling process. Furthermore, the posterior mean of δ is 0.895. That is, the odds ratio of correctly answering a compromised item is about exp(0.895) = 2.447 when comparing a cheater and a non-cheater with the same ability level. Again, we point out that these interpretations depend on the extent to which our model holds and thus should be taken with caution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Detection based on Item Responses and Response Times</head><p>We continue the modelling process by incorporating information from response times. The full model is applied to the dataset consisting of both item responses and response times.</p><p>Three MCMC chains were used to fit the model. According to the GR statistics applied to the global parameters, the chains converged to their equilibrium distributions after 18,000 1% 5% 10% Test takers 26 47 65 Items 101 89 74</p><p>Table <ref type="table">4</ref>: Applying the full model for item responses and response times. The first row shows the numbers of detections for test takers, when controlling the corresponding local FDR at 1%, 5%, and 10% levels, respectively. The second row shows the numbers of detections for items, when controlling the corresponding local FNR at 1%, 5%, and 10% levels, respectively.</p><p>iterations.</p><p>Similar as above, inference is drawn based on 24,000 posterior samples from the three chains after convergence. We compare this model with its null version by DIC, to answer the question "does item response time information help detect cheating?" Recall that these two models are the same, except that the response-time drift parameter γ = 0 in the null The classification results are similar to those based only on item responses, and thus some plots shown above are omitted here. In particular, the ROC curves based on the posterior means of ξ i and η j have AUCs of 0.892 and 0.867, respectively, where these AUC values are slightly higher than those from the reduced model. In addition, the numbers of detections for test takers and items are shown in Table <ref type="table">4</ref>, where we still control local FDR for test takers and control local FNR for items. Comparing the results in Tables <ref type="table">2</ref> and<ref type="table">4</ref>, generally more detections tend to be made under the full model. This is likely due to the fact that the posterior distributions tend to be more concentrated under the full model as it utilises more information.</p><p>Posterior means and 95% credible intervals for the global parameters are given in Table <ref type="table">5</ref>.</p><p>Comparing Tables <ref type="table">3</ref> and<ref type="table">5</ref>, we find that the estimates of the common parameters shared by the two models are close to each other. In particular, the 95% credit intervals overlap for each parameter. In addition, based on the posterior mean of Σ, the correlation between Table <ref type="table">5</ref>: Applying the full model for item responses and response times. The row labelled "EAP" shows the posterior means of the global parameters and the row labelled "95% CI" provides the corresponding 95% credible intervals.</p><p>the ability and speed factors is as high as 0.410. This result indicates that test takers with higher ability tend to answer the items faster. Such a high correlation between the two factors is not uncommon for high-stake tests. For example, Wang et al. ( <ref type="formula">2013</ref>) report a similar level of correlation between the ability and speed factors in a high-stake computerised adaptive test, under a similar Bayesian hierarchical model but without a cheating component.</p><p>The estimated correlation between the two item-specific parameters is 0.237. This positive correlation suggests that solving more difficult items tends to take more time, which is consistent with our intuition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Simulation Study</head><p>We now present two simulation studies for evaluating the finite-sample performance of the proposed method. The first study focuses on settings where our model is correctly specified, and the second study investigates the sensitivity of the proposed method under various forms of model misspecification.</p><p>6.1 Study I</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Settings</head><p>We consider simulation settings that mimic real educational tests. Specifically, we consider two settings for the sample size N and item size J, (1) N = 2, 000, J = 200, and (2) N = 4, 000, J = 400. This leads to two different settings, where the detection is expected to be more accurate under the second setting given its larger sample and item sizes. In what follows, these two settings are referred to as S1 and S2, respectively.</p><p>For each setting, we generate 50 independent datasets under the full model, with the global parameters fixed across the datasets. The proportion parameters π 1 and π 2 are set to 10% and 40%, respectively, the drift parameters δ and γ are both set to be 1.2, and the rest of the global parameters are set to be the same as the posterior means in Table <ref type="table">5</ref> from the real data analysis above. For each dataset, we apply both the reduced model for item responses and the full model for item responses and response times. An additional simulation study is presented in the appendix that shares a similar setting with the current study, except that the item size J is set to mimic educational tests with a smaller number of items. More specifically, this additional study considers two settings for N and J: (1) N = 2, 000, J = 50, and (2) N = 4, 000, J = 100, and the rest of the settings remain the same. Similar results are observed in this additional study as those below from Study I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Results</head><p>The analysis is conducted using our parallel tempering MCMC algorithm. For each dataset, we run 10,000 iterations, with the first 3,000 iterations as the burn-in. The results are based on the posterior samples from the last 7,000 iterations.</p><p>We first examine the classification results. For each model and each simulated dataset, we classify the test takers based on the posterior means of ξ i and evaluate the classification based on the AUC value of the corresponding ROC curve. A larger AUC value implies higher For each model, each setting, and each local FDR target (1%/5%/10%), we show the 25%, 50%, and 75% quantiles of the FDPs of the corresponding classifications from 50 independent datasets. classification accuracy. Similarly, the classification of the items is based on the posterior means of η j and the accuracy is measured by the corresponding AUC value. These results are shown in Table <ref type="table" target="#tab_3">6</ref>. It can be observed that the classification is slightly more accurate under setting S2, due to the increased sample and item sizes. Moreover, the AUC values given by the full model tend to be slightly larger than those from the reduced model, thanks to the additional information from response times.</p><p>We further evaluate the proposed compound decision rules. For each dataset, we control local FDR and local FNR at levels 1%, 5%, and 10% for test takers and items, respectively.</p><p>We evaluate each decision rule by examining the resulting FDP and FNP; see Section 3.2 for the definitions of FDP and FNP. The results are given in Tables <ref type="table" target="#tab_4">7</ref> and<ref type="table" target="#tab_5">8</ref> for the classifications of test takers and items, respectively. According to these tables, the FDP is well-controlled for test takers and so is the FNP for items.</p><p>Finally, we show the results on the estimation of the global parameters, as these param-  eters have substantive interpretations in cheating detection. Specifically, we focus on the posterior mean estimator, for which bias and variance are estimated based on the results from 50 independent replications. These results are presented in Table <ref type="table" target="#tab_6">9</ref>. The bias, in general, tends to be close to zero for all the global parameters from both models and both settings. In addition, the estimation tends to be more accurate under setting S2, due to the increased sample and item sizes.</p><p>assumed</p><formula xml:id="formula_20">P (Y ij = 1|Θ i , ∆ j , α j , δ) = exp(α j (θ i -β j ) + ξ i η j δ) 1 + exp(α j (θ i -β j ) + ξ i η j δ) ,</formula><p>where α j is known as the discrimination parameter. Note that the proposed model can be viewed as a special case where α j = 1 for all j. In the misspecified model, we generate the discrimination parameters α j from a uniform distribution U [1, 1.5].</p><p>In the proposed model, θ i and ξ i are assumed to be independent, meaning that whether a test taker cheats or not is independent of his/her ability. This assumption may not hold and it is likely that these two variables are negatively associated, i.e., test takers with lower ability are more likely to cheat in a test. To mimic this situation, we generate (θ i , ξ i ) jointly from a Gaussian copula. That is, we first generate (θ i , ξ * i ) from a bi-variate normal distribution, with mean vector (-0.867, 0) and covariance matrix ((0.289, -0.134) , (-0.134, 1) ). Under this bivariate normal distribution, the correlation between θ i and ξ * i is -0.25. We then let ξ i = 1 {ξ * i ≥z 0.9 } , which is obtained by truncating ξ * i at z 0.9 , the 90% quantile of the standard normal distribution, so that P (ξ i = 1) = 0.1. Under this Gaussian copula model, the marginal distributions of θ i and ξ i remain the same as those in Study I, while a negative association is introduced between the two variables.</p><p>For model parsimony, it is also assumed in the proposed model that the drift parameter δ is common across all the test takers and items. This assumption may not hold in practice.</p><p>Therefore, in this misspecified model, instead of using a constant drift, we assume the drift parameter to be both item-and person-specific. That is, we assume</p><formula xml:id="formula_21">P (Y ij = 1|Θ i , ∆ j , δ ij ) = exp(θ i -β j + ξ i η j δ ij ) 1 + exp(θ i -β j + ξ i η j δ ij )</formula><p>,</p><p>where the drift parameters δ ij are generated i.i.d. from a uniform distribution U [1, 1.5]. Table <ref type="table" target="#tab_0">11</ref>: Study II: Overall classification performance based on the posterior means of ξ i and η j . For each model, each setting, and each target (test taker/item), we show the 25%, 50%, and 75% quantiles of the AUCs of the corresponding ROC curves from 50 independent datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Results</head><p>We evaluate the proposed method under the six settings above. Similar to Study I, we evaluate the overall classification performance by AUC and the performance of the compound decision rules by the corresponding FDP and FNP. The results are given in Tables <ref type="table" target="#tab_10">11 through   13</ref>. Specifically, the AUC values in Table <ref type="table" target="#tab_0">11</ref> are comparable to those from the correctly specified model in Table <ref type="table" target="#tab_3">6</ref>, though the AUCs from settings S3, S4, S6, and S7 are slightly smaller. As further shown in Tables <ref type="table" target="#tab_9">12</ref> and<ref type="table" target="#tab_10">13</ref>, the compound decision rules tend to control the corresponding FDP and FNP under the targeted levels, expect when the target level is 1%. That is, when controlling the local FDR and local FNR to be below 1% for test takers and items, respectively, the resulting FDP and FNP tend to exceed the targeted level under all six settings. This is likely due to the fact that the posterior probabilities cannot be accurately obtained when they are close to 0 or 1, under model misspecification.</p><p>Overall, the proposed method is reasonably robust against several forms of model specification, though the performance may be slightly affected. However, under potential model misspecification, the method should be used with caution if we aim to control local FDR or local FNR to be below a very small threshold (e.g., 1%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Concluding Remarks</head><p>In this paper, we propose a Bayesian hierarchical model for the detection of latent dif-   The proposed model is largely motivated by, and applied to, the detection of test takers who benefit from item preknowledge and compromised items in educational tests. The proposed method requires little prior knowledge either the test takers with item preknowledge or the compromised items, and thus is directly applicable to operational tests as a monitoring tool or more generally about outlying cases and items in other applications.</p><p>The proposed method is successfully applied to data from a licensure test which is known to suffer from item preknowledge. In this study, two models are applied, including the reduced model for item responses and the full model for item responses and response times.</p><p>Both models accurately detect the potential cheaters and compromised items identified by the testing program, suggesting their usefulness in practice. In addition, the full model performs slightly better than the reduced one, suggesting that response-time information may help detect cheating. However, it should be noted that the labels provided by the testing program in this example are not the ground truth and thus the accuracy measures may be compromised. The validity of the proposed method remains to be checked through applications to other educational tests. We note that a simple model, such as the one applied in the case study, may be more preferable for the detection of cheating in educational tests, even though more general models are available as discussed in Section 2. This is because the numbers of test takers with preknowledge and compromised items are usually small in an educational test, which makes the effective sample sizes small for estimating parameters related to the outlier classes. In that case, a more complex model may lead to a high variance in the estimation, which further yields inaccurate classifications.</p><p>Limitations of the proposed method have been discussed in Section 2.1.4. as well as its robustness against model misspecification in Section 6.2. Another limitation is that it only models a specific type of cheating, i.e., preknowledge due to item leakage. It does not handle other types of cheating behaviours, such as copying others' answers, electronic transmission of data, hiring stand-ins, and bribing test administrators to correct one's answers. To investigate different types of cheating behaviours, different sources of information are needed and suitable statistical methods remain to be developed. For example, to detect copying behaviour, a statistical model is needed to characterise the similarity between the item responses from two test takers, possibly taking into account their response process information (e.g., response time), seat locations in a test centre, etc. We leave these problems for future investigation.</p><p>Missing data are widely encountered in educational tests that may be informative for the detection of cheating, though not observed in our real data example. For an educational test with cheating test takers, the missingness of a response likely depends on whether the test taker is cheating and whether the item is compromised. If many missing responses are observed, then the current framework should be extended by modelling the probabilities of responding. This problem is left for future development, for which ideas may be borrowed from latent variable models for non-ignorable missingness (e.g., <ref type="bibr" target="#b37">Kuha et al., 2018;</ref><ref type="bibr" target="#b46">O'Muircheartaigh and Moustaki, 1999)</ref>.</p><p>Besides the applications to cheating detection in educational tests, future research will be conducted to investigate the computation, model evaluation and comparison in other areas of application, such as voting behaviours and psychological measurement. Specifically, MCMC algorithms for the inference of the proposed model will be further explored. Although our parallel tempering algorithm works well for the current analysis, its performance will be evaluated under more settings, especially large-scale settings (larger numbers of individuals and items). In addition, other tempering methods, such as simulated tempering, can be explored. Moreover, goodness-of-fit issues and model selection will be further studied. In particular, the use of Bayes factors and BIC for comparing the proposed model with several relevant models will be investigated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B A Parallel Tempering Algorithm</head><p>As mentioned in Section 4.2, the standard MCMC algorithms, such as the Metropolis-Hastings algorithm, suffer from slow-mixing for our problem, due to the presence of many discrete variables and the interactions between these discrete variables in the current problem.</p><p>Let Ξ be a generic notation for the parameters and hyperparameters to be sampled. Note that Ξ = {θ i , ξ i , β j , η j , ν 1 , ν 2 , δ : i = 1, ..., N, j = 1, ..., J} for the reduced model, and Ξ = {θ i , ξ i , τ i , β j , η j , α j , ν 1 , ν 2 , δ, γ, κ : i = 1, ..., N, j = 1, ..., J} for the full model, respectively. Recall that Z is used as the generic notation for data, where Z = Y and (Y, T) for the reduced model and the full model, respectively. We use f (Ξ|Z) as a generic notation for the posterior distribution of interest. The goal is to sample Ξ from the target posterior distribution f (Ξ|Z).</p><p>The algorithm involves sampling K MCMC chains with tempered target distributions.</p><p>More specifically, let 0 &lt; ψ 1 &lt; ψ 2 &lt; . . . &lt; ψ K = 1 be a pre-specified sequence of temperature levels. Then the kth chain has a target distribution f k (Ξ|Z) ∝ (f (Ξ|Z)) (1/ψ k ) , where ∝ means that the two sides differ by a normalising constant which does not depend on Ξ. The target distribution of the Kth chain is our target posterior distribution. Let t be the current iteration number and Ξ k,t be the current samples from the kth chain. The parallel tempering algorithm performs the following steps in the t + 1th iteration.</p><p>1. For each of the chains, sample Ξ k,t+1 given Ξ k,t using a Metropolis-Hastings within Gibbs sampler, which will be further discussed below.</p><p>2. Randomly sample a pair of adjacent chains, k and k +1, and use a Metropolis-Hastings update to decide whether to swap the statuses of Ξ k,t+1 and Ξ k+1,t+1 . That is, a Bernoulli random variable with success probability min 1,</p><formula xml:id="formula_22">f k (Ξ k+1,t+1 |Z)f k+1 (Ξ k,t+1 |Z) f k (Ξ k,t+1 |Z)f k+1 (Ξ k+1,t+1 |Z)</formula><p>is generated to decide whether to swap or not. If the Bernoulli random variable takes value 1, then we swap the statuses of Ξ k,t+1 and Ξ k+1,t+1 and otherwise, we reject the swap and keep their statuses unchanged.</p><p>For simplicity, the MCMC sampling within each chain is conducted by using a Metropolis-Hastings within Gibbs sampler. That is, Ξ is split into multiple blocks. Each block is sampled given all the others, using a random-walk Metropolis-Hastings sampler, for which the step size is tuned following <ref type="bibr" target="#b59">Roberts and Rosenthal (2001)</ref> that is based on the Metropolis-Hastings acceptance rate. For the reduced model, Ξ is split into 10 blocks, including (1) θ i , i = 1, ..., N ,</p><p>(2) ξ i , i = 1, ..., N , (3) β j , j = 1, ..., J, (4) η j , j = 1, ..., J, (5) δ, (6) π 1 , (7) σ 11 , (8) π 2 , (9) µ 1 , and (10) ω 11 . For the full model, Ξ is split into 14 blocks, including (1) θ i , i = 1, ..., N , (2) τ i , i = 1, ..., N , (3) ξ i , i = 1, ..., N , (4) β j , j = 1, ..., J, (5) α j , j = 1, ..., J, (6) η j , j = 1, ..., J, (7) δ, (8) γ, (9) κ, (10) π 1 , (11) Σ, (12) π 2 , (13) µ, and ( <ref type="formula">14</ref>) Ω.</p><p>The specification of the number and levels of the temperatures also needs some tuning.</p><p>A fine-tuned system tends to have faster mixing. We suggest choosing the number and levels of the temperatures by following the theoretical guidance given in <ref type="bibr" target="#b2">Atchadé et al. (2011)</ref> that is based on the Metropolis-Hastings acceptance rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C An Additional Simulation Study</head><p>We provide an additional simulation study under settings similar to Study I in Section 6, but with smaller values of J to mimic educational tests with relatively smaller item sizes. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of the two-way outlier structure in the proposed model.</figDesc><graphic coords="7,181.44,72.00,249.12,215.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Graphical representation of the proposed model for the joint distribution of item responses and response times. The boxes are plates representing replicates. The two outer plates represent individuals and items, respectively, and the inner plates present item response and response time, respectively.</figDesc><graphic coords="11,169.38,72.00,273.24,221.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Graphical representation of the reduced model when all the response times are missing completely at random. The boxes are plates representing replicates. The two outer plates represent individuals and items, respectively, and the inner plate presents an item response.</figDesc><graphic coords="12,196.20,72.00,219.60,187.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>the decision rule given by D i (ζ * ), i = 1, ..., N , minimises the local FNR under the constraint that the local FDR is below ρ. The proof of Proposition 1 is given in Appendix A. Proposition 1. Given data Z = Y or (Y, T), the local FDR fdr ζ (Z) as a function of ζ is non-increasing and left-continuous, and the local FNR fnr ζ (Z) is non-decreasing in ζ. Thus, ζ * = inf{ζ : fdr ζ (Z) ≤ ρ} (7) solves the optimisation min ζ fnr ζ (Z), s.t. fdr ζ (Z) ≤ ρ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>provide a powerful tool for exploring distributions with many local modes. Specifically, parallel tempering, which is also known as the Metropolis-coupled Markov chain Monte Carlo, is chosen for the computation of the proposed model. More precisely, parallel tempering simulates multiple MCMC chains simultaneously. A Metropolis-Hastings sampler is used for the MCMC sampling within each chain. The target distributions of these chains are obtained by tempering the original posterior density, i.e., raising the original posterior density to different powersT -1 ∈ [0, 1],where T is known as the 'temperature'. The original posterior density is included by setting T = 1. A chain corresponding to a higher temperature tends to have a flatter target distribution, for which the MCMC sampler is less likely to be trapped at local modes and thus has fast mixing. In contrast, when the temperature is low, the MCMC chain is more likely to be trapped and thus suffers from slow mixing. Parallel tempering improves the mixing of the low-tempered MCMC chains, by exchanging information between chains with adjacent temperatures. That is, at each iteration, a pair of chains with adjacent temperatures is randomly chosen and a Metropolis-Hastings update is used to decide whether to swap their parameter states.The use of the algorithm requires some tuning, including (a) the step sizes of random-walk Metropolis-Hastings updates within each chain, (b) the number of temperature levels, and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Descriptive analysis. Panel (a): Histogram of test takers' total scores by the testing program's cheating labels. Panel (b): Histogram of items' correct rates by the testing program's compromisation labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Descriptive analysis. Panel (a): Histogram of test takers' mean log-time by the testing program's cheating labels. Panel (b): Histogram of items' mean log-time by the testing program's compromisation labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Applying the reduced model for item responses. Panel (a): Box plots of the posterior means of ξ i for the cheating and non-cheating groups (defined by the testing program). Panel (b): Box plots of the posterior means of η j for the compromised and non-compromised items (defined by the testing program).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Applying the reduced model for item responses. Panel (a): ROC curve for the classification of cheaters (labelled by the testing program) by the posterior means of ξ i . Panel (b): ROC curve for the classification of compromised items (labelled by the testing program) by the posterior means of η j . The x-and y-axes of an ROC curve give the true positive rate (TPR) and false positive rate (FPR) for classification, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Applying the reduced model for item responses: The local FDR (represented by black solid curves) and the local FNR (represented by blue dashed curves) as functions of the number of detections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>model. The DIC values for the proposed full model and its null version are 176,935.2 and 214,201.3, respectively. The smaller DIC value for the proposed full model suggests that response times contain substantial information about the cheating indicators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>fdr ζ (Y) ≤ ρ. Then by the non-decreasing property of fnr ζ (Y), fnr ζ (Y) ≥ fnr ζ * (Y;ρ) (Y). Therefore, ζ * (Y; ρ) solves the optimisation problem (8).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Table1, where N 00 , N 01 , N 10 , and N 11 denote the numbers of true negative, false positive, false negative, and true positive, respectively. The quality of decisions can be quantified by two quantities. One is the False Discovery Proportion (FDP) N 01 / max {N •1 , 1}, which is the proportion of non-outliers among the detections. In the application to cheating detection, this gives the proportion of innocent test takers among those who are flagged as cheaters. The denominator is cho-A summary of the outcome of detecting outlying individuals. Note that this table is hypothetical, as in real applications, outliers and non-outliers are directly observable.among the non-detections. It is worth noting that, however, the FDP and FNP cannot be directly used because the outliers are not directly observable. As an alternative, we use the posterior means of the FDP and FNP, which are known as the local FDR and local FNR,</figDesc><table><row><cell></cell><cell cols="3">Not flagged as outlier Flagged as outlier Total</cell></row><row><cell>Non-outlier</cell><cell>N 00</cell><cell>N 01</cell><cell>N 0•</cell></row><row><cell>Outlier</cell><cell>N 10</cell><cell>N 11</cell><cell>N 1•</cell></row><row><cell>Total</cell><cell>N •0</cell><cell>N •1</cell><cell>N</cell></row></table><note><p><p><p><p><p>sen so that this proportion is well-defined even when N •1 = 0. The other quantity is the False Non-discovery Proportion (FNP) N 10 / max {N •0 , 1}, which is the proportion of outliers respectively. Similar measures have been proposed for solving compound decision problems in</p><ref type="bibr" target="#b24">Efron et al. (2001)</ref></p>,</p>Efron (2004,0,1)</p>, among others. Given data and a decision rule, the local FDR and local FNR are completely determined under the proposed model.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 :</head><label>6</label><figDesc>Study I: Overall classification performance based on the posterior means of ξ i and η j . For each model, each setting, and each target (test taker/item), we show the 25%, 50%, and 75% quantiles of the AUCs of the corresponding ROC curves from 50 independent datasets.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">Test taker</cell><cell></cell><cell></cell><cell cols="2">Item</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>S1</cell><cell></cell><cell>S2</cell><cell></cell><cell></cell><cell>S1</cell><cell></cell><cell>S2</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">AUC Reduced Full</cell><cell cols="2">Reduced Full</cell><cell cols="2">Reduced Full</cell><cell cols="3">Reduced Full</cell><cell></cell></row><row><cell></cell><cell>25%</cell><cell>0.953</cell><cell cols="2">0.954</cell><cell>0.951</cell><cell>0.959</cell><cell>0.951</cell><cell cols="2">0.959</cell><cell>0.951</cell><cell>0.959</cell><cell></cell></row><row><cell></cell><cell>50%</cell><cell>0.981</cell><cell cols="2">0.983</cell><cell>0.984</cell><cell>0.987</cell><cell>0.976</cell><cell cols="2">0.980</cell><cell>0.979</cell><cell>0.981</cell><cell></cell></row><row><cell></cell><cell>75%</cell><cell>0.990</cell><cell cols="2">0.994</cell><cell>0.993</cell><cell>0.993</cell><cell>0.992</cell><cell cols="2">0.994</cell><cell>0.997</cell><cell>0.996</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>S1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>S2</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Reduced</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell><cell cols="2">Reduced</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell></row><row><cell>FDP</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell></row><row><cell cols="13">25% 0.009 0.038 0.088 0.007 0.037 0.086 0.004 0.026 0.067 0.004 0.025 0.072</cell></row><row><cell cols="13">50% 0.012 0.048 0.091 0.011 0.048 0.092 0.007 0.031 0.079 0.006 0.029 0.083</cell></row><row><cell cols="13">75% 0.016 0.052 0.099 0.015 0.056 0.096 0.009 0.039 0.092 0.007 0.033 0.088</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 7 :</head><label>7</label><figDesc>Study I: Local FDR control for test takers.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 8 :</head><label>8</label><figDesc>Study I: Local FNR control for items. For each model, each setting, and each local FNR target (1%/5%/10%), we show the 25%, 50%, and 75% quantiles of the FNPs of the corresponding classifications from 50 independent datasets.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>S1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>S2</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Reduced</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell><cell></cell><cell cols="2">Reduced</cell><cell></cell><cell></cell><cell>Full</cell></row><row><cell>FNP</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell cols="2">10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell></row><row><cell cols="14">25% 0.009 0.049 0.091 0.010 0.045 0.089 0.006 0.024 0.063 0.007 0.025 0.065</cell></row><row><cell cols="14">50% 0.011 0.051 0.098 0.012 0.048 0.092 0.010 0.031 0.079 0.011 0.033 0.077</cell></row><row><cell cols="14">75% 0.013 0.059 0.104 0.012 0.057 0.096 0.015 0.039 0.091 0.012 0.037 0.089</cell></row><row><cell>S1</cell><cell></cell><cell cols="3">Reduced model</cell><cell></cell><cell></cell><cell>S2</cell><cell></cell><cell></cell><cell cols="3">Reduced model</cell></row><row><cell></cell><cell>π 1</cell><cell>π 2</cell><cell>σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell><cell></cell><cell>π 1</cell><cell>π 2</cell><cell cols="2">σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell></row><row><cell>Bias</cell><cell cols="7">0.13 0.09 -0.15 -0.19 -0.11 0.13 Bias</cell><cell cols="6">0.09 0.05 0.11 -0.08 -0.08 0.09</cell></row><row><cell cols="4">Variance 0.14 0.12 0.37</cell><cell>0.23</cell><cell cols="8">0.27 0.31 Variance 0.11 0.15 0.29 0.25</cell><cell>0.21 0.27</cell></row><row><cell>S1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Full model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>π 1</cell><cell>π 2</cell><cell>σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell><cell>σ 22</cell><cell>σ 12</cell><cell>µ 2</cell><cell>ω 22</cell><cell>ω 12</cell><cell>κ</cell></row><row><cell>Bias</cell><cell cols="13">0.11 -0.08 0.07 -0.24 -0.08 0.08 -0.12 -0.04 0.07 0.14 0.09 -0.16</cell></row><row><cell cols="5">Variance 0.16 0.11 0.34 0.19</cell><cell cols="3">0.32 0.35 0.09</cell><cell cols="6">0.07 0.12 0.13 0.08 0.77</cell></row><row><cell>S2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Full model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>π 1</cell><cell>π 2</cell><cell>σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell><cell>σ 22</cell><cell>σ 12</cell><cell>µ 2</cell><cell>ω 22</cell><cell>ω 12</cell><cell>κ</cell></row><row><cell>Bias</cell><cell cols="13">0.07 -0.03 0.11 -0.18 -0.05 0.11 -0.08 -0.06 0.09 0.15 0.05 -0.11</cell></row><row><cell cols="5">Variance 0.12 0.08 0.33 0.21</cell><cell cols="3">0.34 0.31 0.05</cell><cell cols="6">0.09 0.08 0.10 0.12 0.63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 9 :</head><label>9</label><figDesc>Study I: Accuracy of the posterior mean estimator of the global parameters. The bias and variance for the posterior mean estimator are calculated based on the 50 replications.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 12 :</head><label>12</label><figDesc>Study II: Local FDR control for test takers. For each model, each setting, and each local FDR target (1%/5%/10%), we show the 25%, 50%, and 75% quantiles of the FDPs of the corresponding classifications from 50 independent datasets.</figDesc><table><row><cell></cell><cell></cell><cell>S3</cell><cell></cell><cell></cell><cell>S4</cell><cell></cell><cell></cell><cell>S5</cell><cell></cell></row><row><cell>FNP</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell></row><row><cell cols="10">25% 0.007 0.021 0.061 0.019 0.032 0.078 0.015 0.039 0.072</cell></row><row><cell cols="10">50% 0.014 0.032 0.074 0.022 0.037 0.073 0.028 0.043 0.081</cell></row><row><cell cols="10">75% 0.017 0.038 0.076 0.024 0.041 0.085 0.030 0.047 0.087</cell></row><row><cell></cell><cell></cell><cell>S6</cell><cell></cell><cell></cell><cell>S7</cell><cell></cell><cell></cell><cell>S8</cell><cell></cell></row><row><cell>FNP</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell></row><row><cell cols="10">25% 0.009 0.024 0.045 0.012 0.031 0.072 0.014 0.036 0.064</cell></row><row><cell cols="10">50% 0.011 0.025 0.059 0.015 0.036 0.079 0.026 0.046 0.073</cell></row><row><cell cols="10">75% 0.014 0.032 0.082 0.025 0.041 0.086 0.029 0.054 0.083</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 13 :</head><label>13</label><figDesc>Study II: local FNR control for items. For each model, each setting, and each local FNR target (1%/5%/10%), we show the 25%, 50%, and 75% quantiles of the FNPs of the corresponding classifications from 50 independent datasets. ferential item functioning in item-response-type multivariate data. The proposed method simultaneously detects outlying individuals and items that deviate from a given baseline model. Furthermore, a compound decision theory is proposed for the detection of two-way outliers under a Bayesian decision framework. Statistical inference is carried out under a fully Bayesian framework for which a parallel tempering MCMC algorithm is developed.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 15 :</head><label>15</label><figDesc>.032 0.089 0.008 0.035 0.085 0.007 0.028 0.072 0.008 0.029 0.069 50% 0.012 0.047 0.092 0.011 0.046 0.091 0.011 0.043 0.078 0.009 0.037 0.073 75% 0.013 0.051 0.098 0.013 0.053 0.099 0.013 0.047 0.084 0.012 0.044 0.087 Local FDR control for test takers. For each model, each setting, and each local FDR target (1%/5%/10%), we show the 25%, 50%, and 75% quantiles of the FDPs of the corresponding classifications from 100 independent datasets. .033 0.063 0.007 0.032 0.061 0.007 0.029 0.059 0.006 0.031 0.062 50% 0.012 0.037 0.068 0.009 0.036 0.067 0.009 0.038 0.067 0.007 0.036 0.065 75% 0.013 0.046 0.071 0.010 0.043 0.069 0.012 0.045 0.072 0.012 0.041 0.071</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>C.S1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C.S2</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Reduced</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell><cell></cell><cell>Reduced</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell></row><row><cell>FDP</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell></row><row><cell cols="4">25% 0.008 0S1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>S2</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Reduced</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell><cell></cell><cell>Reduced</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell></row><row><cell>FNP</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell><cell>1%</cell><cell>5%</cell><cell>10%</cell></row><row><cell cols="2">25% 0.009 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 16 :</head><label>16</label><figDesc>Local FNR control for items. For each model, each setting, and each local FNR target (1%/5%/10%), we show the 25%, 50%, and 75% quantiles of the FNPs of the corresponding classifications from 100 independent datasets.</figDesc><table><row><cell>C.S1</cell><cell></cell><cell></cell><cell cols="2">Reduced model</cell><cell></cell><cell></cell><cell>C.S2</cell><cell></cell><cell></cell><cell cols="3">Reduced model</cell></row><row><cell></cell><cell>π 1</cell><cell>π 2</cell><cell>σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell><cell></cell><cell>π 1</cell><cell>π 2</cell><cell>σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell></row><row><cell>Bias</cell><cell cols="7">0.11 -0.02 -0.05 -0.11 0.17 0.22 Bias</cell><cell cols="5">0.05 0.15 -0.04 -0.13 0.20 -0.07</cell></row><row><cell cols="3">Variance 0.16 0.09</cell><cell>0.32</cell><cell cols="7">0.43 0.17 0.30 Variance 0.21 0.11 0.39</cell><cell cols="2">0.25 0.22 0.22</cell></row><row><cell>C.S1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Full model</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>π 1</cell><cell>π 2</cell><cell>σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell><cell>σ 22</cell><cell>σ 12</cell><cell>µ 2</cell><cell>ω 22</cell><cell>ω 12</cell><cell>κ</cell></row><row><cell>Bias</cell><cell cols="12">-0.11 -0.08 0.07 0.24 -0.08 0.11 -0.12 -0.04 -0.12 0.14 -0.08 -0.16</cell></row><row><cell cols="2">Variance 0.17</cell><cell cols="3">0.19 0.32 0.32</cell><cell>0.21</cell><cell>0.30</cell><cell>0.11</cell><cell>0.17</cell><cell cols="3">0.15 0.23 0.00</cell><cell>0.37</cell></row><row><cell>C.S2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Full model</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>π 1</cell><cell>π 2</cell><cell>σ 11</cell><cell>µ 1</cell><cell>ω 11</cell><cell>δ</cell><cell>σ 22</cell><cell>σ 12</cell><cell>µ 2</cell><cell>ω 22</cell><cell>ω 12</cell><cell>κ</cell></row><row><cell>Bias</cell><cell cols="12">-0.04 0.06 0.08 -0.15 -0.17 -0.15 -0.04 -0.11 -0.15 0.11 -0.04 -0.11</cell></row><row><cell cols="2">Variance 0.21</cell><cell cols="3">0.18 0.23 0.29</cell><cell>0.31</cell><cell>0.35</cell><cell>0.07</cell><cell>0.19</cell><cell cols="3">0.12 0.12 0.18</cell><cell>0.46</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 17 :</head><label>17</label><figDesc>Accuracy of the posterior mean estimator of the global parameters. The bias and variance for the posterior mean estimator are calculated based on the 100 replications.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The R code for the MCMC algorithm can be found on https://github.com/YanLu-stats/OD2WIRT.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting Misspecification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N J S3</head><p>(1) 2,000 200 S4</p><p>(2) 2,000 200 S5</p><p>(3) 2,000 200 S6</p><p>(1) 4,000 400 S7</p><p>(2) 4,000 400 S8</p><p>(3) 4,000 400</p><p>Table <ref type="table">10</ref>: Study II: Six simulation settings, where (1)-(3) correspond to three forms of model misspecification, including the misspecification of (1) the baseline model, (2) the relationship between ξ i and θ i , and (3) the common drift parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Study II</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Settings</head><p>In this study, we investigate the sensitivity of the proposed method under several forms of model misspecification. For the clarity of simulation settings, we focus on the misspecification of the item-response submodel. That is, we generate item-response data from a misspecified model and then apply our reduced model to classify the test takers and items.</p><p>The overall classification performance, as well as the performance of the proposed compound decision rules, is evaluated. We focus on three forms of model misspecification whose details are discussed below, including the misspecification of (1) the baseline model, (2) the relationship between ξ i and θ i , and (3) the common drift parameter. The three forms of model misspecification, together with two settings for N and J as in Study I, lead to six different settings as summarised in Table <ref type="table">10</ref>. For each setting, except for the misspecified part, the global parameters are set the same as those in Study I. For each setting, 50 independent datasets are generated.</p><p>We now discuss the three forms of model misspecification in detail. For the baseline model, we replace the Rasch model by the two-parameter logistic model, an IRT model that is widely used in educational testing. That is, the following item-response submodel is</p><p>where n is less than or equal to N as there might be ties. We further let p (0) = 0 and   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Settings</head><p>We consider two settings, with (1) N = 2, 000, J = 50, and (2) N = 4, 000, J = 100. The rest of the simulation setting is exactly the same as that of Study I. These two settings are referred to as settings C.S1 and C.S2, respectively. For each setting, 100 independent data sets are simulated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Results</head><p>The analysis is conducted using the parallel tempering MCMC algorithm described above.</p><p>For each dataset, we run 10,000 iterations, with the first 3,000 iterations as the burn-in. The results are based on the posterior samples from the last 7,000 iterations.</p><p>Our results are given in Tables <ref type="table">14 through 17</ref>. The results are similar to those from Study I. Table <ref type="table">14</ref> gives the AUC values for the classification of test takers and items. Tables <ref type="table">15</ref> and 16 evaluate the performance of the local FDR control and local FNR control procedures for the classification of test takers and items, respectively. More specifically, Table <ref type="table">15</ref> gives the corresponding FDP values when controlling the local FDR at 1%, 5%, and 10% levels for the test takers. Table <ref type="table">16</ref> gives the FNP values when controlling the local FNR at 1%, 5%, and 10% levels for the items. Finally, the bias and variance for the posterior mean estimator are given in Table <ref type="table">17</ref>. of a CAT system. Applied Psychological Measurement, 38:87-104.</p><p>Zhou, Z., Li, X., Wright, J., <ref type="bibr">Candès, E., and Ma, Y. (2010)</ref>. Stable principal component pursuit. In 2010 IEEE international symposium on information theory, pages 1518-1522. IEEE.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Approximate is better than &quot;exact&quot; for interval estimation of binomial proportions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agresti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Coull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="119" to="126" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifiability of parameters in latent structure models with many observed variables</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Allman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rhodes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="3099" to="3132" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards optimal scaling of metropolis-coupled markov chain monte carlo</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">F</forename><surname>Atchadé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="555" to="568" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Practical issues in implementing and understanding Bayesian ideal point estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bafumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Latent variable models and factor analysis: A unified approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bartholomew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Knott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moustaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>West Sussex, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detection of test collusion via Kullback-Leibler divergence</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Belov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="141" to="163" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: A practical and powerful approach to multiple testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Some latent trait models and their use in inferring an examinee&apos;s ability</title>
		<author>
			<persName><forename type="first">A</forename><surname>Birnbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical theories of mental test scores</title>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Lord</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Novick</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford, England</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1968">1968</date>
			<biblScope unit="page" from="397" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Item parameter estimation under conditions of test speededness: Application of a mixture Rasch model with ordinal constraints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Bolt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Wollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="331" to="348" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A hybrid model for test speededness</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Boughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multivariate and mixture distribution Rasch models</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Davier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Carstensen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="147" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Robust principal component analysis?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Bayes and empirical Bayes methods for data analysis</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Louis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An introduction to empirical Bayes data analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="83" to="87" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computational and inferential difficulties with mixture posterior distributions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Celeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hurn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="957" to="970" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Item quality control in educational testing: Change point model, compound risk, and sequential detection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.10104</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Compound sequential change point detection in multiple data streams</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.05903</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An NCME instructional module on latent DIF analysis using mixture item response models</title>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational Measurement: Issues and Practice</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="48" to="61" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Handbook of quantitative methods for detecting cheating on tests</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Cizek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Wollack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Routledge</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Joint consistency of nonparametric item characteristic curve and ability estimation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Douglas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="7" to="28" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Nonparametric Bayesian modelling for item response</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Maceachern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Modelling</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="41" to="66" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Large-scale simultaneous hypothesis testing: The choice of a null hypothesis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="96" to="104" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Microarrays, empirical Bayes and the two-groups model</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Large-scale inference: Empirical Bayes methods for estimation, testing, and prediction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Two modeling strategies for empirical Bayes estimation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="285" to="301" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Empirical Bayes analysis of a microarray experiment</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Storey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tusher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1151" to="1160" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Item response theory for psychologists</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Embretson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Lawrence Erlbaum Associates Publishers</publisher>
			<pubPlace>Mahwah, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Prior distributions for variance parameters in hierarchical models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="515" to="534" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A weakly informative default prior distribution for logistic and other regression models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jakulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Pittau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1360" to="1383" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Inference from iterative simulation using multiple sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="457" to="472" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Importance sampling, simulated tempering, and umbrella sampling</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Geyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-L</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Markov chain Monte Carlo</title>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="295" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A speeded item response model with gradual process change</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Goegebeur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>De Boeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Wollack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="65" to="87" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Exploratory latent structure analysis using both identifiable and unidentifiable models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="215" to="231" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Identifying multiple outliers in multivariate data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Hadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="761" to="771" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Differential item functioning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wainer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Feedback-optimized par-allel tempering monte carlo</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Katzgraber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Trebst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Huse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Troyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Mechanics: Theory and Experiment</title>
		<imprint>
			<biblScope unit="page">3018</biblScope>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Test fraud: Statistical detection and methodology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kingston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Latent variable modelling with nonignorable item nonresponse: multigroup response propensity models for cross-national analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kuha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Katsikatsou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moustaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series A: Statistics in Society</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="1169" to="1192" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Latent structure analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Lazarsfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Henry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968">1968</date>
			<publisher>Houghton Mifflin Co</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Lunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<title level="m">The BUGS book: A practical introduction to Bayesian analysis</title>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Detecting outliers in factor analysis using the forward search algorithm</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mavridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moustaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate behavioral research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="453" to="475" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The forward search algorithm for detecting aberrant response patterns in factor analysis for binary data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mavridis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moustaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1016" to="1034" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Bayesian method for the detection of item preknowledge in computerized adaptive testing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcleod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thissen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="121" to="137" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Millsap</surname></persName>
		</author>
		<title level="m">Statistical approaches to measurement invariance</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Bounded-influence robust estimation in generalized linear latent variable models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Moustaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-P</forename><surname>Victoria-Feser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="644" to="653" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Detecting candidate preknowledge and compromised content using differential person and item functioning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of quantitative methods for detecting cheating on tests</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Cizek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Wollack</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="151" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Symmetric pattern models: a latent variable approach to item non-response in attitude scales</title>
		<author>
			<persName><forename type="first">C</forename><surname>O'muircheartaigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Moustaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series A (Statistics in Society)</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="177" to="194" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust factor analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Pison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Filzmoser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Croux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="145" to="172" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On the half-cauchy prior for a global scale parameter</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="887" to="902" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Patterns of congressional voting</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Political Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="228" to="278" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">On dimensionalizing roll call votes in the US Congress</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">T</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Koford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="955" to="976" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Comparing hierarchical models via the marginalized deviance information criterion</title>
		<author>
			<persName><forename type="first">A</forename><surname>Quintero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lesaffre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="2440" to="2454" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Maximum marginal likelihood estimation for semiparametric item analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ramsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="365" to="379" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Probabilistic models for some intelligence and achievement tests</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rasch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nielsen and Lydiche</title>
		<imprint>
			<date type="published" when="1960">1960</date>
			<pubPlace>Copenhagen, Denmark</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Reckase</surname></persName>
		</author>
		<title level="m">Multidimensional item response theory</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Analysis of residuals for the multionmial item response model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Reiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="509" to="528" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">On Bayesian analysis of mixtures with an unknown number of components (with discussion)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="731" to="792" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Asymptotically subminimax solutions of compound statistical decision problems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second Berkeley symposium on mathematical statistics and probability</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Neyman</surname></persName>
		</editor>
		<meeting>the second Berkeley symposium on mathematical statistics and probability<address><addrLine>Berkeley, CA</addrLine></address></meeting>
		<imprint>
			<publisher>University of California Press</publisher>
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An empirical Bayes approach to statistics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third Berkeley symposium on mathematical statistics and probability</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Neyman</surname></persName>
		</editor>
		<meeting>the third Berkeley symposium on mathematical statistics and probability<address><addrLine>Berkerly, CA</addrLine></address></meeting>
		<imprint>
			<publisher>University of California Press</publisher>
			<date type="published" when="1956">1956</date>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Optimal scaling for various metropolis-hastings algorithms</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="351" to="367" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An item response model for characterizing test compromise</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">O</forename><surname>Segall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="163" to="179" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<title level="m">Mathematical statistics</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Using deterministic, gated item response theory model to detect test cheating due to item compromise</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="481" to="497" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Detection of item preknowledge using likelihood ratio test and score test</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sinharay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="46" to="68" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Which statistic should be used to detect item preknowledge when the set of compromised items is known?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sinharay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="403" to="421" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">The case for Bayesian methods when investigating test fraud</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Skorupski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wainer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of quantitative methods for detecting cheating on tests</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Cizek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Wollack</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="214" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Bayesian measures of model complexity and fit</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Linde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="583" to="639" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The deviance information criterion: 12 years on</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Linde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B: Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="485" to="493" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Oracle and adaptive compound decision rules for false discovery rate control</title>
		<author>
			<persName><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="901" to="912" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A hierarchical framework for modeling speed and accuracy on test items</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Van Der Linden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="287" to="308" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Detection of known items in adaptive testing with a statistical quality control method</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Veerkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Glas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="373" to="389" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">The linear transformation model with frailties for the analysis of item response times</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Douglas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="144" to="168" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A mixture hierarchical model for response times and response accuracy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="456" to="477" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A two-stage approach to differentiating normal and aberrant behavior in computer based testing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="223" to="254" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Detecting compromised items using information from secure items</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="667" to="689" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Item factor analysis: current approaches and future directions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Handbook of test security</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Wollack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Fremer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Routledge</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Robust mean and covariance structure analysis</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="63" to="88" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Effect of outliers on estimators and tests in covariance structure analysis</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="161" to="175" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Compound decision theory and empirical Bayes methods</title>
		<author>
			<persName><forename type="first">C.-H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="379" to="390" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">A sequential procedure for detecting compromised items in the item pool</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
