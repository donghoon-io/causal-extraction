<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unfolding the Network of Peer Grades: A Latent Variable Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-10-18">18 Oct 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Giuseppe</forename><surname>Mignemi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yunxiao</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Irini</forename><surname>Moustaki</surname></persName>
						</author>
						<title level="a" type="main">Unfolding the Network of Peer Grades: A Latent Variable Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-10-18">18 Oct 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2410.14296v1[stat.AP]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Peer grading</term>
					<term>rating model</term>
					<term>cross-classified model</term>
					<term>Bayesian modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Peer grading is an educational system in which students assess each other's work. It is commonly applied under Massive Open Online Course (MOOC) and offline classroom settings. With this system, instructors receive a reduced grading workload, and students enhance their understanding of course materials by grading others' work. Peer grading data have a complex dependence structure, for which all the peer grades may be dependent. This complex dependence structure is due to a network structure of peer grading, where each student can be viewed as a vertex of the network, and each peer grade serves as an edge connecting one student as a grader to another student as an examinee. This paper introduces a latent variable model framework for analyzing peer grading data and develops a fully Bayesian procedure for its statistical inference. This framework has several advantages. First, when aggregating multiple peer grades, the average score and other simple summary statistics fail to account for grader effects and, thus, can be biased. The proposed approach produces more accurate model parameter estimates and, therefore, more accurate aggregated grades, by modeling the heterogeneous grading behavior with latent variables. Second, the proposed method provides a way to assess each student's performance as a grader, which may be used to identify a pool of reliable graders or generate feedback to help students improve their grading. Third, our model may further provide insights into the peer grading system by answering questions such as whether a student who performs better in coursework also tends to be a more reliable grader. Finally, thanks to the Bayesian approach, uncertainty quantification is straightforward when inferring the student-specific latent variables as well as the structural parameters of the model. The proposed method is applied to two real-world datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Peer grading, also known as peer assessment, is a system of formative assessment in education whereby students assess and give feedback on one another's work. It substantially reduces teachers' burden for grading and improves students' understanding of the subject and critical thinking <ref type="bibr" target="#b57">(Yin et al., 2022;</ref><ref type="bibr" target="#b36">Panadero &amp; Alqassab, 2019)</ref>. Consequently, it is widely used in many educational settings, including massive open online courses (MOOCs; <ref type="bibr" target="#b14">Gamage et al., 2021)</ref>, large university courses <ref type="bibr">(Double et al.,</ref> Figure <ref type="figure" target="#fig_3">1</ref>: Network diagram representing the network structure of peer grading data. Each circle is a vertex of the network and represents a student. The arrows are the peer grades, which serve as edges connecting two students; their direction indicates whether the student receives or gives the grade. 2020), and small classroom settings <ref type="bibr" target="#b46">(Sanchez et al., 2017)</ref>. In a peer grading system, each student's work is assigned, often randomly, among several other students who act as graders or raters. Due to the design of this system, peer grading data have a different structure from traditional rating data, which also consists of students' grades from graders. For traditional rating data, the students, whose work is evaluated, cannot serve as graders, which leads to a relatively simple data structure. On the other hand, peer grading data has a network structure where all the peer grades may be dependent. Each student can be viewed as a network vertex, and each peer grade serves as an edge connecting two students -a grader and an examinee; see Figure <ref type="figure" target="#fig_3">1</ref> for a visual illustration of such a network structure.</p><p>A simple peer grading system aggregates the peer grades using a straightforward method like the mean or median to derive a final grade for each student's work <ref type="bibr" target="#b44">(Sajjadi et al., 2016;</ref><ref type="bibr" target="#b43">Reily et al., 2009)</ref>. This conventional method does not consider the heterogeneity among the graders. Some graders may exhibit systematic biases and tend to assign higher or lower grades than their peers when assessing the same work. Graders may also exhibit varying levels of reliability; while some maintain consistent grading standards, others may give erratic grades that lack a consistent standard. Furthermore, when the data involve multiple formative assessments for each student, a more accurate grade may be derived by borrowing information across assessments. Finally, monitoring how students perform as graders is often helpful, as it provides an opportunity to reward the best-performing graders and offer feedback to help those who need improvement. Different methods have been developed to mitigate grader bias and improve peer assessment reliability; see <ref type="bibr" target="#b0">Alqassab et al. (2023)</ref> for a review. Depending on whether instructors' scores are needed in method training, they can be classified as supervised and unsupervised learning methods. Supervised learning methods utilize instructors' scores to train a function that maps multiple peer grades to an aggregated grade that mimics the instructor's score <ref type="bibr" target="#b30">(Namanloo et al., 2022;</ref><ref type="bibr" target="#b55">Xiao et al., 2020)</ref>. On the other hand, unsupervised learning methods try to find an aggregation rule only based on peer grades without access to instructors' scores. Unsupervised learning is typically performed by employing latent-variable-based measurement models (e.g., <ref type="bibr" target="#b20">Han, 2018;</ref><ref type="bibr" target="#b40">Piech et al., 2013;</ref><ref type="bibr" target="#b56">Xu et al., 2021)</ref>, which are closely related to models for traditional rating data. As will be explained in the sequel, they make an independence assumption that is also adopted in the latent variable models for traditional rating data. However, as peer grading data have a complex network structure, this independence assumption is likely over-simplified, leading to suboptimal performance.</p><p>Many latent variable models have been proposed for traditional rating data, including the facet model <ref type="bibr" target="#b25">(Linacre, 1989)</ref> and its extensions <ref type="bibr" target="#b49">(Uto &amp; Ueno, 2020;</ref><ref type="bibr" target="#b48">Uto, 2021)</ref>, the hierarchical rater models <ref type="bibr" target="#b7">(Casabianca et al., 2016;</ref><ref type="bibr" target="#b10">DeCarlo et al., 2011;</ref><ref type="bibr" target="#b29">Molenaar et al., 2021;</ref><ref type="bibr" target="#b35">Nieto &amp; Casabianca, 2019;</ref><ref type="bibr" target="#b39">Patz et al., 2002)</ref>, the rater bundle model <ref type="bibr" target="#b54">(Wilson &amp; Hoskens, 2001)</ref>, and the generalized rater model <ref type="bibr" target="#b51">(Wang et al., 2014)</ref>. These models introduce rater-specific parameters to model the rater effects in the data. When having many raters, these rater-specific parameters are treated as random effects (i.e., latent variables) and further assumed to be independent of the examinee-specific latent variables that are used to model examinee performance. These assumptions are also made in the existing latent variable models for peer grading data <ref type="bibr" target="#b20">(Han, 2018;</ref><ref type="bibr" target="#b40">Piech et al., 2013;</ref><ref type="bibr" target="#b56">Xu et al., 2021)</ref>. However, we note that the assumption about the independence between the rater-specific latent variables and examinee-specific latent variables does not hold for peer grading data, as the same students are both examinees and raters, and the characteristics of the same student as a rater and those as an examinee are naturally correlated. Ignoring such dependence can result in model misspecification and substantial information loss. To our knowledge, no rater model in the literature accounts for such a dependence structure.</p><p>We fill this gap by proposing an unsupervised latent variable model for peer grading data. The proposed model jointly analyzes peer grades for multiple assessments and produces more accurate aggregated grades. It models the student effects with correlated latent variables that capture a student's characteristics as an examinee and a grader, respectively. Unlike the existing latent variable models for peer grading data, the proposed model captures the dependence in data brought by the network structure of peer grades and the dual roles of each student as an examinee and a rater.</p><p>Due to the complex dependence structure under the proposed model, its marginal likelihood involves a very high-dimensional integral with respect to all the studentspecific latent variables that can hardly be simplified. Thus, solving the maximum likelihood estimator is computationally infeasible, and consequently, frequentist inference based on the marginal likelihood is a challenge. We develop a fully Bayesian approach for drawing statistical inferences to overcome the computational challenge. With this approach, uncertainty quantification is straightforward when inferring the student-specific latent variables as well as the structural parameters of the model. However, its computation is still non-trivial due to the presence of a large number of latent variables and a complex network structure. To solve this, we use a No-U-Turn Hamiltonian Monte Carlo sampler <ref type="bibr" target="#b21">(Hoffman &amp; Gelman, 2014)</ref>, which produces efficient approximate samples from the posterior distribution.</p><p>Besides the traditional rater models, the proposed framework is closely related to cross-classified random effects models <ref type="bibr" target="#b42">(Raudenbush, 1993;</ref><ref type="bibr" target="#b18">Goldstein, 1994;</ref><ref type="bibr" target="#b41">Rasbash &amp; Goldstein, 1994)</ref>, an extension of standard multilevel models for non-hierarchical data that have cross-classified structures. These models have received wide applications for evaluating measurement reliability, including in generalizability theory <ref type="bibr" target="#b4">(Brennan, 2001</ref><ref type="bibr" target="#b5">(Brennan, , 2010))</ref>. Our data involve three crossed factors -the examinees, the graders, and the assessments, and the proposed model decomposes each peer grade based on these three factors. However, our model allows the latent variables (i.e., random effects) associated with the crossed factors (examinees and raters) to be correlated to account for the special design of peer grading. In contrast, a standard cross-classified random effects model assumes the random effects associated with different crossed factors to be independent. Introducing such dependence among the latent variables substantially increases the complexity of the model and its inferences. Our model also has close connections with several latent variable models concerning dyadic data, including social relations models (e.g., <ref type="bibr" target="#b22">Kenny &amp; La Voie, 1984;</ref><ref type="bibr" target="#b32">Nestler, 2016;</ref><ref type="bibr" target="#b33">Nestler et al., 2017</ref><ref type="bibr" target="#b34">Nestler et al., , 2020;;</ref><ref type="bibr" target="#b52">Warner et al., 1979)</ref> and the dyadic item response theory (IRT) model <ref type="bibr" target="#b17">(Gin et al., 2020)</ref>, where the dyadic IRT model extends the social relations models by incorporating an IRT measurement model. Peer grading data can be viewed as a special type of dyadic data, where each dyad involves an examinee and a grader, and the dyads are formed by random assignment. However, our model differs substantially from the existing social relations models in how latent variables are modeled and interpreted. The traditional social relations models focus on inferring the causes and consequences of interpersonal perceptions and judgments. In contrast, the current analysis focuses on measuring some latent traits that are concerned in the application of peer grading (e.g., examinee performance and rater reliability). As a result, the existing social relations models are unsuitable for the current application.</p><p>The rest of the paper is organized as follows. Section 2 proposes a latent variable model framework for peer grading data, within which specific models are discussed. Two real data applications are given in Section 3. Section 4 discusses advantages, limitations, and future directions. The appendix includes extensions of the proposed model, technical details, and additional simulated examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Setup</head><p>Consider N students who receive T assessments. Each student i's work on assessment t is randomly assigned to a small subset of other students to grade their work. We denote this subset as S it , which is a subset of {1, ..., i -1, i + 1, ..., N}. Each grader g ∈ S it gives this work a grade Y igt , following certain scoring rubrics. For simplicity, we consider the case when Y igt is continuous. It is common, but not required, for the number of graders |S it | to be the same for all students and assessments. An aggregated score is then computed as a measure of student i's performance on the tth assessment, often by taking the mean or the median of the peer grades Y igt , g ∈ S it . We note that a simple aggregation rule, such as the mean and the median of the peer grades, fails to account for the grader effect and, thus, may not be accurate enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Proposed Model</head><p>Modelling Peer Grade Y igt . We assume the following decomposition for the peer grade Y igt :</p><formula xml:id="formula_0">Y igt = θ it + τ igt -δ t , i = 1, ..., N,t = 1, . . . , T, g ∈ S it .<label>(1)</label></formula><p>Here, δ t captures the difficulty level of assessment t. A larger value of δ t corresponds to a more difficult assessment. In addition, θ it represents student i's true score for assessment t, and τ igt is an error attributed to the grader. We assume θ it , τ igt and δ t to be independent.</p><p>Modeling True Score θ it . For each student i, we assume that their true scores for different assessments θ it , t = 1, . . . , T , are independent and identically distributed (i.i.d.), following a normal distribution</p><formula xml:id="formula_1">θ it ∼ N(α i , η 2 i ),<label>(2)</label></formula><p>where the mean and variance are student-specific latent variables. The latent variable α i captures the student's average performance over the assessments, and the latent variable η 2 i measures their performance consistency (i.e., the extent to which student's proficiency varies across assessments). This model assumes the true scores fluctuate randomly around the average score α i without a trend. This assumption can be relaxed if we are interested in assessing students' growth over time; see Appendix B for a relaxation of this assumption.</p><p>Modelling Grader Effect τ igt . Each student g grades multiple assessments from multiple students. We let H g = {(i,t) : g ∈ S it ,t = 1, ..., T } be all the work student g grades. For each student g, we assume that τ igt , for all (i,t) ∈ H g , are i.i.d., following a normal distribution N(β g , φ 2 g ), where the mean and variance are student-specific latent variables. The latent variable β g may be interpreted as the bias of student g as a grader. For two students g and g ′ satisfying β g &gt; β g ′ , student g will give a higher grade on average than student g ′ when grading the same work. We say grader g is unbiased when β g = 0. Moreover, the latent variable φ 2 g measures the grader's reliability. A smaller value of φ 2 g implies that the grader provides consistent grades to assessments of similar quality, while a larger value suggests the opposite. In other words, when grading multiple pieces of work with the same true score and assessment difficulty (so that ideally they should receive the same grade), a grader with a small φ 2 g tends to give similar grades, and thus, the grades are more reliable. In contrast, a grader with a large φ 2 g tends to give noisy grades that lack consistency. We remark that the grader effects τ igt , t = 1, ..., T , are assumed to be i.i.d. in the current setting, which means the grading quality remains the same over time.</p><p>Joint Modelling of Student-Specific Latent Variables. The model specification above introduces four latent variables, namely α i , β i , η 2 i , and φ 2 i , for each student i. These variables allow us to account for the relationship between a student's performance data and grading data as an examinee and a grader. By allowing for dependence between these variables, we can share information and make more informed evaluations of their performance. We assume that (α i , β i , η 2 i , φ 2 i ), where i = 1, ..., N are i.i.d.; we also assume that (α i , β i , log(η 2 i ), log(φ 2 i )) follows a multivariate normal distribution N (µ µ µ, Σ Σ Σ), where µ µ µ = (µ 1 , ..., µ 4 ) ⊤ and Σ Σ Σ = (σ mn ) 4×4 . To ensure parameter identifiability, we set µ 1 = µ 2 = 0 so that the average score of each assessment (averaged across students and graders) is completely captured by the difficulty parameter δ t . There are no constraints on µ 3 and µ 4 .</p><p>Remarks. Figure <ref type="figure">2</ref> shows an illustrative path diagram for the proposed model under a simplified setting with N = 4 students and T = 2 assessments. Compared with many traditional latent variable models, the current path diagram shows a network structure where the latent variables of different individuals interact with each other. This phenomenon is due to the network structure of peer grading data, where each grade involves two students -one as the examinee and the other as the grader.</p><p>The proposed model is useful in different ways. First, the model provides a measurement model for the true score of each student i's assessment t. By inferring each latent variable, θ it , whose technical details will be discussed in Section 2.3, the grader and assessment effects will be adjusted. Thus, a more accurate aggregated score may be obtained. Second, it allows us to further assess each student's overall performance and consistency as an examinee by inferring α i and η 2 i . Third, the model also provides a measurement model for the characteristics of each student as a grader. Specifically, the bias and reliability of each grader can be assessed by inferring β i and φ 2 i . Such results can be used to reward the best-performing graders and offer feedback to help those who need improvement. Finally, the statistical inference of the structural parameters in Σ Σ Σ allows us to address substantive questions, such as whether a student who performs better in the coursework tends to be a more reliable grader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Bayesian Inference</head><p>We adopt a fully Bayesian procedure for drawing statistical inference under the proposed model.</p><p>Prior specification. We first specify the prior for the assessment difficulty parameters δ 1 , . . . , δ T . When T is large, we can get reliable estimates of the assessments' population parameters (e.g., the mean and the variance, <ref type="bibr" target="#b6">Cao &amp; Stokes 2008;</ref><ref type="bibr" target="#b9">De Boeck 2008;</ref><ref type="bibr" target="#b15">Gelman 2006;</ref><ref type="bibr" target="#b12">Fox &amp; Glas 2001)</ref>. In such cases, we can use a hierarchical prior specification and assume that δ 1 , . . . , δ T are i.i.d. following a specific prior distribution (e.g., a normal distribution) with some hyper-parameters. Then, we set a hyper-prior distribution for the hyper-parameters. When T is small, it is not reasonable to assume to observe a representative sample of assessments, and the estimates at the population level might be very unreliable <ref type="bibr" target="#b9">(De Boeck, 2008)</ref>. Therefore, we let each δ t have a weakly informative prior distribution of N(0, 25). However, tailored considerations must be made depending on the specific data set, and different prior specifications might be specified <ref type="bibr" target="#b16">(Gelman et al., 2013)</ref>.</p><p>Figure <ref type="figure">2</ref>: Path diagram representing the network structure of peer grading data. The latent variables of four independent students are represented as an example. Students' grades, reported in the squared box, refer to two assessments, as the subscripts indicated. The curve double-arrows stand for correlation; the straight (solid and dotted) lines represent the effect of the respective latent variable. For the sake of readability, we prefer to adopt the solid lines for the effect of variables referring to the role of the examinee (i.e., α, η 2 ), whereas the dotted lines refer to the effect of the latent variables associated to the role of grader (i.e., β , φ 2 ).</p><p>We specify a prior for the parameters µ µ µ and Σ Σ Σ in the joint distribution for the student-specific latent variables. Recall that µ 1 and µ 2 are constrained to zero, so no prior is required. As for µ 3 and µ 4 , they are assumed to be independent, and each follows a weakly informative normal prior N(0, 25). Finally, for the covariance matrix Σ Σ Σ, we reparameterize it as</p><formula xml:id="formula_2">Σ Σ Σ = SΩ Ω ΩS, where S = diag( √ σ 11 , . . . , √ σ 44 ) is a 4 × 4 diagonal matrix with diagonal entries the standard deviations of (α i , β i , log(η 2 i ), log(φ 2 i )),</formula><p>and</p><formula xml:id="formula_3">Ω Ω Ω = (ω i j ) 4×4 = S -1 Σ Σ ΣS -1 is the correlation matrix of (α i , β i , log(η 2 i ), log(φ 2 i )).</formula><p>The prior distribution on Σ Σ Σ is imposed through the priors on S and Ω Ω Ω. For S, we assume √ σ 11 , . . . , √ σ 44 to be i.i.d., each following a half-Cauchy distribution with location 0 and scale 5. For the correlation matrix Ω Ω Ω, we assume a Lewandowski-Kurowicka-Joe (LKJ) prior distribution with shape parameter 1 <ref type="bibr" target="#b24">(Lewandowski et al., 2009)</ref>, which corresponds to the uniform distribution over the space of all correlation matrices. Model Comparison. Several reduced models can be derived under the proposed framework as special cases. For instance, a reduced model may be obtained by constraining</p><formula xml:id="formula_4">η 2 1 = • • • = η 2 N = η 2 , i.e.</formula><p>, students' performance consistency as examinee is homogeneous. Another reduced model may be derived by constraining</p><formula xml:id="formula_5">φ 2 1 = • • • = φ 2 N = φ 2 .</formula><p>An even more simplified model can be obtained by imposing both sets of constraints. Given a dataset, Bayesian model comparison methods may be used to find the best-performing model among the full and the reduced models and, thus, provide insights into the peer grading system and yield more accurate aggregated grades.</p><p>We consider a Bayesian leave-one-out (LOO) cross-validation procedure for model comparison, which concerns the model's prediction performance. For a given dataset and a given model, this procedure computes the expected log point-wise predictive density (elpd; <ref type="bibr" target="#b50">Vehtari et al., 2017)</ref> to measure the overall accuracy in predicting each data point (i.e., peer grade) based on the rest of the data. More precisely, we define the Bayesian LOO estimate of out-of-sample predictive fit as</p><formula xml:id="formula_6">elpd loo = T ∑ t=1 N ∑ i=1 ∑ g∈S it log p(Y igt |Y -igt ),</formula><p>where Y -igt denotes all the observed peer grades except for Y igt , and p(Y igt |Y -igt ) denotes the conditional probability mass function of Y igt given Y -igt ) under the fitted Bayesian model. A model with a higher value of elpd loo is regarded to have better prediction power and, thus, is preferred. In Section 3, we also report the Watanabe-Akaike information criterion (WAIC), which corrects the expected log point-wise predictive density by adding a penalty term for the effective number of parameters <ref type="bibr" target="#b50">(Vehtari et al., 2017)</ref>.</p><p>Computation. As illustrated in Figure <ref type="figure">2</ref>, the proposed model involves a latent space with dimension 4N and a complex dependence structure between the observed data and the latent variables. This complex model structure makes its statistical inference computationally a challenge. We use a Markov Chain Monte Carlo (MCMC) algorithm for statistical inference. More specifically, we adopt the No-U-Turn Hamiltonian Monte Carlo (HMC) sampler <ref type="bibr" target="#b21">(Hoffman &amp; Gelman, 2014)</ref>, a computationally efficient MCMC sampler, and implement it under the Stan programming language. Compared with classical MCMC samplers, such as the Gibbs and Metropolis-Hastings samplers, the No-U-Turn HMC sampler uses geometric properties of the target distribution to propose posterior samples. It thus converges faster to high-dimensional target distributions <ref type="bibr" target="#b21">(Hoffman &amp; Gelman, 2014)</ref>. Further computational details are given in the appendix.</p><p>Regarding the implementation, we use the CmdStan interface (Stan Development Team, 2023) for posterior sampling, which is a command-line interface to Stan that is considerably more efficient than using R as the interface. For all the models, 4 HMC chains are run in parallel for 2,000 iterations, of which the first 1,000 iterations were specified as the burn-in period. We use the rstan R package to analyze the resulting posterior samples, more specifically, it enables us to merge the MCMCs, compute the summary statistics of the posteriors and check the MCMC mixing and convergence. Moreover, the R package loo <ref type="bibr" target="#b50">(Vehtari et al., 2017)</ref> and Bayesplot <ref type="bibr" target="#b13">(Gabry et al., 2019)</ref> are used separately for model comparisons and to plot the results, respectively. The computation code used in our analysis, the computational time, and other details on model diagnostics are publically available online<ref type="foot" target="#foot_0">foot_0</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">A Related Model</head><p>One of the most well-known approaches to latent variable modeling of peer grading data was proposed by <ref type="bibr" target="#b40">Piech et al. 2013</ref>. They present three models of increasing complexity, in which the observed score is assumed to be a function of two independent variables: the student's ability (also known as the true score) and the effect of the grader (often considered the error part). This type of decomposition is very common in rater effects models <ref type="bibr" target="#b27">(Martinková et al., 2023;</ref><ref type="bibr" target="#b19">Gwet, 2008)</ref> and is also assumed in our framework. For comparison purposes, we briefly discuss their more complex model, which is also considered in Section 3 and compared with the one we present in Section 2.2. The notation we adopt in presenting their model is consistent with our framework. They assume that the observed score Y ig is normally distributed with the mean parameter given by the sum of the true score θ i and the grader bias β g , and the precision parameter being a linear function of the true score of student g:</p><formula xml:id="formula_7">Y ig ∼ N θ i + β g , 1 γ 0 + γ 1 θ g .</formula><p>The model assumes that the true scores of students, denoted by θ i , are independently and identically normally distributed, θ i ∼ N(µ 0 , 1/γ 2 ), i = 1, . . . , N. In addition, the model assumes that graders' biases denoted by β g , are i.i.d. normally distributed, β g ∼ N(0, 1/γ 3 ), g = 1, . . . , N.</p><p>While this model relates to the proposed method, the two have several differences. For example, the model proposed by the authors does not account for the difficulty level of the assignment. Even if they propose to use normalized grades (z-scores) to remove any assignment effects, it may still be useful to estimate the difficulty level of the assignment. Furthermore, the model assumes that the parameters θ i and β i , which are the same student indexes, are independent. It also imposes a strict constraint on the precision parameter of the observed score. Specifically, it does not allow the precision to vary given the same value of θ g , and it assumes that the precision is independent of the grader bias β g . Finally, the model does not account for the temporal dependency in the presence of multiple assessments. This model, denoted in Section 3 as PM (i.e., Piech's Model), is compared against the proposed one using real data from multiple and single assessment contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Reduced Model for a Single Assessment</head><p>Some peer grading data only involve a single assessment, as the case for one of our real data examples in Section 3. The proposed model can still be applied in that situation, but certain constraints must be imposed for model identification. Details of the Bayesian inference for this model are given in the appendix.</p><p>Modelling Peer Grade Y ig . With only one assessment, the notation for peer grade simplifies to Y ig = Y ig1 , and its decomposition simplifies to</p><formula xml:id="formula_8">Y ig = θ i + τ ig -δ , i = 1, ..., N, g ∈ S i ,<label>(3)</label></formula><p>where the subscript t is removed from all the notations in (1), and the interpretation of the variables remains the same. Due to the lack of multiple assessments, the examinee parameters α i and η 2 i in the main model, Equation (2), can no longer be identified and, thus, are not introduced here.</p><p>Modelling Grader Effect τ ig . Each student g grades the assessment of multiple peers. Let H g = {i : g ∈ S i } be the peers whose work is graded by student g. It is assumed that τ ig , i ∈ H g , are i.i.d., following a normal distribution N(β g , φ 2 g ). The interpretation of these parameters is the same as in the primary model; see Section 2.2.</p><p>Joint Modelling of Student Specific Latent Variables. The reduced model involves three student-specific latent variables (θ i , β i , φ 2 i ). Similar to the main model, we assume that (θ i , β i , log(φ 2 i )), i = 1, ..., N, are i.i.d., each following a multivariate normal distribution N (µ µ µ, Σ Σ Σ), where µ µ µ = (µ 1 , µ 2 , µ 3 ) ⊤ and Σ Σ Σ = (σ i j ) 3×3 . Similar to the main model, we constrain µ 1 = µ 2 = 0, while keep µ 3 freely estimated. Figure <ref type="figure" target="#fig_0">3</ref> gives an illustrative path diagram for this reduced model with N = 3 students. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Real Data Examples</head><p>Two real-world applications referring to single-and multiple-assessments settings are considered here. Various models are compared for each data set, and the one that exhibits the best predictive performance is used for inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multiple-Assessments Setting</head><p>The peer grading data is from <ref type="bibr" target="#b58">Zong et al. (2021)</ref>. In this data, 274 American undergraduate students taking a Biology course completed four double-blind peer gradings throughout the course (N = 274, T = 4). The assessments had a similar format, and the online peer reviewing system managed the submission and peer grading procedures SWoRD/Peerceptiv <ref type="bibr" target="#b38">(Patchan et al., 2016)</ref>. Students' mean age was 20, and 59% were female. Students' ethnicity was quite heterogeneous, 69% were Asian, 2% Black, 14% Latinx and 15% White. On average, each work was graded by a random set of five other students. <ref type="bibr" target="#b58">Zong et al. 2021</ref> produced the peer grading score as the average across different rubrics. As a result, gradings are on a 1-7 continuous scale. The minimum and the maximum observed values were, respectively, 1 and 7. The mean and the median grades were 5.414 and 5.500, respectively, which suggest that data are slightly negatively skewed. To implement the main model, only students who completed at least three assessments were included in the analysis, which resulted in a sample size of 212 students.</p><p>Model comparison. Four different models of increased complexity are fitted and compared. In the first model (M1), we only accounted for one student-specific latent variable: the ability and the assessment difficulty level. This model did not consider the effects of graders, such as their systematic biases and reliability levels. Additionally, M1 assumed that the student's ability was equal across all assessments. This is the more constrained model. In the second model (M2), we relax our assumptions and consider the graders' effects, such as their systematic bias and reliability levels. To do this, we use a three-dimensional multivariate normal distribution to jointly model the student-specific latent variables, including θ i , β i and φ<ref type="foot" target="#foot_1">foot_1</ref> i , i = 1, . . . , N. It is worth noting that fitting M2 is like fitting the reduced model for a single assessment separately (see Section 2.5), except that students are assumed to have the same ability level across assessments, i.e., θ it = θ i , i = 1, . . . , N. In the third model (M3), we relax this assumption and allow for variations in students' abilities across assessments by introducing a fourth student-specific latent variable, η 2 i , i = 1, . . . , N. Under this model, examinee-and grader-specific latent variables, respectively, (θ i , η 2 i ) and (β i , φ 2 i ) are assumed to be independent. This assumption is relaxed in the fourth model (M4) in which the latent variables θ i , β i , log(η 2 i ), log(φ 2 i ), i = 1, . . . , N, are allowed to be correlated. M4 is the main model introduced in Section 2.2. We also compare these models with the one proposed by <ref type="bibr" target="#b40">Piech et al. (2013)</ref> and detailed in Section 2.4. Under this multiple-assessments setting, we let the difficulty parameter vary across assessments for comparison purposes.</p><p>Model comparison is based on the predictive performance criteria discussed in Section 2.3. The models are fitted using the prior specifications and posterior procedure discussed in Section 2.3. Grades are on a continuous 1-7 scale, with the midpoint considered the average assessment difficulty. Therefore, we have set the prior distribution for δ 1 , . . . , δ 4 iid ∼ N(4, 25). The students are then given an estimate of the true score for each work and a reliability estimate as a grader.</p><p>Results from the selected Model. Upon graphical inspection of the MCMCs, no mixing or convergence issues were detected, as indicated by R values being less than 1.01. The Number of Effective Sample Size was above the cut-off Ne f f &gt; 0.10 for all the structural parameters <ref type="bibr" target="#b16">(Gelman et al., 2013)</ref>. The average computational time per chain varies from 64.445 to 1, 594.02 seconds, respectively, recorded for models M1 and M4. Further details on model diagnostics (e.g., trace plot, R, Ne f f , convergence diagnostic plots), as well as computational time, can be found in Supplementary Materials 2 .</p><p>Table <ref type="table" target="#tab_0">1</ref> gives the value of the leave-one-out expected log point-wise density elpd loo and the relative standard error for each model fitted, including the pairwise difference in terms of elpd loo between M4 and each of the other models; in the last column we also report the WAIC <ref type="bibr" target="#b16">(Gelman et al., 2013)</ref>. The procedure for model comparison showed that M4 provides the best predictive performance. The slightly better performance of M4 over M4 in terms of these criteria supports our assumption of the examinee-and grader-specific latent variables being correlated.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows that the difficulty levels of the assessments are increasing throughout the course. The 95% quantile-based credible intervals of the assessment difficulty parameters are moderately narrow, indicating a low level of uncertainty for these parameters.</p><p>The posterior means for the latent variable variances are μ3 = -1.27 with a 95% credible interval of (-1.46, -1.07) and μ4 = -0.46 with a 95% credible interval of (-0.51, -0.41). This implies that, on average, the variance of the student's ability is smaller than the error variance of the grades they give. In other words, they are more consistent as an examinee than a grader. This seems reasonable, considering that they are not grader experts. Note that these parameters are expressed on a logarithmic scale, meaning that the average variance of the students' proficiency across different assessments is exp( μ3 ) = 0.28, and, on average, their reliability parameter is exp( μ4 ) = 0.63.</p><p>Students are moderately homogeneous regarding their mean abilities, as suggested by σ1 = 0.23. In contrast, they are more variable in their systematic bias, σ2 = 0.35. In other words, they are, on average, more similar as examinees than as graders. Moreover, students are widely different concerning their consistency across assessments, σ3 = 0.66. Finally, they have slightly less variability concerning the reliability parameters as indicated by σ4 = 0.32.</p><p>Regarding the dependencies among the latent variables, higher values of students' proficiency are associated with higher consistency values. Indeed, there is evidence of a strong correlation between the first and the second student-specific latent variable, respectively, α i and log(η 2 i ), as suggested by ω13 = -0.86 and the 95% credible interval of and (-0.99, -0.76). In addition, higher mean bias values predict higher reliability levels. This is evidenced by ω24 = -0.74 and the 95% credible interval of (-0.86, -0.62). The estimates of the other correlation parameters do not provide clear evidence about any other dependencies. The grader's effect explains, on average, 26.1% of the grading variance, conditioning on the assessment difficulties.</p><p>At the student-specific level, a score estimate and a 95% quantile-based credible interval may be provided for each assessment to measure the uncertainty. For students' scores, the posterior mean of θitδt can be used as a point estimate. Additionally, the posterior distributions for both the average bias and the reliability of each grader can be useful in assessing their grading behavior. If a grader is accurate and reliable, their β i and η 2 i values should be close to zero. Conversely, values far from zero indicate biased and unreliable grading behavior. Both parameters are provided with a 95% quantilebased credible interval. For illustrative purposes, the posterior estimates of the true score θ11 -δ1 , the mean bias β 1 and the reliability φ 1 of student i = 1 are reported in Figure <ref type="figure" target="#fig_1">4</ref>. On the examinee side, the posterior estimates of the true score suggest that for the first assessment t = 1, the proficiency level of this student is slightly larger than the average. On the grader side, based on the posterior estimates of β 1 and φ 2 1 , this student is more severe and moderately less reliable than the average (note that µ 2 = 0 and the posterior mean of µ 4 is -0.46 on the log scale).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Single Assessment Setting</head><p>The data used for the cross-sectional analysis was obtained from an applied economics undergraduate course at the University of Oviedo, as reported by <ref type="bibr" target="#b26">(Luaces et al., 2018)</ref>.</p><p>The sample consisted of 108 students who participated in a double-blind individual peer assessment on an online platform provided by the university. Each coursework was an open-response assessment rated by ten students according to different rubrics on Likert scales of various lengths. For the present analysis, we consider the sum of the ratings given on these other aspects as the final grade. The observed grades ranged from 0 to 12, with a mean of 7.526 and a median of 8.000. Further information on the grading procedure might be found in <ref type="bibr" target="#b26">Luaces et al. 2018</ref>.</p><p>Model comparison. Four models are fitted and compared. Three are nested models, and the fourth is the model provided by <ref type="bibr" target="#b40">Piech et al. (2013)</ref> and discussed in Section 2.4.</p><p>In the first model ( <ref type="formula" target="#formula_0">M1</ref>), we specify one single student-specific latent variable: the student ability and the assessment difficulty parameter. This model did not consider the effects of graders, such as their systematic biases and reliability levels. In other words, graders' mean bias is fixed to zero, and they are assumed to be equally reliable. This model is the same as the (M1) model detailed in Section 3.1, but only with one assessment. In the second model (M2), we let the graders' mean biases be freely estimated. Moreover, we let this second student-specific latent variable correlate with the first one. Indeed, they are assumed to be i.i.d. across students, following a bivariate normal distribution. In the third model (M3), we relax the assumption of equal reliability across different graders. However, the latent ability θ i is assumed to be independent of the other features of the student as a grader (i.e., β i and φ 2 i ), for i = 1, . . . , N. This independence assumption is relaxed in the fourth model (M4) and we allow them to be correlated. M4 is the model presented in Section 2.5. The models are fitted using the prior specifications and the posterior procedure discussed in Section 2.3. As with the multiple-assessments example, the prior distribution for the difficulty parameters is set to <ref type="bibr">N(5.5, 25)</ref>. The students are then given an estimate of the true score for each assessment and a reliability estimate as a grader.</p><p>Results for the Selected Model. As with the multiple-assessments example, no mixing or convergence issues were detected, as indicated by R values less than 1.01. The average computational time per chain ranges from 2.7 to 44.772 seconds, respectively, recorded from Models M1 and M4. Further details on Model diagnostics (e.g., trace plot, R), as well as computational time, can be found in the Appendix and an anonymous link <ref type="foot" target="#foot_2">3</ref> .</p><p>Table <ref type="table" target="#tab_2">3</ref> indicates that model M4 has the best predictive performance, though its advantage over M3 is very small. μ3 = 0.10 gives the mean graders' reliability level (i.e., the posterior mean of η i ), and there is considerable variability among them as indicated by σ 3 . Indeed, the estimates of σ 3 on a log scale imply a posterior standard deviation of η i larger than one on the original rating scale. Students are very similar in their latent ability, as suggested by the small values of the posterior standard deviation of their abilities, i.e., σ 1 (see Table <ref type="table" target="#tab_4">4</ref>). The same extent of variability is estimated concerning their mean biases σ 2 . This implies that students are pretty homogeneous regarding proficiency in doing the assessment and severity in grading their peers. The 95% CI for the correlation parameters ω 1 and ω 2 do not suggest a clear relation between the respective latent variables. A positive correlation between graders' bias and their reliability is highlighted by ω 23 . Nonetheless, the relative credible interval is quite large, implying uncertainty about the correlation size. Grader's effects explain, on average, the 16.3% of the grading variance.</p><p>Each student might receive a true score estimate at the individual level. The posterior mean of θiδ might be used as a point estimate for students' true scores. Moreover, the posterior distributions of both the mean bias and the reliability of each grader might be helpful information to assess their grading behavior. As an illustration, the posterior estimates of the true score θ11 -δ , the mean bias β 1 and the reliability φ 1 of student i = 1 are reported in Figure <ref type="figure" target="#fig_2">5</ref>. On the examinee side, the true score's posterior estimates suggest that this student's proficiency level is slightly larger than the average. On the grader side, the posterior estimates of β 1 and φ 2 1 suggest that this student is moderately more severe than the average in terms of mean bias but average in terms of reliability level (note that µ 2 = 0 and the posterior mean of µ 3 is 0.10 on the log scale).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussions</head><p>This paper presents a new modeling framework for peer grading data, which introduces latent variables to capture the dependencies in the data from the network structure of peer grades and the dual role of each student as an examinee and a grader. The statistical inference uses a Bayesian method, and an algorithm based on the No-U-Turn Hamiltonian Monte Carlo sampler was developed. The proposed model was applied to two real-world peer grading datasets, one with a single assessment and the other with four. The results showed that the proposed model had superior prediction performance in real-world applications and that the MCMC did not suffer from mixing or  The posterior mean (Post. Mean) and the 95% quantile-based credible interval (CI) are reported for each parameter. The parameter δ represents the difficulty level of the assessment; µ 3 is the location parameter of the third latent variable; σ 1 , . . . , σ 3 are the standard deviations of the latent variables; ω mn is the correlation parameter between the latent variables m and n. convergence issues.</p><p>The current work also has some limitations. First, the peer grades in the applications in Section 3 are bounded, which may cause ceiling and floor effects, as the variability of student performance is no longer measurable when they receive a very high or low score. However, the proposed model is based on several normal assumptions, which fail to capture such phenomena. To model bounded grades, we may add a nonlinear transformation to the right-hand side of (1) to ensure Y ig to be bounded.</p><p>Second, it is not easy to verify the assumptions about the latent variables in our model and further validate their interpretation, as we cannot observe the latent variables. Without additional information, it is hard to disentangle different assumptions about the latent variables and verify them separately. We can only check whether the model-implied distribution for the observed data fits its empirical distribution (e.g., using Bayesian LOO and WAIC) and use it to compare different models. Using this approach, we can only tell that the assumptions of one model as a whole are more sensible than those of the other. To further verify the assumptions of our model, we may collect data with both peer and instructor grades. The instructor grades may be used as the underlying truth to check some specific assumptions in our model.</p><p>The current work can be further extended in several directions. First, in formative assessment settings, people are often interested in the growth of students over multiple assessments during a course. Therefore, it may be useful to extend the proposed model to a longitudinal setting and develop a latent growth curve model for peer grading. To explore this direction, we have considered a simple extension of the proposed model and performed a small simulation study in Appendix B. This model assumes the true score θ it to follow a latent growth curve model. While this model performed well in the simulation, it may be over-simplified for real-world settings. In practice, student characteristics as a rater and the difficulty levels of the assessments may also change over time. Simultaneously modeling all these changes may result in model identification issues. We leave this problem for future investigation.</p><p>Second, additional context information, such as student-and classroom-related factors, is often available in formative assessment settings. Such information is useful in explaining and predicting each student's performance both as an examinee and as a rater. In this regard, we believe it is useful to extend the framework of explanatory item response models <ref type="bibr" target="#b23">(Kim &amp; Wilson, 2020;</ref><ref type="bibr" target="#b53">Wilson &amp; De Boeck, 2004)</ref> to the current setting to include context information as covariates.</p><p>Third, the reliability of the peer grading system based on the proposed model is worth investigating. This may be done by adapting the generalizability theory <ref type="bibr" target="#b4">(Brennan, 2001</ref><ref type="bibr" target="#b5">(Brennan, , 2010))</ref>, originally established under the traditional cross-classified random effects models, to the current model. With the new generalizability theory, we may evaluate the reliability of the system from different perspectives (e.g., examinees, raters, and assessments).</p><p>Fourth, many real-world peer grading systems involve ordinal peer grades. The proposed model may be extended to ordinal data by replacing the linear model (1) with a generalized linear model. One possible formulation is given in Appendix D, which still mimics the proposed model but replaces (1) with a partial credit model form <ref type="bibr" target="#b28">(Masters, 1982)</ref>. Alternative models also may be available, such as one based on the graded response model <ref type="bibr" target="#b45">(Samejima, 1969)</ref>. The suitability of these models for peer grading remains to be studied through a theoretical investigation and numerical studies based on simulated and real data. We leave it for future investigation.</p><p>Finally, it should be noted that although the Bayesian approach allows for statistical inferences, it can be time-consuming to compute. The high computational cost is due to the proposed model's high dimensionality, which depends on the number of students and assessments. To make the proposed method scalable for large-scale applications, like MOOC data, advanced computational methods for Bayesian inference, such as stochastic gradient MCMC algorithms, should be explored <ref type="bibr" target="#b31">(Nemeth &amp; Fearnhead, 2021)</ref>. modeling <ref type="bibr" target="#b3">(Bollen &amp; Curran, 2006)</ref>. For example, a linear latent curve unconditional model can expand the structural model ( <ref type="formula" target="#formula_1">2</ref>) for true score θ it by assuming</p><formula xml:id="formula_9">θ it ∼ N(α i0 + λ t α i1 , η 2 i ), (B.1)</formula><p>where α i0 , α i1 and η 2 i are student-specific latent variables, and λ t , t = 1, ..., T are a prespecified coding of time. The linear function α i0 + λ t α i1 can be interpreted as the latent trajectory of student i. The coding of time can be chosen based on the time when the assessments are given. In the special case when the assessments are given at equally spaced intervals, we can set λ t = t -1,t = 1, 2, ..., T . We keep the model for τ igt unchanged. The student-specific latent variables now include (α i0 , α i1 , β i , η 2 i , φ 2 i ). In line with our assumptions in the main model, we assume that (α i0 , α i1 , β i , log(η 2 i ), log(φ 2 i )), i = 1, ..., N are i.i.d., and follow a multivariate normal distribution.</p><p>This model can be further extended to capture nonlinear trajectories. For example, a quadratic latent curve model may be assumed for θ it by assuming</p><formula xml:id="formula_10">θ it ∼ N(α i0 + λ t α i1 + λ 2 t α i2 , η 2 i ), (B.2)</formula><p>where α i0 , α i1 , α i2 and η 2 i are student-specific latent variables, and λ t , t = 1, ..., T are still a pre-specified coding of time. The random second-order coefficient α i2 is the rate of change in the linear component along time and represents the acceleration in growth for student i' ability <ref type="bibr" target="#b3">(Bollen &amp; Curran, 2006;</ref><ref type="bibr" target="#b2">Biesanz et al., 2004)</ref>. The joint model for student-specific latent variables can be extended accordingly.</p><p>The prior specifications discussed in Section 2 for the unknown parameters, δ 1 , . . . , δ T and µ µ µ, Σ Σ Σ, might be consistently adopted for the current model. The same procedures and reparametrization used for the posterior computation introduced above might be freely applied here for the multivariate normal distribution. The Bayesian model comparison procedure discussed in Section 2 might be used to compare the models under both the main and LGC framework. As for the previous models, each parameter and student-specific latent variables might be provided with both a posterior point estimate, e.g. the posterior mean, and an interval estimate, e.g. a 95% quantile-based credible interval. Indeed it might be seen as an uncertainty measure of the relative estimated parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 A Simulation under the LGC Model</head><p>Homoscedastic LGC models typically require at least three time-points per individual (e.g., <ref type="bibr" target="#b8">Curran et al., 2010)</ref>, whereas, our proposal concerns a heteroscedastic setting that allows some variance terms to be individual-specific and implies a larger number of parameters. Given the relatively small number of assignments per student (at most four) and the rather small sample size N = 212, the LGC model might not be suitable for the real data analyzed in Section 3.1. We provide a simulated example based on the above LGC model an illustrative example.</p><p>Data generation. We generated a dataset from the linear LGC Model in which a sample of N = 100 students are assigned T = 6 assessments. For each assessment, the work of each student is graded by a random subset of other |S it | = 3 students.</p><p>The following values are fixed for the structural parameters of the model: µ δ = 0, σ δ = 1, µ µ µ = 0, Ω Ω Ω = I I I is a 5-dimensional identity matrix, S S S = diag(1, 0.1, 1, 0.2, 0.2), see Table <ref type="table" target="#tab_5">B</ref>.1. Estimated parameters. All the considerations on the prior and computational aspects discussed in the main text are consistently followed here. The graphical inspection of the MCMCs does not suggest any mixing or convergence issues which is consistent with the low values of R &lt; 1.01. The average computational time per chain recorded is 5, 293.08 seconds<ref type="foot" target="#foot_3">foot_3</ref> .</p><p>The estimates of the structural parameters are reported in Table <ref type="table" target="#tab_5">B</ref>.1. All the true values are included in the 95% credible intervals, even though these posterior intervals are considerably large. This uncertainty might be due to the small sample size N = 100. The only exception is the correlation parameter ω 34 which 95% credible interval does not include the true value (even if it is the difference between the upper bound of the interval and the true value is practically negligible). More replications might shed light on these aspects.</p><p>Under this model, along with the estimates of the true grade and the grader's effects (i.e., the mean bias and the reliability), each student might be provided with the estimate of his/her latent linear growth trend. For illustrative purposes, we plot the estimated growth of four different students in Figure <ref type="figure">B</ref>.1. Note that the 95% credible intervals of the student-specific trend α 0i + α 1i (t -1) are proportional to the values of t. This is because the 0.05 and the 0.95 quantiles of the posterior of α 1i are multiplied by this covariate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Prior Sensitivity Analysis</head><p>We performed a prior sensitivity analysis to investigate the impact of the prior on final model estimates <ref type="bibr" target="#b16">(Gelman et al., 2013)</ref>. As discussed by <ref type="bibr" target="#b15">Gelman (2006)</ref>, inferences might be very sensitive to the choice of the prior distribution for hierarchical variance parameters and useful information might come from tailored stimulative studies. As a preliminary analysis, we fit the main model on different generated data sets comparable to the real data set analysed in Section 3.1. For each data set, we alternatively fit the main model under three different prior specifications resulting in three different scenarios. We compare the respective estimates through the root mean square error (RMSE) and the mean absolute error (MAE).</p><p>Data generation. We generated R = 10 independent datasets from the Main Model in which a sample of N = 100 students are assigned T = 4 assessments. For each assessment, each student's work is graded by a random subset of other |S it | = 3 students. The following values are fixed for the structural parameters of the model: µ δ = 0, σ δ = 1, µ µ µ = 0, Ω Ω Ω = I I I is a 4-dimensional identity matrix, S S S = diag(1, 1, 0.2, 0.2). and the 95% quantile-based credible interval (CI) are reported for each parameter. The parameter δ is the difficulty level of the assessment; µ 2 ,µ 4 and µ 5 are the location parameters of the second, the fourth and the fifth latent variable, respectively; σ 1 , . . . , σ 5 are the standard deviations of the latent variables; ω mn is the correlation parameter between the latent variables m and n. Results Inferences are the same across different scenarios, suggesting a robustness of the model to different prior specifications for the scale parameters. Table <ref type="table" target="#tab_6">C</ref> gives the RMSE and the MAE for the structural parameters and the true scores (i.e., θ itδ t ). The RMSE and the MAE of the estimates of the true scores are, on average, 1.99 and 1.59 under all the scenarios. The RMSE and the MAE of the aggregated score using the mean to derive the final grade for each student's work <ref type="bibr" target="#b44">(Sajjadi et al., 2016;</ref><ref type="bibr">Reily et al., 2009) are, respectively, 2.46 and 1.98</ref>. This suggests that our proposal might consistently mitigate graders' systematic bias and unreliability.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Path diagram representing the network structure of peer grading data for a single assessment. The latent variables of three independent students are represented as an example. The box indicates the students' grades for a single assessment. The double arrows represent correlation, while the straight (solid and dotted) lines represent the effect of the respective latent variable. The meaning of the arrows is consistent with those of Figure 2. The solid line represents the effect of the latent variable related to the role of the examinee (i.e., θ ). The dotted lines refer to the effect of the latent variables associated with the grader role (i.e., β , φ 2 ).</figDesc><graphic coords="11,177.67,124.80,255.90,162.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Application 1, multiple-assessments example: Posterior distribution of the true score of the first assessment (a), mean bias (b), and reliability (c) of student i = 1. The black dotted lines indicate the 95% quantile-based credible interval and the posterior mean of each estimated parameter.</figDesc><graphic coords="15,222.15,377.97,166.95,106.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Single assessment example: Posterior distribution of the true score (a), mean bias (b), reliability (c) of student i = 1. The black dotted lines indicate the 95% quantile-based credible interval and the posterior mean of each estimated parameter.</figDesc><graphic coords="18,221.83,490.64,167.58,112.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure B. 1 :</head><label>1</label><figDesc>Figure B.1: Estimated linear latent growth of a random sample of four students. The red and the black dotted lines are the true linear growth and the estimated one, respectively; the red bands are the 95% credible intervals of this trend.</figDesc><graphic coords="24,153.18,240.91,151.20,100.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure C. 1 :</head><label>1</label><figDesc>Figure C.1: Priors placed under different scenarios on σ 1 , . . . , σ 4 , µ 3 , µ 4 . The blue, orange and green solid lines indicate, respectively, the half-Cauchy, the inverse-gamma and the exponential priors.</figDesc><graphic coords="25,225.70,146.45,159.84,98.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Multiple-assessments example: Four model specifications are compared using a leaveone-out cross-validation approach. The expected log point-wise density value (elpd loo ) and its respective standard error (SE) are reported. The models are given in descending order based on their elpd loo values. ∆el pd loo gives the pairwise comparisons between each model and the model with the largest elpd loo (M4), and SE∆ is the standard error of the difference. The Watanabe-Akaike information criterion (WAIC) is given in the last column for each model.</figDesc><table><row><cell cols="2">Model el pd loo</cell><cell>SE</cell><cell cols="2">∆el pd loo SE∆</cell><cell>WAIC</cell></row><row><cell>M4</cell><cell cols="2">-3751.8 49.9</cell><cell>-</cell><cell>-</cell><cell>7358.18</cell></row><row><cell>M3</cell><cell cols="2">-3770.0 49.3</cell><cell>-18.2</cell><cell cols="2">8.5 7382.30</cell></row><row><cell>MP</cell><cell cols="5">-3937.7 52.0 -185.9 24.7 7819.19</cell></row><row><cell>M2</cell><cell cols="5">-3939.4 54.1 -187.6 24.8 7820.01</cell></row><row><cell>M1</cell><cell cols="5">-4470.7 54.2 -718.9 47.1 8939.57</cell></row><row><cell></cell><cell cols="3">Parameter Post. Mean</cell><cell></cell><cell>95% CI</cell></row><row><cell cols="2">Assessments</cell><cell>δ 1</cell><cell cols="3">-6.31 (-6.40, -6.22)</cell></row><row><cell></cell><cell></cell><cell>δ 2</cell><cell cols="3">-5.39 (-5.47, -5.30)</cell></row><row><cell></cell><cell></cell><cell>δ 3</cell><cell cols="3">-5.36 (-5.44, -5.28)</cell></row><row><cell></cell><cell></cell><cell>δ 4</cell><cell cols="3">-4.96 (-5.05, -4.88)</cell></row><row><cell>Students</cell><cell></cell><cell>µ 3</cell><cell cols="3">-1.27 (-1.46, -1.07)</cell></row><row><cell></cell><cell></cell><cell>µ 4</cell><cell cols="3">-0.46 (-0.51, -0.41)</cell></row><row><cell></cell><cell></cell><cell>σ 1</cell><cell>0.23</cell><cell></cell><cell>(0.18, 0.29)</cell></row><row><cell></cell><cell></cell><cell>σ 2</cell><cell>0.35</cell><cell></cell><cell>(0.31, 0.40)</cell></row><row><cell></cell><cell></cell><cell>σ 3</cell><cell>0.66</cell><cell></cell><cell>(0.49, 0.84)</cell></row><row><cell></cell><cell></cell><cell>σ 4</cell><cell>0.32</cell><cell></cell><cell>(0.28, 0.37)</cell></row><row><cell></cell><cell></cell><cell>ω 12</cell><cell>-0.10</cell><cell cols="2">(-0.31, 0.11)</cell></row><row><cell></cell><cell></cell><cell>ω 13</cell><cell cols="3">-0.86 (-0.99, -0.76)</cell></row><row><cell></cell><cell></cell><cell>ω 14</cell><cell>0.17</cell><cell cols="2">(-0.05, 0.40)</cell></row><row><cell></cell><cell></cell><cell>ω 23</cell><cell>-0.07</cell><cell cols="2">(-0.32, 0.17)</cell></row><row><cell></cell><cell></cell><cell>ω 24</cell><cell cols="3">-0.74 (-0.86, -0.62)</cell></row><row><cell></cell><cell></cell><cell>ω 34</cell><cell>0.12</cell><cell cols="2">(-0.15, 0.38)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Multiple-assessments example: Model M4 estimated structural parameters. The posterior mean (Post. Mean) and the 95% quantile-based credible interval (CI) are reported for each parameter. The parameter δ t represents the difficulty level of the assessment t; µ 3 and µ 4 are the location parameters of the third and the fourth latent variable, respectively; σ 1 , . . . , σ 4 are the standard deviations of the latent variables; ω mn is the correlation parameter between the latent variables m and n.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Single assessment example: Four model specifications are compared using a leaveone-out cross-validation approach. The expected log point-wise density value (elpd loo ) and its respective standard error (SE) are reported. The models are given in descending order based on their elpd loo values. ∆el pd loo gives the pairwise comparisons between each model and the model with the largest elpd loo (M4), and SE∆ is the standard error of the difference. The Watanabe-Akaike information criterion (WAIC) is given in the last column for each model.</figDesc><table><row><cell>Model</cell><cell>el pd loo</cell><cell>SE</cell><cell cols="2">∆el pd loo SE∆</cell><cell>WAIC</cell></row><row><cell>M4</cell><cell cols="2">-1712.6 25.8</cell><cell>0.0</cell><cell cols="2">0.0 3410.29</cell></row><row><cell>M3</cell><cell cols="2">-1712.9 25.5</cell><cell>-0.3</cell><cell cols="2">0.7 3410.76</cell></row><row><cell>M2</cell><cell cols="2">-2271.2 22.4</cell><cell>-558.7</cell><cell cols="2">19.9 4535.97</cell></row><row><cell>M1</cell><cell cols="2">-2271.2 22.3</cell><cell>-558.7</cell><cell cols="2">19.8 4536.05</cell></row><row><cell>MP</cell><cell cols="2">-2283.9 22.8</cell><cell>-571.4</cell><cell cols="2">20.8 4557.39</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Application 2, single assessment example: Model M4 estimated structural parameters.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table B .</head><label>B</label><figDesc>1: Estimated structural parameters. The true value, the posterior mean (Post. Mean)</figDesc><table><row><cell></cell><cell cols="3">Parameter True Value Post. Mean</cell><cell>95% CI</cell></row><row><cell>Assessments</cell><cell>µ δ</cell><cell>0.00</cell><cell>0.05</cell><cell>(-3.72, 3.80)</cell></row><row><cell></cell><cell>σ δ</cell><cell>2.00</cell><cell>3.59</cell><cell>(1.95, 6.35)</cell></row><row><cell></cell><cell>δ 1</cell><cell>2.52</cell><cell>2.48</cell><cell>(2.18, 2.78)</cell></row><row><cell></cell><cell>δ 2</cell><cell>-1.72</cell><cell cols="2">-1.74 (-3.04, -0.40)</cell></row><row><cell></cell><cell>δ 3</cell><cell>-1.01</cell><cell>-0.95</cell><cell>(-3.53, 1.67)</cell></row><row><cell></cell><cell>δ 4</cell><cell>1.39</cell><cell>1.01</cell><cell>(-2.84, 4.90)</cell></row><row><cell></cell><cell>δ 5</cell><cell>-3.45</cell><cell>-3.55</cell><cell>(-8.69, 1.65)</cell></row><row><cell></cell><cell>δ 6</cell><cell>3.30</cell><cell>3.27</cell><cell>(-3.15, 9.75)</cell></row><row><cell>Students</cell><cell>µ 2</cell><cell>0.00</cell><cell>-0.05</cell><cell>(-1.32, 1.26)</cell></row><row><cell></cell><cell>µ 4</cell><cell>0.00</cell><cell>-0.01</cell><cell>(-0.09, 0.06)</cell></row><row><cell></cell><cell>µ 5</cell><cell>0.00</cell><cell>0.01</cell><cell>(-0.03, 0.05)</cell></row><row><cell></cell><cell>σ 1</cell><cell>1.00</cell><cell>1.02</cell><cell>(0.85, 1.20)</cell></row><row><cell></cell><cell>σ 2</cell><cell>0.01</cell><cell>0.07</cell><cell>(0.01, 0.15)</cell></row><row><cell></cell><cell>σ 3</cell><cell>1.00</cell><cell>1.03</cell><cell>(0.91, 1.17)</cell></row><row><cell></cell><cell>σ 4</cell><cell>0.20</cell><cell>0.17</cell><cell>(0.05, 0.28)</cell></row><row><cell></cell><cell>σ 5</cell><cell>0.20</cell><cell>0.19</cell><cell>(0.16, 0.23)</cell></row><row><cell></cell><cell>ω 12</cell><cell>0.00</cell><cell>0.11</cell><cell>(-0.43, 0.66)</cell></row><row><cell></cell><cell>ω 13</cell><cell>0.00</cell><cell>0.11</cell><cell>(-0.09, 0.31)</cell></row><row><cell></cell><cell>ω 14</cell><cell>0.00</cell><cell>-0.13</cell><cell>(-0.53, 0.30)</cell></row><row><cell></cell><cell>ω 15</cell><cell>0.00</cell><cell>0.10</cell><cell>(-0.13, 0.33)</cell></row><row><cell></cell><cell>ω 23</cell><cell>0.00</cell><cell>-0.30</cell><cell>(-0.76, 0.21)</cell></row><row><cell></cell><cell>ω 24</cell><cell>0.00</cell><cell>0.13</cell><cell>(-0.49, 0.69)</cell></row><row><cell></cell><cell>ω 25</cell><cell>0.00</cell><cell>0.03</cell><cell>(-0.50, 0.54)</cell></row><row><cell></cell><cell>ω 34</cell><cell>0.00</cell><cell cols="2">-0.40 (-0.74, -0.03)</cell></row><row><cell></cell><cell>ω 35</cell><cell>0.00</cell><cell>0.13</cell><cell>(-0.07, 0.34)</cell></row><row><cell></cell><cell>ω 45</cell><cell>0.00</cell><cell>0.33</cell><cell>(-0.10, 0.70)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table C .</head><label>C</label><figDesc>1: Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) related to students' true scores and structural parameters under different scenarios across 10 independent data sets.</figDesc><table><row><cell></cell><cell>RMSE MAE RMSE MAE RMSE MAE</cell></row><row><cell>δ 1</cell><cell>0.243 0.195 0.244 0.196 0.244 0.196</cell></row><row><cell>δ 2</cell><cell>0.182 0.138 0.182 0.137 0.183 0.138</cell></row><row><cell>δ 3</cell><cell>0.159 0.138 0.161 0.142 0.159 0.138</cell></row><row><cell>δ 4</cell><cell>0.131 0.095 0.131 0.096 0.131 0.095</cell></row><row><cell>µ 3</cell><cell>1.018 1.015 1.012 1.009 0.994 0.991</cell></row><row><cell>µ 4</cell><cell>1.001 0.997 0.999 0.996 1.029 1.023</cell></row><row><cell>σ 1</cell><cell>0.150 0.126 0.127 0.108 0.109 0.090</cell></row><row><cell>σ 2</cell><cell>0.145 0.124 0.105 0.088 0.133 0.102</cell></row><row><cell>σ 3</cell><cell>0.834 0.825 0.772 0.760 0.840 0.826</cell></row><row><cell>σ 4</cell><cell>0.855 0.841 0.811 0.806 0.849 0.847</cell></row><row><cell>ω 12</cell><cell>0.124 0.101 0.124 0.101 0.122 0.099</cell></row><row><cell>ω 13</cell><cell>0.220 0.184 0.162 0.136 0.215 0.181</cell></row><row><cell>ω 14</cell><cell>0.246 0.224 0.235 0.210 0.247 0.226</cell></row><row><cell>ω 23</cell><cell>0.136 0.085 0.116 0.068 0.135 0.084</cell></row><row><cell>ω 24</cell><cell>0.275 0.214 0.262 0.202 0.276 0.215</cell></row><row><cell>ω 34</cell><cell>0.119 0.078 0.078 0.054 0.116 0.082</cell></row><row><cell cols="2">True score 1.995 1.597 1.994 1.596 1.995 1.597</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Our code is available through the link: https://osf.io/v3ucw/?view only= aad3bc91cbda43cc9e6c490409323839</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Available through the link https://osf.io/v3ucw/?view only= aad3bc91cbda43cc9e6c490409323839</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Available through the link: https://osf.io/v3ucw/?view only= aad3bc91cbda43cc9e6c490409323839.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>More details on computational time and model diagnostic are available through the link: https:// osf.io/v3ucw/?view only=aad3bc91cbda43cc9e6c490409323839</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We are sincerely grateful to <rs type="person">Professors Oscar Luaces</rs> and <rs type="person">Christian Schunn</rs> for sharing real datasets in Section 3.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Computational details</head><p>To resolve the convergence issue and make the MCMC mix well, we used a non-centred reparametrization for the multivariate normal distribution <ref type="bibr" target="#b16">(Gelman et al., 2013;</ref><ref type="bibr" target="#b1">Betancourt &amp; Girolami, 2015;</ref><ref type="bibr" target="#b37">Papaspiliopoulos et al., 2007)</ref>. We express the distribution of the vector of student-specific latent variables through an affine transformation, such that:</p><p>Here L is the Cholesky factor of the correlation matrix Ω Ω Ω = LL ′ and S S S is the diagonal matrix of the standard deviation of the latent variables, S S S = diag(σ j ), j = 1, . . . , 4; note that Σ Σ Σ = S S SΩ Ω ΩS S S. The element of the four-dimensional vector γ γ γ i ∈ R 4 are i.i.d. following a standard normal distribution, γ i,1 , . . . , γ i,4 iid ∼ N(0, 1), i = 1, . . . , N. Notice that, as stated above, µ 1 = µ 2 = 0 for identifiability purposes. Under this inference procedure, each parameter and student-specific latent variables might be provided with a posterior point estimate, e.g., the posterior mean, and an interval estimate, e.g., a 95% quantile-based credible interval. The latter might be seen as an uncertainty measure of the estimated parameter; broader intervals suggest more uncertainty about the values of the parameters, whereas narrower intervals reflect less uncertainty about their values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Extension to Latent Growth Curve Model B.1 Model Specification</head><p>When sufficient assessments are given over time, evaluating students' growth during that period may be interesting. This can be done using Latent Growth Curve (LGC)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D An Extension to Ordinal Peer Grades</head><p>The models in this paper are for continuous grades, while grades in many peer grading systems are on an ordinal scale. In what follows, we discuss how the proposed model may be extended to ordinal grades. We consider a formulation based on the partial credit model <ref type="bibr" target="#b28">(Masters, 1982)</ref> under the same setting as our main model in Section 2.2 except for the grades being ordinal. More specifically, suppose that Y igt ∈ {1, . . . , K}.</p><p>For each k = 2, ..., K, we assume that</p><p>(D.1) where δ δ δ t = (δ t1 , . . . , δ t,K-1 ) ⊤ contains the item-specific parameters and the rest of the variables can be interpreted similarly as in Section 2.2. More specifically, θ it may be interpreted as student i's true score for assessment t. The larger the value of θ it , the more likely that Y igt takes a value in a higher category. The variable β g can still be interpreted as rater g's bias, as raters with a larger β g value tend to give a higher grade on average. In addition, φ g still indicates rater g's reliability. When φ g goes to infinity and the rest of the parameters remain fixed, the probability in (D.1) will converge to 0.5, and thus, the probability of Y igt = k will converge to 1/K, for each category k, regardless what the true score θ it is. In other words, the grade Y igt becomes a purely random guess. On the other hand, when φ g goes to zero, the distribution of Y igt will concentrate on one of the categories.</p><p>Similar to the model in Section 2.2, we can assume θ it to follow (2), and further set priors for the student-specific latent variables, as well as the rest of the model parameters. Bayesian inference can then be performed.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A systematic review of peer assessment design elements</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alqassab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-W</forename><surname>Strijbos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Panadero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Warrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>To</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hamiltonian Monte Carlo for hierarchical models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Girolami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Current trends in bayesian methodology with applications</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Upadhyay</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Singh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">A</forename><surname>Loganathan</surname></persName>
		</editor>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="79" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The role of coding time in estimating and interpreting growth curve models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Biesanz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Deeb-Sossa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Papadakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="30" to="52" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Latent curve models: A structural equation perspective</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Brennan</surname></persName>
		</author>
		<title level="m">Generalizability theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalizability theory and classical test theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Brennan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Measurement in Education</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bayesian irt guessing models for partial guessing behaviors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Stokes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="209" to="230" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hierarchical rater models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Casabianca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Junker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Patz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of item response theory</title>
		<imprint>
			<publisher>Chapman and Hall/CRC</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="477" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Twelve frequently asked questions about growth curve modeling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Obeidat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Losardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognition and Development: Official Journal of the Cognitive Development Society</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="121" to="136" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Random item irt models</title>
		<author>
			<persName><forename type="first">P</forename><surname>De Boeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="533" to="559" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A hierarchical rater model for constructed responses, with a signal detection rater model</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Decarlo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="356" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The impact of peer assessment on academic performance: a meta-analysis of control group studies</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Double</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Mcgrane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Hopfenbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology Review</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="481" to="509" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bayesian estimation of a multilevel irt model using gibbs sampling</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Glas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="271" to="288" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualization in bayesian workflow</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. A</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="389" to="402" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Peer assessment in moocs: systematic literature review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gamage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Staubitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Whiting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distance Education</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="515" to="534" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<title level="m">Bayesian data analysis</title>
		<imprint>
			<publisher>Chapman and Hall/CRC</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A dyadic IRT model</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Skrondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rabe-Hesketh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="815" to="836" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multilevel cross-classified models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="364" to="375" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Computing inter-rater reliability and its variance in the presence of high agreement</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Gwet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="48" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent trait modelling of rater accuracy in formative peer assessment of english-chinese consecutive interpreting</title>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Assessment and Evaluation in Higher Education</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="979" to="994" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The no-u-turn sampler</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1593" to="1623" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The social relations model</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>Voie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="141" to="182" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Polytomous item explanatory item response theory models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="726" to="755" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Generating random correlation matrices based on vines and extended onion method</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kurowicka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Joe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1989" to="2001" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Many-faceted rasch measurement</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Linacre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>The University of Chicago</publisher>
		</imprint>
	</monogr>
	<note>Unpublished doctoral dissertation</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A peer assessment method to provide feedback, consistent grading and reduce students&apos; burden in massive teaching settings</title>
		<author>
			<persName><forename type="first">O</forename><surname>Luaces</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Díez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bahamonde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="283" to="295" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Assessing inter-rater reliability with heterogeneous variance components models: flexible approach accounting for contextual variables</title>
		<author>
			<persName><forename type="first">P</forename><surname>Martinková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bartoš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brabec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="383" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A rasch model for partial credit scoring</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Masters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="149" to="174" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The hierarchical rater thresholds model for multiple raters and multiple items</title>
		<author>
			<persName><forename type="first">D</forename><surname>Molenaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Uluman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tavs ¸ancıl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>De Boeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Open Education Studies</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="33" to="48" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improving peer assessment with graph neural networks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Namanloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Salehi-Abari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th international conference on educational data mining</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Mitrovic</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Bosch</surname></persName>
		</editor>
		<meeting>the 15th international conference on educational data mining</meeting>
		<imprint>
			<publisher>International Educational Data Mining Society</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="325" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stochastic gradient Markov chain Monte Carlo</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nemeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fearnhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">533</biblScope>
			<biblScope unit="page" from="433" to="450" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Restricted maximum likelihood estimation for parameters of the social relations model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1098" to="1117" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tackling longitudinal round-robin data: a social relations growth model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Geukes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hutteman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Back</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1162" to="1181" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation of a social relations structural equation model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lüdtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robitzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="870" to="889" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Accounting for rater effects with the hierarchical rater model framework when scoring simple structured constructed response tests</title>
		<author>
			<persName><forename type="first">R</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Casabianca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="547" to="581" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An empirical review of anonymity effects in peer assessment, peer feedback, peer review, peer evaluation and peer grading</title>
		<author>
			<persName><forename type="first">E</forename><surname>Panadero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alqassab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Assessment &amp; Evaluation in Higher Education</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1253" to="1278" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A general framework for the parametrization of hierarchical models</title>
		<author>
			<persName><forename type="first">O</forename><surname>Papaspiliopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sköld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="73" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The nature of feedback: How peer feedback features affect students&apos; implementation rate and quality of revisions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Patchan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Schunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Correnti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1098</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The hierarchical rater model for rated test items and its application to large-scale educational assessment data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Patz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Junker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Mariano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="384" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Tuned models of peer assessment in MOOCs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Piech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th international conference on educational data mining</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>D'mello</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Calvo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">A</forename><surname>Olney</surname></persName>
		</editor>
		<meeting>the 6th international conference on educational data mining</meeting>
		<imprint>
			<publisher>International Educational Data Mining Society</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Efficient analysis of mixed hierarchical and crossclassified random structures using a multilevel model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rasbash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="337" to="350" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A crossed random effects model for unbalanced data with applications in cross-sectional and longitudinal research</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Raudenbush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Statistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="349" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Two peers are better than one: Aggregating peer reviews for computing assignments is surprisingly accurate</title>
		<author>
			<persName><forename type="first">K</forename><surname>Reily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Finnerty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Terveen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 acm international conference on supporting group work</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Teasley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Havn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Prinz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">W</forename><surname>Lutters</surname></persName>
		</editor>
		<meeting>the 2009 acm international conference on supporting group work<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Peer grading in a course on algorithms and data structures: machine learning algorithms do not improve over simple baselines</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S M</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alamgir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third ACM Conference on Learning at Scale</title>
		<meeting>the Third ACM Conference on Learning at Scale</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="369" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Estimation of latent ability using a response pattern of graded scores</title>
		<author>
			<persName><forename type="first">F</forename><surname>Samejima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">Suppl 1</biblScope>
			<biblScope unit="page" from="1" to="97" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Selfgrading and peer-grading for formative and summative assessments in 3rd through 12th grade classrooms: A meta-analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Sanchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Koenka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moshontz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1049" to="1066" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">RStan: the R interface to Stan</title>
		<author>
			<orgName type="collaboration">Stan Development Team.</orgName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>R package version 2.32</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A multidimensional generalized many-facet rasch model for rubric-based performance assessment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Uto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behaviormetrika</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="469" to="496" />
			<date type="published" when="2021-07">2021, 07</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A generalized many-facet rasch model and its bayesian estimation using hamiltonian monte carlo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Uto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ueno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behaviormetrika</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Practical bayesian model evaluation using leave-one-out cross-validation and waic</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1413" to="1432" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Item response models for local dependence among multiple ratings</title>
		<author>
			<persName><forename type="first">W.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-M</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">&amp; X.-L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="260" to="280" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A new round robin analysis of variance for social interaction data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Warner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">1742</biblScope>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Descriptive and explanatory item response models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>De Boeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Explanatory item response models: A generalized linear and nonlinear approach</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="43" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The rater bundle model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoskens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="283" to="306" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Detecting problem statements in peer assessments</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zingle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Gehringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th international conference on educational data mining</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Rafferty</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Whitehill</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Romero</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Cavalli-Sforza</surname></persName>
		</editor>
		<meeting>the 13th international conference on educational data mining</meeting>
		<imprint>
			<publisher>International Educational Data Mining Society</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="704" to="709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Leveraging cognitive diagnosis to improve peer assessment in moocs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="50466" to="50484" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Assessment as learning: how does peer assessment function in students&apos; learning?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">912568</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">What aspects of online peer feedback robustly predict growth in students&apos; task performance?</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Schunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computers in Human Behavior</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">106924</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
