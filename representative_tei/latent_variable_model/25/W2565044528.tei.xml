<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Connection Discovery using Shared Images by Gaussian Relational Topic Model</title>
				<funder>
					<orgName type="full">HKUST-NIE Social Media Lab., HKUST</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2016-12-12">12 Dec 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaopeng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Social Media Lab</orgName>
								<orgName type="institution" key="instit1">HKUST-NIE</orgName>
								<orgName type="institution" key="instit2">Hong Kong University of Science &amp; Technology</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ming</forename><surname>Cheung</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Social Media Lab</orgName>
								<orgName type="institution" key="instit1">HKUST-NIE</orgName>
								<orgName type="institution" key="instit2">Hong Kong University of Science &amp; Technology</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>She</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Social Media Lab</orgName>
								<orgName type="institution" key="instit1">HKUST-NIE</orgName>
								<orgName type="institution" key="instit2">Hong Kong University of Science &amp; Technology</orgName>
								<address>
									<country key="HK">Hong Kong</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Connection Discovery using Shared Images by Gaussian Relational Topic Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-12-12">12 Dec 2016</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1612.03639v1[cs.SI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian</term>
					<term>topic model</term>
					<term>variational inference</term>
					<term>user shared images</term>
					<term>connection</term>
					<term>discovery</term>
					<term>recommendation</term>
					<term>social network analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social graphs, representing online friendships among users, are one of the fundamental types of data for many applications, such as recommendation, virality prediction and marketing in social media. However, this data may be unavailable due to the privacy concerns of users, or kept private by social network operators, which makes such applications difficult. Inferring users' interests and discovering users' connections through their shared multimedia content has attracted more and more attention in recent years. This paper proposes a Gaussian relational topic model for connection discovery using user shared images in social media. The proposed model not only models users' interests as latent variables through their shared images, but also considers the connections between users as a result of their shared images. It explicitly relates user shared images to user connections in a hierarchical, systematic and supervisory way and provides an end-to-end solution for the problem. This paper also derives efficient variational inference and learning algorithms for the posterior of the latent variables and model parameters. It is demonstrated through experiments with over 200k images from Flickr that the proposed method significantly outperforms the methods in previous works.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Social graphs (SGs), representing online friendships among users, are fundamental data for many applications, such as recommendation, virality prediction and marketing in social media. However, this data may be unavailable due to the privacy concerns of users, or kept private by social network operators, and these applications become challenging with an incomplete set of data. Providing a potential solution to this problem, user connections are also reflected in the abundant social content, especially images, shared on social networks. Inferring users' interests and discovering users' connections through their shared multimedia content has attracted more and more attention in recent years. A common but unreliable approach is using user annotated tags (or user tagging) associated with each shared image to discover user connections when the SG is not accessible. However, user annotated tags may be unavailable or images may be incorrectly labeled, as shown in Fig. <ref type="figure" target="#fig_0">1</ref>. Instead of indirectly taking the image content information through tags, a more direct method is to consider the image's visual content. Users with connections of follower/followee relationships are found to have relatively higher visual content similarities among their shared images. An simplistic example of user generated images on Flickr is shown in Fig. <ref type="figure" target="#fig_0">1</ref>: Both users A and B share images of cars and user C shares an image of a flower. The follower/followee relationship between users A and B can possibly be detected from the higher similarity of visual features in their shared images. When more shared images from each of users A, B and C are accessible for evaluation, the actual follower/followee relationships should become reliably and accurately detectable, though such a task is becoming challenging with the number of shared images and user connections in social networks growing larger every day. The effectiveness of connection discovery using user shared images is mainly determined by two elements: effective extraction of information from images and an effective method to connect the image content to user connections. On the one hand, with the recent development of convolutional neural network (CNN), the analysis and understanding of image content has become much more effective <ref type="bibr" target="#b0">[1]</ref> through hierarchical representation, closing the semantic gap between pixels and content. It is therefore possible to extract rich image content information through CNN. On the other hand, how to effectively discover user connections using the image content remains a challenge. Summarizing the methods or frameworks proposed in previous works such as <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b4">[5]</ref>, the process is generally divided into two stages: first, construction of user profile by counting the occurrences of image labels or summing the image feature vectors, and second, prediction of connections between users based on the constructed user profile. The limitation of these methods is two-fold. First, aggregating all items in a simple way for each user might not be solid enough to capture users' interests. An analogy can be found in text analytics, where the bag-of-words model is compared with topic models, especially latent Dirichlet allocation (LDA) <ref type="bibr" target="#b5">[6]</ref>. Second, user profiling through images is completely separated from connection discovery. Separating the two potentially results in untight relatedness of image content and social links, meaning that the observation of partial social links lends no help toward connection discovery using image content.</p><p>In this paper, a Gaussian relational topic model (GRTM) is proposed for connection discovery using user shared images in order to overcome the abovementioned limitations. GRTM is an end-to-end hierarchical model specifically designed to not only model users' interests through image content but also to supervise the modeling in such a way that the content of shared images is statistically connected to the links between users, inspired by hierarchical relational model in text document domain <ref type="bibr" target="#b6">[7]</ref>. GRTM effectively extracts rich image content information through CNN and models each semantic topic as a Gaussian topic. GRTM also models each user's interests as a latent factor and assumes that the action of the user sharing an image is probabilistically motivated by his or her interests. Furthermore, the links between users are modeled based on the images each user shares. Combining these in a coherent probabilistic generative process, the proposed GRTM provides a systematic way to close the gap between the actions of users sharing images and users connecting to each other. The main contributions of this paper are the following:</p><p>• proposes an end-to-end Gaussian relational topic model for connection discovery using user shared images, closely relating user shared image content to user connections. • derives efficient variational inference for the proposed model to approximate the posterior of latent variables and learn model parameters.</p><p>• evaluates the performance of the proposed model with real data and proves the significantly better performance of the proposed method.</p><p>The rest of the paper is organized as follows. Section II discusses previous works. Section III introduces the GRTM for connection discovery using shared images. Section IV describes in detail the inference of latent variables and model parameters, as well as the prediction method. Section V presents experimental results and discussion, and Section VII concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>One content-based approach to discover connections through images is to generate a label for an image based on its visual elements <ref type="bibr">[8][9]</ref>. However, determining the relationship between the visual elements and the label is not a trivial task because the same object can be visually different among images, and denoting each image by a single label loses a lot of information. <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b9">[10]</ref> propose to first generate labels for user shared images by clustering and describe users' characteristics by counting the occurrences of image clusters appearing in their collections. The prediction is then made through analyzing the similarities among the users' histograms. Both methods assume each image contains one and only one topic, neglecting potentially rich information. On the other hand, <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b3">[4]</ref> represent users' interests by summing the feature vectors of their images, achieving a similar effect to the other methods. However, all these methods do not actually connect shared images to the links between users, or only connect shared images to links, and not the other way around.</p><p>Relational topic model was first proposed in <ref type="bibr" target="#b6">[7]</ref> for document networks in the text analytics domain. It is an extension of the latent Dirichlet model (LDA) <ref type="bibr" target="#b5">[6]</ref> and supervised LDA <ref type="bibr" target="#b10">[11]</ref>. This family of approaches model each document as topic proportions, and each word in the document is drawn from a set of topics, which are distributions over a fixed vocabulary. Furthermore, the relational topic model models the links between documents as a binary random variable that is conditioned on their contents. More recent papers, <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b12">[13]</ref>, share a similar methodology with this paper, also proposing a hierarchical topic model to process user images and infer users' interest as latent factors from Bayesian inference. However, <ref type="bibr" target="#b11">[12]</ref> starts with lowlevel pixels and describes image regions with visual words, while <ref type="bibr" target="#b12">[13]</ref> models the visual descriptor as drawn from a vocabulary, just like in the text domain. Also, <ref type="bibr" target="#b11">[12]</ref> considers no social information and hence, as with other works, does not relate image content to user relationships for connection discovery, and <ref type="bibr" target="#b12">[13]</ref> considers the social influence of existing links to the users rather than predicting new ones. Our work extracts rich information of image content through CNN and models users' interests and users' connections simutaneously. As an end-to-end model, ours closely relates users' connections to user shared images, with the goal being connection discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED MODEL FOR CONNECTION DISCOVERY USING SHARED IMAGES</head><p>This section introduces the problem of connection discovery using shared images and the proposed Gaussian relational topic model. Given a social network, there are N users, {u 1 , u 2 , . . . , u N }. Each of the users, u, shares a collection of images, I u = {x u,1 , x u,2 , . . . , x u,Nu }, where N u is the number of images the user u shares and x u,n is the nth image shared by the user u. The connections between users are not available due to privacy concerns or proprietary information protection. However, the connections can still be discovered through the images shared by the users. The objective is to predict the possible connections between users based on the user shared images. The proposed GRTM model, is based on Gaussian mixture model and relational topic model, as shown in Fig. <ref type="figure" target="#fig_1">2</ref>. It is a generative probabilistic model in which a user is described by a topic distribution that is reflected through his or her collection of shared images. It models that the action of a user sharing an image follows a generative process: a user's preferences or the topic proportion in his or her collections is generated through a Dirichlet-distributed vector, and he shares an image by first drawing a topic assignment from his or her preferences then drawing an image from the corresponding topic distribution. Unlike LDA and relational topic model, where text documents are the context and words are generated from a vocabulary, this paper extracts rich information from images through a pre-trained CNN and Gaussian topic is adopted in order to consider and preserve the rich information of the images, as shown in Fig. <ref type="figure" target="#fig_4">3</ref>. The links between users are then modeled as binary variables and are determined by the users' preferences. In this way, the user shared images and the links between users are statistically connected.</p><formula xml:id="formula_0">z u,n θ u x u,n N u z v,n θ v x v,n N v K y u,v !, # $ % , Σ % ' x u,n x v,n y u,v</formula><p>Formally, the generative process of the proposed GRTM is as follows:</p><p>1) For each user u:   2) For each pair of users u, v:</p><formula xml:id="formula_1">a) Draw binary link indicator between users y|z u , z v ∼ ψ(•|z u , z v ).</formula><p>Fig. <ref type="figure" target="#fig_1">2</ref> illustrates the graphical model for the generative process. Assuming there are a total of K topics, generating an image is done by first picking the topic it belongs to. The apparent choice of distribution for picking the topic assignment z u,n from K possible values is multinomial distribution, parameterized by the k-dimensional user preference θ u . The conjugate prior for multinomial distribution is Dirichlet distribution. Therefore, the user preference θ u is assumed to be drawn from Dirichlet distribution, parameterized by α.</p><p>Under each topic, an image is assumed to be drawn from a multivariate Gaussian distribution, parameterized by mean µ and covariance Σ:</p><formula xml:id="formula_2">p(x u,n |z u,n , {µ, Σ} 1:K ) = K k=1 N (x u,n |µ k , Σ k ) 1(zu,n=k) . (1)</formula><p>where 1(•) is an indicator function. Therefore, given the parameters α and topic distribution {µ, Σ} 1:K , the generative probability of a user shared image is given by</p><formula xml:id="formula_3">p(x u,n ,z u,n , θ u |α, {µ, Σ} 1:K ) = p(θ u |α)p(z u,n |θ u )p(x u,n |z u,n , {µ, Σ} 1:K ).<label>(2)</label></formula><p>Given two users and the topic assignments of all their images, the link between the two users is determined by the link probability function ψ. Specifically, the exponential function is adopted due to the linear form of the log likelihood <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_4">ψ(y = 1|z u , z v ) = exp(η T ( zu • zv ) + ν),<label>(3)</label></formula><p>where zu = 1</p><p>Nu n z u,n , η and ν are parameters, and the notation • denotes the element-wise product.</p><p>The overall joint likelihood of the observation, i.e., the user shared images and links between users, and the latent variables, i.e., the user preference and topic assignment, is determined by p(U, y, θ, z|α, {µ, Σ}</p><formula xml:id="formula_5">1:K ) = u p(θ u |α) n p(z u,n |θ u )p(x u,n |z u,n , {µ, Σ} 1:K ) (u,v) p(y|z u , z v ).<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. INFERENCE, ESTIMATION AND PREDICTION</head><p>In this section, the Bayesian variational inference for the proposed GRTM is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Inference</head><p>The posterior distribution of the latent variables and parameters given the observations and topic parameters is inferred by: p(θ, z, η, ν|U, y, α, {µ, Σ} 1:K ) = p(U, y, θ, z|α, {µ, Σ} 1:K ) zu,n p(U, y, θ, z|α, {µ, Σ} 1:K )dθ</p><formula xml:id="formula_6">. (<label>5</label></formula><formula xml:id="formula_7">)</formula><p>The exact posterior, however, is intractable since the denomenator involves a complex summation and integral. Instead, like previous works, variational inference with free parameters is used to approximate the exact posterior. Specifically, the mean field approximation with the form</p><formula xml:id="formula_8">q(θ, z|γ, φ) = u q u (θ u |γ u ) n q z (z u,n |φ u,n )<label>(6)</label></formula><p>is used to approximate the posterior p of θ and z. And the goal is to minimize the Kullback-Leibler (KL) divergence between the approximation and the exact posterior. Equivalently, we try to maximize the variational free energy, which is the evidence lower bound of the log marginal probability of the observations:</p><formula xml:id="formula_9">L = u n E q [log p(x u,n |z u,n , {µ, Σ} 1:K )] + u n E q [log p(z u,n |θ u )] + u E q [log p(θ u |α)] - u E q [log q θ (θ u |γ u )] - u n E q [log q z (z u,n |φ u,n )] + (u,v) E q [log p(y u,v |z u,v , η, ν)].<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Estimation</head><p>Having the evidence lower bound of the log likelihood, the maximization of the lower bound can be achieved through coordinate ascent, where each variable is iteratively updated assuming all others are fixed, until convergence. By taking the derivative of the evidence lower bound in Eq. 7, subject to the sum-to-one constraint, the update of the free parameter φ is</p><formula xml:id="formula_10">φ u,n,k ∝ exp(log N (x u,n |µ k , Σ k ) + Ψ(γ i ) -Ψ( K j=1 γ j ) + v|yu,v=1 η • φv N u ),<label>(8)</label></formula><p>where</p><formula xml:id="formula_11">φv = E q [z v ] = 1 Nv n φ v,n .</formula><p>And the normalization term is the sum over all K.</p><p>With a similar method, the update of the free parameter γ is</p><formula xml:id="formula_12">γ u,k = α k + Nu n=1 φ u,n,k .<label>(9)</label></formula><p>Isolating the terms involving {µ, Σ} 1:K in the lower bound and taking the derivative, the update of the topic parameters {µ, Σ} 1:K is</p><formula xml:id="formula_13">µ k = u n φ u,n,k x u,n u n φ u,n,k ,<label>(10)</label></formula><formula xml:id="formula_14">Σ k = u n φ u,n,k (x u,n -µ k )(x u,n -µ k ) T u n φ u,n,k .<label>(11)</label></formula><p>It would be inappropriate to regard all links except observed positive links as negative training examples since there might be positive but unobserved links between users, which is expected to predict. Therefore, following <ref type="bibr" target="#b6">[7]</ref>, we use a regularization penalty parameterized by ρ for the negative observations. And the updates of the link function are conducted analytically by</p><formula xml:id="formula_15">ν ← log(M -1 T Π) -log(ρ(1 - 1 K ) + M -1 T Π),<label>(12)</label></formula><formula xml:id="formula_16">η ← log( Π) -log( Π + ρ K 2 1 -1ν),<label>(13)</label></formula><p>where</p><formula xml:id="formula_17">M = u,v 1(y u,v = 1), Π = u,v πu,v 1(y u,v = 1)</formula><formula xml:id="formula_18">and πu,v = 1 Nu n φ u,n • 1 Nv n φ v,n .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Prediction</head><p>With all the variational parameters estimated, the link between two users given their shared collection of images can be predicted. The variational Bayesian prediction is given by:</p><formula xml:id="formula_19">p(y u,v |x u , x v ) = E q [p(y u,v |z u , zv )].<label>(14)</label></formula><p>However, it still involves complicated summations over all possible z for all the images considered. Instead, we perform plug-in approximation and substitute all z with its variational expectation. Hence, the predictive probability is approximated with</p><formula xml:id="formula_20">p(y u,v |x u , x v ) = exp(η T πu,v + ν),<label>(15)</label></formula><p>where</p><formula xml:id="formula_21">πu,v = 1 Nu n φ u,n • 1 Nv n φ v,n .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head><p>In this section, experiments are conducted to investigate the effectiveness of the proposed GRTM for connection discovery using user shared images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset and Experimental Setup</head><p>A set of 201,006 images uploaded by 542 users are scraped from Flickr, an online social network for image sharing, with millions of images uploaded. The 542 users are selected randomly from images under the same tag query page to provide diversity. The average number of shared images for each user is 370, covering diverse content, and there are 902 connections among the 542 users. The images are processed by GoogLeNet <ref type="bibr" target="#b13">[14]</ref>, pretrained using the ILSVRC 2014 dataset, for image representation, so that rich semantic information can be extracted. The links between users are divided into two parts: 60% of the links are used for training and 40% of the links are used for testing. Using the user shared images and training links, the latent variables and model parameters of the GRTM are estimated through an iterative process, as described in the previous section. Using Eq. 15, the testing process is then undertaken to predict the probability of the links existing between users , excluding the observed training links, and the results are then compared with the groundtruth of the testing links. The Dirichlet hyperparameter α is set to 2.0, and the number of topics is set to be 100 in our experiment. Though the number of topics has some influence to some extent, the overall performance does not vary much.</p><p>As a comparison with previous works on similar applications, the Mean method from <ref type="bibr" target="#b3">[4]</ref> where users' profiles are constructed through their shared images by taking the mean features of all the images, and the BoFT method <ref type="bibr" target="#b1">[2]</ref> where users' profiles are obtained by counting the occurrences of cluster labels in users' collections obtained through image clustering, are implemented. The prediction of user connections is thus conducted through computing the similarity between users. And instead of using the scale invariant feature transform (SIFT) for image feature extraction, CNN (GoogLeNet) features are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results</head><p>The prediction performance of the Mean method, BoFT method and proposed GRTM is shown in Fig. <ref type="figure" target="#fig_5">4</ref>, where both the receiver operating characteristic (ROC) curve and precision-recall curve are plotted. The ROC curve is the function of true positive rate (TPR) and false positive rate (FPR) and is used to measure how well the model can distinguish whether two users are friends or not. As it is shown, the ROC curve of the GRTM clearly dominates the other two methods. For example, for the point in the ROC curve with TPR of 0.8, given a pair of users with a true friendship, GRTM has 80% probability of predicting it correctly, while given a pair of users without a friendship,  it has 20% probability of predicting it incorrectly. For the same TPR, however, the BoFT method has 35% probability of incorrect prediction for users without a friendship, and Mean method has 45%. Overall, the area under curve (AUC) for ROC curve of the proposed GRTM is 0.89, while that of the BoFT method is 0.84 and that of Mean method is 0.78. As an alternative measure, the precision-recall curve, as shown in Fig. <ref type="figure" target="#fig_6">5</ref>, is the function of the precision rate and recall rate. It measures what fraction of the recommended candidates are the user's true friends and what fraction of true friends are recommended. As with the ROC curve, the precision-recall curve of the proposed GRTM also dominates the others. For example, for the same recall rate of 10%, the precision rate of the GRTM is 18%, while that of the BoFT method is 11% and that of the Mean method is 5.9%. Overall, the precision-recall AUC of the proposed GRTM is 0.05, while that of the BoFT method is 0.039 and that of the Mean method is 0.021.</p><p>In order to illustrate how the proposed GRTM interprets the user shared images, some example images are shown  in Fig. <ref type="figure" target="#fig_8">6</ref>. Since each Gaussian topic is defined by µ k and Σ k and each image has a probability under the Gaussian topic, images that achieve the highest probabilities under that topic are selected as representatives. As shown in Fig. <ref type="figure" target="#fig_8">6</ref>, the semantic meaning of the Gaussian topics, such as cars, flowers, buildings, race cars and surfing, can be readily distinguished. The Gaussian topics cover a variety of objects, scenes, sports, etc. Those images that contain more than one topic could also be revealed through the probabilities under different Gaussian topics. It is also noted that ordinary cars and race cars are separated as different topics, which is also beneficial to reflect users' preferences for subsequent connection discovery. Fig. <ref type="figure" target="#fig_8">6</ref> shows examples of the friendship prediction results obtained by the three methods. The example user, A, shares a lot of car images. For recommendation purposes, all three methods are directed to recommend 10 friends. As shown in the figure, out of the 10 recommendations, the proposed GRTM successfully predicts 5 of them, whereas the BoFT only successfully predicts 2 and the Mean method successfully predicts 1. Furthmore, the successful predictions of the other two methods are in fact a subset of those of the proposed GRTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>This paper proposes a Gaussian relational topic model (GRTM) for connection discovery using user shared images in social media. The GRTM not only models users' interests as latent variables through user shared image content but also models the connections between users as a result of their shared images. It explicitly relates user shared images to the connections between users in a hierarchical, systematic and supervisory way and provides an end-to-end model for connection discovery using shared images. It is demonstrated by experiment that the proposed model significantly outperforms the methods in previous works where the modeling of users' interests and connection discovery are separated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of user shared images, image tags, user interest reflected and user connections.</figDesc><graphic coords="1,368.62,178.44,71.94,128.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The proposed Gaussian Relational Topic Model (GRTM) (shaded nodes are observed.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>a) Draw topic proportions θ u |α ∼ Dir(α). b) For each image x u,n : i) Draw topic assignment z u,n |θ u ∼ M ult(θ u ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: CNN feature extraction for images and Gaussian topic</figDesc><graphic coords="3,371.04,94.84,108.15,52.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: ROC curve for Mean method<ref type="bibr" target="#b3">[4]</ref>, BoFT method<ref type="bibr" target="#b1">[2]</ref> and proposed GRTM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Precision-Recall curve for Mean method [4], BoFT method [2] and proposed GRTM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Left: examples of Gaussian topics; Right: examples of friendship prediction by Mean method, BoFT method and the proposed GRTM.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENT</head><p>This work is supported by the <rs type="funder">HKUST-NIE Social Media Lab., HKUST</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Connection discovery using big data of user-shared images in social media</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1417" to="1428" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Multimedia</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond classification: Latent user interests profiling from visual contents analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-K</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining Workshop</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1410" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling social strength in social media community via kernel-based learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Multimedia</title>
		<meeting>the 19th International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">One of a kind: User profiling by social curation</title>
		<author>
			<persName><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="567" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Relational topic models for document networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIStats</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="81" to="88" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Not all tags are created equal: Learning flickr tag semantics for global annotation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Moxley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Manjunath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia and Expo, International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1452" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Social image tagging using graph-based reinforcement on multi-type interrelated objects</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2178" to="2189" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Non-user generated annotation on user shared images for connection discovery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cyber, Physical and Social Computing, the 8th IEEE Conference</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Supervised topic models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mining user interests from personal photos</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1896" to="1902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Right buddy makes the difference: An early exploration of social relation analysis in multimedia applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM International Conference on Multimedia</title>
		<meeting>the 20th ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
