<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-Supervised Variational Reasoning for Medical Dialogue Generation</title>
				<funder ref="#_fhvu7Dr">
					<orgName type="full">National Key R&amp;D Program of China</orgName>
				</funder>
				<funder ref="#_e3CfuY8">
					<orgName type="full">Shandong University</orgName>
				</funder>
				<funder>
					<orgName type="full">Dutch Ministry of Education, Culture and Science through the Netherlands Organisation for Scientific Research</orgName>
				</funder>
				<funder ref="#_6WRq5zM #_H9H262q #_3Zh8BvD">
					<orgName type="full">Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_6yNfwfy">
					<orgName type="full">Key Scientific and Technological Innovation Program of Shandong Province</orgName>
				</funder>
				<funder ref="#_HfFXXQY">
					<orgName type="full">Tencent WeChat Rhino-Bird Focused Research Program</orgName>
				</funder>
				<funder>
					<orgName type="full">Hybrid Intelligence Center</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-05-13">13 May 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dongdong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University</orgName>
								<address>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
							<email>zhaochun.ren@sdu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University</orgName>
								<address>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
							<email>chenzhumin@sdu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University</orgName>
								<address>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Miao</forename><surname>Fan</surname></persName>
							<email>fanmiao@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University</orgName>
								<address>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Baidu Inc</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jun</forename><surname>Ma</surname></persName>
							<email>majun@sdu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shandong University</orgName>
								<address>
									<settlement>Qingdao</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
							<email>m.derijke@uva.nl</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Ahold Delhaize</orgName>
								<address>
									<settlement>Zaandam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-Supervised Variational Reasoning for Medical Dialogue Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-05-13">13 May 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3404835.3462921</idno>
					<idno type="arXiv">arXiv:2105.06071v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical dialogue systems</term>
					<term>Task-oriented dialogue generation</term>
					<term>Variational inference</term>
					<term>Semi-supervised learning In addition to fever, do you have other symptoms like fatigue, night sweats, dry cough? å››ç§è¯ç»„åˆåƒï¼Œå¼‚çƒŸè‚¼, åˆ©ç¦å¹³,å¡å—ªé…°èƒº,â¼„èƒºä¸é†‡ã€‚ The combination of four drugs, Isoniazid, Rifampicin, Pyrazinamide, and Ethambutol å‘çƒ§, ..., å’³å—½ï¼Œ...ï¼Œè‚ºç»“ æ ¸ (fever, ..., cough, ..., å¼‚çƒŸè‚¼, åˆ©ç¦å¹³,å¡å—ªé…° èƒº,â¼„èƒºä¸é†‡ (Isoniazid, Rifampicin, Pyrazinamide, Ethambutol) å‘çƒ§ï¼Œâ»æ¬²ä¸æŒ¯ï¼Œå’³å—½ ç–²åŠ³ï¼Œå¤œæ±—ï¼Œâ¼²å’³ (fatigue, night sweats, dry cough)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Medical dialogue generation aims to provide automatic and accurate responses to assist physicians to obtain diagnosis and treatment suggestions in an efficient manner. In medical dialogues two key characteristics are relevant for response generation: patient states (such as symptoms, medication) and physician actions (such as diagnosis, treatments). In medical scenarios large-scale human annotations are usually not available, due to the high costs and privacy requirements. Hence, current approaches to medical dialogue generation typically do not explicitly account for patient states and physician actions, and focus on implicit representation instead.</p><p>We propose an end-to-end variational reasoning approach to medical dialogue generation. To be able to deal with a limited amount of labeled data, we introduce both patient state and physician action as latent variables with categorical priors for explicit patient state tracking and physician policy learning, respectively. We propose a variational Bayesian generative approach to approximate posterior distributions over patient states and physician actions. We use an efficient stochastic gradient variational Bayes estimator to optimize the derived evidence lower bound, where a 2stage collapsed inference method is proposed to reduce the bias during model training. A physician policy network composed of an action-classifier and two reasoning detectors is proposed for augmented reasoning ability. We conduct experiments on three datasets collected from medical platforms. Our experimental results show that the proposed method outperforms state-of-the-art baselines in terms of objective and subjective evaluation metrics. Our experiments also indicate that our proposed semi-supervised reasoning method achieves a comparable performance as state-of-the-art fully supervised learning baselines for physician policy learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Increasingly, conversational paradigms are being used to connect people to information, both to address open domain information needs [e.g., <ref type="bibr">14, 17, 23-25, 43, 50]</ref> and in support of professionals in highly specialized vertical domains [e.g., <ref type="bibr" target="#b49">48,</ref><ref type="bibr" target="#b63">62]</ref>. Our focus is on conversational information seeking approaches in the medical domain. During clinical treatment, a conversational medical system can serve as a physician's assistant to help generate responses for a patient's need, i.e, inquire about symptoms, make a diagnosis, and prescribe medicine or treatment <ref type="bibr" target="#b55">[54,</ref><ref type="bibr" target="#b58">57,</ref><ref type="bibr" target="#b60">59]</ref>. Intelligent medical dialogue systems (MDSs) are able to reduce the work pressure of physicians <ref type="bibr" target="#b47">[46]</ref>. Previous work on MDSs mostly focuses on producing an accurate diagnosis given the dialogue context <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b55">54,</ref><ref type="bibr" target="#b58">57,</ref><ref type="bibr" target="#b60">59]</ref>. There is very little work that considers the task of multi-turn medical dialogue generation to provide proper medical responses by tapping into large-scale medical knowledge sources.</p><p>There are two key characteristics that are specific to clinical decision support (CDS), and hence for dialogue systems that are meant to support clinical decision making: patient states (e.g., symptoms, medicine, etc.) and physician actions (e.g., treatments, diagnosis, etc.). These two characteristics make MDSs more complicated than other knowledge-intensive dialogue scenarios. Similar to taskoriented dialogue systems (TDSs), a medical dialogue generation (MDG) process can be decomposed into 3 stages: (1) patient state tracking (PST): after encoding the patient's descriptions, the MDS tracks the patient's physiological condition, i.e., patient states, in the discourse context; (2) physician policy learning (PPL): given the patient's states and utterances, the MDS generates the physician's action to embed into the response; and (3) medical response generation (MRG): the MDS responds with a coherent sentence based on detected states and actions. Figure <ref type="figure" target="#fig_0">1</ref> shows an example medical dialogue from the infection department. The left part lists the conversation, whereas the right part indicates patient states and physician actions during the conversation. At the first turn the patient shares their symptoms, i.e., fever, loss of appetite, and cough, as the patient state; the physician asks if the patient has other symptoms, i.e., fatigue, night sweats, and dry cough, to reflect the physician action at the second turn. Both states and actions vary as the conversation develops. At the last turn, the physician's action is to prescribe drugs: Isoniazid, Rifampicin, Pyrazinamide, and Ethambutol.</p><p>The development of end-to-end MDG solutions faces a number of challenges: (1) Most TDSs need a large amount of manually labeled data to predict explicit dialogue states. In medical dialogues, annotators need medical expertise to annotate data. For privacy reasons, large-scale manually labeling intermediate states is problematic. Hence, few TDS methods can directly be applied to MRG <ref type="bibr" target="#b56">[55]</ref>.</p><p>(2) Existing approaches to MDG have a limited semantic understanding of the domain, which makes it hard to generate knowledgeable responses in a medical context <ref type="bibr" target="#b37">[36]</ref>. <ref type="bibr" target="#b4">(3)</ref> To help patients or physicians understand why a MDG system generates a response, explainability with indicative and interpretable information is indispensable, which is ignored by most TDS studies.</p><p>To address these challenges, we propose VRBot, which performs variational reasoning for MRG. Inspired by approaches to TDS, VR-Bot contains a patient state tracker and a physician policy network to detect patient states and physician actions, respectively. Unlike previous work, which learns from massive amounts of human-labeled observed variables, VRBot considers the patient state and the physician action as dual latent variables inferred in a variational Bayesian manner. We employ a stochastic gradient variational Bayes (SGVB) estimator to efficiently approximate the posterior inference. To alleviate the bias problem during SGVB estimation, we propose a 2stage collapsed inference method to iteratively approximate the posterior distribution over states and actions.</p><p>To address the problem of limited semantic understanding during response generation, we proceed as follows. The physician policy network comprises an action-classifier that classifies physician actions into action categories, and two reasoning components, a context reasoning detector and a graph reasoning detector, that infer explicit action keywords through the dialogue context and medical knowledge graph, respectively. With explicit sequences of patient states, physician actions, and multi-hop reasoning, VRBot is able to provide a high degree of explainability of its medical dialogue generation results.</p><p>To assess the effectiveness of VRBot, we collect a knowledgeaware medical dialogue dataset, KaMed. KaMed contains over 60,000 medical dialogue sessions with 5,682 entities (such as Asthma and Atropine). Using KaMed and two other MDG benchmark datasets, we find that VRBot, using limited amounts of labeled data, outperforms state-of-the-art baselines for MDG. Hence, given largescale unlabeled medical corpora, VRBot can accurately trace the patient's physiological conditions and provide more informative and engaging responses by predicting appropriate treatments and diagnosis. We also find that VRBot is able to provide more explainable response generation process over other MDG baselines.</p><p>Our contributions are as follows: <ref type="bibr" target="#b2">(1)</ref> We propose an end-to-end medical response generation model, named VRBot. To the best of our knowledge, VRBot is the first to simultaneously model states and actions as latent variables in TDSs. <ref type="bibr" target="#b3">(2)</ref> We devise a hybrid policy network that contains a context-reasoning detector and a graph-reasoning detector, which allow VRBot to predict physician actions based on the dialogue session and external knowledge simultaneously. (3) We show that VRBot can explicitly track patient states and physician actions even with few or no human-annotated labels. (4) We release KaMed, a large-scale medical dialogue dataset with external knowledge. ( <ref type="formula" target="#formula_5">5</ref>) Experiments on benchmark datasets show that VRBot is able to generate more informative, accurate, and explainable responses than state-of-the-art baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Medical dialogue systems. Previous methods for MDSs are modeled after TDSs, following the paradigm that a patient expresses their symptoms. Wei et al. <ref type="bibr" target="#b55">[54]</ref> propose to learn a dialogue policy for automated diagnosis based on reinforcement learning. Lin et al. <ref type="bibr" target="#b33">[32]</ref> build a symptom graph to model associations between symptoms to boost the performance of symptom diagnosis. Xu et al. <ref type="bibr" target="#b60">[59]</ref> consider the co-occurrence probability of symptoms with diseases explicitly with reinforcement learning. Xia et al. <ref type="bibr" target="#b58">[57]</ref> improve upon this work using mutual information rewards and generative adversarial networks. Meanwhile, various approaches have been explored to improve the understanding of medical dialogue histories, including symptom extraction <ref type="bibr" target="#b9">[8]</ref>, medical slot-filling <ref type="bibr" target="#b47">[46]</ref>, and medical information extraction <ref type="bibr" target="#b65">[64]</ref>. Chen et al. <ref type="bibr" target="#b6">[5]</ref> investigate the performance of pre-trained models for predicting response entities. Chen et al. <ref type="bibr" target="#b6">[5]</ref> collect a dataset that consists of millions of dialogue sessions but do not explicitly consider learning the dialogue management as there are no human-annotated labels.</p><p>Currently, no prior work is able to explicitly learn a dialogue policy from a large-scale unlabeled corpus, greatly limiting the application of medical dialogue systems.</p><p>Dialogue state tracking. Dialogue state tracking plays an important role for TDSs. Conditional random field-based approaches <ref type="bibr" target="#b22">[21,</ref><ref type="bibr" target="#b23">22]</ref> and deep neural network-based approaches <ref type="bibr" target="#b13">[12,</ref><ref type="bibr" target="#b42">41]</ref> have been proposed to track states in modular TDSs <ref type="bibr" target="#b4">[3]</ref>. Recently, end-to-end TDSs have attracted a lot of interest <ref type="bibr" target="#b14">[13,</ref><ref type="bibr" target="#b18">17,</ref><ref type="bibr" target="#b25">24,</ref><ref type="bibr" target="#b31">30,</ref><ref type="bibr" target="#b40">39,</ref><ref type="bibr" target="#b57">56,</ref><ref type="bibr" target="#b66">65]</ref>. For non-task-oriented dialogue generation, Serban et al. <ref type="bibr" target="#b45">[44]</ref> and Chen et al. <ref type="bibr" target="#b5">[4]</ref> propose generation methods with implicit state representations, for which it is hard to distinguish medical concepts. Dialogue states have also been represented as a sequence of keywords from the dialogue context <ref type="bibr" target="#b53">[52]</ref>. Jin et al. <ref type="bibr" target="#b18">[17]</ref> and Zhang et al. <ref type="bibr" target="#b66">[65]</ref> propose semi-supervised generative models to leverage unlabeled data to improve state tracking performance. Liang et al. <ref type="bibr" target="#b30">[29]</ref> propose an encoder-decoder training framework, MOSS, to incorporate supervision from various intermediate dialogue system modules. MOSS exploits incomplete supervision during model training. However, existing approaches fail to generate engaging and informative responses as do not address the semantic reasoning ability of the dialogue agents. As far as we know, no existing method simultaneously models states and actions under a few-shot regime.</p><p>In the MDG scenario, learning physician actions is as important as state tracking. Compared to <ref type="bibr" target="#b18">[17,</ref><ref type="bibr" target="#b30">29,</ref><ref type="bibr" target="#b66">65]</ref>, our model is capable of inferring missing states and actions simultaneously.</p><p>Knowledge-grounded conversations. The task of knowledge grounded conversation (KGC) is to generate responses based on accurate background knowledge. The task can be grounded into two categories according to the format of the background knowledge, i.e., structured KGC and unstructured KGC. The former focuses on exploiting knowledge triplets <ref type="bibr" target="#b36">[35,</ref><ref type="bibr" target="#b69">68]</ref> or knowledge graphs <ref type="bibr" target="#b16">[15,</ref><ref type="bibr" target="#b38">37,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b59">58,</ref><ref type="bibr" target="#b68">67]</ref>, the latter conditions on paragraph text <ref type="bibr" target="#b11">[10,</ref><ref type="bibr" target="#b19">18,</ref><ref type="bibr" target="#b29">28,</ref><ref type="bibr" target="#b41">40]</ref>. For structured KGC, Liu et al. <ref type="bibr" target="#b36">[35]</ref> utilize a neural knowledge diffusion module to encode knowledge triplets to predict related entities. Liu et al. <ref type="bibr" target="#b38">[37]</ref> augment a knowledge graph to integrate with dialogue contexts in an open-domain dialogue. Tuan et al. <ref type="bibr" target="#b50">[49]</ref> assess a model's ability to reason multiple hops using a Markov chain over a constructed transition matrix, so that the model can zero-shot adapt to updated, unseen knowledge graphs. Xu et al. <ref type="bibr" target="#b59">[58]</ref> represent prior dialogue transition information as a knowledge graph and learn a graph grounded dialogue policy for generating coherent and controllable responses. Lei et al. <ref type="bibr" target="#b27">[26]</ref> construct a useritem-attribute knowledge graph and ingeniously formalize dialogue policy learning as path reasoning on the graph.</p><p>Unlike most structured KGC methods that select knowledge from open-domain knowledge-bases, MDG aims to explore a multihop knowledge path transferred from patient states to physician actions using dedicated medical-domain knowledge graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD 3.1 Problem formulation</head><p>Medical dialogue systems. Given ğ‘‡ dialogue turns, a medical dialogue session ğ‘‘ consists of a sequence of utterances, i.e., ğ‘‘ = {ğ‘ˆ 1 , ğ‘… 1 , ğ‘ˆ 2 , ğ‘… 2 , . . . , ğ‘ˆ ğ‘‡ , ğ‘… ğ‘‡ }, where ğ‘ˆ ğ‘¡ and ğ‘… ğ‘¡ refers to utterances from a patient and responses from a virtual physician, respectively. At the ğ‘¡-th turn, given the ğ‘¡-th patient utterance ğ‘ˆ ğ‘¡ and previous physician response ğ‘… ğ‘¡ -1 , the dialogue system generates a response ğ‘… ğ‘¡ . Let |ğ‘ˆ ğ‘¡ | be the number of words in ğ‘ˆ ğ‘¡ , we define ğ‘ˆ ğ‘¡ = (ğ‘ˆ ğ‘¡,1 , ğ‘ˆ ğ‘¡,2 , . . . , ğ‘ˆ ğ‘¡, |ğ‘ˆ ğ‘¡ | ) as a sequence of words. The full vocabulary is defined as V. ğ¾ denotes an external knowledge base in the medical dialogue system, where each triplet in ğ¾ indicates a head entity, a relation, and a tail entity. Following <ref type="bibr" target="#b54">[53]</ref>, we construct a knowledge graph ğº global by linking all triplets with overlapping entities (i.e., two triples will be linked iff they share overlapping entities) in ğ¾. We assume that each entity is categorized into a set of entity types, i.e., ğ¸ ğ‘¡ ğ‘¦ğ‘ğ‘’ = {disease, symptoms, medicines, treatments}.</p><p>We consider VRBot as a model with parameters ğœƒ . Given the dialogue context, responses, and the knowledge graph ğº global , we aim to maximize the probability distribution over ğ‘‘ in VRBot:</p><formula xml:id="formula_0">ğ‘‡ ğ‘¡ =1 ğ‘ ğœƒ (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğº global ).<label>(1)</label></formula><p>Patient states and physician actions. Text-span based dialogue state trackers have the double advantage of simplicity and good interpretability <ref type="bibr" target="#b18">[17,</ref><ref type="bibr" target="#b25">24,</ref><ref type="bibr" target="#b56">55]</ref>. Hence, at the ğ‘¡-th turn, we define a text span ğ‘† ğ‘¡ (i.e., a sequence of words) as the patient state to summarize past utterances and responses (i.e., ğ‘ˆ 1 , ğ‘… 1 , . . . , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ ). Then we take ğ‘† ğ‘¡ as constraints to search in a knowledge base. Similar to ğ‘† ğ‘¡ , we also use a text span ğ´ ğ‘¡ to represent the physician action at the ğ‘¡th turn, which summarizes the physician's policy such as diagnose, medicine, or treatment. ğ´ ğ‘¡ is predicted through a policy learning process given ğ‘† ğ‘¡ . Thus, task completion in MDG becomes a problem of generating two successive text spans, ğ‘† ğ‘¡ and ğ´ ğ‘¡ , at each turn.</p><p>As text spans also help to improve the performance of response generation <ref type="bibr" target="#b18">[17,</ref><ref type="bibr" target="#b25">24]</ref>, generating ğ‘† ğ‘¡ and ğ´ ğ‘¡ at each turn is a key component in MDG. In this paper, the problem of MDG is decomposed into three successive steps: (1) generating a state span ğ‘† ğ‘¡ ; (2) generating an action span ğ´ ğ‘¡ ; and (3) generating the response ğ‘… ğ‘¡ .</p><p>Variational Bayesian generative model. Large volumes of intermediate annotations for patient states and physician actions are impractical in MDG. Thus, in VRBot we regard ğ‘† ğ‘¡ and ğ´ ğ‘¡ as latent variables within a Bayesian generative model, so we reformulate Eq. 1 as:</p><formula xml:id="formula_1">ğ‘‡ ğ‘¡ =1 âˆ‘ï¸ ğ‘†ğ‘¡ ,ğ´ğ‘¡ ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘¡ , ğ´ ğ‘¡ ) â€¢ ğ‘ ğœƒğ‘  (ğ‘† ğ‘¡ ) â€¢ ğ‘ ğœƒğ‘ (ğ´ ğ‘¡ ),<label>(2)</label></formula><p>where ğ‘ ğœƒ ğ‘” (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘¡ , ğ´ ğ‘¡ ) is derived using a response generator, and ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) and ğ‘ ğœƒ ğ‘ (ğ´ ğ‘¡ ) are estimated through a patient state tracker and a physician policy network, respectively. The graphical representation of VRBot is shown in Fig. <ref type="figure" target="#fig_1">2</ref>, where shaded and unshaded nodes indicate observed and latent variables, respectively. We see that a dependency exists between two adjacent states. At ğ‘¡, ğ‘† ğ‘¡ is derived depending on previous state ğ‘† ğ‘¡ -1 , response ğ‘… ğ‘¡ -1 , and utterance ğ‘ˆ ğ‘¡ ; subsequently, ğ´ ğ‘¡ is inferred using ğ‘† ğ‘¡ , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , and ğº global . Thus, we calculate ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) and ğ‘ ğœƒ ğ‘ (ğ´ ğ‘¡ ) as: where ğœƒ ğ‘  and ğœƒ ğ‘ are parameters; and a fixed initial value is assigned to ğ‘† 0 at the beginning. In VRBot we propose two prior networks to estimate probabilistic distributions in Eq. 3, i.e., a prior state tracker and prior policy network. Eventually, we draw a response ğ‘… ğ‘¡ from</p><formula xml:id="formula_2">ğ‘ ğœƒğ‘  (ğ‘† ğ‘¡ ) â‰œ ğ‘ ğœƒğ‘  (ğ‘† ğ‘¡ |ğ‘† ğ‘¡ -1 , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ ) (prior state tracker), ğ‘ ğœƒğ‘ (ğ´ ğ‘¡ ) â‰œ ğ‘ ğœƒğ‘ (ğ´ ğ‘¡ |ğ‘† ğ‘¡ , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğº ğ‘”ğ‘™ğ‘œğ‘ğ‘ğ‘™ ) (prior policy network),<label>(3)</label></formula><formula xml:id="formula_3">ğ‘ ğœƒ ğ‘” (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘¡ , ğ´ ğ‘¡ ), with parameters ğœƒ ğ‘” .</formula><p>To maximize Eq. 2, we estimate the posterior distribution ğ‘ ğœƒ (ğ‘† ğ‘¡ , ğ´ ğ‘¡ |ğ‘… ğ‘¡ , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğº global ). However, the exact posterior distribution is intractable due to its complicated posterior expectation estimation.</p><p>To address this problem, we introduce two inference networks <ref type="bibr" target="#b21">[20]</ref> (i.e., ğ‘ ğœ™ ğ‘  (ğ‘† ğ‘¡ ) and ğ‘ ğœ™ ğ‘ (ğ´ ğ‘¡ )) to approximate the posterior distributions over ğ‘† ğ‘¡ and ğ´ ğ‘¡ , respectively:</p><formula xml:id="formula_4">ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ ) â‰œ ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ |ğ‘† ğ‘¡ -1 , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘… ğ‘¡ ) (inference state tracker), ğ‘ ğœ™ğ‘ (ğ´ ğ‘¡ ) â‰œ ğ‘ ğœ™ğ‘ (ğ´ ğ‘¡ |ğ‘† ğ‘¡ , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘… ğ‘¡ ) (inference policy network),<label>(4)</label></formula><p>where ğœ™ ğ‘  and ğœ™ ğ‘ are parameters in inference networks.</p><p>Evidence lower bound (ELBO). At ğ‘¡, we derive the ELBO to optimize both prior and inference networks simultaneously as follows:</p><formula xml:id="formula_5">log ğ‘ ğœƒ (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğº global ) â‰¥ E ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ -1 ) E ğ‘ ğœ™ğ‘  (ğ‘†ğ‘¡ ) â€¢ğ‘ ğœ™ğ‘ (ğ´ğ‘¡ ) [log ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘¡ , ğ´ ğ‘¡ ) ] -KL(ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ ) | |ğ‘ ğœƒğ‘  (ğ‘† ğ‘¡ )) -KL(ğ‘ ğœ™ğ‘ (ğ´ ğ‘¡ ) âˆ¥ğ‘ ğœƒğ‘ (ğ´ ğ‘¡ )) = -L joint ,<label>(5)</label></formula><p>where E( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Context encoder</head><p>At ğ‘¡, we encode the dialogue history (ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ ) into a list of wordlevel hidden vectors ğ‘¯ ğ‘¡ = (ğ’‰ ğ‘¡,1 , . . . , ğ’‰ ğ‘¡, |ğ‘… ğ‘¡ -1 |+ |ğ‘ˆ ğ‘¡ | ) using a bidirectional Gated Recurrent Unit (GRU) <ref type="bibr" target="#b7">[6]</ref>:</p><formula xml:id="formula_6">ğ‘¯ ğ‘¡ = BiGRU(ğ’‰ ğ‘ ğ‘¡ -1 , ğ’† ğ‘… ğ‘¡ -1 1 , ğ’† ğ‘… ğ‘¡ -1 2 , . . . , ğ’† ğ‘… ğ‘¡ -1 |ğ‘… ğ‘¡ -1 | , . . . , ğ’† ğ‘ˆğ‘¡ |ğ‘ˆğ‘¡ | ),<label>(6)</label></formula><p>where </p><formula xml:id="formula_7">ğ‘ ğœƒğ‘  (ğ‘† ğ‘¡ ) = |ğ‘† | ğ‘–=1 softmax(MLP(ğ’ƒ ğ‘† ğ‘ ğ‘¡,ğ‘– )),<label>(7)</label></formula><p>where MLP is a multilayer perceptron (MLP) <ref type="bibr" target="#b10">[9]</ref>. To approximate the state posterior distribution, the inference state tracker follows a similar process but additionally incorporates the encoding of ğ‘… ğ‘¡ , i.e., ğ’‰ ğ‘… ğ‘¡ . The GRU decoder is initialized as</p><formula xml:id="formula_8">ğ’ƒ ğ‘† ğ‘ ğ‘¡,0 = ğ‘¾ ğ‘ ğ‘  [ğ’‰ ğ‘ ğ‘¡ ; ğ’‰ ğ‘† ğ‘ ğ‘¡ -1 ; ğ’‰ ğ‘… ğ‘¡ ],</formula><p>where ğ‘¾ ğ‘ ğ‘  is a learnable parameter, and it outputs ğ’ƒ ğ‘† ğ‘ ğ‘¡,ğ‘– at the ğ‘–-th decoding step. Accordingly, we write the approximate posterior distribution as:</p><formula xml:id="formula_9">ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ ) = |ğ‘† | ğ‘–=1 softmax(MLP(ğ’ƒ ğ‘† ğ‘ ğ‘¡,ğ‘– )).<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Physician policy network</head><p>The prior and inference policy networks are also based on an encoder-decoder structure. </p><formula xml:id="formula_10">ğ‘ƒ ğœƒğ‘,ğ‘ (ğ´ ğ‘ ğ‘¡ ) = softmax(ğ‘¾ ğ‘ ğ‘ [ğ’‰ ğ‘† ğ‘ ğ‘¡ ; ğ’‰ ğ‘ ğ‘¡ ; ğ’’ ğ‘¡ ]),<label>(9)</label></formula><p>where </p><formula xml:id="formula_11">ğ‘¾</formula><formula xml:id="formula_12">ğ‘ ğœƒ ğ‘,ğ‘‘ (ğ´ ğ‘˜ ğ‘¡,ğ‘– ) = 1 ğ‘§ ğ´ exp (MLP( [ğ’‰ ğ‘† ğ‘ ğ‘¡ ; ğ’‰ ğ‘ ğ‘¡ ; ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,ğ‘– ])),<label>(10)</label></formula><p>where ğ‘§ ğ´ is the normalization term shared with the graph-reasoning detector. The graph-reasoning detector considers to copy entities from ğº local ğ‘› :</p><formula xml:id="formula_13">ğ‘ ğœƒğ‘,ğ‘” (ğ´ ğ‘˜ ğ‘¡,ğ‘– ) = 1 ğ‘§ ğ´ I(ğ‘’ ğ‘— , ğ´ ğ‘˜ ğ‘¡,ğ‘– ) â€¢ exp (ğ‘¾ ğ‘” [ğ’‰ ğ‘ ğ‘¡ ; ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,ğ‘– ; ğ’ˆ ğ‘— ]),<label>(11)</label></formula><p>where ğ‘¾ ğ‘” is a learnable parameter matrix, ğ‘’ ğ‘— is the ğ‘—-th entity in </p><formula xml:id="formula_14">ğº local ğ‘› ,</formula><p>Eventually, we get the approximate posterior distribution of ğ´ ğ‘¡ :</p><formula xml:id="formula_16">ğ‘ ğœ™ğ‘ (ğ´ ğ‘¡ ) = ğ‘ ğœ™ğ‘,ğ‘ (ğ´ ğ‘ ğ‘¡ ) â€¢ |ğ´| ğ‘–=1 ğ‘ ğœ™ ğ‘,ğ‘‘ (ğ´ ğ‘˜ ğ‘¡,ğ‘– ).<label>(15)</label></formula><p>Inspired by Jin et al. <ref type="bibr" target="#b18">[17]</ref>, we also employ the copy mechanism in ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) and ğ‘ ğœ™ ğ‘  (ğ‘† ğ‘¡ ), so as to copy tokens from ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘ ğ‘¡ -1 . In the same way, we copy tokens from ğ‘… ğ‘¡ for ğ‘ ğœ™ ğ‘ (ğ´ ğ‘¡ ).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Response generator</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Collapsed inference and training</head><p>Eq. 5 provides a unified objective for optimizing all components. However, the joint distribution ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) â€¢ğ‘ ğœƒ ğ‘ (ğ´ ğ‘¡ ) is hard to optimize as ğ‘ ğœƒ (ğ´ ğ‘¡ ) is easily misled with incorrect sampling results of ğ‘† ğ‘ ğ‘¡ from ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ). To address this problem, we propose a 2-stage collapsed inference method by decomposing the objective function into 2stage optimization objectives. During the first stage, we fit ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) to ğ‘ ğœ™ ğ‘  (ğ‘† ğ‘¡ ) to derive the ELBO (labeled by âŠ in Fig. <ref type="figure" target="#fig_3">4</ref>):</p><formula xml:id="formula_17">log ğ‘ ğœƒ (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğº global ) â‰¥ E ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ -1 ) E ğ‘ ğœ™ğ‘  (ğ‘†ğ‘¡ ) E ğ‘ ğœƒğ‘ (ğ´ğ‘¡ ) [log ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘¡ , ğ´ ğ‘¡ ) ] -KL(ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ ) âˆ¥ğ‘ ğœƒğ‘  (ğ‘† ğ‘¡ )) = -L ğ‘  .<label>(17)</label></formula><p>Subsequently, similar to the optimization of ğœ™ ğ‘  and ğœƒ ğ‘  , ğ‘ ğœƒ ğ‘ (ğ´ ğ‘¡ ) is fit ğ‘ ğœ™ ğ‘ (ğ´ ğ‘¡ ) to formulate the ELBO (labeled by â‹ in Fig. <ref type="figure" target="#fig_3">4</ref>) as follows:</p><formula xml:id="formula_18">log ğ‘ ğœƒ (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğº global ) â‰¥ E ğ‘ ğœ™ğ‘  (ğ‘† ğ‘¡ -1 ) E ğ‘ ğœƒğ‘  (ğ‘†ğ‘¡ ) E ğ‘ ğœ™ğ‘ (ğ´ğ‘¡ ) [log ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡ |ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘¡ , ğ´ ğ‘¡ ) ] -KL(ğ‘ ğœ™ğ‘ (ğ´ ğ‘¡ ) âˆ¥ğ‘ ğœƒğ‘ (ğ´ ğ‘¡ )) = -L ğ‘ .<label>(18)</label></formula><p>Accordingly, the training procedure comprises two stages when no human-annotation exist. So we have:</p><formula xml:id="formula_19">L ğ‘¢ğ‘› = L ğ‘  (1st training stage) L ğ‘  + L ğ‘ (2nd training stage). (<label>19</label></formula><formula xml:id="formula_20">)</formula><p>We first minimize L ğ‘  to get proper state tracking results. Then we jointly train all parameters to the 2nd stage optimization. We learn VRBot by SGVB and draw samples with the Gumbel-Softmax trick <ref type="bibr" target="#b17">[16]</ref> to calculate the gradients with discrete variables. If annotated states Sğ‘¡ and actions Ä€ğ‘¡ are partially available, we add the auxiliary loss L ğ‘ ğ‘¢ğ‘ to perform semi-supervised training:</p><formula xml:id="formula_21">L ğ‘ ğ‘¢ğ‘ = -(log ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡ | Sğ‘¡ , Ä€ğ‘¡ , ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ ) + log(ğ‘ ğœƒğ‘  ( Sğ‘¡ ) â€¢ ğ‘ ğœ™ğ‘  ( Sğ‘¡ )) + log(ğ‘ ğœƒğ‘ ( Ä€ğ‘¡ ) â€¢ ğ‘ ğœ™ğ‘ ( Ä€ğ‘¡ ))). (<label>20</label></formula><formula xml:id="formula_22">)</formula><p>In the test process, we only execute ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) and ğ‘ ğœƒ ğ‘ (ğ´ ğ‘¡ ) to infer patient states and physician actions (labeled by b in Fig. <ref type="figure" target="#fig_2">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL SETUP 4.1 Research questions</head><p>We seek to answer the following research questions: (RQ1) How does VRBot perform on medical dialogue generation? Is unlabeled data helpful for generating accurate responses? (RQ2) What is the effect of each component in VRBot? Are the reasoning detectors helpful to improve physician action prediction? (RQ3) What is the effect of the length of the patient state and physician action in VRBot? (RQ4) Can VRBot provide interpretable results?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets</head><p>We adopt three medical dialogue datasets for our experiments, all of which are collected from real-world medical consultation websites after data anonymization, i.e., close to clinically authentic medical scenarios. Two have been applied in previous studies, and we propose a new dataset with large-scale external knowledge.</p><p>Existing medical dialogue datasets have a limited amount of external knowledge, a limited length of dialogues, and a handful of medical departments. These constraints make it difficult to evaluate MDG approaches. To address this problem, we collect a large-scale dataset Knowledge-aware Medical conversation dataset (KaMed) from ChunyuDoctor,<ref type="foot" target="#foot_0">foot_0</ref> a large online Chinese medical consultation platform. The dataset caters for challenging and diverse scenarios, as it contains over 100 hospital departments with a large-scale external knowledge graph. To simulate realistic clinical conversational scenarios, in KaMed the average number of rounds of a dialogue is 11.62, much longer than existing medical dialogue datasets. Unlike other medical dialogue datasets, KaMed is equipped with large-scale external medical knowledge, crawled from CMeKG,<ref type="foot" target="#foot_1">foot_1</ref> the largest Chinese medical knowledge platform.</p><p>To evaluate VRBot, we also use two benchmark datasets. MedDG <ref type="bibr" target="#b37">[36]</ref> is collected from ChunyuDoctor, related to 12 types of common gastrointestinal diseases, and provides semi-automatic annotated states and actions; the average number of rounds of a dialogue session is 9.92. MedDialog <ref type="bibr" target="#b6">[5]</ref> is collected from an online medical platform. We filter out dialogues with fewer than three rounds, but the average number of rounds is still relatively low, only 4.76. We also collect relevant medical knowledge for the MedDG and MedDialog datasets. The dataset statistics are listed in Table <ref type="table" target="#tab_6">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines and comparisons</head><p>In the context of RQ1, we write VRBot\un for the model that is only trained using annotated data. We devise a variation of VRBot by replacing the GRU encoder with Bert, and use VRBot-Bert to denote it. In the context of RQ2, we write VRBot\S for the model that eliminates the latent state variable, VRBot\A for the model that eliminates the latent action variable, VRBot\G for the model without the graph-reasoning detector, VRBot\C for the model without the context-reasoning detector, and VRBot\2s for the model without 2-stage collapsed inference (i.e., minimizing L joint in Eq. 5).</p><p>As far as we know, only Liu et al. <ref type="bibr" target="#b37">[36]</ref> have addressed the same task as we do. Thus, for MDG, we use HRED-Bert <ref type="bibr" target="#b37">[36]</ref> as a baseline, which integrates Bert <ref type="bibr" target="#b8">[7]</ref> with the HRED model for MRG. We consider three types of baseline: open-domain dialogue generation, knowledge grounded conversations, and task-oriented dialogue generation. As open-domain approaches, we use Seq2Seq <ref type="bibr" target="#b48">[47]</ref>, HRED <ref type="bibr" target="#b45">[44]</ref>, and VHRED <ref type="bibr" target="#b46">[45]</ref> as baselines. Seq2Seq is a sequenceto-sequence generation model with attention and copy mechanism <ref type="bibr" target="#b12">[11]</ref>; HRED uses a hierarchical encoder-decoder structure to model the dialogue at the word-and utterance-level; VHRED extends HRED with a continuous latent variable to facilitate generation. As knowledge-grounded methods, we use CCM <ref type="bibr" target="#b68">[67]</ref>, NKD <ref type="bibr" target="#b36">[35]</ref>, and PostKS <ref type="bibr" target="#b29">[28]</ref> as baselines. CCM applies two graph attention mechanisms to augment the semantic information during response generation; NKD uses a neural knowledge diffusion module to retrieve relevant knowledge; PostKS uses dialogue context and responses to infer the posterior knowledge distribution. For taskoriented dialogue generation, we use SEDST <ref type="bibr" target="#b18">[17]</ref>, LABES <ref type="bibr" target="#b66">[65]</ref>, MOSS <ref type="bibr" target="#b30">[29]</ref>, and DAMD <ref type="bibr" target="#b67">[66]</ref> as baselines. SEDST formalizes the dialogue state as a text-span to copy keywords from question to state; LABES regards the state as discrete latent variables to conduct the Straight-Through Estimator for calculating the gradient; MOSS incorporates supervision from various intermediate dialogue system modules; DAMD uses GRU-based decoders to decode the state, action, and response in a supervised manner. Similar performance can be also observed in Transformer based methods <ref type="bibr" target="#b61">[60,</ref><ref type="bibr" target="#b62">61]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation metrics</head><p>Automatic evaluation. To assess the language quality for the generated responses, we employ classical word-overlap based metrics, BLEU-2 (B@2) <ref type="bibr" target="#b43">[42]</ref> and ROUGE-2 (R@2) <ref type="bibr" target="#b32">[31]</ref>, to measure performance. As shortcomings have been reported for using BLEU/ROUGE to measure dialogue generation <ref type="bibr" target="#b34">[33]</ref>, we also use Distinct-1 (D@1) and Distinct-2 (D@2) <ref type="bibr" target="#b28">[27]</ref>, where Distinct-n is defined as the proportion of distinct n-grams in generated responses.</p><p>To measure the correctness of prediction results from the physician policy network, following <ref type="bibr" target="#b37">[36]</ref>, we calculate Precision (P), Recall (R), and F1 (F1) scores of predicted entities in the responses. We adopt the prefix ma-and mi-to indicate macro-average and microaverage Precision, Recall, and F1 scores, respectively. We also employ embedding-based topic similarity metrics <ref type="bibr" target="#b35">[34]</ref>, i.e., Embedding Average (EA) and Embedding greedy (EG), to evaluate the semantic relevance of the predicted entities between generated response and target response. We use mean explainability precision (MEP) and mean explainability recall (MER) to evaluate explainability <ref type="bibr" target="#b64">[63]</ref>.</p><p>Human evaluation. We randomly sample 600 dialogues and their corresponding generations from our model as well as the baselines. We recruit three professional annotators from a third-party hospital to evaluate the responses generated by different models. Following Liu et al. <ref type="bibr" target="#b37">[36]</ref>, we evaluate the responses generated by all models in terms of following three metrics: sentence fluency (Flu), knowledge correctness (KC), and entire quality (EQ). Flu measures if the generated response is smooth; KC evaluates whether the response is correct; EQ measures the annotator's satisfaction with the generated response. Three annotators are asked to rate each generated response with a score range from 1 (bad) to 5 (excellent) for each entry. Model names were masked out during evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Implementation details</head><p>We conduct our experiments with a batch size of 16, and the size of embedding and the GRU hidden state set to 300 and 512, respectively. We set ğ‘› = 2 in the ğ’’ğ’”ğ’–ğ’ƒ operation. The graph hidden size and output size are set to 128 and 512, respectively. All modules are trained in an end-to-end paradigm. We use the pkuseg <ref type="bibr" target="#b39">[38]</ref> toolkit to segment words. The vocabulary size is limited to 30, 000 for KaMed and MedDialog, and 20, 000 for MedDG. The lengths of the state text span and action text span are set to 10 and 3 in our experiments. We employ the PCL-MedBERT<ref type="foot" target="#foot_2">foot_2</ref> embedding which is trained on a largescale medical corpus. We set the temperature of Gumbel-Softmax to ğœ = 3.0, and anneal to 0.1 in 30, 000 training steps. We use the Adam optimizer <ref type="bibr" target="#b20">[19]</ref>; the learning rate is initialized to 1ğ‘’ -4 and decrease to 1ğ‘’ -5 gradually. For all models, we apply beam search decoding with a beam size of 5 for response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall performance</head><p>We show the automatic evaluation results for all unsupervised models on KaMed and MedDialog in Table <ref type="table">2</ref>, and the semi-supervised results in Table <ref type="table" target="#tab_7">3</ref>. We see in Table <ref type="table">2</ref> that VRBot significantly outperforms all baselines in terms of most evaluation metrics on both datasets. In terms of D@1 and D@2 VRBot outperforms other baselines as the generated responses in VRBot are more diverse. For KaMed, VRBot achieves an increase of 14.68%, 36.81%, 61.00%, and 67.57% over PostKS in terms of B@2, R@2, D@1, and D@2, respectively. For MedDialog, VRBot gives an increase of 21.47%, 14.17%, 31.29%, and 43.63% over PostKS. Models without reasoning give high ma-P and mi-P scores, but they do not perform well in terms of ma-R, mi-R, ma-F1, mi-F1. In terms of ma-R, mi-R, ma-F1, mi-F1, EA and EE, VRBot outperforms all baselines by a large margin. Hence, VRBot is effective in predicting physician actions. Table <ref type="table" target="#tab_7">3</ref> shows the performance in semi-supervised settings on the MedDG dataset. SEDST and LABES are two state-of-the-art semi-supervised state tracking approaches. Without labeled action data, VRBot still achieves 23.35% and 26.73% improvements over LABES in terms of ma-F1 and mi-F1 with 25% labeled states; when the state labeling proportion increases to 50%, VRBot achieves an increase of 20.11% and 20.38%. VRBot outperforms VRBot\un by 12.36% and 10.36% in terms of ma-F1 and mi-F1 with the supervision proportion set to 50%; the increase is more significant with a lower supervision proportion. Thus, unlabeled data improves the performance of VRBot.</p><p>VRBot outperforms MOSS by a large margin despite the fact that MOSS can also use unlabeled data; it outperforms MOSS by 11.90% and 14.14% in terms of mi-F1 when with 25% and 50% labeled data, respectively. VRBot significantly outperforms HRED-Bert in terms of all metrics when the supervision proportion â‰¤ 25%. With 50% and 100% annotated data, VRBot-Bert still outperforms HRED-Bert by 12.04% and 7.93% in terms of mi-F1.</p><p>In Table <ref type="table" target="#tab_8">4</ref>, we perform a human evaluation on the KaMed and MedDG dataset to investigate the unsupervised and semisupervised performance of VRBot. VRBot achieves the best performance in terms of all metrics on both datasets. On KaMed, VR-Bot outperforms SEDST and PostKS in terms of KC and EQ by a large margin. The result is consistent with our automatic evaluation results, confirming the importance of simultaneously modeling patient state and physician action. On MedDG, MOSS slightly outperforms DAMD, a fully-supervised method. VRBot achieves a 13% and 15% increase over MOSS in terms of KC and EQ. Thus, the unlabeled states and actions inferred by VRBot help to improve performance. We compute the average pairwise Cohen's kappa (ğœ…) to measure the consistency between annotators, and find that 0.6 â‰¥ ğœ… â‰¥ 0.4 for all metrics.  The results are shown in Fig. <ref type="figure" target="#fig_5">5</ref>. Focusing on the left part, we see that mi-P decreases, while mi-R and mi-F1 increase as the state text span length grows. As |ğ‘† | increases from 4 to 10, the mi-R and mi-F1 achieve 12.79% and 4.92% improvements, while mi-P decreases by  6.53%. On the right side, we see a tendency for all metrics to increase as |ğ´| increases, and the upward trend gradually slows down. As |ğ´| increases from 1 to 3, VRBot achieves 3.71%, 16.81% and 11.72% improvements in terms of mi-P, mi-R and mi-F1. The recall score rises a lot as a longer action text spans are able to present more information in the reply. As |ğ´| further increases from 3 to 5, the improvements are relatively small, i.e., 1.04% in terms of mi-F1. We have qualitatively similar findings on the KaMed dataset, which we omit due to space limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Explainability comparsion</head><p>To explicitly assess the explainability of VRBot's results, we calculate MEP and MER scores of action text spans in KaMed. We take a random sample of 50 dialogues from KaMed and manually compare the explainability performance of VRBot and PostKS. The results are listed in Table <ref type="table" target="#tab_11">6</ref>. We observe that VRBot outperforms PostKS by a large margin in terms of MEP and MER; our user study also shows that VRBot achieves a 44% win rate. This confirms that VR-Bot can provide more interpretable results in responses and action text spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Case study</head><p>We randomly sample an example from the KaMed test set to compare the performance of VRBot, SEDST and PostKS in Tab. 7. The dialogue occurs in the ear-nose-throat department and concerns the treatment of 'allergic rhinitis'.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this paper, we focus on medical dialogue response generation with a large-scale unlabeled corpus. We propose a generative model named VRBot, which uses latent variables to model unobserved patient state and physician actions. We derive the ELBO for VR-Bot and propose a 2-stage collapsed inference training trick that decomposes the ELBO into two learning objectives. Extensive experiments on three medical dialogue datasets show that VRBot achieves state-of-the-art performance on both unsupervised and semi-supervised learning. Furthermore, in a fully-supervised setting, VRBot-Bert which is a variation of VRBot augmented by Bert achieves the best results compared to all the baselines. Analysis also confirms that VRBot is able to generate interpretable results. VRBot proves the value of having a large-scale unlabeled medical corpus. It can be also applied to other task-oriented dialogue systems with few annotated data. As to our future work, we aim to leverage the labeled data of a single hospital department to improve the MDG performance on other departments without labeled data by transfer learning or zero-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REPRODUCIBILITY</head><p>Our code and dataset are available at <ref type="url" target="https://github.com/lddsdu/VRBot">https://github.com/lddsdu/ VRBot</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example medical dialogue in the infection department, the left part shows the dialogue; the right part illustrates dialogue states and actions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The graphical representation of VRBot. Shaded nodes represent observed variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An overview of VRBot. We divide VRBot into a context encoder, a patient state tracker, a physician policy network, and a response generator. Labels a, b indicate different sampling procedure in training and test process respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The graphical representation of 2-stage collapsed inference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5. 3</head><label>3</label><figDesc>Impact of |ğ‘† | and |ğ´| The length of state and action text span are set to fixed integers |ğ‘† | and |ğ´| respectively, as they could not be inferred in unsupervised learning. We conduct experiments on MedDialog by setting |ğ‘† | to values in {4, 6, 8, 10, 12} while fixing |ğ´| to 3, and selecting |ğ´| from {1, 2, 3, 4, 5} while fixing |ğ‘† | to 10, to see the effects of |ğ‘† | and |ğ´|.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The effect of text span length on MedDialog</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>We estimate ğ‘ ğœƒ ğ‘ (ğ´ ğ‘¡ ) and ğ‘ ğœ™ ğ‘ (ğ´ ğ‘¡ ) using ğ‘† ğ‘ ğœ™ ğ‘ (ğ´ ğ‘¡ ). Finally, ğ‘ ğœƒ ğ‘” (ğ‘… ğ‘¡ |â€¢) generates ğ‘… ğ‘¡ depending on ğ‘†</figDesc><table><row><cell>ğ‘ ğ‘¡ and ğ‘†</cell><cell>ğ‘ ğ‘¡ , respectively, and</cell></row><row><cell cols="2">draw ğ´ ğ‘ ğ‘¡ from ğ‘ ğ‘¡ and ğ´ ğ‘ ğ‘¡ . The above sampling procedure is shown in Fig. 3 (a.</cell></row><row><cell>Training process).</cell><cell></cell></row></table><note><p>â€¢) is the expectation, and KL(â€¢âˆ¥â€¢) denotes the Kullback-Leibler divergence. To estimate Eq. 5, from ğ‘ ğœ™ ğ‘  (ğ‘† ğ‘¡ -1 ) we first draw a state ğ‘† ğ‘ ğ‘¡ -1 , which is for estimating ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) and ğ‘ ğœ™ ğ‘  (ğ‘† ğ‘¡ ); then, ğ‘† ğ‘ ğ‘¡ is drawn from ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) and ğ‘† ğ‘ ğ‘¡ is obtained through ğ‘ ğœ™ ğ‘  (ğ‘† ğ‘¡ ).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>turn, the last hidden state ğ’‰ ğ‘¡, |ğ‘… ğ‘¡ -1 |+|ğ‘ˆ ğ‘¡ | attentively read ğ‘¯ ğ‘¡ to get the ğ‘¡-th turn's hidden representation, i.e., ğ’‰ ğ‘ ğ‘¡ . We then incorporate ğ’‰ ğ‘† ğ‘ ğ‘¡ -1 with ğ’‰ ğ‘ ğ‘¡ to infer the prior state distribution ğ‘ ğœƒ ğ‘  (ğ‘† ğ‘¡ ) at the ğ‘¡-th turn. During the decoding procedure, we first infer the prior distribution over the patient state. We denote ğ’ƒ ğ‘† ğ‘ ğ‘¡,0 = ğ‘¾ denotes vector concatenation. At the ğ‘–-th token during decoding, the decoder sequentially decodes ğ‘† ğ‘¡ to output ğ’ƒ ğ‘† ğ‘ ğ‘¡,ğ‘– given previous token embedding ğ’† ğ‘† ğ‘ ğ‘¡,ğ‘–-1 , next projects ğ’ƒ ğ‘† ğ‘ ğ‘¡,ğ‘– into the patient state space. We set ğ‘† ğ‘¡ 's length to |S|, and the prior distribution over ğ‘† ğ‘¡ is calculated as:</figDesc><table /><note><p><p><p><p>|ğ‘… ğ‘¡ -1 | and |ğ‘ˆ ğ‘¡ | indicate the number of words in ğ‘… ğ‘¡ -1 and ğ‘ˆ ğ‘¡ respectively; ğ’† ğ‘… ğ‘¡ -1 ğ‘– denotes the embedding of the ğ‘–-th word in ğ‘… ğ‘¡ -1 .</p>Initializing from the hidden representation ğ’‰ ğ‘ ğ‘¡ -1 of the (ğ‘¡ -1)-th</p>3.3 Patient state tracker</p>As we formulate patient states as text spans, the prior and inference state trackers are both based on an encoder-decoder framework. We encode ğ‘† ğ‘ ğ‘¡ -1 using a GRU encoder to get ğ’‰ ğ‘† ğ‘ ğ‘¡ -1 during the encoding procedure. ğ‘ ğ‘  [ğ’‰ ğ‘ ğ‘¡ ; ğ’‰ ğ‘† ğ‘ ğ‘¡ -1 ] as the initial hidden representation of the decoder, where ğ‘¾ ğ‘ ğ‘  is a learnable parameter matrix, and [â€¢; â€¢]</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>As for the prior policy network, at the beginning of the encoding procedure, we encode ğ‘† ğ‘ ğ‘¡ to a vector ğ’‰ ğ‘† ğ‘ ğ‘¡ using a GRU encoder. Furthermore, external knowledge is important for the physician network to react given the patient state. As the external medical knowledge graph ğº global is large (in the number of entities), we extract a sub-graph ğº local ğ‘› from ğº global via a knowledge base retrieval operation qsub, where we regard each entity in ğ‘† ğ‘ ğ‘¡ as seed nodes during qsub. Starting from ğ‘† ğ‘ ğ‘¡ , we extract all the accessible nodes and edges in ğº global within ğ‘› hops to get the sub-graph ğº local To combine the relation type during information propagation, we employ the relational graph attention network (RGAT) [2] to represent each entity in the external knowledge graph. Given a graph ğº = {ğ‘‹, ğ‘Œ } including relations ğ‘Œ and nodes ğ‘‹ , after multiple rounds of propagation, RGAT outputs a feature matrix ğ‘® = [ğ’ˆ 1 , ğ’ˆ 2 , . . . , ğ’ˆ ğ‘‹ ], where ğ’ˆ ğ‘¥ (1 â‰¤ ğ‘¥ â‰¤ ğ‘‹ ) is the embedding of node ğ‘¥. We use RGAT to denote this operation, so we have: ğ‘® local ğ‘› = RGAT(ğº local ğ‘› ). To decode outputs, we infer ğ´ ğ‘ ğ‘¡ and ğ´ ğ‘˜ ğ‘¡ sequentially. We devise an action classifier to infer ğ´ ğ‘ ğ‘¡ . Following [1], we compute an attention vector ğ’’ ğ‘¡ over ğ‘® local ğ‘› with ğ’‰ ğ‘ ğ‘¡ as the query. Sequentially, the action classifier incorporates ğ’’ ğ‘¡ , and classifies physician action into four categories, i.e., ask symptoms, diagnosis, prescribe medicine and chitchat, as follows:</figDesc><table><row><cell></cell><cell>ğ‘›</cell><cell>[51]. Besides,</cell></row><row><cell>we link all the entities appear in ğ‘†</cell><cell>ğ‘ ğ‘¡ to ensure ğº local ğ‘›</cell><cell>is connected.</cell></row></table><note><p>Specifically, we represent ğ´ ğ‘¡ as a pair of an action category ğ´ ğ‘ ğ‘¡ and a list of explicit keywords ğ´ ğ‘˜ ğ‘¡ , i.e., ğ´ ğ‘¡ = {ğ´ ğ‘ ğ‘¡ , ğ´ ğ‘˜ ğ‘¡ }. Here we set the length of ğ´ ğ‘˜ ğ‘¡ to |A|.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>,ğ‘ ğ‘¡ by sampling from ğ‘ ğœƒ ğ‘,ğ‘ (ğ´ ğ‘ ğ‘¡ ). ğ´ğ‘˜  ğ‘¡ is decoded sequentially based on a GRU decoder. To infer the prior probabilistic distribution, two reasoning detectors (i.e., a context-reasoning detector and a graph-reasoning detector) are proposed to corporately project the hidden representation of the decoder to the action space at each decoding step. The decoder is initializes as ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,0 = ğ‘¾ At the ğ‘–-th decoding step, the decoder outputs ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,ğ‘– . The context-reasoning detector and the graph-reasoning detector together infer ğ´ ğ‘˜ ğ‘¡,ğ‘– with ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,ğ‘– . Learning from the raw context and state, the context-reasoning detector infers the prior distribution over ğ´ ğ‘˜ ğ‘¡,ğ‘– using a MLP as follows:</figDesc><table /><note><p>ğ‘ ğ‘ is a learnable parameter. Then we draw an action category ğ´ ğ‘ğ‘ ğ‘˜ [ğ’‰ ğ‘† ğ‘ ğ‘¡ ; ğ’‰ ğ‘ ğ‘¡ ; ğ’† ğ´ ğ‘,ğ‘ ğ‘¡ ], where ğ’† ğ´ ğ‘,ğ‘ ğ‘¡ is the embedding of ğ´ ğ‘,ğ‘ ğ‘¡ .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>ğ’ˆ ğ‘— is the ğ‘—-th entry embedding of ğ‘® local ğ‘› , I(ğ‘’ ğ‘— , ğ´ ğ‘˜ ğ‘¡,ğ‘– ) equals 1 if ğ‘’ ğ‘— = ğ´ ğ‘˜ ğ‘¡,ğ‘– otherwise 0. Eventually, we calculate the prior distribution over ğ´ ğ‘¡ as follows: The inference policy network approximates the action category posterior distribution and keywords posterior distribution by extracting indicative information from the response ğ‘… ğ‘¡ . A GRU encoder encodes ğ‘… ğ‘¡ to ğ’‰ ğ‘… ğ‘¡ , ğ‘† ğ‘ ğ‘¡ to ğ’‰ ğ‘† ğ‘ ğ‘¡ respectively. Then we get the action category approximate posterior distribution as follows: ğ‘ ğœ™ ğ‘,ğ‘ (ğ´ ğ‘ ğ‘¡ ). To reinforce the effect of information from ğ‘… ğ‘¡ , we only use the context-reasoning detector to approximate the posterior distribution of ğ´ ğ‘˜ ğ‘¡ . The decoder is initialized as ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,0 = ğ‘¾ At the ğ‘–-th decoding step, the decoder outputs ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,ğ‘– , so we have the approximate posterior distribution over the ğ‘–-th action keyword: ğ‘ ğœ™ ğ‘,ğ‘‘ (ğ´ ğ‘˜ ğ‘¡,ğ‘– ) = softmax(MLP( [ğ’‰ ğ‘ ğ‘¡ ; ğ’‰ ğ‘† ğ‘</figDesc><table><row><cell cols="2">ğ‘ ğœ™ğ‘,ğ‘ (ğ´ ğ‘ ğ‘¡ ) = softmax(ğ‘¾</cell><cell cols="2">ğ‘ ğ‘ [ğ’‰ ğ‘ ğ‘¡ ; ğ’‰ ğ‘† ğ‘ ğ‘¡ ; ğ’‰ ğ‘… ğ‘¡ ]).</cell><cell>(13)</cell></row><row><cell cols="3">Thereafter, we draw ğ´ ğ‘,ğ‘ ğ‘¡ via sampling from ğ‘ ğ‘˜ [ğ’‰ ğ‘ ğ‘¡ ; ğ’‰ ğ‘† ğ‘ ğ‘¡ ; ğ’† ğ´ ğ‘,ğ‘ ğ‘¡</cell><cell>; ğ’‰ ğ‘… ğ‘¡ ], where ğ’† ğ´ ğ‘,ğ‘ ğ‘¡</cell></row><row><cell>is the embedding of ğ´ ğ‘,ğ‘ ğ‘¡ , ğ‘¾</cell><cell cols="3">ğ‘ ğ‘˜ reflects a learnable parameter matrix.</cell></row></table><note><p>ğ‘ ğœƒğ‘ (ğ´ ğ‘¡ ) = ğ‘ ğœƒğ‘,ğ‘ (ğ´ ğ‘ ğ‘¡ ) â€¢ |ğ´| ğ‘–=1 [ğ‘ ğœƒ ğ‘,ğ‘‘ (ğ´ ğ‘˜ ğ‘¡,ğ‘– ) + ğ‘ ğœƒğ‘,ğ‘” (ğ´ ğ‘˜ ğ‘¡,ğ‘– ) ]. (12) ğ‘¡ ; ğ’ƒ ğ´ ğ‘˜,ğ‘ ğ‘¡,ğ‘– ])).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>-st word in ğ‘… ğ‘¡ . The probability of generating ğ‘… ğ‘¡,ğ‘– is formulated as a sum of the generative probability and a copy term:</figDesc><table><row><cell cols="6">At the first stage during the response generation, we use a GRU</cell></row><row><cell cols="5">encoder to encode ğ‘†</cell><cell>ğ‘ ğ‘¡ into ğ‘º</cell><cell>ğ‘ ğ‘¡ which is a word-level embedding ma-</cell></row><row><cell cols="2">trix of ğ‘†</cell><cell cols="4">ğ‘ ğ‘¡ . Each column vector in ğ‘º</cell><cell>ğ‘ ğ‘¡ reflects an embedding vec-</cell></row><row><cell cols="6">tor of the corresponding word in ğ‘†</cell><cell>ğ‘ ğ‘¡ . In the same manner, ğ´ ğ‘˜,ğ‘ ğ‘¡ is</cell></row><row><cell cols="6">encoded to ğ‘¨ ğ‘˜,ğ‘ ğ‘¡ . As mentioned in Sec. 3.3 and 3.4, we also calcu-</cell></row><row><cell cols="6">late the holistic embedding ğ’‰ ğ‘† ğ‘ ğ‘¡ and ğ’‰ ğ´ ğ‘˜,ğ‘ ğ‘¡</cell><cell>from ğ‘†</cell><cell>ğ‘ ğ‘¡ and ğ´ ğ‘˜,ğ‘ ğ‘¡ , re-</cell></row><row><cell cols="6">spectively. The response decoder with a GRU cell takes ğ’ƒ ğ‘… ğ‘¡,0 =</cell></row><row><cell cols="4">ğ‘¾ ğ‘‘ [ğ’‰ ğ‘ ğ‘¡ ; ğ’‰ ğ‘† ğ‘ ğ‘¡ ; ğ’† ğ´ ğ‘,ğ‘ ğ‘¡</cell><cell cols="2">; ğ’‰ ğ´ ğ‘˜,ğ‘ ğ‘¡</cell><cell>] as the initial hidden state.</cell></row><row><cell cols="6">At the ğ‘–-th decoding step, the output ğ’ƒ ğ‘… ğ‘¡,ğ‘–-1 from the ğ‘– -1-th</cell></row><row><cell cols="6">step attentively reads the context representation ğ‘¯ ğ‘¡ to get ğ’ƒ â„ ğ‘¡,ğ‘– ,</cell></row><row><cell cols="6">Meanwhile, ğ’ƒ ğ‘… ğ‘¡,ğ‘–-1 attentively read ğ‘º</cell><cell>ğ‘ ğ‘¡ ğ‘ğ‘›ğ‘‘ğ‘¨ ğ‘˜,ğ‘ ğ‘¡ to get ğ’ƒ ğ‘  ğ‘¡,ğ‘– and ğ’ƒ ğ‘ ğ‘¡,ğ‘–</cell></row><row><cell cols="6">respectively. Subsequently, [ğ’ƒ â„ ğ‘¡,ğ‘– ; ğ’ƒ ğ‘  ğ‘¡,ğ‘– ; ğ’ƒ ğ‘ ğ‘¡,ğ‘– ; ğ’† ğ‘… ğ‘¡,ğ‘–-1 ] are fed into the</cell></row><row><cell cols="6">decoder GRU cell to output ğ’ƒ ğ‘… ğ‘¡,ğ‘– , where ğ’† ğ‘… ğ‘¡,ğ‘–-1 is the embedding of</cell></row><row><cell cols="6">(ğ‘– -1)ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡,ğ‘– ) = ğ‘</cell><cell>ğ‘” ğœƒğ‘” (ğ‘… ğ‘¡,ğ‘– ) + ğ‘ ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡,ğ‘– ),</cell></row><row><cell></cell><cell></cell><cell>ğ‘</cell><cell cols="3">ğ‘” ğœƒğ‘” (ğ‘… ğ‘¡,ğ‘– ) =</cell><cell>1 ğ‘§ ğ‘…</cell><cell>exp (MLP(ğ’ƒ ğ‘… ğ‘¡,ğ‘– )),</cell><cell>(16)</cell></row><row><cell></cell><cell></cell><cell cols="4">ğ‘ ğ‘ ğœƒğ‘” (ğ‘… ğ‘¡,ğ‘– ) =</cell><cell>1 ğ‘§ ğ‘…</cell><cell>ğ‘— :ğ‘Š ğ‘— =ğ‘… ğ‘¡,ğ‘– âˆ‘ï¸</cell><cell>exp (ğ’‰ ğ‘Š ğ‘—</cell><cell>T â€¢ ğ’ƒ ğ‘… ğ‘¡,ğ‘– ),</cell></row><row><cell>where ğ‘</cell><cell cols="2">ğ‘” ğœƒ ğ‘”</cell><cell></cell><cell></cell></row></table><note><p>(ğ‘… ğ‘¡,ğ‘– ) is the generative probability, ğ‘ ğ‘ ğœƒ ğ‘” (ğ‘… ğ‘¡,ğ‘– ) is the copy term, ğ‘§ ğ‘… is the normalization term shared with ğ‘ ğ‘ ğœƒ ğ‘” (ğ‘… ğ‘¡,ğ‘– ). We write ğ‘Š for a concatenation sequence of ğ‘… ğ‘¡ -1 , ğ‘ˆ ğ‘¡ , ğ‘† ğ‘ ğ‘¡ , and ğ´ ğ‘˜,ğ‘ ğ‘¡ , where ğ‘Š ğ‘— is the ğ‘—-th word in ğ‘Š , and ğ’‰ ğ‘Š ğ‘— is the ğ‘—-th vector in [ğ‘¯ ğ‘¡ ; ğ‘º ğ‘ ğ‘¡ ; ğ‘¨ ğ‘˜,ğ‘ ğ‘¡ ].</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 :</head><label>1</label><figDesc>Statistics of KaMed, MedDialog and MedDG; âœ“ under 'An' indicates the dataset provides annotations.</figDesc><table><row><cell>Dataset</cell><cell>Train/Valid/Test</cell><cell cols="3">Entity/Triplet Turn An</cell></row><row><cell>KaMed</cell><cell cols="2">57, 754/3, 000/3, 000 5, 682/53, 159</cell><cell>11.62</cell><cell>âœ—</cell></row><row><cell cols="3">MedDialog 32, 723/3, 000/3, 000 4, 480/79, 869</cell><cell>4.76</cell><cell>âœ—</cell></row><row><cell>MedDG</cell><cell cols="2">14, 864/2, 000/1, 000 160/1, 240</cell><cell>9.92</cell><cell>âœ“</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Automatic evaluation on the MedDG dataset. S-Sup and A-Sup indicate the supervision proportion of states and actions, respectively. Models that are able to use unlabeled data are marked with # .</figDesc><table><row><cell>Model</cell><cell cols="4">S-sup A-sup ma-F1 mi-F1</cell><cell>EA</cell><cell>EG</cell></row><row><cell>SEDST #</cell><cell>25% 50%</cell><cell>0%</cell><cell>13.50 12.29</cell><cell>20.94 19.97</cell><cell cols="2">22.39 33.19 23.12 33.59</cell></row><row><cell>LABES #</cell><cell>25% 50%</cell><cell>0%</cell><cell>12.80 12.28</cell><cell>20.05 20.02</cell><cell cols="2">23.31 33.20 23.40 33.88</cell></row><row><cell></cell><cell></cell><cell>25%</cell><cell>5.45</cell><cell>16.40</cell><cell cols="2">20.46 29.64</cell></row><row><cell>NKD</cell><cell>0%</cell><cell>50%</cell><cell>6.15</cell><cell>18.89</cell><cell cols="2">22.10 32.03</cell></row><row><cell></cell><cell></cell><cell>100%</cell><cell>8.92</cell><cell>21.68</cell><cell cols="2">23.77 34.48</cell></row><row><cell></cell><cell></cell><cell>25%</cell><cell>9.33</cell><cell>22.07</cell><cell cols="2">24.04 34.89</cell></row><row><cell>PostKS #</cell><cell>0%</cell><cell>50%</cell><cell>9.44</cell><cell>22.34</cell><cell cols="2">24.55 35.58</cell></row><row><cell></cell><cell></cell><cell>100%</cell><cell>9.68</cell><cell>22.19</cell><cell cols="2">24.90 36.08</cell></row><row><cell></cell><cell></cell><cell>10%</cell><cell>8.74</cell><cell>18.15</cell><cell cols="2">23.21 33.47</cell></row><row><cell>HRED-Bert</cell><cell>0%</cell><cell>25% 50%</cell><cell>12.24 14.91</cell><cell>22.57 23.83</cell><cell cols="2">26.17 37.92 27.36 39.58</cell></row><row><cell></cell><cell></cell><cell>100%</cell><cell>15.52</cell><cell>25.57</cell><cell cols="2">28.42 41.13</cell></row><row><cell></cell><cell>25%</cell><cell>25%</cell><cell>12.94</cell><cell>21.62</cell><cell cols="2">23.91 34.82</cell></row><row><cell>DAMD</cell><cell>50%</cell><cell>50%</cell><cell>14.26</cell><cell>23.70</cell><cell cols="2">24.83 36.06</cell></row><row><cell></cell><cell>100%</cell><cell>100%</cell><cell>13.47</cell><cell>25.06</cell><cell cols="2">26.28 38.39</cell></row><row><cell></cell><cell>25%</cell><cell>25%</cell><cell>12.74</cell><cell>23.03</cell><cell cols="2">25.83 37.46</cell></row><row><cell>MOSS #</cell><cell>50%</cell><cell>50%</cell><cell>13.78</cell><cell>23.33</cell><cell cols="2">25.36 36.87</cell></row><row><cell></cell><cell>100%</cell><cell>100%</cell><cell>13.84</cell><cell>24.36</cell><cell cols="2">25.21 36.69</cell></row><row><cell>VRBot\un</cell><cell>25% 50%</cell><cell>25% 50%</cell><cell>10.86 13.10</cell><cell>20.74 24.13</cell><cell cols="2">24.49 35.69 26.11 38.19</cell></row><row><cell></cell><cell>25%</cell><cell>0%</cell><cell cols="4">15.79* 25.41* 24.09 35.29*</cell></row><row><cell></cell><cell>50%</cell><cell>0%</cell><cell cols="4">14.75* 24.10* 25.69* 34.72*</cell></row><row><cell>VRBot #</cell><cell>10% 25%</cell><cell>10% 25%</cell><cell cols="4">15.10* 24.85* 27.21* 39.72* 15.88* 25.77* 27.73* 40.52*</cell></row><row><cell></cell><cell>50%</cell><cell>50%</cell><cell>14.72</cell><cell cols="3">26.63* 27.82* 40.69*</cell></row><row><cell></cell><cell>100%</cell><cell>100%</cell><cell cols="4">15.31* 26.66* 27.51* 40.29*</cell></row><row><cell>VRBot-Bert #</cell><cell>50% 100%</cell><cell>50% 100%</cell><cell>15.80 16.11</cell><cell cols="3">26.70* 28.21 41.18* 27.60* 28.80 42.08</cell></row><row><cell cols="3">5.2 Ablation study</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p>As shown in Table</p>5</p>, all components in VRBot contribute to its performance. On KaMed, the performance of VRBot\S and VRBot\A</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Human evaluation on the KaMed and MedDG datasets (with 25% annotations). The context-reasoning detector is able to leverage the raw dialogue to improve the reasoning ability, whereas the graph-reasoning detector can only use prior knowledge in the knowledge base. In terms of EA and EG, VRBot\C outperforms VRBot\A by 18.12% and 16.98% on KaMed, 28.03% and 26.27% on MedDialog, despite the fact that the mi-F1 score is close to VRBot\A. Hence, VRBot\C benefits from the rich semantics of external knowledge though the entity name in the knowledge graph does not strictly match the dialogue corpus. Without the 2-stage collapsed inference training trick (that is, VRBot\2s), the mi-F1 score decreases by 18.22% and 18.37% on KaMed and MedDialog, respectively.</figDesc><table><row><cell>Model</cell><cell></cell><cell># KaMed</cell><cell></cell><cell>Model</cell><cell></cell><cell># MedDG</cell></row><row><cell></cell><cell>Flu</cell><cell>KC</cell><cell>EQ</cell><cell></cell><cell>Flu</cell><cell>KC</cell><cell>EQ</cell></row><row><cell cols="4">SEDST 3.52 1.88 1.81</cell><cell cols="3">DAMD 3.77 2.62 2.49</cell></row><row><cell cols="4">PostKS 3.20 1.77 1.67</cell><cell>MOSS</cell><cell cols="2">3.76 2.88 2.59</cell></row><row><cell cols="4">VRBot 4.21 2.96 2.69</cell><cell>VRBot</cell><cell cols="2">4.00 3.26 2.99</cell></row><row><cell>ğœ…</cell><cell cols="3">0.54 0.56 0.49</cell><cell>ğœ…</cell><cell cols="2">0.45 0.47 0.48</cell></row><row><cell cols="7">drop by 42.27% and 17.64% in terms of mi-F1 respectively. On Med-</cell></row><row><cell cols="7">Dialog, VRBot\S and VRBot\A drop by 50.54% and 44.76% respec-</cell></row><row><cell cols="7">tively, which means that states and actions are equally important,</cell></row><row><cell cols="7">modeling only one of them is far from enough. The performance of</cell></row><row><cell cols="7">VRBot\C drops sharply in terms of all metrics; it drops by 22.32%</cell></row><row><cell cols="7">and 58.85% in terms of mi-F1 on KaMed and MedDialog, respec-</cell></row><row><cell cols="7">tively. VRBot\G drops a little, 3.66% and 1.34% in terms of mi-F1 on</cell></row><row><cell cols="3">KaMed and MedDialog.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Ablation study: A comparison of different variations by masking out specific sub-module.</figDesc><table><row><cell>Model</cell><cell></cell><cell># KaMed</cell><cell></cell><cell cols="2"># MedDialog</cell></row><row><cell></cell><cell>mi-F1</cell><cell>EA</cell><cell>EG</cell><cell>mi-F1</cell><cell>EA</cell><cell>EG</cell></row><row><cell>VRBot\S</cell><cell>15.14</cell><cell cols="2">30.01 29.64</cell><cell>12.03</cell><cell cols="2">21.48 22.05</cell></row><row><cell>VRBot\A</cell><cell>18.31</cell><cell cols="2">31.67 31.67</cell><cell>12.51</cell><cell cols="2">21.26 22.53</cell></row><row><cell>VRBot\G</cell><cell>20.78</cell><cell cols="2">42.02 41.84</cell><cell>17.87</cell><cell cols="2">33.09 35.41</cell></row><row><cell>VRBot\C</cell><cell>17.61</cell><cell cols="2">37.41 37.05</cell><cell>11.40</cell><cell cols="2">27.22 28.45</cell></row><row><cell>VRBot\2s</cell><cell>18.22</cell><cell cols="2">38.09 37.91</cell><cell>15.30</cell><cell cols="2">28.93 30.82</cell></row><row><cell>VRBot</cell><cell cols="6">21.54 42.37 42.33 18.11 34.51 36.79</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>In the 3rd round we see that SEDST and VRBot can both generate a state text span (i.e., ğ‘† 3 in Tab. 7) to model the patient state. VRBot tracks patient disease and symptoms 'allergic rhinitis, stuffy nose, sneezing', then prescribes the correct drugs 'Nasonex' and 'Montelukast' to meet the patient requirements (it is correct though does not match the gold response); We see a reasoning path 'allergic rhinitis â treated_by â Montelukast (0.09)' in the graph, where 0.09 indicates the copying weight of 'Montelukast' in the graph reasoning detector. SEDST and PostKS both fail to generate an accurate and interpretable response; this confirms the importance of simultaneously modeling patient states and physician actions. VRBot is able to generate interpretable responses with explicit text spans and reasoning paths.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Explainability comparison of VRBot and PostKS.</figDesc><table><row><cell cols="2">Model MEP MER Win Rate (User Study)</cell></row><row><cell>PostKS 30.19 56.48</cell><cell>16.00</cell></row><row><cell>VRBot 44.22 82.61</cell><cell>44.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>One case extracted from KaMed, âœ˜and âœ”denote that the response is incorrect and excellent, respectively.Um. I usually feel the nose be a little uncomfortable, often dry nose. Montelukast (0.09) ; allergic rhinitis â treated_by â Cetirizine (0.04); allergic rhinitis â treated_by â Dexamethasone (0.02) Spray your nose with Nasonex , take Montelukast Sodium Chewable Tablets. âœ”</figDesc><table><row><cell>ğ‘ˆ 1 :</cell><cell>Is it allergic rhinitis (female, 19 years old)? My nose is very itchy and runny after</cell></row><row><cell></cell><cell>running.</cell></row><row><cell>ğ‘… 1 :</cell><cell>How long has it been? Did you sneeze? Stuffy nose?</cell></row><row><cell>ğ‘ˆ 2 :</cell><cell></cell></row><row><cell>ğ‘… 2 :</cell><cell>You can use Budesonide Nasal Spray.</cell></row><row><cell>ğ‘ˆ 3 :</cell><cell>Do you have any other suggestions for my symptoms?</cell></row><row><cell>Golden :</cell><cell>Flushed your nasal cavity with physiological seawater, take loratadine tablets.</cell></row><row><cell>ğ‘† 3 :</cell><cell>allergic rhinitis, stuffy nose, sneezing, Budesonide Nasal Spray</cell></row><row><cell>SEDST:</cell><cell>Spray your nose with Budesonide Nasal Spray. âœ˜</cell></row><row><cell>ğ´ 3 :</cell><cell>allergic rhinitis</cell></row><row><cell>PostKS:</cell><cell>Your symptom is caused by allergic rhinitis, suggest you go to the hospital to check</cell></row><row><cell></cell><cell>the nose. âœ˜</cell></row><row><cell>ğ‘† 3 :</cell><cell>allergic rhinitis, stuffy nose, sneezing</cell></row><row><cell cols="2">ğº ğ‘™ğ‘œğ‘ğ‘ğ‘™ ğ‘› allergic rhinitis â treated_by â ğ´ 3 : : prescribe medicine, Nasonex, Montelukast</cell></row><row><cell>VRBot:</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.chunyuyisheng.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>http://zstp.pcl.ac.cn:8002</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>https://code.ihub.org.cn/projects/1775/repository/mindspore_pretrain_bert</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>This work was supported by the <rs type="funder">Natural Science Foundation of China</rs> (<rs type="grantNumber">61902219</rs>, <rs type="grantNumber">61972234</rs>, <rs type="grantNumber">62072279</rs>), the <rs type="funder">National Key R&amp;D Program of China</rs> with grant No. <rs type="grantNumber">2020YFB1406704</rs>, the <rs type="funder">Key Scientific and Technological Innovation Program of Shandong Province</rs> (<rs type="grantNumber">2019JZZY010129</rs>), <rs type="funder">Shandong University</rs> multidisciplinary research and innovation team of young scholars (No. <rs type="grantNumber">2020QNQT017</rs>), the <rs type="funder">Tencent WeChat Rhino-Bird Focused Research Program</rs> (<rs type="grantNumber">JR-WXG-2021411</rs>), the <rs type="funder">Hybrid Intelligence Center</rs>, and a 10-year program funded by the <rs type="funder">Dutch Ministry of Education, Culture and Science through the Netherlands Organisation for Scientific Research</rs>, <ref type="url" target="https://hybrid-intelligence-centre.nl">https: //hybrid-intelligence-centre.nl</ref>. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_6WRq5zM">
					<idno type="grant-number">61902219</idno>
				</org>
				<org type="funding" xml:id="_H9H262q">
					<idno type="grant-number">61972234</idno>
				</org>
				<org type="funding" xml:id="_3Zh8BvD">
					<idno type="grant-number">62072279</idno>
				</org>
				<org type="funding" xml:id="_fhvu7Dr">
					<idno type="grant-number">2020YFB1406704</idno>
				</org>
				<org type="funding" xml:id="_6yNfwfy">
					<idno type="grant-number">2019JZZY010129</idno>
				</org>
				<org type="funding" xml:id="_e3CfuY8">
					<idno type="grant-number">2020QNQT017</idno>
				</org>
				<org type="funding" xml:id="_HfFXXQY">
					<idno type="grant-number">JR-WXG-2021411</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Automatic evaluation on the KaMed and MedDialog datasets. Boldface scores indicate best results, significant improvements over the best baseline are marked with * (t-test</title>
		<idno>ğ‘ &lt; 0.05</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Dataset Model B@2 R@2 D@1 D@2 ma-P ma-R ma-F1 mi-P mi-R mi-F1 EA EG KaMed Seq2Seq 2</title>
		<imprint>
			<biblScope unit="page">71</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">* REFERENCES [1] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<idno>VRBot 3.96* 1.45* 2.14 12.18 22.77 14.11* 17.42* 23.50 14.73* 18.11* 34.51* 36.79</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Dan</forename><surname>Busbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dane</forename><surname>Sherburn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Cavallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nils</forename><forename type="middle">Y</forename><surname>Hammerla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05811</idno>
		<title level="m">Relational Graph Attention Networks</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Survey on Dialogue Systems: Recent Advances and New Frontiers</title>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaorui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Hierarchical variational memory network for dialogue generation</title>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihong</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<idno>WWW. 1653-1662</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MedDialog: A Large-scale Medical Dialogue Dataset</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeqian</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongchao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruisi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Penghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengtao</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9241" to="9250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</title>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bart</forename><surname>Van MerriÃ«nboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extracting Symptoms and their Status from Clinical Conversations</title>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="915" to="925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Artificial Neural Networks (The Multilayer Perceptron)-A Review of Applications in the Atmospheric Sciences</title>
		<author>
			<persName><forename type="first">W</forename><surname>Matt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><surname>Dorling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric environment</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2627" to="2636" />
			<date type="published" when="1998">1998. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<title level="m">A Knowledge-grounded Neural Conversation Model. In AAAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="5110" to="5117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Incorporating Copying Mechanism in Sequence-to-sequence Learning</title>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep Neural Network Approach for the Dialog State Tracking Challenge</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="467" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A Simple Language Model for Task-oriented Dialogue</title>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Hosseini-Asl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Semih</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In NeurIPS. 20179-20191</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-Based Dialogue Systems</title>
		<author>
			<persName><forename type="first">Kai</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="525" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Knowledge Graph Embedding based Question Answering</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="105" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical Reparameterization with Gumbel-softmax</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Explicit State Tracking with Semi-supervision for Neural Dialogue Generation</title>
		<author>
			<persName><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangsong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1403" to="1412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue</title>
		<author>
			<persName><forename type="first">Byeongchang</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaewoo</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Structured Discriminative Model for Dialog State Tracking</title>
		<author>
			<persName><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="442" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recipe for Building Robust Spoken Dialog State Trackers: Dialog State Tracking Challenge System Description</title>
		<author>
			<persName><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="414" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conversational Recommendation: Formulation, Methods, and Evaluation</title>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2425" to="2428" />
		</imprint>
	</monogr>
	<note>Maarten de Rijke, and Tat-Seng Chua</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sequicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-sequence Architectures</title>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xisen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1437" to="1447" />
		</imprint>
	</monogr>
	<note>Xiangnan He, and Dawei Yin</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Re-examining the Role of Schema Linking in Text-to-SQL</title>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhixin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6943" to="6954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interactive Path Reasoning on Graph for Conversational Recommendation</title>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gangyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yisong</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2073" to="2083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Diversity-Promoting Objective Function for Neural Conversation Models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning to Select Knowledge for Response Generation in Dialog Systems</title>
		<author>
			<persName><forename type="first">Rongzhong</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinhua</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04911</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Moss: End-toend Dialog System Framework with Modular Supervision</title>
		<author>
			<persName><forename type="first">Weixin</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youzhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengcai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8327" to="8335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunshan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenqiang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.13129</idno>
		<title level="m">Rethinking Dialogue State Tracking with Reasoning</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Rouge: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Text Summarization Branches Out, Post-Conference Workshop of ACL 2004</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Enhancing Dialogue Symptom Diagnosis with Global Attention and Symptom Graph</title>
		<author>
			<persName><forename type="first">Xinzhu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiahui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaixiao</forename><surname>Tou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5036" to="5045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">How to Evaluate your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">How not to Evaluate your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Iulian V Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Knowledge Diffusion for Neural Dialogue Generation</title>
		<author>
			<persName><forename type="first">Shuman</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1489" to="1498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">Wenge</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghui</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.07497</idno>
		<title level="m">MedDG: A Large-scale Medical Consultation Dataset for Building Medical Dialogue System</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Knowledge Aware Conversation Generation with Reasoning on Augmented Graph</title>
		<author>
			<persName><forename type="first">Zhibin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Yu</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10245</idno>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Ruixuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.11455</idno>
		<title level="m">Pkuseg: A Toolkit for Multi-domain Chinese Word Segmentation</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Structured Fusion Networks for Dialog</title>
		<author>
			<persName><forename type="first">Shikib</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tejas</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>EskÃ©nazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="165" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dukenet: A Dual Knowledge Interaction Network for Knowledge-grounded Conversation</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1151" to="1160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Nikola</forename><surname>MrkÅ¡iÄ‡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Diarmuid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsung-Hsien</forename><surname>SÃ©aghdha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Blaise</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><surname>Young</surname></persName>
		</author>
		<title level="m">Neural Belief Tracker: Data-Driven Dialogue State Tracking</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1777" to="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Open-Retrieval Conversational Question Answering</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minghui</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="539" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Building End-to-end Dialogue Systems using Generative Hierarchical Neural Network Models</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Iulian V Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3776" to="3783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A Hierarchical Latent Variable Encoder-decoder Model for Generating Dialogues</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3295" to="3301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Understanding Medical Conversations with Scattered Keyword Attention and Weak Supervision from Responses</title>
		<author>
			<persName><forename type="first">Xiaoming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongqian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<idno>AAAI. 8838-8845</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Conversations with Documents: An Exploration of Document-Centered Assistance</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Maartje Ter Hoeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elnaz</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Nouri</surname></persName>
		</author>
		<author>
			<persName><surname>Fourney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
	<note>Maarten de Rijke, and Ryen White</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs</title>
		<author>
			<persName><forename type="first">Yi-Lin</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung-Yi</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1855" to="1865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An Analysis of Mixed Initiative and Collaboration in Information-Seeking Dialogues</title>
		<author>
			<persName><forename type="first">Svitlana</forename><surname>Vakulenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2085" to="2088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ripplenet: Propagating User Preferences on the Knowledge Graph for Recommender Systems</title>
		<author>
			<persName><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Chat More: Deepening and Widening the Chatting Topic via a Deep Model</title>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin-Shun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fumin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Kgat: Knowledge Graph Attention Network for Recommendation</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="950" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Task-oriented Dialogue System for Automatic Diagnosis</title>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qianlong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaixiao</forename><surname>Tou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan-Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="201" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A Network-based End-to-End Trainable Task-oriented Dialogue System</title>
		<author>
			<persName><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikola</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Alternating Recurrent Dialog Model with Large-scale Pre-trained Language Models</title>
		<author>
			<persName><forename type="first">Qingyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1292" to="1301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Generative Adversarial Regularized Mutual Information Policy Gradient Framework for Automatic Diagnosis</title>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1062" to="1069" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Conversational Graph Grounded Policy Learning for Open-domain Conversation Generation</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng-Yu</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1835" to="1845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">End-to-end Knowledge-routed Relational Dialogue System for Automatic Diagnosis</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qixian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<idno>AAAI. 7346-7353</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">On the Generation of Medical Dialogues for COVID-19</title>
		<author>
			<persName><forename type="first">Wenmian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangtao</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeqian</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subrato</forename><surname>Chakravorty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuehai</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengtao</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05442</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Multi-Domain Dialogue State Tracking-A Purely Transformer-Based Generative Approach</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.14061</idno>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Summarizing and Exploring Tabular Data in Conversational Search</title>
		<author>
			<persName><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1537" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.11192</idno>
		<title level="m">Explainable Recommendation: A Survey and New Perspectives</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">MIE: A Medical Information Extractor towards Medical Dialogues</title>
		<author>
			<persName><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongtao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiwan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6460" to="6469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning</title>
		<author>
			<persName><forename type="first">Yichi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijian</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junlan</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9207" to="9219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Task-oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</title>
		<author>
			<persName><forename type="first">Yichi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijian</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhou</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9604" to="9611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Commonsense Knowledge Aware Conversation Generation with Graph Attention</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haizhou</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4623" to="4629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">Wenya</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaixiang</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhangbin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezheng</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04264</idno>
		<title level="m">Flexible End-to-end Dialogue System for Knowledge Grounded Conversation</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
