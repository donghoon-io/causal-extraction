<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CONDITION-TRANSFORMING VARIATIONAL AUTOENCODER FOR CONVERSATION RESPONSE GENERATION</title>
				<funder ref="#_MQtp6qW">
					<orgName type="full">National Nature Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yu-Ping</forename><surname>Ruan</surname></persName>
							<email>ypruan@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
							<email>zhling@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Quan</forename><surname>Liu</surname></persName>
							<email>quanliu@iflytek.com</email>
							<affiliation key="aff1">
								<orgName type="department">iFLYTEK Research</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhigang</forename><surname>Chen</surname></persName>
							<email>zgchen@iflytek.com</email>
							<affiliation key="aff1">
								<orgName type="department">iFLYTEK Research</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nitin</forename><surname>Indurkhya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">P.R.China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CONDITION-TRANSFORMING VARIATIONAL AUTOENCODER FOR CONVERSATION RESPONSE GENERATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>variational</term>
					<term>autoencoders</term>
					<term>conversation</term>
					<term>text generation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes a new model, called condition-transforming variational autoencoder (CTVAE), to improve the performance of conversation response generation using conditional variational autoencoders (CVAEs). In conventional CVAEs , the prior distribution of latent variable z follows a multivariate Gaussian distribution with mean and variance modulated by the input conditions. Previous work found that this distribution tends to become conditionindependent in practical application. In our proposed CTVAE model, the latent variable z is sampled by performing a non-linear transformation on the combination of the input conditions and the samples from a condition-independent prior distribution N (0, I). In our objective evaluations, the CTVAE model outperforms the CVAE model on fluency metrics and surpasses a sequence-to-sequence (Seq2Seq) model on diversity metrics. In subjective preference tests, our proposed CTVAE model performs significantly better than CVAE and Seq2Seq models on generating fluency, informative and topic relevant responses.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>There has been a growing interest in neural-network-based end-toend models for text generation tasks, including machine translation <ref type="bibr" target="#b1">[1]</ref>, text summarization <ref type="bibr" target="#b2">[2]</ref>, and conversation response generation <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b4">4,</ref><ref type="bibr">5]</ref>. Among these, encoder-decoder framework has been widely adopted and they principally learn the mapping from an input sequence x to its target sequence y. Although this framework has achieved great success in machine translation, previous studies on generating responses for chit-chat conversations <ref type="bibr">[5,</ref><ref type="bibr" target="#b6">6]</ref> have found that ordinary encoder-decoder models tend to generate dull, repeated and generic responses in conversations, such as "i don't know", "that's ok", which are lack of diversity. One possible reason is the deterministic calculation of ordinary encoder-decoder models which constrains them from learning the 1-to-n mapping relationship, especially on semantic connections, between input sequence and potential multiple target sequences. In the task of chit-chat conversation, modeling and generating the diversity of responses is important because an input post or context may correspond to multiple responses with different meanings and language styles.</p><p>Many attempts have been made to alleviate these deficiencies of encoder-decoder models, such as by utilizing extra features or knowledge as conditions to generate more specific responses <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b8">8]</ref> and by improving the model structure, the training algorithms and the decoding strategies <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b11">11]</ref>. Additionally, conditional variational autoencoders (CVAEs), which were originally proposed for image generation <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13]</ref>, have recently been applied to dialog response generation <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b15">15]</ref>. Variational generative models, including variational autoencoders (VAEs) and CVAEs, are suitable for learning the 1-to-n mapping relationship due to their variational sampling mechanism for deriving latent representations.</p><p>This paper studies variational generative models for text generation in single-turn chit-chat conversations. The CVAE models used in previous work <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b15">15]</ref> all assumed a prior distribution of latent variable z followed a multivariate Gaussian distribution p θ (z|x) whose mean and variance were estimated by a prior network using condition x as input. However, previous studies on image generation <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b17">17]</ref> found that the samples of z from p θ (z|x) tended to be independent of x given estimated models, which implied that the effect of the condition x was constrained at the generation stage. In the conversation response generation task, the condition x is in the form of natural language. The semantic space of x in the training set is always sparse, which further increases the difficulty of estimating the prior network p θ (z|x). To address this issue of CVAEs, we propose condition-transforming variational autoencoders (CTVAEs) in this paper. In contrast to CVAEs, which use prior networks to describe p θ (z|x), a condition-independent prior distribution N (0, I) is adopted in CTVAEs. Then, another transformation network is built to derive the samples of z for decoding by transforming the combination of condition x and samples from N (0, I).</p><p>Specifically, the contributions of this paper are two-fold: First, the subjective preference tests in this paper demonstrate that there is no significant performance gap between the ordinary CVAE model and a simplified CVAE model whose prior distribution is fixed as a condition-independent distribution, i.e., N (0, I), which implies that the effects of the condition-dependent prior distribution in CVAE were limited. Second, a new model, called CTVAE, is proposed to enhance the effect of the conditions in CVAEs. This model samples the condition-dependent latent variable z by performing a non-linear transformation on the combination of the input condition and the samples from a condition-independent Gaussian distribution.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">From CVAE to CTVAE</head><p>Figure <ref type="figure" target="#fig_0">1</ref> shows directed graphical models of CVAE and CTVAE. In the single-turn short text conversation task, the condition x is the input post and y is the output response. As Figure <ref type="figure" target="#fig_0">1</ref>(a) shows, a CVAE is composed of a prior network p θ (z|x), a recognition network q φ (z|x, y), and a decoder network p θ (y|x, z). Both p θ (z|x) and q φ (z|x, y) are multivariate Gaussian distributions. The generative process of response y at testing stage is as follows: sample a z point from the prior distribution p θ (z|x), then feed it into decoder network p θ (y|x, z). CVAEs can be efficiently trained with the stochastic gradient variational Bayes (SGVB) <ref type="bibr" target="#b18">[18]</ref> framework by maximizing the lower bound of the conditional log likelihood log p(y|x) as follows,</p><p>LCV AE (θ, φ; x, y) = -KL(q φ (z|x, y)||p θ (z|x)) + E q φ (z|x,y) [log p θ (y|x, z)] ≤ log p(y|x).</p><p>As shown in Figure <ref type="figure" target="#fig_0">1</ref>(b), a CTVAE has no prior network but adopts N (0, I) as a transitional prior distribution p θ (t) to generate y. Similarly, a CTVAE includes a recognition network q φ (t|y) and a decoder network p θ (y|x, z). Additionally, CTVAEs use an alternative non-linear transformation network p θ (z|x, t) to sample the latent variable z from the combination of x and the samples of transitional latent variable t. Following the training strategy for CVAEs, the model parameters of CTVAEs can be estimated by maximizing the lower bound of the conditional log likelihood log p(y|x) as follows,</p><formula xml:id="formula_1">LCT V AE (θ, φ; x, y) = -KL(q φ (t|y)||p θ (t)) + E p θ (z|x,t)q φ (t|y) [log p θ (y|x, z)] ≤ log p(y|x).<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Model Implementation</head><p>The model architecture of the CTVAE implemented in this paper is shown in Figure <ref type="figure" target="#fig_1">2</ref>. Specifically, all the encoders and decoders are 1-layer recurrent neural networks with long short-term memory units. For an input post x = [x1, x2, ..., x lx ] with lx words, we can derive the corresponding output hidden states [h1, h2, ..., h lx ] by sending its word embedding sequence X = [x1, x2, ..., x lx ] into the Condition Encoder. Then, the mean pooling of hidden states [h1, h2, ..., h lx ] is used to present the condition post, denoted as</p><p>x. Similarly, we can derive vector representation y for response y by inputting Y = [y1, y2, ..., y ly ] into the Output Encoder. The Recognition Network is a multi-layer perceptron (MLP), which has a hidden layer with softplus activation and a linear output layer in our implementation. The recognition network predicts µ and log(σ 2 ) from y, which gives q φ (t|y) = N (µ, σ 2 I). The samples of the transitional latent variable t generated by q φ (t|y) are further used to derive the samples of latent variable z for reconstructing y during training. To guarantee the feasibility of error backpropagation for model training, reparametrization <ref type="bibr" target="#b18">[18]</ref> is performed to generate the samples of t. To derive the samples of latent variable z, the sampled t is concatenated with condition x and passed through a transformation network, which is a MLP with two hidden layers with tanh activation in our implementation. The output of the transformation network is used as the samples of latent variable z.</p><p>The initial hidden state of the OutputDecoder is x. At each time step of the 1-layer LSTM-RNN, the input is composed of the word embedding from the previous time step and the encoding vector enc, which is the concatenation of x and z samples. According to Eq. ( <ref type="formula" target="#formula_1">2</ref>), the summation of the log-likelihood of reconstructing y from the OutputDecoder and the negative KL divergence between q φ (t|y) and the prior distribution of the transitional latent variable p θ (t) = N (0, I) is used as the objective function for training.</p><p>In the CVAE built for comparison, all its encoders and decoder have identical structure to those in CTVAE. Both the recognition network and prior network have the same structure as the recognition network in CTVAE except that the recognition network accepts the concatenation of x and y as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Reranking Multiple Responses</head><p>To evaluate the performance of producing diverse responses using different models, multiple responses for each post are generated at the testing stage. Specifically, for the CVAE/CTVAE models, we first generatd multiple samples of z. Then, for each z sample, a beam search is adopted to return the best result. The multiple responses for each post are reranked using a topic coherence discrimination (TCD) model, which is trained based on the ESIM model <ref type="bibr" target="#b19">[19]</ref>. Specifically, we replace all BiLSTMs in the ESIM with 1-layer LSTMs and define the objective of the TCD model as judging whether a response is a valid response to a given post. In order to train the TCD model, all post-response pairs in the training set are used as positive samples and negative samples are constructed by randomly shuffling the mapping between posts and responses. Finally, ranking scores are adopted to rerank all responses generated for one post. The scores are calculated as log p θ (ỹ|c) + λ * log pT CD (true|x, ỹ), where the first term is the log-likelihood of generating response y using the decoder network and c is the condition input to the decoder, i.e., [x, z] in CVAE/CTVAE models. The second term is the loglikelihood of the output probability of the TCD model. λ represents the weight between these two terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset</head><p>The short text conversation (STC) dataset from NTCIR-12 <ref type="bibr" target="#b20">[20]</ref> was used in our experiments. This dataset was crawled from Chinese Sina Weibo 1 . The dataset contains 1, 800, 000 post-response pairs 2 , 1 <ref type="url" target="https://weibo.com/">https://weibo.com/</ref> 2 This dataset was originally prepared for retrieval models and had no standard division for generative models. Here we filtered the post-response and one post corresponds to an average of 19 responses. Therefore, it contains 1-to-n mapping relationship and is appropriate for studying diverse text generation methods. We randomly split the data into 1, 708, 415/73, 120/18, 465 pairs to build the training, development and test sets. There were no overlapping posts among these three sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Models in Our Experiments</head><p>In our experiments, we compared CTVAE with following three baseline models, i.e., Seq2Seq, CVAE-simple, and CVAE . We didn't include the models in NTCIR-12 contest because they were all retrieval models.</p><p>• Seq2Seq Like previous study, we used the encoder-decoder neural network with attention as the baseline model <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b15">15]</ref>, which was similar to that for machine translation <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b21">21]</ref>. Both the encoder and decoder were 1-layer LSTM-RNNs, and the attention weights were obtained by the inner product of the hidden states.</p><p>• CVAE-simple &amp; CVAE The CVAE model has been described in Section 2.2. As described in Section 1, the prior distribution p θ (z|x) in CVAEs was previously found to degrade to p θ (z). To verify this, we manually removed the prior network p θ (z|x) in the CVAE and fixed the prior distribution to p θ (z) = N (0, I). This modified CVAE model was denoted as CVAE-simple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Parameter Setting</head><p>We trained the models in our experiments with the following hyperparameters. All word embeddings, hidden layers of the recognition network and prior network, hidden layers of the transformation network, and hidden state vectors of the encoders and decoders had 300 dimensions. The latent variables t in CTVAE and z in CVAE had 100 dimensions. Each encoder and decoder had word embeddings of its own, and the vocabulary size was 35, 000. All word embeddings and model parameters were initialized randomly with Gaussian-distributed samples. The method of Adam <ref type="bibr" target="#b22">[22]</ref> was adopted for optimization with initial learning rate 5e -04. The batch size was set to 128. When training the CVAEs and CTVAEs, the KL annealing strategy <ref type="bibr" target="#b23">[23]</ref> was adopted to address the issue of latent variable vanishing. The model parameters were pre-trained without optimizing the KL divergence term. Additionally, we also adopted a training strategy which optimized the KLD loss term every 3 steps but optimized the reconstruction non-negative log likelihood pairs in raw STC dataset according to word frequencies to built our dataset. (NLL) loss term every 1 step. As described in Section 2.3, we generated multiple responses for each post. Specifically, for CVAE and CTVAE models, the number of z samples was set to 50, the beam search size was 20. For Seq2Seq, a beam search with beam size 50 was used to return multiple responses. The weight λ for reranking was heuristically set to 5. The top-5 responses after reranking were used for evaluation in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Objective Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Fluency</head><p>We trained a RNN language model (LM) <ref type="bibr" target="#b24">[24]</ref> using the same STC dataset to evaluate the fluency of the generated responses by calculating their perplexities, denoted as PPL on LM here. Furthermore, the percentage of generated responses that exactly matched any responses in the training set were counted. This matching percentage was used as a metric to evaluate the model's ability to generate fluency sentences with reasonable syntactic and semantic representations. For each model, 50 responses were generated for 512 unique posts in the test set, and the responses were reranked using the methods described in Section 2.  <ref type="table" target="#tab_4">3</ref>. Average preference scores (std.) (%) on fluency, topic relevance, and informativeness score between three model pairs (P1-P3), where N/P stands for "no preference" and p denotes the p-value of a t-test between two models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Diversity</head><p>The percentages of distinct unigrams and bigrams <ref type="bibr" target="#b6">[6]</ref> in the generated top-5 responses were used to evaluate the diversity of the generated responses. These two percentages, denoted as distinct-1 and distinct-2, respectively, represented the diversity at the n-gram level. We also counted the percentage of unique response sentences, which evaluated the diversity of responses at sentence level. The results for the four models are presented in Table <ref type="table" target="#tab_2">2</ref>. It can be found that the Seq2Seq model had the worst diversity at both the n-gram level and the sentence level. CVAE performed slightly better than CVAE-simple. And both CVAE models achieved better diversity at n-gram level than that of the CTVAE model, especially for distinct-2. According to the results of Section 3.4.1, the CVAE models performed worst on fluency performance, which may lead to higher diversity at the surface-text level. For the diversity at sentence level, the percentage of unique responses achieved by CTVAE was close to that of CVAE models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Subjective Evaluation</head><p>It is difficult to evaluate the final performance of the generated conversation responses using objective metrics, such as BLEU. It has been argued that such objective metrics for machine translation are very weakly correlated with human judgment in dialog generation <ref type="bibr" target="#b25">[25]</ref>. To evaluate the responses generated by our models in a more comprehensive and convincing manner, several groups of subjective ABX preference tests were conducted. We randomly chose 50 posts from the test set and generated the top-5 responses from each model for each post. The responses generated by two models were compared in each test. Five native Chinese speakers with rich Sina Weibo experience were recruited for the evaluation.</p><p>For each test post, a pairs of top-5 responses generated by two models were presented in random order. The evaluators were asked to judge which top-5 responses in each pair were preferred or if there was no preference on three subjective metrics: fluency, topic relevance, and informativeness score. Fluency was used to evaluate the quality of grammar and the semantic logic of responses. Topic relevance measured whether a response matched the topic of the given post. Informativeness measured how informative and interesting a response was. In addition to calculating the average preference scores, the p-value of a t-test was adopted to measure the significance of the difference between two models. Several significance levels were examined, including p &lt; 0.05, p &lt; 0.01, and p &lt; 0.001. p &gt; 0.05 indicated that there was no significant difference between two models. The subjective evaluation results are presented in Table <ref type="table" target="#tab_4">3</ref>.</p><p>According to results of model pair P2 in Table <ref type="table" target="#tab_4">3</ref>, we can  see that there is no significant difference on all three metrics between CVAE and CVAE-simple whose prior latent distribution was condition-independent, which implies that the effects of the condition-dependent prior distribution in the CVAE model were limited. From the model pair P1, it can be found that CVAE outperformed Seq2Seq significantly on all metrics except fluency. On the other hand, the results of model pair P3 show that CTVAE outperformed CVAE significantly on all three metrics, which confirms the effectiveness of our proposed CTVAE model. These results indicate that our CTVAE model can derive z samples with better condition-dependency than CVAE model. Case study Figure <ref type="figure">3</ref> shows one typical example of the top-5 responses generated by the Seq2Seq, CVAE, and CTVAE models. We can see that the Seq2Seq model tend to generate dull and generic responses. Furthermore, the responses of CTVAE tended to be more topic relevant and informative than those of CVAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>We have proposed a model named condition-transforming variational autoencoder (CTVAE) for diverse text generation. In this model, the samples of latent variable z are derived by performing a non-linear transformation on the combination of the input condition and the samples from a prior Gaussian distribution N (0, I). In our experiments on single-turn short text conversation, the CTVAE outperformed the Seq2Seq and CVAE models in both objective and subjective evaluations, which indicates that the CTVAE can derive z samples with better condition-dependency than CVAE models. Applying the proposed CTVAE model to multi-turn conversation response generation and pursuing controllable sampling of the latent variable z will be our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Graphical models of (a) CVAE, and (b) CTVAE. In each subgraph, the left part shows the recognition process of latent variable z during the training stage, and the right part shows the process of generating y during the testing stage. The dashed lines and the single solid lines represent the recognition network and the decoder network respectively. The double solid line in (a) and the thick solid lines in (b) denote the prior network and the transformation network respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The model architecture of the CTVAE implemented in this paper.denotes the concatenation of input vectors. All the encoders and decoders are 1-layer LSTM-RNNs, both recognition network and transformation network are MLPs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>285 8 Fig. 3 .</head><label>83</label><figDesc>Fig. 3. An example of the top-5 responses generated by Seq2Seq, CVAE, and CTVAE for the post "It will be sunny after the rain in Beijing today. night owls, please get up early today.(今天北京雨后天 晴，熬夜人啊，早起吧。)".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>In our experiments of generating short text conversations, the CTVAE model outperforms CVAE on objective fluency metrics and surpasses a sequence-to-sequence (Seq2Seq) model on objective diversity metrics. In subjective preference tests, our proposed CTVAE model performs significantly better than CVAE and Seq2Seq models on generating fluency, informative and topic relevant responses.</figDesc><table><row><cell>y</cell><cell>)</cell><cell cols="4">( ) z ~ p z </cell><cell>q z | ( </cell><cell>) x, y</cell><cell cols="3">z ~ p z | ( </cell><cell>) x</cell><cell>p z | t (  x,</cell><cell>)</cell><cell>p z | t (  x,</cell><cell>)</cell></row><row><cell></cell><cell></cell><cell></cell><cell>z</cell><cell></cell><cell>x</cell><cell>z</cell><cell>x</cell><cell>z</cell><cell></cell><cell></cell><cell>x</cell><cell>z</cell><cell>x</cell><cell>z</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>t</cell><cell>t</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>q t | ( </cell><cell>y</cell><cell>)</cell><cell>t ~ p t ( ) </cell></row><row><cell></cell><cell></cell><cell></cell><cell>y</cell><cell></cell><cell></cell><cell>y</cell><cell></cell><cell>y</cell><cell></cell><cell></cell><cell></cell><cell>y</cell><cell>y</cell></row><row><cell></cell><cell></cell><cell>p</cell><cell>(  y |</cell><cell>z</cell><cell>)</cell><cell></cell><cell>p</cell><cell>(  y x, |</cell><cell>z</cell><cell>)</cell><cell></cell><cell>p</cell><cell>(  y x, |</cell><cell>z</cell><cell>)</cell></row><row><cell cols="2">a)VAE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(a)CVAE</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)CTVAE</cell></row><row><cell></cell><cell></cell><cell cols="4">arXiv:1904.10610v1 [cs.CL] 24 Apr 2019</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>The objective fluency performance of different models.</figDesc><table><row><cell></cell><cell cols="4">Seq2Seq CVAE-simple CVAE CTVAE</cell></row><row><cell>PPL on LM Matching(%)</cell><cell>7.61 92.58</cell><cell>31.82 8.12</cell><cell>36.96 10.51</cell><cell>21.75 19.10</cell></row><row><cell></cell><cell cols="4">Seq2Seq CVAE-simple CVAE CTVAE</cell></row><row><cell>Distinct-1(%) Distinct-2(%) Unique(%)</cell><cell>1.61 5.26 22.86</cell><cell>10.26 41.23 97.66</cell><cell>11.52 42.6 97.78</cell><cell>8.69 33.44 97.62</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>The objective diversity performance of different models.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc><ref type="bibr" target="#b3">3</ref>. The average LM perplexity and matching percentage of all top-5 responses were calculated for each model and the results are presented in Table1. It can be found that the Seq2Seq model achieved the lowest perplexity on LM and the highest matching percentage because it tended to generate its dull, generic and repeated responses. The CVAE models performed worst on these two fluency metrics. For CTVAE, it performed much better than the CVAE models on both LM perplexity and matching percentage.</figDesc><table><row><cell>Fluency Topic relevance Informativeness</cell><cell>Pair No. Seq2Seq CVAE-simple P1 32.8(4.0) -P2 -25.6(1.6) P3 --P1 17.2(1.7) -P2 -28.0(1.9) P3 --P1 6.4(0.9) -P2 -28.4(2.3) P3 --</cell><cell>CVAE 40.4(6.0) 32.4(1.7) 23.6(3.4) 41.2(2.9) 35.2(6.0) &lt; 0.001 N/P p CTVAE -26.8(5.3) &gt; 0.05 -42.0(3.0) &gt; 0.05 63.2(3.2) -19.6(2.9) &lt; 0.001 34.4(1.1) -37.6(2.5) &gt; 0.05 29.6(2.4) 40.8(1.9) 29.6(4.1) &lt; 0.05 79.6(3.1) -14.0(2.7) &lt; 0.001 28.0(2.1) -43.6(4.2) &gt; 0.05 32.4(2.2) 47.2(1.1) 20.4(2.6) &lt; 0.01</cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Average preference scores (std.) (%) on fluency, topic relevance, informativeness, and general score between three model pairs (C1-C3), where N/P stands for "no preference" and p denotes the p-value of a t-test between two models.</figDesc><table><row><cell>Fluency Topic relevance Informativeness General</cell><cell>C# Seq2Seq CVAE-simple C1 32.8(4.0) -C2 -25.6(1.6) C3 --C1 17.2(1.7) -C2 -28.0(1.9) C3 --C1 6.4(0.9) -C2 -28.4(2.3) C3 --C1 16.0(2.9) -C2 -30.8(1.9) C3 --</cell><cell>CVAE 40.4(6.0) 32.4(1.7) 23.6(3.4) 41.2(2.9) 35.2(6.0) &lt; 0.001 CTVAE N/P p -26.8(5.3) &gt; 0.05 -42.0(3.0) &gt; 0.05 63.2(3.2) -19.6(2.9) &lt; 0.001 34.4(1.1) -37.6(2.5) &gt; 0.05 29.6(2.4) 40.8(1.9) 29.6(4.1) &lt; 0.05 79.6(3.1) -14.0(2.7) &lt; 0.001 28.0(2.1) -43.6(4.2) &gt; 0.05 32.4(2.2) 47.2(1.1) 20.4(2.6) &lt; 0.01 73.6(3.3) -10.4(1.6) &lt; 0.001 36.4(1.4) -32.8(2.8) &gt; 0.05 30.8(2.4) 54.4(1.1) 14.8(1.9) &lt; 0.001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>An example of the top-5 responses generated by Seq2Seq, CVAE, and CTVAE for the post "It will be sunny after the rain in Beijing today. night owls, please get up early today.(今天北京雨后天</figDesc><table><row><cell cols="2">晴，熬夜人啊，早起吧。)".</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Seq2Seq</cell><cell>CVAE</cell><cell>CTVAE</cell></row><row><cell>top-1</cell><cell>是什么软件？ What's this software?</cell><cell>早安。。。 Good morning...</cell><cell>早起的鸟儿有虫吃的 The early bird catches the worm</cell></row><row><cell>top-2</cell><cell>还没睡呢 Haven't slept yet?</cell><cell>失眠的！！ Sleepless!!</cell><cell>早睡早起身体好好 Early to bed and early to rise makes a man healthy</cell></row><row><cell>top-3</cell><cell></cell><cell></cell><cell>北京下雨了 It's rainy in Beijing</cell></row><row><cell></cell><cell></cell><cell></cell><cell>帝都的天气啊！</cell></row><row><cell>top-4</cell><cell></cell><cell></cell><cell>What a weather in the city of emperors!</cell></row><row><cell>top-5</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p><p><p>还没睡啊 Haven't slept yet! 今儿今天！！ Today and today!! 我也在北京 I'm in Beijing, too. 早上起床了…… Got up in the morning... 我也想去北京 I want to go to Beijing, too 今天也迟到了吧？ Are you late today too? 北京天气很好的天气 Good weather in Beijing</p>According to results of model pair C2 in Table</p>3</p>, we can see that there is no significant difference 275 on all four metrics between CVAE and CVAE-simple whose prior latent distribution was condition-276 independent, which confirms again that the effects of the condition-dependent prior distribution in 277 the CVAE model were limited. From the model pair C1, it can be found that CVAE outperformed 278 Seq2Seq significantly on all metrics except fluency. On the other hand, the results of model pair C3 279 show that CTVAE outperformed CVAE significantly on all four metrics. 280 Table 4 shows one typical example of the top-5 responses generated by the Seq2Seq, CVAE, and 281 CTVAE models. We can see that the responses generated by Seq2Seq were dull and generic compared 282 with those generated by CVAE and CTVAE. Furthermore, the responses of CTVAE tended to be 283 more topic relevant and informative than those of CVAE.</p></note></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This work was partially funded by the <rs type="funder">National Nature Science Foundation of China</rs> (Grant No. <rs type="grantNumber">U1636201</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MQtp6qW">
					<idno type="grant-number">U1636201</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Alexander M Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="379" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">February 12-17, 2016. 2016</date>
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03055</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Topic aware neural response generation</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yalou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3351" to="3357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01932</idno>
		<title level="m">A knowledge-grounded neural conversation model</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Neural response generation with dynamic vocabularies</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dejian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11191</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mechanism-aware neural machine for dialogue response generation</title>
		<author>
			<persName><forename type="first">Ganbin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongyu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3400" to="3407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3483" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Attribute2image: Conditional image generation from visual attributes</title>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="776" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Vlad Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3295" to="3301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Generating thematic chinese poetry with conditional variational autoencoder</title>
		<author>
			<persName><forename type="first">Xiaopeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunda</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07632</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Diederik P Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Overview of the ntcir-12 short text conversation task</title>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryuichiro</forename><surname>Higashinaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<editor>NTCIR</editor>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName><forename type="first">Luke</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>The 20th SIGNLL Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="10" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName><forename type="first">Tomáš</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukáš</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Černockỳ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
