<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Probabilistic Generative Model for Typographical Analysis of Early Modern Printing</title>
				<funder ref="#_zcxbUpB #_strkWsR">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_5awCcW6">
					<orgName type="full">NEH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-05-04">4 May 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kartik</forename><surname>Goyal</surname></persName>
							<email>kartikgo@andrew.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
							<email>cdyer@google.com</email>
						</author>
						<author>
							<persName><forename type="first">Christopher</forename><surname>Warren</surname></persName>
							<email>cnwarren@andrew.cmu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of English</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Max</forename><surname>G'sell</surname></persName>
							<email>mgsell@andrew.cmu.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Deepmind</surname></persName>
						</author>
						<title level="a" type="main">A Probabilistic Generative Model for Typographical Analysis of Early Modern Printing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-05-04">4 May 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2005.01646v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a deep and interpretable probabilistic generative model to analyze glyph shapes in printed Early Modern documents. We focus on clustering extracted glyph images into underlying templates in the presence of multiple confounding sources of variance. Our approach introduces a neural editor model that first generates well-understood printing phenomena like spatial perturbations from template parameters via interpertable latent variables, and then modifies the result by generating a non-interpretable latent vector responsible for inking variations, jitter, noise from the archiving process, and other unforeseen phenomena associated with Early Modern printing. Critically, by introducing an inference network whose input is restricted to the visual residual between the observation and the interpretably-modified template, we are able to control and isolate what the vector-valued latent variable captures. We show that our approach outperforms rigid interpretable clustering baselines (Ocular) and overly-flexible deep generative models (VAE) alike on the task of completely unsupervised discovery of typefaces in mixed-font documents.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scholars interested in understanding details related to production and provenance of historical documents rely on methods of analysis ranging from the study of orthographic differences and stylometrics, to visual analysis of layout, font, and printed characters. Recently developed tools like Ocular <ref type="bibr" target="#b1">(Berg-Kirkpatrick et al., 2013)</ref> for OCR of historical documents have helped automate and scale some textual analysis methods for tasks like compositor attribution <ref type="bibr" target="#b14">(Ryskina et al., 2017)</ref> and digitization of historical documents <ref type="bibr" target="#b5">(Garrette et al., 2015)</ref>. However, researchers often find the need to go beyond textual analysis for establishing provenance of historical documents. For example, <ref type="bibr" target="#b7">Hinman (1963)</ref>'s study of typesetting in Shakespeare's First Folio relied on the discovery of pieces of damaged or distinctive type through manual inspection of every glyph in the document. More recently, <ref type="bibr">Warren et al. (2020)</ref> examine pieces of distinctive types across several printers of the early modern period to posit the identity of clandestine printers of John Milton's Areopagitica (1644). In such work, researchers frequently aim to determine whether a book was produced by a single or multiple printers <ref type="bibr" target="#b18">(Weiss (1992)</ref>; <ref type="bibr" target="#b12">Malcolm (2014)</ref>; <ref type="bibr" target="#b16">Takano (2016)</ref>). Hence, in order to aid these visual methods of analyses, we propose here a novel probabilistic generative model for analyzing extracted images of individual printed characters in historical documents. We draw from work on both deep generative modeling and interpretable models of the printing press to develop an approach that is both flexible and controllable -the later being a critical requirement for such analysis tools.</p><p>As depicted in Figure <ref type="figure" target="#fig_0">1</ref>, we are interested in identifying clusters of subtly distinctive glyph shapes as these correspond to distinct metal stamps in the type-cases used by printers. However, other sources of variation (inking, for example, as depicted in Figure <ref type="figure" target="#fig_0">1</ref>) are likely to dominate conventional clustering methods. For example, powerful models like the variational autoencoder (VAE) (Kingma and Welling, 2014) capture the more visually salient variance in inking rather than typeface, while more rigid models (e.g. the emission model of Ocular <ref type="bibr" target="#b1">(Berg-Kirkpatrick et al., 2013)</ref>), fail to fit the data. The goal of our approach is to account for these confounding sources of variance, while isolating the variables pertinent to clustering.</p><p>Hence, we propose a generative clustering model that introduces a neural editing process to add expressivity, but includes interpretable latent variables that model well-understood variance in the printing process: bi-axial translation, shear, and rotation of canonical type shapes. In order to make our model controllable and prevent deep latent variables from explaining all variance in the data, we introduce a restricted inference network. By only allowing the inference network to observe the visual residual of the observation after interpretable modifications have been applied, we bias the posterior approximation on the neural editor (and thus the model itself) to capture residual sources of variance in the editor -for example, inking levels, ink bleeds, and imaging noise. This approach is related to recently introduced neural editor models for text generation <ref type="bibr" target="#b6">(Guu et al., 2018)</ref>.</p><p>In experiments, we compare our model with rigid interpretable models (Ocular) and powerful generative models (VAE) at the task of unsupervised clustering subtly distinct typeface in scanned images early modern documents sourced from Early English Books Online (EEBO).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>Our model reasons about the printed appearances of a symbol (say majuscule F) in a document via a mixture model whose K components correspond to different metal stamps used by a printer for the document. During various stages of printing, random transformations result in varying printed manifestations of a metal cast on the paper. Figure <ref type="figure" target="#fig_1">2</ref> depicts our model. We denote an observed image of the extracted character by X. We denote choice of typeface by latent variable c (the mixture component) with prior π. We represent the shape of the k-th stamp by template T k , a square matrix of parameters. We denote the interpretable latent variables corresponding to spatial adjustment of the metal stamp by λ, and the editor latent variable responsible for residual sources of variation by z. As illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>, after a cluster component c = k is selected, the corresponding template T k undergoes a transformation to yield Tk . This transformation occurs in two stages: first, the interpretable spatial adjustment variables (λ) produce an adjusted template ( §2.1), Tk = warp(T k , λ), and then the neural latent variable transforms the adjusted template ( §2.2), Tk = filter( Tk , z). The marginal probability under our model can be written as</p><formula xml:id="formula_0">p(X) = k π k p(X|λ, z; T k )p(λ)p(z)dzdλ</formula><p>where p(X|λ, z; T k ) refers to the distribution over the binary pixels of X where each pixel has a bernoulli distribution parametrized by the value of the corresponding pixel-entry in Tk .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Interpretable spatial adjustment</head><p>Early typesetting was noisy, and the metal pieces were often arranged with slight variations which resulted in the printed characters being positioned with small amounts of offset, rotation and shear. These real-valued spatial adjustment variables are denoted by λ = (r, o, s, a), where r represents the rotation variable, o = (o h , o v ) represents offsets along the horizontal and vertical axes, s = (s h , s v ) denotes shear along the two axes. A scale factor, ã = 1.0 + a, accounts for minor scale variations arising due to the archiving and extraction processes. All variables in λ are generated from a Gaussian prior with zero mean and fixed variance as the transformations due to these variables tend to be subtle.</p><p>In order to incorporate these deterministic transformations in a differentiable manner, we map λ to a template sized attention map H ij for each output pixel position (i, j) in T as depicted in Figure <ref type="figure" target="#fig_2">3</ref>. The attention map for each output pixel is formed in order to attend to the corresponding shifted (or scaled or sheared) portion of the input template and is shaped according to a Gaussian distribution with mean determined by an affine transform. This approach allows for strong inductive bias which contrasts with related work on spatial-VAE <ref type="bibr" target="#b0">(Bepler et al., 2019)</ref> that learns arbitrary transformations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Residual sources of variations</head><p>Apart from spatial perturbations, other major sources of deviation in early printing include random inking perturbations caused by inconsistent application of the stamps, unpredictable ink bleeds, and noise associated with digital archiving of the documents. Unlike in the case of spatial perturbations which could be handled by deterministic affine transformation operators, it is not possible to analytically define a transformation operator due to these variables. Hence we propose to introduce a non-interpretable real-valued latent vector z, with a Gaussian prior N (0, I) , that transforms T into a final template T via neurally-parametrized function filter( T , z; θ) with neural network parameters θ. This function is a convolution over T whose kernel is parametrized by z, followed by non-linear operations. Intuitively, parametrizing the filter by z results in the latent variable accounting for variations like inking appropriately because convolution filters capture local variations in appearance. Srivatsan et al. ( <ref type="formula">2019</ref>) also observed the effectiveness of using z to define a deconvolutional kernel for font generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning and Inference</head><p>Our During training, we maximize the likelihood wrt. λ instead of marginalizing, which is an approximation inspired by iterated conditional modes <ref type="bibr" target="#b2">(Besag, 1986)</ref>:</p><formula xml:id="formula_1">max T,θ d log k max γ k,d π k p(X d |λ d = γ k,d , z d ; T k , θ)p(λ d = γ k,d )p(z d )dz d</formula><p>However, marginalizing over z remains intractable. Therefore we perform amortized variational inference to define and maximize a lower bound on the above objective (Kingma and Welling, 2014). We use a convolutional inference neural network parametrized by φ (Fig. <ref type="figure" target="#fig_3">4</ref>), that takes as input, the mixture component k, the residual image R k = X -Tk , and produces mean and variance parameters for an isotropic gaussian proposal distribution q(z | R k , k; φ). This results in the final training objective:</p><formula xml:id="formula_2">max T,θ,φ d log k E q(z d |R d,k ,k;φ) max γ k,d π k p(X d |λ = γ k,d , z d ; T k , θ)p(λ = γ k,d ) -KL q(z d |R d,k , k; φ)||p(z)</formula><p>We use stochastic gradient ascent to maximize this objective with respect to T, γ, θ and φ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We train our models on printed occurrences of 10 different uppercase character classes that scholars have found useful for bibliographic analysis <ref type="bibr">(Warren et al., 2020)</ref> because of their distinctiveness. As a preprocessing step, we ran Ocular (Berg-Kirkpatrick et al., 2013) on the grayscale scanned images of historical books in EEBO dataset and extracted the estimated image segments for the letters of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Quantitative analysis</head><p>We show that our model is superior to strong baselines at clustering subtly distinct typefaces (using realistic synthetic data), as well as in terms of fitting the real data from historical books. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Baselines for comparison</head><formula xml:id="formula_3">max T,θ,φ d log k E q(z d |X d ,k;φ) π k p(X d |z d ; T k , θ) -KL q(z d |X d , k; φ)||p(z)</formula><p>No-residual: The only difference from the full model is that the encoder for the inference network conditions the variational distribution q(z) on the entire input image X instead of just the residual image X -T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Font discovery in Synthetic Data</head><p>Early modern books were frequently composed from two or more type cases, resulting in documents with mixed fonts. We aim to learn the different shapes of metal stamps that were used as templates for each cluster component in our model. Data: In order to quantitatively evaluate our model's performance, we experiment with synthetically generated realistic dataset for which we know the ground truth cluster identities in the following manner: For each character of interest, we pick three distinct images from scanned segmented EEBO images, corresponding to three different metal casts. Then we randomly add spatial perurbations related to scale, offset, rotation and shear.</p><p>To incorporate varying inking levels and other distortions, we randomly either perform erosion, dilation, or a combination of these warpings using OpenCV <ref type="bibr" target="#b3">(Bradski, 2000)</ref> with randomly selected kernel sizes. Finally, we add a small Gaussian noise to the pixel intensities and generate 300 perturbed examples per character class.</p><p>Results: We report macro-averaged results across all the character classes on three different clustering measures, V-measure <ref type="bibr" target="#b13">(Rosenberg and Hirschberg, 2007)</ref>, Mutual <ref type="bibr">Information and Fowlkes and Mallows Index (Fowlkes and Mallows, 1983)</ref>. In Table <ref type="table" target="#tab_12">11</ref>, we see that our model significantly outperforms all other baselines on every metric. Ocular and λ-only models fail because they lack expressiveness to explain the variations due to random jitters, erosions and dilations. The VAE-only model, while very expressive, performs poorly because it lacks the inductive bias needed for successful clustering. The No-residual model performs decently but our model's superior performance emphasizes the importance of designing a restrictive inference network such that z doesn't explain any variation due to the interpretable variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Fitting Real Data from Historical Books</head><p>For the analysis of real books, we selected three books from the EEBO dataset printed by different printers. We modeled each character class for each book separately and report the macro-aggregated upper bounds on the negative log likelihood (NLL) in Table <ref type="table" target="#tab_12">11</ref>. We observe that adding a small amount of expressiveness makes our λ-only model better than Ocular. The upper bounds of other inference network based models are much better than the (likely tight)<ref type="foot" target="#foot_0">foot_0</ref> bounds of both the interpretable models. Our model has the lowest upper bound of all the models while retaining interpretability and control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Qualitative analysis</head><p>We provide visual evidence of desirable behavior of our model on collections of character extractions from historical books with mixed fonts. Specifically, we discus the performance of our model on the mysterious edition of Thomas Hobbes' Leviathan known as "the 25 Ornaments" edition. <ref type="bibr" target="#b8">(Hobbes, 1651</ref><ref type="bibr">(Hobbes, [really 1700?]?]</ref>). The 25 Ornaments Leviathan is an interesting test case for several reasons. While its title page indicates a publisher and year of publication, both are fabricated (Malcolm, 2014). The identities of its printer(s) remain speculative, and the actual year of publication is uncertain. Further, the 25 Ornaments exhibits two distinct fonts. Our model is successful in discovering distinctly shaped typefaces in the 25 Ornaments Leviathan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Quality of learned templates</head><p>We focus on the case study of majuscule letters F and R, each of which have two different typefaces mixed in throughout. The two typefaces for F differ in the length of the middle arm (Fig. <ref type="figure" target="#fig_0">1</ref>), and the two typefaces for R have differently shaped legs. In Fig. <ref type="figure" target="#fig_5">5</ref>, we show that our model successfully learns the two desired templates T 1 and T 2 for both the characters which indicates that the clusters in our model mainly focus on subtle differences in underlying glyph shapes. We also illustrate how the latent variables transform the model templates T to T</p><p>for four example F images. The model learns complex functions to transform the templates which go beyond simple affine and morphological transformations in order to account for inking differences, random jitter, contrast variations etc. Finally, we visualize the ability of our model to separate responsibility of modelling variation among the interpretable and non-interpretable variables appropriately. We use the inferred values of the interpretable (λ) variable for each image in the dataset to adjust the corresponding image. Since the templates represent the canonical shape of the letters, the λ variables which shift the templates to explain the images can be reverse applied to the input images themselves in order to align them by accounting for offset, rotation, shear and minor size variations. In Fig. <ref type="figure" target="#fig_6">6</ref>, we see that the input images (top row) are uneven and vary by size and orientation. By reverse applying the inferred λ values, we are able to project the images to a fixed size such that they are aligned and any remaining variations in the data are caused by other sources of variation. Moreover, this alignment method would be crucial for automating certain aspects of bibliographic studies that focus on comparing specific imprints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Interpretable variables (λ) and Control</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Beyond applications to typeface clustering, the general approach we take might apply more broadly to other clustering problems, and the model we devel-oped might be incorporated into OCR models for historical text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Character wise quantitative analysis</head><p>The quantitative experiments were performed on the following character classes: A, B, E, F, G, H, M, N, R, W.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: We desire a generative model that can be biased to cluster according to typeface characteristics (e.g. the length of the middle arm) rather than other more visually salient sources of variation like inking.</figDesc><graphic coords="1,325.98,232.89,178.13,113.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Proposed generative model for clustering images of a symbol by typeface. Each mixture component c corresponds to a learnable template T k . The λ variables warp (spatially adjust) the original template T to T . This warped template is then further transformed via the z variables to T via an expressive neural filter function parametrized by θ.</figDesc><graphic coords="2,307.28,62.81,221.89,226.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Translation operation: The mode of the attention map is shifted by the offset values for every output pixel in T . Similar operations account for shear, rotation, and scale.</figDesc><graphic coords="3,113.09,348.53,133.37,59.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Inference network for z conditions on the mixture component and only the residual image left after subtracting the λ-transformed template from the image. This encourages z to model variance due to sources other than spatial adjustments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>aim is to maximize the log likelihood of the observed data ({X d | d ∈ N, d &lt; n}) of n images wrt. model parameters: LL(T 1,...,k , θ) = max d |λ d , z d ; T k , θ)p(λ d )p(z d )dz d dλ d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The learned templates for F and R and the transformed templates T for four examples of F are shown. Our model is able to learn desirable templates based on underlying glyph structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Result of alignment on Leviathan extractions using the interpretable λ variables along with their pixelwise average images. Aligned average image is much sharper than the unaligned average image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>(a)  Clustering results on synthetic data (V-measure,</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>Ocular</cell><cell>0.42</cell><cell>0.45</cell><cell>0.61</cell><cell>379.21</cell></row><row><cell>λ-only</cell><cell>0.49</cell><cell>0.51</cell><cell>0.70</cell><cell>322.04</cell></row><row><cell>VAE-only</cell><cell>0.22</cell><cell>0.29</cell><cell>0.38</cell><cell>263.45</cell></row><row><cell cols="2">No-residual 0.54</cell><cell>0.58</cell><cell>0.73</cell><cell>264.27</cell></row><row><cell cols="2">Our Model 0.73</cell><cell>0.74</cell><cell>0.85</cell><cell>257.92</cell></row><row><cell cols="5">Mutual Info, F&amp;M). (b) Test negative log likelihood (NLL)</cell></row><row><cell cols="5">on real data from historical documents, or negative ELBO</cell></row><row><cell cols="3">bound for intractable models (NLL).</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results for character A</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.37</cell><cell>0.39</cell><cell>0.59</cell><cell>261.1</cell></row><row><cell>VAE-only</cell><cell>0.15</cell><cell>0.2</cell><cell>0.32</cell><cell>229.1</cell></row><row><cell cols="2">No-residual 0.37</cell><cell>0.39</cell><cell>0.58</cell><cell>228.1</cell></row><row><cell cols="2">Our Model 0.68</cell><cell>0.73</cell><cell>0.81</cell><cell>226.25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results for character B</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.33</cell><cell>0.36</cell><cell>0.55</cell><cell>282.4</cell></row><row><cell>VAE-only</cell><cell>0.17</cell><cell>0.19</cell><cell>0.30</cell><cell>253.2</cell></row><row><cell cols="2">No-residual 0.33</cell><cell>0.35</cell><cell>0.56</cell><cell>251.45</cell></row><row><cell cols="2">Our Model 0.65</cell><cell>0.70</cell><cell>0.76</cell><cell>234.05</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Results for character E</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.09</cell><cell>0.10</cell><cell>0.55</cell><cell>258.40</cell></row><row><cell>VAE-only</cell><cell>0.03</cell><cell>0.05</cell><cell>0.31</cell><cell>218.2</cell></row><row><cell cols="2">No-residual 0.12</cell><cell>0.09</cell><cell>0.59</cell><cell>208.1</cell></row><row><cell cols="2">Our Model 0.81</cell><cell>0.56</cell><cell>0.94</cell><cell>204.48</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Results for character F</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.60</cell><cell>0.62</cell><cell>0.73</cell><cell>268.40</cell></row><row><cell>VAE-only</cell><cell>0.28</cell><cell>0.38</cell><cell>0.40</cell><cell>250.8</cell></row><row><cell cols="2">No-residual 0.64</cell><cell>0.66</cell><cell>0.77</cell><cell>244.5</cell></row><row><cell cols="2">Our Model 0.60</cell><cell>0.62</cell><cell>0.73</cell><cell>240.84</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Results for character G</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.72</cell><cell>0.71</cell><cell>0.79</cell><cell>313.75</cell></row><row><cell>VAE-only</cell><cell>0.32</cell><cell>0.32</cell><cell>0.40</cell><cell>254.2</cell></row><row><cell cols="2">No-residual 0.90</cell><cell>0.97</cell><cell>0.94</cell><cell>258.8</cell></row><row><cell cols="2">Our Model 0.92</cell><cell>1.01</cell><cell>0.96</cell><cell>249.81</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Results for character H</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.62</cell><cell>0.64</cell><cell>0.78</cell><cell>392.06</cell></row><row><cell>VAE-only</cell><cell>0.29</cell><cell>0.38</cell><cell>0.40</cell><cell>323.5</cell></row><row><cell cols="2">No-residual 0.70</cell><cell>0.83</cell><cell>0.74</cell><cell>329.25</cell></row><row><cell cols="2">Our Model 0.75</cell><cell>0.84</cell><cell>0.87</cell><cell>323.04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Results for character M</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.65</cell><cell>0.70</cell><cell>0.73</cell><cell>331.6</cell></row><row><cell>VAE-only</cell><cell>0.30</cell><cell>0.45</cell><cell>0.40</cell><cell>265.2</cell></row><row><cell cols="2">No-residual 0.74</cell><cell>0.81</cell><cell>0.82</cell><cell>270.11</cell></row><row><cell cols="2">Our Model 0.69</cell><cell>0.75</cell><cell>0.75</cell><cell>264.23</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Results for character N</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.07</cell><cell>0.08</cell><cell>0.55</cell><cell>330.6</cell></row><row><cell>VAE-only</cell><cell>0.03</cell><cell>0.04</cell><cell>0.34</cell><cell>247.1</cell></row><row><cell cols="2">No-residual 0.06</cell><cell>0.07</cell><cell>0.53</cell><cell>251.32</cell></row><row><cell cols="2">Our Model 0.46</cell><cell>0.32</cell><cell>0.78</cell><cell>246.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Results for character R</figDesc><table><row><cell></cell><cell cols="4">V-measure Mutual Info F&amp;M NLL</cell></row><row><cell>λ-only</cell><cell>0.65</cell><cell>0.71</cell><cell>0.79</cell><cell>418.01</cell></row><row><cell>VAE-only</cell><cell>0.31</cell><cell>0.45</cell><cell>0.42</cell><cell>364.2</cell></row><row><cell cols="2">No-residual 0.72</cell><cell>0.78</cell><cell>0.82</cell><cell>369.5</cell></row><row><cell cols="2">Our Model 0.72</cell><cell>0.79</cell><cell>0.84</cell><cell>364.21</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 11 :</head><label>11</label><figDesc>Results for character W</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For Ocular and λ-only models, we report the upper bound obtained via maximization over the interpretable latent variables. Intuitively, these latent variables are likely to have unimodal posterior distributions with low variance, hence this approximation is likely tight.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgements</head><p>This project is funded in part by the <rs type="funder">NSF</rs> under grants <rs type="grantNumber">1618044</rs> and <rs type="grantNumber">1936155</rs>, and by the <rs type="funder">NEH</rs> under grant <rs type="grantNumber">HAA256044-17</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_zcxbUpB">
					<idno type="grant-number">1618044</idno>
				</org>
				<org type="funding" xml:id="_strkWsR">
					<idno type="grant-number">1936155</idno>
				</org>
				<org type="funding" xml:id="_5awCcW6">
					<idno type="grant-number">HAA256044-17</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Explicitly disentangling image content from translation and rotation with spatial-vae</title>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Bepler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kotaro</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Brignole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bonnie</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15409" to="15419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised transcription of historical documents</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Sofia, Bulgaria. Association for Computational Linguistics</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="207" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the statistical analysis of dirty pictures</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="279" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
		<title level="m">The OpenCV Library. Dr. Dobb&apos;s Journal of Software Tools</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A method for comparing two hierarchical clusterings</title>
		<author>
			<persName><forename type="first">B</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">L</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><surname>Mallows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical association</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">383</biblScope>
			<biblScope unit="page" from="553" to="569" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised code-switching for multilingual historical document transcription</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Alpert-Abrams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/N15-1109</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Denver, Colorado. Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1036" to="1041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generating sentences by editing prototypes</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="437" to="450" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The printing and proofreading of the first folio of Shakespeare</title>
		<author>
			<persName><forename type="first">Charlton</forename><surname>Hinman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963">1963</date>
			<publisher>Clarendon Press</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Hobbes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1651">1651</date>
		</imprint>
	</monogr>
	<note>really 1700?</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">the matter, form, and power of a common-wealth ecclesiastical and civil. By Thomas Hobbes of Malmesbury</title>
		<author>
			<persName><forename type="first">Or</forename><surname>Leviathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Number R13935 in ESTC</title>
		<meeting><address><addrLine>St. Pauls Church-yard, London</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>printed for Andrew Crooke</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Autoencoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations, ICLR 2014</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14">2014. April 14-16, 2014</date>
		</imprint>
	</monogr>
	<note>Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Durk P Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Editorial Introduction</title>
		<author>
			<persName><forename type="first">Noel</forename><surname>Malcolm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Leviathan</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Clarendon Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Vmeasure: A conditional entropy-based external cluster evaluation measure</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 joint conference on empirical methods in natural language processing and computational natural language learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 joint conference on empirical methods in natural language processing and computational natural language learning (EMNLP-CoNLL)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="410" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic compositor attribution in the first folio of shakespeare</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Ryskina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Alpert-Abrams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-2065</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="411" to="416" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A deep factorization of style and structure in fonts</title>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Srivatsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1225</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2195" to="2205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">Akira</forename><surname>Takano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thomas Warren: A Printer of Leviathan</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
	<note>head edition</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Shruti Rijhwani, and Max G&apos;Sell. 2020. Damaged type and Areopagitica&apos;s clandestine printers</title>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">N</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierce</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<publisher>Milton Studies</publisher>
			<biblScope unit="page" from="62" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shared Printing, Printer&apos;s Copy, and the Text(s) of Gascoigne&apos;s &quot;A Hundreth Sundrie Flowres</title>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Bibliography</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="71" to="104" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
