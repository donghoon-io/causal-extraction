<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Point Cloud Based Reconstruction of Large-Scale Outdoor Scenes</title>
				<funder ref="#_AfSxwhG">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-05-23">23 May 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ziquan</forename><surname>Lan</surname></persName>
							<email>ziquan@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zi</forename><surname>Jian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yew</forename><surname>Gim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hee</forename><surname>Lee</surname></persName>
							<email>gimhee.lee@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Point Cloud Based Reconstruction of Large-Scale Outdoor Scenes</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-05-23">23 May 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1905.09634v1[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Outlier feature matches and loop-closures that survived front-end data association can lead to catastrophic failures in the back-end optimization of large-scale point cloud based 3D reconstruction. To alleviate this problem, we propose a probabilistic approach for robust back-end optimization in the presence of outliers. More specifically, we model the problem as a Bayesian network and solve it using the Expectation-Maximization algorithm. Our approach leverages on a long-tail Cauchy distribution to suppress outlier feature matches in the odometry constraints, and a Cauchy-Uniform mixture model with a set of binary latent variables to simultaneously suppress outlier loop-closure constraints and outlier feature matches in the inlier loop-closure constraints. Furthermore, we show that by using a Gaussian-Uniform mixture model, our approach degenerates to the formulation of a state-of-the-art approach for robust indoor reconstruction. Experimental results demonstrate that our approach has comparable performance with the state-ofthe-art on a benchmark indoor dataset, and outperforms it on a large-scale outdoor dataset. Our source code can be found on the project website <ref type="url" target="https://github.com/ziquan111/RobustPCLReconstruction">https://github.com/ ziquan111/RobustPCLReconstruction</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Point cloud reconstruction of outdoor scenes has many important applications such as 3D architectural modeling, terrestrial surveying, Simultaneous Localization and Mapping (SLAM) for autonomous vehicles, etc. Compared to images, point clouds from 3D scanners exhibit less variation under different weather or lighting conditions, e.g., summer and winter (Fig. <ref type="figure">1</ref>), or day and night (Fig. <ref type="figure" target="#fig_4">5</ref>). Furthermore, the depths of point clouds from 3D scanners are more accurate than image-based reconstructions. Consequently, point clouds from 3D scanners are preferred for large-scale outdoor 3D reconstructions. Most existing methods for 3D reconstruction are solved via a two-step approach: a frontend data association step and a back-end optimization step. More specifically, data association is used to establish feature matches <ref type="bibr" target="#b29">[30]</ref> in point cloud fragments for registration, Odometry Choi et al. <ref type="bibr" target="#b4">[5]</ref>,</p><p>Identity cov.</p><p>Choi et al. <ref type="bibr" target="#b4">[5]</ref> Ours (Sec. and loop-closures <ref type="bibr" target="#b25">[26]</ref> between point cloud fragments for pose-graph <ref type="bibr" target="#b20">[21]</ref> optimization. Unfortunately, no existing algorithm for feature matching and loop-closure detection guarantees complete elimination of outliers. Although outlier feature matches are usually handled with RANSACbased geometric verification <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b29">30]</ref>, such pairwise checks do not consider global consistency. In addition, the numerous efforts on improving the accuracy in loop-closure detection <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26]</ref> are not completely free from false positives. Many back-end optimization algorithms <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21]</ref> are based on non-linear least-squares that lack the robustness to cope with outliers. A small number of outliers would consequently lead to catastrophic failures in the 3D reconstructions. Several prior works focus on disabling outlier loop-closures in the back-end optimization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b24">25]</ref>. However, these methods do not consider the effect from the outlier feature matches with the exception of <ref type="bibr" target="#b33">[34]</ref> that solves global geometric registration in a very small-scale problem setting.</p><p>The main contribution of this paper is a probabilistic approach for robust back-end optimization to handle out-liers from a weak front-end data association in large-scale point cloud based reconstructions. Our approach simultaneously suppresses outlier feature matches and loop-closures. To this end, we model our robust point cloud reconstruction problem as a Bayesian network. The global poses of the point cloud fragments are the unknown parameters, and odometry and loop-closure constraints are the observed variables. A binary latent variable is assigned to each loopclosure constraint; it determines whether a loop-closure constraint is an inlier or outlier. We model feature matches in the odometry constraints with a long-tail Cauchy distribution to gain robustness to outlier matches. Additionally, we use a Cauchy-Uniform mixture model for loop-closure constraints. The uniform and Cauchy distributions model outlier loop-closures and the feature matches in inlier loopclosures, respectively. In contrast to many existing backend optimizers that use rigid transformations as the odometry and loop-closure constraints <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>, we use the distances between feature matches to exert direct influence on these matches.</p><p>We use the Expectation-Maximization (EM) algorithm <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15]</ref> to find the globally consistent poses of the point cloud fragments (Sec. 4). The EM algorithm iterates between the Expectation and Maximization steps. In the Expectation step, the posterior of a loop-closure constraint being an inlier is updated. In the Maximization step, a local optimal solution for the global poses is found from maximizing the expected complete data log-likelihood over the posterior from the expectation step. We also generalize our approach to solve reconstruction problems with an easier setting (Sec. 5). In particular, a strong assumption is imposed: odometry and inlier loop-closure constraints are free from outlier feature matches. We show that by using a Gaussian-Uniform mixture model, our approach degenerates to the formulation of a state-of-the-art approach for robust indoor reconstruction <ref type="bibr" target="#b4">[5]</ref>. Fig. <ref type="figure">1</ref> shows an example of the reconstruction result with our method compared to other methods in the presence of outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Reconstruction of outdoor scenes has been studied in <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. Schöps et al. <ref type="bibr" target="#b22">[23]</ref> propose a set of filtering steps to detect and discard unreliable depth measurements acquired from a RGB-D camera. However, loop-closures is not detected and this can lead to reconstruction failures. Relying on very accurate GPS/INS, Pollefeys et al. <ref type="bibr" target="#b21">[22]</ref> propose a 3D reconstruction system from RGB images. However, GPS/INS signal may be unavailable or unreliable, especially on cloudy days or in urban canyons. Our work relies on neither GPS/INS nor RGB images. In contrast, we focus on reconstruction from point cloud data acquired from 3D scanners that is less sensitive to weather or lighting changes. There are also many works on indoor scene reconstruction. Since the seminal KinectFusion <ref type="bibr" target="#b17">[18]</ref>, there are several follow-up algorithms <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27]</ref>. Unfortunately, these methods do not detect loop-closures. Nonetheless, there are many RGB-D reconstruction methods with loopclosure detection <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>Choi et al. <ref type="bibr" target="#b4">[5]</ref> achieve the state-of-the-art performance for indoor reconstruction with robust loop-closure. However, they assume no outlier feature matches in the odometry and inlier loop-closure constraints. We relax this assumption to achieve robust feature matching. More specifically, <ref type="bibr" target="#b4">[5]</ref> estimates a switch variable <ref type="bibr" target="#b24">[25]</ref> for each loopclosure constraint using line processes <ref type="bibr" target="#b1">[2]</ref>. Outlier loopclosures are disabled by setting the respective switch variables to zero. Additional switch prior terms are imposed and chosen empirically <ref type="bibr" target="#b24">[25]</ref> to prevent a trivial solution of removing all loop-closure constraints. In comparison, our approach does not require the additional prior terms. We estimate the posterior of a loop-closure being an inlier constraint in the Expectation step shown in Sec. 4. The EM approach is also used by Lee et al. <ref type="bibr" target="#b14">[15]</ref>. However, they solve a robust pose-graph optimization problem without coping with the feature matches for reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview</head><p>In this section, we provide an overview of our reconstruction pipeline that consists of four main components: point cloud fragment construction, point cloud registration, loop-closure detection, and robust reconstruction with EM.</p><p>Point cloud fragment construction. A single scan from a 3D scanner, e.g. LiDAR, contains limited number of points. We integrate multiple consecutive scans with odometry readings obtained from dead reckoning e.g., the Inertial Navigation System (INS) <ref type="bibr" target="#b16">[17]</ref> to form local point cloud fragments. A set of 3D features is then extracted from each point cloud fragment using <ref type="bibr" target="#b29">[30]</ref>.</p><p>Point cloud registration. The top k 1 feature matches between two consecutive point cloud fragments F i and F i+1 are retained as the odometry constraint X i,i+1 . Since consecutive fragments overlap sufficiently by construction <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30]</ref>, we define X i,i+1 as a reliable constraint but note that it can contain outlier feature matches.</p><p>Loop-closure detection. It is inefficient to perform an exhaustive pairwise registration for large-scale outdoor scenes with many point cloud fragments. Hence, we perform point cloud based place-recognition <ref type="bibr" target="#b25">[26]</ref> to identify a set of candidate loop-closures. We retain the top k 2 potential loopclosures for each fragment and remove the duplicates. For each loop-closure between fragments F i and F j , we keep the set of top k 1 feature matches denoted as Y ij . We define Y ij as a loop-closure constraint, which can either be an inlier or outlier. Similar to the odometry constraint, an inlier loop-closure Y ij can also contain outlier feature matches.</p><p>Robust reconstruction with EM. The constraints from point cloud registration and loop-closure detection can contain outliers. In particular, both odometry and loop-closure constraints can contain outlier feature matches. Moreover, many detected loop-closures are false positives. In the next section, we describe our probabilistic modeling approach to simultaneously suppress outlier feature matches and false loop-closures. The EM algorithm is used to solve for the globally consistent fragment poses. Optional refinement using ICP can be applied to further improve the global point cloud registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Robust Reconstruction with EM</head><p>We model the robust reconstruction problem as a Bayesian network shown in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>Let T = [T 1 , ..., T i , ..., T N ] , where T i ∈ SE(3), denote the N fragment poses, X = [X 12 , ..., X i,i+1 , ..., X N -1,N ] denote the N -1 odometry constraints obtained in point cloud registration, and Y = [..., Y ij , ...] denote the M loop-closure constraints obtained in loop-closure detection. We explicitly assign the loop-closure constraints into 2 clusters that represent the inliers and outliers. For each loop-closure constraint Y ij , we introduce a corresponding assignment variable</p><formula xml:id="formula_0">Z ij = [Z ij,in , Z ij,out ] ∈ {[1, 0] , [0, 1] }.</formula><p>Z ij is a one-hot vector: Z ij,in = 1 and Z ij,out = 1 assigns assigns Y ij as an inlier and outlier loop-closure constraint, respectively. We use Z = [..., Z ij , ...] to denote the assignment variables. T is the unknown parameter, Z is the latent variable, and X and Y are both observed variables.</p><p>Robust reconstruction can be solved as finding the Maximum a Posterior (MAP) solution of p(T |X, Y ). However, the MAP solution involves an intractable step of marginalization over the latent variable Z. We circumvent this problem by using the EM algorithm that takes the maximization of the expected complete data log-likelihood over the posterior of the latent variables. The EM algorithm iterates between the Expectation and Maximization steps. In the Expectation step, we use T old , i.e., fragment poses solved from the previous iteration to find the posterior distribution of the latent variable Z,</p><formula xml:id="formula_1">p(Z|Y, T old ) = p(Y |Z, T old )p(Z|T old ) p(Y |T old ) ,<label>(1)</label></formula><p>in which Z does not depend on X, since they are conditionally independent given Y according to the Bayesian network in Fig. <ref type="figure" target="#fig_1">2</ref>.</p><p>In the Maximization step, the posterior distribution (Eq. ( <ref type="formula" target="#formula_1">1</ref>)) is used to update T by maximizing the expectation of the complete data log-likelihood denoted by</p><formula xml:id="formula_2">Q EM : = Z p(Z|Y, T old ) ln p(X, Y, Z|T )<label>(2)</label></formula><p>= ln p(X|T )</p><formula xml:id="formula_3">Q X + Z p(Z|Y, T old ) ln p(Y, Z|T ) Q Y .</formula><p>We define Q X for the term with odometry constraints, and Q Y for the term with loop-closure constraints.</p><p>Initialization. The unknown parameters, i.e., global poses T of the N fragments, are initialized with the relative poses computed from odometry constraints X using ICP. Other dead reckoning methods such as wheel odometry and/or INS readings can also be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Modeling Odometry Constraints</head><p>Odometry constraints are obtained from point cloud registration between two consecutive point cloud fragments. Recall that an odometry constraint X i,i+1 is a set of feature matches between fragments F i and F i+1 , which can contain outlier matches. To gain robustness, we model each feature match (p, q) ∈ X i,i+1 with a long-tail multivariate Cauchy distribution. Suppose these feature matches are independent and identically distributed (i.i.d.), we take a geometric mean over their product to get</p><formula xml:id="formula_4">p(X i,i+1 |T ) = (p,q)∈Xi,i+1 Cauchy i,i+1 (p, q) 1 |X i,i+1 | ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_5">Cauchy i,i+1 (p, q) = 1 π 2 √ det Σ(1 + d 2 Σ (T i p, T i+1 q)) 2 , (<label>4</label></formula><p>) which we assume an isotropic covariance Σ = σ 2 I with scale σ, and d Σ denotes the Mahalanobis distance such that</p><formula xml:id="formula_6">d 2 Σ (T i p, T i+1 q) = (T i p -T i+1 q) Σ -1 (T i p -T i+1 q).<label>(5)</label></formula><p>The value of σ is set based on the density of extracted features. For example, σ = 0.5m in the outdoor dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Modeling Loop-Closure Constraints</head><p>A loop-closure constraint Y ij is the set of feature matches between fragments F i and F j . We propose to use a Cauchy-Uniform mixture model to cope with the (1) outlier loop-closure constraints and (2) outlier feature matches in the inlier loop-closure constraints.</p><p>To distinguish between inlier and outlier loop-closures, we model the distribution of assignment variable Z as a Bernoulli distribution defined by the inlier probability λ ∈</p><formula xml:id="formula_7">[0, 1], p(Z ij ) = λ Zij,in (1 -λ) Zij,out .<label>(6)</label></formula><p>Next, we use two distributions: Cauchy and Uniform distributions to model the inlier and outlier loop-closure constraints, respectively.</p><p>Cauchy distribution -inlier loop-closure constraints. The inlier loop-closure constraints can contain outlier feature matches. We use the same multivariate Cauchy distribution as Eq. ( <ref type="formula" target="#formula_4">3</ref>) and further reorganize the terms. We define C ij for brevity, such that <ref type="bibr" target="#b6">(7)</ref> in which</p><formula xml:id="formula_8">C ij := p(Y ij |Z ij,in = 1, T ) = π -2 σ -3 e -2Aij ,</formula><formula xml:id="formula_9">A ij = 1 |Y ij | (p,q)∈Yij ln(1 + T i p -T j q 2 σ 2 ),<label>(8)</label></formula><p>and |Y ij | denotes the number of feature matches in Y ij .</p><p>Uniform distribution -outlier loop-closure constraints.</p><p>We model the outlier loop-closure constraints with a uniform distribution defined by a constant probability u ∈ (0, 1),</p><formula xml:id="formula_10">p(Y ij |Z ij,out = 1, T ) = u.<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Expectation Step</head><p>Recall that the expectation step is evaluated in Eq. ( <ref type="formula" target="#formula_1">1</ref>). Plugging Eq. ( <ref type="formula" target="#formula_7">6</ref>), ( <ref type="formula">7</ref>) and ( <ref type="formula" target="#formula_10">9</ref>) into the Bayes' formula, we obtain the posterior of being an inlier loop-closure constraint,</p><formula xml:id="formula_11">P in ij := p(Z ij,in = 1|Y, T ) = Θ Θ + e 2Aij ,<label>(10)</label></formula><p>where</p><formula xml:id="formula_12">Θ = λ (1 -λ)uπ 2 σ 3 . (<label>11</label></formula><formula xml:id="formula_13">)</formula><p>The constant Θ consists of two distribution parameters: λ is the probability of being an inlier loop-closure; u is the constant probability to uniformly sample a random loopclosure, which are difficult to set manually based on different datasets. Hence, we propose to estimate Θ based on the input data. More specifically, we learn Θ from the odometry constraints, since all odometry constraints are effectively inlier loop-closure constraints.</p><p>The process to learn Θ is as follows. First, for each odometry constraint X i,i+1 , we denote its corresponding error term m i,i+1 = e 2Ai,i+1 (analogous to Eq. ( <ref type="formula" target="#formula_11">10</ref>)), where</p><formula xml:id="formula_14">A i,i+1 = 1 |X i,i+1 | (p,q)∈Xi,i+1 ln(1 + T i p -T i+1 q 2 σ 2</formula><p>).</p><p>(12) Next, we compute the median error denoted as m. Since we regard all odometry constraints as inlier loop-closure constraints, let</p><formula xml:id="formula_15">Θ Θ + m = p,<label>(13)</label></formula><p>where we set p = 90%, meaning that a loop-closure Y ij with a small error (e 2Aij &lt; m) is very likely to be an inlier (P in ij &gt; p). Finally, we solve for Θ using Eq. ( <ref type="formula" target="#formula_15">13</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Maximization Step</head><p>In the maximization step, we solve for T that maximizes</p><formula xml:id="formula_16">Q EM = Q X + Q Y ,</formula><p>where Q X and Q Y are shorthand notations defined in Eq. ( <ref type="formula" target="#formula_2">2</ref>). These two terms are evaluated independently, and then optimized jointly.</p><p>Evaluate Q X . Assuming the odometry constraints in X are i.i.d., the joint probability of all odometry constraints is given by</p><formula xml:id="formula_17">p(X|T ) = N -1 i=1 p(X i,i+1 |T ).<label>(14)</label></formula><p>Substituting the joint probability of the feature matches within each odometry constraint (Eq. ( <ref type="formula" target="#formula_4">3</ref>)), we can rewrite Q X as</p><formula xml:id="formula_18">Q X = -2 N -1 i=1 A i,i+1 + const. (<label>15</label></formula><formula xml:id="formula_19">)</formula><p>Evaluate Q Y . Using the product rule, the joint probability of loop-closure constraints and their corresponding assignment variables can be written as p(Y, Z|T ) = p(Z)p(Y |Z, T ). Plugging Eq. ( <ref type="formula" target="#formula_7">6</ref>), ( <ref type="formula">7</ref>) and ( <ref type="formula" target="#formula_10">9</ref>) in, we have</p><formula xml:id="formula_20">p(Y, Z|T ) = i,j (λ C ij ) Zij,in (1 -λ)u Zij,out .<label>(16)</label></formula><p>We can rewrite Q Y as</p><formula xml:id="formula_21">Q Y = i,j P in ij ln C ij + const,<label>(17)</label></formula><p>with the joint probability from Eq. ( <ref type="formula" target="#formula_20">16</ref>) and the posterior from Eq. ( <ref type="formula" target="#formula_11">10</ref>), which can be further expanded to</p><formula xml:id="formula_22">Q Y = -2 i,j P in ij A ij + const. (<label>18</label></formula><formula xml:id="formula_23">)</formula><p>Maximize Q EM . The maximization of Q X + Q Y can be reformulated into a non-linear least-squares problem with the following objective function</p><formula xml:id="formula_24">argmin T i,j P in ij |Y ij | (p,q)∈Yij ln(1 + T i p -T j q 2 σ 2 )<label>(19)</label></formula><formula xml:id="formula_25">+ N -1 i=1 1 |X i,i+1 | (p,q)∈Xi,i+1 ln(1 + T i p -T i+1 q 2 σ 2 ),</formula><p>which can be easily optimized using the sparse Cholesky solver in Google Ceres <ref type="bibr" target="#b0">[1]</ref>. The computation complexity is cubic to the total number of feature matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Generalization using EM</head><p>In the previous section, we solved the problem when constraints are contaminated with outlier feature matches. In this section, we study a problem with an easier setting where correct loop-closure constraints contain no outlier feature matches. Recall that long-tail multivariate Cauchy distribution is used to gain robustness against outlier feature matches. We replace the multivariate Cauchy distribution with a multivariate Gaussian distribution for the easier problem without outlier feature matches, and show that our EM formulation degenerates to the formulation of a stateof-the-art approach for robust indoor reconstruction <ref type="bibr" target="#b4">[5]</ref>. To avoid repetition, we only highlight the major differences to the previous section. Each analogous term is augmented with a superscript G that stands for "Gaussian".</p><p>Odometry constraints. Replacing the multivariate Cauchy distribution in Eq. ( <ref type="formula" target="#formula_4">3</ref>) with a multivariate Gaussian distribution, we have <ref type="bibr" target="#b19">20)</ref> where</p><formula xml:id="formula_26">p G (X i,i+1 |T ) = (p,q)∈Xi,i+1 Gauss i,i+1 (p, q) 1 |X i,i+1 | ,<label>(</label></formula><formula xml:id="formula_27">Gauss i,i+1 (p, q) = exp -1 2 d 2 Σ (T i p, T i+1 q) (2π) 3 det Σ ,<label>(21)</label></formula><p>and Σ and d Σ remain unchanged.</p><p>Loop-closure constraints. We note that the Bernoulli distribution in Eq. ( <ref type="formula" target="#formula_7">6</ref>) still holds, and the major changes start from Eq. ( <ref type="formula">7</ref>). Using the multivariate Gaussian distribution, we have</p><formula xml:id="formula_28">G ij := p G (Y ij |Z ij,in = 1, T ) = ( √ 2πσ) -3 e -B ij 2σ 2 , (<label>22</label></formula><formula xml:id="formula_29">)</formula><p>in which</p><formula xml:id="formula_30">B ij = 1 |Y ij | (p,q)∈Yij T i p -T j q 2 , (<label>23</label></formula><formula xml:id="formula_31">)</formula><p>and |Y ij | is the number of feature matches. We note that B ij is a sum-of-square errors that can lead to arithmetic overflow in the e Bij term from the posterior of the latent variable Z ij (analogous to Eq. ( <ref type="formula" target="#formula_11">10</ref>)). In contrast, there is no arithmetic overflow in the e Aij term from Eq. ( <ref type="formula" target="#formula_11">10</ref>) since A ij from Eq. ( <ref type="formula" target="#formula_9">8</ref>) is a sum-of-log errors. We propose to alleviate the arithmetic overflow problem by using a Pareto distribution that approximates G ij as</p><formula xml:id="formula_32">G ij ≈ x 0 B 2 ij ,<label>(24)</label></formula><p>where x 0 &gt; 0 is a scale parameter. For outlier loopclosures, the uniform distribution in Eq. ( <ref type="formula" target="#formula_10">9</ref>) still holds.</p><p>Expectation step. Using the approximation of G ij in Eq. ( <ref type="formula" target="#formula_32">24</ref>), the posterior from Eq. ( <ref type="formula" target="#formula_11">10</ref>) becomes</p><formula xml:id="formula_33">P in ij G ≈ Θ G Θ G + B 2 ij ,<label>(25)</label></formula><p>where</p><formula xml:id="formula_34">Θ G = x 0 λ (1 -λ)u . (<label>26</label></formula><formula xml:id="formula_35">)</formula><p>It becomes apparent in P in G ij that the arithmetic overflow problem is alleviated by the replacement of e Bij with B 2 ij . In the previous section, Θ in Eq. ( <ref type="formula" target="#formula_15">13</ref>) is learned from the median error m of all the error terms m i,i+1 = e 2Ai,i+1 in the odometry constraints. Unfortunately, the median error mG from m G i,i+1 = B 2 i,i+1 becomes uninformative because we assume no outlier feature matches, i.e., mG → 0 since m G i,i+1 = B 2 i,i+1 → 0. Despite the absence of outlier feature matches, T i p -T j q is upper bounded by some threshold, . Hence, the mean error term can be directly estimated from Eq. ( <ref type="formula" target="#formula_30">23</ref>) as mG = 2 . Subsequently, let</p><formula xml:id="formula_36">Θ G Θ G + mG = p,<label>(27)</label></formula><p>where we set p = 90% and solve for Θ G . We set = 0.05m for our experiments on the indoor dataset (see next section) based on the typical magnitude of sensor noise.  <ref type="table">2</ref>. Reconstruction accuracy on the indoor dataset. The entries are the mean distances of each model to its respective ground-truth surface (in meters). Our proposed method shows comparable result with the state-of-the-art and outperforms the rest.</p><p>Maximization step. Finally, we reformulate the maximization problem as a non-linear least-squares problem with the following objective function</p><formula xml:id="formula_37">argmin T i,j P in ij G |Y ij | (p,q)∈Yij T i p -T j q 2<label>(28)</label></formula><formula xml:id="formula_38">+ N -1 i=1 1 |X i,i+1 | (p,q)∈Xi,i+1 T i p -T i+1 q 2 ,</formula><p>which is similar to the formulation in <ref type="bibr" target="#b4">[5]</ref> with two minor differences. First, we average the square errors over the number of feature matches but <ref type="bibr" target="#b4">[5]</ref> does not. Second, we estimate the posterior P in ij G by iterating between the Expectation and Maximization steps but <ref type="bibr" target="#b4">[5]</ref> estimates it using line processes <ref type="bibr" target="#b1">[2]</ref>. It is important to note that Eq. ( <ref type="formula" target="#formula_37">28</ref>) is derived from the original Gaussian formulation in Eq. ( <ref type="formula" target="#formula_28">22</ref>) instead of the Pareto approximation in Eq. ( <ref type="formula" target="#formula_32">24</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation</head><p>We use the experimental results from two datasets for the comparison between our approach and the state-of-theart approach <ref type="bibr" target="#b4">[5]</ref>. The first dataset is from small-scale indoor scenes with no outlier feature matches in the odometry and inlier loop-closure constraints, and the second dataset is from large-scale outdoor scenes with outlier feature matches. Our Gaussian-Uniform EM (Sec. 5) and Cauchy-Uniform EM (Sec. 4) are evaluated on the smallscale indoor and large-scale outdoor datasets, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Small-Scale Indoor Scenes</head><p>The "Augmented ICL-NUIM Dataset" provided and augmented by <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b4">[5]</ref>, respectively, is used as the small-scale indoor dataset. This dataset is generated from synthetic indoor environments and includes two models: a living room and an office. There are two RGB-D image sequences for each model, resulting in a total of four test cases. To ensure fair comparison, we follow the same evaluation criteria and experimental settings as <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results.</head><p>Tab. 1 shows the comparison of the average recall and precision of the loop-closures on (1) before pruning, (2) <ref type="bibr" target="#b4">[5]</ref> after pruning and (3) our method after pruning. Here, "before pruning" refers the loop-closures from the loop-closure detection, and "after pruning" refers to the inlier loop-closures after robust optimization. It can be seen that the average precision and recall of our method is comparable to <ref type="bibr" target="#b4">[5]</ref>. This is an expected result since we showed in Sec. 5 that our method degenerates to the method in <ref type="bibr" target="#b4">[5]</ref> with minor differences in the absence of outlier feature matches. We further evaluate the reconstruction accuracy of the final model using the error metric proposed in <ref type="bibr" target="#b8">[9]</ref>, i.e., the mean distance of the reconstructed surfaces to the ground truth surfaces. Tab. 2 shows the comparison of the reconstruction accuracy of our method to other existing approaches. In addition, as suggested in <ref type="bibr" target="#b4">[5]</ref>, the reconstruction accuracy of the model obtained from fusing the input depth images with the ground truth trajectory (denoted as GT Trajectory in Tab. 2) is reported for reference. As expected, our method shows comparable result with the state-of-the-art on the indoor dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Large-Scale Outdoor Scenes</head><p>The large-scale outdoor dataset is based on the "Oxford Robotcar Dataset" <ref type="bibr" target="#b16">[17]</ref>. It consists of 3D point clouds captured with a LiDAR sensor mounted on a car that repeatedly  drives through Oxford, UK, at different times over a year. We select two different driving routes from the dataset, a short route (about 1km) and a long route (city-scale). Furthermore, we take two traversals at different times for each route, resulting four traversals in total. Unlike the synthetic indoor dataset, there is no ground truth of the surface geometry. We evaluate the trajectory accuracy against the GPS/INS readings as an indirect measurement of reconstruction accuracy. We prepare the dataset as follows:</p><p>• Point cloud fragments. We integrate the push-broom 2D LiDAR scans and their corresponding INS readings into the 3D point clouds. We segment the data into fragments with 30m radius for every 10m interval. Each fragment is then downsampled using a VoxelGrid filter with a grid size of 0.2m. 242 and 1770 fragments are constructed for the 1km route and the city-scale route, respectively.</p><p>• Odometry trajectory. The odometry trajectory is disconnected due to discontinuous INS data since we are combining two traversals. We simulate the odometry trajectory via geometric registrations between consecutive point cloud fragments, and manually identify one linkage transformation between the two traversals. We also check the entire odometry trajectory to ensure that there are no remaining erroneous transformations. The resulting odometry trajectory is used to initialize the fragment poses, T .</p><p>• Odometry constraints. For every two consecutive frames along the odometry trajectory, we perform point cloud registration as described in Sec. 3. Specifically, we extract 1024 features for each fragment, and collect the top 200 feature matches to form an odometry constraint. Note that the feature matches are selected without additional geometric verification, and it can contain outliers. 241 and 1769 odometry constraints are constructed for the 1km route and the city-scale route, respectively.</p><p>• Loop-closure constraints. We perform loop-closure detection as described in Sec. 3. We take every 5th fragment along the trajectory as a keyframe fragment; loopclosures are detected among the selected keyframe fragments. For the 1km route, we find the top 5 loop-closures for each keyframe fragment and then remove the duplicates. For the city-scale route, we find the top 10 loopclosures for each keyframe fragment and then remove the duplicates. 171 and 1438 loop-closure constraints are constructed for the 1km and city-scale route, respectively. The outlier loop-closure ratio is more than 80% for both routes.</p><p>Baseline Methods. We compare the effectiveness of our approach with two baseline methods based on <ref type="bibr" target="#b4">[5]</ref>: a stronger and a weaker baseline. The stronger baseline encodes uncertainty information of the feature matches between two fragments into a covariance matrix. The feature matches used to construct the covariance matrix are those within 1m apart after geometric registration. Refer to <ref type="bibr" target="#b4">[5]</ref> for the more details on the covariance matrix. The covariance matrix of the weaker baseline is set to identity, i.e., no uncertainty information on the feature matches. The relative poses between the point cloud fragments computed from Table <ref type="table">3</ref>. Reconstruction accuracy on outdoor dataset. Each entry is the mean distance of the estimated poses to the GPS/INS ground truth (in meters).</p><p>ICP are used as the odometry and loop-closure constraints in the baseline methods.</p><p>Results. Tab. 3 summarizes the mean distances of the estimated poses to the GPS/INS trajectory as an indirect measure of the reconstruction accuracy on the 1km and city-scale outdoor datasets. Fig. <ref type="figure" target="#fig_2">3</ref> and<ref type="figure" target="#fig_3">4</ref> show the plots of the trajectories. We align the first five fragment poses with the GPS/INS trajectory, error measurements start after the 5th fragment pose. The results show that the accuracy increases when more information about the feature matches is considered in the optimization process. We can see from Tab. 3, and Fig. <ref type="figure" target="#fig_2">3</ref> and 4 that the weaker baseline ( <ref type="bibr" target="#b4">[5]</ref> with uninformative identity covariance) without information of the feature matches gives the worst performance. The stronger baseline ( <ref type="bibr" target="#b4">[5]</ref> with informative covariance matrix) that encodes information of feature matches using the covariance matrix shows better performance. In contrast, our method that directly takes feature matches as the odometry and loop-closure constraints outperforms the two baselines. Furthermore, Fig. <ref type="figure">1</ref> and<ref type="figure" target="#fig_4">5</ref> show reconstruction results for qualitative evaluation. It can be seen from the bottom left and right plots in Fig. <ref type="figure" target="#fig_4">5</ref> that our method produces the sharpest reconstructions of the 3D point clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>In this paper, we proposed a probabilistic approach for robust point cloud reconstruction of large-scale outdoor scenes. Our approach leverages on a Cauchy-Uniform mixture model to simultaneously suppress outlier feature matches and loop-closures. Moreover, we showed that by using a Gaussian-Uniform mixture model, our approach degenerates to the formulation of a state-of-the-art approach for robust indoor reconstruction. We verified our proposed methods on both indoor and outdoor benchmark datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4 )Figure 1 .</head><label>41</label><figDesc>Figure 1. Reconstruction of a 1km route traversed in two different seasons: summer (orange) and winter (blue). The outlier (red links) loop-closures significantly outnumber the inliers (green links). Four zoomed-in point clouds on the right are reconstructed from different methods.</figDesc><graphic coords="1,311.06,276.02,156.81,103.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Bayesian network representation of the robust reconstruction problem. Ti+1, Ti and Tj are fragment poses. Xi,i+1 is an odometry constraint. Yij is a loop-closure constraint. Zij is an assignment variable. N -1 and M indicate the numbers of odometry constraints and loop-closure constraints respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Trajectories on the 1km route. Each trajectory (blue) is overlaid with the GPS/INS trajectory (green). Red asterisk indicates the position of the 1st fragment pose.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Trajectories on the city-scale route. Each trajectory (blue) is overlaid with the GPS/INS trajectory (green). A zoomed-in region is shown on the top right corner for each trajectory. Red asterisk indicates the position of the 1st fragment pose.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Reconstruction results on the city-scale route traversed in day and night. The two columns of zoomed-in point clouds are reconstructed based on different trajectories.</figDesc><graphic coords="8,75.56,280.10,90.11,60.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Results of robust optimization on the indoor dataset. Our method shows comparable result with the state-of-the-art.</figDesc><table><row><cell></cell><cell></cell><cell cols="6">Living room 1 Living room 2 Office 1 Office 2 Average</cell></row><row><cell>Before pruning</cell><cell>Recall(%) Precision(%)</cell><cell>61.2 27.2</cell><cell>49.7 17.0</cell><cell>64.4 19.2</cell><cell></cell><cell>61.5 14.9</cell><cell>59.2 19.6</cell></row><row><cell>Choi et al. [5]</cell><cell>Recall(%)</cell><cell>57.6</cell><cell>49.7</cell><cell>63.3</cell><cell></cell><cell>60.7</cell><cell>57.8</cell></row><row><cell>after pruning</cell><cell>Precision(%)</cell><cell>95.1</cell><cell>97.4</cell><cell cols="2">98.3</cell><cell>100.0</cell><cell>97.7</cell></row><row><cell>Ours (Sec. 5)</cell><cell>Recall(%)</cell><cell>58.7</cell><cell>48.4</cell><cell>63.9</cell><cell></cell><cell>61.5</cell><cell>58.1</cell></row><row><cell>after pruning</cell><cell>Precision(%)</cell><cell>97.0</cell><cell>94.9</cell><cell>96.6</cell><cell></cell><cell>93.6</cell><cell>95.4</cell></row><row><cell></cell><cell cols="6">Living room 1 Living room 2 Office 1 Office 2 Average</cell></row><row><cell cols="2">Whelan et al. [27]</cell><cell>0.22</cell><cell>0.14</cell><cell>0.13</cell><cell>0.13</cell><cell>0.16</cell></row><row><cell cols="2">Kerl et al. [12]</cell><cell>0.21</cell><cell>0.06</cell><cell>0.11</cell><cell>0.10</cell><cell>0.12</cell></row><row><cell cols="2">SUN3D [29]</cell><cell>0.09</cell><cell>0.07</cell><cell>0.13</cell><cell>0.09</cell><cell>0.10</cell></row><row><cell cols="2">Choi et al. [5]</cell><cell>0.04</cell><cell>0.07</cell><cell>0.03</cell><cell>0.04</cell><cell>0.05</cell></row><row><cell cols="2">Ours (Sec. 5)</cell><cell>0.06</cell><cell>0.09</cell><cell>0.05</cell><cell>0.04</cell><cell>0.06</cell></row><row><cell cols="2">GT Trajectory</cell><cell>0.04</cell><cell>0.04</cell><cell>0.03</cell><cell>0.03</cell><cell>0.04</cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work is supported in part by a <rs type="grantName">Singapore MOE Tier 1 grant</rs> <rs type="grantNumber">R-252-000-A65-114</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_AfSxwhG">
					<idno type="grant-number">R-252-000-A65-114</idno>
					<orgName type="grant-name">Singapore MOE Tier 1 grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mierle</surname></persName>
		</author>
		<author>
			<persName><surname>Others</surname></persName>
		</author>
		<ptr target="http://ceres-solver.org" />
		<title level="m">Ceres solver</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the unification of line processes, outlier rejection, and robust statistics with applications in early vision</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IJCV</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A classification em algorithm for clustering and two stochastic versions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Celeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Govaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CSDA</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scalable real-time volumetric surface reconstruction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bautembach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TOG</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robust reconstruction of indoor scenes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Appearance-only slam at large scale with fab-map 2.0. In IJRR</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cummins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">3-d mapping with an rgb-d camera</title>
		<author>
			<persName><forename type="first">F</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<editor>T-RO</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Real-time loop detection with bags of binary words</title>
		<author>
			<persName><forename type="first">D</forename><surname>Galvez-Lopez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Tardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A benchmark for RGB-D visual odometry, 3D reconstruction and SLAM</title>
		<author>
			<persName><forename type="first">A</forename><surname>Handa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Whelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Patch volumes: Segmentation-based consistent mapping with rgb-d cameras</title>
		<author>
			<persName><forename type="first">P</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bhowmik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mongia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rgbd mapping: Using kinect-style depth cameras for dense 3d modeling of indoor environments</title>
		<author>
			<persName><forename type="first">P</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krainin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Herbst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJRR</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dense visual slam for rgb-d cameras</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Factor graphs and the sum-product algorithm</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Kschischang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-A</forename><surname>Loeliger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">T-IT</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A general framework for graph optimization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kümmerle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Grisetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strasdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Robust pose-graph loop-closures with expectation-maximization</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fraundorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised learning of threshold for geometric verification in visual-based loop-closure</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">1 year, 1000 km: The oxford robotcar dataset</title>
		<author>
			<persName><forename type="first">W</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pascoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Linegar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJRR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Kinectfusion: Real-time dense surface mapping and tracking</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMAR</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Real-time 3d reconstruction at scale using voxel hashing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zollhöfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TOG</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scalable recognition with a vocabulary tree</title>
		<author>
			<persName><forename type="first">D</forename><surname>Nister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stewenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast iterative alignment of pose graphs with poor initial estimates</title>
		<author>
			<persName><forename type="first">E</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Detailed real-time urban 3d reconstruction from video</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nistér</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Frahm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akbarzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mordohai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Clipp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Engels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gallup</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Merrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCV</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Largescale outdoor 3d reconstruction on a mobile device</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schöps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Häne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large-scale multiresolution surface reconstruction from rgb-d sequences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Steinbrucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Switchable constraints for robust pose graph slam</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sünderhauf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Protzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Uy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Robust real-time visual odometry for dense rgb-d mapping</title>
		<author>
			<persName><forename type="first">T</forename><surname>Whelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Johannsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Deformation-based loop closure for large scale dense rgb-d slam</title>
		<author>
			<persName><forename type="first">T</forename><surname>Whelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcdonald</surname></persName>
		</author>
		<editor>IROS</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sun3d: A database of big spaces reconstructed using sfm and object labels</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">3DFeat-Net: Weakly Supervised Local 3D Features for Point Cloud Registration</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dense scene reconstruction with points of interest</title>
		<author>
			<persName><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TOG</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Simultaneous localization and calibration: Self-calibration of consumer depth cameras</title>
		<author>
			<persName><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Elastic fragments for dense scene reconstruction</title>
		<author>
			<persName><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast global registration</title>
		<author>
			<persName><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
