<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Generative Model for Simultaneous Range Error Mitigation and Environment Identification</title>
				<funder ref="#_qV7v9Fn">
					<orgName type="full">Basic Research Strengthening Program of China</orgName>
				</funder>
				<funder ref="#_jCdXBuG">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_MEaGsvw">
					<orgName type="full">Spanish Ministry of Science and Innovation through Ramon y Cajal</orgName>
				</funder>
				<funder ref="#_beTFbyX">
					<orgName type="full">Basque Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuxiao</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Santiago</forename><surname>Mazuelas</surname></persName>
							<email>smazuelas@bcamath.org</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">BCAM-Basque Center for Applied Mathematics</orgName>
								<orgName type="department" key="dep2">IKERBASQUE-Basque Foundation for Science</orgName>
								<address>
									<settlement>Bilbao</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuan</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic Engineering</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Generative Model for Simultaneous Range Error Mitigation and Environment Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/GLOBECOM46510.2021.9685255</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Generative Model</term>
					<term>Range Error Mitigation</term>
					<term>Environment Identification</term>
					<term>Non-Linear Signal Processing</term>
					<term>Bayesian Model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Received waveforms contain rich information for both range information and environment semantics. However, its full potential is hard to exploit under multipath and nonline-of-sight conditions. This paper proposes a deep generative model (DGM) for simultaneous range error mitigation and environment identification. In particular, we present a Bayesian model for the generative process of the received waveform composed by latent variables for both range-related features and environment semantics. The simultaneous range error mitigation and environment identification is interpreted as an inference problem based on the DGM, and implemented in a unique end-toend learning scheme. Comprehensive experiments on a general Ultra-wideband dataset demonstrate the superior performance on range error mitigation, scalability to different environments, and novel capability on simultaneous environment identification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>As a fundamental description of the channel, the received waveform represents how a signal propagates from the transmitter to the receiver in a multipath channel. Received waveforms inherently contain information both range-related and environment-related, and have been widely exploited in many localization algorithms for harsh environments <ref type="bibr" target="#b0">[1]</ref>. Exploiting semantic features from received waveforms can provide enhanced localization, and is critical for beyond fifth-generation (B5G) network requirements <ref type="bibr" target="#b1">[2]</ref>.</p><p>Typical localization systems obtain received signals corresponding with specific radio-frequency technologies including Wi-Fi <ref type="bibr" target="#b2">[3]</ref>, mmWave <ref type="bibr" target="#b3">[4]</ref>, and ultra-wideband (UWB) <ref type="bibr" target="#b4">[5]</ref>. Among these technologies, UWB transmission is the most promising with a bandwidth over 500 MHz and extremely short transmitted pulses, which allow for a finer time resolution of multipath signals. However, the capability of these radiofrequency systems in practical deployment is still limited and hurdled by a number of technical challenges, especially in harsh environments. These devices often adopt the first estimated delay as the line-of-sight (LOS) path to perform range estimation <ref type="bibr" target="#b2">[3]</ref>. Though easy to implement, such method tend to introduce a positive bias in range estimation caused by the non-line-of-sight (NLOS) propagation, as well as a cluttering noise due to the multi-path effect <ref type="bibr" target="#b5">[6]</ref>. Moreover, the usage of received waveforms to identify different environments currently provides a coarse LOS or NLOS classification, leaving out richer environmental semantics like geometric layouts of the room and materials of the blocking objects <ref type="bibr" target="#b4">[5]</ref>. Therefore, techniques to improve range error mitigation and obtain detailed environment identification are imperative for wireless networks <ref type="bibr" target="#b6">[7]</ref>.</p><p>Existing methods address separately range error mitigation and environment identification. For range error mitigation, conventional methods detect NLOS propagation and assign different weights to LOS and NLOS range estimations for positional purpose <ref type="bibr" target="#b7">[8]</ref>. Early machine learning methods, such as SVM <ref type="bibr" target="#b4">[5]</ref>, use hand-crafted features <ref type="bibr" target="#b0">[1]</ref> to represent received signals and learn the range error from a regression problem. Recently, several deep learning methods have been proposed where the whole waveform is utilized as input to learn a regressor of the range error <ref type="bibr" target="#b8">[9]</ref>. Though enjoying a significant improvement in performance using full waveforms, such deep learning methods suffer from generalization problems and are prone to overfitting.</p><p>Existing methods for environment identification aim to determine coarse LOS or NLOS conditions instead of more detailed environment semantics. These methods use characteristic features of waveform to determine the LOS or NLOS conditions. As in range error mitigation, these features are either hand-crafted conducted by SVM <ref type="bibr" target="#b9">[10]</ref>, relevance vector machine (RVM) <ref type="bibr" target="#b10">[11]</ref>, or data-driven conducted by neural networks <ref type="bibr" target="#b11">[12]</ref>.</p><p>We propose a deep generative model (DGM) for simultaneous range error mitigation and environment identification, with a generative modeling illustrated in Fig. <ref type="figure" target="#fig_0">1</ref>. Specifically, ©2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. Cite from IEEE: DOI No. 10.1109/GLOBECOM46510.2021. <ref type="bibr">9685255</ref> we present a Bayesian model for the generative process of the received waveform, where the range-related features and environmental semantics are disentangled from waveforms via a modified variational auto-encoder (VAE). Simultaneous inference is carried out based on these features by two sub neural modules. The presented method is technology-agnostic and is applicable to any technology providing received waveforms.</p><p>The remaining sections are organized as follows. Section II introduces the proposed DGM, including the Bayesian modeling and network learning scheme employed. The performance of the proposed method on both tasks is evaluated with a case study in Section III. Finally, Section IV concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DEEP GENERATIVE MODEL</head><p>In this section we propose a deep learning method for simultaneous range error mitigation and environment identification. We first describe the problem of exploiting received waveforms to obtain richer semantics. Then a Bayesian model is presented involving a range-related variable and an environment-related variable. Afterwards, we introduce the network implementation and learning scheme of the proposed method, illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Statement</head><p>Given the transmitted waveform s, the received signal x can be expressed as follows,</p><formula xml:id="formula_0">x(t) = l α l s(t -τ l ) + n(t), t ∈ [0, T ob ]<label>(1)</label></formula><p>where s(t) denotes the transmitted waveform, L, denotes the number of multi-path components, α l , and τ l are the amplitude and propagation delay of the lth component, respectively, n(t) represents an additive white Gaussian noise (AWGN), and [0, T ob ] is the observation interval. Suppose different environment scenarios are annotated by labels with discrete values, denoted as k in {1, 2, . . . , K}. Techniques for environment identification utilizes the whole waveform x to estimate scenario k, while range error mitigation estimate the non-negative bias ∆d between the true distance d and the measured distance d M from the delay components. Both tasks involve complex semantics caused by different environments. It is difficult to capture all of the environment factors in one theoretic model. Nevertheless, some observations from the received waveforms can be concluded to give helpful insights <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b4">[5]</ref>: i) received waveforms show different characteristics in different environments; ii) the distinction between LOS and NLOS conditions is rather coarse to exploit the inherent semantics of waveforms.</p><p>This paper develops a more general approach to exploit the inherent semantics of received waveforms, which can disentangle the related features in received waveforms and simultaneously conduct range error mitigation and environment identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Bayesian Model for Received Waveform</head><p>We model the generative process of the waveform x involving two independent latent variables: y for range-related features and z for environment-related features. The generation from the latent space to the data space can be obtained via the likelihood distribution p(x|y, z). The generative process consists of three sequential steps:</p><p>1) A value y (i) is generated from distribution p(y) of the latent variable for range-related feature. 2) A value z (i) is generated from distribution p(z) of the latent variable for environment-related feature. 3) A value x (i) for a UWB measurement sample is generated from the conditional distribution p(x|y (i) , z (i) ). Therefore, the generation of a measurement sample can be obtained by sampling the distribution on the two latent variables, and the distribution of data conditioned on these samples, i.e.,</p><formula xml:id="formula_1">x (i) = g(y (i) , z (i) ) ∼ p(x|y (i) , z (i) )<label>(2)</label></formula><p>where y (i) ∈ R Dr and z (i) ∈ R De . The estimations of range error and environment label from waveform x (i) can be obtained from the conditional distributions p(∆d|x (i) ) and p(k|x (i) ). With the two latent variables defined above, the problem can be transferred to estimating p(∆d|y (i) ) and p(k|z (i) ) instead, with y (i) , z (i) being the latent variables corresponding with x (i) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Network Learning Scheme</head><p>Given the observed measurements, the estimated range error ∆ d is obtained by the range-related variable y, and the predicted environment label k is obtained by the environmentrelated variable z. Both variables are obtained from the waveform x using the deep learning method described in the following.</p><p>Given a dataset D = {x (i) , ∆d (i) , k (i) } N i=1 consisting of N i.i.d. samples with paired waveform x, range error ∆d, and environment label k. The network structure consists of three sub neural modules: an auto-encoder (AE) for the disentanglement of latent variables, an estimator to predict range error, and a classifier to predict environment label. The whole network structure is illustrated in Fig. <ref type="figure" target="#fig_1">2</ref>. Specifically, the training phase consists of simultaneous-learning of the three neural modules:</p><p>1) the AE is learned on waveform sample x (i) ∼ D and disentangles two latent variables y (i) and z (i) in the bottleneck; 2) the estimator is learned on y (i) to obtain the range error ∆ d(i) with the supervision of ∆d (i) in the dataset; 3) the classifier is learned on z (i) to obtain the environment label k(i) with the supervision of k (i) in the dataset. In the testing phase, network parameters are learned and frozen. Given any received waveform x (j) , simultaneous error mitigation and environment identification are conducted on pure waveform data with the following two steps:</p><p>1) feed the waveform sample x (j) into the encoder of VAE and get range code y (j) and environment code z (j) ; 2) feed code y (j) into the estimator and get estimated range error ∆ d(j) ; 3) feed code z (j) into the classifier and get environment label k(j) .</p><p>Since the whole network is learned in a unified scheme, range error mitigation and environment identification can be conducted simultaneously in the testing step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Formulation of the Objective Function</head><p>Suppose the auto-encoder (AE) is denoted as (g enc , g dec ) with parameters {ϕ, θ}, where g enc (•; ϕ) : x → y, z and g dec (•; θ) : y, z → x. The range error estimator is denoted as f est with parameter φ e , and the environment classifier as f cls with parameter φ c , where f est (•; φ e ) : y → d and f cls (•; φ c ) : z → k. The objective function w.r.t. dataset D and parameters ϕ, θ and φ is composed of three loss terms: i) a reconstruction loss to regularize the outputs of AE, ii) a regression loss to make ∆ d close to the real error ∆d, and iii) a classification loss to make k close to label k, i.e.,</p><formula xml:id="formula_2">L(D; ϕ, θ, φ) = L rec x, x + L est ∆ d, ∆d + L cls k, k<label>(3)</label></formula><p>where related variables from AE are x = g dec g enc (x; ϕ); θ , the variable from the estimator is ∆ d = f est y; φ e , and the variable from the classifier is k = f cls z; φ c .</p><p>The reconstruction loss term in equation ( <ref type="formula" target="#formula_2">3</ref>) is given by:</p><formula xml:id="formula_3">L rec (D; ϕ, θ) = N i=1 ∥x (i) -x(i) ∥ 2 2 = N i=1 ∥x (i) -g dec g enc (x (i) ; ϕ); θ ∥ 2 2<label>(4)</label></formula><p>The loss terms for the estimator and the classifier in equation ( <ref type="formula" target="#formula_2">3</ref>) are given by:</p><formula xml:id="formula_4">L est (D; θ, φ e ) = N i=1 ∥∆ d(i) -∆d (i) ∥ 2 = N i=1 ∥ f est (g enc (x (i) ; ϕ); φ e ) -∆d (i) ∥ 2<label>(5)</label></formula><formula xml:id="formula_5">L cls (D; θ, φ c ) = N i=1 ∥ k(i) -k (i) ∥ 2 = N i=1 ∥ f cls (g enc (x (i) ; ϕ); φ c ) -k (i) ∥ 2<label>(6)</label></formula><p>Implemented by the proposed DGM with loss function Eq.( <ref type="formula" target="#formula_2">3</ref>), the optimization problem is conducted on dataset D with respect to parameters ϕ, θ, φ by addressing the optimization problem min ϕ,θ,φ L(D; ϕ, θ, φ) by means of stochastic gradient descent algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS</head><p>In this section, we evaluate the proposed algorithm using a UWB system as a case study. In particular, we give the quantitative results on range error mitigation and environment identification. Qualitative results of latent space visualization are also presented to show the effectiveness of environment semantic disentanglement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. UWB Database and Experimental Setup</head><p>We use a public database <ref type="bibr" target="#b12">[13]</ref> that is composed by waveform samples with labeled range errors (m) in different environment scenarios. The configurations for environment include 5 room scenarios and 10 obstacle scenarios. Specifically, the 5 room scenarios include i) an outdoor space, ii) 3 office-like rooms of large, medium, and small sizes, and iii) cross room  measurements. The obstacle scenarios include 10 different materials that block the LOS path. In order to explore the effect of different environments on waveforms, as well as evaluate the generality of the proposed method, we create 5 different datasets from this database. 1) Room Full: waveform samples from all the 5 room scenarios, each labeled with range error and the corresponding room scenario.</p><p>2) Room Rough: waveform samples from all the 5 room scenarios, each labeled with range error and the rough 'indoor' or 'outdoor' settings (i.e., conclude 3 office-like rooms and the cross room setting together as 'indoor'). 3) Room Part: waveform samples from 3 office-like rooms, each labeled with range error and the corresponding room scenario (i.e., big, medium or small sized). 4) Obstacle Full: waveform samples from all the 10 obstacle scenarios, each labeled with range error and the corresponding obstacle scenarios. 5) Obstacle Rough: waveform samples with heavy blocking materials (i.e., 'metal') and light ones (i.e., 'plastic', 'wood', 'glass'), each labeled with range error and the rough 'heavy' or 'light' settings.</p><p>For all the datasets, we randomly choose 80% data samples as the training set and the rest 20% samples as the testing set, without overlapping between the two sets to prevent overfitting.</p><p>We then conduct range error mitigation and environment identification on each of these datasets. SVM methods with hand-crafted features <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b4">[5]</ref> are adopted as baselines. Since conventional methods cannot conduct the two tasks simultaneously, a SVM as in <ref type="bibr" target="#b4">[5]</ref> is trained as a regressor for range error, and a separate SVM as in <ref type="bibr" target="#b9">[10]</ref> is trained as a classifier for environment identification. For convenience, we refer to the first SVM as SVR, and the second as SVC.</p><p>The proposed method is referred to as DGM for convenience. We build the VAE module and the classifier with cascaded 2D convolutional layers, and the estimator module with linear layers. The whole model is trained on GTX 1080 GPU with the accelerator powered by the NVIDA Pascal architecture. The code and trained models will all be released to public in our final version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results of Range Error Mitigation</head><p>We evaluate the range error mitigation performance in terms of the root mean square error (RMSE) and the mean absolute error (MAE). The results are presented in the first 6 columns of Table <ref type="table" target="#tab_0">I</ref>. The CDFs of the methods on dataset Room Full and Obstacle Full are shown in Fig. <ref type="figure" target="#fig_2">3</ref>. It can be seen that the proposed DGM achieves superior results in all the datasets, implying both effectivess and generality. Specifically, DGM can realize a centimeter-level accuracy, with improvements to SVR of over above 55% for RMSE and 80% for MAE. The steady performance rise across dataset illustrates the generality of DGM, without a problem to certain dataset. In addition, DGM obtains better results on room-related datasets than on obstacle-related datasets. This implies that the obstacle materials have a more complicated impact on range error than room layouts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results of Environment Identification</head><p>We evaluate the identification performance in terms of classification accuracy of environment labels, shown in the last two columns of Table <ref type="table" target="#tab_0">I</ref>. The proposed DGM shows better results than SVC in all the datasets. It can be noticed that the accuracy values on obstacle settings are relatively lower compared to room settings, in accordance with the results from range error mitigation that obstacles are more complex in semantics than room layouts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Latent Space Structure for Environment Semantics</head><p>We use UMAP algorithm <ref type="bibr" target="#b13">[14]</ref> for latent space visualization of environment semantics, which can reduce the highdimensional spaces to two dimensions while preserving the neighborhood of the latent codes. The scatter plots are shown in Figs. <ref type="figure" target="#fig_3">4</ref><ref type="figure" target="#fig_4">5</ref><ref type="figure">6</ref>. Each point is the latent code for one sample from the test set and the color represents the corresponding environment label. Note that the input to UMAP is the environment code z, and the scales of the x-and y-axis don't have any specific meaning but pure illustration for 2-dimensional visualization.</p><p>The learning process of latent codes is shown in Fig. <ref type="figure" target="#fig_3">4</ref>. It can be seen that code samples are gathered in a ring-shaped manifold in the early epochs. With the learning progress, the ring is gradually unfolded to fulfill the 2-dimensional space. Moreover, a spectrum can be observed, with heavy materials (e.g. metal windows (blue), metal plate (red), LCD TV (purple)) presented in the left part and light materials (e.g. glass plate (orange), wood door (green)) in the right part. We further consider latent codes of several critical classes for clearness, illustrated in Fig. <ref type="figure" target="#fig_4">5</ref>. It can be seen that metal obstacles (blue) is well separated from the others, while the rest three materials (red-green-orange) form a cluster. This hints at a connection between these environments, as they are all relatively light materials of low density. In the latter case, a remarkable separation of the two class can be observed. This implies that objects are clustered based on different dielectric coefficients, which consistent with the intuition.</p><p>Similar visualizations are conducted for room scenarios, shown in Fig. <ref type="figure">6</ref>. We can observe a cluster of indoor scenarios (red-green-orange), and a separation of the indoor and outdoor scenarios (purple). This explains the drastic difference between indoor and outdoor environments, and why existing methods find it challenging to generalize in both indoor and outdoor conditions. Such phenomenon implies that the environmental semantics lies in a low-dimensional manifold embedded in the high-dimensional data space, and can be effectively disentangled by the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>The paper introduced a DGM for efficient feature extraction of waveforms, which can simultaneously conduct range error mitigation and beyond NLOS environment identification. The proposed method was based on a Bayesian model and implemented by an efficient end-to-end learning network. The complicated high semantic features in raw waveform data were automatically exploited via the presented DGM framework. Experimental results illustrated the superior performance of our method on both tasks using a general dataset with different environmental settings. The presented methodology also guaranteed potential variants to the extraction of soft range information and direct learning-based localization schemes, which will be our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustrations of the proposed generative model for received waveforms. Waveform samples in data space are generated with latent variables for rangerelated features and environment semantics. Different environment semantics lead to different output waveforms.</figDesc><graphic coords="1,321.84,194.00,231.33,96.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Network structure of the proposed DGM for simultaneous range error mitigation and environment identification. Waveform samples are encoded into two latent variables with the guidance of real environment labels and range errors from dataset. The estimations are obtained via sub modules, with the according features extracted by the encoder from waveform as inputs.</figDesc><graphic coords="3,48.96,50.54,514.07,195.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The CDFs of the remaining error after mitigation on (a) Room Full dataset, and (b) Obstacle Full dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Visualization of environment codes on the Obstacle Full dataset, with model sampled every 100 epochs from epoch 0 to 500.</figDesc><graphic coords="5,74.67,50.54,462.68,227.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visualization of environment codes in different obstacle scenarios.</figDesc><graphic coords="6,58.83,50.54,231.33,326.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I QUANTITATIVE</head><label>I</label><figDesc>RESULTS ON RANGE ERROR MITIGATION AND ENVIRONMENT IDENTIFICATION WITH FIVE DIFFERENT ENVIRONMENT SETTINGS.</figDesc><table><row><cell></cell><cell cols="3">ENVIRONMENT SCENARIOS</cell><cell cols="2">RANGE ERROR MITIGATION UNMITIGATED SVR MAE RMSE MAE RMSE DGM MAE</cell><cell>ENVIRONMENT IDENTIFICATION SVC DGM ACCURACY ACCURACY</cell></row><row><cell></cell><cell cols="2">Room Full</cell><cell></cell><cell>0.1084</cell><cell>0.1553 0.0895 0.0568 0.0163</cell><cell>0.4859</cell><cell>0.6203</cell></row><row><cell></cell><cell cols="2">Room Rough</cell><cell></cell><cell>0.1066</cell><cell>0.1535 0.0886 0.0539 0.0157</cell><cell>0.9945</cell><cell>0.9998</cell></row><row><cell></cell><cell cols="2">Room Part</cell><cell></cell><cell>0.1118</cell><cell>0.1677 0.0916 0.0462 0.0078</cell><cell>0.7330</cell><cell>0.8551</cell></row><row><cell></cell><cell cols="2">Obstacle Full</cell><cell></cell><cell>0.1271</cell><cell>0.1746 0.1018 0.0678 0.0185</cell><cell>0.3129</cell><cell>0.3334</cell></row><row><cell></cell><cell cols="3">Obstacle Rough</cell><cell>0.1571</cell><cell>0.2083 0.1193 0.0878 0.0232</cell><cell>0.8650</cell><cell>0.9362</cell></row><row><cell></cell><cell>1.0</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CDF</cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3 0.4</cell><cell></cell><cell></cell><cell></cell><cell>Unmitigated Error SVM GEM (Our Method)</cell></row><row><cell></cell><cell>0.0</cell><cell>0.1</cell><cell cols="2">0.2 Residual Range Error (m) 0.3 0.4</cell><cell>0.5</cell><cell>0.6</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>ACKNOWLEDGMENT This research is partially supported by the <rs type="funder">Basic Research Strengthening Program of China</rs> (<rs type="programName">173 Program</rs>) (<rs type="grantNumber">2020-JCJQ-ZD-015-01</rs>), the <rs type="funder">Basque Government</rs> through the <rs type="programName">ELKARTEK programme</rs>, the <rs type="funder">Spanish Ministry of Science and Innovation through Ramon y Cajal</rs> Grant <rs type="grantNumber">RYC-2016-19383</rs> and Project <rs type="grantNumber">PID2019-105058GA-I00</rs>, and <rs type="institution">Tsinghua University -OPPO Joint Institute for Mobile Sensing Technology</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qV7v9Fn">
					<idno type="grant-number">2020-JCJQ-ZD-015-01</idno>
					<orgName type="program" subtype="full">173 Program</orgName>
				</org>
				<org type="funding" xml:id="_beTFbyX">
					<orgName type="program" subtype="full">ELKARTEK programme</orgName>
				</org>
				<org type="funding" xml:id="_MEaGsvw">
					<idno type="grant-number">RYC-2016-19383</idno>
				</org>
				<org type="funding" xml:id="_jCdXBuG">
					<idno type="grant-number">PID2019-105058GA-I00</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Soft range information for network localization</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mazuelas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Conti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Win</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3155" to="3168" />
			<date type="published" when="2018-06">Jun. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Localization Based on Channel Impulse Response Estimates</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Conti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Win</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Position Location and Navigation Symp. (PLANS)</title>
		<meeting>IEEE Position Location and Navigation Symp. (PLANS)</meeting>
		<imprint>
			<date type="published" when="2020-06">Jun. 2020</date>
			<biblScope unit="page" from="1014" to="1021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SpotFi: Decimeter level localization using WiFi</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kotaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bharadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Katti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM<address><addrLine>London, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-08">Aug. 2015</date>
			<biblScope unit="page" from="269" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enabling situational awareness in millimeter wave massive MIMO systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mendrzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Win</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization of environment codes in different room scenarios</title>
		<imprint>
			<date type="published" when="2019-08">Aug. 2019</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1196" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A machine learning approach to ranging error mitigation for UWB localization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wymeersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Maranò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Gifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Win</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1719" to="1728" />
			<date type="published" when="2012-04">Apr. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fundamental limits of wideband localization -Part II: Cooperative networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wymeersch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Win</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4981" to="5000" />
			<date type="published" when="2010-10">Oct. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Position location for futuristic cellular communications: 5g and beyond</title>
		<author>
			<persName><forename type="first">O</forename><surname>Kanhere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rappaport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Commun Mag</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="70" to="75" />
			<date type="published" when="2021-02">Feb. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Diland: An algorithm for distributed sensor localization with noisy distance measurements</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1940" to="1947" />
			<date type="published" when="2010-03">Mar. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Robust ultra-wideband range error mitigation with deep learning at the edge</title>
		<author>
			<persName><forename type="first">S</forename><surname>Angarano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mazzia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Salvetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiaberge</surname></persName>
		</author>
		<idno>abs/2011.14684</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Non-line-of-sight identification and mitigation using received signal strength</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trigoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Frolik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Commun</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1689" to="1702" />
			<date type="published" when="2015-03">Mar. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine learning for wideband localization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Win</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Areas Commun</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1357" to="1380" />
			<date type="published" when="2015-07">Jul. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">CSI-based outdoor localization for massive MIMO: Experiments with a learning approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Decurninge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Ordóñez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ferrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guillaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proc. 15th Int. Symp. on Wireless Communication Systems</title>
		<meeting>15th Int. Symp. on Wireless Communication Systems</meeting>
		<imprint>
			<date type="published" when="2018-08">Aug. 2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Deep UWB: A dataset for uwb ranging error mitigation in indoor environments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Angarano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Salvetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mazzia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chiaberge</surname></persName>
		</author>
		<ptr target="https://zenodo.org/record/4290069.X75qYc3-3Dc" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">UMAP: Uniform manifold approximation and projection for dimension reduction</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<idno>abs/1802.03426</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
