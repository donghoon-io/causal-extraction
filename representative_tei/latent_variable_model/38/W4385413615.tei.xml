<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">VAE-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation</title>
				<funder ref="#_9KByd5X">
					<orgName type="full">EU H2020</orgName>
				</funder>
				<funder ref="#_Jn7Zk8Q">
					<orgName type="full">UKRI/EPSRC RAIN</orgName>
				</funder>
				<funder ref="#_ZZjA656">
					<orgName type="full">EPSRC CDT</orgName>
				</funder>
				<funder ref="#_gDRJHGC">
					<orgName type="full">ORCA</orgName>
				</funder>
				<funder ref="#_Uq8WNHK #_CXr4SmJ">
					<orgName type="full">EPSRC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-07-12">12 Jul 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alexander</forename><forename type="middle">L</forename><surname>Mitchell</surname></persName>
							<idno type="ORCID">0000-0002-8716-4598</idno>
						</author>
						<author>
							<persName><forename type="first">Wolfgang</forename><surname>Merkt</surname></persName>
							<email>wolfgang@robots.ox.ac.uk</email>
							<idno type="ORCID">0000-0003-3235-4906</idno>
						</author>
						<author>
							<persName><forename type="first">Mathieu</forename><surname>Geisert</surname></persName>
							<idno type="ORCID">0000-0002-5651-8736</idno>
						</author>
						<author>
							<persName><forename type="first">Siddhant</forename><surname>Gangapurwala</surname></persName>
							<email>sid-dhant@robots.ox.ac.uk</email>
							<idno type="ORCID">0000-0002-1308-3744</idno>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><forename type="middle">Engelcke</forename><surname>Oiwi</surname></persName>
							<email>oiwi@robots.ox.ac.uk</email>
							<idno type="ORCID">0000-0001-8306-1236</idno>
						</author>
						<author>
							<persName><forename type="first">Parker</forename><surname>Jones</surname></persName>
							<idno type="ORCID">0000-0003-0307-9837</idno>
						</author>
						<author>
							<persName><forename type="first">Ioannis</forename><surname>Havoutis</surname></persName>
							<email>ioannis@robots.ox.ac.uk</email>
							<idno type="ORCID">0000-0002-4371-4623</idno>
						</author>
						<author>
							<persName><forename type="first">Ingmar</forename><surname>Posner</surname></persName>
							<idno type="ORCID">0000-0001-6270-700X</idno>
						</author>
						<author>
							<persName><surname>Oiwi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Oxford</forename><forename type="middle">Martin</forename><surname>Engelcke</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Ingmar Posner are with the Oxford Robotics Institute</orgName>
								<orgName type="institution">Ioannis Havoutis</orgName>
								<address>
									<settlement>Parker Jones</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Ox</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">VAE-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-07-12">12 Jul 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2205.01179v2[cs.RO]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Quadruped locomotion is rapidly maturing to a degree where robots are able to realise highly dynamic manoeuvres. However, current planners are unable to vary key gait parameters of the in-swing feet midair. In this work we address this limitation and show that it is pivotal in increasing controller robustness by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters such as cadence, footstep height and full stance duration. Due to the nature of our approach these synthesised gaits are continuously variable online during robot operation. The use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on two versions of the real ANYmal quadruped robots and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Quadruped locomotion has advanced significantly in recent years, extending their capability towards applications of significant value to industry and the public domain. Driven primarily by advances in optimisation-based <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b4">[5]</ref> and reinforcement learning-based methods <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b7">[8]</ref>, quadrupeds are now able to robustly plan and perform dynamic manoeuvres, making them an increasingly popular and reliable choice for tasks such as inspection, monitoring, search and rescue or goods delivery in difficult. However, despite recent advances, important limitations remain. Due to the complexity of the system, models used for gait planning and control are often overly simplified and handcrafted for particular and pre-determined Fig. <ref type="figure">1</ref>: Using a variational auto-encoder (VAE), our approach learns a structured latent space capturing key stance phases constituting a particular gait. The space is disentangled to a degree such that application of a drive signal to a single dimension of the latent variable induces gait styles which can be seamlessly interpolated between with continuous control over key gait parameters such as cadence, full-support duration, foot swing height, and footstep distance. This approach allows for precise base twist control and readily transfers from ANYmal B to ANYmal C, a dynamically dissimilar robot, without retraining. Additionally, we measure disturbances as out of distribution seen during training and adjust cadence as a rudimentary, but effective response.</p><p>contact schedules <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>. In the worst case, this can limit the versatility of the robot as the models deployed are failing to exploit the full capability of the underlying hardware (e.g. <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>). In particular, fixed gait parameters limit the ability of the robot to react to and reject external disturbances such as pushes to the robot's base. For example, the ability to adjust the robot's swing trajectories on demand (e.g. the swing height, length and timing) allows the robot to stabilise itself. The feet can be placed faster and into positions ahead of the centre of mass. There are works which are capable of making adjustments to a pre-determined contact schedule. The first category of method updates the contact schedule utilising simplified dynamics-models <ref type="bibr" target="#b11">[12]</ref>. The second type solves for the contact timings in advance by adjusting the switching times between optimisation segments <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref> and uses reduced-order models. The last category optimises dynamics over gait schedules, footstep lengths and heights. These are often computationally expensive <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> meaning that varying the gait parameters is not achievable in real time. A limitation of all these methods is that they are unable to adjust key gait parameters, in particular the contact timings, of the feet midair. Furthermore, these adjustments are limited to small perturbations around a default value. The result of which is that these methods are unable to react quickly to external perturbations irrespective of the terrain the robot is traversing. In contrast, the ability to control key gait parameters -such as contact timing, swing height, and full-support duration -onthe-fly would enable a smooth interpolation between dynamic manoeuvres allowing for swift reaction to external stimuli. This leads to significantly more versatile locomotion.</p><p>Inspired by recent work on a quadruped that achieves a crawl gait via the traversal of a learnt latent space <ref type="bibr" target="#b14">[15]</ref>, we approach the challenge of continuous contact schedule variation from the perspective of learning and traversing a structured latent-space. This is enabled by learning a generative model of locomotion data which, in addition to capturing relevant structure in the latent space, also enables the detection and mitigation of disturbances to provide a versatile and robust planning framework. In particular, we train a variational auto-encoder (VAE) <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> on short sequences of statespace trajectories taken from a single gait type (trot), and predict a set of future states. We show that the resulting latent space has an interpretable structure, lending itself to the generation of a variety of trot styles, depending on how the latent space is traversed. In fact, examining trot trajectories in latent space reveals an oscillatory drive signal which controls fundamental aspects of the gait. We subsequently find that by overwriting this trajectory with a synthetic drive signal, we can continuously control the robot's gait properties whilst the robot is executing the motion. Parameters of this drive signal can be mapped explicitly to gait parameters such as cadence, footstep height, and full-stance support duration. With this, we can continuously vary the contact timings of feet midair. In fact we can accelerate the cadence of the swing feet from four steps a second at take off to eight at touch down within the duration of a single footstep. This constitutes a novel capability in quadruped control. We emphasise that this ability to generalise over gait styles emerges from training on a single gait type: a trot gait with constant parameters.</p><p>We illustrate the efficacy of our approach by generating a range of continuously blended trajectories firstly on the real ANYmal B quadruped robot -a medium-sized platform (35 kg) standing 0.5 m tall. Subsequently with no retraining, we repeat the experiment on the heavier ANYmal C quadruped, which weighs in at 50 kg and delivers twice the peak torque of the former platform. This demonstrates not only transfer from simulation to the real robot, but to a dynamically dissimilar platform crucially without retraining. While the latent space is learnt using examples only from a specific gait style, our approach is able to synthesise behaviours significantly beyond this training distribution. We choose to limit our analysis to locomotion on flat ground in order to fully explore and understand this novel control paradigm.</p><p>In addition, we leverage our generative approach to both characterise and react to external perturbations. A large impulse applied to the robot's base triggers a spike in the Evidence Lower Bound (ELBO) which clearly identifies the disturbance as out of the distribution seen during training.</p><p>Inspired by <ref type="bibr" target="#b17">[18]</ref>, which states that an increase in cadence is both a response to slip and a form of push recovery in humans, our planner automatically increases the robot's cadence to aid in counteracting the disturbance. This demonstrates a marked improvement in robustness.</p><p>To the best of our knowledge, our method is the first which enables the continuous online adaptation of the robot's gait characteristics during a swing phase whilst the robot is walking. It provides a versatile and data-driven approach to quadruped locomotion which additionally allows for disturbance detection and recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Statement of Contributions</head><p>The primary contribution of this paper and its conference version Next Steps <ref type="bibr" target="#b18">[19]</ref> is a novel planning methodology, which realises locomotion with continuously variable gait parameters. Indeed, prior art is only able to alter the future timings of quadruped's contact schedule <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, whilst the methods presented here facilitate the variation of timings for in-swing feet midair. Varying the foot step speed of the airborne feet in response to detected disturbance is shown to increase the robot's ability to reject large push disturbances. In this paper, we deploy the VAE without retraining on a brand new platform with significantly different dynamics: the ANYmal C. This paper extends our previous work, Next Steps <ref type="bibr" target="#b18">[19]</ref> in order to showcase in-depth analysis of the method previously proposed. This includes significant extensions to key sections of Next Steps as well as new analysis. In particular, we have extended the description and justification for the oscillatory drive-signal in Sec. III-A. We have significantly expanded the interpretation of the latent-space structure and explain how the trajectory in this space looks (Sec. VI-A). Additionally, we compare the nominal trajectory in latent space to that seen during the disturbance and recovery phase, significantly expanding on the analysis of the disturbance rejection experiments (Sec. VI-H). We also extend the discussion of the ablation study of the model's sensitivity to hyper-parameters (Sec. VI-C).</p><p>In this paper, we introduce new aspects of analysis. Firstly, we show how backpropagating the binary cross-entropy (BCE) through the VAE's encoder is essential for structuring the latent-space (Sec. VI-B). The result of which are crisp decision boundaries and axis-alignment of the latent space. This results in an interpretable and disentangled representation. Secondly, we analyse the receptive field of the VAE's encoder in order to understand how the robot's gait phase is inferred, see Sec. VI-D. Inference of the gait phase is crucial for successful closed-loop planning in latent-space. Thirdly, we compare the dynamic feasibility of the trajectories from the VAE-planner to those seen during training, see Sec. VI-F and show that the VAE-planner's locomotion trajectories remain dynamically feasible as they are significantly varied. Next, we compare the distribution of realisable gait parameters output from the VAEplanner to those seen in the dataset, see Sec. VI-G. We show the range of gaits achievable using our approach and compare this to the distribution seen during training. Lastly, after showing that the approach can transfer from simulation to the real ANYmal B in Next Steps, we push this limit and deploy the VAE-planner on ANYmal C without retraining, (Sec. VI-I). This experiment demonstrates the extent to which the VAEplanner is able to generalise to out-of-distribution scenarios. In particular, ANYmal C exhibits significantly different dynamics to ANYmal B, which are detailed in Sec. V-I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Planning and control for quadruped locomotion have advanced in leaps and bounds in recent years. For example, hierarchical-optimisation frameworks split locomotion tasks into a series of smaller problems. Examples in this area include Dynamic Gaits (DG) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b11">[12]</ref> and <ref type="bibr" target="#b19">[20]</ref>. DG and <ref type="bibr" target="#b19">[20]</ref> enable a quadrupedal robot (such as ANYmal) to execute a wide variety of dynamic gaits (e.g. trot, pace, lateral walk, jump) with realtime motion planning and control. However, to achieve this impressive range of behaviours, all these methods provide each gait type with its own contact schedule and utilise an environment-specific footstep planner, ultimately limiting their capabilities. The work in <ref type="bibr" target="#b20">[21]</ref> addresses the shortcomings of hierarchical planning approaches by learning a set of heuristic operating ranges in order to increase the overall dynamic range of quadruped locomotion. This is similar in philosophy to the work we present here. However, we achieve a broad dynamic range by learning a distribution over feasible trot gaits. This distribution is then sampled via our drive signals resulting in flexible and dynamic trot locomotion. This allows us to continually adjust the foot-swing timing of the airborne feet and is achievable much faster and to a broader degree than prior art. We distinguish this ability from methods which perturb the swing-duration of feet which are yet to break contact <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>. In addition, <ref type="bibr" target="#b11">[12]</ref> requires a heuristic metric for synchronising the contact scheduler with the current contactstate. Our approach sidesteps this requirement by performing closed-loop feedback directly in the learnt latent-space.</p><p>Latent space approaches for planning and control learn useful and typically low-dimensional representations that can be used to control complex dynamics, without relying on known system models. Classic examples include Deep Variational Bayes Filters (DVBF) <ref type="bibr" target="#b21">[22]</ref> and Embed to Control (E2C) <ref type="bibr" target="#b22">[23]</ref>. DVBF produces dynamically consistent trajectories by traversing continuous paths in latent space whilst E2C learns a linear system model in which control problems can be solved. Conditional Neural Movement Primitives (CNMP) <ref type="bibr" target="#b23">[24]</ref> is a more recent latent space approach for robotic arms that generalises between a variety of tasks, such as pick-and-place and obstacle avoidance. Other recent works like UPN and PlaNet <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> show impressive capabilities in simulation but are yet to be applied to real-world systems, including floating-base robots.</p><p>In the locomotion domain, Li et al. propose an approach in <ref type="bibr" target="#b26">[27]</ref>, which utilise a learnt latent-action model to create different locomotion trajectories. However, this latent-action space does not capture robot dynamics, and samples trajectories via a random shooting method. In contrast, First Steps <ref type="bibr" target="#b14">[15]</ref> learns a structured latent space based on feasible robot configurations to capture the complete robot dynamics. First Steps defines a set of performance predictors that can be used in an optimisation framework to control the robot. In practice, these performance predictors can be viewed as symbolic inputs (e.g. 'left front leg up') but drive the robot in continuous space. However, because First Steps is trained on static snapshots of robot configurations, it does not learn from observable dynamics and thus requires more explicit structuring of the latent space than is necessary. Our previously published work Next Steps <ref type="bibr" target="#b18">[19]</ref> addresses this shortcoming and significantly extends this framework to effective and robust closed-loop planning and control. In this paper, we provide significantly more in-depth study into continuous variation of the gait parameters via planning in a structured latent-space. In doing so, we further justify the utilisation of an oscillatory drive signal, analyse the quality of the VAE's trajectories, and push the limits of domain transfer through deployment on new robotic platform without retraining.</p><p>The Motion VAE (MVAE) <ref type="bibr" target="#b27">[28]</ref> learns to represent dynamic trajectories in a structured latent space for the locomotion of computer-animated humanoids. This is similar to our emphasis here on learning representations for dynamic trajectories in the context of locomotion. However, moving from simulated to real physical systems, as is required for robotic applications, necessitates tackling additional complexities like latency, hard real-time requirements, and actuator dynamics. In this work, we tackle these challenges and demonstrate that a single gait style contains sufficient richness to learn a structured latent space that can be exploited to manipulate gait characteristics that generalise beyond the range seen during training. Unlike MVAE, our approach does not train on multiple gait styles, despite succeeding in producing them.</p><p>Other approaches build a model over multiple gait types and styles without utilising a structured latent-space. An example of which is <ref type="bibr" target="#b28">[29]</ref>. This utilises a vision-based system to sample a footstep schedule and gait for the terrain ahead. These form the input to an MPC approach. Alternatively, we choose not to condition the gait parameters on vision, but allow the operator to directly choose the gait style. Additionally, our system is able to generate a broad range of trot trajectories while being trained on a single demonstration of a trot gait with fixed parameters. Hence, we propose our method as an alternative to <ref type="bibr" target="#b28">[29]</ref> for creating a queryable model over different types of locomotion styles.</p><p>Finally, a study conducted concurrently to our own <ref type="bibr" target="#b29">[30]</ref> yields variation between gait types (walk and trot). It utilises a reinforcement learning (RL) approach which employs a phase iterator similar to our drive signal. However, this phase iterator is enforced, whilst our gait dynamics are discovered automatically purely from exposure to trot trajectories with constant parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. APPROACH</head><p>Our aim is to use unsupervised learning to infer a structured latent-space which facilitates real-time and smooth variation of key gait parameters. We conjecture that structure can emerge from the exposure of a suitable generative model to a gait with predetermined and constant characteristics such as cadence, swing height, and full-support duration. Specifically, we propose that due to this structure, continuous latent trajectories result in robot locomotion, see Fig. <ref type="figure" target="#fig_0">2</ref>. By inspecting this structure, we discover a disentangled latentspace where gait parameters are axis-aligned within this space (Sec. VI-A). Periodic trajectories in latent space can then be decoded back to smooth robot locomotion as depicted in Fig. <ref type="figure">1</ref>. Subsequently, the VAE is deployed as a planner in a real-time control loop.</p><p>VAE Architecture: We train a VAE <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> to create a structured latent-space using observed dynamic data. The input to the VAE X k at time step k consists of N robot states sampled from simulated trot gaits with constant parameters (e.g. cadence and foot-step height). These state-space quantities are values we wish either to control or are required to infer the gait phase. These are joint angles; end-effector positions in the base frame; joint torques; contact forces; the base velocity; and the base pose evolution relative to a control frame, which is updated periodically. These quantities are denoted as</p><formula xml:id="formula_0">x k = [q k , ee k , τ k , λ k , ċk , ∆c k ],</formula><p>where k is the time step. Note that velocities and accelerations do not form part of the VAE's input, but are inferred from the input history. This has dual benefits: first, it yields a lower-dimensional input space; and, second, it prevents sensitivity to fast-changing quantities such as the recorded joint accelerations during inference.</p><p>To deploy the VAE-planner in a closed-loop framework, we encode the input history at the control frequency f c . However, due to restrictions on the VAE's size caused by the tight computation bounds required for real-time control, the encoder input X k is constructed using states spaced at a frequency of f enc :</p><formula xml:id="formula_1">X k = [x ⊤ k-r(N -1) , . . . , x ⊤ k-r , x ⊤ k ],<label>(1)</label></formula><p>where r = f c /f enc is the ratio between the control and encoder frequencies. The input X k is created every time step by sampling from an input buffer which stores every robot state x from time step k to kr(N -1) at the control frequency. We provide full details of the setting used in our experiments in Sec. IV-B. The VAE's decoder output X+ k predicts the current robot state x k as well as M future ones sampled at a frequency of</p><formula xml:id="formula_2">f dec = f c : X+ k = [x ⊤ k , x⊤ k+1 , . . . , x⊤ k+M ].<label>(2)</label></formula><p>Here, + denotes future steps and ˆdenotes predictions.</p><p>As the desired-feet-in-contact is an input to the tracking controller, we also want to predict which of the four feet are in contact, s k , at the current time step, k, as well as J steps in the future. Inspired by First Steps <ref type="bibr" target="#b14">[15]</ref>, we therefore utilise a feet-in-contact performance predictor g pp (z k ). This is attached to the latent space, which estimates the probability of each foot being in contact:</p><formula xml:id="formula_3">Ŝk = [ŝ ⊤ k , ..., ŝ⊤ k+J-1 ] ⊤<label>(3)</label></formula><p>To command the base twist of the robot, a high-level action command a k is utilised. This represents longitudinal (x), lateral (y), and yaw (θ) twist in the robot's base frame. The latent state z k and the action a k form the input to the decoder.</p><p>Training the VAE: We train the VAE and performance predictor together. The VAE's training loss is the modified ELBO formulation found in <ref type="bibr" target="#b30">[31]</ref>. This loss consists of a reconstruction loss (mean-squared error) plus the Kullback-Leibler (KL) divergence D KL between the inferred posterior q(z|X k ) and the prior p(z), multiplied by a hyper-parameter β:</p><formula xml:id="formula_4">L ELBO = MSE(X + k , X+ k ) + βD KL [q(z|X k )||p(z)].<label>(4</label></formula><p>) These ELBO terms are then summed with the binary crossentropy loss between the predicted feet in contact and the recorded ones. The latter term is scaled by γ, resulting in the overall loss</p><formula xml:id="formula_5">L = L ELBO + γBCE(S k , Ŝk )<label>(5)</label></formula><p>The VAE training loss (Eq. 4), as seen in prior work <ref type="bibr" target="#b30">[31]</ref>, is responsible for any subsequent disentanglement found in the latent space. The reconstruction error is weighed against the decomposition of the latent space using the hyper-parameter β. This constraint encourages an efficient latent representation, containing only the required information for reconstruction, hence acting to regularise the latent space. As shown in <ref type="bibr" target="#b30">[31]</ref>, the D KL term used with an isotropic unit Gaussian (p(z) = N (0, I)) encourages conditional independence within z.</p><p>In our approach, as well as that of First Steps <ref type="bibr" target="#b14">[15]</ref>, a structured latent space is encouraged by backpropagating gradients from the performance predictor's loss through to the encoder input. However, we hypothesise that useful structuring of this space is inferred from the continuous trajectories used for training, and, in contrast to First Steps, no explicit labelling for each stance is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Control over the gait parameters</head><p>Once the VAE has been trained as described above, we find that the learnt latent-space is disentangled. We discover that an oscillation injected into one latent dimension decodes to the robot taking steps. Further analysis detailed in Sec. VI-A finds that adding a second oscillation into the latent space varies the robot's step length. The former oscillation we denote as the drive signal, and the latter as the trot signal. We find that in order to control the robot, we only need to inject the drive signal into latent space, and can infer the trot signal. By modulating and visualising the joint-space output from the decoder, we discover that varying the amplitude and phase of the drive signal leads to continuously variable trot locomotion. Therefore, we choose a specific drive signal with features which map directly to the gait parameters we wish to control. These parameters are the robot's cadence, stance duration and step height.</p><p>While any periodic oscillation (e.g. sin) decodes to robot locomotion, we choose a drive signal featuring specific components allowing for control over the robot's cadence, swing duration and step height. The drive signal chosen here is a modified sin 3 oscillation with amplitude A k , and phase ϕ k :</p><formula xml:id="formula_6">z k,dz = A k sin 3 (ϕ k ).<label>(6)</label></formula><p>The amplitude A k controls the foot swing height, and the phase ϕ k governs cadence and support duration.</p><p>To control the robot's swing and stance duration separately, we set the drive signal's time-period T k and we employ a stance counter ϵ k . The time-period T k is equal to the swing duration, whilst the time that the drive signal is equal to zero is extended by ϵ k time steps to introduce a full-support duration of (ϵ k /f c ) s. Hence, once both T k and ϵ k are used together, the phase dynamics are:</p><formula xml:id="formula_7">ϕ k+1 = ϕ k if ϕ k mod π = 0 and k ϵ &lt; ϵ k ϕ k + 2π/T k otherwise (7)</formula><p>and, in tandem, the counter ϵ k is updated as:</p><formula xml:id="formula_8">k ϵ ← k ϵ + 1 if ϕ k mod π = 0 and k ϵ &lt; ϵ k 0 otherwise<label>(8)</label></formula><p>A sin 3 (•) drive signal is chosen as it is smooth over its domain meaning that the decoded trajectories will also be smooth. Additionally, a sin 3 (•) drive signal's gradient is zero at ϕ k = Kπ for K ∈ Z. Therefore, there is a continuous transition between the sin 3 (•) part of the drive signal and the points where the drive signal is held artificially zero for ϵ k control-ticks. The resulting signal is shown in Fig. <ref type="figure" target="#fig_1">3</ref> along with the decoded contact schedule and swing trajectory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Planning for closed-loop control</head><p>Once the VAE is trained, it is fast enough to act as a planner in a closed-loop controller. Thus, our approach can react to external disturbances and mitigate against real-world effects such as unmodelled dynamics and hardware latency. For closed-loop control, we begin by encoding a history of robot states from the raw sensor measurements to infer the current gait phase. We store a buffer of past robot states and sample from this at f enc to create the encoder's input.</p><p>With an estimate of the current latent variable, we overwrite latent dimension d z with the drive signal (see Sec. III-A). Next, we employ a second-order Butterworth filter to smooth the latent trajectory and further smooth the locomotion plan. In essence, the drive signal encourages the decoder to output the next open-loop prediction while the other latent variables infer the gait phase from the raw sensor input. This process is repeated at the control frequency (400 Hz).</p><p>The latent variable z k and a desired base twist a k are decoded to produce X+ k = g dec (z k , a k ). From this, the jointspace trajectory Qk , and local base velocity Ĉk are extracted and derived or integrated to produce the base and joint positions, velocities and accelerations. These quantities and the predicted contact schedule are sent to the wholebody controller (WBC) <ref type="bibr" target="#b31">[32]</ref>. The WBC solves a hierarchical optimisation problem to calculate the joint torques which are commands sent to the actuators. The series of constraints enforced by the WBC are: contact creation, friction constraints and torque limits. Next, the WBC applies forward kinematics to the VAE's trajectory to track it in task-space. Note that the WBC does not compensate for infeasible plans, i.e. the VAE's trajectories shown in Sec. VI-E are dynamically consistent otherwise the robot fails to walk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Disturbance detection and response</head><p>Our approach is able to both detect and react to disturbances. The VAE is trained using canonical feasible trajectories. Therefore, any disturbances are characterised as out of distribution with respect to the training set. Given the generative nature of our approach, this discrepancy is quantified during operation by the trained model via the Evidence Lower-Bound (ELBO, Eq. 4 where β is set to one). We will show in the evaluation (Sec. VI-H) that even a rudimentary response strategy serves to increase the range of disturbance the system can reject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMPLEMENTATION DETAILS</head><p>In order to deploy the VAE-planner on-board the ANYmal quadruped, there are a number of real-world constraints which affect the VAE-planner. The first of which is that in order to deploy the VAE in a real-time control loop, there is a constraint on the VAE's inference time. Secondly, we discuss how we address the simulation to reality gap. We discuss the VAE's specific architecture, the hyper-parameters used to train the model, and finally, specific the specific criteria required for domain transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset generation</head><p>To train the VAE and create the structured latent space, we require a set of continuous trot trajectories. We restrict these trajectories to quadruped locomotion over flat ground only so that we can study and understand how to generate versatile locomotion utilising a structured latent-space. The training trajectories are generated using Dynamic Gaits (DG) <ref type="bibr" target="#b0">[1]</ref>. DG is a hierarchical planning and control framework which is used with a fixed contact schedule and predefined footstep heights. The swing, full-stance durations and footstep heights set to 0.5 s, 75 ms and 0.10 m, respectively.</p><p>DG is made up of a footstep planner, a base motion planner and a whole-body controller (WBC). The footstep planner computes the next four steps over the gait period using an inverted-pendulum model. The base motion planner solves for the base trajectory over the gait period using a centroidal dynamics model <ref type="bibr" target="#b10">[11]</ref>. The latter is constrained with a Zero-Moment Point (ZMP) <ref type="bibr" target="#b9">[10]</ref> criterion, the footstep positions and schedule from the footstep planner. The WBC <ref type="bibr" target="#b31">[32]</ref> outlined in Sec. III-B converts the task space trajectories to joint feedforward torques, reference positions and velocities: these are sent to the actuators.</p><p>The dataset is generated by uniformly sampling desired base twist and executing DG in the RaiSim physics simulator <ref type="bibr" target="#b32">[33]</ref>. The fidelity of the simulation is improved by modelling the dynamics of the Series-Elastic Actuators (SEA) <ref type="bibr" target="#b33">[34]</ref> in the ANYmal's joints using an actuator network <ref type="bibr" target="#b5">[6]</ref>. We specifically utilise the network found in <ref type="bibr" target="#b7">[8]</ref>. This network takes into account the commanded positions, velocities, feedforward torques, and low-level PD gains The actuator network is essential for good performance as the input response of SEAs depends on a history of states, inputs, and the low-level control law.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. VAE architecture details</head><p>Fig. <ref type="figure">1</ref> outlines the approach's architecture, and here we describe the VAE's specific details. Prior to the ablation study in Sec. VI-C, the VAE's encoder, decoder and stance performance predictor have two hidden layers and widths of 256 units, using ELU non-linearities <ref type="bibr" target="#b34">[35]</ref>. The encoder input is created using N = 80 robot states sampled at 200 Hz -representing a history of 0.4 s -from the encoder input, which is of size 5120 units. The input is compressed via a latent space of 125 units which is concatenated with an action of 3 units. Next, the decoder outputs the current state and the next M = 19 robot states at the control frequency of 400 Hz (preview horizon 47.5 ms, output size: 1216 units). The performance predictor predicts the current feet in contact and two future states. Finally, hyper-parameters used for training are β = 1.0, γ = 0.5, with a learning rate of 1×10 -3 using the Adam optimiser. Training is terminated after 1 × 10 6 gradient steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Domain transfer</head><p>To achieve domain transfer and deployment on the real robot, some modifications are required. The contact forces are artificially set to zero when the robot measures no contact (as determined by a probabilistic contact estimator) <ref type="bibr" target="#b35">[36]</ref>. This is necessary since the real-world ANYmal robot measures large contact forces even during swing motion, as these forces are inferred from torque residuals and are affected by model error. In contrast, simulators estimate no contact force during swing. As mentioned in Sec. III-B, a Butterworth filter with a cutoff frequency of 10 Hz is employed to smooth the latent trajectory. Due to the strict computation budget for real-time control, inference times for the VAE are restricted to at most 1 ms, which imposes constraints on the capacity of the model (see Sec. VI-C for an ablation of model hyperparameters). Our largest model takes approximately 1 ms for the VAE computation, which is roughly equal to the computation time of the WBC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL DESIGN</head><p>In this section, we explain how the latent-space properties are discovered and how we assess the performance of the VAEplanner deployed on the real robot. In doing so, we motivate the following guiding questions. The aim of these questions is to analyse the latent space once the VAE is trained and to analyse the capabilities of the VAE as a flexible and robust locomotion-planner.</p><p>We investigate (i) the structure induced in the latent space (Sec. VI-A), (ii) the effect backpropagating the binary crossentropy gradients through the encoder has on the latent-space structure (Sec. VI-B) (iii) the sensitivity of our approach to variations in key hyper parameters (Sec. VI-C), (iv) which parts of the encoder's input are used to infer the robot's gait phase (Sec. VI-D), (v) to what extent the locomotion parameters can be varied online (Sec. VI-E), (vi) the feasibility of the locomotion plans produced (Sec. VI-F), (vii) a comparison between the gait parameters seen during training and those shown in experiments using the VAE-planner (Sec. VI-G), (viii) the degree to which disturbance detection, coupled with a rudimentary recovery strategy, further increases the robustness of our approach (Sec. VI-H), and finally, (ix) whether the VAE-planner can be deployed successfully on the next generation ANYmal C robot without retraining (Sec. VI-I). Please see the following video for an extended set of experiments along with a brief description of our approach (<ref type="url" target="https://youtu.be/GT2WLh2Ackc">https://youtu.be/GT2WLh2Ackc</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Investigating the latent space</head><p>We wish to examine if there is any structuring in the latent space as well as investigate if any locomotion properties are disentangled within. This knowledge is crucial in understanding how to solve for locomotion trajectories in latent space.</p><p>Latent Space Structure: Structure in latent space manifests itself as clustered latent variables. During training, we expect that points in latent space which are of the same gait type will become gathered together. To verify this, we sample a set of random latent variables which we pass through the stance performance predictor. These points are plotted and colourcoded based upon their predicted stance. The resulting plot can be found in Sec. VI-A, specifically in Fig. <ref type="figure">5</ref>.</p><p>Latent Space Disentanglement: We wish to see what trajectories in latent space look like, and if any of the dimensions within are interpretable. State-space trajectories of the robot trotting from the test set are encoded into latent-space, and the subsequent latent-space paths are visualised. These paths in latent space are oscillatory and each oscillation has its own phase.</p><p>In order to understand what each oscillation encodes, we artificially inject sine waves into each latent dimension in turn. Decoding these trajectories and visualising the jointspace paths reveals that the latent space is indeed disentangled. See Sec. VI-A for full details. This revelation informs how we solve for locomotion paths in latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Backpropagating the binary cross-entropy through the encoder</head><p>As in First Steps <ref type="bibr" target="#b14">[15]</ref>, we encourage the latent space to become structured by backpropagating the BCE loss for the contact state of the feet through the encoder. We train an alternative VAE where we detach the BCE gradients at the latent space. This means that the latent-space structure is not informed by the prediction loss of the feet in contact performance predictor. The resulting latent-space of the VAE with detached gradients is compared to the original. Firstly, we look for the crispness of the decision boundaries between stance clusters. Secondly, we look to see if the decision boundaries are aligned with any dimensions in latent space. This analysis is aimed to investigate the importance of using the contact performance predictor to generate feasible locomotion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Analysing the encoder's receptive field</head><p>In our experiments on the real robot, the VAE is able to infer the robot's gait phase from raw sensor inputs. We wish to understand which parts of the encoder's input are utilised to infer this. We utilise activation maximisation (AM) <ref type="bibr" target="#b36">[37]</ref> to measure the flow of gradients through the encoder. This procedure requires backpropagating from some randomly sampled input encoding until the encoder output matches a predetermined target value. The target is chosen to match key points along the robot's gait phase and are chosen such that the drive signal's phase is equal to 0.0, π/2, π/4, π/8, π. The gradients at the encoder input resulting from this optimisation are recorded. The magnitude of these values reveal which parts of the input are required to infer the gait phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Studying the VAE's sensitivity to key hyper-parameters</head><p>The VAE's architecture is ablated and the VAE-planner is tested in simulation until the gait phase can no longer be inferred. This leads to noisy and jerky trajectories in simulation. Firstly, the size of the latent dimension is reduced from 125 to a minimum of 6 in strides of 32 units. Secondly, the number of input states N is reduced from 80 units to 60, sampled at 200 Hz, meaning that the encoded input history reduces from 0.4 s to 0.3 s. Thirdly, the encoder frequency is halved to 100 Hz with N = 80. Lastly, the widths of the encoder, decoder and performance predictor are reduced in increments of 32 units from 256 to a minimum of 64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Varying the gait parameters online</head><p>We wish to vary the robot's gait parameters continuously whilst the robot is walking. This is straight-forward for the robot to do. We utilise a simple ROS publisher with which sets the drive signal's amplitude, time-period, and stance duration. The robot's base twist is commanded independently using the action a k . In fact, we utilise a navigation waypoint following controller which produces the action so that the robot walks around a square trajectory in our lab.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Analysing the dynamic feasibility of the VAE's trajectories</head><p>The previous guiding question asks how broad the set of manoeuvres from the VAE-planner are. We now compare the dynamic feasibility of these trajectories to plans from DG. Please note that this dynamic feasibility comparison is undertaken as a post-experiment analysis. On the robot, the output of the VAE-planner is sent directly to the WBC unaltered.</p><p>To evaluate the dynamic feasibility of trajectories synthesised by our VAE, we measure the distance of the Zero Moment Point (ZMP) <ref type="bibr" target="#b9">[10]</ref> to the support line (i.e. when one pair of legs are swinging) and then compare this distance with that in the synthetic dataset. The ZMP is a commonly used criterion in model-based legged robot control <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b9">[10]</ref>. This analysis is performed for the trajectories in the dataset as a baseline to which we can compare. Dynamically stable trajectories have the ZMP as close as possible to the support line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Measuring the distribution of gait parameters achievable with the VAE</head><p>The gait parameters set during the robot experiments are recorded meaning that we can measure the distribution of visited states. To show the entire range of movements and compare against those seen during training, we plot a box and whisker plot of the stance and swing durations. This shows the ability of the VAE-planner to generalise producing gait parameters not seen in the training distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Detecting and reacting to disturbances</head><p>We wish to analyse the degree to which disturbances can be detected and whether increasing the robot's cadence helps Fig. <ref type="figure">4</ref>: Closed-loop control of the real ANYmal quadruped using our VAE-planner. This demonstrates user-controlled variation of gait parameters on the fly. Here, coloured rectangles represent the full-stance phase, whilst white space denotes the swing duration. The top row shows a trot gait with an introduced quadrupedal stance phase (gait cycle of 0.75 s -swing 312.5 ms, stance 62.5 ms; a gait cycle consists of a swing phase for each of the leg pairs). Next, the swing duration T k is reduced using the time-period slider (gait cycle of 0.5 s -swing 188 ms, stance 62.5 ms). The third row illustrates the effect of reducing the stance duration counter ϵ k to produce trot with reducing full-stance phases (gait cycle of 250 ms -swing 125 ms, stance 0.0 s). Finally, transition into standing occurs when the drive signal amplitude A k is reduced to zero. To view the full range of movements, please see the following video <ref type="url" target="https://youtu.be/GT2WLh2Ackc">https://youtu.be/GT2WLh2Ackc</ref>. the robot to recover from them. As mentioned, we monitor the ELBO as this is a measure of the evidence for an encoded input relative to the learnt distribution. Hence, a large spike in this value (given the formulation in Eq. 4) is a consequence of a disturbance.</p><p>To perturb the robot, we utilise a push broom and disturb the robot's base. If the ELBO value surpasses a pre-determined constant, we characterise the event as a disturbance. The ELBO value is calibrated such during normal operation, the ELBO remains below this "disturbance" threshold. This is easily found by walking the robot using the VAE-planner for 2 min, whilst recording the ELBO.</p><p>Following disturbance detection, the VAE-planner automatically reduces the drive signal's time-period to increase the robot's cadence. This response is inspired by human locomotion in response to slippage <ref type="bibr" target="#b17">[18]</ref>: a group of participants encounter a slippery surface and their reaction is recorded, resulting in an increase in cadence.</p><p>We evaluate the effectiveness of increasing the robot's cadence by repeating the push experiment with and without the cadence increase. The base velocity is utilised to measure the size of the disturbance. Larger velocities arise from bigger pushes. We make a comparison between the reactive VAEplanner and a constant cadence version.</p><p>In addition, the latent-space trajectory is inspected during and after a disturbance. We are interested in how this is affected by out of distribution occurrences like a shove from a push broom or a kick to the robot's base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Deployment on ANYmal C without retraining</head><p>The VAE which is trained using simulated ANYmal B locomotion data is deployed on ANYmal C without retraining. Since our generative model has successfully transferred from simulation to the real robot, a key question is can the VAEplanner work on a different robot with similar kinematics, but significantly different dynamics? Therefore, we deploy the VAE-planner on a different robot which has a few key differences. Firstly, the ANYmal C has around twice the torque limit of ANYmal B, 80 N m and 40 N m respectively. Secondly, ANYmal C is significantly heavier than ANYmal B weighing in at 50 kg to B's 35 kg. Finally, ANYmal C's actuators have a lower bandwidth due to the additional reduction gearing.</p><p>The only alterations made to the VAE-planner are firstly the torques are standardised to reflect the difference in peak torque demand, and secondly, the WBC's internal dynamics' model is updated to ANYmal C.</p><p>As previously discussed, the VAE-planner can be utilised to measure differences between the learnt distribution and the encoded one. Therefore, this approach is able to characterise differences between the two robots. Again, we utilise the ELBO for this, and we record this quantity when the VAEplanner is deployed on ANYmal C. The ELBO distribution can be separated in the KL divergence and the reconstruction error. The former provides insight into the distribution of encoded values and the latter acts as a prediction loss.</p><p>To verify if the differences in KL-divergence collected from both robots are statistically significant, we utilise a Mann-Whitney U-test <ref type="bibr" target="#b37">[38]</ref>. Our null hypothesis is that the median of the distribution from ANYmal B is equal to the median from the distribution from ANYmal C. The values of KL-divergence are collected from deploying the same VAE-planner on both robots. In total, we analyse 2.5 × 10 4 values from each robot, which is equivalent to 62.5 s at 400 Hz. The nullhypothesis is rejected if the resulting p-value is less than our chosen statistical significance value of 0.1 %. This procedure is repeated for the two sets of reconstruction error gathered from each robot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTAL RESULTS</head><p>Now that we have posed our guiding questions and stated how to answer them, we present the results. These questions can be split up into two categories: (a) introspection of the VAE and (b) analysis of the VAE as a planner deployed on two real-world platforms. Please see the following video for a complete set of experiments along with a brief description of our approach: <ref type="url" target="https://youtu.be/GT2WLh2Ackc">https://youtu.be/GT2WLh2Ackc</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Structure induced in the latent space</head><p>The latent space is inspected to discover what structure exists and if any locomotion properties are disentangled within.</p><p>Latent Space Structure: Fig. <ref type="figure">5</ref> shows samples from the latent space colour-coded by their predicted stance. For trot, there are four stances: the full-support phase, left front and right hind in contact, another support phase and finally right front plus left hind in contact. Fig. <ref type="figure">5</ref> reveals that the latent space has emerged clustered by stance and that, due to the ordering of these stances, a periodic trajectory decodes to a trot gait. This favourable structure is inferred from the continuous trot trajectory input during training.</p><p>The ordering of the clusters matches the sequence of the trot gait. The reason for this is that the encoder's input contains information about the evolution of the robot's state over time. This additional information coupled with the training paradigm means that continuous trajectories in latent space match with continuous trajectories in state space. This is in contrast to the work in First Steps <ref type="bibr" target="#b14">[15]</ref>. First Steps generates a crawl gait via gradient descent in a structured latent-space. However, the input to that model is a static snapshot of the robot's state with no temporal information (e.g. x k ). Since there is no information about the evolution of the robot's state in the encoder's input, additional structuring was required to order the clusters in the crawl gait sequence.</p><p>Latent Space Disentanglement: By examining the latent variables, we discover that oscillations injected into just two dimensions in the latent space decode to continuously varying trot trajectories. This result stems from a latent space where variation in footstep length and cadence is aligned along one dimension, while variation in footstep distance lies along another. Specifically, the time period of what we denote the drive signal oscillation controls the robot's cadence, whilst its amplitude is proportionate to the footstep height. In addition, the amplitude of the second signal, which is π/2 out of phase with the drive signal, controls foot swing length and as such is denoted as the trot signal. Given that other work has tried to explicitly build this structure into locomotion systems <ref type="bibr" target="#b29">[30]</ref>, it is important to emphasise that this disentanglement emerges in our study as a result of the training paradigm and data. Only the synthetic drive-signal needs to be injected into the latent space for closed-loop control; the trot signal is inferred.</p><p>Visualising The Latent-Space Trajectory: We plot the injected drive-signal and inferred trot signal in Fig. <ref type="figure">5</ref> in red and blue respectively. When these two signals are plotted against one another, they combine to form a cycle in latent space. This is plotted as the black-vector field in Fig. <ref type="figure">5</ref>. This cycle is annotated to show how the latent-space trajectory visits each stance cluster in turn. We also show the corresponding contact schedule with images of the robot in their matching configurations.</p><p>To begin at point (1), the robot has four feet in contact, before moving anti-clockwise tracing out a triangular lobe in the red region to point <ref type="bibr" target="#b1">(2)</ref>. This lobe forms the first foot-swing. The trajectory continues anti-clockwise through the magenta region (3) before tracing another lobe through the blue area back to point <ref type="bibr" target="#b0">(1)</ref>. This cycle repeats as the robot takes more steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Backpropagating the BCE loss through the encoder</head><p>We compare the latent space created by backpropagating the BCE gradients through the encoder to the vanilla case, where these gradients are detached before the latent space in Fig. <ref type="figure" target="#fig_2">6</ref>. The latent space structured using the BCE gradients exhibits crisp decision boundaries for the stance clustering. These boundaries are aligned perpendicular to the drive-signal dimension in latent space, meaning that stance classification results mostly from this dimension. In contrast, the detached gradient latent-space has fuzzy decision boundaries. This is less than ideal as the predicted contact state is an input to the controller, and vitally affects the propagation of the dynamics model. If this is a noisy prediction, the robot will change contact state in an unpredictable way. Note that the decision boundaries in the detached case are rotated at roughly 30 • in comparison the nominal case. This results in the latent space being no longer axis aligned with the drive signal. In order to create locomotion trajectories and have independent control over the gait parameters, namely step height and length, the drive signal needs to be rotated to align with Fig. <ref type="figure">5</ref>: The latent space and trajectory in black during unperturbed operation. The latent space trajectory is result of the combination of the red drive-signal along the horizontal dimension and the blue trot-signal in the vertical. The drive signal is user controlled, whilst the trot-signal is inferred. The subsequent robot locomotion and contact schedule is included. the decision boundaries. This is not required for the nominal case, where the BCE gradients are backpropagated through the encoder. Therefore, the crisp decision boundaries and the axisalignment justifies our decision -and more crucially highlights the importance -of using the BCE gradients to structure the latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Sensitivity To Hyper Parameters</head><p>As mentioned in Sec. IV-C, real-time performance is only achievable if VAE inference can be performed in under a 1 ms. Therefore, we report the results of our ablation study where the VAE's channel capacity is systematically reduced. Table <ref type="table">I</ref> summarises the results of this study. Firstly, the latent dimension is reduced from 125 to a minimum of 6. The VAE with latent size of 6 units is deployed successfully in simulation and on the real robot. Next, the VAE's width is reduced in 32-unit increments and a limit of 128 units is found. This corresponds to a reduction in channel capacity by 52.8 %.</p><p>Additionally, the window of time used to construct the VAE's input is reduced from 0.4 s to 0.3 s whilst maintaining an encoder frequency of 200 Hz. This results in poor openloop performance as the VAE is no longer able to learn the gait phase. This is a result of the swing duration in the dataset which is 0.45 s. Therefore, an input history over the last 0.3 s is insufficient to capture the gait phase. Next, we investigated reducing the encoder's sampling frequency f enc by halving it to 100 Hz whilst the history remains sampled over 0.4 s. Though this speeds up inference, the resulting trajectories are less smooth than the 200 Hz encoder and the robot is not stable during closed-loop operation.</p><p>As a result of these analyses, the minimum VAE architecture requires a latent space of 6 units, an input history of 0.4 s sampled at 200 Hz, and a hidden layer size of 128 neurons. We confirm this by deploying this reduced model on the real robot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE I:</head><p>We perform an ablation study to find the minimum channel capacity required for the VAE-planner to transfer successfully to the real robot. The original VAE model denoted as (O) is found in the bottom right-hand corner of this table. The latent-space size is reduced to six whilst the width remains 256. The width is reduced to 64 in units of 32. The smallest model which transfers to the real robot has width of 128 and latent size of six. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Analysing the encoder's receptive field</head><p>It is crucial that the VAE is able to infer the robot's gait phase from raw sensor input to permit successful latent-space planning. This poses the question which parts of the encoder input are used to infer this. Fig. <ref type="figure">7</ref> depicts a saliency map where a bright colour denotes areas of high gradient. These are areas where the VAE's encoder focuses to infer the gait phase. The left map in Fig. <ref type="figure">7</ref> shows the receptive field of the encoder over the entire input X k . Here, the input X k is reshaped such that each row is the robot state x k , see Eq. 1. The columns represent specific robot quantities which we have highlighted in Fig. <ref type="figure">7</ref>. The areas of high gradient are the contact forces and the most recent jointtorques. The left part of Fig. <ref type="figure">7</ref> are the contact forces normal to Fig. <ref type="figure">7</ref>: Visualisation of the encoder's receptive field with respect to the gait phase. The encoder input is reshaped such that robot state quantities such as joint torques are in the same column. We also show the contact forces normal to the ground plane λ zk . The lightest areas in these two sub-figures are of highest gradient meaning that the encoder focuses on these parts in order to infer the gait phase.</p><p>the ground plane (i.e. the z-direction). This plot reveals that the most recent and earliest contact forces are utilised to infer the gait phase. High values of contact force correlate well with the contact state. The joint torques are related to the contact forces through the robot dynamics' equation <ref type="bibr" target="#b38">[39]</ref>. Lastly, the basevelocity has a high gradient value. This quantity is utilised in inferring the robot's momentum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Varying locomotion parameters online</head><p>We leverage the disentangled latent-space to smoothly transition between gait parameters whilst the robot is walking. Crucially, cadence, stance duration, and footstep height can be varied during any phase of the gait by modulating the drive signal's parameters (see Sec. III-A). This results in operating modes which vary from those seen during training. Examples of walking motion using the VAE-planner on the real robot are shown in Fig. <ref type="figure">4</ref>.</p><p>Swing Duration: The swing duration is varied over a large operating window on the ANYmal robot. This begins with a swing time-period starting at 312.5 ms, and is smoothly varied until the swing duration reaches 125 ms, more than doubling the step rate. In parallel, we alter the robot's heading, demonstrating the independence of the action and the latentspace dynamics. Specifically, the top row of Fig. <ref type="figure">4</ref> shows the nominal swing duration of 312.5 ms as the robot turns clockwise, tracking a constant angular velocity command. Following this, we demand a slightly faster swing 188 ms and a constant angular velocity anti-clockwise, before transitioning to the fastest swing (125 ms) in the third row. Here, the coloured contact schedule captures the changes in swing duration as it occurs in real-time.</p><p>Stance Duration: Following a successful reduction in cadence, the stance duration is reduced and the robot transitions into a trot with negligible full-stance phase: ϵ k = 0. Trot gaits with little to no full-support phase are particularly challenging manoeuvres for the system in general, as there is reduced control authority to correct for accrued base pose error. During the swing phase of this gait style, only feet across the diagonal are in contact resulting in a line contact limiting the robot's ability to steady its base. The transition to a negligible fullstance phase is captured in the third row, where the coloured stance duration reduces in length. Note that the full-stance duration does not reduce to zero seconds. The mean lowest stance-duration is found to be 19.4 ms. We can see this in Fig. <ref type="figure">10</ref>, which shows the spread of achievable swing and stance durations compared to the those in the dataset. The right sub-plot shows the stance durations, where we see that the bottom whisker of plot does not quite touch zero. The reason for this is that the full-support region in the latentspace must be traversed. This part of latent space is highlighted in purple in Fig 2 . It is possible to introduce a non-smooth drive-signal which jumps this region, but this discontinuous drive-signal would introduce a large acceleration into the resulting locomotion trajectory. This might not be trackable by the WBC. Instead we recommend utilising a smooth and continuous drive-signal.</p><p>Footstep Height: We vary the amplitude of the drive signal smoothly to zero as is seen in the bottom row (Fig. <ref type="figure">4</ref>): The footstep height reduces to zero as the white-space in the contact schedule disappears and the robot remains standing. Beyond versatility, e.g. to increase swing heights to overcome irregular ground height, this capability further enables a safe, smooth and natural transition into and out of the VAE control mode (i.e. to start and come to a halt).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. ZMP of planned motion as a measure of dynamic feasibility</head><p>On the robot, the trajectories from the VAE-planner are sent directly to the WBC unaltered. Here, we compare dynamic feasibility of the trajectories shown in Sec. VI-E after the experiment in order to compare to the training dataset's distribution generated using DG. The position of the ZMP relative to the support line is utilised as a metric for this comparison. The optimal trajectory will have the ZMP lie on the support line.</p><p>The results of this are summarised in Fig. <ref type="figure">9</ref>. The distribution the ZMP positions is similar for both DG (dataset) and a range of the VAE-planner's operating modes. Crucially, this remains true despite the maximum swing duration generated by the VAE-planner being up to 3.2 times faster than in the training data. We conclude that the representation is good enough to generalise to the robot's dynamics shown here. Empirically, we have further been able to steer the robot with arbitrary and fast changing input actions for x, y, and yaw rates, issued from a remote control while being able to interpolate the gait style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Generalisation to different trot-gait styles</head><p>The VAE is able to produce a far broader range of different trot styles than those in the dataset. The ranges of swing Fig. <ref type="figure">8</ref>: Push recovery following a shove to the base. A disturbance to the robot causes the ELBO of the form in Eq. 4 to rise above a predetermined threshold (red areas). This identifies a disturbance and triggers an increase in cadence from 250 ms to 125 ms as a rudimentary response. This reduction in the swing duration is visible in the contact schedule. To appreciate the results fully, please see the following video <ref type="url" target="https://youtu.be/GT2WLh2Ackc">https://youtu.be/GT2WLh2Ackc</ref>. and stance durations produced by the VAE in Sec. VI-E and those in the dataset are summarised in Fig. <ref type="figure">10</ref>. As discussed previously, the dataset is constructed utilising a pre-determined and constant swing duration of 500 ms, with stance duration of 75 ms. The VAE-planner's swing duration varies between 312.5 ms and 125 ms and its stance ranges between 325 ms to negligible duration. This demonstrates that the VAE-planner is able to generalise to a variety of trot styles by navigating the structure within the disentangled latent-space, even when trained using a very restrictive training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Disturbance detection and recovery</head><p>Our approach is able to detect and mitigate disturbances applied to the robot using a heuristic policy which monitors the ELBO loss whilst the robot is walking. The robot is pushed with a broom resulting in a large spike in the ELBO loss. A spike above a certain threshold is characterised as a disturbance. For our push experiments, we choose the ELBO threshold value to be 11.0. We find this value by walking the robot around the lab using the VAE-planner and choosing a value above what is seen during normal operation.</p><p>The VAE-planner in nominal conditions is able to reject a wide range of impulses applied to the robot's base. However, this operating window is enlarged by increasing the robot's cadence as soon as a disturbance is detected. This reactive VAE-planner halves the robot's swing duration from a nominal 250 ms to 125 ms once the ELBO threshold is surpassed.</p><p>We show the VAE-planner detecting and reacting to the push broom disturbance in Fig. <ref type="figure">8</ref>. The top row shows the robot being pushed violently before recovering in three to four steps. At point (b) the ELBO spikes above the threshold indicating the disturbance. Throughout the next 1.5 s, the cadence is halved. This is visible in the contact schedule-the white space reduces in width, see point (c). At points (d) and (e) the robot has fully recovered. The ELBO and contact schedule plots continue on and the robot is pushed twice more in this figure . 
A comparison between the reactive VAE-planner and a constant cadence version is drawn in Fig. <ref type="figure" target="#fig_5">12</ref>. The constant cadence VAE-planner uses swing durations of 313 ms and 250 ms, whilst the reactive version halves the robot's cadence to 125 ms as described. Here, we see that the range of rejectable push disturbances increases as the swing duration decreases.</p><p>Finally, we illustrate what happens to the latent-space trajectory during and after the disturbance. The nominal latent-space trajectory forms a figure of eight and is typified by triangular lobes. This is visible in Fig. <ref type="figure" target="#fig_4">11</ref> sub-figures (a) and (e). When the robot is perturbed these lobes deform and elongate e.g. in   The user control over the robot's base twist using the action and the gait parameters are varied as on ANYmal B using the drive-signal parameters. The variation in gait parameters is captured by the swing and stance durations in the contact schedule below the images of the robot. Please view the ANYmal C locomotion in our video found at <ref type="url" target="https://youtu.be/GT2WLh2Ackc">https://youtu.be/GT2WLh2Ackc</ref>. control loop which causes the increase in KL-divergence.</p><p>The reconstruction error for ANYmal B is, unsurprisingly, lower than for ANYmal C. The median value for ANYmal B reconstruction error is 5.74 × 10 -3 , whilst for ANYmal C it is 1.58 × 10 -2 . These median values are compared using the Mann-Whitney U-test conducted over two sets containing 2.5 × 10 4 values. The U-statistic is 8.26 × 10 7 resulting in a p-value of p &lt; 0.001. The results in the rejection of the nullhypothesis, meaning that the two distributions are statistically different. Since the VAE-planner is trained using data from the ANYmal B, a lower reconstruction error is expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. FUTURE WORK</head><p>The most significant limitation of the current system is that, despite the VAE-planner being able to interpolate between a broad range of dynamic manoeuvres, the resulting locomotion gaits are constrained to follow the trot contact sequence and operate on flat ground. This stems from the decision to only train the model using demonstrations of the trot gait with fixed parameters and on flat ground. These decisions were made so that we could inspect and interpret the resulting latent-space thoroughly in this restrictive domain.</p><p>To generate different contact schedules other than trot, it is necessary to train a new VAE with different gait trajectories. These different contact schedules should similarly become embedded in latent space. This provides an opportunity to train the VAE with even more dynamic gaits such as bound as well as asymmetrical gaits.</p><p>Another limitation is that the current VAE-planner has not been exposed to the trajectories required in order to traverse uneven terrain. Therefore, we wish to train the model on a variety of different locomotion gaits generated when the quadruped walks in unstructured environments. The resulting latent-space will be analysed and the VAE deployed as a planner so that the quadruped can operate in these environments. This will discover firstly how well the VAE-planner reacts to external disturbances resulting from uneven terrain, and secondly the range of motion the VAE-planner can produce in response to the unstructured terrain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we present a robust and flexible approach for locomotion planning from the perspective of traversing a structured latent-space. This is achieved utilising a deep generative model to capture relevant structure from locomotion data and enables the detection and mitigation of disturbances. The latent space is disentangled to a degree that key salient locomotion features are automatically discovered from a single style of trot gait. An investigation of this latent space reveals a twodimensional representation which encapsulates the underlying dynamics of the system. This disentanglement is exploited using a drive signal with which dynamically consistent locomotion is generated. Crucially, the amplitude and phase of the drive signal directly control the gait characteristics, namely the cadence, swing height, and full-support duration. Once deployed, the ease with which modulation of the drive signal gives rise to seamless interpolation between gait parameters is demonstrated. Despite generalising to remarkably distinct trot styles compared to the training distribution, the entire range of VAE trajectories remains dynamically consistent. Additionally, utilising a generative model affords the ability to characterise disturbances as out of the distribution seen during training. Though the VAE-planner is able to reject a broad range of impulses applied to the robot's base, this window is broadened by increasing the cadence as soon as the disturbance is detected. Finally, we show that the approach readily transfers to a kinematically similar but dynamically different platform without needing to be retrained. This helps to showcase the VAE's ability transfer to new unseen domains. He is currently a Senior Researcher at the Oxford Robotics Institute, University of Oxford with I. Havoutis. During his Ph.D., he worked on trajectory optimization and warm starting optimal control for high-dimensional systems and humanoid robots under the supervision of S. Vijayakumar. His research interests include fast learning-and optimization-based methods for planning and control, locomanipulation, and legged robots.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2:A slice through the structured latent space, colour coded to illustrate the ordering and clustering of the distinct stances which make up the trot gait. The component of the latent-space trajectory (black) along the horizontal axis contributes to the robot's footstep height, whilst the vertical component gives rise to the footstep length. Snapshots of the robot controlled using the VAE-planner illustrates the inter-play between these two latent dimensions.</figDesc><graphic coords="4,370.73,88.36,114.55,114.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: An oscillatory drive signal overwrites the dimension with the smallest variance in the structured latent-space. The amplitude A k , time-period T k and stance duration counter ϵ k of this signal control the robot's foot swing height, cadence and full-support duration in real time.</figDesc><graphic coords="5,48.96,53.14,251.05,96.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: A comparison of a latent space actively structured using BCE gradients which flow through the encoder's input (sub-figure (a)) to the vanilla case, where BCE gradients are detached at the latent space (sub-figure (b)). Points in latent space are coloured by their stance. In the key above the latentspace images, a filled-in circle represents a closed contact and a circular outline denotes an open contact.</figDesc><graphic coords="10,61.78,408.00,114.21,110.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 9 :Fig. 10 :</head><label>910</label><figDesc>Fig.9: Distribution of the signed distance between the ZMP and the support line during the 2-stance phases (i.e., one pair of legs was in swing). In orange, the distribution with upper and lower bounds (dashed lines) from the dataset which uses a swing duration of T k = 0.5 s. In blue, the distribution of the VAE trajectories shown over a range of modes deployed on the real robot.</figDesc><graphic coords="12,48.96,258.49,251.06,122.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 11 :</head><label>11</label><figDesc>Fig. 11: We show the latent-space trajectory in a series of sub-figures as the robot is walking normally, is perturbed, and recovers. The latent-space trajectory (in black) is plotted on the latent-space colour-coded to show the stances of the trot-gait. In normal operation (sub figures (a) and (e)) the latent-space path is a figure of eight with triangular lobes during the robot's footswing (blue and red areas). As the robot is perturbed (sub figure (b)), the lobes are far more elongated. Crucially, this elongated trajectory reverts back to the nominal trajectory as the robot recovers. The accompanying footstep schedule is plotted along side.</figDesc><graphic coords="13,48.96,53.14,514.07,157.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 12 :</head><label>12</label><figDesc>Fig.12:The range of rejectable base-velocity disturbances increases when automatically modulating the cadence. This plot is symmetrical for ease of view. The range of swing durations plotted is 313 ms, 250 ms, and 125 ms.</figDesc><graphic coords="13,67.79,301.85,213.40,140.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 13 :</head><label>13</label><figDesc>Fig.13: We deploy our VAE-planner on a different robot: ANYmal C. The VAE used here is trained using data from a simulated ANYmal B robot. ANYmal C is significantly heavier than ANYmal B (50 kg to 35 kg) with twice as much maximum torque, but has actuators with lower bandwidth. With the use of the WBC, the VAE-planner is able to control ANYmal C effectively. The user control over the robot's base twist using the action and the gait parameters are varied as on ANYmal B using the drive-signal parameters. The variation in gait parameters is captured by the swing and stance durations in the contact schedule below the images of the robot. Please view the ANYmal C locomotion in our video found at https://youtu.be/GT2WLh2Ackc.</figDesc><graphic coords="14,48.96,53.14,514.09,102.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Alexander L. Mitchell received his M.Eng. from the University of Oxford in 2018. Subsequently, he enrolled at the University of Oxford as a Doctoral candidate. He is currently co-supervised by Professor Ingmar Posner and Dr Ioannis Havoutis at the Oxford Robotics Institute. Alexander's research interests include optimal control and learning-based methods for path planning and control of legged robots. Wolfgang Merkt received the B.Eng.(Hns) degree in mechanical engineering with management and the M.Sc.(R) and Ph.D. degrees in robotics and autonomous systems from the University of Edinburgh, Edinburgh, U.K., in 2014, 2015 and 2019, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,311.97,184.65,251.05,203.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="8,48.96,53.13,514.05,315.40" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>The authors would like to acknowledge the use of the SCAN facility, and thank <rs type="person">Oliver Groth</rs> for useful discussions.</p></div>
			</div>
			<div type="funding">
<div><p>This work was supported by a <rs type="grantName">UKRI/EPSRC Programme Grant</rs> [<rs type="grantNumber">EP/V000748/1</rs>], the <rs type="funder">EPSRC</rs> grant '<rs type="projectName">Robust Legged Locomotion</rs>' [<rs type="grantNumber">EP/S002383/1</rs>], the <rs type="funder">EPSRC CDT</rs> [<rs type="grantNumber">EP/L015897/1</rs>], the <rs type="funder">UKRI/EPSRC RAIN</rs> [<rs type="grantNumber">EP/R026084/1</rs>] and <rs type="funder">ORCA</rs> [<rs type="grantNumber">EP/R026173/1</rs>] Hubs and the <rs type="funder">EU H2020</rs> Project <rs type="projectName">MEMMO</rs> (<rs type="grantNumber">780684</rs>). It was conducted as part of <rs type="affiliation">ANYmal Research</rs>, a community to advance legged robotics.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Uq8WNHK">
					<idno type="grant-number">EP/V000748/1</idno>
					<orgName type="grant-name">UKRI/EPSRC Programme Grant</orgName>
					<orgName type="project" subtype="full">Robust Legged Locomotion</orgName>
				</org>
				<org type="funding" xml:id="_CXr4SmJ">
					<idno type="grant-number">EP/S002383/1</idno>
				</org>
				<org type="funding" xml:id="_ZZjA656">
					<idno type="grant-number">EP/L015897/1</idno>
				</org>
				<org type="funding" xml:id="_Jn7Zk8Q">
					<idno type="grant-number">EP/R026084/1</idno>
				</org>
				<org type="funding" xml:id="_gDRJHGC">
					<idno type="grant-number">EP/R026173/1</idno>
				</org>
				<org type="funded-project" xml:id="_9KByd5X">
					<idno type="grant-number">780684</idno>
					<orgName type="project" subtype="full">MEMMO</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Transfer to ANYmal C</head><p>We successfully deploy the VAE-planner trained using simulated ANYmal B data on ANYmal C. Please note that the VAE is not retrained. The differences between the two robots are significant as ANYmal C's joint torque limits are 80.0 N m instead of 40.0 N m, and ANYmal C's total mass is 50 kg instead of 35 kg. Also note that the WBC's internal model for both kinematics and dynamics are updated when the VAE-planner is deployed on ANYmal C. However, the joint trajectory output from the VAE-planner is the input to the WBC meaning that joint trajectories from the VAE-planner are suitable for ANYmal C.</p><p>Despite not retraining, the VAE-planner is able to command ANYmal C's heading and control the robot's gait parameters.</p><p>In essence, the experiment in Sec. VI-E is repeated with the same VAE-planner, but deployed on ANYmal C. Fig. <ref type="figure">13</ref> shows ANYmal C with the VAE-planner deployed onboard, along with the contact schedule. The latter shows the variation in both swing and stance duration as the robot walks.</p><p>Comparing ANYmal B and C using ELBO: The ELBO can be used to further compare the differences between encoding the raw ANYmal B and C data. As mentioned in Sec. V-I, key parameters such as joint torque limits are standardised before encoding. Analysis of the ELBO is split into comparison of the KL divergence and mean-squared reconstruction error between ANYmal B and ANYmal C.</p><p>The KL divergence term is particularly affected by latency in the input. For example, if the states in the encoder input are not sampled exactly at the encoder frequency, the KL divergence term will increase. The distributions of these values are quite different between each robot. The KL-divergence values for ANYmal B show a steady mean drift upwards which is negligible for ANYmal C. The median value for ANYmal C is also noticeably lower than for ANYmal B.</p><p>As described in Sec. V-I, we compare the KL-divergence values from both robots together using a Mann-Whitney Utest <ref type="bibr" target="#b37">[38]</ref>. As a reminder, we record the KL-divergence for both robots and analyse sets of size 2.5×10 4 . The resulting Ustatistic is 1.82 × 10 9 and the p-value is p &lt; 0.001. Therefore, the null-hypothesis is rejected and the difference in the median values of the KL-divergence from both robots is statistically significant.</p><p>The reason for ANYmal C's lower median value is down to the relative performance of the onboard computers on the two ANYmals. ANYmal C has a much faster CPU meaning that the VAE-planner's control loop is comfortably under the 2.5 ms required for real-time control. The result of which is the encoder's input is sampled at the desired encoder frequency. In contrast, on average the control loop on ANYmal B violates the real-time control law roughly 20 % of the time during the experiment run in Fig. <ref type="figure">10</ref>. This introduces latency into the Ingmar Posner is Professor of Engineering Science at Oxford University, where he leads the Applied Artificial Intelligence Lab. His research aims to enable machines to robustly act and interact in the real world -for, with, and alongside humans. Ingmar's track record in machine perception and decision-making includes seminal work on largescale learning from demonstration, representation learning for scene understanding and prediction as well as 3D object detection and machine introspection. Currently his research interests revolve around the use of structured latent spaces for robot perception, planning and control.</p><p>Ingmar received an M.Eng. degree in Electronic Systems Engineering from Aston University, Birmingham, U.K., and a D.Phil. degree in bioacoustics from the University of Oxford. He is a founding Director of the Oxford Robotics Institute and, in 2014, co-founded Oxbotica, multi-award winning provider of mobile autonomy software solutions.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dynamic locomotion through online nonlinear motion optimization for quadrupedal robots</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Bellicoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jenelten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Automat. Lett. (RA-L)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2261" to="2268" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A feasibility-driven approach to control-limited ddp</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mastalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Merkt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marti-Saumell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ferrolho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mansard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Robots</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Receding-horizon perceptive trajectory optimization for dynamic legged locomotion with learned initialization</title>
		<author>
			<persName><forename type="first">O</forename><surname>Melon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Orsolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Surovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geisert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Havoutis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fallon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Rob. Autom. (ICRA)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gait and trajectory optimization for legged systems through phase-based endeffector parameterization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Bellicoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Automat. Lett. (RA-L)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1560" to="1567" />
			<date type="published" when="2018-07">July 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Agile maneuvers in legged robots: a predictive control approach</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mastalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Merkt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mistry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Havoutis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayakumar</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2203.07554" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning agile and dynamic motor skills for legged robots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hwangbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bellicoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tsounis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Robotics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">26</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Guided constrained policy optimization for dynamic quadrupedal robot locomotion</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gangapurwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Havoutis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Automat. Lett. (RA-L)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3642" to="3649" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rloc: Terrain-aware legged locomotion using reinforcement learning and optimal control</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gangapurwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geisert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Orsolino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fallon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Havoutis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2908" to="2927" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast trajectory optimization for legged robots using vertex-based ZMP constraints</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Farshidian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neunert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Automat. Lett. (RA-L)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2201" to="2208" />
			<date type="published" when="2017-10">Oct 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Zero-moment point -thirty five years of its life</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vukobratovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Borovac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Hum. Rob. (IJHR)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Centroidal dynamics of a humanoid robot</title>
		<author>
			<persName><forename type="first">D</forename><surname>Orin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Robots</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<date type="published" when="2013">10 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Model predictive control with environment adaptation for legged locomotion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bratta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Focchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Villarreal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Semini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bemporad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="145" to="710" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An efficient optimal planning and control framework for quadrupedal locomotion</title>
		<author>
			<persName><forename type="first">F</forename><surname>Farshidian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neunert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017-05">may 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Trajectory and foothold optimization using low-dimensional models for rough terrain locomotion</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mastalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Focchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Havoutis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Radulescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Calinon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Caldwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Semini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">First steps: Latentspace control with semantic constraints for quadruped locomotion</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Surovik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Gangapurwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Melon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Havoutis</surname></persName>
		</author>
		<author>
			<persName><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Int. Conf. Intell. Rob. Sys. (IROS)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5343" to="5350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learn. Repr. (ICLR)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Mach. Learn. (ICML)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gait parameters as predictors of slip severity in younger and older adults</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Moyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Redfern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ergonomics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="329" to="343" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Next steps: Learning a disentangled gait representation for versatile quadruped locomotion</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Merkt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geisert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gangapurwala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Havoutis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Rob. Autom. (ICRA)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page">570</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Multi-layered safety for legged robots via control barrier functions and model predictive control</title>
		<author>
			<persName><forename type="first">R</forename><surname>Grandia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Ames</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Extracting legged locomotion heuristics with regularized predictive control</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bledt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="406" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep variational bayes filters: Unsupervised learning of state space models from raw data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Soelch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Smagt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learn. Repr. (ICLR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Embed to control: A locally linear latent dynamics model for control from raw images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Watter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boedecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Conditional neural movement primitives</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Seker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Imre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Piater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ugur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rob.: Sci. Sys. (RSS)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Universal planning networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jabri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Mach. Learn. (ICML)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning latent dynamics for planning from pixels</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Mach. Learn. (ICML)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="2555" to="2565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Planning in learned latent action spaces for generalizable legged locomotion</title>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Calandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2008">2008.11867, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Character controllers using motion VAEs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Panne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Vision-aided dynamic quadrupedal locomotion on discrete terrain using motion libraries</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sreenath</surname></persName>
		</author>
		<idno>abs/2110.00891</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast and efficient locomotion via learned gait transitions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Coumans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boots</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conf. on Rob. Learn. (CoRL)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">β-VAE: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learn. Repr. (ICLR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic locomotion and whole-body control for quadrupedal robots</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Dario</forename><surname>Bellicoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jenelten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fankhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hwangbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Int. Conf. Intell. Rob. Sys. (IROS)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3359" to="3365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Per-contact iteration method for solving contact dynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hwangbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Automat. Lett. (RA-L)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="895" to="902" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Series elastic actuators</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Int. Conf. Intell. Rob. Sys. (IROS)</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName><forename type="first">D.-A</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Learn. Repr. (ICLR)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">ANYmal -a highly mobile and dynamic quadrupedal robot</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Bellicoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Tsounis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hwangbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bodie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fankhauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bloesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Diethelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bachmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Melzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hoepflinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ Int. Conf. Intell. Rob. Sys. (IROS)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visualizing Higher-Layer Features of a Deep Network</title>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2009 Workshop on Learning Feature Hierarchies</title>
		<meeting><address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06">Jun. 2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Montreal</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 1341</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Whitney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="60" />
			<date type="published" when="1947">03 1947</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Inverse dynamics control of floating base systems using orthogonal decomposition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mistry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Buchli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Rob. Autom. (ICRA)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
