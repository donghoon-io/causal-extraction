<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A novel sandwich algorithm for empirical Bayes analysis of rank data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Arnab</forename><surname>Kumar Laha</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Management</orgName>
								<address>
									<settlement>Ahmedabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Somak</forename><surname>Dutta</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Iowa State University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vivekananda</forename><surname>Roy</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Iowa State University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A novel sandwich algorithm for empirical Bayes analysis of rank data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Algebraic-Probabilistic model</term>
					<term>Convergence</term>
					<term>Gibbs sampler</term>
					<term>Markov chains</term>
					<term>MCMC</term>
					<term>Permutation</term>
					<term>Rank data</term>
					<term>Sandwich algorithm</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rank data arises frequently in marketing, finance, organizational behavior, and psychology. Most analysis of rank data reported in the literature assumes the presence of one or more variables (sometimes latent) based on whose values the items are ranked. In this paper we analyze rank data using a purely probabilistic model where the observed ranks are assumed to be perturbed versions of the true rank and each perturbation has a specific probability of occurring. We consider the general case when covariate information is present and has an impact on the rankings. An empirical Bayes approach is taken for estimating the model parameters. The Gibbs sampler is shown to converge very slowly to the target posterior distribution and we show that some of the widely used empirical convergence diagnostic tools may fail to detect this lack of convergence. We propose a novel, fast mixing sandwich algorithm for exploring the posterior distribution. An EM algorithm based on Markov chain Monte Carlo (MCMC) sampling is developed for estimating prior hyperparameters. A real life rank data set is analyzed using the methods developed in the paper. The results obtained indicate the usefulness of these methods in analyzing rank data with covariate information.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The phenomenon of ranking a given set of items according to some attributes is well known. Students are ranked routinely according to their proficiency in some subject, job applicants are ranked according to their suitability for 1 arXiv:1708.04377v1 [stat.ME] 15 Aug 2017 a particular job, various brands of soap are ranked by consumers according to their intention to purchase them at some later time, various mutual funds are ranked by the investors according to their intention to invest money in them etc. In some cases, like ranking of students for their proficiency in a given subject one may use some objective criterion like the marks scored in an appropriately designed examination for assigning the rank -the student who gets the highest marks gets rank 1, the student who gets the next highest marks gets rank 2 etc. However, in other cases, like the case of evaluating a job applicant, usually more than one attribute is considered. Typically a panel of experts evaluate the items (the candidates) on a variety of relevant dimensions some of which may be objective while others are subjective. Often the individual experts are only able to provide a ranking of the items as perceived by them during the evaluation process. The whole group of experts then considers all the rankings by the individual experts and tries to arrive at a consensus ranking through some subjective decision making process. We call this generally accepted rank the "true rank". The number of items to be ranked by an expert (a.k.a. subject) is typically small since the "robustness of ranking may well fall if the subject is required to rank a large number of items simultaneously" <ref type="bibr">(Brown , 1974, p.19)</ref>. Along the same lines <ref type="bibr">Russell and Gray (1994, p. 81)</ref>, states that forcing subjects to give a different rank to each item may "overtax their true powers of differentiation, with the result that the rank differences they give do not reflect true value differences, but merely add to the noise in the data." <ref type="bibr" target="#b21">Laha and Dongaonkar (2009)</ref> provide a statistical method to derive the "true rank" based on the rankings provided by the individual experts. In this paper we extend this method to the case when the true rank depends on some covariates.</p><p>When there are no covariates on the experts, we denote the true rank as π and the ranking given by the ith expert as y i . The ranking y i can be considered as a 'perturbed' version of π i.e. we assume that y i = σ i •π where σ i ∈ S p , the set (group) of permutations of the integers 1, 2, . . . , p. The permutations σ i 's are assumed to be independently distributed S p valued random variables following some common law. <ref type="bibr" target="#b21">Laha and Dongaonkar (2009)</ref> discuss the estimation of π using a Bayesian approach and the Sampling Importance Resampling (SIR) technique.</p><p>Suppose now that there are covariates on the experts and the true rank depends on the value of the covariate. Let X be the covariate and suppose it takes the value x i for the ith expert. In this case, we have the model y i = σ i • π(x i ) where as before σ i 's are i.i.d. S p valued random variables. We are interested in estimating π(x) where x ∈ Range(X).</p><p>There are several other methods in the literature for analyzing rank data most of which do not incorporate covariates. Models based on orderstatistics are discussed in <ref type="bibr" target="#b37">Thurstone (1927)</ref>, <ref type="bibr" target="#b38">Yellot (1977)</ref>, <ref type="bibr" target="#b5">Critchlow (1980)</ref>, <ref type="bibr" target="#b6">Daniels (1950)</ref>, <ref type="bibr" target="#b29">Mosteller (1951)</ref> and <ref type="bibr" target="#b39">Yu (2000)</ref>. Order-statistics based models consider a latent utility y i , of ith item, i = 1, . . . , p given by a expert who ranks the items in decreasing order of utility. While some of them assume that for a given expert the variables y i 's are independent, <ref type="bibr" target="#b39">Yu (2000)</ref> considers a multivariate normal model for the utilities with nonidentity covariance matrix. He also considers the case when covariates are associated with items and experts. Models based on distance are first considered in <ref type="bibr" target="#b25">Mallows (1957)</ref>. These models are further studied in <ref type="bibr" target="#b9">Feigin and Cohen (1978)</ref> and <ref type="bibr" target="#b7">Diaconis (1988)</ref>. Further work in distance based models has been reported in <ref type="bibr" target="#b11">Fligner and Verducci (1986)</ref>. Mallows model has been generalized by <ref type="bibr" target="#b22">Lebanon and Lafferty (2002)</ref>. <ref type="bibr" target="#b12">Fligner and Verducci (1988)</ref> proposed multistage ranking model where they introduced the concept of central ranking π but without any covariates. Recently, mixtures of distance-based models have been considered in <ref type="bibr" target="#b30">Murphy and Martin (2003)</ref>.</p><p>An approach based on mixture of experts model to cluster voters in Irish election background has been recently considered in <ref type="bibr" target="#b15">Gormley and Murphy (2008)</ref>. The mixture of experts model can include covariates (see also <ref type="bibr" target="#b16">Gormley and Murphy , 2010)</ref>. Also other methods for analyzing rank data without covariates using group representation have been studied in <ref type="bibr" target="#b8">Diaconis (1989)</ref>. However, our approach of estimating the true rank is not considered elsewhere and is innovative in this regard. We develop a flexible conjugate prior for Bayesian inference. The use of conjugate prior allows us to construct a Gibbs sampler with standard conditional distributions. Although it is shown that the Gibbs sampler is a uniformly ergodic Markov chain, it converges very slowly to the target posterior distribution because it moves between the modes of the posterior too infrequently (see e.g. <ref type="bibr" target="#b28">Meyn and Tweedie , 1993</ref>, for definition of uniformly ergodic Markov chain). On the other hand, this lack of convergence is not detected by a popular Markov chain Monte Carlo (MCMC) empirical convergence diagnostic tool, namely the potential scale reduction factor introduced by <ref type="bibr" target="#b14">Gelman and Rubin (1992)</ref>. Even though the Gibbs sampler is stuck in a local mode, the autocorrelation (between iterations of the Gibbs chain) is close to zero even before lag three. Only when the Gibbs sampler is run for a very large number (more than five million) of iterations, it visits other modes and the autocorrelations jump to near one showing lack of mixing. This is an alarming issue as in practice, MCMC users employ these empirical convergence diagnostic tools to determine MCMC simulation length and we show that inference drawn from prematurely stopped MCMC simulation may be far from the truth. These observations demonstrate the danger in depending purely on empirical convergence diagnostic tools to verify convergence of MCMC algorithms as these tools may give false indication of convergence.</p><p>Every two-variables Gibbs sampler has the same rate of convergence as its two reversible subchains (see e.g. <ref type="bibr" target="#b31">Robert and Casella , 2004;</ref><ref type="bibr" target="#b23">Liu, Wong and Kong , 1994)</ref>. These subchains can also be viewed as data augmentation (DA) chains (see <ref type="bibr" target="#b17">Hobert and Marchev , 2008)</ref>. Over the last two decades a lot of effort has gone into modifying DA chains to improve its convergence. These improved algorithms include the parameter expanded DA (PX-DA) algorithm of <ref type="bibr" target="#b24">Liu and Wu (1999)</ref>, the conditional and marginal augmentation algorithms of <ref type="bibr" target="#b27">Meng and van Dyk (1999)</ref>, the sandwich algorithm of <ref type="bibr" target="#b17">Hobert and Marchev (2008)</ref> and finally the interweaving algorithms of <ref type="bibr" target="#b40">Yu and Meng (2011)</ref>. Here we consider <ref type="bibr">Hobert and Marchev 's (2008)</ref> sandwich techniques to improve the subchains of our Gibbs sampler. In a sandwich algorithm, an extra step is added (sandwiched) to the Gibbs sampler in between the draws from the conditional distributions. We construct a sandwich algorithm and use the Rao-Blackwellization technique to make inference about the true rank, π. Using results in Hobert, <ref type="bibr" target="#b18">Roy and Robert (2011)</ref> we show that all the (ordered) eigenvalues of the Markov operator corresponding to the sandwich chain are less than or equal to the corresponding eigenvalues of the DA Markov operator. We also present an EM algorithm based on MCMC sampling to make inference about the prior hyperparameter.</p><p>The structure of the paper is as follows: In Section 2, we introduce the probabilistic rank model with covariates and discuss estimation of the model parameters using a Bayesian approach. In Section 2.1, we build prior distributions on the parameters and provide the joint and marginal posterior distributions (up to normalizing constants). Section 3 contains construction of MCMC algorithms as well as the EM algorithm for estimating the prior hyperparameter. Section 4 demonstrates the convergence issues of the Gibbs sampler through simulation examples. We also describe how our sandwich algorithm results in huge improvement in mixing by adding an extra step to facilitate moves between the modes of the posterior. In Section 5, we discuss analysis of a real life dataset using methods developed earlier in the paper. Some concluding remarks are given in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">An algebraic-probabilistic model</head><p>Let us think of a situation in which p items are ranked by a random sample of n experts from a population. In the absence of any covariate information, <ref type="bibr" target="#b21">Laha and Dongaonkar (2009)</ref> suppose that there is a "true rank" π of the p items and the observed ranks are "perturbed" versions of the true rank π. The perturbation is the composition of a random permutation from the group of all permutations S p with the true rank π. When there is one or more categorical variable partitioning the population of the experts into few categories, a natural way to extend the model is to assume that there is a true rank associated with each category of experts and the observed ranks are some random perturbed versions of these true ranks. Thus, if there are g categories of experts and b j denotes the number of experts in the jth category and y ij 's are the ranks observed from the experts in jth category, then we assume that there are true ranks π 1 , π 2 , . . . , π g such that</p><formula xml:id="formula_0">y ij = σ ij • π j , i = 1, . . . , b j ,<label>(1)</label></formula><p>for j = 1, . . . , g, where σ ij 's are i.i.d random permutations having some distribution and are synonymous to random error perturbations. Notice that because composition is the natural group operation on the group S p , (1) is the natural ANOVA model on the permutation group.</p><p>We use the following notations to denote the p! permutations in S p . Let ζ j = jth ranking in lexicographic order in S p . So ζ 1 is the identity permutation,</p><formula xml:id="formula_1">ζ 2 = 1 2 • • • p -1 p 1 2 • • • p p -1 , ζ 3 = 1 2 • • • p -2 p -1 p 1 2 • • • p -1 p -2 p</formula><p>and so on. Finally,</p><formula xml:id="formula_2">ζ p! = 1 2 • • • p -1 p p p -1 • • • 2 1 .</formula><p>Next, in order to construct the distribution of the σ ij 's, suppose they take the value ζ k with probability θ k , i.e. P (σ = ζ k ) = θ k . It is expected that the experts are sensible so that large random error perturbations are less likely to occur than the smaller ones, where we order the permutations by their distance from the identity permutation. Thus, θ 1 should be the highest because it is the probability that the observed rank equals to the true rank for any category. Moreover, whenever ζ k is farther away from ζ 1 than ζ l , it is expected that θ k would be smaller than θ l . Based on this assumption, we build our prior distribution on the vector θ = (θ 1 , . . . , θ p! ) in the next section.</p><p>We break our task into three parts. First we construct prior distributions on the parameters necessary for the Bayesian inference. Next we derive the analytic forms of the marginal posterior distributions of the true ranks π 1 , . . . , π g and the vector θ, up to a normalizing constant and demonstrate acute challenges present in computing the normalizing constant. In order to avoid the mammoth computational challenge, we construct a powerful MCMC algorithm that enables us to make fast inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Prior distributions</head><p>In order to construct a prior on θ reflecting our belief that the experts are less likely to make big errors, we begin with fixing the notion of big or small perturbations using the Cayley distance on S p <ref type="bibr" target="#b4">(Cayley , 1849)</ref>. The Cayley distance between two permutations τ and α is defined as</p><formula xml:id="formula_3">d C (τ, α) = p -|τ • α -1 |</formula><p>where |τ •α -1 | is the number of cycles in the unique representation of τ •α -1 as a product of disjoint cycles. Based on this distance, we call a perturbation τ smaller than a perturbation α, if d C (τ, ζ 1 ) &lt; d C (α, ζ 1 ). Consequently, we take the prior on θ as a Dirichlet(a 1 , . . . , a p! ) distribution because it is the conjugate prior. We set the hyperparameters of this distribution as</p><formula xml:id="formula_4">a k = exp(λ (p -d C (ζ k , ζ 1 ))) = exp(λ|ζ k |),<label>(2)</label></formula><p>where λ &gt; 0 is a parameter that reflects the overall precision in ranking the items. If λ is large then the distribution of the error σ is concentrated on the set of permutations having many cycles and thus at most a few items are mis-ranked by the experts. In contrast, when the value of λ is small, the experts end up mis-ranking a large number of items. This prior distribution on the θ stems from the natural exponential family on the permutation group <ref type="bibr" target="#b26">McCullagh (2011)</ref> which puts a mass proportional to exp(λ|ζ k |) on the permutation ζ k . However, had we deterministically set θ k ∝ exp(λ|ζ k |), computations would have been very difficult because the nice conjugacy structure enjoyed by our model would be broken.</p><p>In this article, we follow an empirical Bayesian route and estimate the hyperparameter λ by maximizing the marginal likelihood p(y|λ), the details of which are given in Section 3.4. Estimating λ by maximizing the marginal likelihood ensures that the inference remains invariant to multiplying the a k 's in (2) by any arbitrary constant.</p><p>As far as the prior on the true ranks are concerned, we could incorporate any available knowledge while constructing the prior distribution. For example, if an item is known to be favorite we can construct a prior under which that particular item is more likely to be a top choice. If there is any reason to believe spatial correlation among the true ranks, e.g. for voting data, we can incorporate this information in the prior. For simplicity and ease of computation, however, we would like to assume that the π j 's are apriori independently distributed and if there is no obvious reason as to why one or more items should be given preference to others, we can keep uniform priors (on S p ). In general, we denote the prior on π ≡ (π 1 , π 2 , . . . , π g ) by</p><formula xml:id="formula_5">p(π) = p 1 (π 1 )p 2 (π 2 ) • • • p g (π g ).</formula><p>Figure <ref type="figure">1</ref>: Graphical representation of the algebraic-probabilistic model proposed in this paper. Here y j = {y ij , i = 1, . . . , b j }, is the collection of all ranks given by experts in the jth category; j = 1 . . . , g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Exact posterior and its limitations</head><p>It is quite useful to visualize the conditional dependence structure among the variables. This is displayed in Figure <ref type="figure">1</ref>. Two features are noticeable from the graph. Firstly, π j 's are conditionally independent among themselves given θ and the data y. Secondly, the likelihood of λ given all other variables depends only on θ. These two observations will be key ingredients in our computational methods later in the article. To this end, notice that the likelihood of the data is given by</p><formula xml:id="formula_6">p(y| θ, π 1 , . . . , π g ) = g j=1 p! i=1 θ n ij ζ i •π -1 j (3)</formula><p>where n ij is the number of times the ranking ζ i is observed in the jth category. Since the conjugate Dirichlet prior for θ is assumed, the joint posterior simplifies to</p><formula xml:id="formula_7">p(θ, π 1 , . . . , π g |y, λ) ∝ p! k=1 θ m k (π)+a k -1 k × p(π),<label>(4)</label></formula><p>where</p><formula xml:id="formula_8">m k (π) = g j=1 p! i=1 n ij I(ζ i • π -1 j = ζ k ),</formula><p>where I(•) is the indicator function. Integrating out θ gives the marginal posterior of π = (π 1 , . . . , π g ) up to a normalizing constant:</p><formula xml:id="formula_9">p(π|y, λ) ∝ p(π) p! k=1 Γ(m k (π) + a k ).<label>(5)</label></formula><p>Further, the marginal (joint) posterior of θ is given by a mixture of Dirichlet densities,</p><formula xml:id="formula_10">p(θ|y, λ) = π∈S g p D(θ; m 1 (π) + a 1 , . . . , m p! (π) + a p! )p(π|y, λ),<label>(6)</label></formula><p>where S g p = S p × S p × • • • × S p , g times. From (6) the marginals of θ k , for k = 1, ..., p! can be obtained as mixtures of Beta densities,</p><formula xml:id="formula_11">p(θ k |y, λ) = π∈S g p B(θ k ; m k (π) + a k , N + a 0 -m k (π) -a k ) × p(π|y, λ),</formula><p>where N is the total sample size and a 0 = k≥1 a k . One important thing stands out from these exact posterior distributions. The mixture representations of the marginal posterior densities of θ k 's indicate that they might be multimodal. However, unless the rankings are completely random, only a few of the components in the mixture have substantial contributions. That is, p(π|y, λ)'s are insignificant for all but few π = (π 1 , . . . , π g ) ∈ S g p . Thus a subjective judgment about goodness of fit can be deduced from the number of modes of posterior marginals of θ k 's. If there are too many modes, this would indicate that the model is not good for that data.</p><p>However, these exact forms are not of much use in real applications mainly because the normalizing constant in (5) requires too much computational effort. Even when p, the number of items is small, the storage requirement and computational complexity are O(p! g ) which scale exponentially in g. For example, if there are few factorial variables present and each of them have a moderate number of levels, the total number of categories, i.e. g, will be large. Thus when there are only p = 3 items to be ranked and there are only g = 12 categories, a total of 16GB of memory is required to store the values in ( <ref type="formula" target="#formula_9">5</ref>), that are required to not only compute the normalizing constant but also the marginal posteriors of θ i 's. With p = 4, this computational bottleneck is reached even for g as low as 7. Note that for the sushi data example considered in Section 5 the memory requirements would have been 10 24 GB.</p><p>Yet, despite their futility in direct computation, these formulas pave way for constructing a Gibbs sampler because the full conditionals consist of tractable distributions due to conjugacy that is displayed in (4). The main reasons behind constructing a Gibbs sampler is that the per iteration computational and storage requirements scale linearly in both p! and g. Thus even if g is large, a Gibbs sampler remains a practically viable option as long as it converges fast. However, as we shall see the traditional Gibbs sampler has a very slow convergence rate. And thus we shall construct a novel and efficient sandwich algorithm by using (5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MCMC algorithms and parameter estimation</head><p>In this section we construct MCMC algorithms for making inference on the model parameters. The conditional densities and calculations in sections 3.1 and 3.2 are conditional on λ. Then in section 3.4 we describe an EM algorithm for estimating the hyperparameter λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Gibbs sampler</head><p>We begin with deriving the conditional distributions associated with the joint posterior density (4) in order to construct a Gibbs sampler. Notice that the conditional distribution of θ given π and y is given by</p><formula xml:id="formula_12">p(θ|π, y) ∝ p! k=1 θ m k (π)+a k -1 k</formula><p>, that is, θ|π, y has a Dirichlet distribution. If independent priors are used on π 1 , . . . , π g , from (4) we see that the conditional distribution of π given θ and y is</p><formula xml:id="formula_13">p(π 1 , . . . , π g |θ, y) ∝ p! k=1 θ m k (π)+a k -1 k p 1 (π 1 ) • • • p g (π g ) ∝ g j=1 p! k=1 θ i n ij I(ζ i •π -1 j =ζ k ) k × p 1 (π 1 ) • • • p g (π g ), that is, π 1 , . . . , π g are conditionally independent. Thus p(π j = ζ r |θ, y) ∝ p! k=1 θ i n ij I(ζ i =ζ k •ζr) k × p j (ζ r ) ≡ γ jr (θ),<label>(7)</label></formula><p>r = 1, . . . , p!. So conditional on θ and y, π 1 , . . . , π g are independent multinomial random variables. Note that, for fixed k and r, there is only one</p><formula xml:id="formula_14">i satisfying ζ i = ζ k • ζ r</formula><p>, and it can be found outside the Gibbs sampler simulation as it does not change between iterations. Let (θ (m) , π (m) ) be the current value of the Gibbs sampler at step m, then the following two steps are used to move to (θ (m+1) , π (m+1) ):</p><p>Iteration m + 1 of the Gibbs sampler:</p><p>1. Draw π (m+1) ∼ p(•|θ (m) , y) which can be done as follows. For j = 1, 2, . . . , g, normalize γ j1 (θ (m) ), . . . , γ jp! (θ (m) ) so that they add up to 1, then draw π</p><formula xml:id="formula_15">(m+1) j ∼ multinomial (1; γ (m) j1 (θ (m) ), . . . , γ (m) jp! (θ (m) )). 2. Draw θ (m+1) |π (m+1) , y ∼ Dirichlet (m 1 (π (m+1) )+a 1 , . . . , m p! (π (m+1) )+ a p! ).</formula><p>For k ≥ 1, define</p><formula xml:id="formula_16">S k := θ ∈ R k : θ i ∈ [0, 1] and θ 1 + • • • + θ k = 1 .</formula><p>The above mentioned Gibbs algorithm results in a Markov chain {θ (m) , π (m) } m≥0 with state space S p! × S g p and invariant density p(θ, π|y, λ) given in (4). It is known that the (sub) chains {π (m) } m≥0 and {θ (m) } m≥0 are reversible Markov chains <ref type="bibr">(Robert and Casella , 2004, Lemma 9.11)</ref>. Since the conditional densities p(π|θ, y) and p(θ|π, y) are everywhere positive, it implies that the Markov chain {π (m) } m≥0 is irreducible and aperiodic. Because {π (m) } m≥0 is a finite state space Markov chain, it follows that {π (m) } m≥0 is uniformly ergodic with unique invariant density p(π|y, λ) given in ( <ref type="formula" target="#formula_9">5</ref>). Moreover, it is well known that {θ (m) , π (m) } m≥0 as well as its two subchains {π (m) } m≥0 and {θ (m) } m≥0 converge to their respective invariant distributions at the same rate (see e.g. <ref type="bibr" target="#b23">Liu, Wong and Kong , 1994</ref>). Hence we have the following lemma.</p><p>Lemma 1 The Gibbs chain {θ (m) , π (m) } m≥0 and the marginal chains {π (m) } m≥0 , {θ (m) } m≥0 are uniformly ergodic.</p><p>In Section 4 we consider the performance of the sub chains and hence the Gibbs sampler through some simulation examples and observe that the Gibbs sampler suffers from slow convergence due to its inability to move between local modes. In the next section, we construct an algorithm improving the Markov chain {θ (m) } m≥0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Improving the DA chain {θ (m) } m≥0</head><p>The θ subchain, {θ (m) } m≥0 , of the Gibbs sampler is a Markov chain with stationary density p(θ|y, λ) given in (6). This chain can be viewed as a DA chain. As mentioned in the introduction, here we consider <ref type="bibr">Hobert and Marchev 's (2008)</ref>  A routine calculation shows that the sandwich chain remains invariant with respect to p(θ|y, λ), so it is a viable alternative to the DA chain. Note that the first and the last steps of the SA are exactly the two steps used in the Gibbs sampler presented in section 3.1. <ref type="bibr">Roy (2012a)</ref> shows that the sandwich chains always converge at least as fast as the corresponding DA algorithms. In particular, <ref type="bibr">Roy (2012a)</ref> shows that SA is at least as good as the DA in terms of having smaller operator norm (see also <ref type="bibr" target="#b17">Hobert and Marchev , 2008)</ref>. Clearly, on a per iteration basis, it is more expensive to simulate the sandwich chain than the DA chain. However, it may be possible to find an r that leads to a huge improvement in mixing despite the fact that the computational cost of drawing from r is negligible relative to the cost of drawing from p(θ|π, y) and p(π|θ, y) (see e.g. <ref type="bibr" target="#b34">Roy , 2014;</ref><ref type="bibr" target="#b35">Roy and Hobert , 2007;</ref><ref type="bibr" target="#b18">Hobert, Roy and Robert , 2011)</ref>.</p><p>We propose the following SA improving the θ subchain, {θ Although the proposed SA is computationally slightly more demanding than the Gibbs sampler, it shows huge gain in mixing in both the simulation examples presented in Section 4 as well as the real data examples in Section 5.</p><p>In Section 4, we see that the extra sandwich step (r) helps the chain move between local modes. The above idea of using random permutation for facilitating moves between local modes is similar to the permutation sampler (Frühwirth-Schnatter, S. , 2001) developed for Bayesian mixture models although there are differences. Firstly in Frühwirth-Schnatter, S. ( <ref type="formula">2001</ref>) the random label switching step is applied on the latent variables, and thus as explained in Hobert, <ref type="bibr" target="#b18">Roy and Robert (2011)</ref> it fits directly into the SA setup of <ref type="bibr" target="#b17">Hobert and Marchev (2008)</ref>. Whereas here the random permutation is applied on the parameters π and this is why we use a Rao Blackwellized estimator of π based on the sandwich chain { θ(m) }. Secondly, the permutation sampler samples from the so-called unconstrained posterior in the mixture model. Thus extra post processing (satisfying identifiability constraint) is needed to make valid inference on the parameters-here we do not need such extra computation.</p><p>Remark 1 Since the sandwich step, r(π |π), is a Metropolis Hastings (MH) step, it is reversible with respect to p(π|y, λ) and hence has p(π|y, λ) as its invariant density. On the other hand, the chain driven by r is reducible and can move to at most p! many states. (Recall that the cardinality of the state space of {π (m) } m≥0 is (p!) g .) The reducibility of r is common among efficient sandwich chains <ref type="bibr">(Roy , 2012b;</ref><ref type="bibr" target="#b18">Hobert, Roy and Robert , 2011;</ref><ref type="bibr" target="#b35">Roy and Hobert , 2007)</ref>.</p><p>Remark 2 The step 2 of our SA may suggest an alternative algorithm for sampling from (4) where in each iteration an (irreducible) MH step is used for the marginal (5) followed by a draw from the conditional density p(θ|π, y) as in step 3 of the SA. We tried to implement this algorithm with different MH proposals including the uniform distribution. But, the average acceptance probability was too low for these algorithms to be practical.</p><p>As mentioned before, any Mtd r with invariant distribution p(π|y, λ) can be used to construct a valid SA. When p is large, then a local move for π may be preferred for the sandwich step. For example, in this case we can generate τ from a distribution which gives high probability on small permutations but zero probability on the identity permutation. (One choice may be to use the multinomial distribution with parameter a k defined in Section 2.1 with the restriction a 1 = 0.) We then propose permutations π j = τ • π j for j = 1, 2, . . . , g, which is accepted with the corresponding MH acceptance probability. As mentioned before, SA is always at least as good as the DA in terms of having smaller operator norm. <ref type="bibr" target="#b18">Hobert, Roy and Robert (2011)</ref> mention that although the norm of a Markov operator provides a univariate summary of the convergence behavior of the corresponding chain, a detailed picture of the convergence can be found by studying the spectrum of the Markov operator. (See Hobert, <ref type="bibr" target="#b18">Roy and Robert (2011)</ref> for a gentle introduction to Markov operators and their spectrum.) Lemma 2 shows that the spectrum of our sandwich chain dominates that of the θ subchain of the Gibbs sampler in the sense that all the (ordered) eigenvalues of the SA are at most as large as the (ordered) eigenvalues of the later. Let L 2 0 (p(θ|y, λ)) denotes the vector space of all mean zero, square integrable (with respect to p(θ|y, λ)) functions defined on S p! . Let K θ and Kθ be the Markov operators, L 2 0 (p(θ|y, λ)) → L 2 0 (p(θ|y, λ)), corresponding to {θ (m) } m≥0 and the sandwich chain, { θ(m) } m≥0 respectively. Since the sandwich step r is performed based on a uniform draw from S p , it follows that two consecutive steps from r still results in a uniform draw. Thus r is idempotent and the following lemma follows from Theorem 1 of Hobert, <ref type="bibr" target="#b18">Roy and Robert (2011)</ref>. Let q ≡ (p!) g .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2</head><p>The operators K θ and Kθ are both compact and each has a spectrum that consists exactly of the point {0} and q -1 eigenvalues in [0, 1). Furthermore, if we denote the eigenvalues of K θ by</p><formula xml:id="formula_17">0 ≤ ρ q-1 ≤ ρ q-2 ≤ • • • ≤ ρ 1 &lt; 1 ,</formula><p>and those of Kθ by</p><formula xml:id="formula_18">0 ≤ ρq-1 ≤ ρq-2 ≤ • • • ≤ ρ1 &lt; 1 , then ρi ≤ ρ i for each i ∈ {1, 2, . . . , q -1}.</formula><p>Since the conditional probabilities P (π i = ζ j |θ, y) are available in closed form (see ( <ref type="formula" target="#formula_13">7</ref>)), we use the Rao-Blackwellized estimator based on the sandwich chain { θ(m) } M m=0 for estimating the true rank probabilities, that is,</p><formula xml:id="formula_19">P (π i = ζ j |y) = 1 M M m=1 P (π i = ζ j | θ(m) , y).</formula><p>Given a sample of θ's (using the sandwich chain) from its marginal posterior density we can get a sample from the posterior of π, by drawing from the conditional distributions of π j 's given θ, j = 1, . . . , g. We can use this sample to estimate marginal as well as joint probability distributions of π j 's.</p><p>Remark 3 In this section, an SA is constructed improving the θ sub chain of the Gibbs sampler. Unfortunately, we could not construct (except for small p and g) a sandwich chain that converges faster than the π subchain {π (m) } m≥0 of the Gibbs sampler and at the same time the computational cost for simulating it is similar to that for {π (m) } m≥0 . The difficulty of constructing such an SA is due to the intractability of the marginal posterior density p(θ|y, λ).</p><p>We now briefly discuss some of the useful properties of our proposed model that are utilized in the data analysis in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Computing joint and conditional posterior probabilities</head><p>A novelty of the model and the sandwich algorithm is that we can compute the Rao-Blackwellized estimator of joint and conditional probabilities involving the central ranks without having to sum over p! g elements. The key ingredient is the conditional independence of the π i 's given θ. Thus for any subsets A 1 , . . . , A g of S p , we can estimate the posterior probability</p><formula xml:id="formula_20">P (π i ∈ A i ∀i | y) by 1 M M m=1 g i=1 P (π i ∈ A i | θ(m) , y).</formula><p>And although MCMC estimates of such statements could be found by drawing samples from the conditional distribution of π i 's given theta, Rao-Blackwellization would result in estimates with smaller MCMC variance. Next, notice that there are two ways to compute conditional probabilities such as</p><formula xml:id="formula_21">P (π i ∈ A i , ∀i | π i ∈ B i ∀i, y)</formula><p>where A i 's and B i 's are subsets of S p . Either we estimate it as the average of the conditional probabilities given θ, i.e., by</p><formula xml:id="formula_22">1 M M m=1 P (π i ∈ A i , ∀i | π i ∈ B i ∀i, θ(m) , y) = 1 M M m=1 P (π i ∈ A i ∩ B i , ∀i| θ(m) , y) P (π i ∈ B i , ∀i| θ(m) , y) ,</formula><p>or as the ratio of averages of joint probabilities each given θ, i.e., by</p><formula xml:id="formula_23">M m=1 P (π i ∈ A i ∩ B i , ∀i| θ(m) , y) M m=1 P (π i ∈ B i , ∀i| θ(m) , y)</formula><p>Although both are computationally feasible because given θ the π i 's are independent we use the second estimator in our data analysis in Section 5.</p><p>The second estimator has lower variance as there could be samples θ (m) for which the probabilities P (π i ∈ B i , ∀i|θ (m) ) are infinitesimally small. These joint and conditional posterior probabilities are important in assessing how the preference for a particular item or a set of items vary over different categories. Because the categories may be induced by levels of factorial covariates these posterior probabilities provide a way to compare the interactions between pairs of factors. The simplest example would be to identify how the posterior probability of an item being most preferred changes from one cross-level interaction to another. We can then repeat the same exercise on another item conditioning on the most preferred item and develop more complicated probability statements that bring out various aspects of a particular dataset.</p><p>We use a Monte Carlo EM algorithm based on the sandwich chain to estimate the hyperparameter λ. In the following, we discuss this EM algorithm in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Estimating λ via Monte Carlo EM</head><p>As mentioned before, we consider an empirical Bayes approach for making inference of the hyperparameter λ. In particular, we estimate λ by where p(y, θ, π|λ) is the joint probability distribution of y, θ, and π. This naturally leads to an EM algorithm by treating (θ, π) as "missing" variables and considering a "Q function" defined as</p><formula xml:id="formula_24">Q(λ|λ ) = π∈S g p log p(y, θ, π|λ)p(θ, π|y, λ )dθ.</formula><p>Then from Figure <ref type="figure">1</ref>, we see that Q(λ|λ ) = log p(θ|λ) p(θ|y, λ )dθ plus a term that does not depend on λ, so that we can avoid summing over π ∈ S g p . Consequently, starting from an initial estimate λ (0) , the (k + 1)st EM iterate of λ is given by maximizing Q λ|λ (k) , that is</p><formula xml:id="formula_25">λ (k+1) = argmax λ p! i=1 e λ|ζ i | E log θ i |y, λ (k) (8) - p! i=1 log Γ e λ|ζ i | + log Γ p! i=1 e λ|ζ i |</formula><p>Since the expectation term in ( <ref type="formula">8</ref>) is not available in closed form, following <ref type="bibr" target="#b3">Casella (2001)</ref>, we replace this expectation by its estimate. To this end, suppose { θ(m) : m = 1, . . . , M } is the sandwich chain from Section 3.2 having the stationary distribution p θ|y, λ (k) . Then,</p><formula xml:id="formula_26">E log θ i |y, λ (k) ≈ (1/M ) M m=1 log θ(m) i where θ(m) i is the ith component of θ(m) .</formula><p>In our practical implementation, we run this stochastic version of the EM with sandwich samples of θ of moderate sizes until the λ (k) 's start fluctuating around the mode and then perform a single EM iteration with a large sandwich chain of θ and obtain the final estimate λ. In order to compute the standard error of λ, we use a method described in <ref type="bibr" target="#b3">Casella (2001)</ref>. The details of the standard error (se) calculations are given in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Simulation examples</head><p>We study the performance of the Gibbs and sandwich chains through simulation studies. Consider the situation where p = 2 and g = 2, that is, we have two categories, two items to rank, and we let the number of observations, n vary. The small values of p and g allow us to compute different Markov transition probabilities in closed form and also it makes possible to compare the rank probability estimates with their true values. Here we consider independent, uniform priors on (π</p><formula xml:id="formula_27">1 , π 2 ), that is, p(π 1 , π 2 ) = p 1 (π 1 )p 2 (π 2 ) with p i (ζ 1 ) = 0.5 = p i (ζ 2 ) for i = 1, 2.</formula><p>We assume Beta (a 1 , a 2 ) prior on θ. We can write down the Markov transition matrix (Mtm) K π of the DA chain {π (m) } m≥0 in closed form (see Appendix B). In order to simulate data, we assume that the true ranks for category 1 and 2 are ζ 1 and ζ 2 respectively. In this section, since we study the convergence performance of the MCMC algorithms, we fix the value of λ. In particular, we assume λ = log 2, that is, we have a 1 = 2, a 2 = 1.</p><p>In our simulation study, we consider same number of observations in each category. We calculate the entries of K π by numerical integration using the formula given in the Appendix B. For each fixed sample size we repeat the simulation 1000 times, that is, we observe 1000 sets of observations and calculate the corresponding Markov transition matrices. It is known that the second largest eigenvalue (ρ) of K π shows the speed of convergence of the DA chain {π (m) } m≥0 (see e.g. <ref type="bibr">Brémaud , 1999, p. 209</ref>) and hence of {θ (m) } m≥0 as well as of the Gibbs chain. Figure <ref type="figure" target="#fig_3">2</ref> shows the boxplots of one thousand ρ values corresponding to each sample size. The labels in the x-axis shows the number of observations in each category. From the plot we see that the convergence rate of the DA chain deteriorates as the sample size increases. We now explain that the reason for the slow convergence of the DA chain is its inability to move away from the local mode. We consider the case where we have 50 observations in each category. In particular, we consider one simulated data set where n 11 = 40, n 12 = 14, n 21 = 10, and n 22 = 36, where n ij denote the number of observations in the jth category with rank ζ i for i, j = 1, 2. The Mtm in this case is:</p><formula xml:id="formula_28">K π =    </formula><p>0.0570291 0.7460761 0.1478273 0.0490667 0.0000006 0.9999993 0.0000000 0.0000001 0.0000004 0.0000001 0.9999981 0.0000014 0.0574185 0.1962019 0.6818719 0.0645066</p><formula xml:id="formula_29">    .</formula><p>We have ordered the points in the state space as follows: <ref type="table"></ref>and<ref type="table">(ζ 2 , ζ 2</ref> ). So, for example, the element in the second row, third column is the probability of moving from (ζ 1 , ζ 2 ) to (ζ 2 , ζ 1 ). Figure <ref type="figure" target="#fig_4">3</ref> shows the plot of the true marginal posterior density of π. From the plot we see that the posterior density has its mode at (ζ 1 , ζ 2 ) with probability around 0.75. The rest of its probability mostly lies at (ζ 2 , ζ 1 ) with almost no weight at the other two ranks. Suppose we start the chain at (ζ 2 , ζ 1 ). We expect the chain to remain at (ζ 2 , ζ 1 ) for about 1/(1 -0.9999981) ≈ 526, 315 iterations before it moves away to another state, that is, the chain remains stuck in a low probability region (a local mode) for a large number of iterations. Conditional on the chain leaving (ζ 2 , ζ 1 ), the expected number of steps before it reaches the true mode, (ζ 1 , ζ 2 ), is also quite large. Given that the chain leaving (ζ 2 , ζ 1 ) there is about 74% chance that it moves to (ζ 2 , ζ 2 ) from where q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 20 30 40 the probability that it will move back to (ζ 2 , ζ 1 ) is about 0.68. Once the chain is back at (ζ 2 , ζ 1 ), it is expected to stay there for 526, 315 iterations before it jumps out to another state. All of this translates into slow convergence.</p><formula xml:id="formula_30">(ζ 1 , ζ 1 ), (ζ 1 , ζ 2 ), (ζ 2 , ζ 1 ),</formula><formula xml:id="formula_31">(ζ 1 ,ζ 1 ) (ζ 1 ,ζ 2 ) (ζ 2 ,ζ 1 ) (ζ 2 ,ζ 2 )</formula><p>Ranks Posterior probability 0.0 0.2 0.4 0.6 Next, we consider the same simulated data set to compare performance of the DA and sandwich chains. Since we are using small values of p and g, we can calculate the true posterior densities of θ and π as given in Figure <ref type="figure">4</ref> (a). From Figure <ref type="figure">4</ref>, we see that although DA algorithm horribly fails to provide reasonable estimates even after 5 million iterations, the sandwich chain results in accurate estimates of true posterior probabilities in less than 50 thousand iterations. In fact, the Kolmogorov-Smirnov distance (plot is not included here) between the the true joint posterior distribution of (π 1 , π 2 ) and its empirical estimate based on the sandwich chain drops below 0.05 within 100 iterations.</p><p>We now show how the empirical convergence diagnostics like, the trace plots and the autocorrelation plots can mislead MCMC practitioners by giving false impression that the chain has converged while the chain has failed to visit the mode of the posterior density even once. Figure <ref type="figure">5</ref> shows the autocorrelation plots and trace plots for the DA and sandwich chains based on 50 thousand and 5 million iterations. From the trace plot in Figure <ref type="figure">5</ref> (a), it may seem that the DA chain is mixing well, which is corroborated by the corresponding autocorrelation plot. In fact, the autocorrelations for the DA chain is close to zero in less than three iterations, and they die down faster than the autocorrelations for the sandwich chain. Note that the Gibbs sampler has not been able to move between the local modes in 50,000 iterations and from Figure <ref type="figure">4</ref> we know that the empirical estimates of probability mass functions (pmfs) and densities obtained using DA chains are far from true posterior probabilities. Since in practice, the true target densities are not available, MCMC practitioners may be misled by the empirical convergence diagnostics like trace plots and autocorrelation plots. When we run the Gibbs chain much longer (5 million iterations), it eventually visits the other local mode. The right panel of Figure <ref type="figure">5</ref> (b) shows the trace plots for the DA and sandwich chains between 2,519,900 and 2,520,899 iterations (to capture a jump of the DA chain from one mode to other). The left panel of Figure <ref type="figure">5</ref> (b) now shows the huge gains in autocorrelation by running the sandwich chain over the DA algorithm. It shows that even 50-lag autocorrelation for the DA chain is close to 1. Finally, we consider the popular potential scale reduction factor (PSRF) <ref type="bibr" target="#b14">(Gelman and Rubin (1992)</ref>) for monitoring convergence of the above DA chain. In general, calculation of PSRF begins with running multiple MCMC chains started at different (overdispersed) initial points. At convergence, these chains produce samples from the same distribution, and this is assessed by comparing the means and variances of these individuals chains with that of the pooled chain. If the PSRF is close to one, it is used as an indicator of the convergence to the stationarity. Figure <ref type="figure" target="#fig_6">6</ref> shows PSRF based on four parallel DA (θ) chains for 50 thousand iterations with different starting values. From Figure <ref type="figure" target="#fig_6">6</ref> we see that when all chains are started close to one mode then PSRF diagnostics fails as the chains have not traveled the whole space yet. PSRF is able to indicate non-convergence of DA only when chains are started at different modes. Since, in practice, especially in multivariate settings, one does not have knowledge about the locations of the modes, PSRF may fail to catch convergence problems of MCMC algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Real data application</head><p>In this section we illustrate the methods proposed in this article by applying them to a sushi preference data, previously published in the literature. The sushi preference data collected by <ref type="bibr" target="#b19">Kamishima (2003)</ref> consists of complete rankings of few types of sushis by 5,000 respondents together with demographic data on the respondents. This dataset has also been used by <ref type="bibr" target="#b20">Kamishima and Akaho (2009)</ref> for model based clustering of orderings. In this article, we consider four types of fish sushis: Anago (sea eel), Maguro (tuna), Toro (fatty tuna) and Tekka Maki (tuna roll). We study the role of gender (male or female), age and geographic location (east or west Japan) of the respondents on ranking of these four types of sushis. The variable age is categorized into six categories: 15-19 years, 20-29 years, 30-39 years, 40-49 years, 50-59 years and 60 years or above. Thus the respondents are categorized into overall 24 categories. Although Toro (fatty tuna) stands out as the most preferred sushi in all categories, substantial variability is observed in ranking the remaining three sushis. Thus apart from identifying the central ranking for these categories we are also interested in the heterogeneity in ranking of Anago, Maguro and Tekka Maki conditional on the Toro being the most preferred sushi. The MCMC sampling outputs allow us to compute these conditional probabilities without having to sum over an enormous 24 24 dimensional joint distribution.</p><p>To this end, we ran our sandwich algorithm for a total of 60,000 iterations and discarded the first 10,000 iterations as burnins, although convergence was observed within first 15,000 iterations. As far as the marginal probabilities are concerned, the central ranks are same for all the categories and it is Toro Maguro Tekka Maki Anago where Toro Maguro means Toro is preferred to Maguro. However, there is substantial heterogeneity in ranking. The marginal probability that Toro is the most preferred sushi ranges from 66% to 69% except for females of age 60 years or more and currently living in west Japan, where the probability is 44.3%. However, the sample sizes are relatively small in these two categories -there are only 12 females in the east Japan of age 60 or above and only 5 females in the west of age 60 or above. Thus the marginal posterior distributions of the central ranks for these two categories have higher variability than the other groups. The joint (posterior) probability of Toro being the most favorite sushi across all the categories is 37% (se 0.2%). We calculate the Monte Carlo standard errors for the posterior estimates using batch means method <ref type="bibr" target="#b10">(Flegal and Jones, 2010)</ref>. The joint (posterior) probability of Toro being among the top two favorite sushis across all the categories is 78% (se 0.3%). Thus Toro can be regarded as the most preferred sushi among the four.</p><p>Next assuming Toro being the most preferred, we compute the conditional probabilities of other sushis being the second most favorite in each of the groups. These conditional probabilities are highest for Maguro (tuna) and varies from 49% to 52% among the categories, followed by Anago (sea eel) with probabilities varying from 24% to 35%. The probability of Maguro being the second most favorite across all categories given that the Toro is the most favorite across all categories is 47% while the same probability for Anago is only 26%.</p><p>In order to judge any interaction effect present we compute the probability that the Toro is the most favorite sushi across all the age groups for each combination of gender (male/female) and geographic location (east/west). The solid lines in Figure <ref type="figure">7</ref> display these posterior probabilities for males (triangles) and females (circles). Notice that the posterior probability of Toro being the most favorite sushi among men does not change from east to west Japan but for women it does. Similarly we compute the posterior interaction probabilities for Maguro being the second most favorite conditional on Toro being the most favorite. The dashed lines in Figure <ref type="figure">7</ref> display these probabilities. Similar to the previous case, the conditional posterior probability changes for women from east to west Japan. However, this change is not as large as the previous case. Such interaction effects were found to be absent between age and gender, suggesting that the preferences towards different sushis do not, as such, depend on age.</p><p>The variability in ranking is also reaffirmed by the small value of λ = 0.175 (se 0.235) and the multi-modal posterior distribution of θ i 's. For example, the posterior density estimate of θ 1 is shown in the left panel of Figure <ref type="figure" target="#fig_7">8</ref>. It is important to note that exploring this variability in ranking is possible because our sandwich algorithm for θ mixes very well (see right panel of Figure <ref type="figure" target="#fig_7">8</ref>) and discovers all the modes of the posterior distributions of θ i 's. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussions</head><p>In comparison to the multinomial logit model, the new rank-data model presented in this paper is far more parsimonious and it requires estimation of far less number of parameters. In addition, the new rank-data model allows us to introduce a notion of central ranking that facilitates a natural modeling of the observed rank data as perturbations of the central rank.</p><p>In the presence of categorical covariates the central rank may vary across categories and the rank-data model has been extended to incorporate this. While the estimation of the parameters of this new rank-data model is conceptually straight forward in a Bayesian set-up, considerable computational challenges are encountered due to the very slow convergence of the Gibbs sampler. Widely used diagnostics for detecting the convergence of the Gibbs sampler seem to fail in this situation. A new sandwich algorithm is devised for efficient posterior computation and is seen to perform effectively in the practically important situation when the number of items to be ranked is small. The case when one or more covariates are continuous will require development of a different technique and will be taken up in a future paper. We are also going to apply the proposed model and the MCMC algorithms in the context of partial rank data, that is, when not all available items are ranked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Supplementary materials</head><p>The online supplementary materials contain codes for analyzing the sushi data. where the first equality follows from <ref type="bibr">(Casella , 2001, p. 497)</ref>, the second equality follows from Figure <ref type="figure">1</ref>, and Ψ(•) and Ψ 1 (•) are the digamma and the trigamma functions respectively. In the above, we approximate the conditional expectation and variance terms by the corresponding MCMC estimate using our sandwich chain. Consequently, the standard error of λ is given by s.e.( λ) = I( λ|y) -1/2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head><p>B The Mtm K π when p = 2, g = 2</p><p>In order to write down the Mtm K π of the DA chain {π (m) } m≥0 , we need to introduce some notations. Let n ij denote the number of observations in the jth category with rank ζ i for i, j = 1, 2. Let n i. = n i1 + n i2 for i = 1, 2, n d = n 11 + n 22 , and n od = n 12 + n 21 . Let r(x) = 1/[x n 1. (1 -x) n 2. + x n 2. (1 -x) n 1. + x n d (1 -x) n od + x n od (1 -x) n d ], a = 1/Beta(n 1. + a 1 , n 2. + a 2 ), b = 1/Beta(n d + a 1 , n od + a 2 ), c = 1/Beta(n od + a 1 , n d + a 2 ), and d = 1/Beta(n 2. + a 1 , n 1. + a 2 ). Let k ij be the (i, j)th element of the matrix K π , i, j = 1, 2, 3, 4. Then straightforward calculations show that k 11 = a 1 0 r(x)x 2n 1. +a 1 -1 (1 -x) 2n 2. +a 2 -1 dx k 12 = a 1 0 r(x)x n 1. +n d +a 1 -1 (1 -x) n 2. +n od +a 2 -1 dx k 13 = a 1 0 r(x)x n 1. +n od +a 1 -1 (1 -x) n 2. +n d +a 2 -1 dx k 14 = a r(x)x 2n 2. +a 1 -1 (1 -x) 2n 1. +a 2 -1 dx.</p><p>As mentioned before, here we have ordered the points in the state space as follows: (ζ </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>sandwich technique to improve this DA chain. A sandwich algorithm (SA) is a simple alternative to the DA algorithm that often converges much faster. Each iteration of a generic SA has three steps. Let r(π |π) be a Markov transition density (Mtd) with invariant density p(π|y, λ) given in (5). If θ(m) is the current value of the sandwich chain at step m, then three steps are used to move to the new state θ(m+1) -draw π ∼ p(π| θ(m) , y), draw π ∼ r(•|π), and finally draw θ(m+1) ∼ p(θ|π , y).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(m) } m≥0 , of the Gibbs sampler. Let θ(m) be the current value of the sandwich chain at step m, then the following three steps are used to move to θ(m+1) : Iteration m + 1 of the Sandwich Algorithm: 1. Draw π ∼ p(•| θ(m) , y) as in step 1 of the Gibbs sampler. 2. Draw a permutation σ randomly uniformly from S p . Move to π = (σ • π 1 , σ • π 2 , . . . , σ • π g ) with probability min 1, p(π |y, λ) p(π, |y, λ) , otherwise π is retained. 3. Draw θ(m+1) ∼ p(•|π , y) as in step 2 of the Gibbs sampler.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>, π)p(θ|λ)p(π)dθ is the normalizing constant of the joint posterior density p(θ, π|y)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The behavior of the second largest eigenvalue for the DA chain {π (m) } m≥0 . The graph shows how the dominant eigenvalue of the DA chain changes with sample size, n.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Plot of posterior density of π.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: (a) True posterior marginals of all parameters. Empirical estimates of the marginal densities based on the DA chain with (b) 50 thousand iterations (c) 5 million iterations. (d) Empirical estimates of the marginal densities based on the sandwich chain with 50 thousand iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The Gelman-Rubin diagnostic plots for the DA chain based on 4 parallel runs of length 50,000 each. The starting values of multiple chains were selected near the global mode (left) and the local mode (middle) and from both modes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 7: Interaction probabilities: the solid lines join the points denoting the posterior probabilities of Toro being the most favorite sushi across all age groups. The dashed lines join the points denoting the posterior probabilities of Maguro being the second most favorite sushi conditional on Toro being the most favorite across all age groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>A</head><label></label><figDesc>Standard errors of λTo obtain the standard error of λ, note that the negative of the observed information for λ is given by-|ζ i | 2 e λ|ζ i | E(log θ i |y, λ) -Ψ 1 e λ|ζ i | e λ|ζ i | -Ψ e λ|ζ i | λ|ζ i | log θ i y, λ ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>x n 1. +n d +a 1 -1 (1 -x) n 2. +n od +a 2 -1 dxk 22 = b 1 0 r(x)x 2n d +a 1 -1 (1 -x) 2n od +a 2 -1 dx k 23 = b 1 0 r(x)x n+a 1 -1 (1 -x) n+a 2 -1 dx k 24 = b 1 0 r(x)x n 2. +n d +a 1 -1 (1 -x) n 1. +n od +a 2 x n 1. +n od +a 1 -1 (1 -x) n 2. +n d +a 2 x 2n od +a 1 -1 (1 -x) 2n d +a 2 -1 dx k 34 = c 1 0 r(x)x n 2. +n od +a 1 -1 (1 -x) n 1. +n d +a 2 -1 dx and finally k 41 = d 1 0 r(x)x n+a 1 -1 (1 -x) n+a 2 -1 dx k 42 = d 1 0 r(x)x n d +n 2. +a 1 -1 (1 -x) n od +n 1. +a 2 x n 2. +n od +a 1 -1 (1 -x) n 1. +n d +a 2 -1 dx k 44 = d 1 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1 , ζ 1 ), (ζ 1 , ζ 2 ), (ζ 2 , ζ 1 ), and (ζ 2 , ζ 2 ). So, for example, the element k 23 is the probability of moving from (ζ 1 , ζ 2 ) to (ζ 2 , ζ 1 ). Note that all of the transition probabilities are strictly positive, which implies that the DA chain is Harris ergodic.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>The second author thanks the <rs type="affiliation">Indian Institute of Management, Ahmedabad, India</rs> for kind support during his stay. The authors thank an editor, an associate editor and a referee for their comments which improved the paper.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Markov Chains Gibbs Fields, Monte Carlo Simulation, and Queues</title>
		<author>
			<persName><forename type="first">P</forename><surname>Brémaud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Biases in Local Government Elections Due to Position on the Ballot Paper</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J G</forename><surname>Upton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="414" to="419" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recognition assessed by rating and ranking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="13" to="22" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Empirical Bayes Gibbs sampling</title>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="485" to="500" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Lxxvii. Note on the theory of permutations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cayley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="527" to="529" />
			<date type="published" when="1849">1849</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Metric methods for analyzing partially rank data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Critchlow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rank correlation and population models</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Daniels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="129" to="135" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Group representation in probability and statistics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">stitute of Mathematical Statistics</title>
		<title level="s">Lecture Notes-Monograph Series</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A generalization of spectral analysis with application to ranked data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="949" to="979" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On a model of concordance between judges</title>
		<author>
			<persName><forename type="first">P</forename><surname>Feigin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="203" to="213" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Batch means and spectral variance estimators in Markov chain Monte Carlo</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Flegal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1034" to="1070" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distance based ranking models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fligner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Verducci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="359" to="369" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multistage ranking models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fligner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Verducci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="892" to="901" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Markov chain Monte Carlo estimation of classical and dynamic switching and mixture models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Frühwirth-Schnatter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="194" to="209" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inference from iterative simulation using multiple sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="457" to="472" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A mixture of experts model for rank data with applications in election studies</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1452" to="1477" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A mixture of experts latent position cluster model for social network data</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">385405</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A theoretical comparison of the data augmentation, marginal augmentation and PX-DA algorithms. The Annals of Statistics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marchev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="532" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving the convergence properties of the data augmentation algorithm with an application to Bayesian mixture modelling</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hobert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="332" to="351" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Nantonac collaborative filtering: recommendation based on order responses</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kamishima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="583" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient Clustering for Orders</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kamishima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Akaho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mining Complex Data</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Computational Intelligence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Zighed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><forename type="middle">W</forename><surname>Tsumoto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Ras</surname></persName>
		</editor>
		<editor>
			<persName><surname>Hacid</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page">261280</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bayesian Analysis of Rank Data using SIR</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dongaonkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Multivariate Statistical Methods</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Sengupta</surname></persName>
		</editor>
		<imprint>
			<publisher>World Scientific Publshers</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cranking: Combining rankings using conditional probability models on permutations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lebanon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on machine learning</title>
		<meeting>the 19th international conference on machine learning<address><addrLine>San Francisco USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Covariance Structure of the Gibbs Sampler with Applications to Comparisons of Estimators and Augmentation Schemes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="27" to="40" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Parameter Expansion for Data Augmentation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="1264" to="1274" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Non-null ranking models</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Mallows</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="114" to="130" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Random permutations and partition models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Mccullagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Encyclopedia of Statistical Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1170" to="1177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Seeking Efficient Data Augmentation Schemes via Conditional and Marginal Augmentation</title>
		<author>
			<persName><forename type="first">X.-L</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Dyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Markov Chains and Stochastic Stability</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Meyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Tweedie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Remarks on the method of paired comparisons: I. The least squares solution assuming equal standard deviations and equal correlations</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mosteller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="3" to="9" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mixtures of distance-based models for ranking data</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics and Data Analysis</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="645" to="655" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Monte Carlo Statistical Methods, 2nd edn</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Spectral analytic comparisons for data augmentation. Statistics and Probability Letters</title>
		<author>
			<persName><forename type="first">V</forename><surname>Roy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="103" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Convergence rates for MCMC algorithms for a robust Bayesian binary regression model</title>
		<author>
			<persName><forename type="first">V</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2463" to="2485" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient estimation of the link function parameter in a robust Bayesian binary regression model</title>
		<author>
			<persName><forename type="first">V</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics and Data Analysis</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="87" to="102" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Convergence rates and asymptotic standard errors for MCMC algorithms for Bayesian probit regression</title>
		<author>
			<persName><forename type="first">V</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="607" to="623" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ranking or rating? Some data and their implications for the measurement of evaluative response</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="79" to="92" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A law of comparative judgment</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Thurstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="281" to="299" />
			<date type="published" when="1927">1927</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The relationship between Luce&apos;s choice axiom, Thurstone theory of comaparative judgment, and the double exponential distribution</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yellot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="109" to="144" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bayesian analysis of order-statistics models for ranking data</title>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">L H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="281" to="299" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">To center or not to center: that is not the question -An ancillarity-sufficiency interweaving strategy (ASIS) for boosting MCMC efficiency</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-L</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="531" to="570" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
