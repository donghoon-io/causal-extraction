<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Learning of Hierarchical Latent Class Models</title>
				<funder ref="#_vYTZs7Y">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_cuHRdUt">
					<orgName type="full">Grant Agency of the Czech Republic</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nevin</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong University of Science &amp; Technology Hong Kong</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tomáš</forename><surname>Kočka</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Laboratory of Intelligent Systems Prague Prague</orgName>
								<orgName type="institution">University of Economics Prague</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Learning of Hierarchical Latent Class Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hierarchical latent class (HLC) models are treestructured Bayesian networks where leaf nodes are observed while internal nodes are hidden. In earlier work, we have demonstrated in principle the possibility of reconstructing HLC models from data. In this paper, we address the scalability issue and develop a search-based algorithm that can efficiently learn high-quality HLC models for realistic domains. There are three technical contributions: (1) the identification of a set of search operators; (2) the use of improvement in BIC score per unit of increase in model complexity, rather than BIC score itself, for model selection; and (3) the adaptation of structural EM for situations where candidate models contain different variables than the current model. The algorithm was tested on the COIL Challenge 2000 data set and an interesting model was found.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Hierarchical latent class (HLC) models <ref type="bibr" target="#b8">[8]</ref> are treestructured Bayesian networks (BNs) where leaf nodes are observed while internal nodes are hidden. They generalize latent class (LC) models <ref type="bibr" target="#b3">[3]</ref> and were first identified as a potentially useful class of Bayesian networks by Pearl <ref type="bibr" target="#b5">[5]</ref>. This paper is concerned with the problem of learning HLC models from data. The problem is interesting for three reasons. First, HLC models represent complex dependencies among observed variables and yet are computationally simple to work with. Second, the endeavor of learning HLC models can reveal latent causal structures. Researchers have already been inferring latent causal structures from observed data. One example is the reconstruction of phylogenetic trees, which can be viewed as special HLC models. Third, HLC models alleviate disadvantages of LC models as models for cluster analysis.</p><p>When learning BNs with latent variables, one needs to determine not only model structures, but also cardinalities of latent variables, i.e. the numbers of values they can take.</p><p>Although not using the terminology of HLC models, Connolly <ref type="bibr" target="#b1">[1]</ref> proposed the first, somewhat ad hoc, algorithm for learning HLC models and tested it on one small toy example. A more principled algorithm was proposed by Zhang <ref type="bibr" target="#b8">[8]</ref>. This algorithm hill-climbs in the space of HLC models guided by a scoring function. It starts with an LC model. At each step of search, it first generates a number of candidate structures by modifying the structure of the current model. It then optimizes cardinalities of latent variables, resulting in candidate models. Finally, it evaluates the candidate models and picks the best one to seed the next step of search. Search terminates when the best candidate model is no better than the current model. To optimize the cardinalities of the latent variables in a model structure, the algorithm employs another hill-climbing routine. Hence we call it the double hill-climbing (DHC) algorithm.</p><p>Zhang <ref type="bibr" target="#b8">[8]</ref> has empirical shown that the DHC algorithm performs well in terms of model quality when coupled with the BIC score <ref type="bibr" target="#b6">[6]</ref>. However, it has a serious drawback, namely its high complexity. Let n be the number of observed variables. At each step of search, DHC generates O(n 2 ) models structures. To optimize the cardinalities of the latent variables in a given model structure, O(n 2 k) models are examined, where k is the maximum cardinality for a latent variable. Hence there are totally O(n 4 k) models to evaluate. Before a model can be evaluated, its parameters must be optimized. Due to the presence of latent variables, parameter optimization requires the EM algorithm, which is known to be computationally expensive.</p><p>In this work, we reduce the complexity of DHC in two steps. The first step is to reduce the number of models examined at each step of search from O(n 4 k) to O(n 2 ). This is achieved via a new algorithm called single hill-climbing (SHC). Two technical aspects of SHC are particularly interesting: 1) The set of search operators that it employs is the result of our efforts in finding an appropriate tradeoff between algorithmic complexity and model quality. The second step to reduce the complexity of DHC is to apply the idea of structural EM <ref type="bibr" target="#b2">[2]</ref> to SHC so that exact EM is required only once for each step of search. The result is an algorithm called heuristic SHC (HSHC). Structural EM completes data using the current model and uses the completed data set to evaluate candidate models. Candidate models generated by SHC contain latent variables that are non-existent in the current model or are different from the corresponding variables in the current model. Therefore, the application of Structural EM to SHC is not straightforward. We have found approximate ways to evaluate the candidate models that turn out to be equivalent to performing hypothesis tests for conditional independence and for goodness-of-fit of LC models.</p><p>We have conducted empirical studies to determine whether HSHC can find good models for real-world applications in a timely fashion. In particular, HSHC was used to analyze the COIL Challenge 2000 <ref type="bibr" target="#b7">[7]</ref> data. The data set consists of 86 variables and 5822 records. After preprocessing, we were left with 42 mostly binary variables. HSHC took 121 hours to finish the analysis and it produced an interesting model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">HLC models</head><p>A hierarchical latent class (HLC) model is a Bayesian network where (1) the network structure is a rooted tree and (2) the variables at the leaf nodes are observed and all the other variables are not. An example HLC model is shown in Figure <ref type="figure" target="#fig_0">1</ref> (left diagram). In this paper, we use the terms "node" and "variable" interchangeably. The observed variables are referred to as manifest variables and all the other variables as latent variables. A latent class (LC) model is an HLC model where there is only one latent node. We usually write an HLC model as a pair M = (m, θ), where θ is the collection of parameters. The first component m consists of the model structure and cardinalities of the variables. We will sometimes refer to m also as an HLC model. When it is necessary to distinguish between m and the pair (m, θ), we call m an uninstantiated HLC model and the pair (m, θ) an instantiated HLC model.</p><p>Two instantiated HLC models M =(m, θ) and M =(m , θ ) are marginally equivalent if they share the same manifest variables In m , X2 is the root. The operation is hence called root walking; the root has walked from X1 to X2. Root walking leads to equivalent models <ref type="bibr" target="#b8">[8]</ref>. This implies that it is impossible to determine edge orientation from data. We can learn only unrooted HLC models, which are HLC models with all directions on the edges dropped. Figure <ref type="figure" target="#fig_0">1</ref> also shows an example unrooted HLC model. An unrooted HLC model represents a class of HLC models. Members of the class are obtained by rooting the model at various nodes. Semantically it is a Markov random field on an undirected tree. The leaf nodes are observed while the interior nodes are latent. The concepts of marginal equivalence and equivalence can be defined for unrooted HLC models in the same way as for rooted models. From now on when we speak of HLC models we always mean unrooted HLC models unless it is explicitly stated otherwise.</p><p>Let |X| stand for the cardinality of a variable X. For a latent variable Z in an HLC model, enumerate its neighbors as X1, X2, . . . , X k . An HLC model is regular if for any latent variable Z, |Z| ≤</p><formula xml:id="formula_0">k i=1 |X i |/max k i=1 |X i |,</formula><p>and when Z has only two neighbors, strict inequality holds and one of the neighbors must be a latent node. Note that this definition applies to both instantiated and uninstantiated models.</p><p>Given an irregular instantiated model m, there exists a regular model that is marginally equivalent to m and has fewer independent parameters <ref type="bibr" target="#b8">[8]</ref>. The process of obtaining the regular model is called regularization. It is evident that if penalized likelihood is used for model selection, the regularized model is always preferred over m itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The SHC algorithm</head><p>Assume that there is a collection D of i.i.d samples on a number of manifest variables generated by an unknown regular HLC model. SHC aims at reconstructing the regular unrooted HLC models that corresponds to the generative model. It does so by hill-climbing in the space of all unrooted regular HLC models for the given manifest variables. For this paper, we assume that the BIC score is used to guide the search. The BIC score of a model m is:</p><formula xml:id="formula_1">BIC(m|D) = logP (D|m, θ * ) - d(m) 2 logN</formula><p>where θ * is the ML estimate of model parameters, d(m) is the dimension of m, i.e. the number of independent parameters, and N is the sample size.</p><p>The overall strategy of SHC is similar to that of greedy equivalence search (GES), an algorithm for learning Bayesian network structures in the case when all variables are observed <ref type="bibr" target="#b4">[4]</ref> The new node has the same number of states as X. Consider the HLC model m 1 in Figure <ref type="figure" target="#fig_2">2</ref>. Applying NI to the latent node X and its neighbors Y 1 and Y 2 results in the model m 2 . The new node X 1 has the same state space as X. For the sake for computational efficiency, we do not consider introducing a new node to mediate X and more than two of its neighbors. Without this restriction, the number of candidate models the operator could produce is exponential in the number of neighbors. Also note that NI is disallowed when X has only two neighbors. In this case, it would create a latent node that is also a leaf node. In HLC models, only manifest nodes can be leaves.</p><p>Let m be a model obtained from another model m via NI. Then m includes m. Note that if we set the cardinality of the new node X to a number smaller than |X|, then m would no longer include m. On the other hand, if we set |X | to a number larger than |X|, then m would be more complex than necessary.</p><p>The two operators discussed so far introduce new ingredients to a model. Node Relocation (NR), the next operator, re-arranges connections among existing nodes. It involves two neighboring latent nodes X 1 and X 2 and a neighbor Z of X 1 that is different from X 2 . It creates a new model by relocating Z to X 2 , i.e. removing the link between Z and X 1 and adding a link between Z and X 2 . Consider the HLC model m 2 in Figure <ref type="figure" target="#fig_2">2</ref>. Relocating Y 3 from X to X 1 results in model m 3 . Note that a node is allowed to be relocated only "one step away". This is for the sake of computational efficiency and, judging from our experience, more flexibility does not seem necessary. Also note that if the latent node X 1 has only two neighbors, relocating Z to X 2 would make the latent node X 1 a leaf node. In this case, we simply remove All of the five operators might lead to the violation of the regularity constraints. We therefore follow each operator immediately with a regularization step.</p><p>Model selection: Given a data set, our task is to find a model that fits the data well and has low complexity. It is possible to achieve perfect fit to data using an LC model where the latent node has a high cardinality. That is to use the model with the lowest structure complexity and high variable complexity. Here variable complexity refers to the number of values latent variables can have, while structure complexity refers to the number of nodes and links among them. Clearly, we need to find a balance between variable complexity and structure complexity so that the overall model complexity is low.</p><p>The SI operator increases variable complexity, while the NI operator increases structure complexity. To find an appropriate tradeoff between the two aspects of model complexity, SHC starts with the model that has the lowest variable complexity and the lowest structure complexity, i.e. the LC model where the latent node has only two states. At each step in Phase I, it generates candidate models by applying the SI, NI, and NR operators on the current model and selects one of the candidate models to seed the next step of step. The key question is which candidate model to select.</p><p>A naive answer to pick the one with the highest BIC score. This strategy does not work. We have observed in experiments that SHC often does not leave LC models when models are selected based on BIC score itself: It kept increasing the cardinality of the only latent node, but did not introduce new latent nodes.</p><p>To understand the phenomenon, consider the first step, where the current model is the LC model with a binary latent node. Suppose there are n manifest variables. Then, SI would introduce n+1 additional parameters, while NI would introduce only 2 additional parameters. More parameters means better fit to data, which in turn implies that the loglikelihood term of the BIC score is higher. At this early stage of search, the improvement in the loglikelihood term is more drastic than the increase in the penalty term. Consequently, the (unique) model generated by SI is likely to have a higher score than models produced by NI and is likely to be chosen, resulting in another LC model where the latent node has three states. In one of our experiments, the initial LC model has a BIC score of -128,684. The model generated by NI from the initial LC model has a BIC score of -125,185, while the best model generated by NI has a BIC score of only -125,569. Repeating the arguments, we see that SI is likely to be applied again in the next step, and again in the step after, and so on.</p><p>As an analogy, we compare candidate models to investment alternatives and their BIC scores to earnings (dividends minus transaction costs) of investment alternatives. When deciding one particular investment, if one aims at maximizing the earning, then one would prefer alternatives that involve large sums of fund to those that involves small sums of fund. Compared with small investments, large investments usually have higher earnings despite higher transaction costs. Similarly, if we aim at maximizing the BIC score, then we would prefer more complex candidate models than less complex one. At the beginning of SHC, the likelihood term of the BIC score increases faster with model complexity than the penalty term. Consequently, more complex candidate models usually have higher BIC scores with less complex ones.</p><p>Maximizing the earnings of each investment transaction does not bring about maximum total earnings for the finite fund that one has. A better strategy is to maximize earnings ratio, i.e. earning over the amount of investment. We apply this idea to model selection. Let m be the current model and m be a candidate model. Define the unit improvement of m over m given D to be</p><formula xml:id="formula_2">U (m , m|D) = BIC(m |D) -BIC(m|D) d(m ) -d(m) . (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>It is the increase in model score per unit increase in model complexity. SHC selects models using the following cost-effectiveness principle: Among all candidate models, choose the one that has the highest unit improvement over the current model.</p><p>The NR operator does not necessarily increase the number of model parameters. Care must be taken when comparing models it produces with models generated by other operators. At each step, SHC first considers candidate models produced by the NR operator. Among them, those models whose BIC scores are not higher than that of the current model are discarded. If there are, among the remaining, models that have fewer parameters than the current model, the one with the highest BIC score is chosen and search moves to the next step immediately without considering other operators. If all the remaining models have more parameters than the current model, on the other hand, then they are compared with other candidate models using the cost-effectiveness principle.</p><p>Model selection in Phase II is straightforward and is based on model score.</p><p>Pseudo code: We now give the pseudo code for the SHC algorithm. The input to the algorithm is a data set D on a list of manifest variables. Records in D do not necessarily contain values for all the manifest variables. The output is an unrooted HLC model. Model parameters are optimized using the EM algorithm. Given a model m, the collections of candidate models the search operators produce will be respectively denoted by NI(m), SI(m), NR(m), ND(m), and SD(m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHC(D)</head><p>Let m be the LC model with a binary latent node. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The heuristic SHC algorithm</head><p>At each step of search, SHC generates a set of candidate models, evaluates each of them, and selects the best one.</p><p>Before a model can be evaluated, its parameters must be optimized. Due to the presence of latent variables, parameters are optimized using the EM algorithm. EM is known to be computationally expensive. SHC runs EM on each candidate model and is hence still inefficient.</p><p>The same problem confronts hill-climbing algorithms for learning general Bayesian networks from data with missing values. There, structural EM was proposed to reduce the number of calls to EM <ref type="bibr" target="#b2">[2]</ref>. The idea is to complete the data, or fill in the missing values, using the current model and then evaluate the candidate models based on the completed data. Parameter optimization based on the completed data does not require EM at all. EM is called only once at the end of each iteration to optimize the parameters of the best candidate model.</p><p>In this section, we apply the idea of structural EM to SHC. The main technical issue that we need to address is that the variables in the candidate models can differ slightly different from those in the current model. Hence there might be a slight mismatch between the completed data and the candidate models. In a candidate model generated by the NI operator, for instance, there is one new variable that does not appear in the current model. The completed data contain no values for the new variable.</p><p>How should we evaluate a candidate model based on a slightly mismatched data set? The answer depends how the candidate model is generated, i.e. by which operator. We divide all the candidate models into several groups, with one group for each operator. Models in a group are compared with each other based on the completed data and the best one is selected. Thereafter a second model selection process is invoked to choose one from the best models of the groups. This second process is the same as the model selection process in SHC, except that there is only one candidate model for each operator. In this phase, parameters of models are optimized using EM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model selection in Phase I</head><p>In the next 3 subsections, we discuss how to select among candidate models generated by each of the search operators used in Phase I. Here are some notations that we will use. We use m to denote the current model and θ * to denote the ML estimate of the parameters of m based on the data set D. The estimate was computed using EM at the end of the previous step. Let Pm be the joint probability represented by the instantiated model (m, θ * ).</p><p>Completing the data set D using the model (m, θ * ), we get a data set that contain values for all variables in m. Denote the completed data set by Dm. Let V the set of variables in m. Dm induces an empirical distribution over V, which we denote by P (V). In the following, we will need to refer to the quantities of P (X) and P (X|Y), where X and Y are subsets of variables. Such quantities are computed from the model (m, θ * ) and the original data set D. They are not obtained from the completed data set Dm. In fact, we never explicitly compute the completed data set. It is introduced only for conceptual clarity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Selecting among models generated by NI</head><formula xml:id="formula_4">d(m ) -d(m) . (<label>3</label></formula><formula xml:id="formula_5">)</formula><p>This is the criterion that we use to select among models in NI(m); We select the one that maximizes the quantity. The criterion is intuitively appealing. Consider the term on the numerator of the expression on the right hand side of (3). Except for a constant factor of 2, it is the G-squared statistic, based on Dm, for testing the hypothesis that B and C are conditionally independent given A. The larger the term, the further away B and C are from being independent given A, and the more improvement in model quality the NI operation would bring about. So selecting the candidate model m in NI(m) that maximizes UNI (m , m|Dm) amounts to choosing the way to apply NI operator that would result in the largest increase in model quality per complexity unit.</p><p>The UNI criterion is also a natural approximation of the cost-effectiveness principle.We explain why in the rest of this subsection.</p><p>The cost-effectiveness principle states that we should choose the model m in NI(m) that maximizes:</p><formula xml:id="formula_6">U (m , m|Dm) = BIC(m |Dm) -BIC(m|Dm) d(m ) -d(m) . (<label>4</label></formula><formula xml:id="formula_7">)</formula><p>For technical convenience, root m and m at node A. It is well known that BIC(m|Dm) is given by</p><formula xml:id="formula_8">N X∈V X,pa(X) P (X, pa(X))log P (X|pa(X) - d(m) 2 logN,</formula><p>where pa(X) stands for the set of parents of X in m.</p><p>The challenge is to compute term BIC(m |Dm). Let θ * be the ML estimate of the parameters of m based on Dm. Use P m to denote the joint probability represented by parameterized model (m , θ * ). Consider a variable X in m that is not B , C, or H. The parents of X in m are the same as those in m. Moreover, the variable and it parents are observed in the data set Dm. Hence we have P m (X|pa(X)) = P (X|pa(X)). Consequently, BIC(m |Dm) is given by</p><formula xml:id="formula_9">logP (Dm|m , θ * ) - d(m ) 2 logN</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Selecting among models generated by NR</head><p>Consider a candidate model m in NR(m). Model m consists of the same variables as m and hence the application of structural EM is straightforward in this case. To be more specific, suppose m is obtained from m by relocating a neighbor B of a node A to another neighbor C of A. For technical convenience, assume m is rooted at A. Then BIC(m |Dm)-BIC(m|Dm) is given by</p><formula xml:id="formula_10">A,B,C P (A, B, C)log P (B|C) Pm(B|A) - d(m ) -d(m) 2 logN. (9)</formula><p>Among all models in NR(m), we choose the one for which this difference is the largest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Model selection in Phase II</head><p>Consider a candidate model m in ND(m). Suppose it is obtained from m by deleting a latent node B. Suppose the neighbors of B in m are A, C1, . . . , Cr and suppose the Ci's are made neighbors of A in m . For technical convenience, assume m is rooted at A. Then BIC(m |Dm)-BIC(m|Dm) is given by</p><formula xml:id="formula_11">m i=1 A,C i P (A, Ci)log P (Ci|A) - m i=1 B,C i P (B, Ci)logPm(Ci|B)] -A,B P (A, B)logPm(B|A) -d(m )-d(m) 2 logN. (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>Among all models in ND(m), we choose the one for which this difference is the largest. We do not have good heuristics for selecting among models in SD(m) based on Dm. So we proceed with them in the straightforward way. Parameters of all these candidate models are optimized by running EM. Their BIC scores are then computed. The one with the highest BIC score is chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">A generalization</head><p>The algorithm outlined so far has a natural generalization. For a given operator, instead of choosing the best model we can choose the top K best models for some number K. This top-K scheme reduces the chance of getting trapped in local maxima. In general, the larger the K, the smaller the probability of encountering local maxima. On the other hand, larger K also implies running EM on more models and hence longer computation time. In practice, one can start with K being 1 and increase it gradually as long as time permits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Local EM</head><p>By applying the idea of structural EM, we have substantially reduced the number of calls to EM. Nonetheless we still need to run EM on a number of models at each step of search. Within the top-K scheme, we need to run EM on K models for each of the operators except for SD. For SD, we need to run EM on n h models, where n h is the number of latent nodes in the current model. To achieve further speedup, we replace all those calls to EM with calls to a more efficient procedure that we refer to as local EM.</p><p>Parameters of the current model m were estimated at the end of the previous search step. <ref type="bibr">Each</ref>  Obviously, model parameters provided by local EM deviate from those provided by EM. To avoid accumulation of deviations, we run EM once at the end of each search step on the model that is selected as the best at that step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Empirical results</head><p>This section reports experiments designed to determine whether HSHC can learn models of good quality and how efficient it is. In all the experiments, EM and local EM were configured as follows. To estimate all/some of the parameters for a given uninstantiated/partially instantiated model m, we first randomly generated 64 sets of parameters for the model, resulting in 64 initial fully instantiated models <ref type="foot" target="#foot_1">1</ref> . One EM/local EM iteration was run on all models and afterwards the worst 32 models were discarded. Then two EM/local EM iterations were run on the remaining 32 models and afterwards the worst 16 models were discarded. This process was continued until there was only one model. On this model, EM/local EM were terminated either if the increase in loglikelihood fell below 0.01 or the total number of iterations exceeded 500. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiments with synthetic data</head><p>We used 5 generative models, consisting of 6, 9, 12, 15, and 18 manifest variables respectively. One of the models is shown in Figure <ref type="figure" target="#fig_5">3</ref>. Parameters were randomly generated except we ensured that each conditional distribution has a component with mass larger than 0.8. We also ensured that, in every conditional probability table, that the largest components of different rows are not all at the same column. A data set of 10,000 records were sampled for each model. We then ran both SHC and HSHC to reconstruct the generative models from the data sets. HSHC was tested on all the 5 data sets, while SHC was tested on only 3, i.e. those sampled from the 3 simplest generative models. For HSHC, we let the K in the top-K scheme run from 1 to 3. So we in fact tested three versions of the algorithm. We will refer to them using HSHC1, HSHC2, and HSHC3. The algorithms were implemented in Java and all experiments were run on a Pentium 4 PC with a clock rate of 2.26 GHz.</p><p>To measure the quality of the learned models, a testing set Dt of 5,000 records were sampled from each generative model. The log score logP l (Dt) of each learned model and the log score logPo(Dt) of the corresponding original model were computed. Let Nt be the number records in Dt in general. Note that as Nt goes to infinity the average log score difference (logPo(Dt) -logP l (Dt))/Nt tends to KL(Po, P l ), the KL divergence of the probability distribution of manifest variables in the learned model from that of manifest variables in the original model. We hence refer to it as empirical KL divergence. It is a good measure of the quality of the learned model.</p><p>The empirical divergences between the learned models and the original models are shown in Figure <ref type="figure" target="#fig_6">4</ref>. We see that some of the models reconstructed by HSHC1 are of poor quality in two of the five cases. However, all the models reconstructed by HSHC2 and HSHC3 match the generative models extremely well in terms of distribution over the manifest variables. The structures of these models are either identical or very similar to the structures of the generative models. The structure of the model produced by HSHC3 for the model shown at the top of 3 is shown at the bottom of the same figure. The two structures are very similar.</p><p>Time statistics are shown in Figure <ref type="figure" target="#fig_6">4</ref>. We see that HSHC is much more efficiently than SHC and it scales up fairly well. In another experiment involving the HLC model shown in Figure <ref type="figure" target="#fig_0">1</ref>, SHC was 22 times faster than DHC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiments with real-world data</head><p>The training set of the COIL Challenge 2000 data consists of 5,822 customer records. Each records consists of 86 attributes, containing socio-demographic information (Attributes 1-43) and insurance product ownerships (Attributes 44-86). The task is to learn a model and use it to predict who would buy caravan (mobile home) insurance polices.</p><p>For our experiments, we selected Attributes 4,5,43 and 44-86. Attribute values were merged so that there are at least 30 cases for each value. Thereafter, the attributes have 2 to 9 values. In the resultant data set, there are fewer than 10 cases where Attributes 50, 60, 71 and 81 take nonzero values. Those attributes were therefore excluded from further analysis. This leaves us with 42 attributes.</p><p>We analyzed the data set using HSHC. Again the top-K scheme was used, with K being 1, 5, 10, and 20. The running times and the BIC scores of the resulting models are shown in the following table: there is a latent variable for each such pair. Moreover, all agriculture-related attributes are under one latent variable, namely h 15 ; all vehicle-related attributes are under the latent variable h 8 ; and so on. One might argue the model structure is not completely in accord with the structure of the domain. We have considered a number of possible improvements. None of them have given rise to a better model.</p><p>In COIL Challenge 2000, there is a test set of 4,000 that contains 238 caravan policy owns. The prediction task requires participants to identify a subset of 800 that contains as many caravan policy owners as possible. Random selection results in 42 policy owners, while the best entry contains 121. Selection based on M 10 gives 110. This is good performance considering that HSHC aims at optimizing BIC score rather than classification error.</p><p>For the sake of comparison, we also ran GES on the training set to obtain a Bayesian network without latent variables. The network is intuitively less appealing than M 10 , as one can naturally imagine. When it is used to guide the prediction task, only 83 policy owners were selected. More details will be given in a longer version of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have developed a search-based algorithm for learning HLC models. The algorithm is not fast enough for online applications, but it can used in applications such as COIL Challenge 2000 to analyze data offline.</p><p>Our results with the COIL Challenge 2000 data should have given the reader a hint about why learning HLC models is interesting from the viewpoint of application. Good results have also been obtained in an application in traditional Chinese medicine. More details will be given in sep-arate papers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. An example HLC model and the corresponding unrooted HLC model. The X i 's are latent variables and the Y j 's are manifest variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>. It begins with the simplest HLC model, i.e. the LC model, and works in two phases. In Phase I, SHC expands models by introducing new latent nodes and additional states for existing nodes. The aim is to improve the likelihood term of the BIC score. In Phase II, SHC retracts models by deleting latent nodes or states of latent nodes. The aim is to reduce the penalty term of the BIC score, while keeping the likelihood term more or less the same. If model quality is improved in Phase II, SHC goes back to Phase I and the process repeats itself. Search operators: SHC hill-climbs using five search operators, namely State Introduction, Node Introduction, Node Relocation, State Deletion, and Node Deletion. The first three operators are used in Phase I and the rest are used in Phase II. Given an HLC model and a latent variable in the model, State Introduction (SI) creates a new model by adding a state to the state space of the variable. Clearly, the new model includes the old one. Node Introduction (NI) involves one latent node X and two of its neighbors. It creates a new model by introducing a new latent node X to mediate X and the two neighbors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The NI and NR operators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>X 1 . State Deletion (SD) is the opposite of SI. Given an HLC model and a latent node, it creates a new model by deleting a state of the latent node. It is not applicable if the latent node has only two states. Node Deletion (ND) is the opposite of NI. It involves two neighboring latent node X and X in an HLC model. It creates a new model by deleting X and making all neighbors of X other than X neighbors of X . If model m is obtained by applying State or Node Deletion to model m, then m includes m .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Repeat until termination: m =PhaseI(m, D). If BIC(m |D)≤BIC(m|D), return m. Else m=m . m =PhaseII(m, D). If BIC(m |D)≤BIC(m|D), return m. Else m=m . PhaseI(m, D) Repeat until termination: Remove from NR(m) all models m s.t. BIC(m |D)≤BIC(m|D), If there is m ∈NR(m) s.t. d(m )≤d(m) m=m and continue. Find m in NR(m)∪NI(m)∪SI(m) that maximizes U (m , m|D). If BIC(m |D)≤BIC(m|D), return m. Else m=m . PhaseII(M, D) Repeat until termination: Find the model m in ND(m)∪SD(m) that maximizes BIC(m |D). If BIC(m |D)≤BIC(m|D), return m. Else m=m .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. TOP: One of the test models. Manifest nodes are labelled with their names. All manifest variables have 3 states. Latent nodes are labelled with their cardinalities. BOTTOM: The unrooted HLC model reconstructed from data by HSHC3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Model quality and time statistics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. HLC model found for the COIL Challenge 2000 data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Y1, Y2, . . . , Yn and</figDesc><table><row><cell>P (Y1, . . . , Yn|m, θ) = P (Y1, . . . , Yn|m , θ ).</cell><cell>(1)</cell></row><row><cell cols="2">An uninstantiated HLC models m includes another m if for</cell></row><row><cell cols="2">any parameterization θ of m , there exists parameterization</cell></row><row><cell cols="2">θ of m such that (m, θ) and (m , θ ) are marginally equiva-</cell></row><row><cell cols="2">lent, i.e. if m can represent any distributions over the mani-</cell></row><row><cell cols="2">fest variables that m can. If m includes m and vice versa,</cell></row><row><cell cols="2">we say that m and m are marginally equivalent. Marginally</cell></row><row><cell cols="2">equivalent (instantiated or uninstantiated) models are equiv-</cell></row><row><cell cols="2">alent if they have the same number of independent param-</cell></row><row><cell cols="2">eters. One cannot distinguish between equivalent models</cell></row><row><cell>using penalized likelihood scores.</cell><cell></cell></row><row><cell cols="2">Let X1 be the root of an HLC model m. Suppose X2 is</cell></row><row><cell cols="2">a child of X1 and it is a latent node. Define another HLC</cell></row><row><cell>model m by reversing the arrow X1→X2.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Consider a candidate model m in NI(m). Suppose it is obtained from m by introducing a latent variable H to mediate the interactions between a node A and two of its neighbors B and C. Define</figDesc><table><row><cell>UNI (m , m|Dm) =</cell><cell>N A,B,C P (A, B, C)log P (B,C|A) P (B|A) P (C|A)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>candidate model m generated at the current search step differs from m only slightly. The idea of local EM is to optimize the conditional probability distributions (CPDs) of only a few variables in m , while keeping those of other variables the same as in m. If m is obtained from m by adding a state to or deleting a state from a variable A, then only the CPD's that involve A are optimized. If m is obtained from m by introducing a latent node H to separate a node A from two of its neighbors, then only the CPD's that involve A and H are optimized. If m is obtained from m by relocating a node B from A to C, then only the CPD's that involve A and C are optimized. Finally, if m is obtained from m by deleting a node B and making all neighbors except for one, which we denote by A, neighbors of A, then only the CPD's that involve A are optimized.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence (ICTAI 2004) 1082-3409/04 $20.00 © 2004 IEEE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>At the end of each search step, we ran EM on the model selected in that step. This model was used as one of the initial instantiated models. Hence only 63 initial models were actually generated randomly.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Proceedings of the 16th IEEE International Conference on Tools with Artificial Intelligence(ICTAI 2004)  </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">Finn V. Jensen</rs> and <rs type="person">Gytis Karciauskas</rs> for valuable discussions. Research was partially supported <rs type="grantName">Hong Kong Research Grants Council</rs> under grant <rs type="grantNumber">HKUST6088/01E</rs> and <rs type="funder">Grant Agency of the Czech Republic</rs> under Grant <rs type="grantNumber">201/02/1269</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_cuHRdUt">
					<idno type="grant-number">HKUST6088/01E</idno>
					<orgName type="grant-name">Hong Kong Research Grants Council</orgName>
				</org>
				<org type="funding" xml:id="_vYTZs7Y">
					<idno type="grant-number">201/02/1269</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>= N X∈V\{B,C} X,pa(X) P (X, pa(X))log P (X|pa(X) where P m (B, C|A)= H P m (H|A)P m (B|H)P m (C|H).</p><p>One can estimate the conditional probability distributions P m (H|A), P m (B|H), and P m (C|H) from Dm. But this requires running EM because Dm does not contain values for H. Not wanting to run EM, we seek an approximation for the second term on the right hand side of the above equation. We choose to approximate it with the maximum value possible, i.e. N A,B,C P (A, B, C)log P (B, C|A). This leads to the following approximation of U (m , m|Dm)</p><p>Simplifying this expression and deleting terms that do not depend on m , we get the term on the right hand side of (3). Let B1, . . . , B k be the neighbors of A (A ) in m (m ). Define USI(m , m|Dm,A) by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Selecting among models generated by SI</head><p>This is the heuristic we use to select among models generated by the SI operator. This selection criterion is intuitively appealing. In m, consider the LC model formed by A and its neighbors B1, . . . , B k . With respect to Dm,A, A is latent and the Bi's are observed. Except for a constant factor of 2, the term on the numerator of the expression on the right hand side of ( <ref type="formula">5</ref>) is the G-Squared statistic for testing the goodness-of-fit of the LC model. If the term is small, then the Bi's are close to being mutually independent of each other given A. Most of the observed correlations among them are accounted for by the latent variable A. If the term is large, on the other hand, the Bi's are far from being mutually independent given A. There are significant correlations among them that are not accounted for by the variable A. Introducing a new state to A will help to capture those correlations and hence significantly increase model fit.</p><p>It is clear that the complexity of computing USI(m , m|Dm,A) is exponential in k. For the sake of efficiency, the criterion is not implemented exactly. Rather, we use the following approximation:</p><p>In the rest of this subsection, we explain how USI(m , m|Dm,A) follows from the cost-effectiveness measure</p><p>Let VA the set of variables in Dm,A. It is the same as the set of variables in m except for A . Let θ * A be the ML estimate of parameters of m based on Dm,A. Use P m ,A to denote the joint probability distributions represented by the parameterized model (m , θ * A ). For technical convenience, root m at node A and m at node A . Then BIC(m |D m,A ) is given by</p><p>To obtain P m ,A (B1, . . . , B k ), one needs to run EM to estimate P m A (A) and P m ,A (Bi|A). Not wanting to run EM, we approximate the second term in the above expression with N B 1 ,...,B k P (B1, . . . , B k )log P (B1, . . . , B k ), which is an upper bound of the term. Let θ * A is the ML estimate of parameters of m based on Dm,A. Use Pm,A to denote the joint probability distribution represented the parameterized model (m, θ * A ). Then BIC(m|Dm,A) is given by  Substituting this for BIC(m |Dm,A)-BIC(m|Dm,A) in ( <ref type="formula">7</ref>), simplifying the resulting expression, and removing terms that does not depend on m , we obtain the right hand side of (5).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Contr. private 3rd party v65: Num. private 3rd party h</title>
		<title level="s">Contr. family accidents v</title>
		<imprint>
			<publisher>Num</publisher>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note>Num. agricultural machines h. tractor v52: Contr. tractor h21(9) v05: Customer main type v43: Purchasing power class v04: Avg age References</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Constructing hidden variables in Bayesian networks via conceptual learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Connolly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML-93</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning belief networks in the presence of missing values and hidden variables</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML-97</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="125" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Lazarsfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Henry</surname></persName>
		</author>
		<title level="m">Latent structure analysis</title>
		<meeting><address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<publisher>Houghton Mifflin</publisher>
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graphical models: Selection causal and statistical models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<biblScope unit="volume">88</biblScope>
			<pubPlace>Palo Alto</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">COIL Challenge 2000: The insurance company case</title>
		<editor>P. van er Putten and M. van Someren</editor>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Sentient Machine Research</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Hierarchical latent class models for cluster analysis</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page" from="230" to="237" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
