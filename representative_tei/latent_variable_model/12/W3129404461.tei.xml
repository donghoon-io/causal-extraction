<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A new approach to measuring absolute pitch on a psychometric theory of isolated pitch perception: Is it disentangling specific groups or capturing a continuous ability?</title>
				<funder ref="#_BTr3mxx #_ebe3wew">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_28MrDEt">
					<orgName type="full">CAPES</orgName>
				</funder>
				<funder ref="#_fDadXSE #_yU6cSDr">
					<orgName type="full">Fundac ¸ão de Amparo à Pesquisa do Estado de São Paulo)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-02-22">February 22, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nayana</forename><surname>Di</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Giuseppe</forename><surname>Germano</surname></persName>
							<idno type="ORCID">0000-0003-3061-644X</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Music</orgName>
								<orgName type="institution" key="instit1">Federal University of Santa Maria</orgName>
								<orgName type="institution" key="instit2">Santa Maria, RS</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hugo</forename><surname>Cogo-Moreira</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">The University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fausto</forename><surname>Coutinho- Lourenc</surname></persName>
							<idno type="ORCID">0000-0002-5656-5137</idno>
						</author>
						<author>
							<persName><forename type="first">Graziela</forename><surname>3☯</surname></persName>
							<idno type="ORCID">0000-0002-5656-5137</idno>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychobiology</orgName>
								<orgName type="institution">SAR</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Bortz</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Music</orgName>
								<orgName type="institution">Federal University of Sao Paulo</orgName>
								<address>
									<settlement>Sao Paulo</settlement>
									<region>SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">UNESP</orgName>
								<address>
									<settlement>Sao Paulo</settlement>
									<region>SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<country key="DK">DENMARK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A new approach to measuring absolute pitch on a psychometric theory of isolated pitch perception: Is it disentangling specific groups or capturing a continuous ability?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-02-22">February 22, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1371/journal.pone.0247473</idno>
					<note type="submission">Received: February 14, 2020 Accepted: February 8, 2021</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Absolute Pitch (AP) is commonly defined as a rare ability that allows an individual to identify any pitch by name. Most researchers use classificatory tests for AP which tracks the number of isolated correct answers. However, each researcher chooses their own procedure for what should be considered correct or incorrect in measuring this ability. Consequently, it is impossible to evaluate comparatively how the stimuli and criteria classify individuals in the same way. We thus adopted a psychometric perspective, approaching AP as a latent trait. Via the Latent Variable Model, we evaluated the consistency and validity for a measure to test for AP ability. A total of 783 undergraduate music students participated in the test. The test battery comprised 10 isolated pitches. All collected data were analyzed with two different rating criteria (perfect and imperfect) under three Latent Variable Model approaches: continuous (Item Response Theory with two and three parameters), categorical (Latent Class Analysis), and the Hybrid model. According to model fit information indices, the perfect approach (only exact pitch responses as correct) measurement model had a better fit under the trait (continuous) specification. This contradicts the usual assumption of a division between AP and non-AP possessors. Alternatively, the categorical solution for the two classes demonstrated the best solution for the imperfect approach (exact pitch responses and semitone deviations considered as correct).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The phenomenon of Absolute Pitch (AP) was first scientifically described by Stumpf <ref type="bibr" target="#b0">[1]</ref>, although it was alluded to much earlier in Mozart's era <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. AP ability has attracted attention from musicians, psychologists, and neuroscientists, leading to a large body of research <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. <ref type="bibr">AP</ref> has not yet been accurately and consensually defined among the academic community <ref type="bibr" target="#b7">[8]</ref>, leading to significant variations among AP evidence and AP classification. Consequently, conclusions regarding AP classification may not be comparable due to the lack of consensus on criteria (e.g., the time required to identify a tone, or the degree of precision in tone identification).</p><p>Only a few defining criteria for AP ability are agreed upon among authors, such as the automatic association between a certain pitch and a learned verbal label <ref type="bibr" target="#b8">[9]</ref>, and the definition of AP as a rare ability that refers to a long-term internal representation for pitches. Consequently, AP typically manifests behaviorally as the ability to identify any given pitch by name (according to the traditional pattern of musical notation learned by a subject), or by producing a given musical tone on demand, with no external reference, e.g., without a diapason <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref>.</p><p>The extant AP literature references certain limitations of AP possessors in pitch identification. Timbre limitation is mentioned by several studies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref>, although it has not yet been universally specified or quantified, and its causes have not yet been scientifically explained. The same can be said of register limitation among AP individuals <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref>. We consider these to be examples of relevant non-consensual criteria excluded from most AP definitions. An important consequence of this methodological decision is that individuals with difficulties in tone recognition due to certain configurations of musical parameters (mostly regarding timbre and/or register) must be considered as non-AP possessors.</p><p>The AP phenomenon is generally considered as instantaneous pitch recognition and some studies adopt a brief time response window (e.g., three or four seconds), assuming it is sufficient to affirm an immediate response in a given task <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. It is also assumed that providing some procedures in AP tests can limit (or completely eliminate) the use of Relative Pitch (RP). These procedures can include some methodological issues, including granting brief time response, separating tones by an interval larger than an octave, or placing brown noise between stimuli <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>.</p><p>There are two different theoretical perspectives regarding the RP definition, namely, the broad and the narrow perspectives <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. In the broad perspective, RP ability is assigned to anyone (musician or non-musician) who is capable of realizing basic music perceptual tasks, such as recognizing familiar music when it is transposed or played on different instruments or singing a familiar song in tune <ref type="bibr" target="#b24">[25]</ref>. These are predominantly intuitive unconscious abilities, and most people accomplish them instinctively. In the narrow perspective, RP is assigned to individuals who can name intervals and other musical elements (including triads, tonalities, harmonic progressions, and scales, among others). Musicians must be able to recognize familiar music, like non-musicians, and also aurally recognize and name basic musical elements used in compositions (e.g., whether the heard musical interval was a minor or major second) <ref type="bibr" target="#b25">[26]</ref>. Hence, RP in the narrow perspective is acquired through years of intense training.</p><p>Thus, the use of classificatory tests to separate AP possessors from RP possessors should be approached with caution. Given that the study of music perception in undergraduate music schools and conservatoires includes sight-singing and ear training, these goals encompass the development of the RP ability among all students. Since most participants in AP studies are musicians, they all have received some degree of training in music perception. Thus, it is reasonable to expect that all test participants possess some degree of RP ability, even AP possessors. Consequently, it is impossible to ascertain whether RP ability can be completely eliminated by the use of a short response time or any other methodology. In fact, the possibility that an individual may possess both abilities, i.e., that AP and RP phenomena are not mutually exclusive, must be considered <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>As posited by Levitin and Rogers <ref type="bibr" target="#b28">[29]</ref>, "AP is neither 'absolute' nor 'perfect' in the ordinary uses of those words". AP possessors not only exhibit limitations for timbre and registers, as mentioned in previous paragraphs, but they also frequently make octave and semitone errors. This occurs so commonly that a substantial portion of classificatory tests for AP consider semitone errors as correct (or partially correct) answers <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>. This leads to a core methodological issue found in AP literature, that is, a lack of agreement for criteria regarding cut-offs in AP classificatory tests, which are arbitrarily defined. Moreover, this affects what is considered a correct or an incorrect answer to the stimuli. An example can be observed in Dohn et al. <ref type="bibr" target="#b29">[30]</ref>, who used a pitch identification test described and provided by Athos et al. <ref type="bibr" target="#b21">[22]</ref>, which was originally developed by Baharloo et al. <ref type="bibr" target="#b20">[21]</ref>. Although all three studies adopted the same test, they did not apply exactly the same methodology, nor the same scoring criteria. This lack of common criteria or a gold-standard tool to measure the same phenomenon leads to difficulties in comparing results, even when researchers intend to utilize the same test.</p><p>We aimed to develop a test for isolated pitch recognition from a psychometric perspective. That is, we considered this ability to be a latent phenomenon, evaluating a) the best model solution underlying the isolated pitch recognition, and b) how different rating approaches commonly used in the literature might influence the decision of the best model for isolated pitch recognition tasks. The use of a latent approach elucidates the item level functioning, providing evidence for construct validity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants and study design</head><p>A total of 783 undergraduate music students (n = 512; male = 65.4%) were recruited to this study. Participants ranged from the first to tenth semesters of study at seven different Brazilian universities, five of which were located in São Paulo city, and two in Curitiba city. This study was approved by the relevant ethics board (Ethics Committee's Approval CAAE: 60855816.3.0000.5477) and participants written consent was provided by all the students before the test/evaluation. The study was conducted during the first semester of the 2017 academic year. The participants' mean age was 24.7 years (range = 17 to 72) and they had an average of 10.29 years of music practice (SD = 6.7; range = 1 to 65). All participants were exposed to ear training and sight singing classes during their music studies.</p><p>The perception task consisted of five different batteries: isolated pitches, melodic intervals, harmonic intervals, fundamental position triads, and first position triads. Each battery included 10 stimuli. In this study, only the first battery (isolated pitches) will be discussed, which is the common procedure used to track AP. It must be emphasized that we considered the isolated pitch recognition without reference as a latent trait, without the automatic assumption that this ability and the AP ability were the same. Therefore, the items intended to measure the ability to identify isolated pitches without a reference was our main priority.</p><p>The first author of this study collected all data, giving exactly the same instructions to all subjects and guaranteeing an adequate standardization of method. The protocol was applied collectively, with previous authorization obtained from professors and the legal guardian responsible for each institution. Each stimulus was played once for 3 seconds, with a 15-second pause in between. No reference pitch was provided. Pitches and registers were highly variable among items. Timbres were chosen to represent each family of musical instruments. The stimuli were recorded in a studio by a professional and played on CD during the tests.</p><p>We attempted to limit the use of RP in our test by not providing any reference pitch, playing each stimulus only once, and changing the timbre and register between each stimulus. However, due to the issues discussed in the introduction section, we considered that it is methodologically impossible to completely prevent the use of RP in any isolated pitch recognition task. Each participant has a unique way of identifying pitches which can employ a combination of AP and RP, and common isolated pitch recognition tasks are incapable of evaluating the underlying mechanism being used. Consequently, we did not evaluate reaction time, providing a 15-second window between each stimulus in our test. With a longer response time, subjects had sufficient time to look at the response sheet, choose their answer, confirm where the right response was located on the drawn piano-keyboard, and mark their answer. This decreased the chance of errors unrelated to pitch discrimination. Notably, all participants in this research were required to pass an aural skill test to be admitted to music programs in Brazilian Universities. This indicates that all participants received some degree of training in music perception. Thus, it is reasonable to expect that all participants possessed some degree of RP ability, even AP possessors.</p><p>Participants were instructed to indicate the pitch they thought was correct on a piano-keyboard drawn on paper. It was expected that some participants would not be fluent in reading and/ or writing traditional musical notations if they had not yet taken the appropriate courses. The drawn piano-keyboard allowed us to delimit specifically 12 possible answers (12 chromatic notes). The piano-keyboard was also chosen because it allowed for easier visualization and identification of each possible answer through key position. It also contained the verbally written note names.</p><p>Participants were informed that the first battery was composed of only isolated pitches. They were also informed about the duration of each stimulus and the time interval between them. This was necessary to avoid confusion and surprise among subjects. No information was provided regarding timbre. The drawn keyboard had only one octave, as the object of our study was pitch class recognition. Therefore, the octave parameter was not considered in this task, and was disregarded by all subjects.</p><p>The first battery contained 10 isolated pitches in 5 different timbres (piano, violin, flute, tuba, and voice). The voice was recorded from two professional vocalists in a studio. All other instruments were recorded with the software Kontakt, using professionally recorded samples. The piano was taken from Piano in 162, the violin from Spitfire Solo Strings, the flute from 8dio Claire Flute, and the tuba from Spitfire Symphonic Brass (Fig <ref type="figure" target="#fig_0">1</ref>).</p><p>In (Fig <ref type="figure" target="#fig_0">1</ref>), the circle represents the latent trait, which we referred to as the ability to identify isolated pitches without reference (AIPWR). Because we were unable to measure any latent trait directly, the 10 stimuli constituted a set of items that could be measured and tested directly. These items, represented by rectangles, are similar to symptoms of psychological disorders, which can be directly observed. The stimuli are composed of three tone dimensions: register, timbre, and pitch class. We chose these 10 items to correspond to a summary of a vast stimuli range that is commonly used to measure AP ability. Thus, they were purposely very heterogeneous stimuli, encompassing all the different ranges of timbre, pitch, and register necessary to access Isolated Pitch Recognition Ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis</head><p>To evaluate the psychometric features of the isolated pitches battery, we used Mplus version 8.0 <ref type="bibr" target="#b34">[35]</ref> and the R program <ref type="bibr" target="#b35">[36]</ref>. All collected data were analyzed under three approaches: continuous, categorical, and hybrid (the factor mixture model). The former Item Response Theory (IRT) approach assumes that there is a continuous latent measure (or "trait") underlying the 10 items. That is, each participant would have some ability to identify isolated pitches without reference, similarly to other continuous cognitive measurements like quotient intelligence, psychopathology, and language skills. Two different IRT models were used:</p><p>a. An IRT model with two parameters for each stimulus: the discrimination parameter (parameter a), which describes the ability of the stimuli to distinguish between persons with low and high pitch identification ability; and the item location parameter (parameter b), representing the level of pitch identification ability where there is a 50% chance of correctly identifying the pitch of the stimulus;</p><p>b. An IRT with three parameters (discrimination, difficulty, and guessing [aka. lower bound asymptote]), where the additional parameter, guessing, is the probability of a person with very low pitch identification ability still correctly providing a correct answer for a given stimulus. The guessing parameter was recently implemented in Mplus and uses a prior maximum likelihood parameter that helps in the convergence of the model <ref type="bibr" target="#b36">[37]</ref>.</p><p>We used a piano keyboard to track the answers of the participants. Out of 12 keys, participants chose only one. Therefore, the prior guessing parameter likelihood was 1/12 for the perfect rating and 3/12 for the imperfect rating criteria. According to Baker <ref type="bibr" target="#b37">[38]</ref>, discrimination parameter cutoffs are 0 (none); 0.1 to 0.34 (very low); 0.35 to 0.64 (low); 0.65 to 1.34 (moderate); 1.35 to 1.69 (high); &lt; 1.70 (very high) and + infinity (perfect).</p><p>For IRT analysis, we used Maximum Likelihood estimator and logit parameterization (theta). The factor is assumed to be normally distributed being the mean fixed at zero and factor variance at 1. That is, the IRT analysis is centered on the person sample being at 0 logits, and the item difficulty parameters are provided relative to this. For the difficulty parameter, values closer to 3 indicated more difficulty, and values closer to -3 indicated less difficulty. Values around zero indicated the middle point between both extremes. To evaluate the model fit indices for IRT models, a Pearson chi-square test for categorical outcomes was used, with pvalues higher than 0.05 being indicators of a good fit. Item level fit was evaluated via Pearson's X2 (S-X2) implemented in R package mirt, as per Orlando and Thissen <ref type="bibr" target="#b38">[39]</ref>.</p><p>For the categorical approach, we used Latent Class Analysis (LCA), which classifies subpopulations where population membership is inferred from the data. LCA has some similarities with the prima prattica of AP research, where subjects are classified in homogeneous groups. However, LCA does not demand a predefined cut-off or a gold-standard measure as reference. For example, in traditional AP research, participants are considered AP possessors if they achieve an arbitrarily defined score (e.g., AP possessors must score 6 points or higher on an isolated pitch test). While previous research provides theoretical justifications for the cut-off choices, there is no statistical justification for choosing one cut-off threshold over another. Contrastingly, in LCA, class membership is inferred from the data and from the underlying patterns of responses across items. In this study, different numbers of classes were considered and evaluated.</p><p>The factor (IRT) mixture model was estimated based on Muthe ´n <ref type="bibr" target="#b39">[40]</ref>, given that it is a generalization of the latent class model, where the assumption of conditional independence between the latent class indicators within a class is relaxed using a factor that influences the items within each class <ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref>. The factor represents individual variations in response probabilities within a class. Therefore, this model allows for heterogeneity within each class. As described in Mplus User's Guide (Example 7.27) <ref type="bibr" target="#b36">[37]</ref>, this model can be considered as an Item Response Theory (IRT) mixture model.</p><p>All three latent models were run twice, considering the two different rating criteria commonly used to define correct and incorrect answers. This choice was based on AP literature, as semitones errors can be considered incorrect <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref> or correct <ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b45">46]</ref> depending on how restrictively AP is defined. In our test, we adopted two criteria as follows: The collected data formed a portrait of the latent trait distribution among the participants and was used to evaluate and validate the proposed test, i.e., how well it would measure the latent trait. The model fit indices used to evaluate and compare IRT and LCA were Akaike Information Criteria (AIC), Bayesian Information Criteria (BIC), and Simple Size Adjusted Bayesian Information Criterion (SSABIC). The lower the AIC, BIC, and SSABIC, the better the models being compared. In our case, we compared continuous versus categorical models under the same approach.</p><p>Due to the non-independence of sampling (i.e., students nested in universities), IRT and LCA models were run using robust maximum likelihood which produces standard errors, and chi-square test of the model fit considered this multilevel structure of the data <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>. Lastly, a comparison between IRT and LCA models was conducted using BIC and AIC. Notably, given that there were three approaches to statistical modeling (i.e., IRT, LCA, and Hybrid modeling), comparisons were always made within the same criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Ordinary descriptive statistics with the proportions and counts under both criteria ratings (perfect and imperfect) are shown in Table <ref type="table" target="#tab_0">1</ref>. The summing of correct answers for both rating criteria are shown in Table <ref type="table" target="#tab_1">2</ref>. It can be observed that the criterion for the perfect approach reduces the probability of a correct answer.</p><p>The results for IRT with two parameters (discrimination and difficulty) and three parameters (discrimination, difficulty, and guessing) for both criteria ratings (perfect and imperfect) are provided in Table <ref type="table" target="#tab_2">3</ref>.</p><p>The perfect approach under IRT with two parameters revealed item discrimination as moderate, high, and very high. The most discriminating item was item g (G6 on violin; 1.929) and the most difficult item was item i (G#1 on tuba; 2.419). The imperfect approach with two parameters showed item discrimination as low, moderate, and high. Item f displayed the highest item discrimination (C5 on piano; 1.697) and item i (G#1 on tuba; 0.926), identical to the perfect approach, showed the highest item difficulty.</p><p>For IRT with three parameters, results for the perfect approach showed item discriminations with high and very high values. The most discriminative item was item b (A5 on violin; 5.289) and the most difficult item, as in the IRT with two parameters, was item i (G#1 on tuba; 1.974). The guessing parameter demonstrated that item b had a high probability of being answered correctly (25.9%), even among those with very low ability to identify isolated pitches under the perfect approach. The imperfect approach with three parameters indicated item discrimination as moderate, high, and very high. Item g (G6 on violin; 8.414) demonstrated the highest discrimination parameter and item i (G#1 on tuba; 1.261) showed the highest item difficulty parameter. Under the imperfect approach, the probabilities of guessing increased across all the items. Item h indicated the highest guessing probability (36.3%), followed by item b (30.9%). Importantly, the standard errors (SE) were larger than under IRT with three parameters regardless of the adopted rating criterion, as commonly described in the literature <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref>. Table <ref type="table" target="#tab_3">4</ref> shows the item-level fit. Under IRT with two parameters, the imperfect rating indicated that all items had a good fit (S-X 2 p &gt; 0.05). However, under the perfect approach, two out of the ten items (items c and d) were statistically significant. Under IRT with three parameters, the majority of the items displayed a reduction in p-values when compared to two parameters, for both approaches.</p><p>A reason for the imperfect approach under two parameters having a better item level fit may be due to the increase in the probabilities of answering the items correctly (i.e., proportion and counts were higher since it was a less strict criterion). For items c and d-scored with the criterion of perfect rating-misfit is illustrated by comparisons of predicted and observed proportion of correct results (Figs <ref type="figure" target="#fig_2">2</ref> and<ref type="figure" target="#fig_3">3</ref>). In particular, higher than expected proportion of correct answers are seen for theta scores a little higher than 1 and for theta scores a little lower than -1</p><p>Table <ref type="table" target="#tab_4">5</ref> depicts the model fit for IRT models (two and three items parameters) for the perfect and imperfect ratings. Considering the perfect approach, the lowest BIC was in favor of an IRT model with two parameters. However, for the imperfect approach, the lowest BIC was in favor of an IRT model with three parameters. Notably, for perfect scoring, evaluations of item fit showed significant misfits for items c and d. This suggests that these two items are problematic as indicators of the latent trait. Moreover, for the imperfect approach, the standard errors of the discrimination parameters were high. Therefore, for both perfect and imperfect models, we concluded that the two-parameter model fits better than three-parameter model.  LCA results indicate the best solution for the two classes for both perfect and imperfect approaches, as illustrated in Table <ref type="table" target="#tab_5">6</ref>.</p><p>The best class solution was two classes, given the strongest decline in the AIC and BIC values. There was still a reduction from the two to three-classes solution in BIC and AIC values, which was expected. However, such information gain is insufficient for the justification of an additional extracted class when compared to the information gain (i.e., the reduction of BIC and AIC) from one to two classes. Figs <ref type="figure" target="#fig_4">4</ref> and<ref type="figure">5</ref> show the LCA results for perfect and imperfect LCA results.</p><p>The figures illustrate that one group had higher a probability of correctly identifying the pitches (depicted by the red line, representing 16.3% of the sample for perfect approach and 20.9% of the sample for imperfect approach). Contrarily, the other group had a lower probability of correctly identifying the stimuli (blue line, 83.7% for perfect approach and 79.1% for imperfect approach). Notably, even the red group did not achieve a value of 1 for any of the items, which would indicate a 100% probability of answering correctly for a giving stimulus. Moreover, the prevalence of the group with the highest probabilities of correctly identifying the pitches was lower than the group with lowest probabilities of correctly identifying the pitches.   Based on the results from the continuous and categorical options, the hybrid model was conducted by merging the features of the best solutions obtained from both modeling approaches, the two classes solution, and a unidimensional solution.</p><p>The hybrid model fit information is given in Table <ref type="table" target="#tab_6">7</ref>.</p><p>Based on model fit information, we conclude that the continuous solution was the best solution for the perfect approach, with lower BIC than the categorical and hybrid solutions. This indicates that the ability to recognize isolated pitches in different timbres and registers without reference is better modeled as a continuous ability, rather than when the perfect rating approach is considered with either a categorical or a hybrid model. Alternatively, the categorical solution demonstrated the best solution for the imperfect approach, with lower BIC than the continuous and hybrid solutions. This indicates that adopting flexibility in isolated pitch recognition without reference (with semitone deviations considered as correct) is better modeled as latent groups.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Our results demonstrate a good fit adjustment in measuring the ability to recognize isolated pitches without reference in a continuous solution of perfect rating criteria. When the imperfect approach is used as a rating criterion, a categorical solution is preferred. Moreover, in a two-parameter IRT model for the perfect scoring approach, all the items showed high values of discrimination. This indicates that our set of stimuli were appropriate for discriminating between subjects with high and low abilities to recognize isolated pitches. The items' difficulty values in both the perfect and imperfect approaches were high (with the exception of items e and h in the imperfect approach with two parameters). This was an expected result, as the identification of pitches without any reference is considered to be an exceedingly challenging task for most musicians. Notably, we could not formally compare the imperfect and perfect approaches regarding superiority, because they are not nested models <ref type="bibr" target="#b50">[51]</ref>.</p><p>When comparing LCA to IRT, our results indicated that the ability to recognize isolated pitches was better represented by a continuous model for the perfect approach. That is, through a continuous line where participants were arranged according to their degree of ability, as can be seen in (Fig <ref type="figure">6</ref>). This is a highly unexpected result, because a consensually adopted methodology in AP research is the division of subjects into two categories. Here, we labeled both groups as high-skilled and low-skilled.</p><p>Alternatively, the common division adopted by most AP research (dividing the population in two groups) is the best solution only when using the imperfect approach as a rating criterion. Crucially, our results demonstrate how the two rating approaches commonly used in AP literature (perfect and imperfect) might influence the decision of the best model underlying isolated pitch recognition ability.</p><p>In theory, it was expected that both the perfect and imperfect approaches would be better represented by a categorical model, because this is a status quo in the field of AP. However, the perfect approach showed the continuous model as the best solution. This was greatly unexpected, as the perfect approach uses more restrictive criteria than the imperfect approach does. According to the literature, AP possessors make many semitone errors. We thus hypothesize that these restrictions allow us to capture more fine grain variations of IWRPV skills across the participants sampling. Using the perfect scoring approach, 1.1% of participants had all items correct. According to the IRT model, these participants would be expected to have greater skills in isolated pitch recognition tasks than participants with lower numbers of correct responses. In contrast, for the imperfect scoring approach, the LCA model assumes that 20.9% of participants have high skills in isolated pitch recognition tasks. Within this group further differentiation in skills cannot be made. The 4.9% who had all 10 responses correct using the imperfect scoring approach were just luckier than the remaining 16% in the high-skill group. More research is necessary to examine the causes for the differences in the underlying models.</p><p>It is especially important to understand that a high ability to identify pitches without reference (as a latent group) is not necessarily synonymous with being an AP possessor. Furthermore, a low skill is not necessarily synonymous with not being an AP possessor. This is because we cannot deduce that a high performance in isolated pitch recognition is due to the presence of AP ability, since well-trained musicians that are non-AP possessors can also possibly have a high performance. This kind of test is not capable of assessing whether a participant is automatically associating a pitch to a verbal label.</p><p>In many areas, it is common procedure to choose a cut-off threshold to categorize subjects into a certain group, even when the original measure is continuous. Results from LCA may be exported from Mplus (or other statistical packages dealing with mixture modeling). This generates a most likely class membership and each subject would have a conditional probability for each group. That is, the probability of being classified as likely to correctly answer and the probability of being classified as less likely to correctly answer. Interestingly, we observed that none of the individual stimuli were answered correctly 100% of the time, even among the group classified as showing a high probability of choosing the correct answer (less than 20% of the 783 participants). These incorrect rates among those classified as having higher probabilities of performing well in isolated pitch discrimination tasks corroborates previous research indicating that participants are fallible and can make a considerable number of mistakes. In terms of limitation, future studies may investigate more detailed elements of psychometrics as local dependency for each of the models (IRT and LCA), invariance testing per sex, time of studies, and played instruments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The latent approach elucidates the psychometrics features for the measurement of isolated pitch recognition ability in a large-scale evaluation, which can be adopted by future researchers. According to model fit information indices, the test measures the proposed latent trait of AIPWR ability very well, given that the stimuli varied according to difficulty and discriminatory levels. The perfect approach showed a better adjustment through a continuous line and the imperfect approach showed a better adjustment when dividing the population in two groups. It is important to note that the ten stimuli did not evaluate whether a participant made an automatic association between a certain pitch and a learned verbal label. Consequently, we could not conclude that a high score in our test indicates that the participant possesses AP or that a low score indicates that they do not. The only plausible conclusion is higher scores indicate more latent trait in the participant, while a lower score indicates less latent trait. These findings may contribute to a better theoretical understanding of AP ability, showing that different rating criteria in AP tests greatly influence test results and the measurement of AP ability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig 1 .</head><label>1</label><figDesc>Fig 1. Theoretical Model for isolated pitch recognition trait. Theoretical Model proposed for Latent Trait AIPWR: Ability to identify Isolated Pitch Without Reference. Items are 10 isolated pitches in various timbres and registers without reference (a-j). The arrows indicate the ability from latent trait to items. Figure adapted from Germano et al. [8]. https://doi.org/10.1371/journal.pone.0247473.g001</figDesc><graphic coords="5,200.01,78.01,288.00,384.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Perfect. only exact pitch responses were considered correct; all other responses were incorrect (e.g., aural stimulus = C, correct response = C); 2. Imperfect. exact pitch responses and semitone deviations were considered correct; all other responses were incorrect (e.g., aural stimulus = C, correct response = C, B, or C#/Db).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig 2 .</head><label>2</label><figDesc>Fig 2. Empirical plots (item c) for perfect model with 2 parameters. Confidence intervals for the probability of endorsement of item c, correctly given the amount of AIPWR, are represented in dashed red lines. The estimated item characteristic curve for item c is indicated in continuous blue lines. https://doi.org/10.1371/journal.pone.0247473.g002</figDesc><graphic coords="9,200.01,507.69,288.00,162.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig 3 .</head><label>3</label><figDesc>Fig 3. Empirical plots (item d) for perfect model with 2 parameters. Confidence intervals for the probability of endorsement of item d, correctly given the amount of AIPWR, are represented in dashed red lines. The estimated item characteristic curve for item d is indicated in continuous blue lines. https://doi.org/10.1371/journal.pone.0247473.g003</figDesc><graphic coords="10,200.01,78.01,288.00,162.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig 4 .</head><label>4</label><figDesc>Fig 4. Isolated pitch perfect approach-latent class analysis for two classes. Class 1 (red line-16.3%) represents the population with greater ability to identify pitches in various registers and timbres, without reference. Class 2 (blue line-83.7%) represents the population with less ability to identify pitches in various registers and timbres, without reference. The y-axis represents the probability of a correct answer and the x-axis represents each item tested. Figure adapted from Germano et al. [8]. https://doi.org/10.1371/journal.pone.0247473.g004</figDesc><graphic coords="11,111.57,424.35,464.37,230.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig 6 Fig 5 .</head><label>65</label><figDesc>Fig 5. Isolated pitch imperfect approach-latent class analysis for two classes. Class 1 (red line-20.9%) represents the population with greater ability to identify pitches with semitone deviations in various registers and timbres without reference. Class 2 (blue line-79.1%) represents the population with less ability to identify pitches with semitone deviations in variated registers and timbres without reference. The y-axis represents the probability of a correct answer and the x-axis represents each item tested. https://doi.org/10.1371/journal.pone.0247473.g005</figDesc><graphic coords="12,114.24,78.01,461.71,233.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>approach (Fig 6) displays a half-normal distribution, while the imperfect approach (Fig 7) displays a log-Cauchy like distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig 6 .Fig 7 .</head><label>67</label><figDesc>Fig 6. Isolated pitch perfect approach-histograms (sample values, estimated factor scores, estimated values, residuals). Perfect approach ability. AIPWR: Ability to identify Isolated Pitch Without Reference. The y-axis represents the number of individuals. The x-axis represents the ability divided into 20 columns. https://doi.org/10.1371/journal.pone.0247473.g006</figDesc><graphic coords="13,137.76,78.01,438.24,184.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 . Frequency distribution.</head><label>1</label><figDesc>This table provides the percentage of correct answers for perfect and imperfect approaches for each item. https://doi.org/10.1371/journal.pone.0247473.t001</figDesc><table><row><cell></cell><cell>Perfect (%)</cell><cell>Imperfect (%)</cell></row><row><cell>Item a</cell><cell>6.9</cell><cell>40.5</cell></row><row><cell>Item b</cell><cell>39.2</cell><cell>46.4</cell></row><row><cell>Item c</cell><cell>11.4</cell><cell>31.2</cell></row><row><cell>Item d</cell><cell>28.2</cell><cell>34.0</cell></row><row><cell>Item e</cell><cell>43.4</cell><cell>53.1</cell></row><row><cell>Item f</cell><cell>42.1</cell><cell>47.6</cell></row><row><cell>Item g</cell><cell>27.6</cell><cell>37.0</cell></row><row><cell>Item h</cell><cell>29.1</cell><cell>49.4</cell></row><row><cell>Item i</cell><cell>7.7</cell><cell>34.4</cell></row><row><cell>Item j</cell><cell>9.6</cell><cell>47.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 . Frequency distribution of a simple correct answers sum.</head><label>2</label><figDesc></figDesc><table><row><cell>Sum of correct answers</cell><cell>Perfect (%)</cell><cell>Imperfect (%)</cell></row><row><cell>0</cell><cell>16.9</cell><cell>2.9</cell></row><row><cell>1</cell><cell>26.2</cell><cell>9.6</cell></row><row><cell>2</cell><cell>19.3</cell><cell>18.9</cell></row><row><cell>3</cell><cell>13.5</cell><cell>15.5</cell></row><row><cell>4</cell><cell>8.3</cell><cell>15.8</cell></row><row><cell>5</cell><cell>3.4</cell><cell>10.9</cell></row><row><cell>6</cell><cell>5.0</cell><cell>6.3</cell></row><row><cell>7</cell><cell>3.1</cell><cell>4.7</cell></row><row><cell>8</cell><cell>2.2</cell><cell>5.4</cell></row><row><cell>9</cell><cell>1.0</cell><cell>5.2</cell></row><row><cell>10</cell><cell>1.1</cell><cell>4.9</cell></row></table><note><p>This table provides the simple correct answers sum for each item for perfect and imperfect approaches. https://doi.org/10.1371/journal.pone.0247473.t002</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 . Item response theory results: Two and three parameters for perfect and imperfect approaches. IRT-2 Parameters IRT-3 Parameters</head><label>3</label><figDesc></figDesc><table><row><cell>Perfect</cell><cell></cell><cell>Discrimination</cell><cell>SE</cell><cell>Difficulty</cell><cell>SE</cell><cell>Discrimination</cell><cell>SE</cell><cell>Difficulty</cell><cell>SE</cell><cell>Guessing</cell><cell>SE</cell></row><row><cell></cell><cell>Item a</cell><cell>1.927</cell><cell>0.197</cell><cell>2.05</cell><cell>0.267</cell><cell>2.942</cell><cell>0.555</cell><cell>1.886</cell><cell>0.237</cell><cell>0.018</cell><cell>0.008</cell></row><row><cell></cell><cell>Item b</cell><cell>1.209</cell><cell>0.202</cell><cell>0.448</cell><cell>0.243</cell><cell>5.289</cell><cell>1.688</cell><cell>0.976</cell><cell>0.213</cell><cell>0.259</cell><cell>0.030</cell></row><row><cell></cell><cell>Item c</cell><cell>1.391</cell><cell>0.295</cell><cell>1.937</cell><cell>0.434</cell><cell>3.484</cell><cell>0.482</cell><cell>1.664</cell><cell>0.240</cell><cell>0.048</cell><cell>0.008</cell></row><row><cell></cell><cell>Item d</cell><cell>1.25</cell><cell>0.140</cell><cell>0.949</cell><cell>0.227</cell><cell>2.416</cell><cell>0.877</cell><cell>1.154</cell><cell>0.174</cell><cell>0.129</cell><cell>0.036</cell></row><row><cell></cell><cell>Item e</cell><cell>1.129</cell><cell>0.164</cell><cell>0.277</cell><cell>0.190</cell><cell>1.490</cell><cell>0.371</cell><cell>0.547</cell><cell>0.348</cell><cell>0.117</cell><cell>0.102</cell></row><row><cell></cell><cell>Item f</cell><cell>1.85</cell><cell>0.138</cell><cell>0.24</cell><cell>0.128</cell><cell>2.521</cell><cell>0.340</cell><cell>0.350</cell><cell>0.119</cell><cell>0.058</cell><cell>0.026</cell></row><row><cell></cell><cell>Item g</cell><cell>1.929</cell><cell>0.391</cell><cell>0.767</cell><cell>0.205</cell><cell>2.999</cell><cell>0.640</cell><cell>0.889</cell><cell>0.179</cell><cell>0.070</cell><cell>0.028</cell></row><row><cell></cell><cell>Item h</cell><cell>1.83</cell><cell>0.233</cell><cell>0.724</cell><cell>0.120</cell><cell>2.615</cell><cell>1.012</cell><cell>0.828</cell><cell>0.167</cell><cell>0.061</cell><cell>0.039</cell></row><row><cell></cell><cell>Item i</cell><cell>1.303</cell><cell>0.239</cell><cell>2.419</cell><cell>0.261</cell><cell>3.021</cell><cell>0.489</cell><cell>1.974</cell><cell>0.096</cell><cell>0.034</cell><cell>0.010</cell></row><row><cell></cell><cell>Item j</cell><cell>1.356</cell><cell>0.149</cell><cell>2.141</cell><cell>0.249</cell><cell>3.509</cell><cell>0.830</cell><cell>1.812</cell><cell>0.143</cell><cell>0.046</cell><cell>0.009</cell></row><row><cell>Imperfect</cell><cell>Item a</cell><cell>1.272</cell><cell>0.201</cell><cell>0.37</cell><cell>0.166</cell><cell>1.913</cell><cell>0.296</cell><cell>0.587</cell><cell>0.139</cell><cell>0.115</cell><cell>0.031</cell></row><row><cell></cell><cell>Item b</cell><cell>1.189</cell><cell>0.219</cell><cell>0.131</cell><cell>0.212</cell><cell>3.669</cell><cell>1.308</cell><cell>0.836</cell><cell>0.258</cell><cell>0.309</cell><cell>0.062</cell></row><row><cell></cell><cell>Item c</cell><cell>1.385</cell><cell>0.221</cell><cell>0.749</cell><cell>0.240</cell><cell>3.219</cell><cell>0.980</cell><cell>1.002</cell><cell>0.230</cell><cell>0.154</cell><cell>0.032</cell></row><row><cell></cell><cell>Item d</cell><cell>1.293</cell><cell>0.135</cell><cell>0.652</cell><cell>0.203</cell><cell>2.421</cell><cell>0.719</cell><cell>0.897</cell><cell>0.167</cell><cell>0.142</cell><cell>0.039</cell></row><row><cell></cell><cell>Item e</cell><cell>1.101</cell><cell>0.209</cell><cell>-0.164</cell><cell>0.199</cell><cell>2.469</cell><cell>0.866</cell><cell>0.513</cell><cell>0.413</cell><cell>0.295</cell><cell>0.118</cell></row><row><cell></cell><cell>Item f</cell><cell>1.697</cell><cell>0.244</cell><cell>0.045</cell><cell>0.145</cell><cell>3.612</cell><cell>2.368</cell><cell>0.458</cell><cell>0.235</cell><cell>0.210</cell><cell>0.118</cell></row><row><cell></cell><cell>Item g</cell><cell>1.458</cell><cell>0.212</cell><cell>0.474</cell><cell>0.179</cell><cell>8.414</cell><cell>5.810</cell><cell>0.865</cell><cell>0.168</cell><cell>0.218</cell><cell>0.028</cell></row><row><cell></cell><cell>Item h</cell><cell>1.209</cell><cell>0.193</cell><cell>-0.001</cell><cell>0.186</cell><cell>8.401</cell><cell>5.824</cell><cell>0.832</cell><cell>0.144</cell><cell>0.363</cell><cell>0.038</cell></row><row><cell></cell><cell>Item i</cell><cell>0.781</cell><cell>0.160</cell><cell>0.926</cell><cell>0.262</cell><cell>1.990</cell><cell>0.439</cell><cell>1.261</cell><cell>0.232</cell><cell>0.210</cell><cell>0.023</cell></row><row><cell></cell><cell>Item j</cell><cell>0.614</cell><cell>0.177</cell><cell>0.203</cell><cell>0.107</cell><cell>1.137</cell><cell>0.332</cell><cell>0.911</cell><cell>0.377</cell><cell>0.240</cell><cell>0.089</cell></row></table><note><p>This table provides the Item Response Theory results for each item for two and three parameters, in both the perfect and imperfect approaches. Item Response for two parameters shows discrimination and difficulty results. Item response for three parameters shows discrimination, difficulty, and guessing results. SE = Standard Error. https://doi.org/10.1371/journal.pone.0247473.t003</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 . Item level fit for perfect and imperfect ratings.</head><label>4</label><figDesc></figDesc><table><row><cell>2 Parameters</cell><cell>3 Parameters</cell></row></table><note><p>This table provides the item-level fit values for each item for two and three parameters, in both perfect and imperfect approaches. S-X2 is an item fit index for dichotomous item response theory models. df(S-X2) is the degree of freedom for item fit index for dichotomous item response theory models. RMSEA = (Root Mean Square Error of Approximation). https://doi.org/10.1371/journal.pone.0247473.t004</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 . Model fit information for IRT models-perfect and imperfect, two and three parameters.</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Number of</cell><cell>Free</cell><cell>Loglikelihood Correction</cell><cell>Loglikelihood (HO</cell><cell>Akaike</cell><cell>Bayesian</cell><cell>SSA</cell></row><row><cell></cell><cell></cell><cell>Classes</cell><cell>Parameters</cell><cell>Factor for MLR</cell><cell>value)</cell><cell>(AIC)</cell><cell>(BIC)</cell><cell>(BIC)</cell></row><row><cell>Perfect Continuous</cell><cell>2</cell><cell>--</cell><cell>20</cell><cell>1.6634</cell><cell>-3474.444</cell><cell>6988.887</cell><cell>7082.150</cell><cell>7018.640</cell></row><row><cell></cell><cell>Par.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>3</cell><cell>--</cell><cell>30</cell><cell>1.3837</cell><cell>-3449.099</cell><cell>6958.198</cell><cell>7098.092</cell><cell>7002.827</cell></row><row><cell></cell><cell>Par.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Imperfect</cell><cell>2</cell><cell>--</cell><cell>20</cell><cell>2.1810</cell><cell>-4816.900</cell><cell>9673.801</cell><cell>9767.064</cell><cell>9703.554</cell></row><row><cell></cell><cell>Par.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>3</cell><cell>--</cell><cell>30</cell><cell>1.6942</cell><cell>-4766.699</cell><cell>9593.398</cell><cell>9733.291</cell><cell>9638.026</cell></row><row><cell></cell><cell>Par.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>This table provides the model fit information for two and three parameters, in both perfect and imperfect approaches. MLR (Maximum Likelihood Robust). AIC (Consistent Akaike's Information Criterion). BIC (Bayesian Information Criterion). SSA (BIC) (Simple Size Adjusted Bayesian Information Criterion). https://doi.org/10.1371/journal.pone.0247473.t005</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 . Latent class analysis results for perfect and imperfect approaches.</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell>Number</cell><cell>Free</cell><cell>Loglikelihood</cell><cell>Loglikelihood</cell><cell>Akaike</cell><cell>Bayesian</cell><cell>SSA</cell><cell>VLMR</cell><cell>LMR LR</cell><cell>Entropy</cell></row><row><cell></cell><cell>of Classes</cell><cell>Parameters</cell><cell>Correction Factor</cell><cell>(HO value)</cell><cell>(AIC)</cell><cell>(BIC)</cell><cell>(BIC)</cell><cell>LRT (p-</cell><cell>adjusted</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>for MLR</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>value)</cell><cell>test</cell><cell></cell></row><row><cell>Perfect Categorical</cell><cell>1</cell><cell>10</cell><cell>4.2098</cell><cell>-3925.508</cell><cell>7871.016</cell><cell>7917.648</cell><cell>7885.893</cell><cell>---</cell><cell>---</cell><cell>---</cell></row><row><cell></cell><cell>2</cell><cell>21</cell><cell>1.8203</cell><cell>-3482.636</cell><cell>7007.273</cell><cell>7105.199</cell><cell>7038.513</cell><cell>0.0212</cell><cell>0.0219</cell><cell>0.914</cell></row><row><cell></cell><cell>3</cell><cell>32</cell><cell>1.5176</cell><cell>-3444.222</cell><cell>6952.444</cell><cell>7101.664</cell><cell>7000.048</cell><cell>0.5114</cell><cell>0.5130</cell><cell>0.656</cell></row><row><cell></cell><cell>4</cell><cell>43</cell><cell>1.4185</cell><cell>-3423.966</cell><cell>6933.931</cell><cell>7134.446</cell><cell>6997.899</cell><cell>0.5677</cell><cell>0.5684</cell><cell>0.678</cell></row><row><cell></cell><cell>5</cell><cell>54</cell><cell>1.2412</cell><cell>-3407.555</cell><cell>6923.11</cell><cell>7174.919</cell><cell>7003.442</cell><cell>0.4955</cell><cell>0.4960</cell><cell>0.675</cell></row><row><cell></cell><cell>6</cell><cell>65</cell><cell>1.1888</cell><cell>-3392.677</cell><cell>6915.335</cell><cell>7218.438</cell><cell>7012.031</cell><cell>0.4577</cell><cell>0.4581</cell><cell>0.718</cell></row><row><cell></cell><cell>7</cell><cell>76</cell><cell>1.2128</cell><cell>-3384.837</cell><cell>6921.745</cell><cell>7276.143</cell><cell>7034.805</cell><cell>0.6390</cell><cell>0.6393</cell><cell>0.732</cell></row><row><cell>Imperfect</cell><cell>1</cell><cell>10</cell><cell>4.6859</cell><cell>-5243.614</cell><cell cols="4">10507.229 10553.86 10522.105 ---</cell><cell>---</cell><cell>---</cell></row><row><cell></cell><cell>2</cell><cell>21</cell><cell>2.0328</cell><cell>-4784.795</cell><cell>9611.589</cell><cell>9709.515</cell><cell>9642.829</cell><cell>0.0160</cell><cell>0.0165</cell><cell>0.893</cell></row><row><cell></cell><cell>3</cell><cell>32</cell><cell>1.6635</cell><cell>-4755.888</cell><cell>9575.775</cell><cell>9724.995</cell><cell>9623.379</cell><cell>0.5189</cell><cell>0.5200</cell><cell>0.688</cell></row><row><cell></cell><cell>4</cell><cell>43</cell><cell>1.6857</cell><cell>-4736.214</cell><cell>9558.428</cell><cell>9758.943</cell><cell>9622.396</cell><cell>0.7612</cell><cell>0.7614</cell><cell>0.768</cell></row><row><cell></cell><cell>5</cell><cell>54</cell><cell>1.4823</cell><cell>-4716.346</cell><cell>9540.692</cell><cell>9792.501</cell><cell>9621.024</cell><cell>0.4518</cell><cell>0.4523</cell><cell>0.797</cell></row><row><cell></cell><cell>6</cell><cell>65</cell><cell>1.4254</cell><cell>-4708.111</cell><cell>9546.223</cell><cell>9849.326</cell><cell>9642.919</cell><cell>0.6568</cell><cell>0.6576</cell><cell>0.651</cell></row><row><cell></cell><cell>7</cell><cell>76</cell><cell>1.3179</cell><cell>-4697.236</cell><cell>9546.471</cell><cell>9900.869</cell><cell>9659.531</cell><cell>0.4955</cell><cell>0.4951</cell><cell>0.709</cell></row><row><cell></cell><cell>8</cell><cell>87</cell><cell>1.2404</cell><cell>-4690.011</cell><cell>9554.022</cell><cell>9959.714</cell><cell>9683.445</cell><cell>0.5387</cell><cell>0.5393</cell><cell>0.742</cell></row><row><cell></cell><cell>9</cell><cell>98</cell><cell>1.2126</cell><cell>-4685.470</cell><cell>9566.94</cell><cell cols="2">10023.927 9712.728</cell><cell>0.5037</cell><cell>0.5038</cell><cell>0.685</cell></row></table><note><p>This table provides the Latent Class Analysis for both perfect (7 classes) and imperfect (9 classes) approaches. MLR (Maximum Likelihood Robust). AIC (Consistent Akaike's Information Criterion). BIC (Bayesian Information Criterion). SSA (BIC) (Simple Size Adjusted Bayesian Information Criterion). VLMR LRT (Vuong-LO-Mendell-Rubin Likelihood Ratio Test). LMR (Likelihood Mendell Rubin). https://doi.org/10.1371/journal.pone.0247473.t006</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 . Hybrid model for perfect and imperfect ratings.</head><label>7</label><figDesc>This table provides the hybrid model for perfect and imperfect ratings with two latent classes and a unidimensional underlying latent factor. MLR (Maximum Likelihood Robust). AIC (Consistent Akaike's Information Criterion). BIC (Bayesian Information Criterion). SSA (BIC) (Simple Size Adjusted Bayesian Information Criterion).</figDesc><table><row><cell></cell><cell>Number of</cell><cell>Free</cell><cell>Loglikelihood Correction Factor</cell><cell>Loglikelihood (HO</cell><cell>Akaike</cell><cell>Bayesian</cell><cell>SSA</cell><cell>Entropy</cell></row><row><cell></cell><cell>Classes</cell><cell>Parameters</cell><cell>for MLR</cell><cell>value)</cell><cell>(AIC)</cell><cell>(BIC)</cell><cell>(BIC)</cell><cell></cell></row><row><cell>Perfect Hybrid</cell><cell>2</cell><cell>43</cell><cell>1.2784</cell><cell>-3418.603</cell><cell>6923.206</cell><cell>7123.721</cell><cell>6987.174</cell><cell>0.876</cell></row><row><cell>Imperfect</cell><cell>2</cell><cell>43</cell><cell>2.8625</cell><cell>-4736.865</cell><cell>9559.731</cell><cell>9760.245</cell><cell>9623.699</cell><cell>0.759</cell></row><row><cell cols="3">https://doi.org/10.1371/journal.pone.0247473.t007</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>PLOS ONE | https://doi.org/10.1371/journal.pone.0247473February 22, 2021  </p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank all students who volunteered in this research, as well as the professors and universities for allowing the conducting of this test.</p></div>
			</div>


			<div type="funding">
<div><p>Germano, N: <rs type="grantNumber">FAPESP 2016/08377-4</rs> (<rs type="funder">Fundac ¸ão de Amparo à Pesquisa do Estado de São Paulo)</rs> provided funding for the research and publication of this article. <rs type="person">Cogo-Moreira</rs>, H: <rs type="funder">CAPES</rs> (<rs type="grantName">Thesis award</rs>) Grant no. <rs type="grantNumber">0374/2016</rs>, process no. <rs type="grantNumber">23038.009191/2013-76</rs>) and <rs type="programName">CAPES-Alexander von Humboldt senior research fellowship</rs> (Grant <rs type="grantNumber">88881.145593/2017-01</rs>). Bortz, G: <rs type="grantNumber">FAPESP 2019/ 02133-4</rs> (<rs type="funder">Fundac ¸ão de Amparo à Pesquisa do Estado de São Paulo)</rs> provided funding for the publication of this article.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fDadXSE">
					<idno type="grant-number">FAPESP 2016/08377-4</idno>
				</org>
				<org type="funding" xml:id="_28MrDEt">
					<idno type="grant-number">0374/2016</idno>
					<orgName type="grant-name">Thesis award</orgName>
				</org>
				<org type="funding" xml:id="_BTr3mxx">
					<idno type="grant-number">23038.009191/2013-76</idno>
					<orgName type="program" subtype="full">CAPES-Alexander von Humboldt senior research fellowship</orgName>
				</org>
				<org type="funding" xml:id="_ebe3wew">
					<idno type="grant-number">88881.145593/2017-01</idno>
				</org>
				<org type="funding" xml:id="_yU6cSDr">
					<idno type="grant-number">FAPESP 2019/ 02133-4</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>All relevant data are within the paper and its Supporting Information files.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Investigation: Nayana Di Giuseppe Germano, Hugo Cogo-Moreira, Graziela Bortz.</p><p>Methodology: Nayana Di Giuseppe Germano, Hugo Cogo-Moreira, Graziela Bortz.</p><p>Supervision: Hugo Cogo-Moreira, Graziela Bortz.</p><p>Validation: Nayana Di Giuseppe Germano, Hugo Cogo-Moreira.</p><p>Visualization: Nayana Di Giuseppe Germano.</p><p>Writing -original draft: Nayana Di Giuseppe Germano, Hugo Cogo-Moreira, Graziela Bortz.</p><p>Writing -review &amp; editing: Nayana Di Giuseppe Germano, Hugo Cogo-Moreira, Fausto Coutinho-Lourenc ¸o, Graziela Bortz.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">C</forename><surname>Stumpf</surname></persName>
		</author>
		<author>
			<persName><surname>Tonpsychologie</surname></persName>
		</author>
		<author>
			<persName><surname>Hirzel</surname></persName>
		</author>
		<idno>1883. I. 1890</idno>
		<imprint>
			<biblScope unit="volume">206</biblScope>
			<biblScope unit="page" from="365" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Mozart: A documentary biography</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">E</forename><surname>Deutsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966">1966</date>
			<publisher>Stanford University Press</publisher>
			<pubPlace>Stanford: CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The puzzle of absolute pitch. Current Directions in Psychological Science</title>
		<author>
			<persName><forename type="first">D</forename><surname>Deutsch</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-8721.00200</idno>
		<ptr target="https://journals.sagepub.com/doi/abs/10.1111/1467-8721.00200" />
		<imprint>
			<date type="published" when="2002-12">2002 Dec</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="200" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Em busca de uma definic ¸ão para o Feno ˆmeno do Ouvido Absoluto. Master&apos;s Dissertation: Instituto de Artes da UNESP</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Germano</surname></persName>
		</author>
		<ptr target="https://repositorio.unesp.br/handle/11449/128062" />
		<imprint>
			<date type="published" when="2015">2015</date>
			<pubPlace>São Paulo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Ouvido Absoluto e Ouvido Relativo: Um Estudo Psicome ´trico dos Trac ¸os Latentes. PhD Dissertation: Instituto de Artes da UNESP</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Germano</surname></persName>
		</author>
		<ptr target="https://repositorio.unesp.br/handle/11449/157223" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>São Paulo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The acquisition of absolute pitch. The American Journal of Psychology</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Mull</surname></persName>
		</author>
		<ptr target="https://www.jstor.org/stable/1413906" />
		<imprint>
			<date type="published" when="1925-10-01">1925 Oct 1</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="469" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A critical review of the literature on absolute pitch</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Neu</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0054212</idno>
		<idno type="PMID">20240004</idno>
		<ptr target="https://insights.ovid.com/psychological-bulletin/plbul/1947/05/000/critical-review-literature-absolute-pitch/2/00006823https://doi.org/10.1037/h0054212" />
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">249</biblScope>
			<date type="published" when="1947">1947</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Psychometric features to assess absolute pitch: Looking for construct validity evidences regarding isolated pitch tasks in undergraduate Brazilian music students</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Germano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cogo-Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bortz</surname></persName>
		</author>
		<ptr target="https://static.uni-graz.at/fileadmin/veranstaltungen/music-psychologyconference2018/documents/ICMPC15_ESCOM10%20Proceedings.pdf" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Music Perception and Cognition</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="164" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Categorizac ¸ão de Ouvido Absoluto em Estudantes de Mu ´sica de Nı ´vel Universita ´rio nas cidades de São Paulo e Brası ´lia. Bachelor&apos;s Dissertation: Instituto de Artes da UNESP</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Germano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>São Paulo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Measurement of absolute pitch</title>
		<author>
			<persName><forename type="first">J</forename><surname>Baggaley</surname></persName>
		</author>
		<idno type="DOI">10.1177/030573567422002?journalCode=poma</idno>
		<ptr target="https://journals.sagepub.com/doi/abs/10.1177/030573567422002?journalCode=poma" />
	</analytic>
	<monogr>
		<title level="j">Psychology of music</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="11" to="17" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Absolute pitch. The new Grove dictionary of music and musicians</title>
		<author>
			<persName><forename type="first">R</forename><surname>Parncutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Levitin</surname></persName>
		</author>
		<ptr target="http://daniellevitin.com/levitinlab/articles/2001-Parncutt-NGDMM.pdf" />
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="37" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Absolute Pitch</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Ward</surname></persName>
		</author>
		<ptr target="http://www.sciencedirect.com/science/article/pii/B9780122135644500093" />
	</analytic>
	<monogr>
		<title level="m">Deutsch D, organization. The Psychology of Music. 2md ed</title>
		<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="265" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Functional anatomy of musical processing in listeners with absolute pitch and relative pitch</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Zatorre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Beckett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Westbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.95.6.3172</idno>
		<idno type="PMID">9501235</idno>
		<ptr target="https://www.pnas.org/content/95/6/3172.shorthttps://doi.org/10.1073/pnas.95.6.3172" />
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="3172" to="3177" />
		</imprint>
		<respStmt>
			<orgName>Proceedings of the National Academy of Sciences of the United States of America</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Effect of Pitch Height, Timbre and Octave Error on Absolute Pitch Accuracy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Iuşcă</surname></persName>
		</author>
		<ptr target="https://www.ceeol.com/search/article-detail?id=752337" />
	</analytic>
	<monogr>
		<title level="j">Educational Implications. Review of Artistic Education</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="353" to="358" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Studies in Psychology, Titchner commemorative volume</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Baird</surname></persName>
		</author>
		<ptr target="https://psycnet.apa.org/record/2006-05077-005" />
		<imprint>
			<date type="published" when="1917">1917</date>
			<biblScope unit="page" from="43" to="78" />
		</imprint>
	</monogr>
	<note>Memory for Absolute Pitch</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Absolute pitch: effects of timbre on note-naming ability</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vanzella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Schellenberg</surname></persName>
		</author>
		<idno type="DOI">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0015449</idno>
		<idno type="PMID">21085598</idno>
		<ptr target="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0015449" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The effects of timbre on absolute pitch judgment</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1177/0305735619893437</idno>
		<ptr target="https://journals.sagepub.com/doi/abs/10.1177/0305735619893437" />
	</analytic>
	<monogr>
		<title level="j">Psychology of Music</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The New Grove Dictionary of Music and Musicians</title>
		<author>
			<persName><forename type="first">N</forename><surname>Spender</surname></persName>
		</author>
		<idno type="DOI">10.1016/0022-3999%2880%2990012-4</idno>
		<idno type="PMID">7205711</idno>
		<ptr target="https://doi.org/10.1016/0022-3999(80)90012-4" />
	</analytic>
	<monogr>
		<title level="m">Sadie S, organization</title>
		<meeting><address><addrLine>6˚ed London</addrLine></address></meeting>
		<imprint>
			<publisher>MacMillan</publisher>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="27" to="29" />
		</imprint>
	</monogr>
	<note>Absolute pitch</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An experimental study of pitch recognition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Petran</surname></persName>
		</author>
		<ptr target="https://psycnet.apa.org/record/2011-21636-001" />
	</analytic>
	<monogr>
		<title level="m">):i. Available from</title>
		<imprint>
			<date type="published" when="1932">1932</date>
			<biblScope unit="volume">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The ability to judge pitch</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Riker</surname></persName>
		</author>
		<ptr target="https://psycnet.apa.org/record/1947-00051-001" />
	</analytic>
	<monogr>
		<title level="j">exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="331" to="346" />
			<date type="published" when="1946">1946</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Absolute pitch: an approach for identification of genetic and nongenetic components</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baharloo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Service</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gitschier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Freimer</surname></persName>
		</author>
		<idno type="DOI">10.1086/301704</idno>
		<idno type="PMID">9463312</idno>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S0002929707634867https://doi.org/10.1086/301704" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Human Genetics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="224" to="231" />
			<date type="published" when="1998-02-01">1998 Feb 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dichotomy and perceptual distortions in absolute pitch ability</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Athos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Levinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kistler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zemansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bostrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Freimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gitschier</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0703868104</idno>
		<idno type="PMID">17724340</idno>
		<ptr target="https://www.pnas.org/content/104/37/14795.shorthttps://doi.org/10.1073/pnas.0703868104" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">37</biblScope>
			<biblScope unit="page" from="14795" to="14800" />
			<date type="published" when="2007-09-11">2007 Sep 11</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Absolute pitch is associated with a large auditory digit span: A clue to its genesis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dooley</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.4792217</idno>
		<idno type="PMID">23556554</idno>
		<ptr target="https://doi.org/10.1121/1.4792217" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1859" to="1861" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Absolute Pitch-Functional evidence of speech-relevant auditory acuity</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Oechslin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ja</forename></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhp113</idno>
		<idno type="PMID">19592570</idno>
		<ptr target="https://academic.oup.com/cercor/article-abstract/20/2/447/310885https://doi.org/10.1093/cercor/bhp113" />
	</analytic>
	<monogr>
		<title level="j">Cerebral cortex</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="447" to="455" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Memory for melody: Infants use a relative pitch code</title>
		<author>
			<persName><forename type="first">J</forename><surname>Plantinga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Trainor</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2004.09.008</idno>
		<idno type="PMID">16297673</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2004.09.008" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2005-11-01">2005 Nov 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ethnicity effects in relative pitch</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Krumhansl</surname></persName>
		</author>
		<idno type="DOI">10.3758/PBR.17.3.310</idno>
		<idno type="PMID">20551351</idno>
		<ptr target="https://link.springer.com/article/10.3758/PBR.17.3.310" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="310" to="316" />
			<date type="published" when="2010-06-01">2010 Jun 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Perception of musical intervals by absolute pitch possessors. Music Perception</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Miyazaki</surname></persName>
		</author>
		<ptr target="https://mp.ucpress.edu/content/9/4/413.abstract" />
		<imprint>
			<date type="published" when="1992-07-01">1992 Jul 1</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="413" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Increased volume and function or right auditory cortex as a marker for absolute pitch</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wengenroth</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhs391</idno>
		<idno type="PMID">23302811</idno>
		<ptr target="https://academic.oup.com/cercor/article/24/5/1127/387865https://doi.org/10.1093/cercor/bhs391" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1127" to="1137" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Absolute pitch: perception, coding, and controversies</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Levitin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2004.11.007</idno>
		<idno type="PMID">15639438</idno>
		<ptr target="https://www.sciencedirect.com/science/article/abs/pii/S1364661304002943https://doi.org/10.1016/j.tics.2004.11.007" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="33" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Gray-and white-matter anatomy of absolute pitch possessors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Garza-Villarreal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Lerch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vuust</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bht334</idno>
		<idno type="PMID">24304583</idno>
		<ptr target="https://academic.oup.com/cercor/article-abstract/25/5/1379/313249https://doi.org/10.1093/cercor/bht334" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1379" to="1388" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Perceiving pitch absolutely: comparing absolute and relative pitch possessors in a pitch memory task</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schulze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gaab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schlaug</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2202-10-106</idno>
		<ptr target="https://link.springer.com/article/10.1186/1471-2202-10-106" />
	</analytic>
	<monogr>
		<title level="j">BMC Neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intracortical myelination in musicians with absolute pitch: quantitative morphometry using 7-T MRI</title>
		<author>
			<persName><forename type="first">S-G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Kno ¨sche Tr</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.23254</idno>
		<ptr target="https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.23254PMID" />
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">27160707</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Absolute pitch and the P300 component of the event-related potential: an exploration of variables that may account for individual differences</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Renninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Granot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Donchin</surname></persName>
		</author>
		<ptr target="https://online.ucpress.edu/mp/article-abstract/20/4/357/62150" />
	</analytic>
	<monogr>
		<title level="j">Music Perception</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="382" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Absolute pitch and planum temporale</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Keenan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Thangaraj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schlaug</surname></persName>
		</author>
		<idno type="DOI">10.1006/nimg.2001.0925</idno>
		<idno type="PMID">11707095</idno>
		<ptr target="https://www.sciencedirect.com/science/article/abs/pii/S1053811901909255https://doi.org/10.1006/nimg.2001.0925" />
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1402" to="1408" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthen</surname></persName>
		</author>
		<title level="m">Mplus version 8. Software Computer</title>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Confirmatory factor analysis and structural equation modeling. Mplus Statistical Analysis With Latent Variables User&apos;s Guide</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthen</surname></persName>
		</author>
		<ptr target="https://www.statmodel.com/download/usersguide/MplusUserGuideVer_8.pdf" />
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="55" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B</forename><surname>Baker</surname></persName>
		</author>
		<title level="m">The Basics of Item Response Theory</title>
		<meeting><address><addrLine>Washington: DC</addrLine></address></meeting>
		<imprint>
			<publisher>ERIC Publications</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Likelihood-based item-fit indices for dichotomous item response theory models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Thissen</surname></persName>
		</author>
		<idno type="DOI">10.3758/PBR.17.3.310</idno>
		<ptr target="https://link.springer.com/article/10.3758/PBR.17.3.310" />
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="64" />
			<date type="published" when="2000-03">2000 Mar</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Item response mixture modeling: Application to tobacco dependence criteria</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthe ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.addbeh.2006.03.026</idno>
		<idno type="PMID">16675147</idno>
		<ptr target="https://www.sciencedirect.com/science/article/abs/pii/S0306460306000967https://doi.org/10.1016/j.addbeh.2006.03.026" />
	</analytic>
	<monogr>
		<title level="j">Addictive behaviors</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1050" to="1066" />
			<date type="published" when="2006-06-01">2006 Jun 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Should substance use disorders be considered as categorical or dimensional?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthe ´n</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1360-0443.2006.01583.x</idno>
		<idno type="PMID">16930156</idno>
		<ptr target="https://doi.org/10.1111/j.1360-0443.2006.01583.x" />
	</analytic>
	<monogr>
		<title level="j">Addiction</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="6" to="16" />
			<date type="published" when="2006-09">2006 Sep</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Advances in behavioral genetics modeling using Mplus: Applications of factor mixture modeling to twin data. Twin research and human genetics</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthe ´n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rebollo</surname></persName>
		</author>
		<idno type="DOI">10.1375/183242706777591317</idno>
		<idno type="PMID">16790142</idno>
		<ptr target="https://doi.org/10.1375/183242706777591317" />
	</analytic>
	<monogr>
		<title level="m">A5CA482005AC90430A92D79059</title>
		<imprint>
			<date type="published" when="2006-06">2006 Jun</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="313" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The neurocognitive components of pitch processing: insights from absolute pitch</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lusher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dudgeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Reutens</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhn121</idno>
		<idno type="PMID">18663250</idno>
		<ptr target="https://academic.oup.com/cercor/article/19/3/724/437009https://doi.org/10.1093/cercor/bhn121" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="724" to="732" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A distribution of absolute pitch ability as revealed by computerized testing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bermudez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Zatorre</surname></persName>
		</author>
		<ptr target="https://online.ucpress.edu/mp/article-abstract/27/2/89/62439" />
	</analytic>
	<monogr>
		<title level="j">Music Perception</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="89" to="101" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Effects of musical training and absolute pitch on a pitch memory task: An event-related potential study</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Hantz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Kreilick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Braveman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Swartz</surname></persName>
		</author>
		<ptr target="https://psycnet.apa.org/record/1997-07268-004" />
	</analytic>
	<monogr>
		<title level="j">Psychomusicology: a journal of research in music cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Absolute pitch as an inability: identification of musical intervals in a tonal context. Music Perception</title>
		<author>
			<persName><forename type="first">K</forename><surname>Miyazaki</surname></persName>
		</author>
		<ptr target="https://online.ucpress.edu/mp/article-abstract/11/1/55/61827" />
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="55" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Sampling weights in latent variable modeling. Structural equation modeling</title>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15328007sem1203_4</idno>
		<ptr target="https://www.tandfonline.com/doi/abs/10.1207/s15328007sem1203_4" />
		<imprint>
			<date type="published" when="2005-07-01">2005 Jul 1</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="411" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">General multi-level modeling with sampling weights</title>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<idno type="DOI">10.1080/03610920500476598</idno>
		<ptr target="https://www.tandfonline.com/doi/abs/10.1080/03610920500476598" />
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics-Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="439" to="460" />
			<date type="published" when="2006-04-01">2006 Apr 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Standard errors of item response theory equating/linking by response function methods</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ogasawara</surname></persName>
		</author>
		<idno type="DOI">10.1177/01466216010251004</idno>
		<ptr target="https://doi.org/10.1177/01466216010251004" />
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="67" />
			<date type="published" when="2001-03">2001 Mar</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Some standard errors in item response theory</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wainer</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02293705</idno>
		<ptr target="https://doi.org/10.1007/BF02293705" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="397" to="412" />
			<date type="published" when="1982-12-01">1982 Dec 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Testing model nesting and equivalence</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0019625</idno>
		<idno type="PMID">20515234</idno>
		<ptr target="https://psycnet.apa.org/record/2010-10555-001https://doi.org/10.1037/a0019625" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">111</biblScope>
			<date type="published" when="2010-06">2010 Jun</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
