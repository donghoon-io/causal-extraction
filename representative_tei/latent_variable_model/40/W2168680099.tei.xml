<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Contextual Maximum Likelihood Framework for Modeling Image Registration</title>
				<funder>
					<orgName type="full">Humboldt foundation and European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Christian</forename><surname>Wachinger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technische Universität München</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science and Artificial Intelligence Lab</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nassir</forename><surname>Navab</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Aided Medical Procedures</orgName>
								<orgName type="institution">Technische Universität München</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Contextual Maximum Likelihood Framework for Modeling Image Registration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/CVPR.2012.6247902</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce a novel probabilistic framework for image registration. This framework considers, in contrast to previous ones, local neighborhood information. We integrate the neighborhood information into the framework by adding layers of latent random variables, characterizing the descriptive information of each image. This extension has multiple advantages. It allows for a unified description of geometric and iconic registration, with the consequential analysis of similarities. It enables to arrange registration techniques in a continuum, limited by pure intensityand feature-based registration. With this wide spectrum of techniques combined, we can model hybrid registration approaches. The probabilistic coupling allows further to deduce optimal descriptors and to model the adaptation of description layers during the process, as it is done for joint registration/segmentation. Finally, we deduce a new registration algorithm that allows for a dynamic adaptation of the description layers during the registration. Excellent results confirm the advantages of the new registration method, the major contribution of this article lies, however, in the theoretical analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Registration is a fundamental process in computer vision. A common classification is to distinguish between geometry-and intensity-based approaches. Geometric approaches establish the spatial relationship between images based on extracted features, landmarks, surfaces, or point clouds. Intensity-based or iconic approaches directly operate on the images by comparing their pixel intensities or photometric properties. For intensity-based registration, unifying probabilistic frameworks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">38]</ref> were proposed. These frameworks are essential in better understanding and categorizing different types of registration approaches. With a strict deduction from a mathematical framework, it is possible to detect implicitly incorporated assumptions. Discovering such assumptions allows for better adapting registration to specific applications and to justify the adequacy of an approach in a specific scenario. Concepts from probability theory, such as maximum likelihood or a posteriori estimation, were in this context shown to be very useful to reason about image registration. The limitation of currently existing probabilistic frameworks is, however, their focus on modeling the similarity measure.</p><p>Looking at registration in practice, we observe that processing steps such as gradient calculation, multi-scale analysis, and noise reduction are applied to the images, before performing the alignment. Further, the comparison of single pixel information is prone to noise, leading to the introduction of context and spatial information in registration. With the presented contextual, probabilistic framework we are able to model these approaches. Moreover, we can model geometric approaches through the introduction of layers of latent random variables. Dealing with these representations allows for differentiating between pure image processing steps, such as smoothing and gradient calculation, and the estimation of the similarity between images. This helps to classify registration techniques and identify commonalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Probabilistic Registration Framework</head><p>In order to describe image registration from a probabilistic point of view, we consider each image to be a random variable U . The probability of the appearance of a concrete sample image u is p(U = u), with the simplified notation p(u). Considering further that an image is defined on a grid Ω, each spatial location U (x) with x ∈ Ω is a random variable. Taking the set of intensity values I, e.g. I = {0, 1, . . . , 255}, the probability of a location having a certain intensity is p(U (x) = i) with i ∈ I. The goal of registration is to find the transformation T that expresses the spatial relationship between the two images u and v u(x) = v(T (x)).</p><p>(1) This is the underlying model of the generative, joint probability T = arg max</p><formula xml:id="formula_0">v u T v u T v u T u v T T v(x) u(x) Ω</formula><formula xml:id="formula_1">T ∈T p(u, v, T ),<label>(2)</label></formula><p>with T being the space of transformations and T the optimal transformation with respect to the model. The model in equation ( <ref type="formula">1</ref>) is commonly augmented with noise and an intensity mapping <ref type="bibr" target="#b19">[20]</ref>. Other noise distributions than the standard Gaussian can be used to adapt the registration to specific applications, such as speckle noise in ultrasound images <ref type="bibr" target="#b28">[29]</ref>. The intensity mapping accounts for multimodal registration and leads, e.g., to sum of squared differences (SSD), correlation ratio (CR), and mutual information (MI), by assuming an identical, functional, or statistical intensity relationship <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b19">20]</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">I.I.D. Coordinate Samples</head><p>A general assumption of the unifying approaches <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39]</ref> are independent and identically distributed (i.i.d.) coordinate samples. With this assumption, equation (2) simplifies tox</p><formula xml:id="formula_2">p(u, v, T ) = x∈Ω p(u(x), v(x), T ).<label>(3)</label></formula><p>This is illustrated in figure <ref type="figure" target="#fig_0">1</ref> for the probability p(v|u, T ), which is the likelihood term of the generative probability, obtained with Bayes' theorem <ref type="bibr" target="#b19">[20]</ref>. Since each of the spatial locations in the images corresponds to a random variable, we use the plate visualization <ref type="bibr" target="#b5">[6]</ref>, permitting a compact representation of the graph. The i.i.d. assumption splits the general problem of similarity estimation between images up into several subproblems of similarity estimation between pixels. This simplification is necessary for the deduction of similarity measures such as SSD, CR, and MI <ref type="bibr" target="#b19">[20]</ref>, but does not accurately model the real world. Objects in the image have a certain size, which is rather rarely limited to the extent of one pixel, so that the i.i.d. assumption is not justified.</p><p>Recent registration approaches show the increasing importance of explicitly integrating context information, such as shape context <ref type="bibr" target="#b4">[5]</ref>, local self-similarity <ref type="bibr" target="#b24">[25]</ref>, and contextual flow <ref type="bibr" target="#b32">[33]</ref>, into registration. Moreover, the addition of spatial information into the similarity estimation, as it is e.g. done with higher-order densities <ref type="bibr" target="#b21">[22]</ref>, neighborhood patches <ref type="bibr" target="#b22">[23]</ref>, conditional mutual information <ref type="bibr" target="#b12">[13]</ref>, local volume densities <ref type="bibr" target="#b36">[37]</ref>, Markov random fields <ref type="bibr" target="#b35">[36]</ref>, and spatial-context mutual information <ref type="bibr" target="#b34">[35]</ref>, leads to improvements. The i.i.d. assumption of current frameworks, however, prohibits their consideration.</p><formula xml:id="formula_3">N u(N i ) d i e i T v(N 0 i ) Figure 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Contextual Probabilistic Graphical Model</head><p>The key component of the novel probabilistic framework is to replace the assumptions of independence of coordinate samples in equation <ref type="bibr" target="#b2">(3)</ref>, by the Markov property. This leads to a dependency of a pixel position on a local pixel neighborhood. One could think of a variety of possibilities for modeling the local neighborhood in a maximum likelihood framework. We decided to introduce two additional layers d and e, because it facilitates the representation of the neighborhood dependency. Each of the layers, we refer to as description layers, consists of latent random variables d i and e i , respectively, with 1 ≤ i ≤ N and N = |Ω|. The layers d and e are lying on the same grid as the images do, so we have a dense set of descriptors. In our model, we let each descriptor d i be dependent on a local neighborhood N i of the image u(N i ), analogously, e i is dependent on v(N i ). The relationship between descriptors d i and e i is one-to-one. The creation of the layer e is dependent on the transformation T .</p><p>We utilize probabilistic graphical models <ref type="bibr" target="#b5">[6]</ref> for establishing the relationship between random variables because they are advantageous in representing the structure and dependency for a multitude of variables. Further, we choose a directed graphical model, where nodes represent random variables and directed edges express probabilistic dependency between them. The graphical model for our framework is shown in figure <ref type="figure">2</ref> as plate with an exemplary 4-and 3-neighborhood, for u and v, respectively. Another illustration, not as plate, is shown in figure <ref type="figure" target="#fig_1">3</ref>  graphical model factorizes to</p><formula xml:id="formula_4">p(u, v, d, e, T ) =p(T ) • N i=1 p(u(x i )) • p(v(T (x i ))) • p(d i |u(N i )) • p(e i |d i , v(N i ), T ). (4)</formula><p>We deduce the term p(e i |d i , v(N i ), T ) further by applying the product rule and Bayes' theorem. Moreover, we assume the conditional independence of d i and v(N i ) with respect to e i , and the independence of d i and v(N i )). Since the description layer e is separating the two layers d and v, the assumption is justified, leading to</p><formula xml:id="formula_5">p(e i |d i , v(N i ), T ) = p(d i |e i ) • p(v(N i ), T |e i ) • p(e i ) p(d i ) • p(v(N i ), T ) = p(e i |d i ) • p(e i |v(N i ), T ) p(e i ) .<label>(5)</label></formula><p>Setting this result in equation ( <ref type="formula">4</ref>) leads to</p><formula xml:id="formula_6">p(u, v, d, e, T ) =p(T ) • N i=1 p(u(x i )) • p(v(T (x i )))<label>(6)</label></formula><p>• p(</p><formula xml:id="formula_7">d i |u(N i )) • p(e i |d i ) • p(e i |v(N i ), T ) p(e i ) .</formula><p>Therein, the marginal terms p(T ), p(u(x i )), p(v(T (x i ))), and p(e i ) -1 represent the probabilities for the transformation, the images, and the description layer. The reason that only the descriptor layer e appears in the formulation is rooted in the asymmetric formulation of the registration by only transforming the image v. This can be changed with a symmetric formulation, by transforming both images, which is shown in the supplementary material for the general case of groupwise registration.</p><p>The marginal terms are used to incorporate prior information into the registration, with the purpose of improving the robustness and capture range <ref type="bibr" target="#b37">[38]</ref>. In most cases, we do not have any a priori knowledge about the probability distribution of these terms, so that we presume a uniform distribution, leading to</p><formula xml:id="formula_8">p(u, v, d, e, T ) = N i=1 p(e i |d i ) similarity • p(d i |u(N i )) • p(e i |v(N i ), T ) coupling . (7)</formula><p>It is mainly the interplay of these three probabilities that determines the functionality of our model. The similarity term p(e i |d i ) is the standard likelihood function as used in previous unifying frameworks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39]</ref>. However, instead of comparing the images u and v, it compares the description layers d and e. If we could arbitrarily modify the description layers and just optimize p(e|d), we would simply change the layers to be totally exact. The coupling terms p(d i |u(N i )) and p(e i |v(N i ), T ) prevent this simplistic solution by expressing how well the description layers fit the original images. In the optimization, they are counterbalancing the influence of the similarity term like a regularizer.</p><p>The joint distribution, p(u, v, e, d, T ), we finally end up with, is different from the one used in maximum likelihood (ML) frameworks, p(u, v, T ). This can, however, be obtained by marginalizing with respect to the descriptors</p><formula xml:id="formula_9">p(u, v, T ) = d,e p(u, v, d, e, T ).<label>(8)</label></formula><p>Practically, it is not possible to sum over all possible descriptors. Thus, the alignment is only optimal with respect to a specific descriptor or a small set of descriptors, which is discussed further in section 3.3 on hybrid approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A Continuum of Registration Approaches</head><p>In this section, we discuss several approaches for geometry-and intensity-based registration and show how they fit into the proposed framework. These methods form, in fact, a continuum of registration approaches, going all the way from pure geometric to pure iconic registration. On the one end, we identify landmark-based registration, where users manually pick salient points in the image. The description is optimal because we exactly know about the correspondence of points. On the other end, we identify intensity-based registration, with single intensity values as minimalistic descriptors. The number of approaches in between can be arranged by the uniqueness of their descriptors, as illustrates figure <ref type="figure" target="#fig_2">4</ref>.</p><p>On the right-hand side of the spectrum, we consider SIFT and GLOH with comparatively high uniqueness of the descriptors. SIFT/GLOH correspondence hypotheses are created without location information, therefore descriptors must uniquely characterize the position they are extracted from. For DAISY <ref type="bibr" target="#b25">[26]</ref>, the dense arrangement of descriptors relaxes this requirement, equally for selfsimilarity <ref type="bibr" target="#b24">[25]</ref>. Entropy images <ref type="bibr" target="#b30">[31]</ref> extract structural information of images for multi-modal registration and re-  semble gradient images. Scale-space images are close to the original ones, because locally weighted averages are created with an emphasis on the center location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Intensity-Based Registration</head><p>Existing probabilistic frameworks for intensity-based registration focus on similarity measures and do not model common processing steps on the images. We demonstrate in the following how these steps can be integrated in the new framework. The proposed framework is a true extension of previous maximum likelihood frameworks, which can be obtained by setting</p><formula xml:id="formula_10">N i = (x i ), d i = u(x i ), N i = (T (x i ))</formula><p>, and e i = v(T (x i )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Image Filtering</head><p>Image filtering is a common pre-processing step for image registration. One application of filtering is image enhancement through operations such as sharpening, noise reduction, and contrast adjustment. Another application is the creation of a scale-space <ref type="bibr" target="#b11">[12]</ref>. Although these processing steps are very popular, it has not yet been described under which conditions they are optimal choices.</p><p>With the proposed framework, it is possible to deduce optimal filters under the incorporation of certain assumptions, similar to the derivation of similarity measures. For this, we focus on the maximization of the coupling term p(d|u) with all considerations analogously for p(e|v, T ). The MAP estimation reads as</p><formula xml:id="formula_11">d = max d p(d|u) = max d N i=1 p(d i |u(N i ))<label>(9)</label></formula><p>= max</p><formula xml:id="formula_12">d N i=1 p(u(N i )|d i ) • p(d i ) p(u(N i )) ,<label>(10)</label></formula><p>where we can maximize for each d i separately in the following. Further, applying the logarithm leads to</p><formula xml:id="formula_13">di = max di {log p(u(N i )|d i ) + log p(d i ) -log p(u(N i ))} = max di    j∈Ni log p(u j |d i ) + log p(d i )    - j∈Ni log p(u j ) ≈ max di    j∈Ni log p(u j |d i )    + H[u(N i )],<label>(11)</label></formula><p>where we obtain the entropy H from the asymptotic equipartition property, which results from the application of the weak law of large numbers <ref type="bibr" target="#b7">[8]</ref>. The entropy has no influence on the maximization. It is, however, interesting to notice that setting</p><formula xml:id="formula_14">d i = H[u(N i )]</formula><p>corresponds to the recently proposed entropy images for multi-modal registration <ref type="bibr" target="#b30">[31]</ref>.</p><p>Incorporating the assumption of a Gaussian noise into the maximization</p><formula xml:id="formula_15">max di j∈Ni log p(u j |d i ) = max di j∈Ni -ω j (d i -u j ) 2 , (<label>12</label></formula><formula xml:id="formula_16">)</formula><p>with weights ω j . Following standard maximum likelihood estimation <ref type="bibr" target="#b5">[6]</ref> leads to the optimal solution for d. This estimation was extended to the usage of various norms, considering for instance least absolute values, instead of least squares. Further extensions resulted in M-estimators, and later, generalized M-estimators <ref type="bibr" target="#b9">[10]</ref>. We consider in the following the minimization problem</p><formula xml:id="formula_17">min di Λ.(d i 1 -u(N i )) with Λ =    ω 1 . . . ω |Ni|    ,<label>(13)</label></formula><p>a vector norm . , the one vector 1 of length |N i |, and weights Λ. Calculating the derivative with respect to d i and setting it to zero leads to optimal descriptors. For different norms and Λ = 1, this results in the following descriptors:</p><formula xml:id="formula_18">Norm Descriptor d i . 2 2 E[u(N i )] . 1 median[u(N i )] . ∞ max[u(Ni)]-min[u(Ni)] 2</formula><p>As an example for least squares . 2 2 and arbitrary weights ω j , we obtain</p><formula xml:id="formula_19">d i = 1 Π j∈Ni ω j u j with Π = j∈Ni ω j .<label>(14)</label></formula><p>Modifying the weights in this case allows for modeling arbitrary linear filters. For creating linear scale-spaces, the weights correspond the entries of a Gaussian filter mask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Gradient-Based Similarity Measures</head><p>Gradient-based similarity measures are, for instance, of interest in 2D-3D registration <ref type="bibr" target="#b16">[17]</ref>. Example metrics are gradient correlation and gradient difference. The gradients are calculated with the Sobel operator represented as 3 × 3 filter mask. Subsequently, the correlation coefficient or difference is evaluated between the gradients of the images. For modeling the Sobel operator in the maximum likelihood framework, as described in section 3.1.1, we have to adapt equation ( <ref type="formula" target="#formula_19">14</ref>), because the weights for differential operators sum up to zero. Consequently, we do not consider the normalization factor Π and set the weights ω j according to the Sobel mask. The description layers of our framework represent the gradient images, which are successively matched.</p><p>In a more recent article, Shams et al. <ref type="bibr" target="#b23">[24]</ref> propose gradient intensity-based registration, where mutual information between the gradient images is calculated. The description layers for both registration approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b23">24]</ref> are the same, it is only the metric that is changing. This shows the increased modularity provided by our framework due to the explicit consideration of description layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Geometry-Based Registration</head><p>The integration of geometric registration in our framework corresponds to embedding the feature points on a dense grid. Once the descriptors are calculated for each image, the next step is the comparison between the images. Looking at the approaches for geometry-based registration, we observe that typically SSD is evaluated between the descriptors, which is derived from the similarity term p(e|d). The difference to intensity-based registration is, however, the focus on certain keypoint locations. To account for this, we introduce indicator variables k i , l i ∈ {0, 1}, where k i = 1 signifies that descriptor d i is located at a keypoint location, analogously for l i and e i . Location i is only considered if it corresponds to keypoint locations in both images, leading the the approximation of the probability</p><formula xml:id="formula_20">p(.) ∝ N i=1   1 + p(e i |d i ) similarity • p(d i |u(N i ))p(e i |v(N i )) coupling    k i • l i keypoint . (<label>15</label></formula><formula xml:id="formula_21">)</formula><p>In the following, we describe landmark-and feature-based registration in more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Landmark-Based Registration</head><p>The term landmark-based registration is ambiguously used in the literature, where we consider it in the sense that experts identify the location of the keyoint and also provide a distinctive description. Most important is the probability p(e i | d i ), which evaluates the similarity that locations with the same labels overlap. The terms p(d i | u(N i )) and p(e i | v(N i )) can be used to model the confidence in the assignment of the label to the keypoint location. For the keypoint locations the values of k i and l i are set to one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Feature-Based Registration</head><p>While in landmark-based registration, the localization and description of the keypoints takes place manually, and for point clouds, the localization is automatic but no description is provided, feature-based registration performs the extraction as well as the description automatically. The first task, the keypoint localization, is to identify locations that can repeatedly be assigned under different views of the same object. Popular methods include the difference-of-Gaussian (DoG) <ref type="bibr" target="#b13">[14]</ref>, Harris detector, Harris-affine, and Hessian-affine detector <ref type="bibr" target="#b14">[15]</ref>. Depending on the output of these detectors the keypoint variables k i and l i are set. The second step, the feature description, has to represent the characteristics of the point within its local neighborhood. Frequently used image descriptors are e.g. Scale-Invariant Feature Transform (SIFT) <ref type="bibr" target="#b13">[14]</ref>, Speeded-Up Robust Features (SURF) <ref type="bibr" target="#b3">[4]</ref>, and Gradient Location and Orientation Histogram (GLOH) <ref type="bibr" target="#b15">[16]</ref>. The descriptors are assigned to the corresponding locations on the description layers. The last step is the feature matching, where descriptors of both images at the corresponding locations are compared.</p><p>In our framework, the terms p(d i |u(N i )) and p(e i |v(N i )) are applied for the deduction and calculation of the descriptors from the images. They ensure that the descriptors well characterize the local image context. p(e i |d i ) expresses the similarity of descriptors. k i and l i restrict the evaluation to keypoint locations.</p><p>Looking at the feature-based approaches, we clearly see the local nature of these techniques. Considering SIFT as an example, the keypoint localization with DoG is achieved by searching for the local maximum in scale-space. The DoG can be modeled by setting the appropriate weights in the linear filtering in equation <ref type="bibr" target="#b13">(14)</ref>. The maximum search only considers the direct neighbors. The SIFT descriptor uses 4 × 4 blocks around the keypoint, where each block consists of 4 × 4 pixels of the corresponding scale-space level. So in total, a 16 × 16 neighborhood of each keypoint is considered for building the descriptor. This shows that the descriptors are built using the local context. In our ML framework we are able to describe them due to the extension with neighborhood information and the integration of latent layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Hybrid Methods</head><p>Hybrid registration approaches combine multiple alignment techniques to achieve an improved registration result. So far, it has not been possible to describe hybrid approaches that combine techniques from geometric and iconic registration in a common framework, because there was no framework that enabled the modeling of both registration approaches. As seen in sections 3.1 and 3.2, the proposed probabilistic framework enables the description of a multitude of registration techniques by choosing different descriptors. A possible differentiation of hybrid approaches is to distinguish between the consecutive application of registration <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b20">21]</ref>, or the coupling to a joint energy formulation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref>. For the joint formulation, we consider the sets of descriptors D and E, which can contain descriptors from geometric registration, such as SIFT, and from iconic registration, such as entropy and gradient information. The final marginalization is similar to equation ( <ref type="formula" target="#formula_9">8</ref>)</p><formula xml:id="formula_22">p(u, v, T ) ≈ d∈D,e∈E p(u, v, d, e, T ).<label>(16)</label></formula><p>Since we marginalize only over finite sets and not all possible descriptors, we only achieve an approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Dynamic Adaption of Description Layers</head><p>In the last section, we showed how registration techniques can be modeled with the proposed framework. Further, we illustrated a continuum of registration approaches, classified by the uniqueness of their descriptors. We achieve this increased flexibility by introducing layers of latent random variables. For the approaches in the last section, these layers were calculated with various deterministic algorithms and did not change during the registration. In this section, we illustrate the second advantage of the our model, the dynamic adaption of the description layers. Instead of reducing the optimization to the similarity term p(e|d), we now rely on the interaction of coupling and similarity terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Joint Registration and Segmentation</head><p>Fundamental operations in image analysis include the segmentation and registration of images. Although they are most times solved separately, there are applications where they can mutually benefit from each other and accordingly a joint formulation is useful <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34]</ref>. The performance of any segmentation approach is primarily dependent on the discriminative power of the underlying likelihood model for the data <ref type="bibr" target="#b33">[34]</ref>. Multiple measurements with different imaging modalities or viewpoints could therefore improve segmentation. On the other hand, the alignment of segmented images, instead of the original ones, significantly reduces the influence of noise and consequently facilitates the registration. In our framework, the description layers represent the segmented images. The similarity term p(e|d) drives the correct global alignment and also provides the combination of both image segmentations. The coupling terms p(d|u) and p(e|v, T ) counterbalance the effect of letting both segmentations looking as similar as possible, by ensuring the segmentations to be close to the underlying data.</p><p>We show how the MAP MRF approach in <ref type="bibr" target="#b33">[34]</ref> naturally integrates into our framework. The MAP problem is stated using Bayes </p><p>For the joint optimization, an alternation is done between solving for the optimal labeling with iterated conditional modes and the alignment with the Powell method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Registration with Dynamic Adaptation</head><p>Next to the analysis of existing registration algorithms, we also want to illustrate the deduction of new methods with the proposed framework. We create an instantiation of the framework by assigning specific distributions to the involved probabilities. More precisely, we consider the problem of images being distorted by severe artifacts. An application where the registration of such images is required is endovascular stent graft placement, where the bright stent is only present in the intra-operative radiograph <ref type="bibr" target="#b2">[3]</ref>. Instead of pre-processing images as in <ref type="bibr" target="#b2">[3]</ref>, we deduce a registration algorithm that is robust to such artifacts. This is advantageous because we retain all the information during the registration and the algorithm identifies artifacts automatically.</p><p>We incorporate a Gaussian distribution for the similarity term p(e|d) leading to p(e|d) ∝ exp -</p><formula xml:id="formula_24">e-d 2 2 σ 2</formula><p>, with variance σ 2 . We allow the description layers to change during the registration, integrating the local neighborhood information, by setting a uniform distribution</p><formula xml:id="formula_25">p(d i |u(N i )) ∝ c d i ∈ u(N i ) 0 d i / ∈ u(N i )<label>(19)</label></formula><p>with constant c. Since we are interested in MAP estimation, the partition function plays no role in the optimization. Instead of assigning a constant likelihood to all patch locations, one could also choose weights that favor the selection of locations close to the patch center.</p><p>For simplicity of presentation, we allow the dynamic adaptation only on layer d. The log-likelihood of equation (7) reads as </p><formula xml:id="formula_26">log p(u, v, d, e) ∝ N i=1 - (e i -d i ) 2 σ 2 + log c d i ∈ u(N i ) -∞ d i / ∈ u(N i )<label>(20)</label></formula><formula xml:id="formula_27">(e i -d i ) 2 subject to d i ∈ u(N i ),<label>(21)</label></formula><p>with e depending on T . We optimize simultaneously over the layer d, which can select values in the local neighborhoods, and the transformation T , which affects the layer e. At each step of the Nelder-Mead simplex optimizer, we set that value in the local neighborhood u(N i ) to d i that minimizes the squared difference (d i -e i ) 2 . In our experiments, we consider a 5 × 5 neighborhood. For a 1-neighborhood, u(N i ) = {u(x i )}, the algorithm reduces to the standard SSD registration. We perform rigid registration experiments on five images, see figure <ref type="figure" target="#fig_4">5</ref>. We set as the moving image v the original, noise-free image. For u, we add the CVPR artifact and white Gaussian noise to the image. Further, we displace u, in our experiments by 10 pixel along the vertical direction. This is the true transformation that we want to recover. We start the registrations from random initial translations along x and y axes, guaranteeing a root mean squared (RMS) distance from the true transformation of 30 pixel. For each image, we run the registration 100 times from the random positions and calculate the RMS error between the registration result and the true transformation. A statistical analysis of the errors is presented in a box-and-whisker diagram in figure <ref type="figure" target="#fig_6">6</ref>. We compare the approach to the registration with SSD, NCC, and MI 1 . Our results show that the addition of artifacts significantly influences the performance of SSD, NCC, and MI. In contrast, the proposed algorithm with the adaptation of description layers leads to excellent results. Further, we illustrate in figure <ref type="figure" target="#fig_4">5</ref> the location of the local neighborhood N i that is assigned to d i in the final step of the optimization. Illustrated is the assignment for the registration with the butterfly image, with similar results for the other images. The values range from -12 to 12, because it corresponds to the vector indexing of the 5 × 5 patch. 0 is the center location. We observe that across the image mainly the central location is selected. For the artifact region, however, locations in the neighborhood are selected to 1 See supplementary material for results on NCC and MI. We plot SSD because it performed best.  maximize the cost function, as expected. This information can be of value for further processing steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We presented a novel probabilistic framework for image registration, which is general enough to describe intensitybased, as well as, geometry-based registration. The proposed framework allows us to move from just modeling the similarity function towards modeling larger parts of the registration process. The key extension, with respect to previous frameworks, is the consideration of local neighborhood information, so replacing the assumption of independent coordinate samples by the Markov property. We reviewed various registration approaches and showed their deduction within our framework. We further introduced a continuum of registration approaches, limited by pure geometric and iconic registration, arranged by the uniqueness of their descriptors. We used the coupling terms in the proposed framework to derive optimal descriptors, as well as, to integrate the dynamic adaption of descriptors during the registration. Finally, we instantiated the framework with specific distributions to deduce a novel registration algorithm. The proposed framework provides further insights about the relationship of various registration techniques, and moreover, helps to understand and classify them.</p><p>In the supplementary material, we present the extension of the proposed framework to groupwise registration and additional experimental results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Left: Probabilistic graphical model showing the probability p(v|u, T ), where each of the images consists of a random variable for each location x ∈ Ω, in this case 6. Right: Assumption of i.i.d. coordinate samples, p(v(x)|u(x), T ), illustrated as plate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Graphical model of the registration framework. Observed 1D images u and v. Latent description layers d and e. u(Ni) neighborhood system of descriptor di.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Continuum between feature-and intensity-based registration, augmented with exemplary approaches. Arranged by the uniqueness of descriptors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>p(d, e, T |u, v) = p(u, v|d, e, T )p(d, e, T ) p(u, v)(17)with the images u, v given and the transformation T and segmentations d, e to calculate. The likelihood term p(u, v|d, e, T ) is represented with a Gaussian mixture model and the prior p(d, e, T ) with an MRF using the Ising model. At the beginning of the registration, when the images are far from being correctly aligned, the joint modeling of both images is not meaningful. Therefore, the independence of the images and consequently the labels is assumed, leading to p(d, e, T |u, v) = p(u|d)p(d)p(v|e)p(e)p(T ) p(u)p(v) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Five images with artifacts. Right: Illustration of selected locations in each local neighborhood. 0 corresponds to center location.</figDesc><graphic coords="8,53.70,77.70,75.36,75.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>error of registration study RMS error in pixel</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Results of random registration study. The order of the results is corresponding to the order of the images in figure 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,113.50,16.20,385.00,140.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Contextual graphical model as plate. Descriptors di and ei are dependent on a local neighborhood Ni of the original images. Further, ei is dependent on di and the transformation T . Observed random variables are filled blue, links indicate dependency.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment: The work was partly supported by the <rs type="funder">Humboldt foundation and European Commission</rs>. We thank <rs type="person">Sandy Wells</rs> for discussions.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unified segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="839" to="851" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An interactive hybrid non-rigid registration framework for 3d medical images</title>
		<author>
			<persName><forename type="first">A</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISBI</title>
		<imprint>
			<date type="published" when="2006-04">April 2006</date>
			<biblScope unit="page" from="824" to="827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stent graft removal for improving 2d-3d registration</title>
		<author>
			<persName><forename type="first">M</forename><surname>Baust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Demirci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISBI</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Speededup robust features (surf)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="346" to="359" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2006. 2, 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large Displacement Optical Flow</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley Online Library</publisher>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A unified framework for atlas based brain image segmentation and registration</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agostino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WBIR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="136" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Understanding robust and exploratory data analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hoaglin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mosteller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Wiley</publisher>
			<biblScope unit="volume">3</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Consistent landmark and intensity-based image registration</title>
		<author>
			<persName><forename type="first">H</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="450" to="461" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The structure of images</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="363" to="370" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonrigid image registration using conditional mutual information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Loeckx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Slagmolen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scale &amp; affine invariant interest point detectors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A performance evaluation of local descriptors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1615" to="1630" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A comparison of similarity measures for use in 2-d-3-d medical image registration</title>
		<author>
			<persName><forename type="first">G</forename><surname>Penney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Desmedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1998-08">Aug. 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image registration by maximization of combined mutual information and gradient information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maintz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMI</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="809" to="814" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Bayesian model for joint segmentation and registration</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Grimson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="228" to="239" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unifying maximum likelihood approaches in medical image registration</title>
		<author>
			<persName><forename type="first">A</forename><surname>Roche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Malandain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Imaging Systems and Technology: Special Issue on 3D Imaging</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Elastic registration of electrophoresis images using intensity information and point landmarks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cathier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wörz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1035" to="1048" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Non-rigid registration using higher-order mutual information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L G</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hawkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">3979</biblScope>
			<biblScope unit="page" from="438" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Image similarity using mutual information of regions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Russakoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rohlfing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jr</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="596" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gradient intensity-based registration of multi-modal images of the brain</title>
		<author>
			<persName><forename type="first">R</forename><surname>Shams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005">Oct. 2007. 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Matching Local Self-Similarities across Images and Videos</title>
		<author>
			<persName><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A fast local descriptor for dense matching</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to match: Deriving optimal template-matching algorithms from probabilistic image models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jedynak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="213" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Alignment by Maximization of Mutual Information</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Viola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995. 1, 2, 3</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.d. thesis</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Locally adaptive nakagami-based ultrasound similarity measures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ultrasonics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="547" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Alignment of viewing-angle dependent ultrasound images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Entropy and laplacian images: Structural representations for multi-modal registration</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wachinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2004">2012. 3, 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic robust medical image registration using a new democratic vector optimization approach with multiple measures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Deinzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="590" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<title level="m">Contextual Flow</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">MAP MRF joint segmentation and registration of medical images</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Noble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="539" to="552" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multimodal registration via spatialcontext mutual information</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPMI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Effective incorporation of spatial information in a mutual information based 3d-2d registration of a ct volume to x-ray images</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MICCAI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Unifying encoding of spatial information in mutual information for nonrigid registration</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hawkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">IPMI</biblScope>
			<biblScope unit="page" from="491" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A Unified Information Theoretic Framework for Pair-and Group-wise Registration of Medical Images</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zöllei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
		<respStmt>
			<orgName>MIT; MIT-CSAIL</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.d. thesis</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A Unified Statistical and Information Theoretic Framework for Multi-modal Image Registration</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zöllei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fisher</surname><genName>III</genName></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPMI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
