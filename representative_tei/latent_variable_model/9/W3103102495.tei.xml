<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generating high-fidelity synthetic patient data for assessing machine learning healthcare software</title>
				<funder>
					<orgName type="full">Innovate UK</orgName>
				</funder>
				<funder>
					<orgName type="full">Department for Business, Energy and Industrial Strategy</orgName>
					<orgName type="abbreviated">BEIS</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Allan</forename><surname>Tucker</surname></persName>
							<email>allan.tucker@brunel.ac.uk</email>
							<idno type="ORCID">0000-0001-5105-3506</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Brunel University London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenchen</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">CPRD, Medicines &amp; Healthcare Products Regulatory Agency</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ylenia</forename><surname>Rotalinti</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Biomedical Informatics Laboratory</orgName>
								<orgName type="institution">University of Pavia</orgName>
								<address>
									<settlement>Pavia</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Puja</forename><surname>Myles</surname></persName>
							<idno type="ORCID">0000-0002-8976-890X</idno>
							<affiliation key="aff1">
								<orgName type="institution">CPRD, Medicines &amp; Healthcare Products Regulatory Agency</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Seoul National University Bundang Hospital</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Generating high-fidelity synthetic patient data for assessing machine learning healthcare software</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1038/s41746-020-00353-9</idno>
					<note type="submission">Received: 18 December 2019; Accepted: 9 October 2020;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>There is a growing demand for the uptake of modern artificial intelligence technologies within healthcare systems. Many of these technologies exploit historical patient health data to build powerful predictive models that can be used to improve diagnosis and understanding of disease. However, there are many issues concerning patient privacy that need to be accounted for in order to enable this data to be better harnessed by all sectors. One approach that could offer a method of circumventing privacy issues is the creation of realistic synthetic data sets that capture as many of the complexities of the original data set (distributions, non-linear relationships, and noise) but that does not actually include any real patient data. While previous research has explored models for generating synthetic data sets, here we explore the integration of resampling, probabilistic graphical modelling, latent variable identification, and outlier analysis for producing realistic synthetic data based on UK primary care patient data. In particular, we focus on handling missingness, complex interactions between variables, and the resulting sensitivity analysis statistics from machine learning classifiers, while quantifying the risks of patient re-identification from synthetic datapoints. We show that, through our approach of integrating outlier analysis with graphical modelling and resampling, we can achieve synthetic data sets that are not significantly different from original ground truth data in terms of feature distributions, feature dependencies, and sensitivity analysis statistics when inferring machine learning classifiers. What is more, the risk of generating synthetic data that is identical or very similar to real patients is shown to be low.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>It is increasingly evident that the use of historical data within health systems can offer huge rewards in terms of increased accuracy, timely diagnoses, the discovery of new knowledge about disease and its progression, and the ability to offer a more personalised prognosis and care pathway for patients <ref type="bibr" target="#b0">1</ref> . What is more, there is a huge demand from the public and governments to make new technology available within health services as quickly as possible while ensuring that any software that uses Artificial Intelligence (AI), in particular Machine Learning, is robustly validated to check for biases and errors <ref type="bibr" target="#b1">2</ref> .</p><p>Many issues concerning patient privacy have been highlighted since the introduction of General Data Protection Regulation <ref type="bibr" target="#b2">3</ref> . This includes protections from the identification of an individual's data within large data samples <ref type="bibr" target="#b3">4</ref> and the right to explanation for any decision that is made by an automated system <ref type="bibr" target="#b4">5</ref> . As a result of this legislation, the ability to offer large samples of real individual-level patient data to companies and institutions is limited. One possible solution to this problem is the use of synthetic data as an alternative to assist in the rapid development and validation of new tools. This data must capture all of the correct (potentially non-linear and multivariate) dependencies and distributions that are apparent in the real data sets, while also preserving patient privacy and avoiding the risks of individual identification.</p><p>In this paper, we explore some of the key issues in generating realistic and useful synthetic data, namely preserving relationships, distributions, predictive capabilities, and patients' privacy. We also explore what robust methods need to be used to validate models using synthetic data in order to ensure biases in the models, overfitting issues, and high variance are discovered and reported. The paper is broken down in to three main sections: first, we discuss some of the key issues concerning the generation and use of synthetic data and introduce a method based on probabilistic graphical models; second, we explore a case study using primary care data from the Clinical Practice Research Datalink (CPRD) in the UK. CPRD is a real-world research service supporting retrospective and prospective public health and clinical studies. It is jointly sponsored by the Medicines and Healthcare products Regulatory Agency and the National Institute for Health Research, as part of the Department of Health and Social Care <ref type="bibr" target="#b5">6</ref> . Finally, we make conclusions and recommendations about the advantages and disadvantages of using synthetic data for rapid development of AI systems in healthcare.</p><p>There are already existing methods for generating synthetic data. One simple approach is through data perturbation by adding noise to the original data set. For example, rotations, cropping, and noise injection in images <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref> in order to produce more diverse data sets for a more generalisable classifier, or through the addition of noise from some distribution such as the Laplace mechanism as used in PrivBayes <ref type="bibr" target="#b9">10</ref> in order to make it more difficult to identify individuals from a data set. Another approach uses generative models of data <ref type="bibr" target="#b10">11</ref> . In this case, models that capture the correct relationships and distributions are built, either handcoded based upon expert knowledge or inferred from real data using models such as Bayesian networks (BNs) <ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12</ref> or neural networks <ref type="bibr" target="#b12">13</ref> . These can then be used to generate synthetic data via sampling techniques. Generative Adversarial Networks have become particularly popular as a method to generate synthetic image data to build more robust models containing fewer biases than those generated on real data alone <ref type="bibr" target="#b13">14</ref> .</p><p>Bias in the data can appear due to the way data is collected. In many fields, data analysis involves using historical secondary-use data that was not collected for the analysis in question, as opposed to well-designed research data aimed at answering a specific statistical question (as found in clinical trials for example). This means that secondary-use data sets are often imbalanced, particularly in medicine. For example, in primary care data the number of patients with a specific disease may be far lower than patients who do not have the disease. Conversely, data that is collected by a particular hospital may not reflect the general population as less-severe patients may be managed in primary care, while the data collected in hospitals will only contain more severe patients who are already diagnosed with a specific disease or are at high risk of developing it. As a result, any models that are inferred from such data must deal with these imbalances, either through resampling methods <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16</ref> or synthetic data generation. SMOTE is a commonly used resampling technique in machine learning for dealing with small and imbalanced samples and involves generating synthetic datapoints to supplement existing data <ref type="bibr" target="#b16">17</ref> .</p><p>An important issue concerning the use of an underlying model to generate synthetic data is that the inherent biases may not be visible. For example, Neural Network approaches whereby models are inferred from data have turned out to be biased, leading to decisions and classifications being made for the wrong reasons <ref type="bibr" target="#b17">18</ref> . Agnostic network approaches have attempted to deal with unwanted biases in the data by selecting known "protected concepts" and using domain adversarial training <ref type="bibr" target="#b18">19</ref> to account for these biases. The issue of bias is especially a problem for models where the relationships between features are not explicitly represented because unwanted correlations cannot easily be identified. This is known as the black box problem where it is difficult to know how a model will behave when it has many complex parameters that are not easily interpreted. Approaches that try to deal with this by modelling influences more transparently include probabilistic graphical models <ref type="bibr" target="#b19">20</ref> and treebased models <ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> .</p><p>Many data sets will contain specific characteristics that must be taken into account when learning a model for synthetic data generation. For example, missing data are common in most medical data sets. These missing data can manifest for many different reasons but if the data are not recorded for some systematic reason then this must be accounted for in the modelling process. This is structurally missing data-also known as Missing Not At Random (MNAR) as opposed to Missing At Random (MAR). If MNAR is non-ignorable, then we must find a way to model these types of missingness. For example, in probabilistic graphical models, a discrete variable can include a "missing" state, while continuous value variables can include a binary node representing whether the variable measurement is missing or not <ref type="bibr" target="#b22">23</ref> . However, for non-ignorable MNAR data we need to use robust methods <ref type="bibr" target="#b23">24</ref> . This is because the pattern of missing data can often have value in itself and be exploited to assist in making predictions <ref type="bibr" target="#b22">23</ref> . Other approaches include explicitly modelling these unmeasured effects as latent variables <ref type="bibr" target="#b24">25</ref> , which we will explore in this paper.</p><p>Most data sets will contain unmeasured effects. That is, some underlying processes that have not been recorded in the data (perhaps because they were not considered important at the time of collection, or perhaps because they were not known at the time -e.g. a particular clinical test that has been introduced part way through the data collection process). These can be modelled using latent variable approaches that use methods such as the FCI algorithm <ref type="bibr" target="#b19">20</ref> to infer the location and the Expectation Maximisation algorithm <ref type="bibr" target="#b25">26</ref> to infer the parameters of these unmeasured variables. A key issue being explored in this paper is how synthetic data can be used while ensuring patient privacy. That is, the ability to use simulated patient data to build new models without giving away personal information. There are a number of concepts that attempt to measure how easy it is to identify a patient from their data. For example, k-anonymisation is a measure of the least number of individuals (k) in a data set who share the set of attributes that might become identifying for each individual <ref type="bibr" target="#b26">27</ref> , while ε-differential privacy is a metric which enables data managers to only release aggregates of data that cannot be used to identify individuals <ref type="bibr" target="#b27">28</ref> . Re-identification has proven to be problematic, for example, through "differentiation attack" where aggregated data are repeatedly requested for different subsets to enable the attacker to identify individual. This is a risk even when data have been anonymised <ref type="bibr" target="#b28">29</ref> . For many individuals, aggregated data can preserve their privacy if data cannot be repeatedly requested as they cannot be identified from the summary statistics/distributions that are learnt from a large population. However, people who are considered outliers, for example, those who have rare disease or demographics may still be identified. As a result, outlier analysis <ref type="bibr" target="#b29">30</ref> needs to be incorporated. Simply removing these patients may be an option but this can sometimes mean missing out on important data that could be used to help future patients.</p><p>In summary, there have been numerous attempts to generate synthetic data for different reasons, including to deal with biased, imbalanced, and small sampled data. There is now a push to explore how synthetic data may enable researchers to build predictive models while preserving patient privacy. In this paper, we explore the integration of probabilistic graphical models with latent variables and resampling to simultaneously capture many features of real-world complex primary care data, including missing data, non-linear relationships, and uncertainty, while focussing on the importance of transparency of the modelling and data generation process. In the next section, we describe the methods that we have adopted to construct and robustly validate synthetic data samples. We also describe the primary care data in detail. We then carry out an empirical analysis on a subset of the primary care data with a focus on cardiovascular risk. This includes an evaluation of our probabilistic graphical model approach to handling missing data by comparing the synthetic data to original ground truth data in terms of distributional characteristics. We then explore how the synthetic data compare on machine learning classification tasks by comparing the sensitivity analyses on synthetic and ground truth data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and modelling</head><p>Our experiments make use of the CPRD Aurum data set. This includes patient Electronic Healthcare Records collected routinely from primary care practices using the EMIS® patient management software system. When a practice agrees to contribute their patient data to CPRD Aurum, CPRD receives a full historic collection of the coded part of the practice's electronic health records, which includes data on deceased patients and those who have left the practice. The coded clinical record includes symptoms, diagnoses, prescriptions, immunisations, tests, lifestyle factors, and referrals recorded by the general practitioner (GP) or other practice staff but does not include free text medical notes <ref type="bibr" target="#b5">6</ref> . The November 2019 release of the CPRD Aurum database included a total of 27.5 million patients (including deceased and transferred patients) from 1042 practices of whom 9.7 million were currently registered with a GP <ref type="bibr" target="#b5">6</ref> .</p><p>We have chosen a generative approach to modelling the CPRD data where the focus is on a combination of machine learning that is augmented with expert knowledge. This is because we want to ensure that any biases that occur in the ground truth data are made explicit and can be dealt with at each stage of the data generation process. As a result, the underlying model must deal with all the potential uncertainty in the data while also modelling the distributions and relationships in as transparent a manner as possible. For this reason, we have chosen a BN framework. The first experiment involved learning a BN from the CPRD data set.</p><p>The general structure of the discovered BNs from multiple samples of the original CPRD data, which we denote as ground truth (GT), are shown in Fig. <ref type="figure" target="#fig_0">1</ref>. This explicit representation of independencies between variables allows experts to assess the underlying model and check for potential biases within the GT data. For example, almost all the black arc relationships are well recognised in medical research:</p><p>• Cholesterol/high-density lipoprotein ratio and type 2 diabetes: increased ratio in type 2 diabetes <ref type="bibr" target="#b30">31</ref> • Steroid treatment and systemic lupus erythematosus (SLE): steroids used in SLE treatment <ref type="bibr" target="#b31">32</ref> • Rheumatoid arthritis (RA) and SLE-both are autoimmune conditions, and while RA affects joints, SLE can affect joints in some variants and mimic RA. They are considered distinct diseases but can co-occur 33</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Severe mental illness and migraines: migraines can precede mental illness and are common in those with anxiety disorders <ref type="bibr" target="#b33">34</ref> • Smoking and severe mental illness: well-known association, especially in schizophrenia (widely observed but may not be causal) <ref type="bibr" target="#b34">35</ref> • Ethnicity and body mass index (BMI): possibly confounded by lifestyle explanations but widely observed association <ref type="bibr" target="#b35">36</ref> • Smoking and systolic blood pressure: the grey in the network reflects the conflicting evidence base in this area <ref type="bibr" target="#b36">37</ref> • Smoking and impotence; this also explains why there is a relationship between the male gender and impotence <ref type="bibr" target="#b37">38</ref> • Type 1 diabetes and impotence <ref type="bibr" target="#b38">39</ref> • Age and systolic blood pressure: increasing systolic blood pressure with increasing age 40</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Family history of coronary heart disease increases risk of stroke/heart attacks 41</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>Antipsychotics and severe mental illness: antipsychotics used for treatment of severe mental illness (bnf.nice.org.uk)</p><p>• Systolic blood pressure and systolic blood pressure SD: correlated variables • Atrial fibrillation (AF) and stroke/heart attack: AF is risk factor for stroke (stroke.org.uk)</p><p>• Chronic kidney disease and stroke/heart attacks: often cooccur <ref type="bibr" target="#b41">42</ref> • Age and type 2 diabetes: increasing risk of type 2 diabetes with age <ref type="bibr" target="#b38">39</ref> There were, however, some surprises:</p><p>• Region was connected to impotence. Perhaps there is an indirect link as linked to regional distribution of smoking <ref type="bibr" target="#b42">43</ref> • There is no clear link between systolic blood pressure and blood pressure treatment. This could possibly be due to systolic blood pressure being a numeric variable spanning normal and high systolic blood pressure readings We adopt three BN modelling approaches to handle missing data: First, we simply delete all cases with missing data. Second, we model missingness in discrete nodes by adding a "Miss State" to all possible node states, and in continuous nodes by adding a new binary parent (a "Miss Node") to each node, representing whether the data point is missing or not. Finally, we explore the use of the FCI algorithm <ref type="bibr" target="#b19">20</ref> to infer any latent variables in the network. These methods are explained in more detail in the "Methods" section. The following links to 6 latent variables were discovered:</p><p>"L1" → "age" "L1" → "af" "L1" → "treathyp" "L2" → "steroid" "L2" → "treathyp" "L3" → "impot" "L3" → "gender" "L4" → "migr" "L4" → "choleratio" "L4" → "gender" "L5" → "strokeha" "L5" → "ckidney" "L5" → "type2" "L5" → "choleratio" "L5" → "sbps" "L6" → "strokeha" "L6" → "ckidney" "L6" → "type2" Having accepted this underlying BN model (though we can choose to update it based on expert knowledge by removing known false links and adding expected true links), we now explore how it can generate synthetic data with the underlying distributions in the GT data on a variable by variable basis, while accounting for missingness using the "Miss Nodes/States" approach and the latent variable approach.</p><p>Synthetic data compared to ground truth data for underlying distributions We compare distributions of variables from 100,000 data samples generated by the BN with the original ground truth data under three conditions for handling missing data: first, by simply deleting all cases with missing data. Second, by using "Miss Nodes" (for continuous variables) and "Miss States" (for discrete variables). Finally, by additionally learning latent variables within the BN structure using the FCI algorithm to capture unmeasured effects, including potentially MNAR data.</p><p>Figures <ref type="figure">2</ref> and<ref type="figure">3</ref> show the resulting distributions for a sample of features in the CPRD. We explore the distribution comparisons between the GT and SYN that is generated by logic sampling from the BN under two conditions for a number of representative variables-first, when missing data are simply deleted (Fig. <ref type="figure">2</ref>). Figure <ref type="figure">2a</ref> shows the result for GT and Fig. <ref type="figure">2b</ref> shows the SYN data generated from this. Second, we explore explicitly modelling the distributions using our approaches described in the "Methods" (Fig. <ref type="figure">3</ref>). Figure <ref type="figure">3a</ref> shows the GT with no missing data removed, Fig. <ref type="figure">3b</ref> shows the SYN data generated from this using our Miss Nodes/ States data approach, and Fig. <ref type="figure">3c</ref> shows the resulting SYN from using the latent variable method. Also included are the number of data points with missing cases and the number of distinct values for a feature (e.g. a value of two for discrete binary features and potentially large numbers for integers and real values).</p><p>First, notice how these results show that, for some variables, simply deleting the missing data can result in very different distributions. For example, the age distribution of the GT when missing data are simply removed in Fig. <ref type="figure">2a</ref> has a very different distribution than for the original GT data without missing data removal in Fig. <ref type="figure">3a</ref>. What is more, the approach to modelling missingness with "Miss Nodes/States" results in a similar shape distribution to the original in Fig. <ref type="figure">3b</ref> for some, but in certain cases, the latent variable approach in Fig. <ref type="figure">3c</ref> results in the most similar distribution to the ground truth with missing data-compare bmi in Fig. <ref type="figure">3a-c</ref>. The bias in categorical data seems less significant and both the "Miss Nodes/States" and latent variable approaches capture the smoking and stroke distributions very closely though notice how different the distributions are if the missing data are simply removed, highlighting the importance of modelling missing values rather than removing them.</p><p>Note that the amount of missing data that is generated (% Missing) is different for the latent variable approach and the "Miss Nodes/States" approach, with the "Miss Nodes/States" approach in Fig. <ref type="figure">3b</ref> reflecting this value more closely and the latent variable Fig. <ref type="figure">2</ref> Plots of sample distributions and statistics of the original ground truth data when all missing data are deleted along with plots, distributions, and statistics from the synthetic data that are generated using a BN inferred from the ground truth.</p><p>approach exhibiting far fewer missing cases. This is likely due to the latent variable method in Fig. <ref type="figure">3c</ref> inferring the missing values. In summary, a close distribution can be created between synthetic data sets and ground truth. Distributions are generally closer to the original when missing data are preserved and modelled. We have found this general trend across all features.</p><p>Each discrete variable is compared using Chi-squared tests to measure the difference between n samples of the Ground Truth (GT) and n samples of SYNthetic data (SYN). For variables with continuous values, Kolmogorov-Smirnov (KS) test is used to measure the distribution difference between GT and SYN data sets. In addition, the Kullback-Leibler divergence (KLD) is used to measure the distribution difference between sampled GT and SYN data sets. These approaches are described in more detail in the "Methods" section.</p><p>Chi-squared test is performed with the null hypotheses to (1) test whether there is no significant difference between expected frequencies from SYN and (2) the observed frequencies from GT for each variable (categorical).</p><p>Table <ref type="table" target="#tab_0">1</ref> shows that for all features the null hypothesis cannot be clearly rejected in both scenarios, i.e. removing the missing data and modelling it (all p values are far greater than the 0.05 level). This was surprising and implies that simply deleting missing data is not a problem for this primary care data (or at least it does not have much impact on the overall distribution). This could be because of the size of data set that we are dealing with and missing data may be more of an issue with smaller sample sizes. In addition, modelling missingness explicitly is likely to impact certain cases more than others (for example, where people have refused to give certain information for some underlying reasoni.e. MNAR data). These cases may be rare but significant.</p><p>The KS test is performed to test the hypothesis if the numerical variables of the GT and SYN data sets come from the same distribution. We explore this for a number of different sample sizes (n). This is because larger sample sizes make the test more likely to conclude that the two distributions are different (i.e. reject the null hypothesis) because it is very sensitive to differences between distributions <ref type="bibr" target="#b43">44</ref> . Fig. <ref type="figure">3</ref> Plots of sample distributions and statistics of the original ground truth data including missing data as well as plots for the synthetic data that models missing data with "Miss Nodes/States" and with latent variables.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows that the numerical variables from SYN and GT data sets are indeed from the same distributions (the p values are always &gt;0.01, meaning we reject the hypothesis that they are from different distributions) for all variables except age and bmi for very high sample sizes (indeed the D statistics are nearly always smaller for the models using latent variables, which means that data sets are generally closer).</p><p>We now look at using the KLD to see the difference over all variables for different samples (of size 100,000) of GT data in comparison to the difference between SYN and GT data sets.</p><p>Table <ref type="table" target="#tab_2">3</ref> shows the mean squared KL distances between repeated GT samples compared to SYN samples scored against GT samples. Table <ref type="table" target="#tab_3">4</ref> calculates the diff KL values using the results above. Additionally, the missing data rates of continuous variables are listed below based on the KL distance. Applying a KS test to these results for each variable shows that the KL distances of two ground truth samples is not significantly different to the KL distance between a ground truth sample and a synthetic data samples for variables with reasonably higher distances (chol and bmi with p values of 0.168 and 0.052, respectively). For age (p = 0.0), sbp (p = 0.0), and sbps (p = 0.002), they were found to be significantly different: age and sbps distances are very small (or zero) for both GT and SYN data comparisons (see Table <ref type="table" target="#tab_2">3</ref>) and sbp interestingly is the variable where the synthetic data actually contains smaller distances to ground truth than between ground truth samples.</p><p>We assume that that the synthetic data are suitably similar in distribution to the ground truth if the KL distances of the samples of synthetic data to the ground truth are similar to the KL distances of the resamples of ground truth data between one another. In order to test this, we randomly resample from ground truth, GT, and calculate the KL distances between each sample. These distances are then compared to the KL distances between the synthetic data, SYN, and the GT. diff KL represents the difference in the KL distances between multiple resamples of GT and between SYN data and GT, for each variable.</p><p>The mean diff KL values for the tested variables (in bottom rows of Table <ref type="table" target="#tab_3">4</ref>) indicate that the synthetic KLDs vary between 8.244 and -1.286 when missing data are presented. In some cases, such as systolic blood pressure (sbp), the synthetic data are constantly closer to the ground truth distribution shape than the resampled data are to one another. For variables without missing values such as age, the KL distance differences are close to zero. In other words, the synthetic data are closer to the GT i distributions. We can thus conclude that our approach generates synthetic data that is no more different to the ground truth data than differences found when generating multiple resamples of ground truth.</p><p>We now explore the joint distributions in the synthetic data sets by using kernel maximum mean discrepancy (kMMD) with a radial basis function kernel. We conducted a combination of distribution tests for 2-variable (253 combinations), 3-variable (1771 combinations), and 4-variable (8855 combinations) comparison. The hypothesis H 0 for kMMD is that samples to be tested come from the same distribution with alpha ~0.05. With the same SYN data sets from the previous experiment for each iteration (10 iterations), we aim to see the difference between same-sized samples from the GT population and samples from SYN in terms of their distributions. The results of the H 0 acceptance rate are shown in Table <ref type="table" target="#tab_4">5</ref> (joint distribution tests on 1000 samples from 1 million GT population and 100,000 sampled SYN data).</p><p>We can conclude from these results that the distance between SYN and GT distributions are generally low when taking account of low-dimensional combinations of data features. What is more, they are not significantly worse than between two GT samples, when using our proposed methods of latent variable modelling to handle missingness. The distance between SYN and GT, however, can increase as the number of combinations of data features increases (potentially as a result of simplification within the structure of the model).   Population sizes are 1,000, 5,000, and 10,000. Kolmogorov-Smirnoff tests comparing distributions between synthetic and ground truth data for numerical variables.</p><p>In order to see the practical implication of differences between GT and SYN data, we further compare GT and SYN's performance on training and testing machine learning classifiers in the next section.</p><p>Synthetic data compared to ground truth data for machine learning classifier comparison Figure <ref type="figure" target="#fig_2">4</ref> compares the receiver operator characteristic (ROC) and precision recall (PR) curves for the GT data and SYN data (generated using the latent variable method) when a machine learning classifier is inferred for predicting stroke. The results shown are on a Bayesian generalised linear classifier. In particular, the area under the ROC curve (AUC) for both curves is calculated for GT and SYN samples and the Granger causality statistic as described in the "Methods" is calculated to determine how predictive the SYN curves are of the underlying GT curves. Note that a p value is generated that determines the Granger causality statistic at the 5% significance level.</p><p>First, notice that the ROC and PR curves are similar in shape for the GT data (blue) and the SYN data (red). Observing these sample curves, it is not surprising the Granger causality statistic for all samples is significant at less than the p = 0.001 level. We also applied identical tests to other machine learning classifiers (see Supplementary Figs. <ref type="figure">3</ref> and<ref type="figure" target="#fig_2">4</ref>) where all p values were found to be   &lt;0.001 except for ROC curves generated when using stepwise regression with N &lt; 1000. We conclude that the outcome of using SYN data samples for the selected prediction algorithms is that we can predict the sensitivity analysis of using actual GT data (as their difference is not significant). Indeed, this experiment set-up implies that the generated SYN data are able to achieve equivalent statistical results to GT data. (Incidentally, these AUC results are in line with similar results documented by Ozenne et al. <ref type="bibr" target="#b44">45</ref> i.e. high AUC ROC low AUC PR curves were observed across tests.).</p><p>Detecting re-identification risks using outlier analysis with distance metrics Finally, we explore the risk of re-identification of patients from the SY data based on the clones (R clone ), inliers (N in ), and outlier (N out ) statistics described in the "Methods" section. We base our experiments on the concept of event per variable (EPV), which explores the effect of sample size and number of variables on predictive accuracy <ref type="bibr" target="#b45">46</ref> . The number of EPV is the number of events divided by the number of degrees of freedom required to represent all of the variables in the model. We use an EPV value of 22.2 based on the conclusions in the study by Austin and Steyerberg <ref type="bibr" target="#b45">46</ref> . The results in Table <ref type="table" target="#tab_5">6</ref> below are based on 10 iterations of resampling without replacement. This indicates a sample size of 7000 for each iteration within 11 random population groups. Notice how the risk of clones decreases as the sample size increases (as one would expect). While we also see that the risk of outliers decreases, they are always very small. What is more, the actual number of outliers generated stays relatively stable (between 10 and 70). These statistics demonstrate that, while there is always a risk of risk of a synthetic patient being linked to an actual patient in the ground truth data in the case or outliers, we can exploit such metrics to identify the at-risk samples and make a decision as to whether they should be removed or not (if they are clones or outliers with a too-small k-anonymisation value).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>This paper has introduced and validated a set of techniques to model complex heterogeneous data for generating realistic synthetic data sets that capture the correct dependencies and distributions. The approach exploits resampling with probabilistic graphical modelling that explicitly handles missingness and complex non-linear/non-Gaussian relationships and is transparent in how data are modelled enabling biases to be assessed and accounted for. Through a case study on cardiovascular risk, the paper has demonstrated that these synthetic data sets not only generate similar distributions over both discrete and continuous variables but also produce similar sensitivity analyses to the original ground truth data (in the form of PR and ROC curves). Patient privacy is quantified through a demonstration that the proximity of individual synthetic data points to real patients can be scored by using outlier statistics and distance metrics, though more research is required on the robustness of this particularly when clusters of patients with rare disease/demographics are modelled. We have demonstrated that our method can flag identical or similar patient profiles in the synthetic and real data. While the occurrence of these "clones" or similar rare patient profiles appears to be low (and does not seem to increase with sample size), there is still a small risk. However, our metrics enable these risks to be quantified so that appropriate action can be taken prior to releasing any data (depending on the risk protocol adopted).</p><p>Another issue that may impact the production of realistic synthetic data is the temporal nature of many health data sets. The methods that we have adopted here are well suited to handle this characteristic. For example, the dynamic BN <ref type="bibr" target="#b46">47</ref> and hidden Markov model <ref type="bibr" target="#b47">48</ref> are generalisations of the standard BN model used in this paper. Here the time dimension is represented by unrolling networks so that nodes represent variables at specific time points in Fig. <ref type="figure" target="#fig_3">5c,</ref><ref type="figure">d</ref>. These approaches will be included in our future directions for the project.</p><p>Generating synthetic data from large-scale real-world data that are noisy, contain structurally missing data, and many non-linear relationships such as the UK primary care data can bring enormous benefits to AI research. In particular, it can prevent the need for using real patient data when developing and validating state-of-the-art predictive models. This paper has explored several key issues involved with this but there is scope for more research to ensure that these data sets do not contain  underlying biases (e.g. by exploring data collection processes) or present a privacy risk by carrying out simulated privacy attacks), if they are to be made freely available without any access controls to facilitate innovation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data description-CPRD Aurum</head><p>For our case study, we used an extract from this database on 122,328 patients (all aged &gt;16 years). We tested the synthetic data performance using a risk prediction algorithm for cardiovascular disease (encompassing stroke, transient ischaemic attack, myocardial infarction, heart attacks, and angina). We used the same features as used by Hippisley-Cox et al. <ref type="bibr" target="#b48">49</ref> for predicting the onset of cardiovascular disease within 10 years (explained in Table <ref type="table">7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BN modelling</head><p>We have selected a BN due to its flexibility and transparency-see Fig. <ref type="figure" target="#fig_3">5a</ref>. BNs model the joint distribution of a data set p(X) by making assumptions about conditional independence between features that are captured in a directed acyclic graph (DAG). A BN represents the joint probability distribution over a set of variables, X 1 ,…,X N , by exploiting conditional independence relationships. These relationships are represented by a DAG. The conditional probability distribution (CPD) associated with each variable, X i , encodes the probability of observing its values given the values of its parents and can be described by a continuous or a discrete distribution. All the CPDs in a BN together provide an efficient factorisation of the joint probability (see Eq. 1)</p><formula xml:id="formula_0">p x ð Þ ¼ Y n i¼1 pðx i jpa i Þ;<label>(1)</label></formula><p>where pa i are the parents of the node x i (which denotes both node and variable). This family of models can be used to perform inference by entering evidence into one or more nodes and inferring the posterior distributions of the remaining nodes. In this way, data can be sampled under different observations. We use logic sampling <ref type="bibr" target="#b49">50</ref> to sample data where we "fix" certain features if necessary, by entering evidence. For example, we can generate data where all samples are formed from people aged &gt;65 years, or female-only samples, or all people who have been diagnosed with hypertension.</p><p>BNs can be constructed by hand where the links represent some form of influence or they can be inferred from data using constraint-based algorithms such as the PC or FCI algorithm <ref type="bibr" target="#b19">20</ref> , or search and score methods such as BIC <ref type="bibr" target="#b50">51</ref> , or MDL <ref type="bibr" target="#b51">52</ref> . Here we use a method to infer models directly from the CPRD that can handle missing data known as structural expectation maximisation <ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b52">53</ref> . We record the fit of the models over multiple runs to calibrate the robustness of the models to sampling variation. This family of models can be used to perform machine learning prediction such as in the BN classifier in Fig. <ref type="figure" target="#fig_3">5b</ref>, clustering using the EM algorithm, and time-series forecasting by unrolling the BN into the timedomain in Fig. <ref type="figure" target="#fig_3">5c,</ref><ref type="figure">d</ref>.</p><p>We use three approaches to handle missing data: one for discrete nodes where we add a "missing" state to all possible states in Fig. <ref type="figure" target="#fig_5">6a</ref>, one for continuous nodes where we add a new binary parent to each node that represents either missing or not in Fig. <ref type="figure" target="#fig_5">6b</ref> and one where we use the FCI algorithm to infer any latent variables in the network. The algorithm is applied to 10 resampled data sets to calculate robust statistics for determining the inclusion and position of any latent variables in the networks, e.g. Fig. <ref type="figure" target="#fig_5">6c</ref> where the distribution of a variable is directly influenced by a discrete latent variable that is discovered as a parent. By Table <ref type="table">7</ref>. Description of the selected features used from CPRD for analysis based on predicting cardiovascular disease.  identifying these robust latent variables, we aim to improve the details of the underlying distributions as well as capture any MNAR effects. see Supplementary Fig. <ref type="figure" target="#fig_0">1</ref> for the threshold statistics for each variable and Supplementary Fig. <ref type="figure">2</ref> for a sample network including latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>Modelling missing data to capture underlying distributions. We assume that the synthetic data are suitably similar in distribution to the ground truth if the KL distances of the samples of synthetic data to the ground truth are similar to the KL distances of the resamples of ground truth data between one another. In order to test this, the experiment base population GT i is randomly sampled from the full CPRD primary care database. KL distances are compared to assess if the generated SYN can be representative. Three groups of data are used, where i denotes the sample size.</p><p>GT i -The sampled ground truth from the total population P; SY n i -The generated n synthetic data sets based on GT i (with equal size to GT i );</p><p>GT n i ; GT m i -The other n or m sets of resampled ground truth data (with equal size to GT i ) from the total population P without replacement.</p><p>Two KL distances are obtained from each target variable's distribution shape and these then can be compared as in Eqs. 2-5.</p><formula xml:id="formula_1">D 2 KL ðGT m i jjSY n Þ and D 2 KL ðGT i jjGT n i Þ:<label>(2)</label></formula><p>When the D 2 KL is close to 0, then the distributions are almost identical. When the value of</p><formula xml:id="formula_2">D 2 KL ðGT m i jjSY n i Þ is close to D 2 KL ðGT i jjGT n i Þ,</formula><p>then the generated synthetic variable has an almost identical distribution as the GT i .</p><formula xml:id="formula_3">D 2 KL ðGT i jjGT n i Þ is the mean squared KLD n 2 1 10 f g ð Þ :<label>(3)</label></formula><formula xml:id="formula_4">D 2 KL ðGT m i jjSY n i Þ is the mean squared KLD m; n 2 1 10 f g ð Þ : (4) diff KL ¼ D 2 KL ðGT m i jjSY n i Þ À D 2 KL ðGT i jjGT n i Þ:<label>(5)</label></formula><p>We also explore the joint distribution of our models compared to the ground truth data using MMD. The MMD is an approach to represent distances between distributions as distances between mean embeddings of features <ref type="bibr" target="#b53">54</ref> . The approach tests whether distributions p and q are different on the basis of samples drawn from each of them, by finding a smooth function that is large on the points drawn from p and small (as negative as possible) on the points from q. The test statistic is the difference between the mean function values on the two samples. When this is large, the samples are likely to be drawn from different distributions.</p><p>For example, if we have any joint distributions P from GT i and Q from SY n i over a set X. The MMD can be defined by a feature map φ:X→H, where H is called a reproducing kernel Hilbert space. Hence, when x ¼ H ¼ R d and φ x ð Þ ¼ a kernel function over x. MMD is defined in Eq. 6.</p><p>MMD</p><formula xml:id="formula_5">P; Q ð Þ¼jjE X$P φ X ð Þ ½ ÀE Y$Q φ Y ð Þ ½ jj H ¼ jjE X$P ½X À E Y$Q ½YjjR d ¼ jjμP À μQjjR d ;<label>(6)</label></formula><p>where μP and μQ are the mean embeddings for distributions p and q. We take 10 synthetic and ground truth data set pairs. For each pair, we explored the combination of 2, 3, and 4 variables and applied the MMD test to compare all combinations of these variables. Each test produces the H 0 hypothesis for that combination. We calculate the percentage of times that the H 0 is not rejected for the combinations of 2, 3, and 4 variables.</p><p>Comparing machine learning classifiers inferred and tested from synthetic data and ground truth data. ROC and PR curves are often used to assess the predictive performance of a machine learning model. ROC curves capture the trade-off between false positives and false negatives but can often mask the biases in imbalanced data sets (for example, when the positive case is rare in a population) <ref type="bibr" target="#b54">55</ref> . PR curves, on the other hand, can detect these biases as they capture the trade-off between precision (also known as the positive predictive value representing the number of correct true positives from all positive prediction) and recall (sensitivity). We analyse the ROC curves and PR curves that are generated when 3 machine learning classifiers (stepwise regression, linear discriminant analysis, and Bayesian generalised linear models) are used to model and predict GT data. We explore the ROC and PR plots for the classifiers' performance on the SYN data and the original GT. We also measure the capability of the synthetic data curves to predict the GT curves for varying sample sizes using a Granger causality test <ref type="bibr" target="#b55">56</ref> . In our experiments, the Granger causality test checks for the null hypothesis that the synthetic data curves cannot predict (or "Granger cause") the ground truth curves.</p><p>Detecting re-identification risks using outlier analysis with distance metrics. The method we propose aims to generate synthetic data that avoids privacy issues associated with releasing real patient data. However, if the synthetic data sets enable re-identification of real patients (for example, through proximity between a synthetic data point and a real patient), then the intrinsic value is lost. As the probability of re-identification increases, the more unique a patient's data is (for example, the older a patient is or cases of rare disease). Here we use a form of outlier detection to measure this risk. We randomly select synthetic datapoints from SYN and calculate the distances between it and all GT datapoints. Using an outlier analysis method (based on the distribution of GT data and the individual synthetic data), we calculate the number of GT datapoints (k) that are in the same distribution as the synthetic data point (rather than being statistically separate as an outlier). We apply this for varying large samples (100 K to 1 million) of synthetic datapoints. The smallest value of k for each of these can be considered the k-anonymisation value.</p><p>We use the quantile function to assess how many real-world patients are close to a synthetic patient given a pre-defined probability of smallest distance (e.g. Euclidean distance) observations. For example, given the probability of 0.1%, n observations of real patient records that are closest to a real patient record can be obtained. In this experiment, GT and SYN data sets are combined into one data set, so the total size of the data set will be S = S GT = S SYN , and we define the instances with high privacy risk under any of the following conditions:</p><p>Clones-when distance is 0, i.e. the synthetic patient record is identical to real-world patient record, the clone rate is used to measure clone risk R clone defined in Eq. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R clone ¼</head><p>Total identical instances Total instances :</p><p>Inliers-when there is only one real patient instance that is closest to the synthetic patient given a pre-defined probability Pr within lower quantiles. The total number of such pairs are used to measure inliers risk R in defined in Eq. 8.</p><p>R in ¼ j Pair SYN i ; GT j À Á jPr À Á j; i; j 2 f1; ; Sg:</p><p>Outliers-when there is only one real patient instance that is closest to the synthetic patient given a pre-defined probability Pt within upper quantiles. The total number of such pairs are used to measure outliers risk R out defined in Eq. 9.</p><p>R out ¼ j Pair SYN i ; GT j À Á jPt À Á j; i; j 2 f1; ; Sg:</p><p>Ethics. The project was undertaken within the institutional governance framework of the Medicines and Healthcare products Regulatory Agency (MHRA) UK and Brunel University London. The use of real anonymised patient data as ground truth data was undertaken under the CPRD's overarching research ethics committee (REC) approval (reference: 05/ MRE04/87) and within CPRD's secure research environment. Additional advice on privacy of the ground truth data was obtained from the UK Information Commissioner's Office (ICO) Innovation Hub in response to a formal query by the MHRA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reporting summary</head><p>Further information on research design is available in the Nature Research Reporting Summary linked to this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DATA AVAILABILITY</head><p>Access to anonymised patient data from CPRD is subject to a data sharing agreement (DSA) containing detailed terms and conditions of use following protocol approval from CPRD's Independent Scientific Advisory Committee (ISAC). The generated synthetic data set discussed in this paper can also be requested from CPRD subject to a DSA (<ref type="url" target="https://www.cprd.com/content/synthetic-data">https://www.cprd.com/content/synthetic-data</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Resultant graph structure for BNs learnt from samples of ground truth data. Confidences of 100% are represented by black arcs while those &lt;100% are represented by varying widths in grey.</figDesc><graphic coords="3,45.92,59.30,228.02,181.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>[D = 0.027] bmi 0.023 [D = 0.0318] 0.206 [D = 0.068] 0.013 [D = 0.0315] 0.108 [D = 0.071] 0.005 [D = 0.0312] 0.014 [D = 0.069] choleratio 0.012 [D = 0.0793] 0.244 [D = 0.046] 0.011 [D = 0.0796] 0.138 [D = 0.067] 0.009 [D = 0.0795] 0.014 [D = 0.057] sbp 0.074 [D = 0.063] 0.065 [D = 0.063] 0.072 [D = 0.063] 0.064 [D = 0.063] 0.071 [D = 0.063] 0.062 [D = 0.063] sbps 0.082 [D = 0.0340] 0.081 [D = 0.083] 0.080 [D = 0.0358] 0.072 [D = 0.076] 0.042 [D = 0.0348] 0.028 [D = 0.073]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Five-sample sensitivity analyses for a Bayesian generalised linear classifier on GT and SYN data (latent model) for fixed sample size of 100,000, including ROC and PR curves, and AUC and Granger statistics.</figDesc><graphic coords="8,133.46,59.30,337.90,599.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Bayesian network architectures. a A Bayesian network with four nodes. b A Bayesian network classifier with class node C. c A dynamic Bayesian network with two time-slices, t and t-1. d A Hidden Markov model with latent variable H.</figDesc><graphic coords="9,112.88,559.39,360.00,151.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>features for predicting cardiovascular disease from the CPRD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Methods to capture missing data and unmeasured effects. a A binary "Miss Node" pointing to all continuous nodes in a Bayesian network. b A "Miss State" for discrete nodes. c A latent variable with m states to capture Missing Not at Random data and other unmeasured effects (in both discrete and continuous nodes).</figDesc><graphic coords="10,321.39,447.82,228.02,237.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,104.37,59.30,396.00,512.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,55.90,59.30,474.01,433.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Chi-squared p values for the hypothesis of there being a difference in distributions between the GT and SYN data sets for categorical variables.</figDesc><table><row><cell>Variable</cell><cell>Missing deleted</cell><cell>Missingness modelled</cell></row><row><cell></cell><cell>p value</cell><cell>(latent) p value</cell></row><row><cell>strokeha [factor]</cell><cell>0.95</cell><cell>0.36</cell></row><row><cell>af [factor]</cell><cell>0.98</cell><cell>0.48</cell></row><row><cell>atyantip [factor]</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>steroid [factor]</cell><cell>0.50</cell><cell>0.16</cell></row><row><cell>impot [factor]</cell><cell>0.82</cell><cell>0.48</cell></row><row><cell>migr [factor]</cell><cell>0.73</cell><cell>0.16</cell></row><row><cell>ra [factor]</cell><cell>0.40</cell><cell>0.75</cell></row><row><cell>ckidney [factor]</cell><cell>0.90</cell><cell>0.51</cell></row><row><cell>semi [factor]</cell><cell>0.65</cell><cell>0.65</cell></row><row><cell>sle [factor]</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>treathyp [factor]</cell><cell>0.64</cell><cell>0.28</cell></row><row><cell>type1 [factor]</cell><cell>0.51</cell><cell>0.57</cell></row><row><cell>type2 [factor]</cell><cell>0.66</cell><cell>0.27</cell></row><row><cell>ethr [factor]</cell><cell>0.80</cell><cell>0.92</cell></row><row><cell>smoking [factor]</cell><cell>0.84</cell><cell>0.27</cell></row><row><cell>fh_cad [factor]</cell><cell>0.57</cell><cell>0.51</cell></row><row><cell>gender [factor]</cell><cell>0.87</cell><cell>0.89</cell></row><row><cell>region [factor]</cell><cell>0.71</cell><cell>0.28</cell></row><row><cell cols="3">Chi-squared tests comparing distributions between synthetic and ground</cell></row><row><cell cols="2">truth data for categorical variables.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>KS test p values for the hypotheses of numerical variables for GT and SYN data sets are from the same distribution and the associated D statistic of the test.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>The mean squared D KL ðGT i jjGT n i Þ (n ∈ {1…10}) of each variable ending with "gt" and the mean squared D KL ðGT m i Þ SY n Leibler divergence between resampled ground truth data compared to synthetic samples scored against ground truth.</figDesc><table><row><cell>i</cell><cell>Á</cell><cell>(m,n ∈ {1…10}) of</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>KL divergence differences between resampled data sets and synthetic data sets for each variable and associated missing rate in parentheses.</figDesc><table><row><cell>Iteration</cell><cell>diff KL age (0% missing)</cell><cell>diff KL chol (88.47%)</cell><cell>diff KL bmi (15.85%)</cell><cell>diff KL sbp (8.37%)</cell><cell>diff KL sbps (38.25%)</cell></row><row><cell>1</cell><cell>0.002</cell><cell>9.937</cell><cell>4.012</cell><cell>-0.845</cell><cell>0.924</cell></row><row><cell>2</cell><cell>0.002</cell><cell>39.964</cell><cell>0.299</cell><cell>0.227</cell><cell>0.887</cell></row><row><cell>3</cell><cell>0.002</cell><cell>-11.167</cell><cell>9.377</cell><cell>-1.783</cell><cell>0.957</cell></row><row><cell>4</cell><cell>0.002</cell><cell>-11.245</cell><cell>8.328</cell><cell>-0.459</cell><cell>0.354</cell></row><row><cell>5</cell><cell>0.002</cell><cell>4.889</cell><cell>-7.034</cell><cell>-1.683</cell><cell>0.861</cell></row><row><cell>6</cell><cell>0.002</cell><cell>-4.445</cell><cell>8.628</cell><cell>-1.99</cell><cell>0.554</cell></row><row><cell>7</cell><cell>0.002</cell><cell>24.476</cell><cell>3.593</cell><cell>-2.046</cell><cell>0.778</cell></row><row><cell>8</cell><cell>0.002</cell><cell>23.892</cell><cell>6.758</cell><cell>0.294</cell><cell>0.638</cell></row><row><cell>9</cell><cell>0.002</cell><cell>8.528</cell><cell>0.116</cell><cell>-3.019</cell><cell>0.958</cell></row><row><cell>10</cell><cell>0.002</cell><cell>-2.387</cell><cell>9.855</cell><cell>-1.554</cell><cell>0.619</cell></row><row><cell>Mean (SD)</cell><cell>0.002 (0.000)</cell><cell>8.244 (16.863)</cell><cell>4.393 (5.376)</cell><cell>-1.286 (1.065)</cell><cell>0.753 (0.204)</cell></row><row><cell cols="4">Kullback-Leibler divergence differences between resampled ground truth and synthetic data.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Joint</figDesc><table><row><cell cols="4">distribution tests for 2-, 3-, and 4-variable combinations</cell></row><row><cell>using kernel MMD.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Iteration</cell><cell>2-kMMD</cell><cell>3-kMMD</cell><cell>4-kMMD</cell></row><row><cell>1</cell><cell>75.49%</cell><cell>65.50%</cell><cell>56.82%</cell></row><row><cell>2</cell><cell>76.68%</cell><cell>68.44%</cell><cell>61.69%</cell></row><row><cell>3</cell><cell>69.96%</cell><cell>61.10%</cell><cell>53.64%</cell></row><row><cell>4</cell><cell>75.89%</cell><cell>66.57%</cell><cell>58.78%</cell></row><row><cell>5</cell><cell>83.00%</cell><cell>75.21%</cell><cell>68.02%</cell></row><row><cell>6</cell><cell>75.89%</cell><cell>67.25%</cell><cell>59.35%</cell></row><row><cell>7</cell><cell>75.89%</cell><cell>67.08%</cell><cell>58.80%</cell></row><row><cell>8</cell><cell>75.89%</cell><cell>67.65%</cell><cell>58.92%</cell></row><row><cell>9</cell><cell>69.96%</cell><cell>60.42%</cell><cell>53.19%</cell></row><row><cell>10</cell><cell>75.49%</cell><cell>66.12%</cell><cell>57.09%</cell></row></table><note><p>Joint distribution similarity for synthetic and ground truth data. In each iteration, 1000 data instances are sampled from ground truth population of 1 million instances and another 1000 from synthetic data set. The results of H 0 being not rejected are shown in percentages, and average H 0 acceptance rates are 75.42, 66.53, and 58.63%, respectively.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>The risk of seeing clones R clone , inliers N in , and outliers N out in the synthetic data for increasing samples sizes of ground truth data.</figDesc><table><row><cell>GT population size</cell><cell>R clone</cell><cell>R in , Pr = 0.001</cell><cell>R out , Pt = 0.999</cell></row><row><cell>100,000</cell><cell>0.016</cell><cell>462 (0.4620%)</cell><cell>25 (0.0250%)</cell></row><row><cell>200,000</cell><cell>0.013</cell><cell>770 (0.3850%)</cell><cell>34 (0.0170%)</cell></row><row><cell>300,000</cell><cell>0.014</cell><cell>613 (0.2043%)</cell><cell>24 (0.0080%)</cell></row><row><cell>400,000</cell><cell>0.012</cell><cell>553 (0.1383%)</cell><cell>53 (0.0133%)</cell></row><row><cell>500,000</cell><cell>0.016</cell><cell>529 (0.1058%)</cell><cell>19 (0.0038%)</cell></row><row><cell>600,000</cell><cell>0.009</cell><cell>254 (0.0423%)</cell><cell>45 (0.0075%)</cell></row><row><cell>700,000</cell><cell>0.008</cell><cell>534 (0.0763%)</cell><cell>24 (0.0034%)</cell></row><row><cell>800,000</cell><cell>0.011</cell><cell>581 (0.0726%)</cell><cell>13 (0.0016%)</cell></row><row><cell>900,000</cell><cell>0.012</cell><cell>518 (0.0576%)</cell><cell>33 (0.0037%)</cell></row><row><cell>1,000,000</cell><cell>0.012</cell><cell>30 (0.0030%)</cell><cell>45 (0.0045%)</cell></row><row><cell>2,000,000</cell><cell>0.010</cell><cell>78 (0.0039%)</cell><cell>29 (0.0015%)</cell></row></table><note><p>Risk of seeing clones, inliers, and outliers.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>npj Digital Medicine (2020) 147Seoul National University Bundang Hospital 1234567890():,;</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Seoul National University Bundang Hospital npj Digital Medicine (2020) 147</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>npj Digital Medicine (2020) 147Seoul National University Bundang Hospital</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work was supported by a grant awarded to the <rs type="institution">MHRA</rs> from the £10m Regulators' Pioneer Fund launched by The <rs type="funder">Department for Business, Energy and Industrial Strategy (BEIS)</rs> and administered by <rs type="funder">Innovate UK</rs>. The fund enables UK regulators to develop innovation-enabling approaches to emerging technologies and unlock the long-term economic opportunities identified in the government's modern Industrial Strategy.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CODE AVAILABILITY</head><p>All our R code is via Github (<ref type="url" target="https://github.com/zhenchenwang/">https://github.com/zhenchenwang/</ref> latent_model). The R package bnlearn (v4.6.1) is used for all Bayesian network inference. The R function FCI used, which is part of the pcalg package (v2. <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>, to identify latent variables. Kmmd is implemented using the R Package kernlab (v0.9-29).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR CONTRIBUTIONS</head><p>A.T. provided machine learning expertise, oversaw the empirical analysis, and was main editor. Z.W. undertook implementation of all experiments and assisted in the manuscript. Y.R. provided code and expertise on the latent variable experiments using FCI. P.M. provided medical and healthcare data expertise, oversaw the empirical analysis, and assisted in writing the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COMPETING INTERESTS</head><p>The authors declare no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ADDITIONAL INFORMATION</head><p>Supplementary information is available for this paper at <ref type="url" target="https://doi.org/10.1038/s41746-020-00353-9">https://doi.org/10.1038/ s41746-020-00353-9</ref>.</p><p>Correspondence and requests for materials should be addressed to A.T.</p><p>Reprints and permission information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/ reprints</ref> Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Lancet Editorial. Personalised medicine in the UK</title>
	</analytic>
	<monogr>
		<title level="j">Lancet</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Proposed Regulatory Framework for Modification to Artificial Intelligence</title>
		<author>
			<persName><surname>Fda</surname></persName>
		</author>
		<ptr target="https://www.fda.gov/media/122535/download" />
	</analytic>
	<monogr>
		<title level="m">Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">European Union regulations on algorithmic decisionmaking and a right to explanation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Flaxman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1606.08813" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><surname>Bbc</surname></persName>
		</author>
		<ptr target="https://www.bbc.co.uk/news/technology-40483202" />
		<title level="m">Google DeepMind NHS app test broke UK privacy law</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Why a right to explanation of automated decision-making does not exist in the general data protection regulation, International Data Privacy Law</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wachter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mittelstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<ptr target="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2903469" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Data resource profile: Clinical Practice Research Datalink (CPRD) Aurum</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<date type="published" when="1740">1740g-1740g (2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning normalized inputs for iterative estimation in medical image segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Drozdzal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving computer-aided detection using convolutional neural networks and random view aggregation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1170" to="1181" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pulmonary nodule detection in CT images: false positive reduction using multi-view convolutional networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Setio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1160" to="1169" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">PrivBayes: private data release via Bayesian Networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Procopiuc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Database Syst</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The synthetic data vault</title>
		<author>
			<persName><forename type="first">N</forename><surname>Patki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wedge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Veeramachaneni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 3rd International Conference on Data Science and Advanced Analytics (DSAA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="399" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using Bayesian networks to create synthetic data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Penny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Off. Stat</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="549" to="567" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Privacy preserving synthetic data release using deep learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Abay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kantarcioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thuraisingham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint European Conference on Machine Learning and Knowledge Discovery in Databases 510-526 (ECML PKDD</title>
		<meeting>Joint European Conference on Machine Learning and Knowledge Discovery in Databases 510-526 (ECML PKDD</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Neural Information Processing Systems (NIPS 2014)</title>
		<meeting>International Conference on Neural Information essing Systems (NIPS 2014)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
		<respStmt>
			<orgName>NIPS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting discharge mortality after acute ischemic stroke using balanced data</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA Annual Symposium Proceedings 1787-1796</title>
		<imprint>
			<publisher>AMIA</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predicting disease complications using a stepwise hidden variable approach for learning dynamic Bayesian networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yousefi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="106" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SMOTE: synthetic minority over-sampling technique</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. AI Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Why should I trust you?: Explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Right for the right reason: training agnostic networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lansdall-Welfare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lect. Notes Computer Sci</title>
		<imprint>
			<biblScope unit="volume">11191</biblScope>
			<biblScope unit="page" from="164" to="174" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Causation, Prediction, and Search 2nd edn</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A new variable importance measure for random forests with missing data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hapfelmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hothorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ulm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strobl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="21" to="34" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploiting missing clinical data in Bayesian network modeling for predicting medical problems</title>
		<author>
			<persName><forename type="first">J.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Haug</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust learning with missing data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ramoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="147" to="170" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A latent-class mixture model for incomplete longitudinal Gaussian data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Beunckens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Molenberghs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Verbeke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mallinckrodt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="96" to="105" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Achieving k-anonymity privacy protection using generalization and suppression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sweeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Uncertainty Fuzziness Knowl. Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="571" to="588" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">pMSE mechanism: differentially private synthetic data with maximal distributional similarity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Snoke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Slavkovi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1805.09392" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Estimating the success of reidentifications in incomplete datasets using generative models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hendrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>De Montjoye</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-019-10933-3</idno>
		<ptr target="https://doi.org/10.1038/s41467-019-10933-3" />
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">There and back again: outlier detection between statistical reasoning and data mining algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Filzmoser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Data Mining Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1280</biblScope>
			<date type="published" when="2018">2018</date>
			<publisher>Wiley Interdiscip</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Usefulness of total cholesterol/HDL-cholesterol ratio in the management of diabetic dyslipidaemia</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Gimeno-Orna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Faure-Nogueras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sancho-Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Diabet. Med</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="26" to="31" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Contemporary treatment of systemic lupus erythematosus: an update for clinicians</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Amissah-Arthur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ther. Adv. Chronic Dis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="163" to="175" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Patients with overlap autoimmune disease differ from those with &apos;pure&apos; disease</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Lockshin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erkan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lupus Sci. Med</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">84</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Migraine and psychiatric comorbidity: a review of clinical findings</title>
		<author>
			<persName><forename type="first">F</forename><surname>Antonaci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Headache Pain</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="115" to="125" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Smoking cessation for people with severe mental illness (SCI-MITAR+): a pragmatic randomised controlled trial</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gilbody</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet Psychiatry</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="379" to="390" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ethnic group differences in overweight and obese children and young people in England: cross sectional survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arch. Dis. Child</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="30" to="36" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Association between smoking and blood pressure. evidence from the Health Survey for England</title>
		<author>
			<persName><forename type="first">P</forename><surname>Primatesta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hypertension</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="187" to="193" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Effects of cigarette smoking on erectile dysfunction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Kovac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Labbate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ramasamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Lipshultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Andrologia</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1087" to="1092" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">diabetes.org.uk</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>Diabetes</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Blood pressure and ageing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Pinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Postgrad. Med. J</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="109" to="114" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Family history of cardiovascular disease</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Kolber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Scrimshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can. Fam. Physician</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">1016</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Epidemiology of chronic kidney disease in heart failure</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Heart Fail. Clin</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="387" to="399" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title/>
		<ptr target="ons.org.uk" />
	</analytic>
	<monogr>
		<title level="j">Office for National Statistics</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lehmann</surname></persName>
		</author>
		<title level="m">Elements of Large-Sample Theory</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The precision-recall curve overcame the optimism of the receiver operating characteristic curve in rare diseases</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ozenne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Subtil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Maucort-Boulch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="855" to="859" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Events per variable (EPV) and the relative performance of different strategies for estimating the out-of-sample validity of logistic regression models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Steyerberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Methods Med. Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="796" to="808" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning the structure of dynamic probabilistic networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Uncertainty in AI</title>
		<meeting>Uncertainty in AI</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="139" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A tutorial on hidden Markov models and selected applications in speech recognition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="257" to="286" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Predicting cardiovascular risk in England and Wales: prospective derivation and validation of QRISK2</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hippisley-Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="page">332</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Propagating uncertainty in Bayesian networks by probabilistic logic sampling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Henrion</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="149" to="163" />
		</imprint>
	</monogr>
	<note type="report_type">Mach. Intell. Pattern Recogn</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning Bayesian belief networks: an approach based on the MDL principle</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bacchus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Intell</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="269" to="293" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning belief networks in the presence of missing values and hidden variables</title>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="125" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Kernel method for the two-sample-problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems NIPS 513-520</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Precision-recall-gain curves: PR analysis done right</title>
		<author>
			<persName><forename type="first">P</forename><surname>Flach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="838" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Vector autoregressions and causality: a theoretical overview and simulation study</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C B</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econom. Rev</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="259" to="285" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
