<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Molecular Generative Model Based On Adversarially Regularized Autoencoder</title>
				<funder ref="#_Sbx2AB2">
					<orgName type="full">Korea government (MSIT)</orgName>
				</funder>
				<funder>
					<orgName type="full">National Research Foundation of Korea</orgName>
					<orgName type="abbreviated">NRF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-11-13">13 Nov 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Seung</forename><forename type="middle">Hwan</forename><surname>Hong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jaechang</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Seongok</forename><surname>Ryu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Woo</forename><forename type="middle">Youn</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">†Department of Chemistry</orgName>
								<orgName type="institution">KAIST</orgName>
								<address>
									<addrLine>291 Daehak-ro Yuseong-gu</addrLine>
									<postCode>34141</postCode>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">‡KI for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit2">KAIST</orgName>
								<address>
									<addrLine>291 Daehak-ro Yuseong-gu</addrLine>
									<postCode>34141</postCode>
									<settlement>Daejeon</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Molecular Generative Model Based On Adversarially Regularized Autoencoder</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-11-13">13 Nov 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1912.05617v1[physics.chem-ph]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep generative models are attracting great attention as a new promising approach for molecular design. All models reported so far are based on either variational autoencoder (VAE) or generative adversarial network (GAN). Here we propose a new type model based on an adversarially regularized autoencoder (ARAE). It basically uses latent variables like VAE, but the distribution of the latent variables is obtained by adversarial training like in GAN. The latter is intended to avoid both inappropriate approximation of posterior distribution in VAE and difficulty in handling discrete variables in GAN. Our benchmark study showed that ARAE indeed outperformed conventional models in terms of validity, uniqueness, and novelty per generated molecule.</p><p>We also demonstrated successful conditional generation of drug-like molecules with ARAE for both cases of single and multiple properties control. As a potential realworld application, we could generate EGFR inhibitors sharing the scaffolds of known active molecules while satisfying drug-like conditions simultaneously.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>One of the prime goals of chemistry is to make novel molecules with desired properties for various purposes. Inspired by the great success of deep generative models in computer vision tasks, 1,2 molecular generative models have emerged as a new promising approach for efficient molecular design. <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4</ref> Diverse models have been proposed for materials design and de novo drug design with promising results. <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref> Their key idea is to estimate the distribution of molecules for a specific purpose and then to sample unseen molecules with target properties from the estimated distribution. So far, generative adversarial networks (GANs) <ref type="bibr" target="#b1">2</ref> and latent variable models have been widely used for that purpose. GANs directly estimate the distribution of true input data by adversarial training of a generator and a discriminator. On the other hand, latent variable models such as variational autoencoders (VAEs) 1 estimate the distribution of latent variables corresponding to input data and generate new molecules by decoding latent variables sampled. Furthermore, one can incorporate desired properties directly in the generation process by estimating the conditional distribution of molecules involving specific target properties.</p><p>For instance, ChemicalVAE 5 is one of the latent variable models. Its latent space is jointly trained with a deep neural network for prediction of a target property. As a result, molecules with desired properties can be designed by optimizing the target property on the latent space.</p><p>The feasibility of molecular generative model demonstrated by ChemicalVAE triggered the active development of various models with similar concepts. <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21</ref> However, VAE-based models often produce unnatural molecules, leading to the low validity of generated molecules. <ref type="bibr" target="#b10">11</ref> That might be because a unknown posterior distribution is approximated by a given family of surrogate distributions, but inappropriate approximation can cause latent variables being decoded to unnatural molecules. Since GANs directly estimate the distribution of true input data via adversarial training, they can avoid limitations arisen from such an approximation. ORGAN <ref type="bibr" target="#b16">17</ref> and MolGAN 11 are prototypes of GAN-based molecular generative models. Indeed, GAN-based models show much improved validity. In contrast to computer vision tasks, however, molecular structures are expressed by the discrete categorical representation of atomic symbols. GAN-based models are troublesome to deal with such a discrete variable because of difficulty in estimating their distribution. As a result, molecules generated by ORGAN and MolGAN were not diverse, leading to low uniqueness.</p><p>Having considered the above facts, it seems desirable to selectively take each advantage of GAN-and VAE-based models to accomplish both high validity and uniquness. For this purpose, we propose to use the platform of adversarially regularized autoencoder (ARAE) <ref type="bibr" target="#b21">22</ref> for molecular design. This model is grounded on the spirit of latent variable models that transform the discretized input of molecular structures to continuous latent representations.</p><p>The key distinct feature of this model is to adopt the adversarial training used in GANs to estimate the distribution of latent variables, which makes it avoid the problem caused by the posterior approximation. As a result, one can achieve a high valid rate as well as high uniqueness in molecular generation. For conditional generation, we disentangle the information of molecular properties from latent vectors. Then, the target molecular properties are injected independently with latent vectors into the decoder. Thus, we could produce unseen molecules having the designated molecular properties with a high success rate.</p><p>We demonstrate the usefulness of our model with the following examples:</p><p>• We verify the high performance of our model in estimating a latent vector distribution by showing the validity, uniqueness, and novelty of generated molecules. We also test smoothness of latent space by interpolating between two vectors in the latent space.</p><p>• We show the feasibility of the simultaneous control of multiple properties with a high success rate.</p><p>• As a possible practical application, we demonstrate that our model can be used for de novo design of hit compounds in drug discovery with the example of epidermal growth factor receptor (EGFR) inhibitors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Previous works</head><p>To compare ARAE with GAN and VAE and its technical advantages for molecular applications, we briefly introduce about each method. Then, we describe our implementation of the ARAE modified for molecular generations in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative adversarial network</head><p>GANs 2 estimate the distribution of input samples, p r (x), through the adversarial training of a generator network and a discriminator network. By taking a random variable s drawn from a prior distribution p(s), the generator g ψ parameterized by ψ produces new samples g ψ (s) of the distribution p g (x). To estimate the distribution of true data by generating samples with the generator, Wassestein GAN is used to minimize the gap between the true and generated distributions (p r (x) and p g (x), respectively). <ref type="bibr" target="#b22">23</ref> Thus, the training objective is given by min ψ W(p r , p g ) = min</p><formula xml:id="formula_0">ψ max w E x∼pr(x) [f w (x)] -E s∼p(s) [f w (g ψ (s))],<label>(1)</label></formula><p>where f w is a discriminator (critic) function parameterized by w satisfying the 1-Lipschtiz continuity f w ≤ 1. As a result of the adversarial training of these two networks, the distributions of data samples p r (x) and of generated samples p g (x) become equivalent, i.e., p r (x) = p g (x).</p><p>Learning discretized representations such as molecular structures with GANs often fails because outputs can be easily degenerated into training data. <ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24</ref> This drawback causes low efficiency for the generation of unseen molecules with GAN-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variational autoencoder</head><p>Instead of directly modeling the distribution of input data, latent variable models infer the distribution of latent variables (the posterior). However, it is intractable to find an exact posterior distribution in most cases. VAEs approximate the posterior distribution with the variational distribution q θ (z|x) which is an output of the encoder parameterized with θ,</p><p>given an input x, and the decoder parameterized by φ reconstructs the inputs from the latent variables drawn from the posterior. <ref type="bibr" target="#b0">1</ref> The minimization objective of VAEs is given by min θ,φ</p><formula xml:id="formula_1">E x∼pr(x) [L rec (θ, φ) + KL(q θ (z|x)||p(z))],<label>(2)</label></formula><p>where L rec (θ, φ) = E q θ (z|x) [-log p φ (x|z)] is the reconstruction loss and KL(q θ (z|x)||p(z)) is the Kullback-Leiber (KL) divergence between the variational distribution q θ (z|x) and the prior distribution p(z). Minimizing the second term makes the two distributions as similar as possible. Hence, the posterior distribution can be approximated by imposing it on the prior distribution.</p><p>Since VAEs approximate the posterior distribution with a predefined prior (a surrogate family of distributions), they can readily estimate the distribution of latent variables. However, the drawback of using the VAEs is well-known; a latent space can have holes in which latent vectors are not matched to true data points. <ref type="bibr" target="#b24">25</ref> That causes the generation of chemically unrealistic molecules. <ref type="bibr" target="#b4">5</ref> The main reasons of the hole existing problem are as follows.</p><p>First, the true posterior distribution may not be well approximated by a given prior, such as a normal distribution. Second, minimizing the KL-divergence between two distributions is not suitable if the posterior distribution is multi-modal. <ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27</ref> In such cases, using VAEs may not be a good approach to model a latent variable distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adversarially regularized autoencoder</head><p>The ARAE method was proposed to address the aforementioned problems of the GANs and the VAEs. <ref type="bibr" target="#b21">22</ref> It is basically a latent variable model which adopts an encode-decoder architecture, but the posterior distribution is estimated by adversarial training. The encoder network parameterized by θ outputs the distribution of true latent variables z = enc θ (x) ∼ p θ (z) from the given inputs. The decoder network parameterized by φ reconstructs the input from the latent variable drawn from the posterior. By following the idea of GANs, the generator parmeterized by ψ outputs the distribution of generated random variables z = g ψ (s) ∼ p ψ (z), where s is a random variable drawn from the prior distribution p(s). Since ARAE aims to estimate the posterior distribution by generating a similar distribution with that of the generator, the training objective is given by min θ,φ,ψ</p><formula xml:id="formula_2">E x∼pr(x) [L rec (θ, φ) + W(p θ (z), p ψ (z))],<label>(3)</label></formula><p>where the reconstruction loss is written as</p><formula xml:id="formula_3">L rec (θ, φ) = E z∼p θ (z) [-log p φ (x|z)]<label>(4)</label></formula><p>and the Wasserstein-1 distance between the two distributions is written as</p><formula xml:id="formula_4">W(p θ (z), p ψ (z)) = max w E z∼p θ (z) [f w (z)] -E z∼p ψ (z) [f w (z)],<label>(5)</label></formula><p>with the 1-Lipschtiz continuity f w ≤ 1. As a result of training, the two distributions p θ and p ψ become identical, and we can generate new samples by using random variables sampled from p ψ as an input to the decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>We devised a new type of molecular generative model by adopting the architecture of ARAE.</p><p>The SMILES representation of molecular structure is adopted as a discrete random variable input to the model. The raw input is first transformed to the latent representation, and its distribution is estimated by adversarial training. As we discussed in the previous section, this approach has the following advantages. First, it can avoid the hole-generating problem appeared in VAEs by estimating the posterior through adversarial training. As a result, the The predictor is trained to predict an original molecular property y and separate this information from the latent vector by minimizing the mutual information term in eq. ( <ref type="formula" target="#formula_6">7</ref>). In decoding phase, the specified property information y c is incorporated together with the latent vector to generate the molecules with specific desired property.</p><p>valid rate of generated molecules is expected to be high. Second, it improves a low learning ability of GANs for discrete representation like SMILES by using continuous latent variables in the adversarial training.</p><p>In addition, we introduced an efficient conditional generation scheme of molecules. The key idea of conditional generative model is to estimate the distribution of data samples as latent vectors and conditions are jointly given: p(x|z, y c ). However, the latent vectors, which are supposed to correspond to molecular structures, would not be independent from target molecular properties. To control the target properties and structures in parallel, therefore, we design a model so as to disentangle the property information from the latent vectors. To do so, we jointly minimize the mutual information MI(z, y; θ, λ) which means the amount of the information of a target property y obtained from the latent vector z. Since an exact value of the mutual information is not known, we compute the variational mutual information <ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29</ref> given by</p><formula xml:id="formula_5">MI(z, y; θ, λ) = H(y) -H(y|z) = E z∼p θ (z) [E y∼p(y|z) log p(y|z)] + H(y) = E z∼p θ (z) [KL(p(y|z)||q λ (y|z)) + E y∼p(y|z) [log q λ (y|z)]] + H(y) ≥ E z∼p θ (z) [E y∼p(y|z) [log q λ (y|z)]] + H(y),<label>(6)</label></formula><p>where H(y) denotes the marginal entropy, H(y|z) is the joint entropy of y and z, and q λ (y|z)</p><p>is the auxiliary conditional distribution of y for the given z, which is estimated by the predictor parameterized by λ. As done in the previous work, <ref type="bibr" target="#b28">29</ref> we also consider H(y) as a constant. Therefore, we set the training objective as follows:</p><formula xml:id="formula_6">min θ,φ,ψ E x∼pr(x) [L rec (θ, φ) + W(p θ (z), p ψ (z)) + VMI(y, z; θ, λ)],<label>(7)</label></formula><p>where VMI(y, z; θ, λ) = max λ E z∼p θ (z) [E y∼p(y|z) [log q λ (y|z)]]. We note that minimizing the third term makes the property information separated from the latent vector. In the decoding phase, the target property information y c , which acts as a condition vector for the reconstruction of molecules, is given together with the latent vector of query molecule z. As a result, molecules with designated properties can be generated with independent structural control. We term this model as 'conditional ARAE (CARAE)' hereafter.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> illustrates the architecture of the CARAE model for molecular generations.</p><p>SMILES seqeunces are transformed by the encoder into latent variables. The generator produces new samples by taking random variables from a distribution N (0, σ 2 I). Then, the distributions of those two variables become as similar as possible by minimizing the first and the second term of eq. ( <ref type="formula" target="#formula_6">7</ref>) with gradient descent optimization. For the CARAE model, we add the predictor network which is used to estimate the variational mutual information term, the third term in eq. ( <ref type="formula" target="#formula_6">7</ref>). In the training phase, the decoder reconstructs input molecular structures from the latent vector and property information of input molecules. In the test phase, we can sample new molecules by tuning the latent vector which is drawn from p ψ (z)</p><p>and by specifying the desired property y c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>To train and test our model, we used the QM9 and ZINC datasets. The QM9 set contains 133,885 small organic molecules with up to nine heavy atoms. <ref type="bibr" target="#b29">30</ref> The ZINC set used in this work is same with that used in training ChemicalVAE, <ref type="bibr" target="#b4">5</ref> which consists of 249,455 molecules randomly selected from the drug-like subset of the ZINC database. <ref type="bibr" target="#b30">31</ref> Before explaining experimental results, we introduce the metrics used to evaluate the performance of our model as follows:</p><p>• Validity: the ratio of the number of valid molecules to the number of generated samples. The validity was checked by using RDKit. <ref type="bibr" target="#b31">32</ref> • Uniqueness: the ratio of the number of unrepeated molecules to the number of valid molecules.</p><p>• Novelty: the ratio of the number of molecules which are not included in the training set to the number of unique molecules.</p><p>• Novel/Sample: the ratio of the number of valid, unique, and novel molecules to the total number of generated samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance of ARAE on molecular generation</head><p>Training a generative model based on GANs is often unstable. Hence, we first investigated using the QM9 dataset how each evaluation metric changes as the training of our model progresses. After each epoch, 10,000 samples were generated, and the four metrics (validity, uniqueness, novelty, and novel/sample) were calculated. Figure <ref type="figure" target="#fig_1">2</ref> shows the result of the first  We also compare the performance of ARAE to those of ChemicalVAE, 5 GrammarVAE, <ref type="bibr" target="#b19">20</ref> GraphVAE, <ref type="bibr" target="#b32">33</ref> and MolGAN. <ref type="bibr" target="#b10">11</ref> For an input molecular representation, ChemicalVAE and GrammarVAE used SMILES, while GraphVAE and MolGAN adopted molecular graphs.</p><p>Table <ref type="table" target="#tab_0">1</ref> summarizes the validity, uniqueness, novelty, and novel/sample of each model. All the models were trained by using the QM9 dataset. Overall, ARAE outperformed the others except for novelty. As intended, it significantly improved the validity and uniqueness from those of the VAEbased and MolGAN models, respectively, by taking the advantages of both methods. The relative low novelty value is due to the low chemical diversity of the QM9 dataset in which molecules are composed of less than ten heavy atoms. This limited number of heavy atoms restricts opportunities to generate novel molecules. On the other hand, ARAE could achieve high novelty for the ZINC dataset (the bottom low of Table <ref type="table" target="#tab_0">1</ref>), because the ZINC dataset spans a huge chemical space. This result further supports the reason of the low novelty of ARAE for QM9. Though MolGAN also adopted the adversarial training, it showed a high novelty value but by sacrificing the uniqueness, meaning that a high value on one metric can be achieved by sacrificing the others. Therefore, the ratio of novel molecules among generated samples (novelty/sample) is a more practical metric for performance comparison. Models using graph representation showed relatively higher novel/sample values than models using SMILES. ARAE achieved the highest value of novel/sample in spite of using the SMILES representation.</p><p>One of the major drawbacks of VAE-based generative models is the presence of holes in the latent space due to the approximated posterior, resulting in low validity as noted in Table <ref type="table" target="#tab_0">1</ref>. This problem can often cause the generation of unrealistic molecules at interpolation points between two latent vectors. In contrast, adversarial training does not impose any analytic form of the posterior. Therefore, it is expected that ARAE can avoid such a problem.</p><p>To demonstrate the successful modeling of latent space with the adversarial training, we attempted to generate molecules through an interpolation experiment as shown in Figure <ref type="figure" target="#fig_2">3</ref>. We obtained 100 latent vectors by linearly interpolating the two seed vectors obtained from Aspirin s a and Tamiflu s b . Then, each sampled vector was decoded to generate the corresponding molecule. All the 100 latent vectors successfully generated valid molecules, and 19 molecules out of them were unique and novel. Figure <ref type="figure" target="#fig_2">3</ref> exhibits 6 examples showing smooth change from Aspirin to Tamiflu. We also note that high-membered ring molecules which often appear in VAE-based molecular generative models <ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b19">20</ref> were not produced by our model. In this section, we examine the performance of our model for conditional generation of molecules. First, we tested that CARAE can generate molecules with high validity, uniqueness, novelty, and diversity as ARAE does. The performance of CARAE may depend on designated property values, so we compared the performance of CARAE for both random property values and certain designated ones. Three properties (logP, SAS, and TPSA) were controlled simultaneously. Table <ref type="table" target="#tab_1">2</ref> summarizes the validity, uniqueness, novelty, and diversity of ARAE and CARAE, where both models were trained using the ZINC dataset. CARAE shows comparable performance with that of ARAE except for the high SAS value (5.0). Since the SAS value is related to synthetic accessibility and structural stability, the frequency of valid molecules would be low at a high SAS value. The high success rates of the conditional generation are an evidence that the latent space was well separated from multiple target properties, and hence one can readily control molecular structures under given fixed multiple conditions.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conditional generation of molecules with CARAE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>de novo design of EGFR inhibitors</head><p>Molecular generative models have attracted attention as a promising solution for de novo molecular design for new drugs or materials. To demonstrate the utility of our model, we applied it to designing novel inhibitors of an epidermal growth factor receptor (EGFR). We obtained active and decoy molecules from the DUD-E database and trained the CARAE model with four target properties: activity against EGFR, logP, TPSA, and SAS. Inhibitors were then generated according to the following two scenarios:</p><p>• Generation with only activity condition: activity = 1. We aimed to generate EGFRactive molecules only.</p><p>• Generation with the four conditions: activity = 1, logP = 2.5, SAS = 1.5, and TPSA = 60. It was intended to generate molecules satisfying the Lipinski's rule of five 34 and synthesizability. We could successfully generate new candidate molecules while satisfying drug-like conditions simultaneously.</p><p>Consequently, we believe that ARAE can be a new platform for AI-based molecular design in various chemical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation details</head><p>We summarize the configuration of our model in Table <ref type="table" target="#tab_2">3</ref>. Each of the encoder and the decoder is composed of a single LSTM layer, and the dimensionality of outputs is 300. The LSTM layer of the encoder reads sequential SMILES strings and transforms them to latent vectors.</p><p>For adversarial training, we use two fully-connected layers with a hidden dimension of 300 for ZINC (200 for QM9) for the generator and the discriminator networks. The predictor network is also composed of two fully-connected layers with a hidden dimension 300 for ZINC (200 for QM9). We uploaded our code on github <ref type="url" target="https://github.com/gicsaw/ARAE_SMILES">https://github.com/gicsaw/ARAE_SMILES</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: The architecture of CARAE for molecular generations. The encoder embeds the SMILES representation of molecular structure x to the latent vector z, and the decoder reconstructs the molecular structures from the latent vector. As a result of the adversarial training, two distributions p θ (z) and p ψ (z) become equivalent. The predictor is trained to predict an original molecular property y and separate this information from the latent vector by minimizing the mutual information term in eq. (7). In decoding phase, the specified property information y c is incorporated together with the latent vector to generate the molecules with specific desired property.</figDesc><graphic coords="7,191.34,72.00,229.31,140.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Convergence of the four evaluation metrics for the ARAE model trained with the QM9 dataset.</figDesc><graphic coords="10,193.68,72.00,224.63,168.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Molecules reconstructed from the latent vectors that appeared in the interpolation among two latent vectors. The starting and ending points are the latent vectors of Aspirin and Tamiflu, respectively.</figDesc><graphic coords="11,83.70,72.00,444.60,122.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Distributions of molecular property -(a) logP, (b) SAS and (c) TPSA -when molecules are generated by specifying a desired property. Note that the curves labeled with ZINC denote the distribution of each molecular property in the ZINC dataset.</figDesc><graphic coords="12,83.70,346.08,444.59,136.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4</head><label>4</label><figDesc>Figure 4 compares the normalized frequency of the conditionally-generated molecules for each property and the natural population of the ZINC set molecules; molecular properties for both cases were computed by RDKit. The logP values of the generated molecules were well localized around the designated values denoted in each panel. The SAS and TPSA valuesshowed relatively broader distributions, but compared to the natural populations, they were also very localized around the given targets. Figure5shows the distributions of molecules</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Joint distribution of the logP, SAS and TPSA values of molecules generated with the simultaneous control of the three target properties denoted in the legend.</figDesc><graphic coords="14,193.68,148.04,224.64,163.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Five generated EGFR inhibitors (A) without additional condition and (B) with additional condition of 'logP = 2.5, SAS = 1.5 and TPSA = 60'.</figDesc><graphic coords="15,76.68,72.00,458.65,194.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance of benchmark models and our model for the QM9 dataset. Baseline results are taken from De Cao et al.<ref type="bibr" target="#b10">11</ref> We also show the performance of our model for the ZINC dataset in the bottom row.</figDesc><table><row><cell>Method</cell><cell cols="4">Validity (A) Uniqueness (B) Novelty (C) Novel/Sample (A×B×C)</cell></row><row><cell>ChemicalVAE</cell><cell>0.103</cell><cell>0.675</cell><cell>0.900</cell><cell>0.063</cell></row><row><cell>GrammarVAE</cell><cell>0.602</cell><cell>0.093</cell><cell>0.809</cell><cell>0.045</cell></row><row><cell>GraphVAE</cell><cell>0.557</cell><cell>0.670</cell><cell>0.616</cell><cell>0.261</cell></row><row><cell>GraphVAE/imp</cell><cell>0.562</cell><cell>0.520</cell><cell>0.758</cell><cell>0.179</cell></row><row><cell>GraphVAE NoGM</cell><cell>0.810</cell><cell>0.241</cell><cell>0.610</cell><cell>0.129</cell></row><row><cell>MolGAN</cell><cell>0.981</cell><cell>0.104</cell><cell>0.942</cell><cell>0.096</cell></row><row><cell>ARAE</cell><cell>0.862</cell><cell>0.935</cell><cell>0.371</cell><cell>0.299</cell></row><row><cell>ARAE (ZINC)</cell><cell>0.903</cell><cell>1.000</cell><cell>1.000</cell><cell>0.903</cell></row><row><cell cols="5">80 epochs. All evaluation metrics were smoothly converged, indicating that common difficul-</cell></row><row><cell cols="5">ties in training GANs such as mode collapse or diminished gradient are less problematic in</cell></row><row><cell>our model.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of ARAE and CARAE trained with ZINC dataset. The diversity of the ZINC testset is 0.915. In this work, we disentangled the information of molecular properties (logP, SAS and TPSA) from latent vectors and incorporated target properties in it later as a condition vector, y c . † For the 'CARAE, random', we randomly chose molecular property values and incorporated them in the latent vectors of molecules in the ZINC dataset. ‡ For the 'CARAE, (•, •, •)', we used molecular property values drawn from a Gaussian distribution N (•, 1.0).</figDesc><table><row><cell cols="5">Method and Condition Validity Uniqueness Novelty Diversity</cell></row><row><cell>ARAE</cell><cell>0.903</cell><cell>1.000</cell><cell>1.000</cell><cell>0.909</cell></row><row><cell>CARAE, random  †</cell><cell>0.812</cell><cell>1.000</cell><cell>1.000</cell><cell>0.911</cell></row><row><cell>CARAE, (1.5, 2.0, 30)  ‡</cell><cell>0.897</cell><cell>0.926</cell><cell>0.998</cell><cell>0.894</cell></row><row><cell>CARAE, (1.5, 2.0, 100)</cell><cell>0.823</cell><cell>0.996</cell><cell>1.000</cell><cell>0.890</cell></row><row><cell>CARAE, (1.5, 5.0, 30)</cell><cell>0.860</cell><cell>0.997</cell><cell>1.000</cell><cell>0.914</cell></row><row><cell>CARAE, (1.5, 5.0, 100)</cell><cell>0.573</cell><cell>1.000</cell><cell>1.000</cell><cell>0.909</cell></row><row><cell>CARAE, (4.5, 2.0, 30)</cell><cell>0.908</cell><cell>0.995</cell><cell>1.000</cell><cell>0.900</cell></row><row><cell>CARAE, (4.5, 2.0, 100)</cell><cell>0.813</cell><cell>1.000</cell><cell>1.000</cell><cell>0.884</cell></row><row><cell>CARAE, (4.5, 5.0, 30)</cell><cell>0.621</cell><cell>1.000</cell><cell>1.000</cell><cell>0.912</cell></row><row><cell>CARAE, (4.5, 5.0, 100)</cell><cell>0.293</cell><cell>1.000</cell><cell>1.000</cell><cell>0.911</cell></row><row><cell cols="5">We investigated how accurate the target properties of molecules generated by CARAE</cell></row><row><cell cols="5">are. The conditional generator produced 10,000 molecules with a given target property.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Configuration of the model used in this work. Note that the predictor is only used for conditional generations with CARAE.</figDesc><table><row><cell></cell><cell>Layer configuration</cell><cell cols="3">Nonlinearity Dimension (QM9) Dimension (ZINC)</cell></row><row><cell>Encoder</cell><cell>One LSTM layer</cell><cell>-</cell><cell>200</cell><cell>300</cell></row><row><cell>Decoder</cell><cell>One LSTM layer + Softmax layer</cell><cell>-</cell><cell>200</cell><cell>300</cell></row><row><cell>Generator</cell><cell>Two fully-connected layers</cell><cell>ReLU</cell><cell>200</cell><cell>300</cell></row><row><cell>Discriminator</cell><cell>Two fully-connected layers</cell><cell>LReLU</cell><cell>200</cell><cell>300</cell></row><row><cell>Predictor</cell><cell>Two fully-connected layers</cell><cell>ReLU</cell><cell>-</cell><cell>300</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>describes the hyperparameters and the optimizers of ARAE.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Optimizers and prarameters of ARAE.</figDesc><table><row><cell></cell><cell cols="3">Variable parameters Optimizer Learning rate</cell></row><row><cell>Auto-Encoder</cell><cell>Encoder and Decoder</cell><cell>SGD</cell><cell>1.0</cell></row><row><cell>Generator</cell><cell>Generator</cell><cell>Adam</cell><cell>1.0 × 10 -5</cell></row><row><cell>Critic</cell><cell>Critic</cell><cell>Adam</cell><cell>2.0 × 10 -6</cell></row><row><cell>Predictor</cell><cell>Predictor</cell><cell>Adam</cell><cell>1.0</cell></row><row><cell>Disentanglement</cell><cell>Encoder</cell><cell>Adam</cell><cell>1.0</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="funder">National Research Foundation of Korea (NRF)</rs> grant funded by the <rs type="funder">Korea government (MSIT)</rs>(<rs type="grantNumber">NRF-2017R1E1A1A01078109</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Sbx2AB2">
					<idno type="grant-number">NRF-2017R1E1A1A01078109</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p>J.L., S.R. and W.Y.K. conceived the idea, J.L. and S.H.H. did the implementation and run the simulation. All the authors analyzed the results and wrote the manuscript together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of interest</head><p>The authors declare no competing financial interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graphical TOC Entry</head><p>Some journals require a graphical entry for the Table of Contents. This should be laid out "print ready" so that the sizing of the text is correct. Inside the tocentry environment, the font used is Helvetica 8 pt, as required by Journal of the American Chemical Society. The surrounding frame is 9 cm by 3.5 cm, which is the maximum permitted for Journal of the American Chemical Society graphical table of content entries. The box will not resize if the content is too big: instead it will overflow the edge of the box. This box and the associated title will always be printed on a separate page at the end of the document.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="2672" to="2680" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The rise of deep learning in drug discovery</title>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Engkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olivecrona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blaschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discovery Today</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1241" to="1250" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Inverse molecular design using machine learning: Generative models for matter engineering</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sanchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">361</biblScope>
			<biblScope unit="page" from="360" to="365" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic chemical design using a data-driven continuous representation of molecules</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gómez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sánchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sheberla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS central science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generating focused molecule li-braries for drug discovery with recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Segler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kogej</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tyrchan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Waller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACS central science</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="120" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for de novo drug design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Popova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Isayev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tropsha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science advances</title>
		<imprint>
			<biblScope unit="page" from="4" to="7885" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Molecular generative model based on conditional variational autoencoder for de novo molecular design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.05805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multi-Objective De Novo Drug Design with Conditional Graph Generative Model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07299</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02473</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Molgan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11973</idno>
		<title level="m">An implicit generative model for small molecular graphs</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative Recurrent Networks for De Novo Drug Design</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Huisman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular Informatics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improving Chemical Autoencoder Latent Space and Molecular De Novo Generation Diversity with Heteroencoders</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bjerrum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sattarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomolecules</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">131</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian molecular design with a chemical language model</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ikebata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hongo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Isomura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Maezono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Aided Molecular Design</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="379" to="391" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Conditional Molecular Design with Deep Generative Models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chemical Information and Modeling</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="43" to="52" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Entangled Conditional Adversarial Autoencoder for de Novo Drug Discovery</title>
		<author>
			<persName><forename type="first">D</forename><surname>Polykovskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhebrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ivanenkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aladinskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mamoshina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bozdaganyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aliper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhavoronkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kadurin</surname></persName>
		</author>
		<idno type="PMID">30180591</idno>
	</analytic>
	<monogr>
		<title level="j">Molecular Pharmaceutics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="4398" to="4405" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Objective-reinforced generative adversarial networks (ORGAN) for sequence generation models</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Guimaraes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sanchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Outeiral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L C</forename><surname>Farias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10843</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Molecular De Novo Design through Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Olivecrona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blaschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Engkvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cheminformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design</title>
		<author>
			<persName><forename type="first">D</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Segler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guasch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Plumbley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sellwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Grammar Variational Autoencoder</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1945" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conditional molecular design with deep generative models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical informatiion and modeling</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04223</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Adversarially Regularized Autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Wasserstein</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><surname>Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Gans for sequences of discrete elements with the gumbel-softmax distribution</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04051</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">B. Adversarial autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<title level="m">NIPS 2016 tutorial: Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The IM algorithm: a variational approach to information maximization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B F</forename><surname>Agakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">201</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="2172" to="2180" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Dral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Von Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scientific data 2014</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">140022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">ZINC: a free tool to discover chemistry for biology</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Irwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sterling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mysinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Bolstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Coleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and modeling</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1757" to="1768" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">RDKit: Open-source cheminformatics</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">GraphVAE: Towards Generation of Small Graphs Using Variational Autoencoders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03480</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Experimental and computational approaches to estimate solubility and permeability in drug discovery and development settings1PII of original article: S0169-409X(96)00423-1. The article was originally published in Advanced</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Lipinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lombardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Dominy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Feeney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Special issue dedicated to Dr</title>
		<imprint>
			<date type="published" when="1991">1997. 2001. 1991-1998</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
	<note>Eric Tomlinson. Advanced Drug Delivery Reviews, A Selection of the Most Highly Cited Articles</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Properties of Known Drugs. 1. Molecular Frameworks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Bemis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Murcko</surname></persName>
		</author>
		<idno type="PMID">8709122</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Medicinal Chemistry</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2887" to="2893" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
