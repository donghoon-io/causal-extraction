<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ESTIMATING AND TESTING RANDOM INTERCEPT MULTILEVEL STRUCTURAL EQUATION MODELS WITH MODEL IMPLIED INSTRUMENTAL VARIABLES</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">L</forename><surname>Giordano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kenneth</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">J</forename><surname>Bauer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Gates</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Andrea</forename><forename type="middle">M</forename><surname>Hussong</surname></persName>
						</author>
						<title level="a" type="main">ESTIMATING AND TESTING RANDOM INTERCEPT MULTILEVEL STRUCTURAL EQUATION MODELS WITH MODEL IMPLIED INSTRUMENTAL VARIABLES</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Estimating and testing random intercept multilevel structural equation models with model implied instrumental variables (Under the direction of Kenneth A. Bollen) Multilevel Structural Equation Modeling (MSEM) is an advanced statistical framework that combines the strengths of traditional Multilevel Modeling (MLM) and Structural Equation Modeling (SEM) allowing for both latent variables and hierarchically clustered data. The most common estimator for MSEMs is Maximum Likelihood (ML) applied to the entire model simultaneously. ML offers desirable asymptotic properties (e.g., consistency, asymptotic efficiency) for valid models. However, ML requires strong assumptions such as correct model specification and no excessive multivariate kurtosis (Browne, 1984). If these assumptions are violated, there is no guarantee about the usual statistical properties. Despite ML's properties and</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>flexibility there may be circumstances when alternative estimators would be beneficial.</p><p>The current study develops a limited information estimator for random intercept MSEMs. This estimator is based on the Model Implied Instrumental Variable Two-Stage Least Squares (MIIV-2SLS) estimator, which has been shown to be an excellent alternative to ML in single level SEMs <ref type="bibr" target="#b20">(Bollen, 1996)</ref>. After adapting the usual MIIV-2SLS procedure for the MSEM model, the current study examines the finite sample properties via two Monte Carlo Simulations.</p><p>In the first simulation, both ML and MIIV-2SLS are used to estimate MSEMs with and without structural misspecification. Results suggest that MIIV-2SLS is robust to the spread of misspecification within levels and between levels. Further, MIIV-2SLS has accurate standard errors and the ability to test individual equations for misspecification based on the Sargan Test.</p><p>The second simulation examines model fit testing by comparing the Sargan Test to ML based chi-square fit statistics. Results show that the Sargan test is sensitive to misspecification at both levels of the model with traditional fit statistics are only sensitive to misspecification in level 1.</p><p>The power of the Sargan test is depends on the type of misspecification and the sample size.</p><p>Finally, this study examines an empirical application testing the relation between the latent variables of Math Confidence and Math Achievement using data from the Trends in International Mathematics and Sciences Study (TIMSS) 2003 international database. The application demonstrates many of the useful properties of MIIV-2SLS side-by-side with ML.</p><p>Overall results of the simulation and empirical data analysis suggest that MIIV-2SLS is a useful alternative to ML for estimating MSEMs. v ACKNOWLEDGEMENTS I owe a great deal of gratitude to the many people who have supported me throughout my education, particularly during my time in graduate school. I am fortunate to be surrounded by supportive family, friends/colleagues, and faculty.</p><p>I would like to thank my parents, Jan and Pete who taught me to be curious and always supported my educational endeavors. Completing my doctorate in Psychology-from UNC, no less-was as close to "joining the family business" as I could get.</p><p>I would like to thank the many UNC faculty who have supported me throughout this journey. Two faculty in particular stand out: Mitch Prinstein and Ken Bollen. I was given the opportunity to join Mitch's lab-the peer relations lab-as a sophomore at UNC. It is an understatement to suggest that Mitch's mentorship has been a major factor in my journey. As a graduate student I have been fortunate to have been advised by Ken. Without his support and mentoring I would not be where I am today. There are many more faculty who have supported me in important ways. Among them are Dan Bauer, Patrick Curran, Andrea Hussong, Dave Thissen, Katie Gates, and Oscar Gonzalez.</p><p>I would like to thank my Chapel Hill friends and fellow students in the L.L. Thurstone Psychometric Lab. I gained many lasting friendships during my time in Chapel Hill-they made life enjoyable even during the periods when school was the most stressful. Perhaps more than anyone else, I own many thanks to my fellow lab mate Zack Fisher. Zack was both a colleague vi and a friend. His deep knowledge and willingness to help kept me afloat many times during my graduate school tenure.</p><p>Finally, I would like to offer my eternal love and gratitude to my wife Carly, who I met while in graduate school. The latter years of my doctorate were some of the most memorable and meaningful. That is no doubt because I found someone to share life with. Thank you for your endless support. For listening when I was frustrated. For telling me when I needed to take a break. For reminding me there was life outside of school. I could not have done this without you.   Clustering, such as the example of students within classrooms, complicates statistical analyses because observations within a cluster are inherently related to one another in a systematic or non-random way. For example, two students in the same honors class are more likely to share higher than average aptitude. This feature-that members of the same cluster are likely to share similarities-violates the statistical assumption of independence, which is a common assumption across many statistical models. Violating this assumption can lead to invalid inferences and needs to be addressed.</p><p>One common statistical approach utilized in psychology to account for dependence among observations, is multilevel modeling (MLM). 1 MLMs are not unique to psychology.</p><p>Similar models have been simultaneously developed in other fields, though the nomenclature varies. In biostatistics and statistics, these are commonly referred to as mixed effects models.</p><p>Mixed effects modeling is a general framework, of which MLMs can be viewed as a special case 1 There are other approaches for dealing with clustering, such as fixed effects models, generalized estimating equations, or cluster robust standard errors. See <ref type="bibr">McNeish, Stapleton and Silverman (2017)</ref> for a discussion of other approaches. For this dissertation, I am particularly interested in a specific type of MLM, and thus I limit my discussion to MLMs as a framework to model nested data structures.</p><p>(e.g., <ref type="bibr" target="#b88">Laird &amp; Ware, 1982)</ref>. In econometrics, models with random intercepts are referenced as random effects models; models with random slopes are called random coefficient models <ref type="bibr" target="#b115">(MuthÃ©n, MuthÃ©n, Asparouhov, 2015;</ref><ref type="bibr" target="#b61">Hildreth &amp; Houck, 1968;</ref><ref type="bibr" target="#b140">Swamy, 1971)</ref>. In education, it is common to refer to MLMs as hierarchical linear models (HLM), in reference to the hierarchical nature of clustering <ref type="bibr" target="#b130">(Raudenbush &amp; Bryk, 2002)</ref>. Throughout this document, I will use the term MLM.</p><p>While MLMs are used to model nested data, they are not commonly used to account for measurement error. <ref type="foot" target="#foot_0">2</ref> In the behavioral sciences, it is common to study constructs that are hard to measure. For example, consider a mental health assessment of anxiety. We would consider anxiety to be a latent variable, in the sense that one cannot not directly measure it. Instead, we measure indicators of anxiety (e.g., fidgeting), which we posit are caused by an underlying latent trait of anxiety. Thus, while one might have an intuitive sense of how anxiety manifests, providing an objective measurement of anxiety is difficult. In order to statistically model the error associated with assessing unobserved traits, researchers in the social and behavioral sciences often use structural equation modeling (SEM), a multivariate statistical framework that handles latent variables.</p><p>The history of SEM is related to the development of path analysis and techniques for studying latent variables. Path analysis was invented by Sewell <ref type="bibr" target="#b150">Wright (1918</ref><ref type="bibr" target="#b151">Wright ( , 1921</ref><ref type="bibr" target="#b153">Wright ( , 1934</ref><ref type="bibr" target="#b155">Wright ( , 1960))</ref>.</p><p>Sewell Wright's path analysis involved path diagrams, visual representations of models with arrows (similar to path diagrams which are still popular today), as well as equations for estimating parameters from observed covariances. Although it took several decades, path analysis would later be adopted in social sciences fields such as Psychology, Sociology, and Political Science <ref type="bibr" target="#b19">(Bollen, 1989;</ref><ref type="bibr" target="#b12">Bentler, 1986;</ref><ref type="bibr" target="#b51">Goldberger, 1972;</ref><ref type="bibr" target="#b17">Blalock, 1961;</ref><ref type="bibr" target="#b42">Duncan, 1966)</ref>.</p><p>The second component to development of SEM comes from traditions for modeling latent variables. Methods for studying latent variables can be traced back through a number of early works including <ref type="bibr" target="#b139">Spearman's (1904)</ref> factor analytic tradition, some of Wright's path analysis studies <ref type="bibr" target="#b154">(Wright, 1954)</ref>, as well as others including <ref type="bibr" target="#b18">Blalock (1963)</ref>, <ref type="bibr" target="#b43">Duncan, Haller, and Portes (1968)</ref> and <ref type="bibr" target="#b59">Heise (1969)</ref>. Often, <ref type="bibr" target="#b83">JÃ¶reskog (1973)</ref>, <ref type="bibr">Keesing (1972)</ref>, and <ref type="bibr" target="#b149">Wiley (1973)</ref>, are attributed with laying the foundations for the general SEM we use today, combining features of path analysis and latent variable modeling. <ref type="foot" target="#foot_1">3</ref> The key feature of SEM is connecting measurement models to path models or structural models. This allows us to include latent variables in a general multivariate analysis.</p><p>MLMs and SEMs are often treated as independent frameworks. However, it is well documented that these frameworks share deep connections <ref type="bibr" target="#b9">(Bauer, 2003;</ref><ref type="bibr" target="#b39">Curran, 2003;</ref><ref type="bibr" target="#b85">Kamata, Bauer, &amp; Miyazaki, 2008;</ref><ref type="bibr" target="#b107">Mehta &amp; Neale, 2005;</ref><ref type="bibr" target="#b108">Meredith &amp; Tisak, 1990;</ref><ref type="bibr" target="#b127">Rabe-Hesketh, Skrondal, Pickles, 2004)</ref>. Indeed, in many circumstances they are completely isomorphic <ref type="bibr" target="#b107">(Mehta &amp; Neale, 2005;</ref><ref type="bibr" target="#b39">Curran, 2003)</ref>. Perhaps the most well-known example of this isomorphism is the equivalence between growth curves in MLM and Latent Growth Curve Models <ref type="bibr" target="#b129">(Raudenbush, 2001;</ref><ref type="bibr" target="#b9">Bauer 2003;</ref><ref type="bibr">Curran 2003, MacCallum, Kim, Malarkey, and</ref><ref type="bibr">Kiecold-Glasser, 1997)</ref>. The equivalences extend past simple growth curves. Rabe-Hesketh et al ( <ref type="formula">2004</ref>) point out how a random effect and a latent variable are essentially identical. 4 In perhaps one of the most impressive and exhaustive analyses <ref type="bibr" target="#b107">Mehta and Neale (2005)</ref> review a series of increasingly complicated MLMs and SEMs, showing deep similarities. Similarly, Rabe-Hesketh et al ( <ref type="formula">2004</ref>),</p><p>showed how both MLMs and SEMs could be considered special cases of a more general, Generalized Linear Latent and Mixed Models (GLLAMM) framework.</p><p>Despite the fact that one can formulate MLMs as SEMs and (and vice versa) it does not always make sense to. The colloquial framing of "MLMs are just SEMs" is oversimplified and ignores that each framework has its advantages and disadvantages. While it would be technically possible to estimate an MLM in a SEM framework, in many circumstances this is tedious and the result is nearly uninterpretable <ref type="bibr" target="#b39">(Curran, 2003;</ref><ref type="bibr" target="#b107">Mehta and Neale, 2005)</ref>.  <ref type="bibr" target="#b137">Schmidt (1969)</ref> was published prior to the foundational SEM works of <ref type="bibr" target="#b83">JÃ¶reskog (1973)</ref>, <ref type="bibr" target="#b149">Wiley (1973)</ref>, and <ref type="bibr">Keesling (1972)</ref>. As a doctoral student, Schmidt worked closely with James Ward Keesling, a fellow doctoral student at the University of Chicago. In fact, <ref type="bibr" target="#b137">Schmidt (1969)</ref> notes that one chapter of his dissertation was written by Keesling. James <ref type="bibr">Keesling's (1972)</ref> dissertation includes an updated version of the same chapter.<ref type="foot" target="#foot_4">foot_4</ref> Thus, the origins of MSEM shares similar roots with the general SEM framework.</p><p>After the early work of <ref type="bibr" target="#b137">Schmidt (1969)</ref>, very little progress was made until nearly two decades later when interest in the topic gained traction again. Important contributions by <ref type="bibr" target="#b54">Goldstein and McDonald (1988)</ref>, <ref type="bibr" target="#b111">MuthÃ©n (1989</ref><ref type="bibr" target="#b112">MuthÃ©n ( , 1990))</ref>, <ref type="bibr" target="#b106">McDonald and Goldstein (1989)</ref>, <ref type="bibr" target="#b116">MuthÃ©n and Satorra (1989)</ref>, and <ref type="bibr" target="#b89">Lee (1990)</ref> added to the theoretical foundations for modern MSEM, while also providing the first practical approaches to estimate MSEMs. I review this history in detail in Chapter 2.</p><p>There are a handful of different frameworks for specifying and estimating MSEMs. The focus of this dissertation is the random intercepts MSEM, sometimes called the within and between approach <ref type="bibr" target="#b69">(Hox, Moerbeek, van de Schoot, 2017)</ref>. The random intercepts MSEM is the most studied framework and it is the most widely used in practice. I would argue this framework is also the most recognizable to a SEM audience. The usual likelihood is specified with covariance matrices and key component of the approach involves assessing fit with Chi-Square based model fit indices. Thus, the strengths of this approach are that it is well understood, it is widely implemented, and it is the most understandable to a broad audience of SEM users. The limitation to this framework is that it does not allow for random slopes. Other MSEM frameworks move beyond random intercepts offering the additional flexibility to specify random slopes. While these are not the focus of this dissertation, it remains important to consider them. I review both random intercept and random slope frameworks in Chapter 2. Now I turn to the primary focus of my dissertation: estimating and testing MSEMs.</p><p>Currently, the de facto estimator for MSEMs is maximum likelihood (ML) applied to all levels of the model simultaneously. This is not without reason-ML offers all the usual desirable asymptotic properties (e.g., consistency, asymptotic efficiency) for valid models. However, ML requires strong assumptions such as correct model specification and no excessive multivariate kurtosis <ref type="bibr" target="#b32">(Browne, 1984)</ref>. If these assumptions are violated, there is no guarantee about the consistency, asymptotic efficiency or asymptotic unbiasedness of the ML estimator. Despite ML's general success, I would suggest there are several reasons to consider alternative estimators, which may offer advantages over ML in some circumstances.</p><p>A common aphorism in statistics states "all models are wrong, some models are useful".</p><p>If there is truth in this statement, and I believe there is, then the assumption of correct model specification seems all the more problematic. Of course, no estimator will be completely robust to incorrect models. This problem will persist. However, some estimators are more robust than others. In the single level SEM, studies have shown that the effects of misspecification (e.g., biased parameter estimates) in one part of the model will spread when estimating model with ML. Alternatively, limited information estimation techniques have been shown to be more robust to these exact same misspecifications.</p><p>More generally, I would suggest there are four primary shortcomings with the usual ML approach to estimating MESMs. Each of these I will discuss at greater length in Chapter 2. First, system-wide estimators such as ML can spread misspecification across model parameters. In this case, I am mostly referring to structural misspecification, as opposed to distributional misspecification. <ref type="bibr" target="#b27">Bollen, Gates, Fisher (2018)</ref> have offered recent discussion about the different types of misspecification. The effects of structural misspecification in MSEMs has been understudied and this particular problem may be exacerbated by the multilevel nature of MSEMs. Second, assessing model fit is complicated and often misleading given traditional chi-square based SEM fit statistics <ref type="bibr" target="#b161">(Yuan &amp; Bentler, 2007;</ref><ref type="bibr" target="#b134">Ryu &amp; West, 2009;</ref><ref type="bibr" target="#b133">Ryu, 2014;</ref><ref type="bibr" target="#b71">Hsu, Kwok, Lin, Acosta, 2015)</ref>. Potential solutions have been suggested, and I review them in Chapter 2. However, the problem of assessing fit in MSEMs remains problematic. Third, due to model complexity MSEMS are more likely to encounter estimation complications with convergence <ref type="bibr" target="#b134">(Ryu, 2009)</ref>. Fourth, under-identification anywhere in the model can prevent estimation.</p><p>In this dissertation, I develop and test a limited information estimator for MSEMs, based on the Model Implied Instrumental Variable Two-Stage Least Squares (MIIV-2SLS) estimator.</p><p>For each problem listed above, there is a direct solution based on MIIV-2SLS. First, MIIV-2SLS</p><p>has been shown to be more robust to the effects of structural and distributional misspecification <ref type="bibr" target="#b27">(Bollen, Gates, Fisher, 2018;</ref><ref type="bibr" target="#b28">Bollen, Kirby, Curran, Paxton, Chen, 2007)</ref>. Second, model specification tests such as the Sargan test offer equation-by-equation tests of model fit <ref type="bibr" target="#b135">(Sargan, 1958)</ref>. As I will demonstrate, it is possible to modify The Sargan test for application in a MSEM context <ref type="bibr" target="#b77">(Jin &amp; Cao, 2018)</ref>. Third, MIIV-2SLS is a non-iterative procedure and thus convergence is a non-issue. Fourth, the procedure I propose involves fitting each level individually, removing the problem of needing all equations at all levels to be identified. The logic of fitting each level separately was first proposed by <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> as a way to prevent cross level misspecification and improve model testing. I review more about MIIV-2SLS in Chapter 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions</head><p>In this dissertation, I offer a number of novel contributions to the field of psychometrics.</p><p>First, I am proposing a limited information procedure for estimating and testing within and between MSEMs. This procedure has similarities to the <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> paper that suggested benefits from fitting each level separately in MSEMs; <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> do not take advantage of the within level robustness features of limited information estimators. Second, I am proposing a method to estimate standard errors for all parameters in the model. Third, I am</p><p>proposing a new over-identification test, which can be used to test every equation at every level.</p><p>No other estimator has this feature in MSEMs. Fourth, I am proposing a Monte Carlo simulation to examine overall performance of MIIV-2SLS including accuracy of standard errors and bias of parameter estimates across a range of conditions. Fifth, I will assess the accuracy of the over identification test as an alternative procedure to assessing fit in MSEMs. Sixth, I will demonstrate the use of MIIV-2SLS with one empirical example, compared side-by-side with ML. Seventh, and finally, the entire procedure will be fully implemented into an R package, and all code will be freely available. This last step will make the new estimation procedure accessible to a broad audience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outline</head><p>In order to accomplish these goals, I begin with a review of MSEMs in Chapter 2. I define the general random intercepts MSEM model, ML estimation, and review the history and development of MSEMs with particular interest on the random intercepts model. As a part of this review, I will examine both technical developments as well as empirical simulations of estimation performance across a variety of important factors. I also review several of the more recent developments for random slope models, though I provide less detail in these sections.</p><p>Finally, in Chapter 2, I review potential shortcomings in the usual ML estimation procedure.</p><p>In  <ref type="bibr">2005)</ref>. This data has been used previously by <ref type="bibr" target="#b133">Ryu (2014)</ref> to demonstrate model fit procedures in MSEMs. I fit an MSEM to understand whether confidence in math is related to overall performance at the individual and classroom levels.</p><p>Finally, in Chapter 6, I will offer conclusions about the performance of MIIV-2SLS, limitations of the approach I developed, as well as directions for future research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>History of MSEM developments</head><p>The general history of MSEM is primarily a history of the random intercepts MSEM.</p><p>Frameworks going beyond random intercepts are more recent, being developed mostly within the last decade. Additionally, this history is almost entirely a history of ML estimation for MSEMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Random Intercepts</head><p>The unpublished doctoral dissertation by <ref type="bibr" target="#b137">Schmidt (1969)</ref> is often credited as the first MSEM study <ref type="bibr" target="#b35">(Burnstein, 1980;</ref><ref type="bibr" target="#b55">Gustafsson, &amp; Lindstrom, 1979;</ref><ref type="bibr" target="#b111">MuthÃ©n, 1989;</ref><ref type="bibr" target="#b128">Raudenbush, 1995)</ref>. <ref type="bibr" target="#b137">Schmidt (1969)</ref> showed how to obtain ML estimates of the within and between covariance matrices and developed a software routine to do so. This work only allowed for balanced data, and did not allow for a level 2 model. Schmidt's work was picked up by <ref type="bibr" target="#b35">Burnstein (1980)</ref> as well as <ref type="bibr" target="#b55">Gustafsson and Lindstrom (1979)</ref>, but overall it did not gain much traction. It would be a few decades until MSEMs were more generally adopted and additional progress was made. A series of papers in the late 1980s including <ref type="bibr" target="#b54">Goldstein and McDonald (1988)</ref>, <ref type="bibr" target="#b111">MuthÃ©n (1989</ref><ref type="bibr" target="#b112">MuthÃ©n ( , 1990))</ref>, <ref type="bibr" target="#b106">McDonald and Goldstein (1989)</ref>, <ref type="bibr" target="#b116">MuthÃ©n and Satorra (1989)</ref>, and <ref type="bibr" target="#b89">Lee (1990)</ref> added to the theoretical foundations laid by <ref type="bibr" target="#b137">Schmidt (1969)</ref>. <ref type="bibr" target="#b54">Goldstein and McDonald (1988)</ref> provided a general formulation for MSEMs, approaching the model from the perspective of a univariate MLM. <ref type="bibr" target="#b65">Hox (2010)</ref> provides an excellent description of this method. By using the general MLM framework, this particular routine was able to handle missing data as well as cross-classified clusters. <ref type="bibr" target="#b54">Goldstein and McDonald (1988)</ref> gave the expression of the likelihood and suggested an iterative GLS algorithm for fitting. While this was important contribution, this paper was ultimately less central to further developments given its roots in univariate MLM.</p><p>McDonald and <ref type="bibr" target="#b106">Goldstein (1989)</ref> and <ref type="bibr" target="#b111">MuthÃ©n (1989)</ref> were far more central to the development of MSEMs as we understand them today. <ref type="bibr" target="#b106">McDonald and Goldstein (1989)</ref> provided a multivariate perspective of the within and between formulation of MSEMs. This multivariate expression was of course much more similar to expressions that SEM users knew.</p><p>McDonald and <ref type="bibr" target="#b106">Goldstein (1989)</ref> provided a general likelihood expression as well as a modified form that was more computationally tractable. However, even with the more computationally tractable form, <ref type="bibr" target="#b106">McDonald and Goldstein (1989)</ref> note while it could be theoretically possible to estimate the model in LISREL it would likely be impractical. Instead, they suggested that specific software might need to be developed to estimate MSEMs. <ref type="bibr" target="#b111">MuthÃ©n (1989</ref><ref type="bibr" target="#b112">MuthÃ©n ( , 1990</ref>) took a slightly different approach and perhaps a more practical approach. <ref type="bibr" target="#b112">MuthÃ©n (1990)</ref> developed an alternative specification for MSEMs and showed that for the balanced case, it could be fit in modern SEM software with a multiple group likelihood function. This estimator would become known as the MUML estimator and was perhaps more usable at this stage than the more general form of <ref type="bibr" target="#b106">McDonald and Goldstein (1989)</ref>. <ref type="bibr" target="#b112">MuthÃ©n (1990)</ref> provided additional derivations of <ref type="bibr" target="#b111">MuthÃ©n (1989)</ref> and further suggested that the MUML estimator could be used with unbalanced designs by simply using the average cluster size, with minimal loss of information. Additional discussion of the MUML estimator is provided in <ref type="bibr" target="#b113">MuthÃ©n (1994)</ref>. Later, <ref type="bibr" target="#b162">Yuan and Hayashi (2005)</ref> proved that the MUML estimator is biased and perhaps more importantly showed that this bias does not improve with larger level 2 sample sizes (i.e., more clusters). <ref type="bibr" target="#b89">Lee (1990)</ref> extended <ref type="bibr" target="#b106">McDonald and Goldstein (1989)</ref> with a more rigorous treatment of the statistical theory, adding important contributions to estimation, inference about parameters, as well as goodness of fit statistics and model constraints. <ref type="bibr" target="#b89">Lee (1990)</ref> suggested using Fisher-Scoring and Gauss-Newton in order to optimize the fit function. <ref type="bibr" target="#b91">Lee and Poon (1992)</ref> went further to incorporate unbalanced designs. <ref type="bibr" target="#b104">McDonald (1993)</ref> extended their work to incorporate missing data by deriving the likelihood for missing data. <ref type="bibr" target="#b105">McDonald (1994)</ref> reports results based on the program "BIRAM" which was used for estimation. Yau, <ref type="bibr" target="#b157">Lee &amp; Poon (1993)</ref> extended the model to the three level context.</p><p>A number of highly technical papers applied the EM algorithm to improve optimization.</p><p>First, <ref type="bibr" target="#b128">Raudenbush (1995)</ref> applied the EM algorithm as a way to account for unbalanced designs, by treating unbalanced data as a missing data problem. In order to implement this method, <ref type="bibr" target="#b128">Raudenbush (1995)</ref> derived expressions for the E-step and suggesting that the more complicated M-steps could be performed by <ref type="bibr" target="#b112">MuthÃ©n's (1990)</ref> method. <ref type="bibr" target="#b128">Raudenbush (1995)</ref> points out that a likely disadvantage of this approach is slow convergence when cluster sizes vary by large amounts. <ref type="bibr" target="#b92">Lee and Poon (1998)</ref> took a slightly different approach and treated latent random vectors as missing data at level two, also applying the EM algorithm. <ref type="bibr" target="#b92">Lee and Poon (1998)</ref> suggest that previous works of <ref type="bibr" target="#b112">MuthÃ©n (1990)</ref>, <ref type="bibr" target="#b96">Longford and MuthÃ©n (1992)</ref> and <ref type="bibr" target="#b128">Raudenbush (1995)</ref> were only solutions to more specific problems and were not general.</p><p>Finally, the works of <ref type="bibr" target="#b16">Bentler and Liang (2003)</ref> and <ref type="bibr" target="#b95">Liang and Bentler (2004)</ref> were some of last technical papers on ML estimation for random intercept MSEMs. <ref type="bibr" target="#b95">Liang and Bentler (2004)</ref> provided key insights suggesting the majority of prior MSEM papers (e.g., <ref type="bibr">McDonald and Goldstein,1989;</ref><ref type="bibr" target="#b111">MuthÃ©n, 1989</ref><ref type="bibr" target="#b112">MuthÃ©n, , 1990;;</ref><ref type="bibr" target="#b128">Raudenbush, 1995;</ref><ref type="bibr" target="#b89">Lee, 1990;</ref><ref type="bibr" target="#b92">Lee &amp; Poon, 1998</ref>) could be considered special cases of a more general form (which will be described in the coming sections. <ref type="bibr" target="#b95">Liang and Bentler (2004)</ref> derived an EM algorithm, which is stated to have the explicit merit of avoiding computation of a large number of inverse matrices. The algorithm they outlined is also capable of estimating models with balanced and unbalanced designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Beyond Random Intercepts</head><p>A number of efforts have been made to move beyond the within and between MSEM. As I have mentioned, these models are not the focus of my dissertation; however, for completeness I also present these frameworks. The primary advantage of moving beyond random intercepts is the addition of random slopes. In practice, adoption of models in this section have been less common. This is likely for a number of reasons including the fact that estimation is exceedingly complex and non-convergence is common <ref type="bibr" target="#b132">(Rockwood, 2019)</ref>.</p><p>There are three primary frameworks for random slopes MSEMs: (i) <ref type="bibr" target="#b114">MuthÃ©n and Asparouhov (2008)</ref>, (ii) GLLAMM, and (iii) Bayesian. All of these are available in limited software packages. <ref type="bibr" target="#b114">MuthÃ©n and Asparouhov (2008)</ref>   <ref type="bibr" target="#b127">-Hesketh, et al 2004)</ref>. This framework is an extension of the generalized linear mixed models (GLMMs) approach. This makes GLLAMM more akin to univariate mixed effects modeling approach allowing for latent variables. In order to specify a two level MSEM in the GLLAMM framework one would specify a three level model. As with the above framework, GLLAMM is generally flexible also allowing for random slopes, different response types and link functions, missing data, and crossclassification. Rabe-Hesketh et al ( <ref type="formula">2004</ref>) have pointed out that other models, such as the <ref type="bibr" target="#b95">Liang and Bentler (2004)</ref> framework are special cases of this GLLAMM framework. GLLAMM models are implemented in Stata via a macro. As with all implementations, there are some negatives. While the approach allows for random slopes, it only allows for random slopes with observed covariates. Second, due to the complexity of specification and estimation, some have noted that estimation tends to be slow <ref type="bibr" target="#b132">(Rockwood, 2019)</ref>.</p><p>The final framework is the Bayesian framework. This framework is the most different given that all other frameworks discussed so far are frequentist. There have been a number of papers on Bayesian MSEM including <ref type="bibr" target="#b5">Arminger and MuthÃ©n (1998)</ref>, <ref type="bibr">Ansari, Jedidi, and</ref><ref type="bibr" target="#b4">Jagpal 2000, Ansari, Jedidi, and</ref><ref type="bibr" target="#b4">Jagpal (2000)</ref>, <ref type="bibr">Lee, Sik-Yum (2007)</ref>, <ref type="bibr" target="#b40">Depaoli and Clifton (2015)</ref>. There are many advantages to Bayesian SEM approaches, many of which stem from the flexibility of Bayesian estimation in general. <ref type="bibr" target="#b6">Asparouhov and MuthÃ©n (2012)</ref> note that Bayesian MSEM solves many of the computations difficulties posed by frequentist frameworks for MSEM. For example, they note that if a predictor variable is a latent variable, estimating a random slope requires numerical integration in the frequentist framework. Practically, this limits the number of random slopes to 3 or 4, before the problem becomes computationally intractable <ref type="bibr" target="#b6">(Asparouhov and MuthÃ©n, 2012)</ref>. In the Bayesian framework, it is possible to estimate any number of random slopes and intercepts. Of course, Bayesian frameworks require computationally intensive numerical algorithms.</p><p>As was already suggested, the primary focus of the dissertation is the random intercepts MSEM. I have provided a brief of review of developments for both the random intercepts and random slopes frameworks. For the remainder of this chapter and this dissertation, I will be solely interested on the random intercepts MSEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Random Intercepts MSEM</head><p>In this section, I define the random intercepts MSEM model. In a two-level multilevel model, there are two sources of variation: within cluster and between cluster (or, Level 1 and Level 2, respectively). Consider the example of students within classrooms. Within any given classroom, there is variation in aptitude among students. Then, each classroom has an average level of aptitude and there is variation between the average aptitudes of classrooms. In the random intercepts MSEM, we split the variation into these components building a model to describe variation at each level.</p><p>Let ğ’š ğ‘–ğ‘— be the ğ‘ x 1 vector of observations with ğ‘– indexing individuals within clusters and ğ‘— indexing clusters. Thus ğ‘– = 1, 2, â€¦ , ğ‘› ğ‘— and ğ‘— = 1, 2, â€¦ , ğ½ , where ğ‘› ğ‘— is the sample size for cluster ğ‘—, and ğ½ is the total number of clusters. We can represent ğ’š ğ‘–ğ‘— as:</p><formula xml:id="formula_0">ğ’š ğ‘–ğ‘— = ğ + ğ’– ğ‘–ğ‘— + ğ’— ğ‘— (1)</formula><p>Where ğ is the grand mean vector, ğ’– ğ‘–ğ‘— represents the within level variation (i.e., disturbance or deviation from a group mean), and ğ’— ğ‘— represents the between level variation (group level disturbance or deviation from grand mean). We make the following assumptions ğ¸(ğ’– ğ‘–ğ‘— ) = 0, ğ‘‰(ğ’– ğ‘–ğ‘— ) = ğšº ğ‘Š , ğ¸(ğ’— ğ‘— ) = 0, and ğ‘‰(ğ’— ğ‘— ) = ğšº ğµ . In other words, each ğ’š ğ‘–ğ‘— vector is given by the overall mean and deviations at each level.</p><p>A key component of the MSEM is the decomposition of the total covariance matrix into parts corresponding to each level. Consider the variance of ğ’š ğ‘–ğ‘— :</p><p>The above equations make explicitly clear that in this model, we decompose the total covariance of ğ’š ğ‘–ğ‘— into the additive and orthogonal level-specific covariance matrices ğšº ğ‘Š and ğšº ğµ . Many papers and book chapters offer little explanation for this step and simply cite <ref type="bibr" target="#b138">Searle, Casella, &amp; McCulloch (1992)</ref> without much explanation (See <ref type="bibr">Hox et al. 2017, p. 271)</ref>. In order for the additive and orthogonal properties to hold, we have to make the assumption of random sampling at both levels of the model. In this section, I have introduced a general form of the MSEM model. However, I would note that model specification has been highly inconsistent throughout the literature. This is best illustrated by <ref type="bibr" target="#b95">Liang and Bentler (2004)</ref>. They reviewed four common MSEM model specifications showing how each could be re-expressed in a single more general way. I do not provide the specific details these alternative expressions. This would require a great deal of new notation, which ultimately would not inform the general approach I am proposing. In general, the different "model specifications" used should be considered different forms of the general model I have presented in this section.</p><p>Estimation is most commonly carried out with maximum likelihood, and we make a few key assumptions. First, we assume the variables at both levels follow multivariate normal distributions. Second, we assume that the levels are from two uncorrelated random components (this assumption was already covered as part of the specification) and finally we assume that within level observations are independent and identically distributed. The ML fitting function given by <ref type="bibr" target="#b16">Bentler and Liang (2003)</ref> and <ref type="bibr" target="#b95">Liang and Bentler (2004)</ref> is</p><formula xml:id="formula_1">ğ¹ ğ‘€ğ¿ = âˆ‘(ğ‘› ğ‘— -1) {log|ğšº ğ‘Š (ğœ½)| + ğ­ğ« (ğšº ğ‘Š -1 (ğœ½)ğ‘º ğ‘¦ ğ‘Š ğ‘— )} ğ½ ğ‘—=1 + âˆ‘{log|ğšº ğ‘”ğ‘— (ğœ½)| + tr(ğšº ğ‘”ğ‘— -1 (ğœ½)ğ‘º ğ‘”ğ‘— )} ğ½ ğ‘—=1</formula><p>where ğœ½ is the vector of all model parameters,</p><formula xml:id="formula_2">ğ‘º ğ‘¦ğ‘Š ğ‘— = (ğ‘› ğ‘— -1) -1 âˆ‘ (ğ’š ğ‘–ğ‘— -ğ’š Ì… ğ‘— )(ğ’š ğ‘–ğ‘— -ğ’š Ì… ğ‘— ) â€² , ğ‘› ğ‘— ğ‘–=1</formula><p>ğšº ğ‘”ğ‘— (ğœ½) = ğšº ğµ (ğœ½) + ğ‘› ğ‘— -1 ğšº ğ‘Š (ğœ½), and</p><formula xml:id="formula_3">ğ‘º ğ‘”ğ‘— = ğ‘› ğ‘— (ğ’š Ì… ğ‘— -ğ’š Ì…)(ğ’š Ì… ğ‘— -ğ’š Ì…) â€² .</formula><p>It is apparent that the ML fitting function has two components. The first corresponds to the level-1 portion of the model and second portion corresponds to the level-2 portion of the model. Essentially, the within groups portion of the model is compared to the sample pooled within groups covariance matrix (ğ‘º ğ‘¦ ğ‘Š ğ‘— ) while the second part of the equation fits the between groups model ğšº ğ‘”ğ‘— (ğœ½) to the between groups covariance matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Fit</head><p>Assessing model fit and detecting model misspecification is a major part of any SEM application. In single level models, this topic has received a great deal of attention (e.g., <ref type="bibr" target="#b13">Bentler, 1990;</ref><ref type="bibr" target="#b14">Bentler 1992;</ref><ref type="bibr">Bentler &amp; Bonnet 1982;</ref><ref type="bibr" target="#b30">Bollen &amp; Long 1993;</ref><ref type="bibr">Browne &amp; Cudeck 1983;</ref><ref type="bibr">Browne, MacCallum, Kim, Andersen, 2002;</ref><ref type="bibr" target="#b72">Hu &amp; Bentler, 1995</ref><ref type="bibr">, 1998</ref><ref type="bibr" target="#b22">, 1999;</ref><ref type="bibr" target="#b146">Tucker &amp; Lewis, 1973;</ref><ref type="bibr" target="#b158">Yuan, 2005)</ref>. There are a large number of possible fit indices; some of the more common MSEMs in mind <ref type="bibr" target="#b74">(Hu and Bentler, 1999)</ref>. <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> were the first to point out the potential issue with assessing model fit in a multilevel context. <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> suggest there are three primary faults with using traditional fit statistics in MSEM:</p><p>"(1) with the same amount of misspecification, the power of a statistic is inversely proportional to model size and degrees of freedom. The overall statistics are less likely to be significant when simultaneously evaluating misspecified multilevel models.</p><p>(2) Even when a statistic is significant, it is not clear whether a model at a single level is misspecified or whether models at all the levels are misspecified.</p><p>(3)When fitting models at different levels simultaneously, misspecification at one level will affect the parameter estimates at the other levels. Thus, model diagnostics in simultaneous model evaluation can be very complicated, if not impossible."</p><p>Others have discussed the problem as one of disproportionate sample size <ref type="bibr" target="#b65">(Hox, 2010)</ref>. For example, the effective sample size at the within level of the model is usually magnitudes larger than the sample size at between level of the model. Thus, fit statistics are disproportionately weighted by fit of the within level. <ref type="bibr" target="#b65">Hox (2010)</ref> suggests this difference in sample size leads to the insensitivity to misfit at the between level.</p><p>The empirical performance of several fit indices in MSEMs have been studied by <ref type="bibr" target="#b134">Ryu and West (2009)</ref>, <ref type="bibr" target="#b133">Ryu (2014), and</ref><ref type="bibr" target="#b71">Hsu, Kwok, Lin, and</ref><ref type="bibr" target="#b71">Acosta (2015)</ref>. <ref type="bibr" target="#b134">Ryu and West (2009)</ref> examined the sensitivity of RMSEA and CFI in MSEMs, concluding that both indices were not able to adequately detect misspecification at the between level. Later Hsu, Kwok, Lin, and Acosta (2015) examined a greater variety of fit indices including RMSEA, CFI, TLI, SRMR-W, and SRMR-B. They concluded similarly that none of these indices were able to detect misspecification at the between level. The one exception to this rule was the SRMR-B was somewhat sensitive to misspecification at the between level. They also found that TLI performed better than CFI and RMSEA at detecting true misspecification, across several factors.</p><p>Given the general inability of the usual chi-square based fit indices to detect misspecification in MSEMs, two alternatives have been proposed to assess fit. First, <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> proposed segregating the model into levels and estimating each level as its own single level SEM model. Second, <ref type="bibr" target="#b134">Ryu and West (2009)</ref> suggested estimating a series of partially saturated models to isolate misfit at each level. I review both of these next. In particular, I provide a thorough description of the first step in the <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> procedure, because it plays an important role in the MIIV-2SLS approach I will outline in Chapter 3. <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> proposed estimating level specific SEM models instead of estimating the full MSEM altogether. In order to do this, one needs level specific data or level specific covariance matrices. <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> published an ML procedure to estimate level specific covariance matrices and the asymptotic covariances of those estimates.</p><p>Additionally, they derive a modified chi-square test. In practice, this procedure improves on the usual approach by providing level specific chi-square tests, which <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> show are sensitive to misfit at both levels. Additionally, <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> suggest that segregating the model into levels prevents misspecification from spreading across levels, much in the same way that MIIV-2SLS can prevent misspecifications spreading between model equations.</p><p>Consider the general model given in equation ( <ref type="formula">1</ref>) and the variance decomposition given in equation ( <ref type="formula">2</ref>). The sample-based counterpart to equation ( <ref type="formula">2</ref>) is,</p><formula xml:id="formula_4">ğ‘º ğ‘‡ = ğ‘º ğ‘Š + ğ‘º ğµ</formula><p>where the total covariation in the sample (ğ‘º ğ‘‡ ) is broken down into the level specific components ğ‘º ğ‘Š and ğ‘º ğµ . In practice, one does not directly observe the level specific components in a sample.</p><p>Instead, these quantities need to be estimated. I will refer to the estimated sample covariance matrices as ğ‘º Ì‚ğ‘Š and ğ‘º Ì‚ğµ. <ref type="bibr" target="#b159">Yuan and Bentler (2002)</ref> provide one possible way to estimate ğ‘º Ì‚ğ‘Š and ğ‘º Ì‚ğµ by maximizing the likelihood function:</p><formula xml:id="formula_5">ğ‘™(ğ, ğ‘º ğ‘Š , ğ‘º ğµ ) = âˆ‘ ğ‘™ ğ‘— (ğ, ğ‘º ğ‘Š , ğ‘º ğµ ) ğ½ ğ‘—=1 (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>where ğ is the vector of means and,</p><formula xml:id="formula_7">ğ‘™ ğ‘— (ğ, ğ‘º ğ‘Š , ğ‘º ğµ ) = ğ‘ ğ‘— - 1 2 log|ğ’ ğ‘—ğ‘Šğµ | - ğ‘› ğ‘— -1 2 log|ğ’ ğ‘Š | = - 1 2 âˆ‘(ğ’š ğ‘–ğ‘— -ğ’š Ì… .ğ‘— ) â€² ğ’ ğ‘Š -1 (ğ’š ğ‘–ğ‘— -ğ’š Ì… .ğ‘— ) ğ‘› ğ‘— ğ‘–=1 = - 1 2 (ğ’š Ì… .ğ‘— -ğ) â€² ğ’ ğ‘—ğ‘Šğµ -1 (ğ’š Ì… .ğ‘— -ğ)<label>(6)</label></formula><p>and,</p><formula xml:id="formula_8">ğ’ ğ‘—ğ‘Šğµ = ğ‘› ğ‘— -1 ğ’ ğ‘Š + ğ’ ğµ<label>(7)</label></formula><p>We assume that ğ’š ğ‘–ğ‘— comes from a multivariate normal distribution; importantly, since ğ, ğ‘º ğ‘Š , ğ‘º ğµ are saturated for equation ( <ref type="formula">1</ref>), the estimates ğ‘º Ì‚ğ‘Š and ğ‘º Ì‚ğµ will be consistent even when ğ’š ğ‘–ğ‘— are not multivariate normally distributed <ref type="bibr" target="#b159">(Yuan and Bentler, 2002;</ref><ref type="bibr" target="#b90">2007)</ref>.</p><p>Additionally, <ref type="bibr" target="#b159">Yuan and Bentler (2002)</ref> provide the necessary information to estimate the asymptotic covariance matrix of ğ Ì‚, ğ‘º Ì‚ğ‘Š, and ğ’ Ì‚ğµ. Let ğœ½ Ì‚ represent the vector of estimates ğ Ì‚, ğ‘º Ì‚ğ‘Š, and ğ’ Ì‚ğµ. <ref type="bibr" target="#b159">Yuan and Bentler (2002)</ref>, demonstrated that that asymptotic distribution of the maximum likelihood estimate ğœ½ Ì‚ is given by</p><formula xml:id="formula_9">âˆšğ½(ğœ½ Ì‚-ğœ½) ğ‘™ â†’ ğ‘(ğŸ, ğš¼)</formula><p>Where ğš¼ can be estimated from the sample as,</p><formula xml:id="formula_10">ğš¼ = ğ‘¨ Ì‚-1 ğ‘© Ì‚ğ‘¨ Ì‚-1<label>(8)</label></formula><p>where,</p><formula xml:id="formula_11">ğ‘¨ Ì‚= 1 ğ½ âˆ‘ ğœ•ğ‘”(ğœ½ Ì‚) ğœ•ğœ½ Ì‚â€² ğ½ ğ‘—=1 ğ‘© Ì‚= 1 ğ½ âˆ‘ ğ’ˆ ğ’‹ (ğœ½ Ì‚) ğ½ ğ‘—=1 ğ’ˆ ğ’‹ ğ‘» (ğœ½ Ì‚)</formula><p>and,</p><formula xml:id="formula_12">ğ’ˆ ğ‘— (ğ›‰) = ( ğ’ ğ‘—12 -1 (ğ’š Ì… .ğ‘— -ğœ‡) ğ‘› ğ‘— -1 ğ‘¾ ğ‘—12 vech ((ğ’š Ì… .ğ‘— -ğœ‡)(ğ’š Ì… .ğ‘— -ğœ‡) ğ‘‡ -ğ’ ğ‘—12 -1 ) + ğ‘¾ 1 vech(ğ‘› ğ‘— ğ‘º ğ‘— -(ğ‘› ğ‘— -1)ğ’ W ) ğ‘¾ ğ‘—12 vech ((ğ’š Ì… .ğ‘— -ğœ‡)(ğ’š Ì… .ğ‘— -ğœ‡) ğ‘‡ -ğ’ ğ‘—12 ) ) ğ’š Ì… .ğ’‹ = 1 ğ‘› ğ‘— âˆ‘ ğ’š ğ‘–ğ‘— ğ‘› ğ‘— ğ‘–=1 ğ‘º ğ‘— = 1 ğ‘› ğ‘— âˆ‘(ğ’š ğ‘–ğ‘— -ğ’š Ì… .ğ‘— )(ğ’š ğ‘–ğ‘— -ğ’š Ì… .ğ‘— ) ğ‘‡ ğ‘› ğ‘— ğ‘–=1 ğ‘¾ ğ‘— = 2 -1 ğ‘« ğ‘ â€² (Î£ ğ‘— -1 âŠ— Î£ ğ‘— -1 )ğ‘« ğ‘ ğ‘¾ ğ‘—12 = 2 -1 ğ‘« ğ‘ â€² (Î£ ğ‘—12 -1 âŠ— Î£ ğ‘—12 -1 )ğ‘« ğ‘</formula><p>and ğ‘« ğ‘ is a duplication matrix as defined by <ref type="bibr" target="#b100">Magnus and Neudecker (2019)</ref>. Finally, the elements corresponding to the ğ’ Ì‚ğ‘Š asymptotic covariance matrix are divided by the within sample size and we divide the elements corresponding to the ğ’ Ì‚ğµ asymptotic covariance matrix by between sample size (i.e., the total number of clusters). <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> suggest obtaining model point estimates at each level by applying ML estimation using ğ‘º Ì‚ğ‘Š, and ğ’ Ì‚ğµ as observed covariance matrices. Then standard errors and the usual chi-square model fit statistics are corrected by using the asymptotic covariance matrices. The derivations for corrected standard errors and the corrected chi-square are not included here because they do not play a significant role in the overall method I will propose in the next chapter. I included all details of their decomposition procedure because I intend to follow a similar procedure. Overall the <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> procedure improves on the usual approach by obtaining fit estimates at each level of the model. <ref type="bibr" target="#b134">Ryu and West (2009)</ref> proposed an alternative solution for testing fit in MSEMs, which I review in less detail. Their procedure involves fitting a series of partially saturated models. This idea was first suggested by <ref type="bibr" target="#b64">Hox (2002)</ref>, though not implemented. To test for fit at level-2, one would fit a model in which the within level was saturated. Thus, the within groups covariance matrix would be exact and any misfit could be attributed to misfit at the between level. This procedure could be reversed in order to test fit at just the within level. <ref type="bibr" target="#b134">Ryu and West (2009)</ref> show how this procedure can be done to capture the test of exact fit as well as other indices such as the CFI and RMSEA. They evaluate their method in a Monte Carlo simulation study to show that testing fit at each level is much more effective than using the usual fit indices.</p><p>Based on the current evidence, it appears as though <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> and <ref type="bibr" target="#b134">Ryu and West (2009)</ref> both provide MSEM users with adequate ways to test the fit of MSEM models (when using ML). However, there are limitations to what is known about these procedures. <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> only tested their procedure with 200 clusters. They used unbalanced clusters but the average cluster size was over 100. The total sample size they used was fixed at 21,100.</p><p>Thus, their procedure was tested under large sample sizes only. <ref type="bibr">Ryu and West (2008)</ref>, tested their procedure with fewer clusters (50, 100, 200, 1000), but did not test any cluster sizes less than 30. Additionally, when examining 50 clusters, they fixed cluster sizes at 50. In sum, evidence for these model testing strategies is positive, but these have mostly been tested in reasonably large samples and ideal conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sample size</head><p>Sample size is an important consideration for MSEMs, as one typically needs large samples and many clusters. In MSEMs, the question of sample size is complicated by the fact that one must consider the sample size at each level. In a two level model, the level-1 sample size is equal to the total number of level 1 units and the level 2 sample size is equal to the total number of clusters. This logic could be extended to a higher number of levels.</p><p>ML relies on asymptotic theory (i.e., large sample sizes); there is reason to expect that the properties will not hold, especially for level-2 estimates, if we do not have enough clusters <ref type="bibr" target="#b67">(Hox &amp; Maas, 2001;</ref><ref type="bibr" target="#b109">Meuleman &amp; Billiet, 2009)</ref>. Simulation studies have confirmed the need for many clusters to ensure unbiased estimates and proper standard errors. In general, several studies have recommended at least 100 clusters at the second level <ref type="bibr" target="#b66">(Hox &amp; Maas, 2004;</ref><ref type="bibr" target="#b84">Julian, 2001;</ref><ref type="bibr" target="#b63">Holtmann, Koch, Lochner, &amp; Eid, 2016)</ref>. <ref type="bibr" target="#b63">Holtmann, Koch, Lochner, and Eid (2016)</ref> examined several estimators, including Bayesian, in order to understand small sample properties. Across most of the estimators they found that minimum of 100 clusters were needed with cluster sizes of at least four. In another study, <ref type="bibr" target="#b109">Meuleman and Billiet (2009)</ref> used a Monte Carlo design to study sample sizes as one might come across them in a large survey with many countries. They examined several sample sizes, finding similar results as previous studies, which have found that in many cases as least 100 clusters is necessary. <ref type="bibr" target="#b109">Meuleman and Billiet (2009)</ref> among others have pointed out that the problem of sample size may be particularly problematic in large-scale survey research across countries <ref type="bibr" target="#b70">(Hox, van de Schoot, Matthijsse, 2012)</ref>. In these studies, it is almost impossible to sample from 100 countries.</p><p>It is much more common to find global samples with roughly 30 different countries being represented. Thus, it remains a limitation that these methods require a large sample size and an especially large number of clusters.</p><p>In sum, the sample size requirements of MSEMs are one of the method's major limitations. In some areas of research, it can be impossible to obtain 100 clusters. In other areas, it may be possible but infeasible. Finding ways to estimate MSEMs with fewer than 100 clusters could be a major benefit to the method as a whole.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opportunities</head><p>Despite the general success of ML estimation and the great progress that has been made in this area, there may be reasons to consider other approaches to estimation. I mentioned several of these in the introduction, and I re-visit them now.</p><p>Given misspecification, system-wide estimators (i.e., ML) can spread structural misspecification throughout the system and this effect has been well documented with single level SEMs <ref type="bibr">(Bollen, 2019)</ref>. Misspecification in MSEMs has not received much attention in the literature. The attention it has received has been almost exclusively about assessing fit, with no studies considering the effect on parameter estimates. The issue is further complicated in MSEMs by the fact that it is possible for misspecification at one level to lead to biased parameters in another level <ref type="bibr" target="#b161">(Yuan and Bentler, 2007</ref>). Thus, the potential for bias spreading may be greater in MSEMs. Several have suggested this is a possibility, though it has not been investigated empirically.</p><p>Second, fit statistics represent the fit of all levels simultaneously, which can be problematic for a variety of reasons. Perhaps most important, the CFI, TLI, and RMSEA have all been shown to be insensitive to misspecification at between groups levels <ref type="bibr" target="#b134">(Ryu &amp; West, 2009;</ref><ref type="bibr" target="#b161">Yuan &amp; Bentler, 2007;</ref><ref type="bibr" target="#b71">Hsu, Kwok, Lin, Acosta, 2015)</ref>. Given a completely misspecified between level model, fit indices may still indicate excellent fit. This lack of sensitivity to higher levels is, at best, not useful. At its worst, this is entirely misleading if one is not aware of this shortcoming and is interested in the fit at level 2. Corrective procedures have been proposed with early results suggesting they are capable of assessing fit at the between level model. However, these are not easily implemented and they have only been studied in a small variety of conditions.</p><p>Third, MSEM models are increasingly complex and could be subject to higher rates of nonconvergence than single level SEMs. Problems with convergence are relatively common (e.g., <ref type="bibr" target="#b76">Jak, Oort, &amp; Dolan, 2014;</ref><ref type="bibr" target="#b94">Li &amp; Beretvas, 2013;</ref><ref type="bibr">Ludke, Marse, Robitzsch &amp; Trautwein, 2011;</ref><ref type="bibr">Jak, 2018)</ref>. Non-convergence is most likely in models with smaller variation at level 2 (e.g., low ICC) and models with small samples sizes. Non-convergence is even more likely to be a problem in models with random slopes.</p><p>Fourth, ML estimation typically requires many clusters (i.e., &gt;100). Obtaining enough data to estimate MSEMs is a major barrier to the usefulness of this methodology. Fewer than 100 clusters can cause problems with convergence as well as parameter bias.</p><p>Finally, under-identification at either level can prevent estimation even if the model at one of levels is identified. In some instances, MSEMs have isomorphic structures at both levels (see, Jak, 2018 for discussion of cross level invariance). In this case, if one level were identified, it would imply the other level to be identified as well. However, MSEMs also allow the ability to estimate different structures at different levels of the model. Models with differing structures may be more difficult to interpret, but they are no doubt possible. In these circumstances, it is very possible that one level of the model would be identified while another level is not. In the traditional ML setup, this would entirely prevent estimating the model.</p><p>Based on these reasons, in the next chapter I will develop a limited information estimator for MSEMs. This procedure will be more robust to the spread of misspecification, less likely to have problems with convergence, does not require global identification, offers equation specific tests of fit, and good small sample properties. Following the development of this procedure, I will examine its empirical properties alongside ML in two Monte Carlo simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CHAPTER 3: MIIV-2SLS FOR MSEMS</head><p>This Chapter has two primary goals. The first goal is to provide the reader with a general overview of MIIV-2SLS for single level SEMs. The second goal is to develop a MIIV-2SLS</p><p>estimator for random intercept MSEMs. I start with a review of research and developments relating to MIIV-2SLS. I then provide a didactic example to illustrate the general procedure.</p><p>Finally, I outline how I apply and modify MIIV-2SLS to estimate MSEMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIIV-2SLS Review</head><p>The MIIV-2SLS estimator was first proposed by <ref type="bibr">Bollen (1996a</ref><ref type="bibr" target="#b21">Bollen ( , 1996b) )</ref> as an estimator for single level SEMs. Since its original publication, the general procedures have been adapted/expanded to incorporate a wide variety of models such as those with categorical or mixed indicators, dynamic factor analysis models, and second order growth curves, just to give a few examples. <ref type="bibr" target="#b29">(Bollen, Kolenikov, &amp; Bauldry, 2014;</ref><ref type="bibr" target="#b31">Bollen &amp; Maydeu-Olivares, 2007;</ref><ref type="bibr" target="#b27">Bollen, Gates, Fisher, 2018;</ref><ref type="bibr">Fisher, Bollen, &amp; Gates, 2019;</ref><ref type="bibr">Gates, Fisher, &amp; Bollen, 2019;</ref><ref type="bibr" target="#b60">Henry, Fisher, Bollen, 2018;</ref><ref type="bibr" target="#b78">Jin, Luo, Yang-Wallentin, 2016;</ref><ref type="bibr" target="#b87">Kirby &amp; Bollen, 2009;</ref><ref type="bibr" target="#b118">Nestler, 2013;</ref><ref type="bibr" target="#b119">Nestler, 2014a;</ref><ref type="bibr" target="#b120">Nestler 2014b;</ref><ref type="bibr" target="#b121">Nestler, 2015;</ref><ref type="bibr" target="#b156">Yang-Wallentin, Joreskog, Luo, 2010;</ref><ref type="bibr" target="#b122">Oczkowski, 2002)</ref>. MIIV-2SLS is part of the general family of Two-Stage Least Squares (2SLS/TSLS) estimators, which have been in use for decades. The overwhelming majority of applications of 2SLS estimators have been in single equation regression or multi-equation simultaneous equation models without latent variables. The family of 2SLS estimators for estimating coefficients of a single equation in a simultaneous equations model, were independently introduced by <ref type="bibr" target="#b142">Theil (1953b</ref><ref type="bibr" target="#b141">Theil ( , 1953a</ref><ref type="bibr" target="#b143">Theil ( , 1954</ref><ref type="bibr" target="#b144">Theil ( , 1961))</ref>, <ref type="bibr" target="#b8">Basmann (1957)</ref>, and <ref type="bibr" target="#b135">Sargan (1958)</ref>  <ref type="bibr" target="#b1">(Anderson, 2005)</ref>. Though less cited, <ref type="bibr" target="#b2">Anderson &amp; Rubin (1950)</ref> also played an important role by deriving the asymptotic distribution for the limited information maximum likelihood (LIML) estimator for simultaneous equation models, which was used in all of the aforementioned works <ref type="bibr" target="#b1">(Anderson, 2005)</ref>.</p><p>MIIV-2SLS was not the first 2SLS estimator developed for estimating latent variable models, though it has arguably gained the most traction (among 2SLS estimators). <ref type="bibr" target="#b56">HÃ¤gglund (1982)</ref> applied a type of the 2SLS estimator for exploratory factor analysis. <ref type="bibr" target="#b80">JÃ¶reskog &amp; SÃ¶rbom, (1987)</ref> incorporated a different 2SLS estimator into factor analysis estimation. These early applications of 2SLS estimators were applied to the measurement model only and assumed no correlated errors. One exception was <ref type="bibr" target="#b81">JÃ¶reskog &amp; SÃ¶rbom (1993)</ref> who applied HÃ¤gglund's method to estimate the measurement model and generated the covariance matrix of latent variables. They estimated the latent variable model by using the covariance matrices as input for a second 2SLS procedure. This method still assumed no correlated errors and did not provide standard errors or significance tests.</p><p>In contrast to these earlier latent variable 2SLS methods, <ref type="bibr" target="#b21">Bollen (1996b)</ref> showed how the MIIV-2SLS estimator could be applied to estimate full SEMs with latent variables in an equation-by-equation basis, while also deriving standard errors and significance tests. Bollen does not require this. MIIV-2SLS offers asymptotic standard errors for all coefficients in the model, which previous versions did not. In addition, <ref type="bibr" target="#b21">Bollen (1996b)</ref> showed that an over identification test for each over identified equations was possible so that a local test of fit was possible.</p><p>The first MIIV-2SLS papers were developed for models with continuous indicators only.</p><p>As was already mentioned, a variety of developments have made MIIV-2SLS a more flexible procedure and now it can be used in a wider variety of models. <ref type="bibr" target="#b31">Bollen and Maydeu-Olivares (2007)</ref>, proposed a polychoric instrumental variable (PIV) estimator for models with categorical variables. Fisher and Bollen (under review), have proposed ways to estimate models with mixed indicators and alternative parameterizations. <ref type="bibr" target="#b77">Jin and Cao (2018)</ref> proposed adjusted specification tests for use with the PIV estimator. <ref type="bibr" target="#b118">Nestler (2013</ref><ref type="bibr" target="#b119">Nestler ( , 2014a</ref><ref type="bibr" target="#b120">Nestler ( , 2014b</ref><ref type="bibr" target="#b121">Nestler ( , 2015) )</ref> has extended the MIIV-2SLS approach to handle equality constraints, second order grown curve models, and tests for latent quadratic and interaction effects. <ref type="bibr" target="#b60">Henry, Fisher, Bollen (2018)</ref> used MIIV-2SLS to estimate SEMs with a Bayesian model averaging procedure. Finally, MIIV-2SLS has been extended to work with dynamic factor analysis models through the works of Fisher, Bollen, Gates (2019) and <ref type="bibr" target="#b48">Gates, Fisher, and Bollen (2019)</ref>. In sum, MIIV-2SLS can be used to estimate a wide variety of SEM models, though notably, it has not been extended to estimate MSEMs.</p><p>The preceding paragraphs sketch the history and recent developments of MIIV-2SLS, but I have not yet described its statistical properties. MIIV-2SLS has a number of desirable properties, which have been examined in both simulation and analytic work. I review several of these over the next few paragraphs.</p><p>The MIIV-2SLS estimator is asymptotically distribution free, that is, the asymptotic standard errors can be used in significance testing even when observed variables are non-normal or have excessive multivariate kurtosis <ref type="bibr" target="#b21">(Bollen, 1996b)</ref>. As comparison, maximum likelihood requires the assumptions of normality or no excessive kurtosis for significance testing, though there are corrections for non-normality (e.g., <ref type="bibr" target="#b136">Satorra &amp; Bentler, 1994)</ref>.</p><p>MIIV-2SLS estimators are more robust to structural misspecification than system-wide estimators. This does not mean MIIV-2SLS is fully robust; any parametric or model based estimator will be affected by model misspecification. However, model misspecification is less likely to spread throughout the model with MIIV-2SLS than with full information estimators. For example, FIML uses information from the full system to estimate all parameters. This means that if one part of the model is misspecified, this information might influence estimates throughout, and can spread bias. MIIV-2SLS will have bias in any given misspecified equation, but that bias is more isolated and is less likely to spread to other parts of the model. In a large Monte Carlo simulation study, <ref type="bibr">Bollen et al., (2007)</ref> compared bias of ML and MIIV-2SLS in conditions of correct model specification and incorrect model specification. First, they analyzed the population covariance matrices to show analytically which parameters would be biased or unbiased given a specific misspecification. Given correct model specification, MIIV-2SLS had similar levels of bias as ML. There is one exception to this which is important to consider. In small samples when MIIV-2SLS had a negative bias when using all possible instruments. They also found that this bias could be completely mitigated in small samples by using a smaller subset of instruments.</p><p>Given misspecification, MIIV-2SLS had less bias than ML. <ref type="bibr" target="#b37">Cragg (1968)</ref> noted the same quality for 2SLS for simultaneous equations as compared to FIML. More recently, the analytic work of <ref type="bibr" target="#b27">Bollen, Gates, &amp; Fisher (2018)</ref> outlined specific conditions of robustness.</p><p>When estimating models with MIIV-2SLS, one can use over-identification tests to identify possible misspecification. <ref type="bibr" target="#b87">Kirby and Bollen (2009)</ref>  As models become more complex, this property may prove more and more advantageous. As I have already suggested, all of these properties are useful in the MSEM case.</p><p>In the next section, I review the specific steps of MIIV-2SLS estimation through a didactic example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIIV-2SLS Estimation for single level SEM</head><p>There are four primary steps in MIIV-2SLS estimation: (i) specify the model, (ii) perform latent to observed transformations (L20), (iii) locate model implied instrumental variables (MIIVs), and (iv) estimate model parameters via 2SLS. I find it useful to illustrate the steps of MIIV-2SLS estimation through example. Consider Figure <ref type="figure">1</ref>, which displays the SEM path diagram that I will use to demonstrate the steps in estimation.</p><p>Step</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">-Model Specification</head><p>The specification/model equations for Figure <ref type="figure">1</ref> are given below. The latent variable model equations are:</p><formula xml:id="formula_13">ğœ‚ 2 = ğ›¼ ğœ‚ 2 + ğ›½ 21 ğœ‚ 1 + ğœ€ ğœ‚ 2 (9) ğœ‚ 3 = ğ›¼ ğœ‚ 3 + ğ›½ 32 ğœ‚ 2 + ğœ€ ğœ‚ 3<label>(10)</label></formula><p>The measurement model equations are: Note that I am using the marker variable (also known as scaling indicator or reference variable) approach to scale the latent variable and I am using the first indicator of each variable as the marker variable. I have fixed the intercepts at zero and factor loadings at one for the marker variables, ğ‘¦ 1 , ğ‘¦ 4 , and ğ‘¦ 7 . Model specification, as presented here, is no different from model specification as it is usually presented in SEM.</p><formula xml:id="formula_14">ğ‘¦ 1 = ğœ‚ 1 + ğœ€ ğ‘¦ 1 ğ‘¦ 2 =</formula><p>Step</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">-Latent to Observed Transformation</head><p>The second step is the "latent to observed" (L20) variable transformation. Unlike the previous step, which was identical to typical SEM specification, this step is unique to MIIV-2SLS. In this step, we algebraically manipulate every equation, transforming them into observed variable regressions.</p><p>First, using the marker variable equations we re-define every latent variable as its scaling indicator minus its error. Below is the L20 transformation, for all three latent variables from our model. Note we have taken the scaling indicator equations for all three latent variables.</p><formula xml:id="formula_15">ğ‘¦ 1 = ğœ‚ 1 + ğœ€ ğ‘¦ â†’ ğœ‚ 1 = ğ‘¦ 1 -ğœ€ ğ‘¦ 1 ğ‘¦ 4 = ğœ‚ 2 + ğœ€ ğ‘¦ 4 â†’ ğœ‚ 2 = ğ‘¦ 4 -ğœ€ ğ‘¦ 4 ğ‘¦ 7 = ğœ‚ 3 + ğœ€ ğ‘¦ 7 â†’ ğœ‚ 3 = ğ‘¦ 7 -ğœ€ y</formula><p>Every latent variable is now expressed as an observed variable minus error. For example, ğœ‚ 1 is now defined as ğ‘¦ 1 -ğœ€ ğ‘¦ 1 .</p><p>Next, using algebraic substitution, we replace every instance of a latent variable, with the L20 expression above. In this case, we replace ğœ‚ 1 , ğœ‚ 2 , and ğœ‚ 3 in the remaining equations. By replacing ğœ‚ 1 , ğœ‚ 2 , and ğœ‚ 3 , in all the remaining equations, we are left with model equations containing only observed variables, while maintaining all of the original regression parameters.</p><p>For example, in equation ( <ref type="formula">9</ref>), we replace both ğœ‚ 2 and ğœ‚ 1 by their respective observed variable expressions:</p><p>In the last step, ğ‘¢ 4 is a composite error term, replacing the complex error term in the step above.</p><p>The above algebraic manipulations show that we can re-express every equation as an observed variable equation, keeping the parameters the same. </p><p>principles for choosing scaling indicators with MIIV-2SLS as one would use with ML. It is best to choose the scaling indicator which is most representative of, or the best measure of, the latent variable in question. Note that the magnitude of parameter estimates will be relative to the magnitude and variance of the scaling indicator. This is generally true when choosing scaling indicators for ML and MIIV-2SLS. The magnitude and variance of the scaling indicator will affect the magnitude and variances of the intercept and coefficient estimates. However, if the model is correctly specified, choice of scaling indicator will not change the overall pattern of results.</p><p>Step</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">-Identify Model Implied Instrumental Variables</head><p>The third step is to identify instrumental variables for each equation. In traditional applications of instrumental variable estimation, instruments are found from outside the system of equations. Discovering clever instruments is thought of as an arduous process. A unique feature of MIIV-2SLS estimation is that we identify instruments from within the system.</p><p>There are several important conditions for a set of instruments to be valid. First, an instrument needs to be uncorrelated with the error in the equation. Second, the instrument needs to be correlated with the problematic explanatory variable. Third, at a minimum there need to be as many instruments as there are problematic explanatory variables. There are other more technical conditions. For example, the covariance matrix of the instrument set must be nonsingular, and the rank of the covariance matrix of instruments and independent variables is equal to the number of independent variables. These last two eliminate the possibility of perfect collinearity of instruments and ensure sufficient association between instruments and independent variables <ref type="bibr">(Bollen, 2012)</ref>. From a practical perspective, in general if a model is globally identified, then there will be enough instrumental variables for every equation in the model <ref type="bibr">(Bollen, 2019)</ref>. <ref type="bibr" target="#b21">Bollen (1996b)</ref> outlines two ways to identify MIIVs. The most intuitive approach involves following the direct and indirect paths of the composite errors in the L2O equations in an algorithmic fashion. These steps are also described in several other papers, most recently in <ref type="bibr">Bollen (2019)</ref>. I have modified the steps slightly from <ref type="bibr">Bollen (2019)</ref>, though the result is identical. Identifying MIIVs one equation at a time, we can go through the following steps:</p><p>1. Use the first component of the composite error and identify all observed variables in direct or indirect paths from that component. Eliminate all of these variables as potential MIIVs.</p><p>2. Consider all error terms correlated with the composite error in question. Identify all observed variables in direct or indirect paths from these. Eliminate all of these variables as potential MIIV's.</p><p>3. Repeat Steps 1 &amp; 2, for all components of the composite error.</p><p>4. All remaining variables are MIIVs for the specific equation.</p><p>Consider equation ( <ref type="formula">9</ref>) again, and more specifically the transformed equation ( <ref type="formula" target="#formula_16">11</ref>). The first component of the composite error is ğœ€ ğœ‚ 2 .</p><p>Step 1: The set of variables with direct and indirect paths from ğœ€ ğœ‚ 2 include ğ‘¦ 4 , ğ‘¦ 5 , ğ‘¦ 6 , ğ‘¦ 7 , ğ‘¦ 8 , ğ‘¦ 9 , and we eliminate all of these from the set of possible</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIIVs.</head><p>Step 2: There are no correlated errors. We repeat these steps for the next two error terms, ğœ€ ğ‘¦ 4 and ğœ€ ğ‘¦ 1 , also eliminating ğ‘¦ 1 as a potential MIIV. This leaves ğ‘¦ 2 and ğ‘¦ 3 as the set of MIIVs for equation ( <ref type="formula" target="#formula_16">11</ref>). This process is repeated for every equation in the model, identifying a unique set of MIIVs in every equation. In general, one does not need to identify MIIVs by hand as this process has been automated in a variety of software programs. <ref type="bibr" target="#b21">Bollen (1996b)</ref> developed an algorithm to automatically select model-implied instruments; <ref type="bibr" target="#b26">Bollen &amp; Bauer, (2004)</ref> programmed this is SAS, Bauldry, (2014) made it available in Stata, and Fisher, Bollen, Gates, and Ronko, (2017) programmed it in R.</p><p>Most of the literature on identifying MIIVs has focused on identifying the full set of all possible instruments. However, there may be circumstances when it might be beneficial to use a subset of instruments, instead of using all possible instruments. For example, <ref type="bibr">Bollen et al. (2007)</ref> found that using a large number of instruments could lead to downward bias in small samples.</p><p>They also found that using a subset of instruments corrected this bias. Others have noted that having a large set of instruments may be more likely to induce weak instrument bias as a part of estimation <ref type="bibr" target="#b41">(Donald &amp; Newey, 2001)</ref>.</p><p>To date, no study has explicitly examined methods for identifying optimal subsets of instruments with MIIV-2SLS. Though this dissertation does not deal with the topic of instrument selection at length, it is worth mentioning. Indeed, this could be a fruitful topic for future inquiry.</p><p>One could imagine three possible strategies for choosing subsets of instruments. First, would be a completely random selection. Given a large set of instruments, one could simply select a random subset. This strategy is unlikely to be the most useful. Second, would be to select instruments that the model implies are more related to the problematic variable. For example, variables from the same latent variable are likely to be more highly correlated, than indicators of another latent variable. In this way, one could use theory to make the subset selection. The last option would be to use data driven techniques such as dimension reduction or variable selection.</p><p>There is a long history of these methods being applied with instrumental variables; <ref type="bibr">Kloek and Mennes (1960)</ref> proposed the use of principal components to create more optimal instrument sets (see also <ref type="bibr" target="#b0">Amemiya, 1966)</ref>. More recently, others in econometrics have suggested strategies such as the jackknife and lasso regression as data driven techniques for selecting optimal sets of instruments <ref type="bibr" target="#b7">(Bai &amp; Ng, 2009;</ref><ref type="bibr" target="#b57">Hansen &amp; Kozbur, 2014</ref>). These methods have not been studied in the context of MIIV-2SLS and more research is needed before these can be applied with confidence.</p><p>From a practical perspective, I would suggest that in most circumstances one should use the full setoff MIIVs. However, in small samples or models with a large number of indicators, it can make sense to use smaller subsets of instruments. There is an additional tradeoff with using all instruments vs a subset of instruments. Using the full set of instruments would provide the most power to test equations with the Sargan test (given sufficiently large sample). On the other hand, choosing a subset of instruments would mean one is less likely to have an incorrect instrument and could make the equation less susceptible to bias. Indeed, more research is needed on the topic of optimal instrument section with MIIV-2SLS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step 4 -Two Stage Least Squares Estimation</head><p>Once we have identified all MIIVs for each equation, the final step is to perform instrumental variable estimation. There are several possible instrumental variable estimators;</p><p>2SLS is one of the more common and popular instrumental variable estimators, and it is the estimator we use in this context.</p><p>The first stage of 2SLS is to regress the problematic predictor variable on the full set of instruments. Continuing the example from equation ( <ref type="formula" target="#formula_16">11</ref>), the problematic predictor variable is ğ‘¦ 1 , the set of instruments are ğ‘¦ 2 and ğ‘¦ 3 . Equations up to this point have been in scalar notation. I now switch to matrix notation as this is simpler to express regression estimation. Let the matrix ğ‘½ contain the set of instruments (and a column of 1's), ğ’€ ğŸ is the vector of ğ‘¦ 1 observations and ğ’€ ğŸ’ is the vector of ğ‘¦ 4 observations. We perform this regression as:</p><p>(ğ‘½â€²ğ‘½) -ğŸ ğ‘½â€²ğ’€ ğŸ and predicted ğ’€ ğŸ 's are given as</p><formula xml:id="formula_17">ğ’€ Ì‚ğŸ = ğ‘½(ğ‘½â€²ğ‘½) -ğŸ ğ‘½â€²ğ’€ ğŸ</formula><p>The second stage of 2SLS involves regressing the original left hand side outcome variable (in this case ğ‘¦ 4 ) on the predicted values from the previous step.</p><p>ğ‘¨ Ì‚= (ğ’€ Ì‚ğŸâ€²ğ’€ Ì‚ğŸ) -ğŸ ğ’€ Ì‚ğŸâ€²ğ’€ ğŸ’ (12)</p><p>Let ğ‘¨ Ì‚ contain the estimated 2SLS regression coefficients. The steps described here follow the usual equation-by-equation 2SLS description and the way this was first implemented in <ref type="bibr" target="#b20">Bollen (1996)</ref>.</p><p>Standard Errors for MIIV-2SLS are obtained by</p><formula xml:id="formula_18">acov(ğ‘¨ Ì‚) = ğˆ Ì‚ğŸ (ğ’€ Ì‚ğŸğ‘» ğ’€ Ì‚ğŸ) -ğŸ<label>(13)</label></formula><p>where,</p><p>ğˆ Ì‚ğ‘–ğŸ = (ğ’€ ğŸ’ ğ’Š -ğ’€ ğŸ ğ’Š ğ‘¨ Ì‚ğ’Š) ğ‘» (ğ’€ ğŸ’ ğ’Š -ğ’€ ğŸ ğ’Š ğ‘¨ Ì‚ğ’Š) ğ‘µ .</p><p>The above equations are the general expressions for 2SLS estimation with the raw data. <ref type="bibr" target="#b47">Fox (1979)</ref> derived the estimating equations when using covariance matrices. The general form is given below where ğ‘£ indicates instruments, ğ‘¥ indicates independent variables, and ğ‘¦ indicates the dependent variable in each equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ğ‘¨ Ì‚= (ğ‘º</head><formula xml:id="formula_19">ğ‘¥ğ‘£ ğ‘º ğ‘£ğ‘£ -1 ğ‘º ğ‘£ğ‘¥ ) -1 (ğ‘º ğ‘¥ğ‘£ ğ‘º ğ‘£ğ‘£ -1 ğ‘º ğ‘£ğ‘¦ )<label>(14)</label></formula><p>And standard errors are given in this form as</p><formula xml:id="formula_20">acov(ğ‘¨ Ì‚) = ğˆ Ì‚ğ‘– 2 [ğ‘º ğ‘¥ğ‘£ ğ‘º ğ‘£ğ‘£ -ğŸ ğ‘º ğ‘£ğ‘¥ ] -1</formula><p>and,</p><formula xml:id="formula_21">ğˆ Ì‚ğ‘–2 = [ğ‘º ğ‘¦ğ‘¦ + ğ‘¨ Ì‚ğ‘‡ğ‘º ğ‘¥ğ‘¥ ğ‘¨ Ì‚-ğŸğ‘º ğ‘¦ğ‘¥ ğ‘¨ Ì‚]ğ‘ -1</formula><p>This particular form will be useful when estimating MSEMs, because of the way data are decomposed into covariance matrices at each level. With multilevel data, we will not have access to raw data at each level, but we can use covariance matrices from each level. The covariances can be used with Equation ( <ref type="formula" target="#formula_19">14</ref>) to obtain 2SLS parameter estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sargan test</head><p>In circumstances where there are more MIIVs than explanatory variables in an equation, To test if the instruments are correlated with the error, several tests have been proposed</p><p>and used in the general instrumental variable literature. <ref type="bibr" target="#b87">Kirby and Bollen (2009)</ref> tested several of these tests and concluded that The <ref type="bibr" target="#b135">Sargan (1958)</ref> test statistic had the best overall performance with MIIV-2SLS.</p><p>The usual form of the Sargan test is given as</p><formula xml:id="formula_22">ğ‘† ğœ’ 2 = ğ’– Ì‚â€²ğ’(ğ’ â€² ğ’) -1 ğ’ğ’– Ã» Ì‚â€²ğ’– Ì‚/ğ‘›<label>(15)</label></formula><p>Where ğ’– Ì‚ contains the residuals and Z contains the instrumental variables, ğ‘› is the sample size <ref type="bibr" target="#b87">(Kirby &amp; Bollen, 2009)</ref>. ğ‘† ğœ’ 2 follows a chi-square distribution with degrees of freedom equal to the difference in the number of instrumental variables and independent variables in the equation. <ref type="bibr">Hayashi (2000, p. 229</ref>) derives an equivalent form of the Sargan test statistic in form using sample covariance matrices.</p><formula xml:id="formula_23">ğ‘† ğœ’ 2 = ğ‘› (ğ‘º ğ’›ğ’š -ğ‘º ğ’›ğ’™ ğ‘¨ Ì‚2ğ‘†ğ¿ğ‘† ) â€² ğ‘º ğ’›ğ’› -ğŸ (ğ‘º ğ’›ğ’š -ğ‘º ğ’›ğ’™ ğ‘¨ Ì‚2ğ‘†ğ¿ğ‘† ) ğœ Ì‚2<label>(16)</label></formula><p>Where ğ‘º ğ’›ğ’š contains covariances between instruments and dependent variables, ğ‘º ğ’›ğ’™ contains covariances between instruments and right hand side explanatory variables, ğ‘º ğ‘§ğ‘§ is contains variance and covariances of instruments, ğ‘¨ Ì‚2ğ‘†ğ¿ğ‘† are 2SLS estimates from equation ( <ref type="formula" target="#formula_19">14</ref>), and ğœ Ì‚2 is the residual variance.</p><p>Finally, the effectiveness of the Sargan test is related to the choice of instruments. If testing the model structure is of primary importance, then using the full set of possible instruments will provide the most power to detect misspecification. When one uses subsets of instruments it could come with a trade-off in that the Sargan test will have less power to detect misspecification in the model. However, in some circumstances this trade-off might be completely justified if using a smaller subset of instruments leads to better estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIIV-2SLS Estimation for MSEMs</head><p>In this section, I move beyond the single level SEM and outline how to estimate and test MSEMs with MIIV-2SLS. The general procedure can be outlined as follows. First, estimate level specific sample covariance matrices (ğ‘º ğ‘Š and ğ’ ğµ ) and their associated asymptotic covariance matrices. Next, use ğ‘º ğ‘Š and ğ’ ğµ as input to fit the within and between models separately using MIIV-2SLS. In order to obtain standard errors for all parameters, I propose to use the delta method, to correct for the fact that ğ‘º ğ‘Š and ğ’ ğµ are estimates. Finally, model testing can be done equation-by-equation with a modified version of the Sargan test. I provide more detail throughout the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Point Estimates and Inference</head><p>The first step is to estimate the within and between covariance matrices ğ‘º ğ‘Š and ğ’ ğµ and their associated asymptotic covariance matrices. This can done in the same way proposed by <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> by maximizing the likelihood function in equation ( <ref type="formula" target="#formula_7">6</ref>). The asymptotic variances and covariances are given in equation ( <ref type="formula" target="#formula_10">8</ref>). Although, I am proposing to implement the estimation routine outlined by <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref>, this step could theoretically be performed in a variety of ways. ğ‘º ğ‘Š and ğ’ ğµ could be estimated with existing software such as lavaan or Mplus by specifying a fully saturated MSEM at both levels (e.g., covary all variables with one another at both levels). As long as we are able to obtain consistent estimates of ğ‘º ğ‘Š and ğ’ ğµ we can obtain consistent point estimates at each level of the model.</p><p>To obtain point estimates, we treat ğ‘º ğ‘Š and ğ’ ğµ as raw data and apply the MIIV-2SLS to each level of the model separately. More specifically the steps are (1) specify the model at each level, (2) perform the L2O transformations at each level, (3) Identify MIIVs at each level, and</p><p>(4) apply equation 14 at each level to obtain point estimates. <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> point out that estimating levels separately can have benefits such as preventing the spread of misspecification bias across levels.</p><p>Next, we need to make adjustments to the usual 2SLS standard errors. In this case, ğ‘º ğ‘Š and ğ’ ğµ are ML based estimates with associated sampling variability. This additional sampling variability needs to be reflected in our estimates of uncertainty. There may be a number of ways to obtain accurate standard errors. In this study, I will use the delta method to obtain approximate standard errors. The delta method is one tool which statisticians often use to estimate the variances of functions of random variables <ref type="bibr" target="#b123">(Oehlert, 1992)</ref>. I describe this is more detail shortly and I will demonstrate in the next chapter that the delta method standard errors adequately capture the sampling variability.</p><p>The delta method is not the only possible solution to obtaining correct standard errors.</p><p>Another solution often used by statisticians is bootstrapping. However, bootstrapping with hierarchical data requires additional considerations <ref type="bibr" target="#b52">(Goldstein, 2011a;</ref><ref type="bibr" target="#b53">Goldstein 2011b;</ref><ref type="bibr" target="#b148">van der Leeden, 2008)</ref>. In theory, the bootstrapping procedure needs to accurately reflect the true sampling procedure that generated the data. In non-heirarchical data this can be done simply by re-sampling observations with replacement. Recall from Chapter 2, that the MSEM model requires the assumption of random sampling at both levels of the model. In this way, if one were to apply bootstrapping by resampling observations at level 1, this would not accurately reflect the actual data generating process, leading to incorrect estimates of variability. Other forms of the bootstrap have been applied successfully with hierarchical data. In general, the parametric bootstrap is one of the better alternatives <ref type="bibr" target="#b52">(Goldstein, 2011a;</ref><ref type="bibr" target="#b53">Goldstein 2011b;</ref><ref type="bibr" target="#b148">van der Leeden, 2008)</ref>. For the parametric bootstrap, one would sample from the theoretical sampling distribution instead of from the empirical data. If one does not want to make parametric assumptions, it may be possible to use the non-parametric residual bootstrap. I do not implement these bootstrapping procedures as a part of this study. However, future work could investigate these as they may be excellent alternatives for estimating variability in these models. For now, I return to the delta method as the standard error correction method implemented in this dissertation.</p><p>The delta method is a flexible procedure often used by statisticians to estimate the variance of a function of a random variable <ref type="bibr" target="#b38">(CramÃ¨r, 1946;</ref><ref type="bibr" target="#b123">Oehlert, 1992;</ref><ref type="bibr" target="#b62">Hoef, 2012</ref>; See also</p><p>Raykov &amp; Marcoulides for an application of the delta method in SEM). Given some continuous differentiable function ğ‘“ of a random variable ğ‘¥, we can approximate the value of this function evaluated at ğœƒ through a Taylor series approximation, shown as:</p><formula xml:id="formula_24">ğ‘“(ğ‘¥) â‰ˆ ğ‘“(ğœƒ) + ğ‘“ â€² (ğœƒ)(ğ‘¥ -ğœƒ) + ğ‘“ â€²â€² (ğœƒ)(ğ‘¥ -ğœƒ) 2 + â€¦ (17)</formula><p>where ğ‘“ â€² is the first derivative of ğ‘“ and ğ‘“ â€²â€² is the second derivative of ğ‘“. With the delta method it is common to only use the first expansion such that</p><formula xml:id="formula_25">ğ‘“(ğ‘¥) â‰ˆ ğ‘“(ğœƒ) + ğ‘“ â€² (ğœƒ)(ğ‘¥ -ğœƒ)<label>(18)</label></formula><p>Importantly, the variance of ğ‘“(ğ‘¥) can be reasonably approximated by</p><p>Var(ğ‘“(ğ‘¥)) â‰ˆ Var(ğ‘“(ğœƒ) + ğ‘“ â€² (ğœƒ)(ğ‘¥ -ğœƒ))</p><p>â‰ˆ ğ‘“ â€² (ğœƒ) 2 Var(ğ‘¥)</p><p>The same principles apply in the multivariate case. Consider another function â„ representing our MIIV-2SLS estimator given in equation ( <ref type="formula" target="#formula_19">14</ref>). Let ğ’Œ represent the vectorized (and unique) elements of ğ‘º ğ‘Š and ğ’ ğµ . Theoretically, we could approximate the value of â„(ğ’Œ) using a Taylor Series expansion:</p><formula xml:id="formula_26">â„(ğ’Œ) â‰ˆ â„(ğœ½) + â„ â€² (ğœ½) ğ‘‡ (ğ’Œ -ğœ½)<label>(19)</label></formula><p>More importantly, we can use the variance of the Taylor series in order to estimate standard errors, adjusting for sampling variability ğ‘º ğ‘Š and ğ’ ğµ . Taking the variance leads to the following result:</p><formula xml:id="formula_27">ğ‘‰ğ‘ğ‘Ÿ(â„(ğ’Œ)) â‰ˆ â‰ˆ â‰ˆ â‰ˆ ğ‘‰ğ‘ğ‘Ÿ(â„(ğœ½) + â„ â€² (ğœ½) ğ‘‡ (ğ’Œ -ğœ½)) ğ‘‰ğ‘ğ‘Ÿ(â„(ğœ½) + â„ â€² (ğœ½) ğ‘‡ ğ’Œ -â„ â€² (ğœ½) ğ‘‡ ğœ½) ğ‘‰ğ‘ğ‘Ÿ(â„ â€² (ğœ½)ğ’Œ) â„ â€² (ğœ½) ğ‘‡ ğ¶ğ‘œğ‘£(ğ’Œ)â„ â€² (ğœ½)<label>(20)</label></formula><p>Where â„ â€² (ğœ½) are the partial derivatives ğğ’‰(ğœ½) ğğœ½ â€² (i.e., the Jacobian) of equation ( <ref type="formula" target="#formula_19">14</ref>), and ğ¶ğ‘œğ‘£(ğ’Œ) is the asymptotic covariance matrix of the estimates ğ‘º ğ‘Š and ğ’ ğµ given in equation ( <ref type="formula" target="#formula_10">8</ref>). The partial derivatives can be computed as numerical derivatives using the numDeriv library in R <ref type="bibr" target="#b49">(Gilbert, P. &amp; Varadhan, R., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adjusted Sargan test</head><p>As </p><p>In equation ( <ref type="formula" target="#formula_28">23</ref>),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ğğ’ˆ(ğˆ)</head><p>ğğˆ â€² is Jacobian of ğ’ˆ(ğˆ) = ğšº ğ’›ğ’š -ğšº ğ’›ğ’™ ğœ½ Ì‚2ğ‘†ğ¿ğ‘† , and ğš· is the asymptotic covariance matrix for the sample estimates of ğšº ğ– or ğšº ğ (note this step is where the sampling variability from the first stage is incorporated). Finally,</p><formula xml:id="formula_29">ğ‘ª Ì‚= ğ›€ -ğŸ<label>(24)</label></formula><p>While this particular form is rather complicated, one important feature to note is that the sampling variability from stage one, is being explicitly included in this adjusted Sargan test.</p><p>Importantly, <ref type="bibr" target="#b77">Jin and Cao (2018)</ref> analytically derived the asymptotic distribution of the modified test statistic proving that it follows a Chi-Square distribution with the same degrees of freedom as the original Chi-Square statistic given in ( <ref type="formula" target="#formula_23">16</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>To review, the MIIV-2SLS procedure I have outlined, addresses the potential shortcomings in the usual ML procedure for MSEMs. Additionally, the overall interpretation of the model is completely unchanged. Results from a model estimated with ML and with MIIV-2SLS would be interpreted identically (assuming results are the same). I review how MIIV-2SLS</p><p>addresses each of the potential shortcoming of ML based estimation for MSEMs.</p><p>First, MIIV-2SLS has been shown to be more robust to structural misspecification that ML. The procedure I have outlined should have the usual robustness between equations, and it has the added robustness that misspecification will not spread between levels.</p><p>The adjusted Sargan test offers equation-by-equation tests of model fit. Using chi-square based fit statistics have proven inadequate for testing model fit at both levels of the model <ref type="bibr">(Hsu,</ref> cross level interactions or random slopes within this framework. Whether this tradeoff is worthwhile depends on the specific application and modeling needs.</p><p>In the next chapter, I study the finite properties of the MIIV-2SLS estimator developed here.</p><p>Chapter 4, have appropriate Type-I error rates. How do these results relate to the previous work on model fit assessments in MSEMs?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Sample Size:</head><p>A final complication with MSEMs is the general need for a large number of clusters (100 is the recommended minimum). Could MIIV-2SLS be used in smaller samples to fit models, when ML might otherwise be problematic? One specific problem in small samples is non-convergence. Does MIIV-2SLS have a better convergence rate and does this depend on the sample size?</p><p>In order to test examine these research questions, I present two Monte Carlo simulations used to examine the MIIV-2SLS estimator and misspecification in MSEMs. In the first Monte Carlo simulation, I consider an MSEM model and study general estimator performance across a range of sample sizes. I also consider minor misspecifications to study robustness properties as well as the performance of Sargan Test in correctly and incorrectly specified models.</p><p>In the second Monte Carlo simulation, I consider misspecification of dimensionality in MSEMs (or an MCFA model more specifically). This type of misspecification has been the primary design used to study model fit testing in MSEMs. I use a similar setup in order to have comparable results to those of <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> and <ref type="bibr">Ryu, and West (2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation #1 -Methods</head><p>The first simulation is designed to demonstrate the general performance of MIIV-2SLS across a range of sample sizes and minor misspecifications. I will use the results of this simulation to reflect on all research hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data generation</head><p>Figure <ref type="figure" target="#fig_3">2</ref> displays the population data-generating model. The general pattern of zero and non-zero parameters are the same for the within and between levels. Factor loadings and latent variable regressions also share the same values between levels. While it is completely possible to have different models at each level it is also quite common to expect similar patterns of coefficients. Latent variable variances and residual variances are smaller at the between level than the within level. This is typical of most MSEMs. In this example, the ICCs for individual indicators range from 0.2-0.3, which might be considered a moderate amount of variance at the group level.</p><p>I manipulated two primary factors in generating the data: number of clusters and the average cluster size. The number of clusters varied continuously between 30 and 300. As a reminder, 100 clusters is commonly considered the minimum number of clusters recommended for ML estimation. Thus, I am testing well below and above the suggested minimum number of clusters. This range of clusters should capture many possible applications, particularly those in areas where it may be more difficult to sample from more than 50 clusters (e.g., states). I varied the average cluster size between 5 and 50. Clusters of 5 would be considered small and clusters of 50 would be considered large. The range of values chosen for this simulation captures small to sufficiently large cluster sizes. Overall, in previous simulations, the size of clusters has proven to be less important; the variety of cluster sizes reflects different possible applications. For example, smaller clusters might be expected in studies of classrooms and larger clusters could be expected in studies where clustering is based on geography or policy.</p><p>Instead of picking specific discrete conditions for cluster size and number of clusters, I allowed these variables to vary continuously between the limits described above. For example, for each iteration the value of the number of clusters was sampled from a random discrete uniform condition with lower and upper bounds of 30 and 300, respectively. The same random sampling procedure was used to set the average size of clusters, except that the lower and upper limits were 5 and 50. This design allows us to evaluate our results over a continuous range.  Unbalanced data was created in the following way. Within any dataset, I fixed the average cluster size, but I allowed the individual cluster sizes to vary around that average. The degree of unbalance was fixed such that minimum and maximum cluster sizes were set to be 50% smaller or larger than the average cluster size. For example, if the average cluster size were 10, then individual clusters sizes were generated randomly between 5 and 15. Similarly, if the average cluster size were set to 20, then individual clusters sizes were generated randomly between 10 and 30. Due to random sampling, the observed average cluster size can differ slightly from the fixed average cluster size.</p><p>With the above specifications, I generated 20,000 independent datasets. Data were generated using the Monte Carlo function of Mplus. Each data set was saved individually to be fit with each estimator and model specification (described next).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimators</head><p>For each dataset, I obtained parameter estimates using three estimators. The first estimator was ML as implemented in Mplus and the "Model = TWOLEVEL" framework (the Mplus language specification of the random intercepts MSEM). The second estimator was MIIV-2SLS using all possible instruments; the third was MIIV-2SLS with a subset of instruments. I will generally refer to these as 2SLS-ALLIV and 2SLS-OVERID2 respectively.</p><p>For 2SLS-OVERID2, I selected the minimum number of instruments necessary to over identify each equation by two degrees of freedom. MIIV-2SLS estimation was carried out in R using the package "MIIVmsem", which I programmed as a part of this dissertation.</p><p>When selecting the subset of instruments, the general rule I followed was to select instruments that one would expect to be most highly correlated with the problematic independent variable, based on the model. This selection strategy was done to mimic how someone might choose a subset of instruments based on the theory of their model. For example, for factor loadings I selected instruments from the same latent variable plus one additional instrument from the closest LV in the causal chain. For items with cross loadings, I selected instruments from both latent variables that the item was directly related. Additionally, I should note that the instruments I selected were fixed across iterations. I did not use any data-driven techniques to select instruments within each dataset, though this theoretically could have been done. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models fit</head><p>For every combination of dataset and estimator, I fit three possible model specifications:</p><p>the true model, omitted cross loadings at the within level, and omitted cross loadings at the between level. I will refer to these as the True Model, Misspecified Within, and Misspecified Between, respectively. Fitting three possible model specifications allowed me to investigate performance of all estimators under ideal circumstances as well as circumstances that are more realistic where the model is not correctly specified. I would also point out that the majority of equations remain completely unchanged between the correctly and incorrectly specified models. Any equation that remains unchanged will be robust to misspecifications for MIIV-2SLS. The same cannot be said for ML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I direct the reader to</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Evaluation</head><p>This simulation involved fitting 20,000 independent datasets with all combinations of estimator and model specification. Thus, this simulation involved fitting 180,000 separate models (20,000 datasets x 3 estimators x 3 model specifications).</p><p>I used a number of metrics to evaluate this simulation. The set of outcomes I examined included relative bias, root mean square error (RMSE), empirical standard deviation of estimates, standard error bias, proportion of 95% confidence intervals containing true parameter, and proportion of Sargan test rejections at ğ›¼ = 0.05. I provide the exact computational formulas for each of these in their respective sections below. Several of these outcomes need to be computed in discrete conditions (e.g., RMSE, standard deviation of estimates, standard error bias). For example, one cannot compute the empirical standard deviation of a single observation (in this case a single parameter estimate within one iteration). Instead, the standard deviation requires computing the variability of a group of observations. We need discrete conditions in order to compute this. This simulation design lacks discrete conditions and requires a small adjustment in order to make sense of these outcomes.</p><p>First, I note that one could technically consider each combination of cluster size and average number of clusters as a discrete condition. However, considering all possible combinations creates far too many discrete conditions and small within cell sample sizes. In order to create larger cell sizes, I aggregated over average cluster sizes creating three separate discrete conditions corresponding to average cluster sizes of 5-15, 16-30, and 31-50. Overall, average cluster sizes had low impact on results, and thus aggregating should not impact conclusions dramatically. At the same time, I did not aggregate number of clusters and treated each as a discrete condition. This leads to 810 discrete between cell conditions (270 discrete number of cluster conditions by 3 cluster size conditions). Each individual between cell conditions then had an average of 24.7 datasets per condition (each fit to all 9 combinations estimator and model specification). Compared to most simulations which have fewer conditions with many iterations per condition, I have many conditions with fewer iterations per condition.</p><p>Each outcome measure was assessed across the following variables: estimator (ML, 2SLS-ALLIV, 2SLS-OVERID2), model specification (True Model, Misspecified Within, Misspecified Between), average cluster size <ref type="bibr">(5-15, 16-30, 31-50)</ref>, and number of clusters (every individual level between 30-300), level of the model (Within or Between), parameter type (LV Regression, Primary Loading, Cross Loading).</p><p>Finally, it is worth discussing explicit meta-models. By meta-model, I mean a statistical model for a simulation outcome, where the outcome is predicted by a set of independent variables such as number of clusters and level of the model. <ref type="foot" target="#foot_6">8</ref> One might note that certain outcomes such as relative bias could be ideally summarized through an explicit statistical model.</p><p>Indeed, in my first attempt at analyzing this simulation I examined this approach. I concluded that an explicit meta-model came with several key complications which obscured the bigger picture and did not aid in understanding the findings.</p><p>The first complication is the functional form. Consider the simulation outcome relative bias as predicted by a single outcome number of clusters. One's first inclination might be to use a multiple regression model. However, this would be inappropriate, without modification, because we would not necessarily expect relative bias follow a linear functional form. Instead, we would expect the bias to change nonlinearly, approaching zero bias as the number of clusters increase.</p><p>Possible ways of dealing this would be a box-cox transformation of the outcome or imposing some other non-linear function. This type of non-linearity is arguably routine, but it can obscure interpretation.</p><p>The second complication is the number of possible interactions. Continuing the example above, we might expect relative bias to be related to all six independent variables outlined above (e.g., number of clusters, average cluster size, model specification, level of the model, etc.).</p><p>Further, we might expect many four, five, or even six way interactions to be significant. Again, interactions are not a problem from a modeling perspective, but they make interpretation of results much more complicated. One way to simplify this would be to run separate analyses for each estimator and specification. However, this only simplifies the interactions and leaves one needing to consider nine separate regression per outcome variable.</p><p>Finally, there are other considerations such as whether the meta-models should be mixed effects models (they probably should be). In sum, the interpretability of meta-models quickly becomes complicated between nonlinearities and potential for high level of interactions. I believe in this particular study that meta-modeling would only serve to complicate and obscure the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation #1 -Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convergence and Extreme Outliers</head><p>As with any iterative estimator, some models will not converge. This is a possible outcome for both ML and MIIV-2SLS in this study, though I expected that more models would converge with MIIV-2SLS than with ML. As a reminder, Stage 1 estimates for MIIV-2SLS are obtained via an iterative ML procedure, leading to the possibility that MIIV-2SLS will not converge during stage 1. Once stage 1 estimates are obtained, the rest of the MIIV-2SLS</p><p>procedure is non-iterative. There are many ways to deal with models that do not converge.</p><p>Overall rates of non-convergence were low in this simulation. As a result, I opted to remove and not replace models that did not converge. If either ML or MIIV-2SLS did not converge, the specific iteration was thrown out for all three estimators. Overall, I dropped less than 0.5% of cases; dropping few cases is unlikely to have an effect on the general pattern of results. In cases when ML failed to converge but MIIV-2SLS did converge, the MIIV-2SLS results did appear to be slightly more aberrant than other case. Though given a small sample it is difficult to draw any serious conclusions.</p><p>Figure <ref type="figure" target="#fig_9">3</ref> displays a heat map of convergence rates by number of clusters (x-axis), average cluster size (y-axis), estimator, and model specification. As predicted, MIIV-2SLS had a higher convergence rate. Although I would note that this difference was small and rates of convergence were generally high for both estimators. In total, 27 models did not converge with MIIV-2SLS, and this is completely unaffected by model specification. Using ML, 71 models did not converge in the true model conditions, 80 models did not converge in the misspecified within model, and 96 models did not converge in the misspecified between model. It is unsurprising to note that the majority of models that did not converge had both a small number of clusters and a small average cluster size.</p><p>The general pattern of converged models also points to an interesting difference between ML and MIIV-2SLS. The rate of convergence with ML depends on the model specification. A less accurate model specification leads to a lower probability of convergence. On the other hand, the iterative portion of this MIIV-2SLS procedure is model independent, and thus rates of convergence are unrelated to model specification. In addition to removing datasets corresponding to models that did not converge, I removed 6 additional datasets which produced extreme outliers (4 MIIV-2SLS solutions and 2 ML solutions). All six datasets were removed for all estimators. All of the problematic datasets contained fewer than 35 total clusters and average cluster sizes less than 10. Solutions were considered to be extreme outliers if the normed score (z-score) of either the parameter estimate or the standard error was greater than 200. In one example, the expected standard error for a parameter would have been roughly 0.3, while estimated standard error was over 100. Majority of outliers were not removed, as this is to be expected in any simulation; I only removed the small number of extreme outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relative Bias</head><p>The first outcome I considered was relative bias. The relative bias of an individual estimate is given by</p><formula xml:id="formula_30">ğ‘…ğµ = ( ğœƒ Ì‚ğ‘– -ğœƒ ğœƒ )<label>(25)</label></formula><p>where ğœƒ Ì‚ğ‘– is the parameter estimate for iteration ğ‘–, and ğœƒ is the true population parameter value.</p><p>The average RB was computed within conditions determined by the six factors described previously (estimator, model specification, number of clusters, average cluster size, level of the model, and parameter type).</p><p>Figure <ref type="figure" target="#fig_10">4</ref> displays scatterplots of mean relative bias given the True Model specification.</p><p>In addition to plotting the average relative bias in each condition, I have added non-parametric locally weighted scatterplot smoothing averages to highlight trends. The average relative bias for within level parameters is effectively zero across all conditions. Even at the smallest clusters sizes and least number of clusters, the effective sample size for within level is at least 150. Given that the effective sample size for the within level model is always reasonably large, the lack of bias at the within level is unsurprising.</p><p>The relative bias for the between level parameters is slightly more interesting. Generally, there is very little bias with ML, even at the smallest sample sizes and 30 clusters. Similarly, there is little bias when using a subset of the MIIVs ("2SLS-OVERID2"). I found the most bias in small samples with MIIV-2SLS when using all possible instruments. This result is consistent with previous MIIV-2SLS studies <ref type="bibr">(Bollen, et al 2007)</ref>. Latent variable regressions and the cross loading parameters were mostly below five percent relative bias which many would consider tolerable. Bias in this condition of using all MIIVs was most notable given the combination or small clusters and a small number of clusters. Interestingly we find consistent results comparing ML and MIIV-2SLS. For those parameters that are incorrectly specified, we find bias as expect. For loadings that are correctly specified we do not find bias for either ML or MIIV-2SLS. For latent variable regressions, we find that the misspecification creates bias with ML; this creates a little over 10% relative bias. On the other hand, estimates from MIIV-2SLS remain unchanged (and unbiased) from the true model condition. This result is an example of the robustness to misspecification of the MIIV-2SLS</p><p>estimator and it is directly related to one of the robustness conditions described in <ref type="bibr" target="#b27">Bollen, Gates, and Fisher (2018)</ref>.</p><p>Additionally, we find that the within level misspecification leads to some parameters being biased at the between groups level when using ML. This is despite the between groups model being perfectly specified. This is particularly true for the cross loading parameters, which are omitted at the within level, and the bias is most pronounced when average cluster sizes are small. At the same time, MIIV-2SLS estimates fom the between level model are robust to the misspecification at the within level. This procedure prevents misspecification at one level of the model from spreading to the other level of the model. <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> predicted that a segregated approach to modeling would prevent bias spreading across levels even for ML. This suggests a unique robustness property of using MIIV-2SLS to estimate MSEMs; misspecification at one level of the model will not affect parameter estimates at another level of the model.</p><p>A similar pattern of results emerges when considering the misspecified between model (omitted cross loadings at the between level). Figure <ref type="figure">6</ref> displays the relative bias results for this specification. We find that incorrectly specified loadings are biased for both ML and MIIV-2SLS and other loadings remain unbiased. Again, the misspecification spreads to LV regressions with ML, and MIIV-2SLS is robust to this. Additionally, when the misspecified model is the between This bias is within tolerable ranges. The MIIV-2SLS estimates at the within level model are entirely unchanged from the true model specification, again illustrating robustness to cross level misspecification.</p><p>Figure <ref type="figure">6</ref>. Average relative bias given the misspecified between level model. Correct and Incorrect specification is with respect to the MIIV-2SLS equations given in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Finally, across all model specifications there was not much difference between the 2SLS-ALLIV and 2SLS-OVERID estimators when the number of clusters was greater than 100. The primary difference between was in small cluster samples, where the 2SLS-OVERID2 estimator remained unbiased while using all instruments led to some negative bias. In other words, in terms of bias one needs to be most aware of the number of instruments being used in small samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Root Mean Squared Error</head><p>Next, I considered RMSE as another metric for the discrepancy between the true and estimated parameters. RMSE is computed as</p><formula xml:id="formula_31">ğ‘…ğ‘€ğ‘†ğ¸ = âˆš âˆ‘ (ğœƒ ğ‘– Ì‚-ğœƒ) 2 ğ¼ ğ‘–=1 ğ¼ (<label>26</label></formula><formula xml:id="formula_32">)</formula><p>where ğ¼ is the number of iterations in a condition, and condition is determined by the combination of estimator, model specification, number of clusters, average cluster size, level of the model, and parameter. Finally, these RMSE values are averaged over parameter type (e.g.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LV regression).</head><p>Figure <ref type="figure" target="#fig_11">7</ref> illustrates RMSE values from the True Model specification. All three estimators have similar RMSE, with ML sometimes appearing to have a slightly lower RMSE on average. This effect is perhaps most pronounced at the smallest average cluster sizes and when estimating cross loadings. The scale of Figure <ref type="figure" target="#fig_11">7</ref> makes it somewhat difficult to see differences between RMSE at the within level. Figure <ref type="figure" target="#fig_1">8</ref>, presents the same data, but for the within level only and with a y-axis more conducive to showing the differences at the within level. Figure <ref type="figure" target="#fig_11">7</ref> &amp; Figure <ref type="figure" target="#fig_1">8</ref> collectively suggest that that the overall variability around the true parameter is similar between ML and MIIV-2SLS, with ML having slightly lower variability around the true. This result obviously relies on the assumption of true model specification.   precisely other estimators can be equally as efficient, but no estimator will be more efficient. Of course, this result only holds if the distributional assumptions hold and the model is exactly valid. The efficiency of MIIV-2SLS is important to consider, as we might expect there to be a general tradeoff between bias and variability.</p><p>In order to assess the variability of estimates, I used the empirical standard deviation of the estimates. This is computed as:</p><formula xml:id="formula_33">ğ‘  ğœƒ Ì‚= âˆš âˆ‘ (ğœƒ ğ‘– Ì‚-ğœƒ Ì… ) 2 ğ¼ ğ‘–=1 ğ¼ -1<label>(27)</label></formula><p>Again, ğ¼ is the number of iterations in a condition determined by the combination of estimator, model specification, number of clusters, average cluster size, level of the model, and parameter.</p><p>After, I computed the mean ğ‘  ğœƒ Ì‚ over parameter types (e.g., LV regression or factor loading), in order to simplify the results.</p><p>Figure <ref type="figure">11</ref> illustrates the empirical standard deviations across conditions when fitting the true model. Results from the misspecified model conditions are similar and I include these in the appendix. Unsurprisingly, these results share a similarity to the RMSE results, with the exception that RMSE is influenced by bias. The empirical standard deviations of each estimator are remarkably similar on average. As expected, ML appears to have a slightly lower variability, though this depends on the level of the model and parameter in question. The relation between MIIV-2SLS and ML appears stable across number of clusters and average cluster size. The most notable differences can be seen for parameters with the lowest magnitude (cross loadings). For factor loadings, we see almost no difference between estimators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standard Error Bias</head><p>Next, I turn to the overall quality of the standard errors. The MIIV-2SLS procedure developed in this document uses delta method standard errors. Delta method standard errors are approximate standard errors which are asymptotically unbiased. It is important to verify their performance in finite samples as compared to ML. In order to do this, I consider the standard error bias, computed as the difference between the standard error and the empirical standard deviation, scaled by the empirical standard deviation. The empirical standard deviation is being used as a proxy for the true variability. The standard error bias of a single estimate is:</p><formula xml:id="formula_34">ğ‘†ğ¸ ğ‘ğ‘–ğ‘ğ‘  = ( ğ‘†ğ¸ ğ‘– -ğ‘  ğœƒ Åğœƒ Ì‚)</formula><p>where, ğ‘†ğ¸ ğ‘– is the standard error for an individual parameter of iteration ğ‘– and ğ‘  ğœƒ Ì‚ is the empirical standard deviation as computed in equation ( <ref type="formula" target="#formula_33">27</ref>). Similar to relative bias of estimates, I computed the mean of ğ‘†ğ¸ ğ‘ğ‘–ğ‘ğ‘  by estimator, model specification, average cluster size, number of clusters, level of the model, and parameter type. for other model specifications are in the appendix. On average, there is little bias in the standard errors, across all three estimators. When there is bias, it primarily appears to be positive bias on average, suggesting the standard errors are more likely to be anti-conservative (slightly too big).</p><p>These results suggest that the delta method standard errors used with MIIV-2SLS, are generally adequate for capturing the true variability across a range of sample sizes and parameters. There are a few caveats which I discuss next.</p><p>In the smallest sample size conditions (small average cluster size and small number of clusters) for between level factor loadings, the standard error bias for 2SLS-ALLIV appears rather high and positive (in fact it goes off the chart). This result is somewhat extreme and unexpected. It is partly a result of several large outliers; sensitivity analyses (removing some additional outliers) made this result somewhat less extreme, but overall bias remains rather high in these conditions. This result might suggest that these delta method standard errors can be unstable in very small samples, when using a large number of instruments. Similar to the relative bias in estimates, this problem was fully mitigated by using a subset of instruments (2SLS-OVERID2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>95% Confidence Intervals</head><p>Another useful metric for standard errors is the proportion of 95% confidence intervals that include the true population parameter. If the standard errors accurately reflect the true sampling variability, then we would expect the 95% confidence intervals to contain the true population parameter 95% of the time. The primary shortcoming of using the 95% confidence interval is that it assumes the estimates are unbiased. When estimates are biased the confidence intervals will not contain the true parameter value at the correct rate. Given this, I only consider the True Model specification.</p><p>Figure <ref type="figure" target="#fig_15">13</ref> shows the proportions of the 95% confidence intervals that include the true parameter estimates. For the vast majority, the 95% confidence intervals do capture the true population parameter 95% of the time, as expected. At the between level model we do see that 95% confidence intervals with the ALLIV estimator does not perform as well at smaller samples while the 2SLS-OVERID2 does. This is explained by the bias in using all MIIVs reported previously and is does not reflect that the standard errors are too small. Finally, at the between level model, ML confidence intervals appear to capture the true parameter at a rate slightly below 95%, but this could be due to bias as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sargan Test Results</head><p>Finally, I examined the performance of the adjusted Sargan test. Overall, we would expect this test to reject the null hypothesis at the level of alpha in correctly specified equations and at some rate much higher than alpha for incorrectly specified equations. Given that I  As expected, the Sargan test rejects the null hypothesis at or below the level of alpha. There do not appear to be any appreciable differences between the 2SLS-ALLIV and 2SLS-OVERID2</p><p>estimators. There are differences between rejection rates for the unadjusted p-values vs the B-H p-values. When using the unadjusted p-values the rejection rate is generally much closer to 0.05. Using the B-H corrected standard errors leads to effectively 0% rejection rates. Given that the unadjusted p-values do not lead to rejection rates higher than 0.05, this suggests that correcting for multiple testing may not be completely necessary.</p><p>Next, we consider Sargan test in the presence of misspecification. For misspecified equations at the within level (Figure <ref type="figure" target="#fig_19">15</ref>) the Sargan test rejects the null hypothesis almost 100% of the time, except for in very small numbers of clusters where the lowest rate of rejecting the null is still around 0.8. There are small differences in the B-H rejection rates leading to slightly lower power in small samples. For misspecified equations at the between level (Figure <ref type="figure" target="#fig_20">16</ref>) the Sargan test has less power especially given smaller sample sizes. 2SLS-OVERID2 rejects the null hypothesis as a much higher rate as well, which suggests that the effectiveness of Sargan test depends on the instruments used. Given medium to large cluster sizes, both 2SLS-ALLIV and 2SLS-OVERID2 reach roughly 80% power when number of clusters reaches 200-250 clusters, using the unadjusted p-values. The difference in the B-H pvalues are starker in this example, such that using adjusted p-values leads to a dramatic loss in power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation #1 -Conclusion</head><p>It is worth revisiting my motivating research questions with Simulation #1 results in mind. First, robustness. In this simulation, MIIV-2SLS was more robust than ML to the spread  of bias within the model. MIIV-2SLS was additionally robust to the spread of misspecification between levels. The robustness to the spread of misspecification within any given level is a wellknown property in the SEM literature <ref type="bibr" target="#b23">(Bollen, 2001)</ref>. The between level robustness is relatively unique except for the ML based method proposed by <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref>. The combination of robustness both within and between levels, makes MIIV-2SLS uniquely situated as an estimator for MSEMs.</p><p>In terms of efficiency, in this simulation, MIIV-2SLS was slightly less efficient than ML.</p><p>However, in many cases this difference was negligible. One could easily argue that the slight loss in efficiency is a worthwhile tradeoff for the additional robustness. One might also wonder why there were not larger differences in efficiency. This result echoed previous work comparing MIIV-2SLS to ML (e.g., <ref type="bibr">Bollen et al., 2007)</ref>. With that said, the small differences in efficiency here could be due to certain design decisions. Future studies should consider if different models lead to larger differences in efficiency. In other words, the lack of difference in efficiency could be in part an effect of study design.</p><p>The delta method standard errors corresponding to model parameters generally captured the sampling variability. This was true for the vast majority of conditions in the study. In other words, one could use the measures of uncertainty to perform inference tests with MIIV-2SLS</p><p>and have confidence in their conclusions. At small sample sizes, the delta method standard errors did display some evidence of large positive bias (perhaps instability) when using all possible instruments. This can be corrected with a smaller subset of instruments. Based on this result, in practice it would be wise to consider using a subset of instruments if one were to have a relatively small sample size. This would mitigate both the potential for parameter bias and overly large standard errors.</p><p>In terms of assessing model fit (i.e., Sargan Test results) using the unadjusted p-values Sargan test had an appropriate Type 1 error rate while also being able to detect correctly misspecification. Given misspecification at the within level model, Sargan had 100% power across the majority of sample sizes tested and a minimum 80% power for the smallest samples.</p><p>Given misspecification at the between level model, Sargan had less power overall, though this obviously depended on sample size. Finally, given that the Type-1 error rates were not inflated for correctly specified equations, these results suggest that the B-H adjusted p-values may not be a necessary correction. Indeed, using the B-H p-values led to a significant loss of power and increase in Type 2 errors given misspecified equations, particularly at the between level.</p><p>In this simulation, small sample properties of MIIV-2SLS were generally positive, with some mixed results at the smallest of samples. This particular quality could be one of the most useful for MIIV-2SLS. The recommended number of clusters for ML estimation-100 clustersis limiting. In many applications, the typical recommendations of 100 clusters is simply not feasible. Thus, one of the primary limitations of MSEMs as a whole, is that many cannot obtain large enough samples to use the method. The performance of MIIV-2SLS in smaller samples could open the door for many more applications.</p><p>The primary limitation in MIIV-2SLS estimation in small samples was the tendency for estimates to have negative bias when using all possible instruments. This result was similar to the findings of <ref type="bibr">Bollen et al. (2007)</ref>. This bias can almost certainly be attributed to the weak instrument bias which is known to be a problem in small samples with 2SLS <ref type="bibr" target="#b117">(Nelson and Startz, 1990;</ref><ref type="bibr">Bound, Joeger, &amp; Baker, 1995)</ref>. <ref type="bibr" target="#b117">Nelson and Startz (1990)</ref> showed that 2SLS was biased towards OLS when using a weak instruments. This result applies to small samples with many instruments because even valid and sufficiently strong instruments are likely to pick up small amounts of endogenous variation in small samples. Given less information, this can lead to bias in small samples. As our study showed, using fewer instruments can help alleviate this bias in small samples, which was the same effect found in <ref type="bibr">Bollen et al. (2007)</ref>.</p><p>In small samples, Sargan test did not have the desired power to detect misspecification at the between level in this simulation. At the within level, the power was adequate across all sample sizes tested. This result suggests that while parameter estimates and standard errors are generally good in smaller samples, in order to have sufficient power to detect misspecification at the between level, one might still need larger samples. The power to detect misspecification is likely related to the type of misspecification. As the next simulation will demonstrate, there are some misspecifications which the Sargan's test have more power in medium to small sample sizes.</p><p>It should be re-iterated that the smallest samples were the most likely to be removed for failing to converge, though rates of convergence were generally high. Regardless, small sample results need to be interpreted with this in mind. The cases which were removed were most likely to have inconsistent patterns of results. This is commonly a problem in simulation work.</p><p>Finally, one aspect that has not been considered is that many practitioners may not have any interest in both levels of the MSEM model. In many cases, researchers are mostly interested in results at the within level, and include the between level to account for dependency. In these cases, MIIV-2SLS (and the strategy of separating both levels) is an ideal approach because one does not need to estimate both levels of the model. Separating the covariances into levels and estimating the within level, will provide the exact same final model and estimates. When using ML, one does not have the option to only estimate one level of the model, except when implementing the <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> approach. And by estimating both levels with ML, one is increasing the likelihood of introducing bias at both levels of the model, assuming the model isn't exactly correct.</p><p>Overall, these results are quite promising for the application of MIIV-2SLS for estimation of MSEMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation #2 -Methods</head><p>The first simulation investigated all five of the research questions outlined at the beginning of this chapter. This second simulation is more focused; I will primarily examine the research questions related to model fit and sample size. Based on the first simulation, I concluded that the Sargan test did not have adequate power (&gt;= 0.80) to detect misfit at the between level model, unless one has 200+ clusters. However, I only studied one form of misspecification (omitted cross loadings), and it could be that the type of misspecification also changes the power to detect misfit. Additionally, the type of misspecification studied in the MSEM literature has exclusively been incorrect dimensionality (at least in terms of structural misspecification). Simulation #1 did not address misspecification of dimensionality, making it somewhat hard to compare to the literature. This second simulation is designed to bridge this gap by studying MIIV-2SLS in the context of misspecification of dimensionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data generation</head><p>The data generating model is given in Figure <ref type="figure" target="#fig_11">17</ref>. The population model is a two dimensional factor model, with two correlated latent variables at each level. Similar to the first simulation, the pattern of coefficients is comparable across levels. Importantly, this model is similar to population models used in <ref type="bibr">Ryu and West (2008)</ref> as well as <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref>, who also examined model fit in MSEMs.</p><p>Aside from the data generating model, the data generation process was similar to simulation #1. I provide a more brief discussion of the methods for simulation #2, given the similarity to simulation #1. Cluster sizes ranged from 30 to 300 and the specific number of clusters in each iteration was chosen at random using a discrete uniform distribution. Average cluster sizes varied from 5 to 50 and were also chosen at random using a discrete uniform distribution. Cluster sizes within any given iteration were unbalanced with the size of individual cluster sizes falling within 50% plus or minus the average cluster size. I generated 20,000 independent datasets with the above specifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimators</head><p>Similar to the previous simulation I compared three different estimators: ML, 2SLS-ALLIV and 2SLS-OVERID2. Table <ref type="table" target="#tab_1">2</ref> lists observed variables corresponding to all equations for both 2SLS-ALLIV and 2SLS-OVERID2. The number of instruments used for 2SLS-OVERID was such that each equation was over identified by two degrees of freedom. Instruments were selected to be the most highly correlated with the problematic variable according to the model.</p><p>Table <ref type="table" target="#tab_1">2</ref>, I note that the factor loadings for items Y2-Y4 remain unchanged across specifications while loadings from the second latent variable are altered in the incorrectly specified models <ref type="bibr">(Bollen, 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Evaluation</head><p>In this simulation, evaluation was primarily focused on model fit. I do not pay as much attention to qualities of the estimates and standard errors, as these were examined in depth in the first simulation. The general pattern of results of parameter estimates and standard errors from simulation #1 also apply to this simulation. It would be redundant to emphasize these results a second time. I created the same discrete conditions in this simulation as in the first simulation. As a reminder, three discrete categories were created from the average cluster size variable. These corresponded to small (5-15), medium (16-30), and large (31-50) cluster sizes. ML results were summarized over the combination of estimator, model specification, number of clusters and average cluster size. Sargan was summarized over the same set of variables with the addition of level of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation #2 -Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convergence</head><p>All models converged with MIIV-2SLS and not all models converged with ML. When the true model was specified 57 out of 20,000 iterations did not converge with ML. When the within level model was misspecified, 236 did not converge. When the between level was misspecified, 249 did not converge. Figure <ref type="figure" target="#fig_12">18</ref> provides a heat map of convergence rates across cluster sizes and number of clusters. Models that did not converge were more likely to have smaller number of clusters and small average cluster sizes. Interestingly, when the within level model was misspecified, it appeared that having small cluster sizes was most related to convergence. When the between level model was misspecified, there was a less distinct pattern, but it appeared as though the number of clusters may have been a more important factor. As with the first simulation, models that did not converge were thrown out for all estimators. Given the relatively low rates of non-convergence, this did not have much effect on results.</p><p>When the true model is fit to the data, nearly all of the fit indices averages are close to 1.00 reflecting excellent fit. This is unsurprising. When misspecification is introduced into the model at the within level all indices indicate poor fit. When misspecification is introduced at the between level model, none of the fit indices reflect misfit. The insensitivity to misfit at the between level model has been known for many years. Despite this, these findings serve as a comparison for results from the Sargan Test, which I discuss in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sargan Test</head><p>Figure <ref type="figure" target="#fig_8">21</ref> displays the proportion rejection rates for the Sargan test when the true model is fit to the data. Given that all parameters are factor loadings, I collapsed the results for all parameters by each level. On average rejection rates were at or below the expected level of ğ›¼. As with the first simulation, using unadjusted p-values did not lead to inflated Type-I error rates.</p><p>The B-H adjusted p-values did lead to fewer Type 1 errors.</p><p>Given misspecification at the between level, Sargan appears to have more power in this simulation than in the former simulation. 30, 2SLS-ALLIV had very low power. 2SLS-OVERID2 performed better given a small number of clusters, especially when cluster sizes were larger than 15, though its power also decreases.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation #2 -Conclusions</head><p>The results of this simulation were more focused than the results of the first simulation.</p><p>This was by design. Though I did not discuss the relative bias, efficiency or standard errors, the general findings from the first simulation also applied to this simulation. Instead, I chose to focus this simulation on model fit; in particular I chose to focus on misspecification of dimensionality, as this is the type of misspecification by which all other model fit procedures have been tested in the MSEM literature.</p><p>The primary result of interest in this simulation is the effectiveness of the Sargan test for detecting misspecification in the between level model. Indeed, when CFI, TLI, and RMSEA all indicated great fit, the Sargan test was able to detect misfit with high power. I would also point out that Sargan test had generally higher power across a range of sample sizes in this simulation.</p><p>This suggests that the effectiveness of the Sargan test depends upon the type of (or magnitude of) misspecification in the model.</p><p>Finally, though I did not explicitly compare Sargan to the model fit procedures of <ref type="bibr">Ryu and West (2008)</ref> and <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref>, it is possible to make comparisons given the similarity in study designs. Both of these previous studies found that their methods could detect misspecifications at the between level, at comparable rates. Neither of these studies examined cluster sizes lower than 50. In sum, this simulation generally confirmed that Sargan test can be used as a comparable method to those already proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CHAPTER 5: ANALYSIS OF EMPIRICAL DATA</head><p>In this Chapter, I demonstrate the use of the MIIV-2SLS approach with empirical data.</p><p>Simulations are useful for investigating certain properties of estimators (e.g., finite sample properties). However, simulations are not always representative of real data analysis. Real data are messy and true data generating processes are unknown. In contrast to the simulations in the previous chapter, this chapter aims capture the complications of real data analysis, illustrating how MIIV-2SLS would be applied in practice. Throughout this chapter, I provide ML as a comparison to illustrate similarities and differences between both approaches to estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trends in International Mathematics and Sciences Study</head><p>Data used in this chapter come from the Math confidence was assessed with four likert type items where responses were coded on an agree to disagree scale, where 0 = agree and 4 = disagree. Table <ref type="table" target="#tab_2">3</ref> lists the four items. Not all of the items are in the same direction. For the first item, "agree" (scored 0) corresponds to more confidence. On the other hand, items Y2-Y4 are negatively worded, such that answering "agree" suggests lack of confidence. I wanted to keep the direction of the scale such that higher scores on math confidence would correspond to higher levels of achievement. This meant reverse coding the first item, and leaving the others as they are. In this way, a response of 0 suggests low math confidence and a response of 4 corresponds to higher confidence. The reverse coding of items can add unexpected complexity to scales. As we will see, this may have an impact on the results.</p><p>Another complication with this data is the categorical nature of Likert type items. Ideally, Likert-type items should be treated as categorical and modeled in a categorical framework. The current MIIV-2SLS framework does not allow this. In the single level SEM, the PIV estimator can be used with categorical items, however the PIV estimator has not yet been extended to the MSEM. Without an explicit categorical framework, there are two options for moving forward.</p><p>The first is to use MSEM while treating items as continuous indicators (ignoring the categorical </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Y4</head><p>Math is not one of my strengths.</p><p>(r) indicates item has been reverse coded nature of the items). The second option is to use sum scores from all item sets and analyze the data as a multilevel path analysis (ignoring the measurement structure of the items). In a similar analysis with the same data, Ryu (2014) used the sum score approach. In order to show the full MSEM model, I decided to do the opposite and model confidence and achievement as latent variables and treat all items as continuous.</p><p>I fit two models to the data. Figure <ref type="figure" target="#fig_25">24</ref> shows Model 1. This model is composed of two latent variables, one for achievement and one for math confidence. In an ideal world, confidence and achievement would be measured in a longitudinal model. Unfortunately, this data is not longitudinal and we are limited to looking at the cross sectional data. Achievement is measured  Sargan test provides different information about the fit of our model, which was not reflected in the ML fit indices. At the within-level model it appears as though there is some misspecification among the factor loadings corresponding to the math confidence latent variable.</p><p>In particular, the Sargan test rejects the null hypothesis for all of the negatively oriented items, suggesting some amount of misfit in the model. This might suggest some local dependence among these items. Sargan test suggests some misspecification which could be affecting the regression of achievement on confidence. Had we only used ML, we would have little indication that these parameters might be affected by misspecification. With MIIV-2SLS, the Sargan test has called into question the validity of several of these model parameters.</p><p>At the between groups level, we also find several significant Sargan tests. At this level Sargan test rejects the null hypothesis for the loadings on the achievement items. Unlike the bad confidence loadings at the within level, the reason for this is less clear. Additionally, the regression of achievement on confidence is affected by misspecification. We know that misspecification affects ML and MIIV-2SLS differently and this might be one explanation for why ML and MIIV-2SLS have different effects for this regression parameter.</p><p>Based on the results of the Sargan test in Model 1, I decided to make one set of modifications, to test the bad factor loadings for the confidence items at the within level. Based on my understanding of the items, I hypothesized that the negatively worded confidence items are likely to exhibit local dependence. Model 2 added correlated residuals among these items only. Given that I did not have any reasonable explanation for problems with the achievement items at the between level, I did not make any changes to this level.</p><p>This modified model did not converge when using ML. Additional steps were taken such as changing starting values and other convergence criteria, but none of these resulted in ML converging. Notably, the change in model specification has no effect on stage 1 estimates with MIIV-2SLS, because stage 1 is independent of the model. The modifications added in Model 2 lead to non-significant Sargan tests for the confidence items at the within level, providing some evidence that our original hypotheses of local dependence was correct. This also leads to slightly adjusted factor loadings. These modifications do not change the LV regression at the within level and the between level model is also unchanged.</p><p>For the purposes of this example, I consider Model 2 to be the final model. In general, the factor loadings of the achievement items are well behaved at both levels of the model (except for the significant Sargan tests at the between level). This is likely because achievement scores are item response theory scores that have already been modeled to reflect some underlying latent variable of achievement. The factor loadings for the confidence latent variable are all reasonably close to 1.0 at the within level and somewhat more mixed at the between level.</p><p>Interpretation of the model is identical with MIIV-2SLS as with ML. Given the significant Sargan tests for LV regressions, I am skeptical of those parameters. Despite this, I will interpret as if I had more confidence in these parameters. Additionally, I caution the reader from inferring about explicit causal relations in these data; these data are observational and we might expect that the relationship between achievement and confidence is confounded by other variables at both levels of the model. Ideally, the relation between these constructs would be studied in a longitudinal context. With those caveats, we find that math confidence is a significant predictor of achievement at level 1 and level 2. At level 1, we would interpret this the same way one might interpret a regression path in a single level SEM. Given a unit increase in the confidence scale, would we expect to see a 0.45 increase in achievement scores. The standard deviation of the scaling indicator for achievement is 0.78, thus a 0.47 increase is a meaningful change. At level 2, the interpretation is about aggregates at the school level. Thus, for a unit increase in the school level average of confidence, we would predict a 2.32 increase in achievement. This effect huge, though one should consider that a 1 unit in the average confidence of a school, is a rather large shift. The level 2 effect is may not be entirely intuitive at first. This reflects that there may be some higher level trends across schools. Some schools have higher confidence on average, and this higher than average confidence would also be reflected in the general achievement.</p><p>This type of model has interesting implications for policy or interventions because we can now imagine having interventions at each level of the model. We could envision affecting change in confidence at both the individual level and the classroom level. However, from this perspective it is not entirely straight-forward to decide where such an intervention would be best placed. One way to think about this is that an intervention at the individual level is likely to have effects at the between level as well. In this way, raising most students' confidence is likely to have compounded effects throughout the model.</p><p>The difference in these estimators is perhaps the starkest when considering how we have evaluated the fit of this model. Majority of the parameters are functionally the same no matter which estimator is used here. However, when looking at results based on ML, we would conclude our model fits reasonably well, and we would move onto interpreting the effects. With MIIV-2SLS, we find more complications when interpreting the effects, in particular based on the Sargan test. In this example, Sargan suggests that our model does not fit as well as we might hope. Of course, we do not know the true model. We never do with real data. In this way, the Sargan test offers additional information about the fit of each equation, instead of the full model.</p><p>ability to handle categorical data and random slopes. Future research is needed to extend MIIV-2SLS to cover more of these types of problems in MSEMs.</p><p>Along with the novel contribution of adapting MIIV-2SLS for MSEMs, this study examined several important research questions about the properties of MIIV-2SLS in finite samples. Overall, the performance of MIIV-2SLS was impressive in this study. My research questions were focused on robustness, standard efficiency, sample size, and model fit. In terms of robustness, this study showed that the robustness qualities which have been examined in the SEM literature also apply when estimating MSEMs. Additionally, MIIV-2SLS was robust to the spread of misspecification across levels of the model. The delta method standard errors as applied in this study were adequate to capture the sampling variability as was shown through the standard error bias and the 95% confidence intervals. MIIV-2SLS was slightly less efficient that ML, though the magnitude of this difference was dependent on the parameter. Overall any loss in efficiency was, as mentioned, slight. One could easily argue that the additional robustness qualities and smaller RMSE (given misspecification) is a valuable tradeoff for some loss in efficiency. This is especially true if one believes that all models are approximations.</p><p>The performance of MIIV-2SLS varied across different sample sizes. Given 100 clusters-the suggested minimum number of clusters-MIIV-2SLS performed well. One major takeaway from this study is that one should use a subset of MIIVs in small samples (fewer than 100 clusters). Being able to estimate models with fewer than 100 clusters is likely to be very valuable for researchers. I tested a rather extreme minimum of 30 clusters in this study. I am hesitant to suggest one could perform MIIV-2SLS consistently in samples this small. The combination of few clusters and small number of clusters had one rather serious side effect of positive biased standard errors when using all instruments. Based on this simulation I would argue that between 50 and 100 clusters might be acceptable. At the same time, in these simulations ML also performed reasonably well across the same range of sample sizes. This performance could be partially an artifact of generally well-behaved data. One is likely to encounter more problems in small samples with real data. Finally, in terms of sample size, the average cluster size was relevant to some of the results but the effect of average cluster size was less relevant than the number of clusters.</p><p>I proposed an alternative form of an adjusted Sargan test which proved to be a useful test for detecting misspecification. This test could be an excellent alternative for testing the fit of models with the usual ML fit statistics do not perform as well. The power to detect misspecification depended on a number of things including the number of clusters as well as the type of misspecification. At the within level power was always high for detecting misspecification. Level-1 sample sizes tend to be large in MSEM data. At the between level, with 100 clusters model fit detection with MIIV-2SLS was mixed. Detecting misspecification caused by omitted cross loadings at the between level had relatively low power given 100 clusters. Alternatively, the Sargan test had high power detect the bad loadings in the second simulation even in sample sizes of 100.</p><p>Taken together this research laid the foundation for MIIV-2SLS estimation of MSEMs.</p><p>Across many conditions studied in this dissertation, the method worked rather well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>One of the primary limitations of any simulation study is generalizability to other models and conditions. In this study, I examined two types of models (MSEM and MCFA) across a range of conditions. One might reasonably assume that the conclusions from this study could extend to a broader set of models. At the same time, it is imperative to realize that these results</p><p>do not capture all of the possible complexities in MSEMs, and I cannot fully predict how these results will reflect on a completely different model. In this way, more research is necessary to understand other model complexities.</p><p>One particularly salient example of this problem with MIIV-2SLS has to do with the availability and selection MIIVs. I only examined globally identified models where every equation had many possible MIIVs. It is possible to encounter models with many fewer instruments. In these models, some equations may be under-identified or perhaps only exactly identified for MIIV-2SLS (meaning no Sargan test). In other applications, there may be plenty of MIIVs but the instruments could be generally weak. I did not examine these more complicated scenarios and future research is needed to study different types of models with varying qualities and quantities of MIIVs.</p><p>In a similar way, this study only examined two types of model misspecification: omitted cross loadings and incorrect dimensionality. Other types of misspecification are possible. Instead of one or two large components of misspecification (e.g., a missing parameter), it could be possible to have many small pieces of misspecification. <ref type="bibr" target="#b98">MacCallum (2003)</ref> discussed the importance of considering different types of misspecification and building these into simulation studies. For example, in the factor analysis context <ref type="bibr" target="#b145">Tucker, Koopman, and Linn (1969)</ref> introduced misspecification in simulated data with a large number of minor factors. Others have discussed adding small perturbations to the model implied covariance matrix. Future work should consider the performance of MIIV-2SLS given different types of misspecification, especially models with a greater number of small perturbations. The performance of both ML and MIIV-2SLS would likely be different given alternative types of misspecification.</p><p>Another form of misspecification is distributional misspecification which this study did not address. In single level SEMs MIIV-2SLS is asymptotically distribution free. However, in the MSEM, Stage 1 estimates for MIIV-2SLS rely on ML and with assumption of multivariate normality. Future research would do well to examine the performance of MIIV-2SLS for MSEMs given distributional misspecification.</p><p>There are more technical limitations about the types of models which can be handled with MIIV-2SLS in MSEMs, as it currently stands. The current estimator does not handle categorical data, random slopes, or more than two levels. Additionally, this study entirely focused on estimating regression coefficients and did not consider the mean structure of the model as well as estimating other model parameter such as residual and latent variable variances. All of these will be important areas of future inquiry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Research</head><p>This study is an important step in establishing MIIV-2SLS estimation for MSEMs.</p><p>Moving forward, I would outline two primary directions for future inquiry. The first direction involves studying the current approach but under different circumstances. The second direction involves modifications to the general procedure which may allow solutions to other problems such as categorical data.</p><p>Identifying more strengths and weaknesses of the Sargan test for testing MSEMs is one area of critical importance. This study examined the Sargan test against chi-square based fit indices, which are known to be insufficient. However, we also know that better ML based testing procedures exist. Previous research on these procedures have mostly considered misspecification in MCFA, similar to the second simulation in this study. Future research should examine Sargan test and these other methods in a broader set of models, side-by-side. This side-by-side comparison may be the most useful for practitioners who may want to know the best procedures for model testing in different scenarios.</p><p>Next, I believe the small sample properties of MIIV-2SLS would benefit from future inquiry. Given that this study was one of the first examining MIIV-2SLS for MSEMs, I thought it was important to examine a large set of possible sample sizes. One could design a more focused study of small samples, with perhaps fewer combinations of cluster size and number of clusters. In particular, the larger than expected standard errors in very small samples, would be worth investigating. One possible direction for small samples would be to explore implementing a Restricted Maximum Likelihood (REML) type estimator for stage 1 estimates. In standard MLMs, REML has been shown to have better performance given small samples, particularly for estimating random effects. To my knowledge, there is no REML equivalent for MSEMs at this point, but future inquiry could uncover a direction for this approach.</p><p>There may be meaningful ways to modify the current MIIV-2SLS procedure. The procedure proposed in this study could be modified to make it completely non-iterative. Early MSEM procedures, in particular the MUML estimator, relied on estimating the level specific covariance matrices with a simple non-iterative computation. The primary shortcoming to this procedure is that no one has worked out the asymptotic covariance matrices of these estimates.</p><p>This meaning, one could not apply the delta method to correct standard errors. However, I suggested earlier in this study that the parametric bootstrap may be an alternative for estimating correct standard errors, and this does not require the asymptotic covariance matrices. The combination of MUML stage 1 estimates with parametric bootstrap could be a way to completely eliminate the possibility of non-convergence while maintaining many of the important qualities of MIIV-2SLS.</p><p>Another area of inquiry would be implementing strategies to test model constraints (e.g., equality constraints), particularly across levels of the model. Some have argued that cross level equality constraints are necessary for the validity of these models (e.g., <ref type="bibr" target="#b75">Jak, 2019)</ref>. In the current approach, it would not be possible to add equality constraints across levels because they are estimated completely separately. Future work could consider ways to add these constraints across levels. Adding equality constraints across levels would undoubtedly break the robustness quality across levels. More exploration is most certainly warranted in this area.</p><p>Despite the fact that the delta method standard errors performed well in this study, there may be reasons to consider implementing a bootstrapping procedure to obtain standard errors.</p><p>Violations of the assumptions of multivariate normality would likely create biased standard errors in the current estimator. The parametric bootstrap might not be ideal in this situation either, but perhaps the non-parametric residual bootstrap could be applied.</p><p>Finally more work is needed to extend the current procedure to handle more complicated models such as those with categorical indicators or random slopes. Both of these are non-trivial extensions. Some work is already under way in order to develop a Bayesian MIIV-2SLS</p><p>estimator for random slopes models. To my knowledge, no one is yet working on categorical extensions.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Figures</head><note type="other">Figure 25.</note></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>x APPENDIX: TABLES...........................................................................................................111 REFERENCES ......................................................................................................................115 xi LIST OF TABLES</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 8 .</head><label>8</label><figDesc>Figure 7. Root Mean Squared Error given true model. Figure 7. Root Mean Squared Error given true model. .................................................................................69</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>chapter 3, I review MIIV-2SLS and propose a related procedure for MSEMs. I begin by reviewing the literature on MIIV-2SLS paying particular attention to its robustness to misspecification and model testing. I propose a procedure to apply MIIV-2SLS estimation for MSEMS by addressing variance decomposition, point estimates, inference, and model testing. I conclude with a discussion of how the proposed procedure may mitigate potential shortcomings of the usual ML approach. In Chapter 4, I evaluate MIIV-2SLS for MSEMs in two finite sample Monte Carlo simulations. I establish baseline performance of MIIV-2SLS fitting the true model across a number of conditions where the number of clusters and average cluster sizes are varied. Next, I study misspecification at both levels of the model. In each of these sections, I will evaluate point estimates and measures of uncertainty. Finally, I study the performance of the usual model test statistic against the local identification tests of the Sargan test. In Chapter 5, I demonstrate the MIIV-2SLS procedure with an empirical example using data from the Trends in International Mathematics and Sciences Study data (TIMSS; Martin,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>CHAPTER 2 :</head><label>2</label><figDesc>REVIEW OF MULTILEVEL STRUCTRAL EQUATION MODELINGIn this chapter, I review Multilevel Structural Equation Modeling (MSEM) focusing primarily on the random intercepts MSEM. I begin with a historical review of MSEM developments. In this review, I consider developments for both the random intercepts and more recent random slope model developments. After, I define the MSEM model equations, ML estimation, and a number of practical considerations including considerations for model fit testing and sample size issues. I conclude the chapter with opportunities for future research.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>fit indices include the model chi-square, CFI, TLI, and RMSEA. In random intercept MSEMs, all of the usual model fit indices are available. As noted before, in MSEMs with random slopes, the usual model fit indices are not available. Except for a few exceptions-which I will outline below-the usual practice in MSEMs has been to use model fit indices with the same cutoffs as in single level SEMs. However, model fit indices and the usual cutoffs were not developed with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(</head><label></label><figDesc>2001) further developed MIIV-2SLS noting a closed form to estimate the full model simultaneously instead of equation-by-equation. This form provides identical point estimates and standard errors. Further, Bollen (2001) provides general analytic condition for when MIIV-2SLS is robust to misspecification. The MIIV-2SLS estimator differs from traditional instrumental variable techniques in several important ways. Early versions of a 2SLS estimator for SEM with latent variables, did not allow for correlated errors of measurement; the MIIV-2SLS estimator does allow correlated errors. JÃ¶reskog and SÃ¶rbom's versions of the 2SLS estimator required estimating the measurement model first and then estimating the latent variable model; the MIIV-2SLS estimator</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>we have the option to use over-identification tests as equation-by-equation tests of model fit. In this case, we are able to test the null hypothesis that all of the instruments are uncorrelated with the equation error. The alternative hypothesis being that at least one of the MIIVs are correlated with the error. In a sense, this is a test of the model structure. MIIVs are chosen based on the model structure, and are only chosen if the model structure suggests that variable is uncorrelated with the error. Therefore rejecting the null hypothesis implies there is a problem with the structure of the model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Within any given dataset, cluster sizes were unbalanced. Early methodological work for MSEMs required the assumption of balanced clusters (i.e., all clusters are of the same size), which is not representative of real-world data. Real data rarely have balanced clusters except in highly controlled study designs. The method proposed in this study does not require the assumption of balanced clusters. With this in mind, I generated all data as unbalanced to best representative of real-world data applications. Of course, if one were lucky enough to have balanced clusters, all findings in this simulation would carry over to balanced clusters as well.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Data generating model for Simulation #1. The True Model specification fits the exact correct model. The Misspecified Within model omits the cross loadings (dashed lines) at the within level, and The Misspecified Between omits the cross loadings at the between level model.</figDesc><graphic coords="67,81.75,139.75,448.20,311.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Convergence rate heat map for Simulation #1.</figDesc><graphic coords="75,85.33,84.50,441.35,320.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Average relative bias given the true model. Relative bias is averaged and plotted across level of the model, type of parameter, estimator, cluster size and number of clusters. Lowess curve overlaid to show trends.</figDesc><graphic coords="77,76.50,84.50,458.25,458.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Root Mean Squared Error given true model.</figDesc><graphic coords="82,84.00,84.50,444.00,444.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Root Mean Squared Error given true model for within level parameters only. The data presented in this plot are identical to Figure 7; the y-axis has been adjusted to show the RMSE at within level more clearly.</figDesc><graphic coords="83,72.00,112.15,468.00,216.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Root Mean Squared Error given misspecification within.</figDesc><graphic coords="84,85.10,84.50,441.73,455.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 12</head><label>12</label><figDesc>Figure 12 displays the standard error bias given the true model specification. Results are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Proportion of 95% confidence intervals which contain the population parameter given the true model.</figDesc><graphic coords="91,81.75,139.75,448.50,414.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 14</head><label>14</label><figDesc>Figure 14 displays rejection rates of the Sargan test given the True Model specification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 14 .</head><label>14</label><figDesc>Figure 14. Proportion Sargan Test rejects the null hypothesis for the true model.</figDesc><graphic coords="92,80.25,194.95,451.48,364.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Figure 15 contains results from the Misspecified Within model and Figure 16 contains results for the Misspecified Between model. For both of the misspecified models I only show results for misspecified equations, only. Equations that remain unchanged have the same rejection rates in the misspecified models as they do in the True model condition shown in Figure 14.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 15 .</head><label>15</label><figDesc>Figure 15. Proportion Sargan Test rejects the null hypothesis for misspecified equations in the misspecified within model. Dotted line marks 80% rejection rate.</figDesc><graphic coords="94,76.15,84.55,459.74,212.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 16 .</head><label>16</label><figDesc>Figure 16. Proportion Sargan Test rejects the null hypothesis for misspecified equations in the misspecified between model. Dotted line marks 80% rejection rate.</figDesc><graphic coords="94,78.75,379.95,454.43,209.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 20 .</head><label>20</label><figDesc>Figure 20. Average CFI, TLI, and 1-RMSEA across sample sizes and model specifications.</figDesc><graphic coords="105,83.25,250.15,445.50,297.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>Figure 21. Proportion of Sargan Tests which reject the null hypothesis given the true model specification.</figDesc><graphic coords="106,79.15,139.75,453.66,237.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 22 .</head><label>22</label><figDesc>Figure 22. Proportion Sargan Test rejects the null hypothesis for the misspecified within model. Correctly specified and incorrectly specified equations shown separately.</figDesc><graphic coords="107,79.90,139.75,452.16,208.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 23 .</head><label>23</label><figDesc>Figure 23. Proportion Sargan Test rejects the null hypothesis for misspecified between model. Correctly specified and incorrectly specified equations shown separately.</figDesc><graphic coords="107,78.00,444.90,455.95,210.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 24 .</head><label>24</label><figDesc>Figure 24. Path diagram of Model 1 fit to the TIMSS data.</figDesc><graphic coords="111,111.00,222.55,389.43,338.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>Figure 25. Empirical standard deviations of parameter estimates given the misspecified within for Simulation 1.</figDesc><graphic coords="124,72.00,112.15,468.00,432.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 26 .</head><label>26</label><figDesc>Figure 26. Empirical standard deviations of parameter estimates given the misspecified between for Simulation 1.</figDesc><graphic coords="125,72.00,84.55,480.00,443.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 28 .</head><label>28</label><figDesc>Figure 28. Standard Error Bias given the misspecified between model for Simulation 1.</figDesc><graphic coords="127,72.00,84.55,480.00,443.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="47,77.58,89.95,456.71,249.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="79,77.75,139.75,456.50,470.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="85,76.30,84.55,459.40,473.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="87,83.25,84.55,445.20,410.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="89,85.15,84.55,441.72,407.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="103,82.50,84.55,447.00,243.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="104,77.65,84.55,456.72,266.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Observed variables corresponding to MIIV-2SLS estimation. .................................57</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Observed variables corresponding to MIIV-2SLS estimation for Simulation #2. Equations are identical for both levels of the model. ..........................88</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Items from the Math Confidence scale. ....................................................................97</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Parameter estimates for Model 1 and Model 2 fit to the TIMSS data with both ML and MIIV-2SLS. .........................................................................................100 Figure 1. Single level SEM path diagram used to demonstrate MIIV-2SLS. .........................34 Figure 2. Data generating model for Simulation #1. The True Model specification fits the exact correct model. The Misspecified Within model omits the cross loadings (dashed lines) at the within level, and The Misspecified Between omits the cross loadings at the between level model. ..................................54 Figure 3. Convergence rate heat map for Simulation #1. .......................................................62 Figure 4. Average relative bias given the true model. Relative bias is averaged and plotted across level of the model, type of parameter, estimator, cluster size and number of clusters. Lowess curve overlaid to show trends. ..........................64 Figure 5. Average relative bias given a misspecified within model. Correct and Incorrect specification is with respect to the MIIV-2SLS equations given in Table 1. ..</figDesc><table><row><cell>LIST OF FIGURES</cell></row><row><cell>xii</cell></row></table><note><p>..................................................................................................................66 Figure 6. Average relative bias given the misspecified between level model. Correct and Incorrect specification is with respect to the MIIV-2SLS equations given in Table 1. ..........................................................................................67 Figure 7. Root Mean Squared Error given true model.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>sampled from within each cluster. This ensures that ğ’– ğ‘–ğ‘— and ğ’— ğ‘— are uncorrelated allowing for the clean separation of ğšº ğ‘Š and ğšº ğµ in Equation2. are the within groups factor loadings, ğœ¼ ğ‘Š ğ‘–ğ‘— are the within group factors, ğœº ğ‘Š ğ‘–ğ‘— are within group disturbances, ğš² ğµ are the between groups factor loadings, ğœ¼ ğµ ğ‘— are the between groups factor, and ğœº ğµ ğ‘— are the between level disturbances. We assume that ğ¸ (ğœº ğ‘Š ğ‘–ğ‘— ) = ğ¸ (ğœº ğµ ğ‘— ) = 0, ğ‘‰ (ğœº ğ‘Š ğ‘–ğ‘— ) = ğš¯ ğœ€ ğ‘Š , ğ‘‰ (ğœº ğµ ğ‘— ) = ğš¯ ğœ€ ğµ , ğ‘‰ (ğœ¼ ğ‘Š ğ‘–ğ‘— ) = ğš¿ ğ‘Š , ğ‘‰ (ğœ¼ ğµ ğ‘— ) = ğš¿ ğµ . We also assume that the disturbances are uncorrelated with the ğœ¼ â€² ğ‘  in each equation. are the latent variable regressions at the within part of the model and ğš© ğµ are the latent variable regressions at the between part of the model, ğœ» ğ‘Š ğ‘–ğ‘— are the within groups distrubances,</figDesc><table><row><cell>observations are randomly One can explain variation at each level of the model by defining measurement and latent where ğš© W and ğœ» ğµ ğ‘— are the between group disturbances. We make the follow assumptions that ğ¸ (ğœ» ğ‘Š ğ‘–ğ‘— ) =</cell></row><row><cell>variable models. For the measurement model, let</cell></row><row><cell>(3) ğ¸ (ğœ» ğµ ğ‘— ) = 0, ğ‘‰ (ğœ» ğ‘Š ğ‘–ğ‘— ) = ğš¯ ğœ ğ‘Š , and ğ‘‰ (ğœ» ğµ ğ‘— ) = ğš¯ Î¶ B . We also assume that the errors are ğ’– ğ‘–ğ‘— = ğš² W ğ›ˆ W ğ‘–ğ‘— + ğœº ğ‘Š ğ‘–ğ‘—</cell></row><row><cell>ğ’— ğ‘— = ğš² ğµ ğœ¼ ğµ ğ‘— + ğœº ğµ ğ‘— uncorrelated with any exogenous variables in the equation. Finally, we can express the (4)</cell></row><row><cell>covariance structure as: One should note that the model equations and covariance structures are quite familiar when ğšº ğµ = ğš² ğµ (ğ‘° -ğš© ğµ ) -1 ğš¿ ğµ (ğ‘° -ğš© ğµ ) -1 â€² ğš² ğµ â€² + ğš¯ ğµ ğšº ğ‘Š = ğš² ğ‘Š (ğ‘° -ğš© ğ‘Š ) -1 ğš¿ ğ‘Š (ğ‘° -ğš© ğ‘Š ) -1 â€² ğš² ğ‘Š â€² + ğš¯ ğ‘Š compared to single level SEM. The primary difference is random intercept MSEMs have a where ğš² W Interestingly, a majority of methods papers concerning random intercepts MSEMs only model for each level.</cell></row><row><cell>explicitly define the multilevel confirmatory factor analysis (MCFA) model, as I have defined</cell></row><row><cell>ğ‘‰(ğ’š ğ‘–ğ‘— ) = ğ‘‰(ğ + ğ’– ğ‘–ğ‘— + ğ’— ğ‘— ) above (e.g., Holtmann, Koch, &amp; Eid, 2016; Hox, Schoot, &amp; Matthijsse, 2012, Hox et al., 2010;</cell></row><row><cell>ğ‘‰(ğ’š ğ‘–ğ‘— ) = ğ‘‰(ğ’– ğ‘–ğ‘— ) + ğ‘‰(ğ’— ğ‘— ) Hsu, Kwok, Lin, Acosta, 2015; Lee 1990, Lee &amp; Poon 1992; Meuleman &amp; Billiet, 2009). Thus, (2)</cell></row><row><cell>ğšº ğ‘‡ = ğšº ğ‘Š + ğšº ğµ throughout most of the literature, explicit model specifications tend to stop with the above</cell></row><row><cell>MCFA model. Despite this, the addition of the structural/latent variable portion of the model is</cell></row><row><cell>straightforward. As with the measurement model, we have a latent variable model for both</cell></row><row><cell>levels.</cell></row><row><cell>ğœ¼ ğ‘Š ğ‘–ğ‘— = ğš© W ğ›ˆ W ij + ğœ» ğ‘Š ğ‘–ğ‘—</cell></row><row><cell>ğœ¼ ğµ ğ‘— = ğœ¶ + ğš© ğµ ğ›ˆ B j + ğœ» ğµ ğ‘—</cell></row><row><cell>That is, level-2 clusters are randomly sampled and then level-1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>studied a number of overidentification tests and found that the Sargan test statistic provided the most accurate reflection of model fit. This equation-by-equation testing procedure differs from the ML approach where fit is assessed through global indices. One could argue that the Sargan test gives more information about each equation in the model.</figDesc><table /><note><p>Finally, MIIV-2SLS does not require global identification. Instead, each individual equation can be identified. If the model is not globally identified for ML estimation, it may still be possible to estimate individual identified equations with MIIV-2SLS. Additionally, MIIV-2SLS is computationally efficient. It does not require an iterative procedure and instead has a closed form solution.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>ğ›¼ ğ‘¦ 2 + ğœ† 21 ğœ‚ 1 + ğœ€ ğ‘¦ 2 ğ‘¦ 8 = ğ›¼ y 8 + ğœ† 83 ğœ‚ 3 + ğœ€ ğ‘¦ 8 y 9 = ğ›¼ ğ‘¦ 9 + ğœ† 93 ğœ‚ 3 + ğœ€ ğ‘¦ 9</figDesc><table><row><cell>ğ‘¦ 3 = ğ›¼ ğ‘¦ 3 + ğœ† 31 ğœ‚ 1 + ğœ€ ğ‘¦ 3</cell></row><row><cell>ğ‘¦ 4 = ğœ‚ 2 + ğœ€ 4</cell></row><row><cell>ğ‘¦ 5 = ğ›¼ ğ‘¦ 5 + ğœ† 52 ğœ‚ 2 + ğœ€ ğ‘¦ 5</cell></row><row><cell>ğ‘¦ 6 = ğ›¼ ğ‘¦ 6 + ğœ† 62 ğœ‚ 2 + ğœ€ ğ‘¦ 6</cell></row><row><cell>ğ‘¦ 7 = ğœ‚ 3 + ğœ€</cell></row></table><note><p><p>ğ‘¦7</p>Figure 1. Single level SEM path diagram used to demonstrate MIIV-2SLS.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>This is sometimes called the endogeneity problem. Instead, we need to use an alternative estimator, one that accounts for endogeneity. In this case, we will use the 2SLS instrumental variable estimator because of its ability to deal with endogeneity. Before moving onto the third step, it is worth briefly dwelling on the scaling indicator ğ›½ 21 ğœ‚ 1 + ğœ€ ğœ‚ 2 ğ›¼ ğœ‚ 2 + ğ›½ 21 (ğ‘¦ 1 -ğœ€ ğ‘¦ 1 ) + ğœ€ ğœ‚ 2 ğ›¼ ğœ‚ 2 + ğ›½ 21 ğ‘¦ 1 + (ğœ€ ğœ‚ 2 + ğœ€ ğ‘¦ 4 -ğ›½ 21 ğœ€ ğ‘¦ 1 ) ğ›¼ ğœ‚ 2 + ğ›½ 21 ğ‘¦ 1 + ğ‘¢ 4</figDesc><table><row><cell>ğœ‚ 2</cell><cell>=</cell><cell>ğ›¼ ğœ‚ 2 +</cell></row><row><cell>ğ‘¦ 4 -ğœ€ ğ‘¦ 4</cell><cell>=</cell><cell></cell></row><row><cell>ğ‘¦ 4</cell><cell>=</cell><cell></cell></row><row><cell>ğ‘¦ 4</cell><cell>=</cell><cell></cell></row></table><note><p><p>Though I am not showing this step for every equation in the model, the same substitution is done for every equation, including both the measurement and structural model. At the end of the L20 step, all equations are reformulated as observed variable regressions.</p>The result of the L20 for the ğœ‚ 2 equation above is a regression model with ğ‘¦ 4 regressed on ğ‘¦ 1 . One might be tempted to estimate this equation with Ordinary Lease Squares (OLS), as this equation is a simple linear regression model. However, we cannot use OLS because the composite error term is almost certainly correlated with the outcome variable; this suggests that OLS would be an inappropriate choice of estimator. Using OLS, we would violate the important assumption that our explanatory variables are uncorrelated with the equation's error. selection. Since every latent variable is re-defined as its scaling indicator minus its error, one might wonder how to choose the scaling indicator. One should follow the same guiding</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>I have already mentioned, the Sargan test is a useful feature for testing each overidentified equation with MIIV-2SLS. Given that model testing is complicated in MSEMs, the Sargan test may be especially useful in this context. Although, the usual form of the Sargan test</figDesc><table><row><cell>and,</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">ğ›€ = ( ğğ’ˆ(ğˆ) ğğˆ â€² ) ğš· (</cell><cell>ğğ’ˆ(ğˆ) ğğˆ â€² )</cell></row><row><cell cols="5">The adjusted Sargan test statistic has the following form:</cell></row><row><cell cols="3">ğ‘† ğ‘ğœ’ 2 = ğ‘›(ğ‘º ğ’›ğ’š -ğ‘º ğ’›ğ’™ ğœ½ Ì‚2ğ‘†ğ¿ğ‘† )</cell><cell cols="2">â€² ğ‘ª Ì‚ğŸ ğŸ ğ‘®ğ‘ª Ì‚ğŸ ğŸ (ğ‘º ğ’›ğ’š -ğ‘º ğ’›ğ’™ ğœ½ Ì‚2ğ‘†ğ¿ğ‘† )</cell><cell>(21)</cell></row><row><cell cols="5">Going from the original Sargan test statistic in equation (16) to the modified Sargan test in</cell></row><row><cell cols="2">equation (21), we can note that the quantity</cell><cell cols="3">ğ‘º ğ’›ğ’› -ğŸ ğœ Ì‚2 is replaced with ğ‘ª Ì‚ğŸ ğŸ ğ‘®ğ‘ª Ì‚ğŸ ğŸ which are defined below.</cell></row><row><cell cols="3">ğ‘® is the Moore-Penrose inverse of ğ‘¸ Ì‚ğ‘¸ Ì‚ğ‘‡, where</cell><cell></cell></row><row><cell>ğ‘¸ = ğ‘° -ğ‘ª</cell><cell cols="4">1 2 ğšº ğ’›ğ’™ (ğšº ğ’›ğ’™ â€² ğšº ğ’›ğ’› -ğŸ ğšº ğ’›ğ’™ ) -1 ğšº ğ’›ğ’™ â€² ğšº ğ’›ğ’› -ğŸ ğ›€ğ‘ª</cell><cell>1 2</cell><cell>(22)</cell></row></table><note><p><p><p><p><p><p><p><p><p><p><p>may be inappropriate for this setting. The test statistic in equation (</p>16</p>) was developed for single level sample covariances. Thus, we expect that the Sargan test needs to be modified for MSEMs.</p>Here I propose to use an adjusted Sargan test statistic based on the work of</p><ref type="bibr" target="#b77">Jin and Cao (2018)</ref></p>.</p><ref type="bibr" target="#b77">Jin and Cao (2018)</ref> </p>studied the model misspecification test with the polychoric instrumental variable (PIV) estimator. The problem being solved by</p><ref type="bibr" target="#b77">Jin and Cao (2018)</ref> </p>is indeed different than the problem I might encounter with multilevel data, but these cases share a similar root problem that the test needs to be adjusted for sampling variability from the first stage of analyses.</p>â€²</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 1</head><label>1</label><figDesc>lists the observed variables for MIIV-2SLS across each equation, full instrument set vs subset of instruments, and correct vs incorrect model specifications. The equations listed apply to both levels of the model.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 1 .</head><label>1</label><figDesc>Table1once more, as it contains the observed variables corresponding to correctly specified models and incorrectly specified models. The incorrectly specified model equations apply to the within level model for the Misspecified Within model and apply to the between level model for the Misspecified Between. Observed variables corresponding to MIIV-2SLS estimation.</figDesc><table><row><cell>Indicator</cell><cell>Regressed on</cell><cell>ALLIV</cell><cell>Instruments</cell><cell>OVERID2</cell></row><row><cell></cell><cell></cell><cell cols="2">Correctly Specified Models</cell><cell></cell></row><row><cell>Factor Loadings</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y2</cell><cell>Y1</cell><cell cols="2">Y3, Y4, Y5, Y6, Y7, Y8, Y9, Y10, Y11, Y12</cell><cell>Y3, Y4, Y5</cell></row><row><cell>Y3</cell><cell>Y1</cell><cell cols="2">Y2, Y4, Y5, Y6, Y7, Y8, Y9, Y10, Y11, Y12</cell><cell>Y2, Y4, Y5</cell></row><row><cell>Y4</cell><cell>Y1</cell><cell cols="2">Y2, Y3, Y5, Y6, Y7, Y8, Y9, Y10, Y11, Y12</cell><cell>Y2, Y3, Y5</cell></row><row><cell>Y6</cell><cell>Y5, Y1</cell><cell cols="2">Y2, Y3, Y4, Y7, Y8, Y9, Y10, Y11, Y12</cell><cell>Y2, Y3, Y7, Y8</cell></row><row><cell>Y7</cell><cell>Y5</cell><cell cols="2">Y1, Y2, Y3, Y4, Y6, Y8, Y9, Y10, Y11, Y12</cell><cell>Y6, Y8, Y10</cell></row><row><cell>Y8</cell><cell>Y5</cell><cell cols="2">Y1, Y2, Y3, Y4, Y6, Y7, Y9, Y10, Y11, Y12</cell><cell>Y6, Y7, Y10</cell></row><row><cell>Y10</cell><cell>Y9, Y5</cell><cell cols="2">Y1, Y2, Y3, Y4, Y6, Y7, Y8, Y11, Y12</cell><cell>Y6, Y7, Y11, Y12</cell></row><row><cell>Y11</cell><cell>Y9</cell><cell cols="2">Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y10, Y12</cell><cell>Y8, Y10, Y12</cell></row><row><cell>Y12</cell><cell>Y9</cell><cell cols="2">Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y10, Y11</cell><cell>Y8, Y10, Y11</cell></row><row><cell>LV regressions</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y5</cell><cell>Y1</cell><cell>Y2, Y3, Y4</cell><cell></cell><cell>Y2, Y3, Y4</cell></row><row><cell>Y9</cell><cell>Y5</cell><cell>Y1, Y2, Y3, Y4, Y6, Y7, Y8</cell><cell></cell><cell>Y2, Y6, Y7</cell></row><row><cell></cell><cell></cell><cell cols="2">Incorrectly Specified Models</cell><cell></cell></row><row><cell>Factor Loadings</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y2</cell><cell>Y1</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y3</cell><cell>Y1</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y4</cell><cell>Y1</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y6</cell><cell>Y5</cell><cell cols="2">Y1, Y2, Y3, Y4, Y7, Y8, Y9, Y10, Y11, Y12</cell><cell>Y2, Y3, Y7, Y8</cell></row><row><cell>Y7</cell><cell>Y5</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y8</cell><cell>Y5</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y10</cell><cell>Y9</cell><cell cols="2">Y1, Y2, Y3, Y4, Y5, Y6, Y7, Y8, Y11, Y12</cell><cell>Y6, Y7, Y11, Y12</cell></row><row><cell>Y11</cell><cell>Y9</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y12</cell><cell>Y9</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>LV regressions</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y5</cell><cell>Y1</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y9</cell><cell>Y5</cell><cell cols="3">(equations unchanged from above)</cell></row></table><note><p>Note: All equations apply to both levels of the model.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 2 .</head><label>2</label><figDesc>Observed variables corresponding to MIIV-2SLS estimation for Simulation #2. Equations are identical for both levels of the model.In assessing model fit, I consider the chi square test statistic, CFI, TLI, and RMSEA when using ML, and I review results from the Sargan test as a test of model fit with MIIV-2SLS.</figDesc><table><row><cell>Indicator</cell><cell>Regressed on (scaling indicators)</cell><cell>ALLIV</cell><cell cols="2">Instruments OVERID2</cell></row><row><cell></cell><cell cols="2">Correctly Specified Models</cell><cell></cell></row><row><cell>Factor Loadings</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y2</cell><cell>Y1</cell><cell cols="2">Y3, Y4, Y5, Y6, Y7, Y8</cell><cell>Y3, Y4, Y5</cell></row><row><cell>Y3</cell><cell>Y1</cell><cell cols="2">Y2, Y4, Y5, Y6, Y7, Y8</cell><cell>Y2, Y4, Y5</cell></row><row><cell>Y4</cell><cell>Y1</cell><cell cols="2">Y2, Y3, Y5, Y6, Y7, Y8</cell><cell>Y2, Y3, Y5</cell></row><row><cell>Y6</cell><cell>Y5</cell><cell cols="2">Y1, Y2, Y3, Y4, Y7, Y8</cell><cell>Y2, Y7, Y8</cell></row><row><cell>Y7</cell><cell>Y5</cell><cell cols="2">Y1, Y2, Y3, Y4, Y6, Y8</cell><cell>Y2, Y6, Y8</cell></row><row><cell>Y8</cell><cell>Y5</cell><cell cols="2">Y1, Y2, Y3, Y4, Y6, Y7</cell><cell>Y2, Y6, Y7</cell></row><row><cell></cell><cell cols="2">Incorrectly Specified Models</cell><cell></cell></row><row><cell>Factor Loadings</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y2</cell><cell>Y1</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y3</cell><cell>Y1</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y4</cell><cell>Y1</cell><cell cols="3">(equations unchanged from above)</cell></row><row><cell>Y5</cell><cell>Y1</cell><cell cols="2">Y2, Y3, Y4, Y6, Y7, Y8</cell><cell>Y2, Y7, Y8</cell></row><row><cell>Y6</cell><cell>Y1</cell><cell cols="2">Y2, Y3, Y4, Y5, Y7, Y8</cell><cell>Y2, Y7, Y8</cell></row><row><cell>Y7</cell><cell>Y1</cell><cell cols="2">Y2, Y3, Y4, Y5, Y6, Y8</cell><cell>Y2, Y6, Y8</cell></row><row><cell>Y8</cell><cell>Y1</cell><cell cols="2">Y2, Y3, Y4, Y5, Y6, Y7</cell><cell>Y2, Y6, Y7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Trends in International Mathematics and Five separate achievement scores were computed with different imputations.Details about the IRT models used to create continuous achievement scores can be found in the TIMSS user manual(Martin, 2005 p. 2-11).</figDesc><table><row><cell>Sciences Study (TIMSS) 2003 international database. The database contains data from 48</cell></row><row><cell>countries, over 360,000 students, 25,000 teachers, and roughly 12,000 school principles. Data</cell></row><row><cell>includes math and science achievement as well as background information on curriculum,</cell></row><row><cell>teachers, schools, and individual students. See the User guide for full information about the study</cell></row><row><cell>(Martin, 2005).</cell></row><row><cell>For this example, I follow the lead of Ryu (2014) who used a subset of the data,</cell></row><row><cell>representing Singaporean 8 th graders from the 2003 assessment of the TIMSS study. This sub-</cell></row><row><cell>sample contains 5928 students clustered in 164 schools in Singapore. School size ranges from 26</cell></row><row><cell>to 42.</cell></row></table><note><p>For this analysis, there are two latent constructs of interest, math achievement and confidence in math. Achievement was measured with continuous IRT scores provided by the TIMSS study.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 3 .</head><label>3</label><figDesc>Items from the Math Confidence scale.</figDesc><table><row><cell>Indicator</cell><cell>Item</cell></row><row><cell>Y1 (r)</cell><cell>I learn things quickly in math.</cell></row><row><cell>Y2</cell><cell>Math is more difficult for me.</cell></row><row><cell>Y3</cell><cell>I do not understand new topics in Math.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 4 .</head><label>4</label><figDesc>Parameter estimates for Model 1 and Model 2 fit to the TIMSS data with both ML and MIIV-2SLS.</figDesc><table><row><cell>Model 1</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>There are exceptions to this. For example, with the HLM software package--which is primarily used for MLM estimation-it is possible to specify measurement models.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>It is near impossible to capture the history of SEM in a paragraph, though I have attempted to succinctly capture some of the important lines of research and specific contributions. Many SEM texts provide more detail about the history (e.g.,Bollen, 1989 pp  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>[4][5][6][7][8]. A more recent chapter on the history of SEM is<ref type="bibr" target="#b103">Matsueda (2012)</ref>.4  The most intuitive way to understand this is to recognize that for both a random effect and latent variable, we assume a distribution and estimate the mean and variance of that distribution.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3"><p>Other common names and acronyms include MLSEM or Multilevel Latent Variable Models (MLLVM).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p><ref type="bibr" target="#b137">Schmidt (1969)</ref> andKeesling (1972)  shared chapters are on Maximum likelihood for factor analysis and numerical approaches to finding the optimums.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_5"><p>Note theAsparouhov &amp; Muthen (2008)  random slopes MSEM framework is accessed in Mplus by using the "TYPE = COMPLEX" syntax. The random intercepts framework is specified with the "TYPE = TWOLEVEL" syntax.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_6"><p>Clarification is provided here in order to avoid confusion with the meta-modeling framework discussed in machine learning and software engineering, which is an entirely different meaning of meta-modeling.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>dissertation submitted to the faculty at the <rs type="institution">University of North Carolina at Chapel Hill</rs> in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the <rs type="institution">Department of Psychology and Neuroscience (Quantitative)</rs>.</p><p>Chapel Hill 2019</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b71">Kwok, Lin, Acosta, 2015;</ref><ref type="bibr" target="#b134">Ryu, 2009)</ref><p>. Alternatively, the equation-by-equation nature of the Sargan test offers a reasonable alternative to examine model fit in MSEMs.</p><p>The MIIV-2SLS procedure is less likely to encounter convergence issues. The usual implementation of MIIV-2SLS for single level SEMs is completely non-iterative. In the current procedure, the first stage of analysis does involve an iterative procedure to obtain estimates of ğ‘º ğ‘Š and ğ‘º ğµ . There is evidence that the saturated model is less likely to cause issues with convergence and thus this procedure should have less trouble with convergence than estimating the model directly with ML <ref type="bibr" target="#b133">(Ryu, 2014)</ref>.</p><p>Finally, identification with MIIV-2SLS can be done on an equation-by-equation basis if the full model is identified. With ML, all levels of the model would be inestimable if one level were under identified. In the case of the current procedure, one level could be under identified and some parameters within that level could still be estimated.</p><p>Of course, there are some potential limitations to MIIV-2SLS as outlined here. I am proposing the use ML to obtain stage 1 estimates of ğ‘º ğ‘Š and ğ‘º ğµ , which introduces normality assumptions. Thus, I have had to avoid making the claim that the MSEM procedure would be asymptotically distribution free (as it is in the single level case). <ref type="bibr" target="#b161">Yuan and Bentler (2007)</ref> claim that ğ‘º ğ‘Š and ğ‘º ğµ will be consistent estimates even if the normality assumption is broken. This suggests the point estimates will be unaffected by breaking distributional assumptions. However, this is unlikely to be true for the standard errors as proposed here, and more work would be needed to estimate correct standard errors when the normality assumptions do not hold.</p><p>Additionally, there is trade-off in estimating levels of the model separately. As I have pointed out, this does create additional robustness properties where bias should not spread from one level of the model to the other. On the other hand, this makes it impossible to add things like CHAPTER 4: MONTE CARLO SIMULATIONS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research Questions</head><p>This chapter aims to examine a number of research questions regarding the empirical performance of MIIV-2SLS estimation for MSEMs. My primary research questions are as follows:</p><p>1. Robustness: One of the desirable properties of MIIV-2SLS is its robustness to structural misspecification. Do we find the same robustness in MSEM estimation? Do we find evidence that MIIV-2SLS is robust to the cross level spread of misspecification.</p><p>Alternatively, do we find evidence that misspecification spreads across levels when using ML? Finally, we would expect the within level robustness properties from single level SEMs to carry over into this context.</p><p>2. Efficiency: One potential trade-off with MIIV-2SLS may be efficiency. Do we find evidence for a noteworthy loss of efficiency when comparing MIIV-2SLS to ML? 3. Corrected Standard Errors: In the previous chapter, I proposed using the delta method to compute approximate standard errors (which should be asymptotically unbiased). Do we find evidence that the delta method standard errors correctly reflect the sampling variability in finite samples?  with respect to the MIIV-2SLS equations given in Table <ref type="table">1</ref>.</p><p>As was already mentioned, one possible trade-off when using MIIV-2SLS would be the potential loss of efficiency. These results do generally confirm that ML has a slight efficiency advantage. This was expected. It also appears that any difference in efficiency is minor, and in many cases, almost non-existent. This would suggest that using MIIV-2SLS does not differ from ML in terms of efficiency in a significant way.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models Fit</head><p>Three models were fit to the data. The first specification involved fitting the True Model.</p><p>The Misspecified Within model was fit a single latent variable at the within level (while correctly specifying the between level). The Misspecified Between was fit with a single latent variable at the between level model (while correctly specifying the within level). Reviewing </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chi-Square Based Model Fit</head><p>In this section I consider the results of the chi-square test and chi-square based model fit statistics CFI, TLI, and RMSEA. Past research has shown that the overall chi-square is sensitive to misfit at both levels of the model, while other fit indices are not. In this way, results related to ML fit statistics in this section are provided to replicate known results.</p><p>First, I consider the chi-square test. Figure <ref type="figure">19</ref> shows the proportion of chi-square tests that reject the null hypothesis that the model is exactly correct (ğ›¼ = 0.05). This is shown across number of clusters, average cluster size, and model specification. When the true model is fit to the data we would expect that the chi-square test would reject the null hypothesis at the level of ğ›¼. Figure <ref type="figure">19</ref> (top row) shows this to be true at larger sample sizes; we also find a higher than expected rejection rate given fewer than 100 clusters. At the smallest sample sizes, the rejection rate given the true model is close to or over 20% depending on the average cluster size. This is much higher than the desired level of ğ›¼. When misspecification was introduced into the model (Figure <ref type="figure">19</ref>, rows 2-3), the chisquare test is almost always significant. When the incorrectly specified model is the within level model, then the chi-square test appears to be significant 100% of the time. When the incorrectly specified model is at the between level, the chi-square test has similar power to detect when there are greater than 100 clusters with slightly less power in smaller samples.</p><p>When assessing fit in SEM models one does not rely on any single fit index. I now turn to other more common chi-square based fit indices such as the CFI, TLI, and RMSEA. Figure <ref type="figure">20</ref> shows the mean values of CFI, TLI, and 1-RMSEA. Note the scale of RMSEA was reversed in order align it with CFI and TLI and make the plot easier to digest (see <ref type="bibr" target="#b22">Bollen, 1999</ref> for example of this). I have added a reference line at 0.95, which some would be considered a rough cut-off for assessing adequate fit. Anything above 0.95 would generally be considered a good fitting model and anything below 0.95 might raise questions. We know that these indices are sensitive to fit at the within level but not the between level <ref type="bibr">(Ryu &amp; West, 2008;</ref><ref type="bibr" target="#b161">Yuan &amp; Bentler, 2007)</ref>. Thus, we might reasonably conclude that our within-level model fits the data; at the same time we know very little about the fit of the between level model.</p><p>Next, I consider the fit of the model based on the Sargan Test and MIIV-2SLS. Table <ref type="table">4</ref> contains the parameter estimates from ML and MIIV-2SLS and Sagan Test results for each equation with MIIV-2SLS. For now, I focus on the Sargan test result and Model 1. The primary goal of this research was to adapt MIIV-2SLS estimation for MSEMs.</p><p>MIIV-2SLS has many useful properties that make it an appealing estimator. Among those tested in this study, include the fact that MIIV-2SLS is more robust to the spread of model misspecification than ML and offers equation specific tests of model fit at both levels of the model. The MIV-2SLS procedure developed in this study is not intended to replace ML. Instead, my hope is to add MIIV-2SLS an additional tool in a researcher's arsenal. Different estimators have different strengths. Perhaps one of the most important strengths of ML estimation is its flexibility. Currently, ML offers more flexibility in the estimation of MSEMs including the </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the Use of Principal Components of Independent Variables in Two-Stage Least-Squares Estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Amemiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Economic Review</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="283" to="303" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Origins of the limited information maximum likelihood and two-stage least squares estimators</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The asymptotic properties of estimates of the parameters of a single equation in a complete system of stochastic equations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Annals of Mathematical Statistics</title>
		<imprint>
			<date type="published" when="1950">1950</date>
			<biblScope unit="page" from="570" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Heterogeneous factor analysis models: A Bayesian approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="77" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Hierarchical Bayesian Methodology for Treating Heterogeneity in Structural Equation Models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagpal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="328" to="347" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Bayesian approach to nonlinear latent variable models using the Gibbs sampler and the Metropolis-Hastings algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Arminger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="300" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<title level="m">General random effect latent variable modeling: Random subjects, items, contexts, and parameters</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Mplus Version 7 Technical Appendix</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Selecting Instrumental Variables in a Data Rich Environment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Time Series Econometrics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A generalized classical method of linear estimation of coefficients in a structural equation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Basmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="77" to="83" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimating multilevel linear models as structural equation models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="167" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">miivfind: A Command for Identifying Model-Implied Instrumental Variables for Structural Equation Models in Stata</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bauldry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stata Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="60" to="75" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: a practical and powerful approach to multiple testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural modeling and Psychometrika: An historical perspective on growth and achievements</title>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="35" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparative fit indexes in structural models</title>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="238" to="246" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the fit of models to covariances and methodology to the Bulletin</title>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="404" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Significance tests and goodness of fit in the analysis of covariance structures</title>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Bonett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="588" to="606" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Two-level mean and covariance structures: Maximum likelihood via an EM algorithm</title>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multilevel Modeling: Methodological Advances, Issues, and Applications</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Duan</surname></persName>
		</editor>
		<meeting><address><addrLine>Mahwah, N.J</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="53" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Correlation and Causality: The Multivariate Case</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Blalock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Forces</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="246" to="251" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Making Causal Inferences for Unmeasured Variables from Correlations Among Indicators</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Blalock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="62" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Structural Equations with Latent Variables</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Limited Information Estimator for LISREL Models with and without Heteroscedasticity</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Structural Equation Modeling: Issues and Techniques</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Marcoulides</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Schumacker</surname></persName>
		</editor>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="227" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An alternative two stage least squares (2SLS) estimator for latent variable equations</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="121" />
			<date type="published" when="1996">1996b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Subject: RMSEA Simple Suggestion</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SEMNET listserv archive</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="1999-01-28">1999. 1/28/1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Two-stage least squares and latent variable models: Simultaneous estimation and robustness to misspecifications</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural Equation Modeling: Present and Future: A Festschrift in Honor of Karl JÃ¶reskog. Scientific Software International</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Cudeck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>JÃ¶reskog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>SÃ¶rbom</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Model Implied Instrumental Variables (MIIVs): An Alternative Orientation to Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="46" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">When Good Loadings Go Bad: Robustness in Factor Analysis</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automating the Selection of Model-Implied Instrumental Variables</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="425" to="452" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robustness Conditions for MIIV-2SLS When the Latent Variable or Measurement Model is Structurally Misspecified</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="848" to="859" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Latent Variable Models Under Misspecification: Two-Stage Least Squares (2SLS) and Maximum Likelihood</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="48" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Model-Implied Instrumental Variable-Generalized Method of Moments (MIIV-GMM) Estimators for Latent Variable Models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kolenikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bauldry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="50" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Testing Structural Equation Models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><surname>Long</surname></persName>
		</author>
		<editor>J. S.</editor>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>SAGE Publications</publisher>
			<pubPlace>Newbury Park</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Problems with Instrumental Variables Estimation when the Correlation between the Instruments and the Endogenous Variables is Weak</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maydeu-Olivares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bound</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jaeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="450" />
			<date type="published" when="1995">2007. 1995</date>
		</imprint>
	</monogr>
	<note>Psychometrika</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Asymptotically distribution free methods for the analysis of covariance structures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="83" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Alternative ways of assessing model fit</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cudeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Testing Structural Equation Models</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Long</surname></persName>
		</editor>
		<meeting><address><addrLine>Newbury Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>SAGE</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="136" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Glaser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">When fit indices and residuals are incompatible</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="403" to="421" />
		</imprint>
	</monogr>
	<note>202AD</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Chapter 4: The analysis of multilevel data in educational research and evaluation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Burnstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review of Educational Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="158" to="233" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Applications of Multilevel Structural Equation Modeling to Cross-Cultural Research</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-L</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="598" to="619" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Some effects of incorrect specification on the small-sample properties of several simultaneous-equation estimators</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Cragg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Economic Review</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>CramÃ¨r</surname></persName>
		</author>
		<title level="m">Mathematical Methods of Statistics</title>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1946">1946</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Have multilevel models been structural equation models all along?</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="529" to="569" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A Bayesian Approach to Multilevel Structural Equation Modeling With Continuous and Dichotomous Outcomes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Clifton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="327" to="351" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Choosing the Number of Instruments</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Newey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1161" to="1191" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Path Analysis: Sociological Examples</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Peer Influences on Aspirations: A Reinterpretation</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Portes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="137" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">An Instrumental Variable Estimator for Mixed Indicators: Analytic Derivatives and Alternative Parameterizations</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<ptr target="https://arxiv.org/pdf/1910.07393.pdf" />
		<imprint/>
	</monogr>
	<note>under review</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">MIIVsem: Model Implied Instrumental Variable (MIIV) Estimation of Structural Equation Models</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>RÃ¶nkkÃ¶</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=MIIVsem" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A Limited Information Estimator for Dynamic Factor Models</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Gates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="246" to="263" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simultaneous Equation Models and Two-Stage Least Squares</title>
		<imprint>
			<date type="published" when="1979">1979</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">130</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Latent variable GIMME using model implied instrumental variables (MIIVs)</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">numDeriv: Accurate Numerical Derivatives</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Varadhan</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=numDeriv" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Model Implied Instrumental Variable Estimation for Multilevel Confirmatory Factor Analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Giordano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Chapel Hill</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of North Carolina</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Structural Equation Methods in the Social Sciences</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="979" to="1001" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
		<title level="m">Multilevel Statistical Models</title>
		<meeting><address><addrLine>West Sussex, UK</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2011">2011a</date>
		</imprint>
	</monogr>
	<note>th Ed</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Bootstrapping in multilevel models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook for advanced multilevel analysis</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Roberts</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY US</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge/Taylor &amp; Francis</publisher>
			<date type="published" when="2011">2011b</date>
			<biblScope unit="page" from="163" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A general model for the analysis of multilevel data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="455" to="467" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Analyzing ATI data by Structural Analysis of Covariance Matrices</title>
		<author>
			<persName><forename type="first">J.-E</forename><surname>Gustafsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lindstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the American Educational Research Association</title>
		<meeting><address><addrLine>San Francisco, CA US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Factor analysis by instrumental variables methods</title>
		<author>
			<persName><forename type="first">G</forename><surname>HÃ¤gglund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="222" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Instrumental variables estimation with many weak instruments using regularized JIVE</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kozbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="290" to="308" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Econometrics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hayashi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Princeton University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Separating Reliability and Stability in Test-Retest Correlation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Heise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Sociological Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Bayesian model averaging for model implied instrumental variable two stage least squares estimators</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<idno>ArXiv:1808.10522</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Some estimators for a linear model with random coefficients</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hildreth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Houck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">322</biblScope>
			<biblScope unit="page" from="584" to="595" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><surname>Ver</surname></persName>
		</author>
		<author>
			<persName><surname>Hoef</surname></persName>
		</author>
		<title level="m">Who Invented the Delta Method? The American Statistician</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="124" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A Comparison of ML, WLSMV, and Bayesian Methods for Multilevel Structural Equation Models in Small Samples: A Simulation Study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holtmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lochner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="661" to="680" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Multilevel analysis: Techniques and applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Lawrence Erlbaum Associates Publishers</publisher>
			<pubPlace>Mahwah, NJ, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</author>
		<title level="m">Multilevel analysis: Techniques and applications</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge, Taylor &amp; Francis</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Multilevel structural equation models: The limited information approach and the multivariate multilevel approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Maas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Developments on Structural Equation Models</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Van Montford</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Oud</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">A</forename><surname>Satorra</surname></persName>
		</editor>
		<meeting><address><addrLine>Dordrecht, Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="135" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">The Accuracy of Multilevel Structural Equation Modeling With Pseudobalanced Groups and Small Samples</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="174" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The effect of estimation method and sample size in multilevel structural equation modeling</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J M</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J S</forename><surname>Brinkhuis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Neerlandica</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="170" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moerbeek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schoot</surname></persName>
		</author>
		<author>
			<persName><surname>Van De</surname></persName>
		</author>
		<title level="m">Multilevel Analysis: Techniques and Applications</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">How few countries will do? Comparative survey analysis from a Bayesian perspective</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matthijsse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Survey Research Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="93" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Detecting Misspecified Multilevel Structural Equation Models with Common Fit Indices: A Monte Carlo Study</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Acosta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="197" to="215" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Evaluating model fit</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural equation modeling: Concepts, issues, and applications</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Hoyle</surname></persName>
		</editor>
		<meeting><address><addrLine>Thousand Oaks, CA, US</addrLine></address></meeting>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="76" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fit indices in covariance structure modeling: Sensitivity to underparameterized model misspecification</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="424" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives</title>
		<author>
			<persName><forename type="first">Li-Tze</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Cross-Level Invariance in Multilevel Factor Models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="607" to="622" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Jak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Oort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Measurement Bias in Multilevel Data</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Selecting polychoric instrumental variables in confirmatory factor analysis: An alternative specification test and effects of instrumental variables</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="387" to="413" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A Simulation Study of Polychoric Instrumental Variable Estimation in Structural Equation Models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang-Wallentin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="680" to="694" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">High School and Beyond first follow-up (1982) school questionnaire data file user&apos;s manual</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tourangeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>O'brien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>National Center for Education Statistics</publisher>
			<pubPlace>Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>JÃ¶reskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>SÃ¶rbom</surname></persName>
		</author>
		<title level="m">New Developments in LISREL. Paper Presented at the National Symposium on Methodological Issues in Causal Modeling</title>
		<meeting><address><addrLine>Tuscaloosa, AL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
		<respStmt>
			<orgName>University of Alabama</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>JÃ¶reskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>SÃ¶rbom</surname></persName>
		</author>
		<title level="m">LISREL 8: Structural equation modeling with the SIMPLIS command language. Scientific Software International</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A general method for analysis of covariance structures</title>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">G</forename><surname>JÃ¶reskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="239" to="251" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A general method for estimating a linear structural equation system</title>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">G</forename><surname>JÃ¶reskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural Equation Models in the Social Sciences</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Goldberger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Duncan</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="85" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The Consequences of Ignoring Multilevel Data Structures in Nonhierarchical Covariance Modeling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Julian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="325" to="352" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Multilevel Measurement Modeling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kamata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Miyazaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multilevel Modeling of Educational Data</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>O'connell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Mccoach</surname></persName>
		</editor>
		<meeting><address><addrLine>Charlotte, NC</addrLine></address></meeting>
		<imprint>
			<publisher>US: Information Age Publishing Inc</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="345" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Maximum likelihood approaches to causal flow analysis (Doctoral Dissertation)</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Keesling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
	<note type="report_type">Dissertation/thesis number: T-24459</note>
	<note>Retrieved from ProQuest Dissertations &amp; Theses Global. Proquest document ID: 302695981</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Using Instrumental Variable Tests to Evaluate Model Specification in Latent Variable Structural Equation Models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methodology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="327" to="355" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Random-Effects Models for Longitudinal Data</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Ware</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="963" to="974" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Multilevel analysis of structural equation models</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="763" to="772" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">Structural Equation Modeling: A Bayesian Approach</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Two-level analysis of covariance structures for unbalanced designs with small level-one samples</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="123" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Analysis of two-level structural equation models via EM type algorithms</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="749" to="766" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Analyzing measurement models of latent variables through multilevel confirmatory factor analysis and hierarchical linear modeling approaches</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Harmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stoolmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="294" to="306" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Sample Size Limits for Estimating Upper Level Mediation Models Using Multilevel SEM</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Beretvas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="264" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">An EM algorithm for fitting two-level structural equation models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="122" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Factor analysis for clustered observations</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Longford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="581" to="597" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">A 2 Ã— 2 taxonomy of multilevel latent contextual models: Accuracy-Bias tradeoffs in full and partial error correction models</title>
		<author>
			<persName><forename type="first">O</forename><surname>LÃ¼dtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Marsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robitzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Trautwein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="444" to="467" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Working with imperfect models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="113" to="139" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Studying multivariate change using multilevel models and latent curve models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Malarkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kiecolt-Glaser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="253" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Magnus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neudecker</surname></persName>
		</author>
		<title level="m">Matrix differential calculus with applications in statistics and econometrics</title>
		<meeting><address><addrLine>Hoboken, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Public/Catholic Differences in the High School and Beyond Data: A Multigroup Structural Equation Modeling Approach to Testing Mean Differences</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Marsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Statistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="199" to="235" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m">TIMSS 2003 User Guide for the International Database</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Martin</surname></persName>
		</editor>
		<meeting><address><addrLine>Chestnut Hill, MA; Boston College</addrLine></address></meeting>
		<imprint>
			<publisher>TIMSS &amp; PRILS International Study Center</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Key Advances in the History of Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Matsueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Structural Equation Modeling</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Hoyle</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Guilford Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">A general model for two-level data with responses missing at random</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="575" to="585" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">The bilevel reticular action model for path analysis with latent variables</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="413" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Balanced versus unbalanced designs for linear structural relations in two-level data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="232" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">People Are Variables Too: Multilevel Structural Equations Modeling</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Neale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="284" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Latent curve analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Meredith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tisak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="122" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">A Monte Carlo sample size study: How many countries are needed for accurate multilevel SEM?</title>
		<author>
			<persName><forename type="first">B</forename><surname>Meuleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Billiet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Survey Research Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="58" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Bayesian structural equation modeling: A more flexible representation of substantive theory</title>
		<author>
			<persName><forename type="first">B</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="335" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Latent variable modeling in heterogeneous populations</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="557" to="585" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Mean and covariance structure analysis of hierarchical data</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<ptr target="https://www.statmodel.com/bmuthen/full_paper_list.htm" />
	</analytic>
	<monogr>
		<title level="m">Psychometric Society meeting in</title>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-06">1990. June 1990</date>
			<biblScope unit="volume">62</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Multilevel covariance structure analysis</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="376" to="398" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Growth mixture modeling: Analysis with non-Gaussian random effects</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Longitudinal data analysis</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Fitzmaurice</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Davidian</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Verbeke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Molenberghs</surname></persName>
		</editor>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<ptr target="https://www.statmodel.com/download/Random_coefficient_regression.pdf" />
		<title level="m">Random Coefficient Regression</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Multilevel aspects of varying parameters in structural models</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multilevel Analysis of Educational Data</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Bock</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, US</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="87" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">The Distribution of the Instrumental Variables Estimator and Its t-ratio when the Instrument is a Poor One</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Startz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="125" to="140" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">A Monte Carlo study comparing PIV, ULS and DWLS in the estimation of dichotomous confirmatory factor analysis</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="143" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">How the 2SLS/IV estimator can handle equality constraints in structural equation models: A system-of-equations approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="353" to="369" />
			<date type="published" when="2014">2014a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Using Instrumental Variables to Estimate the Parameters in Unconditional and Conditional Second-Order Latent Growth Models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2014">2014b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">A Specification Error Test That Uses Instrumental Variables to Detect Latent Quadratic and Latent Interaction Effects</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="542" to="551" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Discriminating Between Measurement Scales Using Nonnested Tests and 2SLS: Monte Carlo Evidence</title>
		<author>
			<persName><forename type="first">E</forename><surname>Oczkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="125" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">A Note on the Delta Method</title>
		<author>
			<persName><forename type="first">G</forename><surname>Oehlert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="27" to="29" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">The Performance of ML, GLS, and WLS Estimation in Structural Equation Modeling Under Conditions of Misspecification and Nonnormality</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Foss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Troye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="557" to="595" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Multilevel structural equation models for assessing moderation within and across levels of analysis</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Preacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zyphur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="205" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">A general multilevel SEM framework for assessing multilevel mediation</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Preacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Zyphur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="233" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Generalized multilevel structural equation modeling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rabe-Hesketh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Skrondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pickles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="190" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation for unbalanced multilevel covariance structure models via the EM algorithm</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Raudenbush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="359" to="370" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Toward a coherent framework for comparing trajectories of individual change</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Raudenbush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Decade of behavior. New methods for the analysis of change</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Sayer</surname></persName>
		</editor>
		<meeting><address><addrLine>Washington, DC, US</addrLine></address></meeting>
		<imprint>
			<publisher>American Psychological Association</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="35" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Raudenbush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Bryk</surname></persName>
		</author>
		<title level="m">Hierarchical linear models: Applications and data analysis methods</title>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Using the Delta Method for Approximate Interval Estimation of Parameter Functions in SEM</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raykov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Marcoulides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="621" to="637" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Estimating Multilevel Structural Equation Models with Random Slopes for Latent Covariates (Doctoral Dissertation)</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Rockwood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019. 27534796</date>
		</imprint>
	</monogr>
	<note type="report_type">Dissertation/thesis number</note>
	<note>Retrieved from ProQuest Dissertations &amp; Theses Global. ProQuest document ID: 2273363974</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Model fit evaluation in multilevel structural equation models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ryu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Level-Specific Evaluation of Model Fit in Multilevel Structural Equation Modeling</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="583" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">The estimation of economic relationships using instrumental variables</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Sargan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="393" to="415" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Corrections to test statistics and standard errors in covariance structure analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Latent variables analysis: Applications for developmental research</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Eye</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Clogg</surname></persName>
		</editor>
		<meeting><address><addrLine>Thousand Oaks, CA, US</addrLine></address></meeting>
		<imprint>
			<publisher>Sage Publications, Inc</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="399" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title level="m" type="main">Covariance structure analysis of the multivariate random effects model (Doctoral Dissertation)</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Schmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
	<note type="report_type">Dissertation/thesis number: T-17635</note>
	<note>Retrieved from ProQuest Dissertations &amp; Theses Global. Proquest document ID: 251131989</note>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Searle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
		<title level="m">Variance components</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="volume">391</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">General intelligence,&quot; objectively determined and measured</title>
		<author>
			<persName><forename type="first">C</forename><surname>Spearman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="293" />
			<date type="published" when="1904">1904</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Statistical Inference in Random Coefficient Regression Models Using Panel Data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A V B</forename><surname>Swamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Inference in Random Coefficient Regression Models</title>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="97" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Estimation and simultaneous correlation in complete equation systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Theil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Central Planning Bureau</title>
		<meeting><address><addrLine>The Hague, mimeo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1953">1953a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title level="m" type="main">Repeated least squares applied to complete equation systems</title>
		<author>
			<persName><forename type="first">H</forename><surname>Theil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1953">1953b</date>
			<publisher>Central Planning Bureau</publisher>
			<pubPlace>The Hague</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Estimation of parameters of econometric models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Theil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of International Statistics Institute</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="122" to="128" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Theil</surname></persName>
		</author>
		<title level="m">XV of Contributions to Economic Analysis</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North-Holland Pub. Co</publisher>
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
	<note>Economic forecast and policy</note>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Evaluation of factor analytic research procedures by means of simulated correlation matrices</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Linn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="421" to="459" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">A reliability coefficient for maximum likelihood factor analysis</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">De potentieeltheorie van intelligentie (The potentiality theory of intelligence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Van Peet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<pubPlace>University of Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>Unpublished Doctoral Dissertation</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Resampling Multilevel Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Der Leeden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Multilevel Analysis</title>
		<editor>
			<persName><forename type="first">Jan</forename><surname>De</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Leeuw</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Erik</forename><surname>Meijer</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="401" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">The identification problem for structural equation models with unmeasured variables</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Wiley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural Equation Models in the Social Sciences</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Goldberger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Duncan</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="69" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">On the nature of size factors</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="367" to="374" />
			<date type="published" when="1918">1918</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Correlation and causation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Agricultural Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="557" to="585" />
			<date type="published" when="1921">1921</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">The Theory of path coefficients: A reply to Niles&apos; criticism</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="239" to="255" />
			<date type="published" when="1923">1923</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">The method of path coefficients</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="161" to="215" />
			<date type="published" when="1934">1934</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">The interpretation of multivariate systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Mathematics in Biology</title>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">K</forename><surname>Kempthorne</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Bancroft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Gowen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Lush</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="11" to="33" />
			<date type="published" when="1954">1954</date>
			<publisher>Iowa State University Press</publisher>
			<pubPlace>Ames</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title level="m" type="main">Path Coefficients and Path Regressions: Alternative or Complementary Concepts?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960">1960</date>
			<publisher>International Biometric Society</publisher>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="189" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Confirmatory Factor Analysis of Ordinal Variables with Misspecified Models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yang-Wallentin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Joreskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="392" to="423" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">Covariance structure analysis with three-level data</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H Y</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-Y</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="159" to="178" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fit indices versus test statistics</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="115" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">On normal theory based inference for multilevel models with distributional violations</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="539" to="561" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Asymptotic robustness of the normal theory likelihood ratio statistic for two-level covariance structure models</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Multivariate Analysis</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="328" to="343" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multilevel Covariance Structure Analysis by Fitting Multiple Single-Level Models</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="53" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">On MuthÃ©n&apos;s maximum likelihood for two-level covariance structure models</title>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="167" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
