<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Randomized Link Transformer for Diverse Open-Domain Dialogue Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jing</forename><forename type="middle">Yang</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Electronic Engineering</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kong</forename><forename type="middle">Aik</forename><surname>Lee</surname></persName>
							<email>lee_kong_aik@i2r.a-star.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Woon</forename><forename type="middle">Seng</forename><surname>Gan</surname></persName>
							<email>ewsgan@ntu.edu.sg</email>
							<affiliation key="aff1">
								<orgName type="department">Institute for Infocomm Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Randomized Link Transformer for Diverse Open-Domain Dialogue Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T18:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A major issue in open-domain dialogue generation is the agent's tendency to generate repetitive and generic responses. The lack in response diversity has been addressed in recent years via the use of latent variable models, such as the Conditional Variational Auto-Encoder (CVAE), which typically involve learning a latent Gaussian distribution over potential response intents. However, due to latent variable collapse, training latent variable dialogue models are notoriously complex, requiring substantial modification to the standard training process and loss function. Other approaches proposed to improve response diversity also largely entail a significant increase in training complexity. Hence, this paper proposes a Randomized Link (RL) Transformer as an alternative to the latent variable models. The RL Transformer does not require any additional enhancements to the training process or loss function. Empirical results show that, when it comes to response diversity, the RL Transformer achieved comparable performance compared to latent variable models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-domain dialogue generation refers to the task of generating coherent, natural and human-like dialogue given solely the dialogue context (also known as the dialogue history). The development of opendomain dialogue agents that can engage humans in seamless general conversation (or chit-chat) is one of the main objectives of conversational AI. Currently, however, agents display a tendency to generate repetitive and generic dialogue responses, which negatively impact both naturalness and contextual coherence.</p><p>Recently, researchers have turned to latent variable models, specifically the Conditional Variational Auto Encoder (CVAE) <ref type="bibr" target="#b29">(Sohn et al., 2015)</ref>, to address this issue <ref type="bibr" target="#b38">(Yang et al., 2021;</ref><ref type="bibr" target="#b4">Gao et al., 2019;</ref><ref type="bibr" target="#b41">Zhao et al., 2017;</ref><ref type="bibr" target="#b0">Cao and Clark, 2017)</ref>.</p><p>In addition to open-domain dialogue generation, latent variable models have also been applied to related tasks such as personalized dialogue <ref type="bibr" target="#b9">(Lee. et al., 2022;</ref><ref type="bibr" target="#b37">Wu et al., 2020;</ref><ref type="bibr" target="#b30">Song et al., 2019)</ref>, empathetic dialogue <ref type="bibr" target="#b13">(Li et al., 2021</ref><ref type="bibr">(Li et al., , 2020b,a;,a;</ref><ref type="bibr" target="#b43">Zhou and Wang, 2018)</ref>, and topical dialogue generation <ref type="bibr" target="#b36">(Wang et al., 2020)</ref>. These works have generally involved modelling the potential dialogue response intents as a latent Gaussian prior, which is typically generated by a Multi-Layer Perceptron (MLP). During inference, a latent instance is sampled from the generated Gaussian prior via the reparameterization trick and fed to the decoder. Stochasticity is induced during the response generation via such random sampling process. However, even though latent variable models are effective at improving response diversity, they are notoriously hard to train primarily due to the Kullback-Liebler (KL) vanishing problem. Usually, this problem is addressed via KL annealing or incorporating a Bag-of-Words loss. While KL annealing requires tuning the weighting hyperparameter β, attaining the Bag-of-Words loss involves defining an additional task of predicting the response bag-of-words. This results in additional complexity during training.</p><p>Several other approaches to promoting response diversity which involve introducing an alternate loss function such as the Maximum Mutual Information (MMI) objective <ref type="bibr">(Li et al., 2016a)</ref>, the Inverse Token Frequency (ITF) objective <ref type="bibr" target="#b20">(Nakamura et al., 2018)</ref>, and the Inverse N-gram Frequency (INF) objective <ref type="bibr" target="#b34">(Ueyama and Kano, 2020)</ref>, require considerable additional computation steps. On the other hand, adversarial learning-based <ref type="bibr">(Li et al., 2017a)</ref> and embedding augmentation-based <ref type="bibr" target="#b1">(Cao et al., 2021)</ref> approaches require extensive modifications to the standard training process, resulting in a significant increase in training complexity.</p><p>Hence, inspired by randomization-based neural networks (Suganthan and Katuwal, 2021) and the Random Vector Functional Link (RVFL) neural network <ref type="bibr" target="#b23">(Pao and Takefuji, 1992)</ref> in particular, we introduce a novel Randomized Link (RL) Transformer. An alternative to latent variable models which does not require any modifications or enhancements to the standard training process or loss function. In other words, the RL Transformer can be trained via standard gradient descent solely on the standard negative log-likelihood loss. Experimental results on the DailyDialog <ref type="bibr">(Li et al., 2017b)</ref> and <ref type="bibr">EmpatheticDialogues (Rashkin et al., 2019)</ref> corpora show that our RL Transformer successfully improves the diversity of the generated response, achieving comparable response diversification relative to latent variable approaches. In addition, compared to the latent variable models, responses generated by our RL Transformer are noticeably more fluent and contextually coherent.</p><p>The remainder of this paper is organized as follows: Section 2 provides additional background information regarding open-domain dialogue generation and RVFL neural networks; Section 3 describes the proposed RL Transformer in detail; Section 4 provides details regarding our implementations and experiments; Section 5 presents the experimental results as well as our analysis of the results; Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural Open-domain Dialogue Generation</head><p>In recent years, generative neural models have been commonly applied to the task of open-domain dialogue generation. Influenced by advances in machine translation, popular approaches to this task featured a sequence-to-sequence (seq2seq) architecture <ref type="bibr" target="#b33">(Sutskever et al., 2014)</ref>. Recurrent neural networks such as the Long Short Term Memory (LSTM) and the Gated Recurrent Unit (GRU) have been often utilized in both the encoder and decoder of a seq2seq model <ref type="bibr" target="#b27">(Shang et al., 2015;</ref><ref type="bibr" target="#b31">Sordoni et al., 2015)</ref>. More recently, Transformer-based models <ref type="bibr" target="#b35">(Vaswani et al., 2017)</ref> have taken centre stage. Multiple works have leveraged Transformerbased pretrained language models such as BERT, GPT and GPT-2 to improve the overall language understanding and generation capabilities of their dialogue agents <ref type="bibr" target="#b6">(Gu et al., 2021;</ref><ref type="bibr" target="#b39">Zhang et al., 2020;</ref><ref type="bibr" target="#b42">Zhao et al., 2019)</ref>. In addition to latent variable models, different learning approaches such as reinforcement learning <ref type="bibr" target="#b26">(Saleh et al., 2019;</ref><ref type="bibr">Li et al., 2016b)</ref> and adversarial learning <ref type="bibr">(Li et al., 2017a)</ref> have also been applied to this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Random Vector Functional Link Neural Networks</head><p>The Random Vector Functional Link (RVFL) neural network <ref type="bibr" target="#b23">(Pao and Takefuji, 1992)</ref> is essentially a single-layer feed forward neural network with a direct link between the input and output layer. The optimal weights of an RVFL can be obtained iteratively, or through a closed form solution via regularized least squares or the Moore-Penrose pseudoinverse. Prior work has mathematically proven that the RVFL is an efficient and effective universal approximator <ref type="bibr" target="#b22">(Needell et al., 2020)</ref>. Over the years, multiple RVFL variants including (but not limited to) the deep RVFL <ref type="bibr" target="#b28">(Shi et al., 2021)</ref>, ensemble deep RVFL <ref type="bibr" target="#b28">(Shi et al., 2021)</ref>, sparse Pretrained-RVFL <ref type="bibr" target="#b40">(Zhang et al., 2019)</ref>  Our proposed model generates the dialogue response based only on the dialogue context. Similar to the standard Transformer, the RL Transformer consists of an encoder and decoder. The encoder maps an input sequence X = {x 0 , ..., x J-1 } (J refers to the length of the input sequence) to an intermediate representation Z = {z 0 , ..., z J-1 }. The decoder then accepts Z as input and generates the final output Y = {y 0 , ..., y K-1 } (K refers to the length of the output sequence) token by token, in an auto-regressive manner.</p><p>The proposed RL Transformer leverages linear layers with randomly initialized weights to incorporate stochasticity into the response generation process. Our work is largely inspired by the Random Vector Functional Link (RVFL) neural network <ref type="bibr" target="#b23">(Pao and Takefuji, 1992)</ref>, a single-layer feed forward randomization-based neural network consisting of a fixed randomized hidden layer and a direct link from the input to the output layer. The  direct link is implemented by concatenating the input with the randomized hidden layer output, before being fed to the output layer. Only the weights in the output layer are trainable. We incorporate the RVFL architecture into the self-attention and feed forward networks of a Transformer.</p><p>Essentially, the Randomized Link Transformer encoder consists of a Randomized Link Self-Attention (RLSA) network and a Randomized Link Feed Forward (RLFF) network. The decoder, on the other hand, consists of a RLSA network, followed by a Encoder-Decoder (ED) RLSA network and a regular Feed Forward (FF) network. Similar to the original Transformer architecture, residual connections and layer normalization is introduced after every RLSA, RLFF, ED RLSA and FF network. An overview is provided in Figure <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Randomized Link Self-Attention</head><p>In order to incorporate stochasticity into the response generation process, we introduce a novel Randomized Link Self-Attention (RLSA) network featuring feed forward linear layers with random weights. Similar to to the original Transformer architecture, our randomized link self-attention involves mapping a query vector, denoted by Q, and a set of key-value vector pairs, denoted by K and V respectively, to an output. The output is derived by computing the weighted sum of the values, where the weight assigned to each value is computed by taking the dot product of the query with the corresponding key. For each attention head in the standard transformer architecture, the input is passed to three distinct linear layers, resulting in the query, key and value vectors Q n , K n , and V n , where n refers to an arbitrary attention head.</p><p>In RLSA, each input will be fed to a single random linear layer. The sizes of all random linear layers used in the randomized Transformer, denoted by d rand , are identical. Similar to the RVFL, we introduce a direct link by concatenating the output of this layer with the original input. The resultant representation is fed to a separate linear layer with trainable weights. Similarly, for multi-headed RLSA, a distinct Q n , K n , and V n vector is defined for each of the N attention heads. The dimensionality of the Q n and K n vectors is denoted by d k , and the dimensionality of the V n vector is denoted by d v . This can be expressed as follows:</p><formula xml:id="formula_0">Q n = W Qn ([X, W r Qn (X)])<label>(1)</label></formula><formula xml:id="formula_1">K n = W Kn ([X, W r Kn (X)])<label>(2)</label></formula><formula xml:id="formula_2">V n = W Vn ([X, W r Vn (X)])<label>(3)</label></formula><p>where W Q , W K , and W V represent the weights of the trainable linear layers corresponding to the Q, K and V vectors respectively. We use the superscript () r to denote the randomized matrices, whereby W r Q , W r K , and W r V represent the weights of the randomly initialized linear layers corresponding to the Q n , K n and V n vectors respectively. X denotes the input sequence, and [•] represents the concatenate operation.</p><p>The randomized linear layers W r Q , W r K , and W r V are initialized every epoch with Xavier normal initialization <ref type="bibr" target="#b5">(Glorot and Bengio, 2010)</ref> </p><formula xml:id="formula_3">i.e., W r Q , W r K , W r V ∼ N (0, σ 2 ) where σ = γ × 2 d hidden +d rand .</formula><p>The gain value γ = 1.0. The selection of the standard deviation or the variance of the initialization is vital to model performance. This is because an excessively large variance would result in model divergence, while an excessively small variance would result in a drop in stochasticity. For the randomized layers in RLSA, weights initialized from a normal distribution with a suitable standard deviation would allow the model to converge while maintaining stochasticity. As seen in the equation, for the Xavier normal initialization, the standard deviation of the Gaussian distribution from which the initial weights are sampled is a function of the total number of inputs and outputs. Empirically, we found that the standard deviation value utilized during Xavier normal initialization would generally outperforms other standard deviation values across all randomized layer sizes.</p><p>Then, following the standard Transformer architecture, the dot product of all corresponding Q and K vectors are computed to obtain the attention maps. Then, to attain the score, the softmax function is applied over the dot products divided by the square root of the dimension of the Q and K vectors i.e., √ d k . Each of the V vectors is then multiplied with the attained score. This results in the following expression:</p><formula xml:id="formula_4">Z n = sof tmax( Q n K T n √ d k )V n (4)</formula><p>where T represents the transpose operation. The output of each attention head Z n is concatenated to form Z:</p><formula xml:id="formula_5">Z = [Z 0 , Z 1 , Z 2 • • • Z N -1 ]<label>(5)</label></formula><p>where N represents the number of attention heads.</p><p>Then, the resulting representation Z is then passed to a single linear layer with randomly initialized weights. Once again, to obtain the encoder output Z, the output of the random layer is concatenated with the original input Z, and fed to a separate linear layer with trainable weights (direct link).</p><formula xml:id="formula_6">Z = W Z ([X, W r Z (Z)])<label>(6)</label></formula><p>where W Z and W r Z represent the weights of the trainable linear layer and randomized linear layer used to obtain the encoder output Z respectively. Similarly, the randomized linear layer W r Z is initialized every epoch with Xavier normal initialization i.e., W r Z ∼ N (0, σ 2 ) where σ = γ × 2 dv+d rand . The gain value γ = 1.0.</p><p>For the Encoder Decoder (ED) RLSA in the decoder, the encoder outputs and prior decoder outputs are used as input. The output of the prior decoder layer is used to generate the queries, and the encoder outputs are used to generate the keys and values. An overview of the RLSA network is presented in Figure <ref type="figure" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Randomized Link Feed Forward Network</head><p>The feed forward network in the standard Transformer consists of a two-layer fully trainable feed forward neural network. Likewise, the Randomized Link Feed Forward (RLFF) network is a two-layer feed forward neural network which features a randomly initialized fixed linear layer with a ReLU ⊕ refers to the concatenate operation.</p><p>activation function followed by a trainable linear layer. Similarly, the direct link is introduced by concatenating the output of the randomized layer with the original inputs, and passing the resultant representation to the trainable layer. In contrast to the RLSA network (Section 3.2), no additional randomized layers are introduced in the RLFF network. The first linear layer is randomized instead. This can be expressed as:</p><formula xml:id="formula_7">RLF F (Z) = W 2 ([ReLU (W r 1 (Z)), Z]) (7) where W r</formula><p>1 and W 2 refer to the first random linear layer and the second trainable linear layer respectively. The size of the randomized linear layer W r 1 is represented by d f f , and the size W 2 is d hidden . Unlike the RLSA network, for the RLFF network, the randomized linear layer W r 1 is initialized every epoch with Xavier uniform initialization <ref type="bibr" target="#b5">(Glorot and Bengio, 2010)</ref> i.e., W r Z ∼ U(-a, a) where a = γ × 6 d hidden +d f f . Since the ReLU activation is applied to the layer output, the gain value. The gain value γ = √ 2. We found that utilizing a uniform initialization in the RLFF network instead of a normal initialization would result in a slight increase in response diversity. Also, it should be noted that the RLFF network is only utilized in the encoder of the Randomized Transformer. An overview of the RLFF network is presented in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We evaluate the Randomized Link Transformer on the DailyDialogs <ref type="bibr">(Li et al., 2017b)</ref> and <ref type="bibr">Em-patheticDialogues (Rashkin et al., 2019)</ref> corpora. For the EmpatheticDialogues corpus, the agent is expected to generate an appropriately empathetic response given the dialogue context and emotion label, which is not used in our experiments. The training, validation and test set consists of 19,533, 2,770, and 2,547 dialogues respectively. The Dai-lyDialog corpus consists of general human-written dialogue examples covering a wide range of topics and emotions. Similarly, the provided intent and emotion labels are not used in our experiments. The training, validation and test set consists of 11,118, 1,000 and 1,000 dialogues respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation</head><p>In our experiments, we implement the Randomized Link (RL) Transformer with 4 encoding layers, 4 decoding layers, with 4 attention heads (N = 4). Since the 300 dimensional GloVe embedding <ref type="bibr" target="#b24">(Pennington et al., 2014)</ref> is used, the hidden dimension d hidden = 300. The size of all randomized layers in the RLSA network d rand is fixed at 512. d k , d v and d z were set to 64 for experiments of the DailyDialog corpus, and 256 on the EmpatheticDialogues corpus. For the RLFF network, d f f is set to 2048. Inputs to the RL Transformer consists of the dialogue context (limited to 4 dialogue turns). Responses are generated via greedy decoding. During training, the Adam optimizer (learning rate = 0.00015, batch size = 32) is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>We implement the following four models in our experiments:</p><p>Transformer. We implement a Transformer <ref type="bibr" target="#b35">(Vaswani et al., 2017)</ref> with standard self attention and feed forward components. The Transformer parameters are identical to the RL Transformer as described in Section 4.2. CVAE. Similar to <ref type="bibr" target="#b41">Zhao et al. (2017)</ref> and <ref type="bibr" target="#b17">Lin et al. (2020)</ref>, we implement a Transformer-based CVAE where the latent variable sampled from the latent Gaussian is combined with the output of the encoder before being fed to the decoder. Following <ref type="bibr" target="#b17">Lin et al. (2020)</ref>, the latent Gaussian is generated by a three-layer MLP with 512 node hidden layers, and the size of the random latent variable is fixed at 300. The remaining Transformer parameters are identical to the RL Transformer as described in Section 4.2. SVT. We also implement the Sequential Variational Transformer (SVT) proposed in <ref type="bibr" target="#b17">Lin et al. (2020)</ref>. The SVT replaces the standard Transformer decoder with a variational decoder layer which implicitly generates a distinct latent variable for each position. Similarly, the latent Gaussians are generated via three-layer MLPs with 512 node hidden layers, and the size of the random latent variable is fixed at 300. The remaining Transformer parameters are identical to the RL Transformer described in Section 4.2. RL Transformer. We implement the proposed RL Transformer with configuration described in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Objective Measures</head><p>Distinct-N. We use the Distinct-1 and 2 scores, denoted by D-1 and D-2 respectively, to quantify the inter-response diversity of the generated responses. Essentially, the Distinct-n score involves computing the number of distinct n-grams in a given text, and dividing the number by the total number of tokens. The Distinct score is derived based on all generated responses. MTLD &amp; MATTR. Additionally, we also utilize lexical diversity measures such as the Measure of Textual Lexical Diversity (MTLD) and Moving-Average Type-Token Ratio (MATTR) score. MATTR and MTLD are essentially text length invariant variants of the Token-Type Ratio (TTR). MTLD involves computing the Token-Type Ratio (TTR) for sequentially larger segments of the sentence until a predefined threshold h. On the other hand, deriving MATTR requires averaging DailyDialog Length D-1 D-2 MATTR MTLD METEOR ROUGE-L Transformer <ref type="bibr" target="#b35">(Vaswani et al., 2017)</ref>   <ref type="bibr">)</ref> between the generated response and response label, followed by computing the harmonic mean of the precision and recall between the LCS and the generated response. METEOR is similarly based on the harmonic mean between precision and recall calculated based on the generated response and response label, with more emphasis placed on recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Human Evaluation</head><p>For human evaluation, we engage five graduate students (native English speakers) to evaluate the Fluency, Diversity and Coherence of the generated responses. The Fluency criteria measures the naturalness and human-likeness of the generated response.</p><p>For the Fluency criteria, the evaluators were told to regard the response in isolation, without regard for the dialogue context. The Diversity criteria accounts for the diversity on terms of vocabulary in the generated response. Coherence refers to the contextual coherence of the generated response i.e., the relevance of the generated response in relation to the dialogue context. The evaluators were given the dialogue context, and told to consider the appropriateness of the generated responses with regard to the dialogue context. For each example, they were told to compare a response generated by RL Transformer and a response generated by either the base Transformer, CVAE or SVT. The superior response in terms of either Fluency, Coherence or Diversity is selected by the evaluator, and either a 'Win', 'Lose' or 'Tie' is assigned to the corresponding model. The percentage of wins, loses or ties for each pair is then computed. Each evaluator was given 50 randomly sampled dialogue contexts and the corresponding responses generated by the implemented models for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Quantitative Analysis</head><p>Automatic metric scores attained on the DailyDialog and EmpatheticDialogues copora are presented in Table <ref type="table" target="#tab_2">1</ref>. Human evaluation was only conducted on the DailyDialog corpus. Results are presented in Table <ref type="table" target="#tab_6">3</ref>.</p><p>Based on the results attained, it can be concluded that the performance of the RL Transformer is comparable to that of latent variable models such as the CVAE and SVT. On the DailyDialog corpus, RL Transformer outperformed all implemented baselines in terms of Distinct-1 and 2 scores. On the EmpatheticDialogues corpus, RL Transformer outperformed all implemented baselines in terms of Distinct-1, MATTR and MTLD.</p><p>When it comes to response diversity, the human evaluation results largely corroborate the automatic metric scores. In terms of Diversity, the RL Transformer achieved a high percentage of 'Wins' over the standard Transformer, and a relatively high percentage of 'Ties' against the latent variable models.</p><p>It can also be observed that the RL Transformer also achieved a high percentage of 'Wins' over la-  tent variable models in terms of Coherence. This is corroborated by the qualitative analysis of the responses provided in the following section. We suspect that low Coherence scores attained by the latent variable models could be partially attributed to the random sampling process. Since the latent Gaussian models the potential dialogue response intents, sampled random variables which deviate significantly from the mean could encompass an irrelevant dialogue intent. When this random variable is fed to the decoder, an incoherent response would likely be generated. Similarly, it can also be observed that the RL Transformer also achieved a high percentage of 'Wins' over latent variable models in terms of Fluency. This could be potentially attributed to the random linear layers introduced in the RLSA networks, which serve to improve the overall capability of the RL Transformer. Additionally, as reported in <ref type="bibr" target="#b18">Liu et al. (2016)</ref>, we note that the ROUGE and METEOR scores do not correlate with any aspect of human evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qualitative Analysis</head><p>We conduct a qualitative analysis by examining the responses generated by each of the implemented  However, numerous responses generated by CVAE and SVT were relatively unnatural due to the relatively poor fluency and contextual coherence. A large number responses generated by the latent variable models had grammatical or structural issues, and a significant number were irrelevant in relation to the dialogue context i.e., out of context. On the other hand, the responses generated by the RL Transformer were significantly more natural and human-like, displaying far fewer grammatical or structural issues and greater relevance with regard to the dialogue context.</p><p>Samples of the generated responses along with the corresponding dialogue contexts are provided in Table <ref type="table" target="#tab_4">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study</head><p>We also conduct an ablation study, using the Dai-lyDialog corpus, to investigate the contributions of each of the RLSA and RLFF components in the encoder and decoder. Additionally, to examine the importance of the direct links, we implement a variant of the RL Transformer without any direct links. The results of the ablation study are presented in Table <ref type="table">4</ref>. In the same table, we also provide the diversity scores for two variants of the RL Transformer where the randomized layers are initialized via Normal initialization (N (0.0, 0.1)) and Uniform initialization (U(0.0, 0.01)) respectively.</p><p>Based on the results attained, we can observe that the RLSA network in the encoder, and the RLSA and ED RLSA networks in the decoder have a relatively large impact on response diversity. Substituting the RLSA or ED RLSA networks for the standard self-attention network results in a significant drop on all diversity measures. However, substituting the RLFF in the encoder for a standard feed forward network results in a relatively minor decrease in diversity. Hence, we conclude that stochasticity introduced in the self-attention networks contribute to overall response diversity to a much larger extent compared to the RLFF network. Although, it should also be noted that, substituting the standard feed forward network in the decoder with a RLFF network would result in a slightly lower diversity scores.</p><p>Also, the importance of the direct links cannot be overstated. From the results attained by the RL Transformer without links, it is apparent that removal of the direct links would result in extremely low response diversity. Upon closer inspection of the responses generated by this variant of the RL Transformer, we notice that a majority of the generated responses are short, generic and highly repetitive.</p><p>In addition, we present the results attained by varying the number of hidden nodes in the randomized layers in Table <ref type="table" target="#tab_7">5</ref>. Intuitively, this implies varying levels of stochasticity. From Table <ref type="table" target="#tab_7">5</ref>, we can observe that increasing the number of neurons in the randomized layer would generally result in an increase in diversity. This can be attributed to an increase in stochasticity due to an increase in the number of randomized weights. However, there is a significant drop in diversity when the size of the randomized layers exceed 512. In this case, the model fails to learn effectively, and generates meaningless, generic, and repetitive responses instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we have proposed a novel RL Transformer which successfully improves response diversity in the task of open-domain dialogue generation. This is achieved by inducing stochasticity in the self-attention and the feed forward networks of a Transformer via randomized layers and direct links. Experimental results on the DailyDialog and Empa-theticDialogues corpora show that, compared to latent variable models, the RL Transformer achieved comparable levels of diversification while further improving on contextual coherence and fluency. In the future, the RL Transformer can be adapted for related dialogue generation tasks such as personalized, empathetic or topical dialogue generation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Model architecture of the proposed Randomized Link Transformer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overview of Randomized Link Self Attention. ⊕ refers to the concatenate operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of Randomized Link Feed Forward network. ⊕ refers to the concatenate operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Performance comparison of the proposed RL Transformer to the three baselines on the DailyDialog and EmpatheticDialogues corpora.the TTR of successive segments of the generated response with a fixed window size w. In this paper, h and w were fixed at 0.72 and 4 respectively. Both MTLD and MATTR are derived based on all generated responses.</figDesc><table><row><cell></cell><cell cols="2">6.075 0.004 0.017</cell><cell>0.360</cell><cell>12.461</cell><cell>0.076</cell><cell>0.060</cell></row><row><cell>CVAE (Zhao et al., 2017) SVT (Lin et al., 2020) RL Transformer</cell><cell cols="2">11.656 0.035 0.200 10.244 0.032 0.199 7.678 0.050 0.221</cell><cell cols="2">0.661 0.580 0.649 EmpatheticDialogues 32.927 21.371 30.049</cell><cell>0.117 0.118 0.113</cell><cell>0.103 0.108 0.101</cell></row><row><cell></cell><cell>Length D-1</cell><cell cols="5">D-2 MATTR MTLD METEOR ROUGE-L</cell></row><row><cell cols="3">Transformer (Vaswani et al., 2017) 9.757 0.015 0.049 CVAE (Zhao et al., 2017) 11.367 0.028 0.226</cell><cell>0.396 0.728</cell><cell>16.479 49.394</cell><cell>0.103 0.097</cell><cell>0.116 0.084</cell></row><row><cell>SVT (Lin et al., 2020) RL Transformer</cell><cell cols="2">12.568 0.023 0.240 11.808 0.030 0.239</cell><cell>0.691 0.734</cell><cell>36.536 51.396</cell><cell>0.105 0.101</cell><cell>0.096 0.085</cell></row></table><note><p>ROUGE-L &amp; METEOR. Both ROUGE-L and METEOR compares the generated response to the response label. Computing the ROUGE-L score involves first identifying the Longest Common Subsequence (LCS</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Examples of responses generated by the Transformer, CVAE, SVT and RL Transformer models.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Human evaluation results on the DailyDialog corpus. For each criteria (Fluency, Coherence, and Di-versity), responses generated by the RL Transformer are compared against responses generated by the Trans-former, CVAE and SVT models. The average 'Win', 'Tie', and 'Loss' percentages are presented. Kappa scores largely range from 0.6 to 0.7, indicating sub-stantial to moderate inter-annotator agreement.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Ablation study results for 64, 128, 256, 512, and 1024 nodes in the random layers.</figDesc><table><row><cell></cell><cell>D-1</cell><cell cols="3">D-2 MATTR MTLD</cell></row><row><cell>64</cell><cell cols="2">0.005 0.025</cell><cell>0.426</cell><cell>13.142</cell></row><row><cell>128</cell><cell cols="2">0.036 0.142</cell><cell>0.527</cell><cell>17.396</cell></row><row><cell>256</cell><cell cols="2">0.043 0.168</cell><cell>0.628</cell><cell>22.053</cell></row><row><cell>512</cell><cell cols="2">0.050 0.221</cell><cell>0.649</cell><cell>30.049</cell></row><row><cell cols="3">1024 0.023 0.100</cell><cell>0.586</cell><cell>19.884</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Latent variable dialogue models and their diversity</title>
		<author>
			<persName><forename type="first">Kris</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<title level="s">Short Papers</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="182" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards efficiently diversifying dialogue generation via embedding augmentation</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiliang</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Fang</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP39728.2021.9414915</idno>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2021 -2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="7443" to="7447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sar target recognition with modified convolutional random vector functional link network</title>
		<author>
			<persName><forename type="first">Qijun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/LGRS.2021.3132020</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Zheng Fang, and Biao Xue</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Android malware classification based on random vector functional link and artificial jellyfish search optimizer</title>
		<author>
			<persName><forename type="first">T</forename><surname>Emad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reham</forename><forename type="middle">R</forename><surname>Elkabbash</surname></persName>
		</author>
		<author>
			<persName><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sherif</surname></persName>
		</author>
		<author>
			<persName><surname>Barakat</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0260232</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A discrete CVAE for response generation on short-text conversation</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1198</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1898" to="1908" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Chia Laguna Resort</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">DialogBERT: Discourse-aware response generation via learning to recover and rank utterances</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Woo</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><surname>Ha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modelling and forecasting of covid-19 spread using wavelet-coupled random vector functional link networks</title>
		<author>
			<persName><forename type="first">Barenya</forename><surname>Bikash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hazarika</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2020.106626</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page">106626</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Random vector functional link neural network based ensemble deep learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Rakesh Katuwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><surname>Tanveer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dlvgen: A dual latent variable approach to personalized dialogue generation</title>
		<author>
			<persName><forename type="first">Jing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lee</forename><surname>Kong Aik Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Woon Seng</forename><surname>Gan</surname></persName>
		</author>
		<idno type="DOI">10.5220/0010812500003116</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Agents and Artificial Intelligence</title>
		<meeting>the 14th International Conference on Agents and Artificial Intelligence</meeting>
		<imprint>
			<publisher>INSTICC, SciTePress</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">2016a. A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1014</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1127</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1192" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1230</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2157" to="2169" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dual-view conditional variational autoencoder for emotional dialogue generation</title>
		<author>
			<persName><forename type="first">Mei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<idno type="DOI">10.1145/3481890</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Asian Low-Resour. Lang. Inf. Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Em-pDG: Multi-resolution interactive empathetic dialogue generation</title>
		<author>
			<persName><forename type="first">Qintong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongshen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.394</idno>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<meeting><address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4454" to="4466" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Emoelicitor: An open domain response generation model with user emotional reaction awareness</title>
		<author>
			<persName><forename type="first">Shifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daling</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaisong</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weichao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3637" to="3643" />
		</imprint>
	</monogr>
	<note>International Joint Conferences on Artificial Intelligence Organization. Main track</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DailyDialog: A manually labelled multi-turn dialogue dataset</title>
		<author>
			<persName><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuzi</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
	<note>Long Papers). Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Variational transformers for diverse response generation</title>
		<author>
			<persName><forename type="first">Zhaojiang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Genta</forename><surname>Indra Winata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.12738</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1230</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A novel ensemble method of rvfl for classification problem</title>
		<author>
			<persName><forename type="first">Ashwani</forename><surname>Kumar Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ganaie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanveer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
		<idno type="DOI">10.1109/IJCNN52387.2021.9533836</idno>
	</analytic>
	<monogr>
		<title level="m">2021 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Another diversitypromoting objective function for neural dialogue generation</title>
		<author>
			<persName><forename type="first">Ryo</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koichiro</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
		<idno>CoRR, abs/1811.08100</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A deep stacked random vector functional link network autoencoder for diagnosis of brain abnormalities and breast cancer</title>
		<author>
			<persName><forename type="first">Ratnakar</forename><surname>Deepak Ranjan Nayak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Banshidhar</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ram</forename><surname>Majhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yudong</forename><surname>Bilas Pachori</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bspc.2020.101860</idno>
	</analytic>
	<monogr>
		<title level="j">Biomedical Signal Processing and Control</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">101860</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Random vector functional link networks for function approximation on manifolds</title>
		<author>
			<persName><forename type="first">Deanna</forename><surname>Needell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">A</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rayan</forename><surname>Saab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Palina</forename><surname>Salanevich</surname></persName>
		</author>
		<idno>CoRR, abs/2007.15776</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Functional-link net computing: theory, system architecture, and functionalities</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Pao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takefuji</surname></persName>
		</author>
		<idno type="DOI">10.1109/2.144401</idno>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="76" to="79" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards empathetic opendomain conversation models: A new benchmark and dataset</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Boureau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1534</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5370" to="5381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">Abdelrhman</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natasha</forename><surname>Jaques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asma</forename><surname>Ghandeharioun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judy</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosalind</forename><surname>Picard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.07547</idno>
		<title level="m">Hierarchical reinforcement learning for open-domain dialog</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-1152</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Random vector functional link neural network based ensemble deep learning</title>
		<author>
			<persName><forename type="first">Qiushi</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Rakesh Katuwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><surname>Tanveer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patcog.2021.107978</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page">107978</biblScope>
		</imprint>
	</monogr>
	<note>Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exploiting persona information for diverse generation of conversational responses</title>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/N15-1020</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the origins of randomization-based feedforward neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ponnuthurai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rakesh</forename><surname>Suganthan</surname></persName>
		</author>
		<author>
			<persName><surname>Katuwal</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.asoc.2021.107239</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page">107239</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Diverse dialogue generation with context dependent dynamic loss function</title>
		<author>
			<persName><forename type="first">Ayaka</forename><surname>Ueyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshinobu</forename><surname>Kano</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.364</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4123" to="4127" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Topic enhanced controllable cvae for dialogue generation (student abstract)</title>
		<author>
			<persName><forename type="first">Yiru</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengda</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyang</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujiu</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i10.7250</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13955" to="13956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Guiding variational response generator to exploit persona</title>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zongsheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junhong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.7</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="53" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Progressive open-domain response generation with multiple controllable attributes</title>
		<author>
			<persName><forename type="first">Haiqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiqun</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianping</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</title>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3279" to="3285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">DIALOGPT : Large-scale generative pre-training for conversational response generation</title>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.30</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="270" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An unsupervised parameter learning model for rvfl neural network</title>
		<author>
			<persName><forename type="first">Yongshan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihua</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neunet.2019.01.007</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="85" to="97" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1061</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Bert for open-domain conversation modeling</title>
		<author>
			<persName><forename type="first">Xue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenya</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojie</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCC47050.2019.9064414</idno>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 5th International Conference on Computer and Communications (ICCC)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1532" to="1536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">MojiTalk: Generating emotional responses at scale</title>
		<author>
			<persName><forename type="first">Xianda</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1104</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<meeting><address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1128" to="1137" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
