<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Latent Variable Models for Sequential Data</title>
				<funder ref="#_P6WrzU3">
					<orgName type="full">Microsoft Research</orgName>
				</funder>
				<funder>
					<orgName type="full">DTU Compute</orgName>
				</funder>
				<funder>
					<orgName type="full">Google DeepMind</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marco</forename><surname>Fraccaro</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kongens</forename><surname>Lyngby</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Applied Mathematics and Computer Science</orgName>
								<orgName type="institution" key="instit1">Technical University of Denmark</orgName>
								<orgName type="institution" key="instit2">Richard Petersens Plads</orgName>
								<address>
									<addrLine>building 324</addrLine>
									<postBox>Phone +45</postBox>
									<postCode>2800 4525 3031</postCode>
									<settlement>Kongens Lyngby</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Applied Mathematics and Computer Science</orgName>
								<orgName type="institution" key="instit1">Cognitive Systems section of DTU Compute</orgName>
								<orgName type="institution" key="instit2">Technical University of Denmark</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Latent Variable Models for Sequential Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Kalman variational auto-encoders <ref type="bibr" target="#b35">(Fraccaro et al., 2017)</ref>, that can learn from data disentangled and more interpretable visual and dynamic representations. Finally, we will show that to deal with temporal applications that require a high memory capacity we can combine deep latent variable models with external memory architectures, as in the generative temporal model with spatial memory of <ref type="bibr" target="#b38">Fraccaro et al., (2018)</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Over the last few decades an ever-increasing amount of data is being collected in a wide range of applications. This has boosted the development of mathematical models that are able to analyze it and discover its underlying structure, and use the extracted information to solve a multitude of different tasks, such as for predictive modelling or pattern recognition. The available data is however often complex and high-dimensional, making traditional data analysis methods ineffective in many applications. In the recent years there has then been a big focus on the development of more powerful models, that need to be general enough to be able to handle many diverse applications and kinds of data. Some of the most interesting advancements in this research direction have been recently obtained combining ideas from probabilistic modelling and deep learning. Variational auto-encoders (VAEs), that belong to the broader family of deep latent variable models, are powerful and scalable models that can be used for unsupervised learning of complex high-dimensional data distributions. They achieve this by parameterizing expressive probability distributions over the latent variables of the model using deep neural networks. VAEs can be used in applications with static data, for example as a generative model of images, but they are not suitable to model temporal data such as the sequences of images that form a video. However, a major part of the data that is being collected has a sequential nature, and finding powerful architectures that are able to model it is therefore fundamental.</p><p>In the first part of the thesis we will introduce a broad class of deep latent variable models for sequential data, that can be used for unsupervised learning of complex and high-dimensional sequential data distributions. We obtain these models by extending VAEs to the temporal setting, and further combining ideas from deep learning (e.g. deep and recurrent neural networks) and probabilistic modelling (e.g. state-space models) to define generative models for the data that use deep neural networks to parameterize very flexible probability distributions. This results in a family of powerful architectures that can model a wide range of complex temporal data, and can be trained in a scalable way using large unlabelled datasets.</p><p>In the second part of the thesis we will then present in detail three architectures belonging to this family of models. First, we will introduce stochastic recurrent neural networks <ref type="bibr" target="#b39">(Fraccaro et al., 2016c)</ref>, that combine the expressiveness of recurrent neural networks and the ability of state-space models to model the uncertainty in the learned latent representation. We will then present Resumé (Summary in Danish) I løbet af de sidste par årtier er der samlet en stadig større maengde data i en bred vifte af anvendelser. Dette har styrket udviklingen af matematiske modeller, der kan analysere og opdage den underliggende struktur i data, og bruge den uddragne information til at løse en lang raekke forskellige opgaver, f.eks. til prediktiv modellering eller mønstergenkendelse. De tilgaengelige data er imidlertid ofte komplekse og høj dimensionelle, hvilket ofte gør traditionelle dataanalysemetoder ineffektive. I de senere år har der vaeret et stort fokus på udviklingen af mere kraftfulde modeller, der skal vaere generelle nok til at kunne håndtere mange forskellige typer anvendelser og data.</p><p>Nogle af de mest interessante fremskridt i denne forskningsretning er for nylig blevet opnået ved at kombinere ideer fra probabilistisk modellering og dyb laering. Variational auto-encoders (VAE'er), der tilhører den bredere familie af dybe latente variabel modeller, er fleksible og skalerbare modeller, som kan bruges til uovervåget (eng unsupervised) laering af komplekse høj dimensionelle datafordelinger. De opnår dette ved at parameterisere ekspressive sandsynlighedsfordelinger over de latente variabler ved hjaelp af dybe neurale netvaerk. VAE'er kan bruges i applikationer med statiske data, for eksempel som en generativ model af billeder, men de er ikke egnede til at modellere tidsmaessige data, såsom sekvenserne af billeder <ref type="bibr">(video)</ref>. En stor del af de data, der indsamles, har imidlertid en sekventiel karakter, og det er derfor en fundamental udfordring at finde ekspressive arkitekturer, der kan modellere det.</p><p>I den første del af afhandlingen introducerer vi en bred klasse af dyb latent variabel modeller til sekventielle data, der kan bruges til uovervåget laering af komplekse og høj dimensionelle sekventielle datafordelinger. Vi kommer frem til disse modeller ved at udvide VAE'erne til det tidslige domaene og yderligere kombinere ideer fra dyb laering f.eks. dybe og rekursive neurale netvaerk (eng recurrent neural networks) og probabilistisk modellering f.eks. state-space-modeller. Dette resulterer i en familie af arkitekturer, som kan bruges til at modellere en bred vifte af komplekse tidsmaessige data og kan traenes på en skalerbar måde ved hjaelp af store datasaet. I anden del af afhandlingen vil vi så detaljeret praesentere tre arkitekturer af ovennaevnte type. For det første vil vi introducere stochastic recurrent neural networks <ref type="bibr" target="#b39">(Fraccaro et al., 2016c)</ref>, der kombinerer ekspressiviteten af rekursive neurale netvaerk og state-space-modellers evne til at modellere usikkerheden i den laerte latente repraesentation. Vi vil derefter praesentere Kalman variational auto-encoders <ref type="bibr" target="#b35">(Fraccaro et al., 2017)</ref>, der kan laere afkoblede og mere fortolkelige visuelle og dynamiske data repraesentationer. Endelig vil vi vise at for at håndtere anvendelser på First of all, I am deeply grateful to my supervisors Ole Winther and Ulrich Paquet for their fundamental role in everything I have accomplished in the last three and a half years. Your inspiration and enthusiasm have guided me through a challenging but extremely fun journey I can be proud of! I truly hope that even after my PhD I can keep learning from you and collaborate in new exciting projects. A special thanks to Ulrich for his help in writing papers until late at night before every deadline, as well as his PR skills that were fundamental to get the funding for this PhD project and my internships.</p><p>During my Master and PhD I spent most of my time at the Cognitive Systems (CogSys) section of DTU Compute, an amazing place whose courses and professors transformed me from a newbie in Machine Learning to a researcher that masters it well enough to publish and obtain a PhD. I wish to thank all my CogSys colleagues for the many great discussions, and in particular my collaborators, the deep learners and everyone from the Bayesian reading/cake group! During my PhD I was lucky enough to intern with two amazing researchers: Tom Minka (Microsoft Research Cambridge) and Danilo Rezende (Google DeepMind). Thank you both for you support and guidance during the internship, it has been lots of fun! Also, thanks to all the other great Microsoft and Google researchers and interns I have met, that made these experiences even better! I am grateful for the financial support from Microsoft Research and DTU Compute for my PhD studies, Otto Mønsteds Fond for allowing me to travel to many different conferences all over the world, and Nvidia for donating many of the GPUs I used to run experiments.</p><p>Last but not least, I am grateful to my friends and family in Denmark, Italy, Colombia and many other parts of the world, for the fantastic moments spent together. A huge thanks to my parents Mario and Giovanna, my sister Claudia and my girlfriend Martina who supported me with love over all these years, and were kind enough to bear with me while I was busy and working hard before the many exams and deadlines I had during the course of my studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part I</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Chapter 1 Introduction</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation</head><p>The majority of the successful practical applications of machine learning use supervised learning methods, that learn a mapping from an input to an output variable using a dataset containing labelled data. We may want for example to learn a classification model that receives an image of an object as input, and outputs a label describing the type of object in the image. For training this model we require a labelled dataset that contains a set of image-label pairs from which the model can learn to distinguish the different objects. However, labelled data is scarce and expensive to obtain, in contrast to the vast amount of unlabelled data collected daily in the Web and in the smart devices connected to the Internet of Things (IoT).</p><p>A major focus in recent machine learning research is therefore the development of unsupervised learning methods, that use the available unlabelled data. In unsupervised learning, the interest is in learning models that can describe the underlying structure of the data, e.g. interesting patterns, clusters, statistical correlations or causal structures. We can use it for example to uncover the hidden structures in a collection of images, learn how to predict some of the pixels of an image given the rest of them (e.g. to deal with occlusions) or generate new images from the same data distribution.</p><p>not require labelled data, training can be performed using very large datasets. It is generally much harder than supervised learning, as instead of predicting a single label given the input, unsupervised methods have learn to describe the structure of the input itself. In the last few years there have been major advancements in unsupervised learning of complex high-dimensional data distributions such as images, most of which build on the seminal works on variational autoencoders (VAEs) <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> and generative adversarial networks (GANs) <ref type="bibr" target="#b51">(Goodfellow et al., 2014)</ref>. Broadly speaking, these models combine ideas from deep learning and probabilistic modelling, by defining generative models for the data that use deep neural networks to parameterize very expressive probability distributions. This results in complex but flexible models containing hundreds of thousands of parameters, that are trained in a scalable way using large datasets of unlabelled data and exploiting the computational capabilities of graphics processing units (GPUs).</p><p>Most of the focus in recent unsupervised learning research has been on static data, i.e. fixed data with no sequential nature such as images. A big part of the available unlabelled data is sequential: we may be interested for example in modelling videos (a sequence of images), speech, music, text, visits in electronic health records, the evolution of financial markets, user-click behaviors or sensor data, all of which have an inherent temporal component. State-of-the-art models for unsupervised learning of high-dimensional distributions such as VAEs are however difficult to use in the sequential setting, as they cannot properly model temporal correlations in the data.</p><p>The aim of this thesis is to introduce a general class of sequential models for unsupervised learning that can be used to model a wide range of complex temporal data and can be trained in a scalable way using large unlabelled datasets. We combine deep learning architectures with probabilistic models for sequential data that use deep neural networks to parameterize their distributions, therefore obtaining flexible models inspired by VAEs. This will be discussed more in detail in Section 1.2. These models can be used for a broad range of tasks such as for generative modelling, representation learning, predictive modelling, compression, probabilistic reasoning or planning in model-based reinforcement learning.</p><p>The primary target audience of this thesis is practitioners who are interested in flexible models for unsupervised learning of high-dimensional sequential data distributions. We assume some experience in basic probability theory and deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Outline and contributions</head><p>Despite its importance, the progress on unsupervised learning in the sequential setting has been slower than the one for the static case. One of the main challenges when learning such methods for sequential data is that the ideas they build on were developed in many different scientific areas such as control theory, aerospace engineering, econometrics, statistics and machine learning (both in probabilistic modelling and deep learning), each of which uses different terminologies and notations. In the first half of this thesis (Chapters 2 to 4) we then present a unified treatment of these topics from a machine learning perspective, hoping to help the reader understand the "big picture" of how all these seemingly disparate ideas and models are connected. We also introduce simple examples and intuitions that can be helpful to grasp the rationale behind more complex methods<ref type="foot" target="#foot_0">foot_0</ref> . The second half of the thesis (Chapters 5 to 7) contains three publications that present some of the novel models for unsupervised learning for high dimensional temporal data distributions, briefly discussed in Chapter 4, in greater detail.</p><p>Chapter 2 introduces latent variable models (LVMs), the building blocks of all the models presented in the rest of the thesis, and shows how they can be used for unsupervised learning in the static setting. LVMs are probabilistic models that use a latent variable to model the generative process from which the data was created and capture its hidden structure. We show that in many cases the integrals needed during posterior inference and parameter learning are not analytically tractable, but can be approximated using Variational inference. We then introduce a flexible and scalable architecture, called variational auto-encoder, that can model a wide range of data distributions by using the function approximation capabilities of deep neural networks to parameterize the probability distributions that define it. Thanks to the deep neural networks, this model can learn to automatically extract useful features in a hierarchical way.</p><p>Chapter 3 presents state-space models (SSM) as sequential extensions to LVMs, that provide a general framework for sequential data modelling. We show that depending on our modelling assumptions we can define different classes of SSMs. The linear Gaussian state-space model is a basic architecture that makes strong assumptions on the generative process of the data, but for which posterior inference is analytically tractable. It is also possible to define more expressive non-linear and non-Gaussian architectures, for which however we will need to perform approximate posterior inference building on the techniques discussed in Chapter 2 for the static setting.</p><p>Chapter 4 shows that we can combine the ideas presented in Chapters 2 and Chapter 3 to define a general family of methods for large-scale unsupervised learning of complex high-dimensional data distributions in the sequential setting. We build a wide variety of models merging ideas from deep learning (e.g. recurrent neural networks and external memories) and probabilistic modelling (e.g. state-space models and variational auto-encoders). These models can be trained in a scalable way using amortized inference ideas from VAEs, with black-box methods that allow us to focus more on the modelling side than on the inference one. However, we also show that inference can be further improved by tailoring the posterior approximation to the specific model. This chapter contains the most novel component of the unified treatment presented in the first half of the thesis, as we illustrate the strong connections between many of the models presented in the recent literature as well as between the approximate inference techniques used for training.</p><p>Chapter 5 contains the paper <ref type="bibr" target="#b39">(Fraccaro et al., 2016c)</ref>, that introduces stochastic recurrent neural networks (SRNN). For some sequential datasets recurrent neural networks (RNNs) are not enough, as they cannot model the stochasticity in the latent representation. We then define a model that combines the ability of RNNs to capture long-term dependencies in the data and the ability of state-space models to model the uncertainty in the stochastic latent states. We use flexible state-space models parameterized by deep networks, that can be trained extending ideas from variational autoencoders to the temporal setting as shown in Chapter 4. architectures, therefore their results are difficult to interpret. In this paper we show that by carefully designing the model including some domain knowledge in a structured prior distribution we can learn disentangled visual and dynamic representations, that make the model more interpretable and computationally efficient when making predictions for future time steps. The backbone of the KVAE is given by a linear Gaussian state-space model, and we can therefore exploit its exact inference procedures and missing data imputations capabilities.</p><p>Chapter 7 contains the paper <ref type="bibr" target="#b38">(Fraccaro et al., 2018)</ref>, that introduces generative temporal models with spatial memory (GTM-SM). In some applications that require a big memory capacity recurrent neural networks are not powerful enough to memorize all the needed information. This is the case for example when modelling agents walking in an environment that need to remember what they have seen in the past. In this paper we show that this task can be solved by combining a structured prior similar to the one presented in Chapter 6 with a non-parametric differentiable external memory architecture.</p><p>Chapter 8 finally summarizes the main contributions of this thesis, discusses open questions and some directions for future work.</p><p>Chapter 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latent Variable Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Latent variable models</head><p>One of the central problems in machine learning is that of unsupervised learning of complicated probability distributions p(x) given a finite sample of possibly high-dimensional data points x drawn from that distribution. For example, consider the task of learning a probability distribution over images of houses. To be able to do this, we need to define a distribution that can model the complex correlations between the hundreds of thousands of pixels that form each image, that are due to the recurring textures and patterns in the image. For example, neighboring pixels will likely have similar colors and there will be multiple windows of the same type. To build such distributions p(x) that are both flexible and scalable enough, several methods cast the image modelling problem to a sequential one, defining an ordering for the pixels in the image and learning to to predict the next pixel given all the previous ones <ref type="bibr" target="#b80">(Larochelle and Murray, 2011;</ref><ref type="bibr" target="#b145">Van Den Oord et al., 2016)</ref>. However, due to the high number of pixels in a sequence, capturing the correlations between distant pixels in the image is challenging.</p><p>Rather than modelling the distribution p(x) directly, we can introduce an unobserved latent variable z and define a conditional distribution p(x|z) for the data, also known as likelihood. In the following, we assume that z is a continuous random variable, but many of the ideas described below also apply to the discrete case. Each of the elements of the observed variable x will depend on the latent variable z, that can therefore be used to express the correlations in the observed variable x. When modelling images of houses, z could for example contain a latent representation of the type of house in the image, its architectural style, the color of the walls and so on. We introduce a prior distribution p(z) over the latent variables, and compute the joint distribution over observed and latent variables as p(x, z) = p(x|z)p(z) .</p><p>(2.1)</p><p>The introduction of the latent variable in the model allows us to express the complex marginal distribution p(x) in terms of a more tractable joint distribution, whose components p(x|z) and p(z) are typically much simpler to define, for example by using exponential family distributions.</p><p>Given the joint distribution we obtain the desired data distribution p(x) by marginalizing over the latent variables: p(x) = p(x, z)dz = p(x|z)p(z)dz .</p><p>(2.2)</p><p>Using Bayes' rule we can then compute the posterior distribution p(z|x) as p(z|x) = p(x|z)p(z) p(x) , (2.3) which allows us to infer the latent variable given the observation.</p><p>Models with latent variables can be interpreted as expressing the generative process from which the data was created: to generate a new data point we first get a sample z (s) from p(z), and we then use it to sample a new observation x (s) from the conditional distribution p(x|z (s) ). Samples obtained in this way can also be used to asses whether the model provides a good approximation to the data distribution. In our example, z can be interpreted as containing a latent representation of the architectural choices that where taken when designing the house, that condition the house that is actually built, i.e. the observation x.</p><p>The specific relationship between the latent variable z and the observation x depends on the form of the distributions in (2.1). Often we assume that the likelihood p(x|z) and the prior p(z) belong to parametric families of distributions. To make this explicit in the notation, we can write the joint distribution as</p><formula xml:id="formula_0">p θ (x, z) = p θ (x|z)p θ (z) ,<label>(2.4)</label></formula><p>where θ denotes the unknown parameters of the model, that can be learned from data as discussed in detail in Section 2.3.</p><p>Using latent variables that have a much lower dimensionality than the observed vectors we can obtain a compressed representation of the data. In this case in fact, the latent variables act as as a bottleneck through which all the information needed to generate the observations has to pass. This is justified by the fact that in many data sets the data lies in a manifold whose dimensionality is much smaller than the one of the original data space. Latent variable models can be used as black-box density models, but we can also include some prior knowledge on the generative mechanism that created the data in the distributions that define the joint p(x, z) e.g. using probabilistic graphical models. We will return to this point in Section 3.1 when discussing state-space models.</p><p>Mathematical models containing latent variables are defined as latent variable models (LVMs). Among this class of methods we find linear Gaussian models such as factor analysis, principal component analysis and mixture of Gaussians, as presented in the seminal paper by <ref type="bibr" target="#b124">Roweis and Ghahramani, (1999)</ref>. These models have the advantage that posterior inference is tractable, but are not expressive enough to model the kind of high-dimensional data we are interested in. This chapter will then focus on non-linear LVMs, that are more suitable to model complex highdimensional data distributions but that require approximate inference as for them the integral in (2.2) has no analytic solution. In Section 2.4 we will introduce variational auto-encoders (VAEs), that merge ideas from deep learning and latent variable models by using deep neural networks to define very flexible distributions for (2.1). We broadly define such non-linear LVMs in which the non-linearities are given by deep neural networks as Deep Latent Variable Models (DLVMs).</p><p>Before introducing VAEs, the next sections present scalable techniques based on variational methods to perform approximate inference and learning in non-linear LVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Posterior inference</head><p>The posterior distribution in (2.3) represents our updated beliefs about the latent variables after having seen the data, and it is a key component for probabilistic reasoning in LVMs. In many of the models presented in this thesis, however, the posterior is intractable due to the lack of an analytic solution to the integral in (2.2) that appears in the denominator of (2.3). There are broadly two classes of methods that were developed to approximate the posterior distribution. They trade accuracy of the approximation with computational time:</p><p>1. Sampling techniques such as Markov Chain Monte Carlo (MCMC) methods provide a sample-based approximation to the posterior distribution. In most cases the posterior is needed primarily to evaluate expectations, that can be approximated using the posterior samples with Monte Carlo integration. Sampling methods have the appealing property that given infinite computational resources they generate exact results, and the approximation only comes from the fact that we have a limited amount of resources in practice. However, these methods are in general computationally expensive and do not scale well to large data sets. Furthermore, it is often difficult to diagnose their convergence.</p><p>2. Deterministic approximation techniques are based on analytic approximations to the posterior distribution, where we assume for example that the posterior comes from a particular parametric family of distributions or that it factorizes in a certain way. These are very scalable methods, but even given infinite computational resources they cannot generate exact results. Among this class of methods we find for example the Laplace approximation, variational inference and expectation propagation.</p><p>This thesis focuses on large data sets of high-dimensional data, for which variational inference provides a good trade-off between quality of the approximation and scalability of the inference procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Variational inference</head><p>In variational inference we use the calculus of variations to find the posterior approximation q(z) that minimizes a measure of dissimilarity between q(z) and the true posterior p(z|x). While there are many different ways to measure of how different two distributions are, variational inference uses the Kullback-Leibler (KL) divergence between the variational distribution and the posterior distribution<ref type="foot" target="#foot_1">foot_1</ref> , defined as</p><formula xml:id="formula_1">KL [q(z)||p(z|x)] = -E q(z) log p(z|x) q(z) ,<label>(2.5)</label></formula><p>where E q(z) denotes an expectation over q(z). Importantly, the KL divergence is a non-negative quantity, i.e. KL [q(z)||p(z|x)] ≥ 0, with equality if and only if q(z) = p(z|x). The more similar q(z) is to p(z|x), the smaller the KL divergence will be. Notice that this quantity is however not a distance in the mathematical sense, as it is not symmetric if we swap the two distributions.</p><p>Our goal is to find a good variational approximation q(z) that minimizes the KL divergence in (2.5). However, this quantity is still not tractable as the intractable posterior p(z|x) appears at the numerator inside the logarithm. Using (2.3) we can rewrite (2.5) as</p><formula xml:id="formula_2">KL [q(z)||p(z|x)] = -E q(z) log p(x, z) q(z) -log p(x)</formula><p>= -E q(z) log p(x, z) q(z)</p><formula xml:id="formula_3">F (q) + log p(x) , (2.6)</formula><p>where the marginal likelihood log p(x) could be taken out of the expectation as it is independent from z. The quantity F(q) is known as Evidence Lower BOund (ELBO), as due to the nonnegativity of the KL divergence it represents a lower bound to the evidence log p(x), i.e. log p(x) ≥ F(q) for all q(z). Notice that in (2.6) the numerator inside the logarithm is now tractable, since it consists of the joint distribution in (2.1), and log p(x) is constant for all q(z). This means that to minimize KL [q(z)||p(z|x)], and finding therefore the optimal variational approximation, we can just maximize the ELBO with respect to the distribution q(z): the closer the ELBO is to the marginal likelihood, the closer (in KL sense) the variational approximation will be to the posterior distribution. Using variational methods, we can therefore reduce a complex inference problem to a simpler optimization problem.</p><p>In practice, the variational distribution q(z) is often restricted to a particular parametric family for which the ELBO is tractable or simple to approximate (e.g. Gaussian distribution), and the maximization with respect to q(z) is therefore a maximization with respect to the parameters of the family. The family of distribution q(z) needs to be flexible enough to provide a good approximation to the posterior distribution, but simple enough to make the ELBO easy to compute. We will return to this point when introducing the posterior approximation for the VAE in Section 2.5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Parameter learning</head><p>We assume that the likelihood p θ (x|z) and the prior p θ (z) belong to families of distributions that depend on some unknown parameters θ. Given a training set with N data points {x i } N i=1 , the optimal parameters θ of the model can be learned using Maximum Likelihood Estimation (MLE), i.e. maximizing</p><formula xml:id="formula_4">L(θ) = N i=1 log p θ (x i ) = N i=1 log p θ (x i , z i )dz i L i (θ)</formula><p>with respect to the parameters θ of the model. Notice in particular that while we have a different latent variable z i for each data point x i , the parameters θ of the likelihood and prior are shared across all data points. In this thesis, we assume that the parameters are fixed but unknown quantities. Alternatively, one could follow a Bayesian approach, considering them as random variables with a prior distribution p(θ) and working with the joint distribution p(x i , z i , θ) = p(x|z i , θ)p(z i |θ)p(θ). In the rest of this chapter, we will omit the superscript i when only one data point is referred to, or when it is clear from the context.</p><p>As discussed in the previous sections, in many cases the marginal density of the observations p θ (x) is intractable and needs to be approximated. As we have seen in Section 2.2.1, a possible approximation can be obtained using the ELBO. This result can be re-derived in an alternative way, provided below as it is widely used in the literature and gives interesting insights in variational methods. For any distribution q(z) over the latent variables, we can compute a lower bound to log p θ (x) as follows:</p><formula xml:id="formula_5">L i (θ) = log p θ (x) = log p θ (x, z)dz = log p θ (x, z) q(z) q(z)dz = log E q(z) p θ (x, z) q(z) ≥ E q(z) log p θ (x, z) q(z) = F i (θ, q) , (2.7)</formula><p>where we have used the concavity of the logarithm and Jensen's inequality to swap the logarithm and the expectation in the last line. F i (θ, q) is exactly the ELBO introduced in (2.6), but we extended the notation to stress the dependence on the parameters θ of the model and on data point x i . We have then shown in an alternative way that the ELBO is a lower bound to log p(x), i.e. L i (θ) ≥ F i (θ, q). To learn the parameters of the model, instead of maximizing the log-likelihood L(θ), we can then maximize the total ELBO F(θ, q) = N i=1 F i (θ, q) with respect to θ and q(z). As we have seen in Section 2.2.1, the variational distribution can be interpreted as an approximation to the posterior distribution p θ (z|x), and the ELBO coincides with the log-likelihood if and only if q(z) is the posterior distribution, i.e. q(z) = p θ (z|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">The Expectation Maximization (EM) algorithm</head><p>The Expectation Maximization (EM) algorithm is a two-stage iterative optimization method for MLE of the parameters of a model with latent variables in it <ref type="bibr" target="#b25">(Dempster et al., 1977)</ref>. The EM algorithm can be formulated in its most general form starting from the ELBO in (2.7). It alternates between two steps, that maximize F i (θ, q) with respect to q(z) and θ respectively, while holding the other fixed. We start from some parameters θ 0 , and until convergence we repeat E-step:</p><formula xml:id="formula_6">q k+1 = argmax q F i (θ k , q) (2.8) M-step: θ k+1 = argmax θ F i (θ, q k+1 ) (2.9) z x θ φ Figure 2</formula><p>.1: Graphical model of a variational auto-encoder. Here and in the other graphical models in this thesis empty nodes denote latent variables, while colored ones denote observations.</p><p>For many models, each of these step will be simpler than updating both q(z) and θ at the same time (in Section 2.4.3 however, we will see that for variational auto-encoders it is easy to perform joint maximization). As in the E-step we are holding the parameters of the model fixed, this step is basically solving a posterior inference problem as the one introduced in Section 2.2.1, therefore the optimal distribution is q k+1 (z) = p θ k (z|x). For models in which the posterior p θ k (z|x) in the E-step is intractable, we can do a partial optimization of q(z), i.e. approximate inference. In the M-step we then fix the distribution over the latent variables and we maximize the ELBO with respect to the parameters θ of the model, using for example gradient ascent methods.</p><p>Interestingly, for simpler classes of models for which inference is exact, we are guaranteed not to decrease the marginal likelihood after each combined EM step, i.e. L i (θ k+1 ) ≥ L i (θ k ). After the E-step, that does not change the value of</p><formula xml:id="formula_7">L i (θ k ) as θ k is held fixed, we have L i (θ k ) = F i (θ k , q).</formula><p>The subsequent maximization of F i (θ, q k+1 ) in the M-step will therefore not decrease L i (θ k+1 ), that is lower bounded by F i (θ, q k+1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Variational auto-encoders</head><p>Variational auto-encoders (VAEs) <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> use deep neural networks to parameterize the probability distributions that define a latent variable model, while providing an efficient approximate inference procedure that scales to large dataset with millions of data point. VAEs have recently had a huge impact in several communities. In the deep learning community, VAEs are mostly being used as generative models of high-dimensional data, e.g. to generate artificial images that resemble real ones <ref type="bibr" target="#b58">(Gulrajani et al., 2016;</ref><ref type="bibr" target="#b17">Chen et al., 2017)</ref>.</p><p>The focus in the probabilistic modelling community, on the other hand, is that of extending to many different probabilistic models ideas first introduced with VAEs, i.e. using deep neural networks to define flexible probability distributions while retaining scalable inference <ref type="bibr" target="#b65">(Johnson et al., 2016;</ref><ref type="bibr" target="#b39">Fraccaro et al., 2016c;</ref><ref type="bibr" target="#b77">Krishnan et al., 2017)</ref>. This thesis fits in the latter category, as these ideas are used to define expressive models to be used with high-dimensional sequential data. To define a VAE, we need to describe its generative model (i.e. the latent variable model), the inference network (i.e. the variational approximation), and how to learn the parameters of the VAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Generative model</head><p>The generative model of a VAE is given by the joint probability distribution p θ (x, z) = p θ (x|z)p θ (z) already introduced in (2.4). z is a continuous latent variable with L dimensions, whose prior is typically an isotropic multivariate Gaussian with zero mean and an identity covariance matrix, i.e. p θ (z) = N (z; 0, I). The likelihood p θ (x|z), also known as decoder, is typically a Gaussian distribution (for continuous data) or a Bernoulli distribution (for binary data) whose parameters are computed by passing the latent state z through a deep neural network. In the continuous case, we can have for example p θ (x|z) = N (x; µ, v) where the mean µ and the diagonal v of the diagonal covariance matrix are parameterized by two deep neural networks (NN) that output vectors in R D , with D being the dimensionality of the observation x:</p><formula xml:id="formula_8">µ = NN 1 (z) , log v = NN 2 (z) .</formula><p>(2.10)</p><p>In this case, the parameters θ of the model are the weights and biases of these neural networks.</p><p>The graphical model for the generative model of a VAE is shown in Figure <ref type="figure">2</ref>.1. Notice that while we have here described a model with a single latent variable, VAEs can also be extended to be formed by multiple layers of stochastic units <ref type="bibr" target="#b122">(Rezende et al., 2014;</ref><ref type="bibr" target="#b137">Sønderby et al., 2016b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Inference network</head><p>Due to the non-linearities in the deep neural networks that parameterize p θ (x|z), in a VAE the exact computation of the data log-likelihood p θ (x) is intractable. To perform Maximum Likelihood learning of the parameters θ of the VAE, we can however use the ELBO introduced in Section 2.3. How can we choose a variational approximation q(z) that performs well while ensuring the scalability of the model to large data sets?</p><p>In traditional variational inference <ref type="bibr" target="#b66">(Jordan et al., 1999)</ref>, the variational approximation is restricted to be in a parametric family of distributions, and for each data point {x i } N i=1 we learn a different set of parameters φ i . To make this explicit in the notation, we can write the variational approximation for data point i as q φ i (z i ). For Gaussian variational approximations with diagonal covariance matrix, φ i would contain for example two L-dimensional vectors, one for the mean and one for the diagonal of the covariance matrix. The parameters θ of the model and the parameters {φ i } N i=1 of the variational approximations for all data points are then learned maximizing the ELBO in (2.7). After training, if a new data point arrives, to find its variational parameters we need to optimize the ELBO again with respect to them. This linear scaling of the parameters of the variational approximation with the number of data points can however be a problem in large data sets that may contain millions of elements and for which the variational approximation cannot be computed analytically. To deal with this issue, in a VAE we perform amortised inference <ref type="bibr" target="#b46">(Gershman and Goodman, 2014)</ref>. Instead of having a different set of parameters φ i to learn for each data point, the variational parameters φ are now shared across all data points (we have therefore dropped the i subscript in the notation). In a VAE in particular, we use deep neural networks that take the data point x i as input, and output the mean and diagonal covariance matrix of the corresponding Gaussian variational approximation, i.e. q φ (z</p><formula xml:id="formula_9">i |x i ) = N (z i ; µ i q , v i q ) with µ i q = NN 3 (x i ) , log v i q = NN 4 (x i ) .</formula><p>(2.11)</p><p>We therefore learn an inference network, also known as encoder, that allows us to compute the parameters of the posterior approximation given the data point. The shared variational parameters φ are now the weights and biases of the neural networks in (2.11), and the cost of learning them is amortised across all data points. Thanks to the inference network, when a previously unseen data point arrives we can immediately compute its variational approximation without the need to run an expensive optimization of the ELBO, as needed in traditional variational inference. However, the posterior approximation found with amortised inference will always be worse than the one found with the traditional approach, as the parameters of the inference network are shared across all data points. An in depth study on the impact of using inference networks in VAEs can be found in <ref type="bibr" target="#b22">(Cremer et al., 2018)</ref>, that empirically shows that the main causes of inference sub-optimality in VAEs are the approximations introduced by using amortized inference, rather than the ones introduced by restricting the family of distributions the variational approximation belongs to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Parameter learning</head><p>In a VAE, the structure of the generative model and inference network introduced above allows fast and scalable training. As we have seen in Section 2.3, to perform Maximum Likelihood learning of the parameters θ of the model in the presence of latent variables, we can use the the ELBO F i (θ, q) introduced in (2.7). The variational approximation q φ (z|x) is however chosen to be in a parametric family, therefore the maximization over q in (2.7) is actually a maximization over the parameters φ (we therefore use below the notation F i (θ, φ)). We can decompose the ELBO in two terms:</p><formula xml:id="formula_10">F i (θ, φ) = E q φ (z|x) log p θ (x, z) q φ (z|x) = E q φ (z|x) [log p θ (x|z)] Reconstruction term -KL [q φ (z|x)|| log p θ (z)] Regularization term .</formula><p>(2.12)</p><p>The reconstruction term encourages the likelihood p θ (x|z) and the inference network to be able to reconstruct the data accurately, maximizing therefore the auto-encoding capabilities of the VAE. <ref type="foot" target="#foot_3">2</ref> The second term penalizes posterior approximations that are too far from the prior, and acts therefore as a regularization term. As both generative and inference models are defined with neural networks, we can efficiently compute gradients of the ELBO with respect to θ and φ using the back-propagation algorithm <ref type="bibr" target="#b125">(Rumelhart et al., 1986)</ref>. Importantly, both set of parameters can be updated jointly in a single optimization step, instead of iteratively optimizing one set of parameters while keeping the other fixed as in the EM algorithm presented in Section 2.3.1. The expectation in (2.12) does not have a closed form solution, but we can obtain a low-variance differentiable unbiased estimator of the lower bound by using the reparametrization trick <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> to be able to back-propagate through the latent variable z, and Monte Carlo integration to approximate the intractable expectation. As both q φ (z|x) and p θ (z) are Gaussians, the KL term can be computed analytically <ref type="bibr">(Kingma and Welling, 2014)</ref>.</p><p>In Figure <ref type="figure">2</ref>.2 (left) we visualize the 2-dimensional latent space of a small VAE trained on the first four digits (0, 1, 2 and 3) of the MNIST data set <ref type="bibr" target="#b82">(LeCun and Cortes, 2010)</ref>. The dataset</p><formula xml:id="formula_11">-4 -2 0 2 4 z 0 -3 -2 -1 0 1 2 3 z 1 Latent space 0 1 2 3</formula><p>Samples from a grid in z-space used during training is unlabelled, i.e. it only consists of image data and does not contain any class information. Despite the model is trained in a fully unsupervised manner, the VAE learns a latent space that captures the natural clustering of the data, as by doing so it is easier to model the data distribution (a higher ELBO is achieved). Not surprisingly, this feature has led several authors to develop extensions of VAEs to the semi-supervised setting, for example to learn a classifier given only a few labelled data points <ref type="bibr">(Kingma et al., 2014;</ref><ref type="bibr" target="#b95">Maaløe et al., 2016;</ref><ref type="bibr" target="#b94">Maaløe et al., 2017)</ref>. Figure <ref type="figure">2</ref>.2 also shows samples generated from a grid of points in the 2-dimensional latent space, that allow us to visualize the different latent representations each of the dimensions of z has learned to model the data. Looking at the last row of digits for example, it seems that the horizontal axis is responsible for modelling rotations in the digits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Improving variational auto-encoders</head><p>VAEs are very flexible deep latent variable models, that can potentially model a wide range of very complex data distributions. However, this modelling power is limited by some of the assumptions and approximations that are necessary to be able to define a scalable architecture.</p><p>As we have seen in Section, 2.3, instead of maximizing the intractable data log-likelihood log p θ (x) we are maximizing the ELBO, relying on the fact that as the data log-likelihood is lower-bounded by the ELBO, an high ELBO implies a high value for log p θ (x). However, we have no guarantees on how tight the bound is, or whether the parameters that maximize the ELBO are also a maximum of the data log-likelihood. For the bound to be tight, the variational approximation needs to be as close as possible to the true posterior distribution, but for practical and computational reasons we are often forced to use a simple Gaussian approximation that cannot properly fit the complex multimodal posterior distributions of deep latent variable models. Other challenges come from the fact that we are doing MLE and posterior inference jointly: as we are maximizing over both the parameters θ of the generative model and φ of the inference network, it is possible to learn a suboptimal generative model whose parameters depend on the choice of the posterior approximation (instead of being independent from it as if we could maximize over log p θ (x) in an exact way). θ defines in fact the shape of the true posterior distribution (2.3), and the optimal θ that maximizes the ELBO will be one such that the true posterior p θ (z|x) can be better approximated by the parametric family chosen for the variational distribution q φ (z|x). In this way we avoid the heavy penalizations in the ELBO for posterior samples that do not explain the observations well enough.</p><p>We will now review different extensions to the basic model presented in Section 2.4, that were proposed in the literature to solve some of these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Tightening the ELBO</head><p>We can use importance sampling to define a new lower bound for log p θ (x) that is tighter than the ELBO. The resulting model is called importance weighted auto-encoder (IWAE) <ref type="bibr" target="#b15">(Burda et al., 2015)</ref>. To define this new objective function, we sample K latent variables {z (k) } K k=1 independently from the same inference network q φ (z|x) used in Section 2.4.2, and we compute the K sample importance-weighted estimate of the log-likelihood</p><formula xml:id="formula_12">F K i (θ, φ) = E z (1) ,...,z (K) ∼q φ (z|x) log 1 K K k=1 p θ (x, z (k) ) q φ (z (k) |x) .</formula><p>(2.13) Importantly, for K = 1 the bound in (2.13) reduces to the ELBO introduced in (2.12), and using more samples can only improve the tightness of the bound, i.e. for all K we have</p><formula xml:id="formula_13">log p θ (x) ≥ F K+1 i (θ, φ) ≥ F K i (θ, φ) .</formula><p>Using more computational power we can therefore to improve the modelling performances. The use of multiple posterior samples in the computation of the bound allows us to learn generative model with a complex posterior distribution p θ (z|x) that would not be approximated well by a single sample from the simple variational approximation of a VAE.</p><p>The work from <ref type="bibr" target="#b87">Li and Turner, (2016)</ref> has extended traditional variational inference by defining objective functions based on the Rényi's α-divergence, a broad family of divergences that extends both the objectives in (2.12) and in (2.13), and that allows to define lower and upper bounds to the data log-likelihood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Defining flexible posterior approximations</head><p>Ideally, we would like to have a very flexible inference network that can approximate very complex posterior distributions. However, to make inference and parameter learning scalable, we often restrict the variational approximation to a simple parametric distribution, e.g. a factorized Gaussian. Can we build more flexible inference networks without increasing too much the computational costs? As we will see below, there are different ways to achieve this.</p><p>Normalizing flows. We can form a complex probability density q R (z R ) by starting from a simple density q 0 (z 0 ) and constructing a chain of R invertible parametric transformations f r , known as normalizing flows, that expand and contract the initial density:</p><formula xml:id="formula_14">z R = f R (f R-1 (. . . f 1 (z 0 ))).</formula><p>The resulting probability density over the variable z R can be computed by repeatedly applying the rule for change of variables, giving</p><formula xml:id="formula_15">log q R (z R ) = log q 0 (z 0 ) - R r=1 log det ∂f r ∂z r-1 .</formula><p>In a VAE in particular, we can use this density to parameterize the approximate posterior distribution, i.e. defining q φ (z|x) q R (z R ), choosing as initial density q 0 (z 0 ) the same inference network introduced in Section 2.4.2 <ref type="bibr" target="#b123">(Rezende and Mohamed, 2015)</ref>. We can use amortized inference to learn the parameters of the flow, by making them dependent on the data point x through a deep neural network. The scalability of this approach can be ensured by choosing relatively simple transformations that have an efficient mechanism for computing the determinant of the Jacobian ∂fr z r-1 , as needed when evaluating q R (z R ) in the ELBO. Some possible choices are planar and radial flows <ref type="bibr" target="#b123">(Rezende and Mohamed, 2015)</ref>, inverse auto-regressive flows <ref type="bibr" target="#b74">(Kingma et al., 2016)</ref>, Hamiltonian flows <ref type="bibr" target="#b126">(Salimans et al., 2015)</ref> and masked auto-regressive flows <ref type="bibr" target="#b111">(Papamakarios et al., 2017)</ref>.</p><p>Auxiliary variables. An alternative way to increase the flexibility of the variational approximation is by introducing an auxiliary latent variable a that parameterizes the joint variational approximation in the extended space as q φ (z, a|x) = q φ (z|a, x)q φ (a|x), while keeping the generative model unchanged <ref type="bibr" target="#b1">(Agakov and Barber, 2004;</ref><ref type="bibr" target="#b120">Ranganath et al., 2015;</ref><ref type="bibr" target="#b95">Maaløe et al., 2016)</ref>. Both distributions on the right hand side of the previous equation are parameterized by deep networks. The variational approximation over z only is then obtained by integrating out the auxiliary variables, q φ (z|x) = q φ (z|a, x)q φ (a|x)da .</p><p>This integral is however intractable, therefore we cannot evaluate the ELBO in (2.12). As shown in <ref type="bibr" target="#b120">(Ranganath et al., 2015;</ref><ref type="bibr" target="#b95">Maaløe et al., 2016)</ref>, this can be solved by maximizing a tractable lower bound to the ELBO instead of the ELBO itself.</p><p>Variational Boosting. This method can be used to iteratively refine the variational approximation by incorporating additional covariance structure and by introducing new components to form a mixture <ref type="bibr" target="#b101">(Miller et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Summary and discussion</head><p>In this chapter we have seen that LVMs can be used to model complex high-dimensional data distributions (Section 2.1). DLVMs use deep neural networks to parameterize the probability distributions that define a LVM. While this allows to define very flexible models, it makes exact inference and parameter learning intractable. We have then shown in Sections 2.2 and 2.3 how they can be approximated with variational methods. In Section 2.4 we have introduced the VAE as a basic example of DLVM, and showed different ways to improve its performances in Section 2.5.</p><p>So far we have used LVMs to model static data, i.e. data with no temporal dependencies such as the images of handwritten digits used in the VAE example in Section 2.4.3. If we think about the images that form the frames of a video however, we know that there will be some temporal correlations among them, i.e. we are dealing with dynamic data. In this case, we are interested in modelling a sequence of observations (the whole video) instead of a single observation (one frame). Consider a data set of N sequences of high-dimensional observations x i 1:T = [x i 1 , . . . , x i T ], i = 1, . . . , N , from which we want to learn a model for the joint probability distribution over a sequence p θ (x 1:T ). For simplicity in the exposition, we make the assumption that the number of time steps T of all sequences is fixed, but the generalization of the ideas presented below to sequences with variable length T i is straightforward. We could in principle treat the dynamic data as static by assuming the factorization p θ (x 1:T ) = T t=1 p(x t ), and fit a LVM (e.g. a VAE) to the data set of N T data points treated as if they were independent. While this can be a good model for a single observation, it does not capture the temporal nature of the data. To do it, we need to introduce some dependencies in the latent states z i 1:T corresponding to all observations of a sequence, instead of considering p θ (z 1:T ) = T t=1 p(z t ) as implicitly done when treating the data used to train the LVM as static. In other words, we want to introduce some temporal structure in the prior p θ (z 1:T ) over the latent variables of a sequence. In the next chapter we will assume that the latent variables form a chain, so that at each time step t, the variable z t directly depends on z t-1 . Latent variable models for sequential data that add this direct dependency among latent variables have been studied -although in different contexts -for more than half a century, since the seminal paper by <ref type="bibr" target="#b68">(Kalman, 1960)</ref>. This class of models is commonly referred to as state-space models (where the term "state" is used to denote what we called in this chapter "latent variables") and will be the focus of the next chapter.</p><p>Chapter 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State-space models</head><p>State-space models (SSM) provide a general and flexible methodology for sequential data modelling. They were first introduced in the 1960s, with the seminal work of <ref type="bibr" target="#b68">Kalman, (1960)</ref>, and were soon used in the Apollo Project to estimate the trajectory of the spaceships that were bringing men to the moon <ref type="bibr" target="#b98">(Mcgee and Schmidt, 1985)</ref>. Since then, they have become a standard tool for time series analysis in many areas well beyond aerospace engineering. In the machine learning community in particular, they are used as generative models for sequential data, for predictive modelling, state inference and representation learning. An excellent treatment of state-space modelling for time series analysis can be found in the in book by <ref type="bibr" target="#b31">Durbin and Koopman, (2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Definitions</head><p>We are given a sequence of T observation x 1:T = [x 1 , . . . , x T ], that possibly depend on some inputs u 1:T = [u 1 , . . . , u T ], and we are interested in modelling the distribution p θ (x 1:T |u 1:T ). This is a very general formulation, that can be applied in a wide variety of applications. We may want to model for example how the movements of the steering wheel and of the brake/throttle pedals (the inputs/controls to the model) change the position of a car (the observations/outputs). Using u t = x t-1 it is also possible to define autoregressive models, as typically used in the deep learning community when building generative models for text, videos or speech.</p><p>In a SSM we introduce at each time step a state variable z t that summarizes all the information coming from the past and determines the present and future evolution of the system. SSMs can then be seen as a temporal extension to the latent variable model introduced in Section 2.1, in which the prior over the latent variables z t at each time step varies over time as it depends on the previous state z t-1 and possibly some inputs u t to the model. We assume that the joint distributions of observations and states given the inputs factorizes as</p><formula xml:id="formula_16">z t-1 z t z t+1 x t-1 x t x t+1 u t-1 u t u t+1</formula><formula xml:id="formula_17">p θ (x 1:T , z 1:T |u 1:T ) = p θ (x 1:T |z 1:T )p θ (z 1:T |u 1:T ) = T t=1 p θ (x t |z t ) • p θ (z 1 ) T t=2 p θ (z t |z t-1 , u t ) (3.1)</formula><p>A graphical representation of the distribution in (3.1) can be found in Figure <ref type="figure">3</ref>.1. The emission distribution p θ (x t |z t ) specifies how the observation x t depends on the latent state z t , and can therefore be seen as the likelihood in a LVM. p θ (z t |z t-1 , u t ) is called transition distribution, and represents the prior distribution for the state at each time step given the previous state and the current input to the model. This distribution fully determines the temporal evolution of the system. The states of the SSM form a Markov chain, that captures the temporal correlations and long-term dependencies between observations at different time steps. Using the d-separation properties <ref type="bibr" target="#b44">(Geiger et al., 1990</ref>) of the graphical model in Figure <ref type="figure">3</ref>.1, we can see that this Markovian structure leads to some interesting conditional independence properties that are implicitly assumed in a SSM:</p><formula xml:id="formula_18">p θ (x t |z 1:t , x 1:t-1 , u 1:t ) = p θ (x t |z t )</formula><p>This property implies that given the present state z t the observation at time t does not depend on the past states, inputs and outputs of the model. As in a LVM, the observation x t is then fully determined by the latent state z t .</p><formula xml:id="formula_19">p θ (z t |z 1:t-1 , x 1:t-1 , u 1:t ) = p θ (z t |z t-1 , u t )</formula><p>Conditioned on z t-1 , the current state z t does not depend on the previous states z 1:t-2 , nor the past inputs or outputs. z t-1 then captures all the relevant information on the past.</p><formula xml:id="formula_20">p θ (z t |z t+1:T , x t+1:T , u t+1:T ) = p θ (z t |z t+1 )</formula><p>Given the next state z t+1 , z t does not depend on the future states, inputs and outputs, i.e. z t+1 captures all the relevant information on the future.</p><p>As we will see in the following, these conditional independence relationships are responsible for many of the nice properties of SSMs.</p><p>Similarly to the LVM in Section 2.1, the marginal distribution over the observations can be obtained by integrating out the states in (3.1), i.e.</p><formula xml:id="formula_21">p θ (x 1:T |u 1:T ) = p θ (x 1:T , z 1:T |u 1:T )dz 1:T . (3.2)</formula><p>Here we have assumed that z 1:T are continuous variables, but the same ideas apply to the discrete case by replacing the integral with a summation. Using Bayes' rule we obtain the posterior distribution of the states given the data:</p><formula xml:id="formula_22">p θ (z 1:T |x 1:T , u 1:T ) = p θ (x 1:T |z 1:T )p θ (z 1:T |u 1:T ) p θ (x 1:T |u 1:T ) . (3.3)</formula><p>Exact posterior inference is analytically tractable for two classes of SSMs, namely Linear Gaussian SSMs and Hidden Markov Models. In all other cases, we will need to resort to approximate inference, as discussed more in detail in Section 3.5.1.</p><p>In some cases we know the exact form of the emission and transition distributions, and we are only interested in inferring the latent states for a given sequence, as shown in the ball tracking example that will be presented in Section 3.4. SSMs can however be also used as black-box methods for sequential data modelling, in which case the emission and transition distribution will have a flexible structure that can be learned from the data, see <ref type="bibr">(Fraccaro et al., 2016c, Chapter 5)</ref> for an example of this approach. Finally, in other cases we can use prior information on the task at hand to define a specific parametric form for the emission and transition distribution that helps the model to learn meaningful and interpretable latent representations. This approach lies halfway between having a known or a black-box model, and will be used in <ref type="bibr">(Fraccaro et al., 2017, Chapter 6</ref>) and in <ref type="bibr">(Fraccaro et al., 2018, Chapter 7)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classes of state-space models</head><p>Depending on the exact form of the emission and transition distributions we can define several classes of state-space models, that will be briefly presented in the following.</p><p>Linear Gaussian state-space models. The simplest class of SSMs is that of Linear Gaussian state-space models (LGSSM), first introduced in <ref type="bibr" target="#b68">(Kalman, 1960)</ref>. We will present them in detail in Section 3.4. As suggested by the name, both transition and emission distributions are Gaussians, and all relationships between states and observations are linear. This makes posterior inference for this model analytically tractable. Despite its simplicity, the LGSSM can be seen as a generalization of many classical models used in time series analysis. As shown in <ref type="bibr" target="#b31">(Durbin and Koopman, 2012)</ref>, the widely used autoregressive integrated moving average (ARIMA) model can be expressed in state-space form.</p><p>LGSSM can also model in a unified framework trends, seasonal components, explanatory variables and interventions.</p><p>Hidden Markov models. A Hidden Markov model (HMM) is a SSM with discrete latent states <ref type="bibr" target="#b116">(Rabiner, 1990)</ref>. As for the LGSSM, for a HMM we can perform exact posterior inference. Notice that HMMs were developed in parallel to LGSSM, therefore some authors prefer to reserve the term "state-space models" for models with continuous states, and use the term "hidden Markov models" when dealing with discrete states. Here however we prefer to consider HMMs as SSMs, as they satisfy all the assumptions we made in Section 3.1 (e.g. the factorization of the joint distribution in (3.1)).</p><p>Non-Linear non-Gaussian state-space models. The linear-Gaussian assumptions of a</p><p>LGSSM are often too restrictive for many applications. If we relax them however we introduce an additional challenge, since inference becomes intractable and we need to resort to approximate methods. See Section 3.5 for details. As we will see in Section 4.3, a flexible class of non-linear state space models is given by deep state-space models (DSSM). In a DSSM, the transition and emission distributions are parameterized with deep neural networks, and efficient training can be achieved with amortized variational inference, computing the required gradients with the back-propagation algorithm. For small data sets it is also common to model the transitions and emissions with Gaussian processes, see <ref type="bibr" target="#b99">(McHutchon, 2014)</ref> for an overview on the topic.</p><p>Hybrid architectures. Different authors have combined in a single architecture different classes of SSMs. <ref type="bibr" target="#b104">Murphy, (1998)</ref> and <ref type="bibr" target="#b48">Ghahramani and Hinton, (2000)</ref> introduce for example Switching Kalman filters, that use the discrete states of a HMM to select different possible regimes for the continuous variables of a LGSSM.</p><p>SSMs in continuous time. In Section 3.1 we have tacitly assumed that the data is observed at equally-spaced discrete time steps. SSMs can however be used also to model continuous time systems, in which the state is used to represent the dynamics of higher-order linear systems as a first order differential equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Posterior inference in the sequential setting</head><p>In (3.3) we have expressed the posterior distribution of the latent states given the whole sequence. However, if we take into account the temporal structure of the data, there are also other types of inference we can be interested in.</p><p>To illustrate this, consider the simplified speech recognition example of trying to understand what a friend is saying in a very noisy bar. The observation x t represents the noisy speech waveform at each time step, while z t is the discrete variable that represents the corresponding word pronounced by the friend.<ref type="foot" target="#foot_4">foot_4</ref> In this example there are no inputs u t to the model, and we will therefore remove them from the equations. At any point in time, we want of course to infer the word that the friend is saying, i.e. compute the posterior distribution p θ (z t |x t ). As the bar is noisy however, we may not be sure of which word was pronounced. At time t we also know what the friend said in x 1:t-1 , and we can therefore condition even on the past observations, i.e. compute p θ (z t |x 1:t ) instead. The knowledge about what the friend was talking about at previous time steps can provide some context and help us better infer z t . We call this task filtering, as it reduces the noise compared to only using the present observation x t during inference. Despite this, due to the noise in the bar we may still be unsure on the inferred word. In this case we can hope that while we keep listening to the friend, there will be one clue that will clarify the inferred state z t . In this case we are therefore also using knowledge on the future during inference, i.e. we are considering the smoothed posterior p θ (z t |x 1:T ). Finally, we may also want to predict what the friend will say in the future given what was said until now, i.e. compute p θ (z t+k |x 1:t ).</p><p>We now provide a more general description of these inference tasks:</p><p>Filtering. We want to compute the filtered posterior distribution of the state z t given present and past input and output information, i.e. p θ (z t |x 1:t , u 1:t ). This task is particularly interesting in an online setting, as it allows to compute the state estimate as the data comes in.</p><p>Smoothing. When doing smoothing, we compute the posterior p θ (z t |x 1:T , u 1:T ), conditioned not only on the past and present information, but also on future one. Since the smoothed posterior requires the knowledge of the whole sequence, it can be computed only offline.</p><p>A trade-off between filtering and smoothing is fixed-lag smoothing, where we compute the smoothed posterior only conditioning on data up to k time steps in the future (and not on the whole sequence), i.e. we compute p θ (z t |x 1:t+k , u 1:t+k ). Fixed-lag smoothing can be used to further improve state estimation in an online setting, whenever a delay of k time steps in admissible.</p><p>Prediction. We can also be interested in predicting the state of the system k steps in the future given only past information, i.e. computing p θ (z t+k |x 1:t , u 1:t+k ) (notice that if the inputs u t are present, they need to be known up to time t + k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Linear Gaussian state-space models</head><p>We now discuss in detail the linear Gaussian state-space model <ref type="bibr" target="#b68">(Kalman, 1960)</ref>, that was briefly introduced in Section 3.2. This model is also known as Linear Dynamical System, or more informally as Kalman Filter. A LGSSM is typically written in terms of two equations, that specify the relationship between the latent states at consecutive time steps and the observations:</p><formula xml:id="formula_23">z t = A t z t-1 + B t u t + ε t (3.4) x t = C t z t + δ t (3.5)</formula><p>The transition model (3.4) describes how to compute the state z t at each time step given the previous state z t-1 and the current input u t . A t and B t are the transition and control matrices respectively, and define a linear relationship between the variables. The transitions are perturbed with a Gaussian process/transition noise ε t ∼ N (ε t ; 0, Q t ), where Q t is called transition covariance. In a LGSSM we do not observe the state, but only a linearly transformed version of it with additive Gaussian noise, as specified by the emission model (3.5). The emission model can be seen as a linear regression model with time-varying inputs z t . In (3.5) C t is called emission matrix, and the measurement/observation noise δ t is a Gaussian random variable, i.e. δ t ∼ N (δ t ; 0, R t ) with R t being the observation covariance. Both transition noise and observation noise are assumed to be independent across time steps. The matrices that define the LGSSM can be time-varying (as indicated by the subscript t) and even depend on the past information. However, for simplicity often the matrices are kept fixed over time, in which case the model is defined as stationary (we will see an example of this at the end of this section).</p><p>The transition and emission distributions of a LGSSM can be easily obtained from (3.4) and (3.5) using the linear transformation properties of Gaussian random variables: where we have defined</p><formula xml:id="formula_24">p θt (z t |z t-1 , u t ) = N (z t ; A t z t-1 + B t u t , Q t ) (3.6) p θt (x t |z t ) = N (x t ; C t z t , R t ) , (<label>3</label></formula><formula xml:id="formula_25">θ t = [A t , B t , C t , Q t , R t ].</formula><p>We assume that the state at the first time step is a Gaussian random variable, i.e. p(z 1 ) = N (z 1 ; µ 1|0 , Σ 1|0 ). The joint distribution in (3.1) then becomes:</p><formula xml:id="formula_26">p θ (x 1:T , z 1:T |u 1:T ) = p θ (x 1:T |z 1:T )p θ (z 1:T |u 1:T ) = T t=1 p θt (x t |z t ) • p(z 1 ) T t=2 p θt (z t |z t-1 , u t ) (3.8) where θ = [µ 1|0 , Σ 1|0 , θ 1 , .., θ T ].</formula><p>One of the major reasons for the widespread usage of LGSSMs is that posterior inference can be done in an exact way, as we will discuss in Section 3.4.1. In Sections 3.4.2 and 3.4.3 we will then see that the LGSSM provides simple methods to perform missing data imputation and parameter learning. These properties will be exploited in the model of <ref type="bibr">Fraccaro et al., (2017, Chapter 6)</ref>. Throughout this section we will use a simple example, introduced below, to showcase the capabilities of LGSSMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ball tracking example.</head><p>LGSSMs are widely used for real-time object tracking, e.g. to estimate the position of satellites or in GPS systems. To see why LGSSM are suitable for such applications, we can look at a simplified example of tracking a ball thrown in vacuum from noisy measurements of its position. The ball is subject to gravity, and we can measure with a noisy sensor its (x, y) position but not its velocity or acceleration. We assume that the data is sampled every ∆ = 0.2 seconds. Figure <ref type="figure">3</ref>.2 shows the true trajectory of the ball in the (x, y) plane (dashed blue line) and the noisy measurements (black dots). As expected, due to the force of gravity acting on the ball, the trajectory forms a parabola.</p><p>To define the parameters of a suitable LGSSM we can exploit our knowledge of the physics of the moving ball. The discretized system dynamics can be modelled using Newton's equations of motion as follows</p><formula xml:id="formula_27">           x t = x t-1 + ẋt-1 ∆ ẋt = ẋt-1 y t = y t-1 + ẏt-1 ∆ -1 2 g∆ 2 ẏt = ẏt-1 -g∆ (3.9)</formula><p>where ẋt and ẏt represent the velocities on the x (horizontal) and y (vertical) axes respectively, and g = 9.81 m s 2 is the acceleration due to gravity. From these equations we can see that the ball is following a linear motion with constant velocity on the x axis, whereas on the y axis there is an acceleration due to the force of gravity. The state of the system at each time step is given by the positions (x t , y t ) and velocities ( ẋt , ẏt ) of the ball. The true state is however unknown, since our sensor can only measure the noisy position of the ball. We then need to be able to estimate the true state from these noisy observations, task for which a stationary LGSSM is the ideal candidate.</p><p>We define the emission matrix and the state of the systems as</p><formula xml:id="formula_28">C = 1 0 0 0 0 0 1 0 , z t =     x t ẋt y t ẏt     ,</formula><p>so that the noisy observations x t can be modelled with (3.5):</p><formula xml:id="formula_29">x t = Cz t + δ t = x t y t + δ t .</formula><p>(3.10)</p><p>The emission matrix derived from (3.9) is time-independent, and we have therefore removed the subscript t that was used previously in this section. We further define the transition matrix, control matrix and control inputs as:</p><formula xml:id="formula_30">A =     1 ∆ 0 0 0 1 0 0 0 0 1 ∆ 0 0 0 1     , B =     0 0 0 0 0 0 0 0 0 0 -1 2 ∆ 2 0 0 0 0 -∆     , u t =     0 0 g g     ,</formula><p>so that the noiseless transition equation z t = Az t-1 +Bu t will return exactly the system dynamics of (3.9). Notice in particular that the gravity, an external force applied to the ball, can be modelled using a fixed control input u t at each time step. We could have otherwise added it as an extra fixed term in the state vector.</p><p>As Newton's equations of motions give us the exact dynamics of a ball moving in the vacuum, we set the transition noise covariance Q to zero. We then set R = 3I, where I is the identity matrix.</p><p>We assume that we do not know anything about the initial state z 1 , and we set its parameters to µ 1|0 = 0 and Σ 1|0 = 2I. This is a relatively concentrated Gaussian around the origin that assigns a low probability to the true initial state. This is done to show in the next sections that exact inference works well despite this and how we can learn this vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Posterior inference</head><p>For LGSSMs the filtered and smoothed posteriors at each time step can be computed analytically using the Kalman filtering and smoothing algorithms. The proofs of the algorithms rely heavily both on the Markovian structure of SSMs and on the linear-Gaussian assumptions, that imply that the joint distribution over all variables, as well as all marginals and conditionals will be Gaussians. In the following we will present the main intuitions behind this algorithms and a sketch of the proofs. A detailed derivation can be found in <ref type="bibr" target="#b105">(Murphy, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Filtering</head><p>In this section we present a filtering routine for the LGSSM known as Kalman filtering. The Kalman filtering algorithm <ref type="bibr" target="#b68">(Kalman, 1960)</ref> recursively computes the marginal posterior distribution p θ (z t |x 1:t , u 1:t ) at each time step given the one at the previous time step, p θ (z t-1 |x 1:t-1 , u 1:t-1 ).</p><p>Using Bayes' rule and the conditional independence properties of the model, we can rewrite this posterior distribution as follows:</p><formula xml:id="formula_31">p θ (z t |x 1:t , u 1:t ) = p θ (z t |x t , x 1:t-1 , u 1:t ) = p θ (x t |z t , x 1:t-1 , u 1:t )p θ (z t |x 1:t-1 , u 1:t ) p θ (x t |x 1:t-1 , u 1:t ) = p θ (x t |z t )p θ (z t |x 1:t-1 , u 1:t ) p θ (x t |x 1:t-1 , u 1:t ) . (3.11)</formula><p>The first term of the numerator is the emission distribution p θ (x t |z t ). The second one, p θ (z t |x 1:t-1 , u 1:t ), can be seen as the predictive prior for z t , i.e. our "best guess" on the distribution of the state at time t given the output information up to time t -1. At each time step, the Kalman filter first performs a prediction step that computes the predictive prior given the filtered posterior at the previous time step, followed by a measurement step in which this distribution is updated using the information coming from the current observation that is carried by the emission distribution. As typically done when working with Gaussian distributions, for the computations we can only focus on the unnormalized distribution at the numerator of (3.11), given by the product of two Gaussians.</p><p>Prediction step. We assume that p θ (z</p><formula xml:id="formula_32">t-1 |x 1:t-1 , u 1:t-1 ) = N (z t-1 ; µ t-1 , Σ t-1</formula><p>), the filtered posterior at the previous time step, is known. Given this distribution and the transition distribution of the LGSSM, the predictive prior can be computed as</p><formula xml:id="formula_33">2 p θ (z t |x 1:t-1 , u 1:t ) = p θ (z t |z t-1 , x 1:t-1 , u 1:t )p θ (z t-1 |x 1:t-1 , u 1:t )dz t-1 = p θ (z t |z t-1 , u t )p θ (z t-1 |x 1:t-1 , u 1:t-1 )dz t-1 = N (z t ; A t z t-1 + B t u t , Q t )N (z t-1 ; µ t-1 , Σ t-1 )dz t-1 = N (z t ; A t µ t-1 + B t u t µ t|t-1 , A t Σ t-1 A T t + Q t Σ t|t-1</formula><p>) ,</p><p>2 In A T t , the superscript T denotes the transpose operator; the sequence length, also denoted with T , will instead always appear as a subscript.</p><p>where we have used the conditional independence properties of the model and the well known rules on the marginalization of conditional Gaussians <ref type="bibr" target="#b11">(Bishop, 2006)</ref>. Notice in particular that to compute the mean µ t|t-1 of this distribution we can simply apply the transition equations to the mean µ t-1 of the previous filtered posterior. The predictive prior at the first time step is given by the initial distribution p(z 1 ) = N (z 1 ; µ 1|0 , Σ 1|0 ).</p><p>Measurement step. In (3.11) we have seen that</p><formula xml:id="formula_34">p θ (z t |x 1:t , u 1:t ) ∝ p θ (x t |z t )p θ (z t |x 1:t-1 , u 1:t ) ∝ N (x t ; C t z t , R t )N (z t ; µ t|t-1 , Σ t|t-1 ) .</formula><p>From this, the mean µ t and the covariance matrix Σ t of the filtered posterior at time t can be computed using the formulas for Bayes' rule for Gaussian distributions of this form and applying the matrix inversion lemmas <ref type="bibr" target="#b105">(Murphy, 2012)</ref>. This gives</p><formula xml:id="formula_35">µ t = µ t|t-1 + K t (x t -C t µ t|t-1 ) Σ t = (I -K t C t )Σ t|t-1 ,</formula><p>where we have defined the Kalman gain matrix K t as</p><formula xml:id="formula_36">K t = Σ t|t-1 C T t (C t Σ t|t-1 C T t + R t ) -1 .</formula><p>To understand the algorithm, it is instructive to look in particular at the update equations for the mean. The posterior mean µ t is obtained shifting the mean of the predictive prior by a factor proportional to the residual r t = x t -C t µ t|t-1 , that is the difference between the true observation and the predicted one. As the Kalman gain K t grows when the observation covariance R t becomes smaller, the Kalman filter will give more importance to the true observation when the emission noise is smaller. On the other hand, if the covariance of the predictive prior Σ t|t-1 is small (i.e. the model is quite sure of its estimation) K t decreases, therefore reducing the contribution of the residual.</p><p>It is important to notice that the prediction and measurement steps of the Kalman filter only depend on the filtered posterior at the previous time step and the current input u t and output x t . This implies that there is no need to reprocess the whole sequences of x 1:t-1 and u 1:t-1 at each inference step, making this iterative algorithm efficient and suitable for the online setting. The computational complexity of the Kalman filter scales cubically in the output dimensionality (due to the matrix inversion in K t ) and quadratically in the state size (due to the matrix multiplication for Σ t ), that make it not efficient for very high-dimensional problems <ref type="bibr" target="#b105">(Murphy, 2012)</ref>. To avoid issues with singular matrices, some more numerically stable versions this algorithm have been developed. Among these, we find for example the square-root filter, that works with Cholesky decompositions of covariance matrices, and the information filter, that updates the natural parameters of the Gaussians instead of the moments.</p><p>Given the output of the Kalman filter, it is also possible to compute the marginal likelihood p θ (x 1:T |u 1:T ) as</p><formula xml:id="formula_37">log p θ (x 1:T |u 1:T ) = T t=1 log p θ (x t |x 1:t-1 , u 1:t ) = T t=1 log N (x t ; C t µ t|t-1 , C t Σ t|t-1 C T t + R t ) .</formula><p>(3.12) </p><formula xml:id="formula_38">0</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Smoothing</head><p>The Kalman filter processes the whole sequence recursively forwards in time. From its output, we can easily compute also the smoothed posterior distribution with the Rauch-Tung-Striebel smoother <ref type="bibr" target="#b121">(Rauch et al., 1965)</ref>, also known as Kalman smoother. After running a forward pass with the Kalman filter, the algorithm does a backward recursion during which it combines information coming from the future observations with the quantities computed during the forward pass.</p><p>We initialize the Kalman smoother using the last step of the Kalman filter, i.e. p θ (z T |x 1:T , u 1:T ) = N (z T ; µ T , Σ T ). To compute the smoothed distribution at time t, we then process the sequence backwards in time, combining the smoothed distribution at time t + 1, denoted as p θ (z t+1 |x 1:T , u 1:T ) = N (z t+1 ; µ t+1|T , Σ t+1|T ), with the parameters obtained during prediction step and the measurement step of the Kalman filter. We then obtain p θ (z t |x 1:T , u 1:T ) = N (z t ; µ t|T , Σ t|T ), with</p><formula xml:id="formula_39">µ t|T = µ t + J t (µ t+1|T -µ t+1|t ) Σ t|T = Σ t + J t (Σ t+1|T -Σ t+1|t )J T t ,</formula><p>where</p><formula xml:id="formula_40">J t = Σ t A T t+1 Σ -1 t+1|t .</formula><p>A derivation of the algorithm, that exploits the fact that z t does not depend on x t+1:T and u t+1:T if we condition on z t+1 , can be found in <ref type="bibr" target="#b105">(Murphy, 2012)</ref>.</p><p>Ball tracking example. We run the Kalman filter and smoother on the ball tracking example presented in Section 3.4. In Figure <ref type="figure">3</ref>.3 we plot the true trajectory, together with the first and third components of the estimated state vector (i.e. the estimated x and y coordinates). We first notice that the filtered posterior distribution drastically reduces the noise in the data, especially towards the end of the sequence as it can leverage information from many data points. The smoothed posterior distribution manages to accurately estimate the trajectory and reduce the noise at all time steps, as it can use data from the whole sequence. As expected, its trajectory it is much smoother that the one estimated by the Kalman filter. Finally, notice that the filter manages to correct the choice of initial state, that was chosen on purpose to be far from the true one. This is possible as the emission noise was chosen to be relatively small, in which case at the first time step the Kalman gain will be big and give more importance to the true observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Missing data imputation</head><p>In many applications we have time series that have been observed irregularly over time. An appealing properties of LGSSM is that they allow to deal with missing data in a simple and principled way. We can in fact use the original Kalman filtering and smoothing algorithms at all time steps taking K t = 0 (or equivalently C t = 0) at the missing time points. In this case, the measurement step will only propagate the sufficient statistics computed during the prediction step, i.e. we will have</p><formula xml:id="formula_41">µ t = µ t|t-1 Σ t = Σ t|t-1 ,</formula><p>so that the filtered posterior coincides with the predictive prior. Once the filtered or smoothed posterior are computed, the missing observation can be estimated simply as C t z t , with z t being the inferred value. In a similar way, the algorithms can be extended to partially observed x t , i.e. observations x t with missing elements, by not considering in the emission matrix the rows corresponding to a missing element, see <ref type="bibr" target="#b31">(Durbin and Koopman, 2012)</ref> for details.</p><p>We finally notice that predictions with a LGSSM can be obtained by treating future observations as missing values, simply running the Kalman filtering algorithm setting K t = 0 for the future time steps that we want to predict.</p><p>Ball tracking example. We consider the same trajectory as in Figure <ref type="figure">3</ref>.3, but we now only observe the first 10 and last 8 observations, treating all the central ones as missing. In Figure <ref type="figure">3</ref>.4 we plot the estimated trajectory from the Kalman filter and smoother. We see that the filtered posterior does not provide a good estimate of the trajectory when the data is missing, as the first 10 time steps only do not provide enough reliable information (the estimate recovers only with the last 8 observations around x = 600). As opposed to the filtered posterior, the smoothed one can use the information on the last 8 observations at all time steps. The smoothed posterior is therefore very accurate, and close to the one obtained in Figure <ref type="figure">3</ref>.3 when all the data was observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Parameter learning with the EM algorithm</head><p>In some cases, some or all of the parameters of the LGSSM are unknown, and we need to learn them from data. Apart from having parameters to learn we also have latent variables to infer, which is the scenario for which in Section 2.3.1 we introduced the EM algorithm. <ref type="foot" target="#foot_6">3</ref> The EM algorithm for LGSSMs was first introduced in <ref type="bibr" target="#b133">(Shumway and Stoffer, 1982)</ref> assuming that the emission matrix was known, and then generalized in <ref type="bibr" target="#b47">(Ghahramani and Hinton, 1996)</ref> to models where all parameters were unknown. The E-step for a LGSSM can be easily done exploiting the tractability of the filtered and smoothed posteriors, and the optimization of all variables in the M-step has a simple closed form solution. In this section we will see as an example how we can learn the parameters of the prior p(z 1 ) of the initial state. Detailed derivations for all the parameters of the emission and transition distributions of the LGSSM can be found in <ref type="bibr" target="#b47">(Ghahramani and Hinton, 1996)</ref> or <ref type="bibr" target="#b11">(Bishop, 2006)</ref>. A discussion on the identifiability of the model when learning all the parameters can be found in <ref type="bibr" target="#b124">(Roweis and Ghahramani, 1999)</ref>.</p><p>The parameters µ 1|0 and Σ 1|0 of the initial state Gaussian prior can be optimized by maximizing the ELBO in (2.7). In the E-step of (2.8) we maximize the ELBO with respect to the variational approximation while keeping the parameters fixed. The optimal distribution for the LGSSM is given by the smoothed posterior marginal at the first time step, i.e. q k+1 (z 1 ) = p θ (z 1 |x 1:T , u 1:T ).</p><p>In the M-step of (2.9) we then keep the posterior distribution fixed, and maximize the ELBO with respect to the parameters of the initial state prior. In this maximization, all the terms that do not depend on µ 1|0 or Σ 1|0 can be absorbed in an additive constant, giving the ELBO:</p><formula xml:id="formula_42">F(µ 1|0 , Σ 1|0 ) = - 1 2 log det(Σ 1|0 ) -E p θ (z 1 |x 1:T ,u 1:T ) 1 2 (z 1 -µ 1|0 ) T Σ -1 1|0 (z 1 -µ 1|0 ) + constant</formula><p>where det(•) denotes the matrix determinant and the superscript T the transpose operation. By setting to 0 the partial derivatives of F(µ 1|0 , Σ 1|0 ) with respect to each of the parameters we obtain the M-step updates</p><formula xml:id="formula_43">µ new 1|0 = µ 1|T Σ new 1|0 = Σ 1|T -µ 1|T µ T 1|T .</formula><p>This new initial state can now be used to compute the smoothed posterior needed for the E-step in the following iteration of the EM algorithm, that is let to run until convergence.</p><p>As we have seen in (3.12), as a byproduct of the Kalman filtering algorithm we can compute the marginal likelihood of the model. An alternative approach to ML learning of the parameters of the LGSSM is then the direct numerical optimization of this quantity with gradient-based methods such as the L-BFGS algorithm <ref type="bibr" target="#b90">(Liu and Nocedal, 1989)</ref>. <ref type="bibr" target="#b133">Shumway and Stoffer, (1982)</ref> suggest to  use the EM algorithm for the first iterations of the learning procedure and switch to gradient-based methods after some iterations, arguing that the EM algorithm has a slow convergence when the parameters approach the local optimum but is more robust than gradient-based methods to poor parameter initializations.</p><p>In this discussion we have assumed that the parameters of the LGSSM are unknown but fixed quantities. It is however possible to consider the parameters as random variables, that results in the Bayesian LGSSM. This Bayesian approach is particularly useful when we need to include strong prior constraints in the parameters to be able to find suitable solutions. One problem that arises in this case is that state inference becomes intractable, and one needs to resort to approximate inference techniques such as the variational EM algorithms of Beal, (2003); <ref type="bibr" target="#b4">Barber and Chiappa, (2007)</ref>.</p><p>Ball tracking example. In our description of the ball tracking example in Section 3.4 we mentioned that the choice of the prior over the initial state was suboptimal. We now use the EM algorithm to learn the parameters of the initial state µ 1|0 and Σ 1|0 , running it for 20 iterations and initializing the parameters as before. In Figure <ref type="figure">3</ref>.5a, we plot the state inferred with the Kalman filter and smoother after the optimization. We see that now both the filtered and smoothed trajectories match very closely the ground truth one. In Figure <ref type="figure">3</ref>.5b we plot the change in log-likelihood of the model during the EM algorithm. As discussed in Section 2.3.1, as inference during the E-step is exact, the log-likelihood does not decrease after each EM iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Non-linear non-Gaussian state-space models</head><p>While the LGSSM provides an elegant mathematical framework for exact state inference, missing data imputation and parameter learning, its applicability is limited by the fact that in many cases the linear-Gaussian assumptions for the transitions and emissions are too strong. These assumptions are no longer valid for example if we consider small extensions to the ball tracking t=1 t=3 t=5 t=7 t=9 t=11 example discussed in Section 3.4:</p><p>• Non-linear transitions. To make the transition linear we had to assume that the ball was traveling in vacuum. In a more realistic setting however the ball moves in air, therefore we also need to take into account air resistance, which adds a non-linear relationship between the velocities at consecutive steps and would strongly modify the final trajectory. Other non-linearities could be given by obstacles in the trajectory of the ball, e.g. walls, see <ref type="bibr">(Fraccaro et al., 2017, Chapter 6)</ref> for an example.</p><p>• Non-Gaussian transition noise. In a real world scenario a precise model of the ball would take into account many physical effects such as the spin of the ball, its roughness, the altitude and the humidity of the air. As it would be very difficult to find a precise mathematical model for these we may want to treat them as noise. These effects would slightly but consistently modify the trajectory of the ball, therefore a Gaussian noise would probably be a poor choice for this (we may need for example a skewed distribution).</p><p>• Non-linear emissions. To have linear emissions, we assumed that we had a noisy sensor that could track the 2-dimensional (x, y) position of the ball. In <ref type="bibr">(Fraccaro et al., 2017, Chapter 6)</ref> we will assume that our sensor is a camera, therefore instead of observing the positions over time we observe a video of the ball flying in the vacuum. An example of a sequence of observations is given in Figure <ref type="figure">3</ref>.6. In this case our observations will be high-dimensional images, that can only be modelled accurately with non-linear emissions, e.g. parameterized with convolutional neural networks.</p><p>• Non-Gaussian emission noise. In the ball tracking example we have assumed that the emission noise is Gaussian. Inaccurate sensor however may return many outliers, that would be better modelled with a heavy-tailed distribution such as a Student-t distribution.</p><p>In all these cases suitable emission distribution p θ (x t |z t ) and transition distribution p θ (z t |z t-1 , u t ) will be non-linear and/or non-Gaussian. The main issue that arises in this case is that inference and parameter learning become intractable, and will need to be approximated as shown in Section 3.5.1.</p><p>Ball tracking example with air resistance. We now illustrate how the trajectory of the ball changes if we assume that it travels in air instead of vacuum <ref type="bibr" target="#b79">(Labbe, 2015)</ref>. To model the physics of this system, the velocities in the equations of motions in (3.9) need to be modified by  subtracting two extra non-linear components that take into account the air resistance:</p><formula xml:id="formula_44">               x t = x t-1 + ẋt-1 ∆ ẋt = ẋt-1 -0.0039 + 0.0058 1+e ( √ ẋ2 t-1 + ẏ2 t-1 -35 ) /5 ẋt-1 ∆ y t = y t-1 + ẏt-1 ∆ -1 2 g∆ 2 ẏt = ẏt-1 -g∆ -0.0039 + 0.0058 1+e ( √ ẋ2 t-1 + ẏ2 t-1 -35 ) /5 ẏt-1 ∆ .</formula><p>(3.13)</p><p>A detailed derivation of these equations is out of the scope of this thesis, for which we are only interested in their non-linear nature.</p><p>In Figure <ref type="figure">3</ref>.7a we see that even if we use the same initial conditions the trajectory is no longer a parabola, since the air resistance slows down the ball in a non-linear way. In Figure <ref type="figure">3</ref>.7b we apply the same LGSSM introduced in Section 3.4 to this new data. As expected, the linear transitions of the LGSSM cannot properly model the non-linear effect of the air resistance, resulting in a poor state estimation. We will see in the next section that this issue can be corrected using non-linear models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Approximate inference and learning</head><p>We now provide a brief overview of the main algorithms developed over the years for approximate inference and learning in non-linear non-Gaussian SSMs. A more in depth treatment of both deterministic and stochastic approximation techniques can be found in <ref type="bibr" target="#b3">(Barber et al., 2011)</ref> and <ref type="bibr" target="#b129">(Särkkä, 2013)</ref>. In Section 4.3.1 we will then discuss variational methods for non-linear SSMs parameterized by deep neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.1">Extended Kalman Filter</head><p>We now consider non-linear models with Gaussian noise, in which the transition and emission equations are described by two non-linear differentiable functions, denoted as f and g respectively:</p><formula xml:id="formula_45">z t = f (z t-1 , u t ) + ε t x t = g(z t ) + δ t with ε t ∼ N (ε t ; 0, Q t ) and δ t ∼ N (δ t ; 0, R t ).</formula><p>The Extended Kalman Filter (EKF) <ref type="bibr" target="#b134">(Smith et al., 1962</ref>) is a deterministic approximation technique that can be used to compute a Gaussian approximation to the posterior distribution for this class of models. It works by linearizing both functions around the estimated posterior mean using a Taylor series expansion, and applying the standard Kalman filtering and smoothing algorithms in this new linearized space.</p><p>We linearize the transition equation around the previous state estimate µ t-1 :</p><formula xml:id="formula_46">f (z t-1 , u t ) = f (µ t-1 + (z t-1 -µ t-1 ), u t ) ≈ f (µ t-1 , u t ) + F t (z t-1 -µ t-1 )</formula><p>where F t is the Jacobian matrix of f evaluated at µ t-1 .</p><formula xml:id="formula_47">F t = ∂ ∂z t-1 f (z t-1 , u t ) z t-1 =µ t-1 ,ut</formula><p>In a similar way, we linearize the emission equation around the predictive prior mean µ t|t-1 :</p><formula xml:id="formula_48">g(z t ) = g(µ t|t-1 + (z t -µ t|t-1 )) ≈ g(µ t|t-1 ) + G t (z t -µ t|t-1 ) G t = ∂ ∂z t g(z t ) zt=µ t|t-1</formula><p>.</p><p>The resulting transition and emission distributions are now linear with respect to z t-1 and z t , i.e.</p><formula xml:id="formula_49">p θt (z t |z t-1 , u t ) = N (z t ; f (µ t-1 , u t ) + F t (z t-1 -µ t-1 ), Q t ) p θt (x t |z t ) = N (x t ; g(µ t|t-1 ) + G t (z t -µ t|t-1 ), R t ) ,</formula><p>and we can then apply the standard Kalman filter and smoothing algorithms. The computational complexity of the EKF is therefore similar to the one of the Kalman filter, apart from the computations needed for the non-linear functions f and g and their Jacobians. Notice that the EKF algorithm reduces to the standard Kalman filter if we use f</p><formula xml:id="formula_50">(z t-1 , u t ) = A t z t-1 + B t u t and g(z t ) = C t z t , i.e.</formula><p>we have a LGSSM.</p><p>The EKF can also be used as E-step when learning the parameters of the model, as done in <ref type="bibr" target="#b49">(Ghahramani and Roweis, 1999)</ref> for models in which Gaussian radial basis functions are used to model non-linearities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.2">The Unscented Kalman Filter</head><p>Due to the linearization steps, the EKF is mostly suitable for systems that are almost linear, as it may quickly diverge with highly non-linear f and g. The Unscented Kalman Filter (UKF) (Julier and Uhlmann, 1997) works similarly to the EKF, but provides a different way to approximate Gaussian random variables that performs better with highly non-linear transitions and emissions.</p><p>Here we will give the main intuition behind the algorithm and an example of application, see <ref type="bibr" target="#b105">(Murphy, 2012)</ref> for a thorough derivation. Instead of first approximating the non-linear functions by linearization and then passing a Gaussian distribution through it as in the EKF, the UKF first passes a deterministically chosen set of points through the non-linear functions and then approximates the resulting distribution with a Gaussian. This set of points, called sigma points, are deterministically sampled and chosen to capture the mean and covariance of the Gaussian random variables. The UKF is typically more accurate and robust than the EKF, and has a similar computational complexity. Furthermore, the UKF does not require derivatives, and can therefore work even for non-differentiable functions. As shown in <ref type="bibr" target="#b148">(Wan and van der Merwe, 2001;</ref><ref type="bibr" target="#b128">Särkkä, 2008)</ref>, the UKF can also be extended to perform smoothing.</p><p>Ball tracking example with air resistance. We start from the same LGSSM used in Section 3.4, but we make the transition transition equation f of the SSM non-linear as in (3.13). In Figure <ref type="figure">3</ref>.8 we then use the Unscented Kalman filter and smoother to perform state inference. As expected, we see that thanks to the non-linear formulation of the model the estimated trajectory is much closer to the true one compared to the one obtained the LGSSM of Figure <ref type="figure">3</ref>.7b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.3">Importance sampling</head><p>Importance sampling is a sampling technique that can be used to approximate posterior expectations as well as to find a sample-based approximation to the posterior p θ (z <ref type="bibr">et al., 2001)</ref>.</p><formula xml:id="formula_51">1:t |x 1:t , u 1:t ) (Doucet</formula><p>Consider the task of finding the posterior expectation of a generic function of the latent states h(z 1:t ), i.e. computing</p><formula xml:id="formula_52">E(h) = E p θ (z 1:t |x 1:t ,u 1:t ) [h(z 1:t )] = h(z 1:t )p θ (z 1:t |x 1:t , u 1:t )dz 1:t . (3.14)</formula><p>For example, solving this integral with h(z 1:t ) = z 1:t would return the posterior mean. The posterior distribution over which we want to take the expectation is intractable for non-linear non-Gaussian models, for which we can only evaluate the unnormalized posterior (i.e. the joint distribution p θ (x 1:t , z 1:t |u 1:t )). We can however find an approximation to this integral by introducing an auxiliary distribution q(z 1:t ), called importance distribution, as we did with the variational distribution that we used to define the ELBO in (2.7). To stress the fact that the importance distribution may depend on x 1:t and u 1:t , we denote it as q(z 1:t |x 1:t , u 1:t ).</p><p>For any distribution q(z 1:t |x 1:t , u 1:t ) whose support includes the support of p θ (z 1:t |x 1:t , u 1:t ), we can rewrite the integral in (3.14) as</p><formula xml:id="formula_53">E(h) = h(z 1:t ) p θ (x 1:t , z 1:t |u 1:t ) p θ (x 1:t |u 1:t ) dz 1:t = h(z 1:t ) p θ (x 1:t ,z 1:t |u 1:t ) q(z 1:t |x 1:t ,u 1:t ) q(z 1:t |x 1:t , u 1:t )dz 1:t p θ (x 1:t ,z 1:t |u 1:t ) q(z 1:t |x 1:t ,u 1:t ) q(z 1:t |x 1:t , u 1:t )dz 1:t = h(z 1:t )w(z 1:t )q(z 1:t |x 1:t , u 1:t )dz 1:t w(z 1:t )q(z 1:t |x 1:t , u 1:t )dz 1:t (3.15)</formula><p>where we have defined the unnormalized importance weights w(z 1:t ) as</p><formula xml:id="formula_54">w(z 1:t ) = p θ (x 1:t , z 1:t |u 1:t ) q(z 1:t |x 1:t , u 1:t ) . (3.16)</formula><p>If we choose an importance distribution which is easy to sample from, e.g. a multivariate Gaussian, we can find a sample-based approximation to the integral in (3.14). We first draw R i.i.d. samples z (r) 1:t ∼ q(z 1:t |x 1:t , u 1:t ), that are also referred to as particles in this setting, and successively approximate the expectation with Monte Carlo integration:</p><formula xml:id="formula_55">E(h) = 1 R R i=1 w(z (r) 1:t )h(z (r) 1:t ) 1 R R i=1 w(z (r) 1:t ) = R i=1 w (r) t h(z (r) 1:t ) ,<label>(3.17)</label></formula><p>where we have defined the normalized importance weights as</p><formula xml:id="formula_56">w (r) t = w(z (r) 1:t ) R i=1 w(z (r) 1:t )</formula><p>.</p><p>The estimate E(h) is therefore computed with a weighted average, whose weights depend on the ratio between the densities of p θ (x 1:t , z 1:t |u 1:t ) and q(z 1:t |x 1:t , u 1:t ). If q is smaller than p at a certain state z 1:t the corresponding weight will be high, vice versa the weight will be small if q is larger than p. This allows to correct in the estimate E(h) the mismatch between the two distributions, making sure that we are correctly representing the high-probability regions of p despite the fact we are sampling from q. Asymptotically, as R → ∞ the estimate E(h) will converge to E(h). In practice however we can only use a finite number of samples, and this makes this estimate biased and only accurate if the choice of the specific form of the importance distribution is sufficiently close to the posterior distribution (so that most of the particles fall in the high probability regions of p).</p><p>Notice that the set of weight-particle pairs {( w</p><formula xml:id="formula_57">(r) t , z<label>(r)</label></formula><p>1:t )} R i=1 can be seen as a sample-based approximation of the posterior p θ (z 1:t |x 1:t , u 1:t ), defined as a weighted mixture of delta functions centered at the samples:</p><formula xml:id="formula_58">p θ (z 1:t |x 1:t , u 1:t ) = R i=1 w (r) t δ(z 1:t -z (r) 1:t ) .</formula><p>Using this approximation we can in fact rewrite (3.17) as</p><formula xml:id="formula_59">E(h) = h(z 1:t ) p θ (z 1:t |x 1:t , u 1:t )dz 1:t .</formula><p>One issue with importance sampling is that it is highly inefficient in high dimensional cases. Also, in the sequential setting this algorithm is not suitable for recursive estimation of the filtered posterior distribution. At each new time step we would have in fact to compute the importance weights over the whole sequence of states, i.e. the computational complexity increases over time. We now present a sequential extension of this algorithm that mitigates both of these problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.4">Particle filtering</head><p>In Section 3.4.1 we have seen that the Kalman filter provides a closed-form expression for the recursive estimation of the marginal posterior distribution p θ (z t |x 1:t , u 1:t ) given the one at the previous time step, p θ (z t-1 |x 1:t-1 , u 1:t-1 ). Particle filtering <ref type="bibr" target="#b28">(Doucet et al., 2001;</ref><ref type="bibr" target="#b29">Doucet and Johansen, 2008)</ref>, on the other hand, uses a sequential extension of importance sampling to recursively update a numerical approximation to the posterior over the whole sequence up to time t, i.e. p θ (z 1:t |x 1:t , u 1:t ), given the posterior p θ (z 1:t-1 |x 1:t-1 , u 1:t-1 ) at time steps 1 : t -1. Using the laws of probability as well as the conditional independence properties of SSMs, we can in fact decompose the posterior p θ (z 1:t |x 1:t , u 1:t ) as</p><formula xml:id="formula_60">p θ (z 1:t |x 1:t , u 1:t ) = p θ (x 1:t , z 1:t |, u 1:t ) p θ (x 1:t |u 1:t ) = p θ (x t , z t |x 1:t-1 , z 1:t-1 , u 1:t )p θ (x 1:t-1 , z 1:t-1 |, u 1:t-1 ) p θ (x t |x 1:t-1 , u 1:t )p θ (x 1:t-1 |u 1:t-1 ) = p θ (x t |x 1:t-1 , z 1:t , u 1:t )p θ (z t |x 1:t-1 , z 1:t-1 , u 1:t ) p θ (x t |x 1:t-1 , u 1:t ) p θ (z 1:t-1 |x 1:t-1 , u 1:t-1 ) = p θ (x t |z t )p θ (z t |z t-1 , u t ) p(x t |x 1:t-1 , u 1:t ) p θ (z 1:t-1 |x 1:t-1 , u 1:t-1 ) .</formula><p>To allow for recursive estimation, we further assume the following factorization for the importance distribution</p><formula xml:id="formula_61">q(z 1:t |x 1:t , u 1:t ) = q(z t |z 1:t-1 , x 1:t , u 1:t )q(z 1:t-1 |x 1:t-1 , u 1:t-1 ) = q(z 1 ) t l=2 q(z l |z 1:l-1 , x 1:l , u 1:l ) .</formula><p>The unnormalized importance weights then become</p><formula xml:id="formula_62">w(z 1:t ) = p θ (x 1:t , z 1:t |, u 1:t ) q(z 1:t |x 1:t , u 1:t ) = p θ (x t |z t )p θ (z t |z t-1 , u t )p θ (x 1:t-1 , z 1:t-1 |, u 1:t-1 ) q(z t |z 1:t-1 , x 1:t , u 1:t )q(z 1:t-1 |x 1:t-1 , u 1:t-1 ) = p θ (x t |z t )p θ (z t |z t-1 , u t ) q(z t |z 1:t-1 , x 1:t , u 1:t ) w(z 1:t-1 )</formula><p>which implies that the normalized importance weights are</p><formula xml:id="formula_63">w (r) t ∝ p θ (x t |z t )p θ (z t |z t-1 , u t ) q(z t |z 1:t-1 , x 1:t , u 1:t ) αt w (r) t-1 . (3.18)</formula><p>The importance weight at time t can then be simply computed given the ones at the previous time step by multiplying the incremental importance weights α t . The computational complexity of the algorithm stays therefore constant over time.</p><p>Starting from a set of particles {( w</p><formula xml:id="formula_64">(r) t-1 , z (r) 1:t-1 )} R i=1</formula><p>, that provides an empirical estimate of the posterior at times 1 : t -1, we can obtain an approximation of the posterior at times 1 : t by extending each particle sampling from q(z t |z (r) 1:t-1 , x 1:t , u 1:t ) and updating the corresponding weight using (3.18). This procedure can be initialized by sampling R i.i.d particles from q(z 1 ).</p><p>The algorithm discussed until now is also known as sequential importance sampling. A particle filter combines sequential importance sampling with a resampling step that is added to prevent degeneracy in the particles. In practice in fact, as t increases the distribution of the weights will become skewed, with just a small percentage of the particles having a non-zero weight. Only a few particles will then effectively approximate the posterior distribution, and a lot of computational resources will be wasted on particles that have a negligible effect on the approximation of the expectation (3.17). However, if at each iteration we resample with replacement the R particles using their weight as resampling probabilities, particles with higher weight will be replicated while particles with low weight will be discarded. This will result in a new set of R particles, that will be assigned weight 1 R . A discussion on different resampling methods can be found in <ref type="bibr" target="#b29">(Doucet and Johansen, 2008)</ref>. While beneficial to prevent degeneracy in the particles, this resampling step is introduces some variance in the estimate and should therefore be done only if necessary. Liu and Chen, (1998) provide the effective sample size</p><formula xml:id="formula_65">R ef f = 1 R r=1 ( w (r)</formula><p>t ) 2 as a metric to measure of the variance of the weights and suggest whether the resampling step should be done. In practice the resampling step is only done if the effective sample size is below a certain number of particles, e.g. R ef f &lt; 0.7R.</p><p>The choice of the importance distribution q is crucial to the success of the particle filter. The optimal distribution in order to minimize the variance of the importance weights is given by</p><formula xml:id="formula_66">q opt (z t |z 1:t-1 , x 1:t , u 1:t ) = p θ (z t |z t-1 , x t , u t ) = p θ (x t |z t )p θ (z t |z t-1 , u t ) p θ (x t |z t-1 , u t ) (3.19)</formula><p>In practice this distribution is often intractable, and many approximations have been proposed over the years. Among the simplest ones, the bootstrap filter uses the prior distribution as importance distribution</p><formula xml:id="formula_67">q(z 1:t |x 1:t , u 1:t ) = p θ (z 1:t |u 1:t ) = p(z 1 ) t l=2 p θ (z l |z l-1 , u l ) so that w (r) t ∝ p θ (x t |z t ) w (r)</formula><p>t-1 . In <ref type="bibr" target="#b30">(Doucet et al., 2000;</ref><ref type="bibr" target="#b146">van der Merwe et al., 2000)</ref> the authors propose to use the approximate Gaussian posterior obtained with the EKF and UKF as proposal distributions. As we will see in Section 4.3.2, it is also possible to learn flexible importance distributions parameterized by deep neural networks.</p><p>We finally notice that as a byproduct of this inference procedure we can also obtain an unbiased estimate of the marginal likelihood p θ (x 1:t |u 1:t ), the denominator in (3.15), using the intermediate unnormalized weights:</p><formula xml:id="formula_68">p θ (x 1:T |u 1:T ) = T t=1 1 R R r=1 w(z (r) 1:t ) .</formula><p>(3.20)</p><p>Particle fiiltering is in general more computationally demanding but more accurate than the EKF and UKF. It is a special case of the broader class of Sequential Monte Carlo algorithm <ref type="bibr" target="#b24">(Del Moral et al., 2006)</ref>, and borrows from it many of the techniques developed to improve sampling. For example, MCMC steps can be used after a resampling step to avoid having too may identical copies of the same particle, i.e. sample impoverishment <ref type="bibr" target="#b50">(Gilks and Berzuini, 2001)</ref>. Also, the number of particles can be adaptively chosen depending on the effective sample size <ref type="bibr">(Fraccaro et al., 2016a)</ref>.</p><p>These ideas can be generalized to compute the smoothed posterior distribution (particle smoothing) <ref type="bibr" target="#b29">(Doucet and Johansen, 2008)</ref> as well as to estimate the parameters of the model, e.g. with the EM algorithm or gradient-based methods <ref type="bibr" target="#b69">(Kantas et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Summary and discussion</head><p>In this chapter we have introduced state-space models as an extension of LVMs that is suitable for sequential data. The Markovian structure of SSMs introduces some conditional independence properties between the latent variables that can be exploited during inference (filtering, smoothing and prediction). We have presented the LGSSM as a basic example of a SSM, for which posterior inference and missing data imputation can be performed in an exact way. Non-linear and non-Gaussian SSMs can be used to model more complex sequences, but require approximate inference procedures such as the EKF, the UKF or particle filters. We have used the ball tracking example to illustrate many of the techniques presented throughout this chapter.</p><p>The main focus of this thesis is building non-linear models that can learn complex high-dimensional sequential data distributions from large unlabelled datasets. The approximate inference methods presented in Section 3.5.1 are however not powerful and/or scalable enough for such applications.</p><p>In the next chapter we will therefore introduce a general class of models that use SSMs with highly non-linear transitions and emissions parameterized by deep neural networks. These models are broadly applicable and can be trained efficiently with the amortized Variational inference ideas presented for VAEs in Section 2.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chapter 4</head><p>Deep latent variable models for sequential data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Motivation</head><p>The main focus of this thesis is unsupervised learning of complex probability distributions for temporal data. We may be interested for example in learning a generative models for speech, music, videos or text, or in using the data stored in electronic health records (EHRs) to learn a patient representation given the information collected during many different visits. These applications are characterized by:</p><p>1. Complex and high-dimensional temporal distributions. We consider high-dimensional sequences (e.g. a video), that require complex architectures that are able to:</p><p>-Model the high-dimensional observations at each time step.</p><p>-Capture long-term temporal dependencies in the data and memorize relevant information.</p><p>-Model the uncertainty and variability in the data, and properly propagate them over time.</p><p>These models will have an intractable log-likelihood, and we will need to resort to approximate inference and parameter learning.</p><p>2. Large-scale datasets. To learn such complex distributions that possibly depend on hundreds of thousands of parameters we will use very large datasets. We then need scalable models and training procedures.</p><p>We will solve these tasks by combining ideas from three classes of models closely related to each other. First, as we have see in Chapter 2, we can use VAEs to model complex high dimensional</p><formula xml:id="formula_69">d t-1 d t d t+1 x t-1 x t x t+1</formula><p>(a) RNN for sequence modelling.</p><formula xml:id="formula_70">d t-1 d t d t+1 x t-1 x t x t+1 u t-1 u t u t+1</formula><p>(b) RNN with input variables. observations by introducing latent variables and using neural networks to parameterize flexible conditional distributions. VAEs allow to perform training using stochastic back-propagation with inference networks in a very scalable way. Secondly, we can use recurrent neural networks (RNNs), that will be introduced in Section 4.2, to model long-term dependencies in the data through their parametric memory cells. Finally, we will show in Section 4.3 that the same ideas that lead to develop VAEs as a deep LVM can be applied to construct deep SSMs, flexible and scalable models for temporal data that offer a principled way to model uncertainty in the latent representation.</p><p>As we will see in the rest of the Chapter, depending on the needs of each application these models can be combined in many different ways. In Section 4.4 we will see that we can extend VAEs to sequential data by using an RNN to define a time-varying prior for the same VAE repeated at each time step. These models can then be further extended using a DSSM instead of the VAEs, as shown in Section 4.5. In Section 4.6 we will then show how these ideas can be used to learn disentangled representations by defining structured prior distribution. In some applications that require higher memory capacity RNNs are not enough, and we need therefore to extend the sequential models using external memory architectures as discussed in Section 4.7.</p><p>All these models use neural networks as their main building block, and we will therefore be able to define very expressive and flexible architectures that can be trained in a similar way using stochastic back-propagation and are simple to implement using existing deep learning libraries.</p><p>Due to their expressiveness it is not always easy to fully exploit the modelling power of these architectures. In Section 4.8 we will then present several training tricks that have proven useful in many applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Recurrent neural networks</head><p>Recurrent neural networks (RNN) are an extension of deep neural networks that can model sequences of variable length. They are widely used in many areas involving temporal data, such as for language modelling and machine translation <ref type="bibr" target="#b53">(Graves, 2013;</ref><ref type="bibr" target="#b141">Sutskever et al., 2014)</ref>.</p><p>For sequence modelling, RNNs assume the following factorization of the joint distribution over the sequence x 1:T ,</p><formula xml:id="formula_71">p θ (x 1:T ) = T t=1 p θ (x t |x 1:t-1 ) , (4.1)</formula><p>and assume that at time t all the relevant information coming from the past that is included in x 1:t-1 can be summarized by a deterministic latent variable d t . A graphical representation of the model can be found in Figure <ref type="figure" target="#fig_11">4</ref>.1a. Instead of defining p θ (x t |x 1:t-1 ), in an RNN we define p θ (x t |d t ), as a distribution whose parameters depend on d t through some deep neural networks parametrized by θ (e.g. a Gaussian distribution). The state d t evolves over time, and at each time step incorporates the information from the previous element of the sequence, using the state update equation</p><formula xml:id="formula_72">d t = f θ (d t-1 , x t-1</formula><p>). The function f θ is a differentiable non-linear transition function that has to be powerful enough to capture the long-term dependencies in the data.</p><p>Common choices for f θ are memory cell units such as LSTMs <ref type="bibr" target="#b63">(Hochreiter and Schmidhuber, 1997)</ref> or GRU <ref type="bibr" target="#b20">(Chung et al., 2014)</ref>, that use learned gating mechanisms to store information that needs to be available at future time steps. The initial state d 0 of the RNN is typically learned or set to 0. The RNN is trained to predict the next output of the sequence given all the previous ones, and gradients can be computed using a temporal extension to the back-propagation algorithm.</p><p>Notice that more in general RNNs can be used to model sequences x 1:T that depend on some inputs u 1:T = [u 1 , . . . , u T ], as illustrated in Figure <ref type="figure" target="#fig_11">4</ref>.1b. In this case, the state update equation is given by d t = f θ (d t-1 , u t ), i.e. d t is now used to capture at each time step the information coming from the input u t . When doing sequence modelling, as illustrated in Figure <ref type="figure" target="#fig_11">4</ref>.1a we are implicitly considering the output at the previous time step as the input (u t = x t-1 ), which is allowed as at time t the value of x t-1 is known (if we assume that there are no missing values).</p><p>In the following, even when considering sequence modelling we will use u t in the equations, as it results in a more general as well as cleaner notation.</p><p>By comparing the graphical representation of SSMs and RNNs in Figures 3.1 and 4.1b respectively, it is easy to see that an RNN can be interpreted as a special case of a SSM whose transition distribution is a delta function that expresses a highly non-linear but deterministic relationship between the RNN states. As the RNN units d t are deterministic, an RNN cannot model uncertainty in the latent states but, on the other hand, the log-likelihood computation is tractable as the integral in (3.2) is straightforward to solve when the transition probabilities are delta functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Deep state-space models</head><p>In this section we introduce a broad class of non-linear SSMs with Gaussian transitions and that, similarly to VAEs, use deep neural networks to define flexible transition and emission distributions <ref type="bibr" target="#b76">(Krishnan et al., 2015;</ref><ref type="bibr" target="#b39">Fraccaro et al., 2016c;</ref><ref type="bibr" target="#b77">Krishnan et al., 2017)</ref>. For simplicity in the exposition we will refer to them as deep state-space models (DSSM).</p><p>In a DSSM the transition distribution is a Gaussian, i.e. p θ (z</p><formula xml:id="formula_73">t |z t-1 , u t ) = N (z t ; µ (p) t , v<label>(p)</label></formula><p>t ), whose mean and diagonal covariance matrix are a function of the previous latent state z t-1 and current input u t through two deep neural networks:</p><formula xml:id="formula_74">µ (p) t = NN (p) 1 (z t-1 , u t ) , log v (p) t = NN (p) 2 (z t-1 , u t ) . (4.2)</formula><p>If scalability is not an issue, to make the model more general it is also possible to use a Gaussian with full covariance matrix, see <ref type="bibr" target="#b122">(Rezende et al., 2014)</ref> for a discussion on possible Gaussian covariance parameterizations. As for VAEs, depending on the type of observations the emission distribution p θ (x t |z t ) is typically chosen to be either a Gaussian distribution (real-valued data) or a Bernoulli distribution (binary data). The parameters of both distribution are computed with deep neural networks with input z t .</p><p>The exact parametrization of transition and emission probabilities is problem dependent. For the transitions, the simplest parameterization concatenates [z t-1 , u t ] and passes this vector through a neural network that returns the mean and the diagonal covariance of the prior over z t . However, if for example we are doing video modelling and u t = x t-1 is an image, it is typically convenient to first pass u t through a (convolutional) neural network that does feature extractor, and then concatenate the resulting vector with z t-1 . <ref type="bibr" target="#b77">Krishnan et al., (2017)</ref> use gated transition functions that allow the model to learn to use linear transitions for some latent dimensions and non-linear ones for others. The parameterization for the emission distribution highly depends on the type of observations. Standard deep neural networks are a good default choice, but when dealing with images it is often better to use convolutional architectures.</p><p>For notational simplicity we assume that the initial state z 0 is a fixed and known vector (we could otherwise learn it). The joint distribution is then given by</p><formula xml:id="formula_75">p θ (x 1:T , z 1:T |u 1:T , z 0 ) = p θ (x 1:T |z 1:T )p θ (z 1:T |u 1:T , z 0 ) = T t=1 p θ (x t |z t )p θ (z t |z t-1 , u t ) (4.3)</formula><p>This distribution specifies the generative process of the data, therefore as in VAEs p θ (x 1:T , z 1:T |u 1:T , z 0 ) is often referred to as generative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Amortized inference and parameter learning</head><p>Thanks to the deep neural networks used in their parameterization, DSSMs are very expressive and can model a wide range of data distributions. However, as discussed in Section 3.5, due to the non-linearities in the model exact inference is not possible. In Section 3.5.1 we discussed several approximate inference techniques, that are however not scalable enough to large datasets and to high dimensional spaces. The usage of neural networks to define non-linear state-space models has also been previously considered <ref type="bibr" target="#b144">(Valpola and Karhunen, 2002;</ref><ref type="bibr" target="#b118">Raiko and Tornio, 2009)</ref>, that approximate the posterior using a variational inference procedure that scales quadratically with the dimensionality of the observations, and is therefore not suitable for the large-scale applications we are interested in.</p><p>Below we will extend the amortized inference ideas used for VAEs in Section 2.4.2 to the temporal setting, that will allow us to specify a powerful and scalable way to perform joint inference and parameter learning in DSSMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.1">ELBO derivation</head><p>As done for the derivation of the ELBO in Section 2.3, we can introduce a variational approximation conditioned on all quantities that are known at inference time, i.e. q φ (z 1:T |x 1:T , u 1:T , z 0 ), and compute the ELBO for a DSSM as:</p><formula xml:id="formula_76">log p θ (x 1:T |u 1:T , z 0 ) = log p θ (x 1:T , z 1:T |u 1:T , z 0 )dz 1:T = log p θ (x 1:T , z 1:T |u 1:T , z 0 ) q φ (z 1:T |x 1:T , u 1:T , z 0 ) q φ (z 1:T |x 1:T , u 1:T , z 0 )dz 1:T = log E q φ (z 1:T |x 1:T ,u 1:T ,z 0 ) p θ (x 1:T , z 1:T |u 1:T , z 0 ) q φ (z 1:T |x 1:T , u 1:T , z 0 ) ≥ E q φ (z 1:T |x 1:T ,u 1:T ,z 0 ) log p θ (x 1:T , z 1:T |u 1:T , z 0 ) q φ (z 1:T |x 1:T , u 1:T , z 0 ) = F i (θ, φ) . (4.4)</formula><p>We now have to define a parameterization for the variational distribution q φ (z 1:T |x 1:T , u 1:T , z 0 ). If all the sequences had the same length, we could in principle define a deep neural network that outputs the mean and variances of the posterior approximation of the latent variables at all T time steps. However, in many applications the sequences may have different lengths and, more importantly, this parameterization does not exploit the dependencies induced by the temporal structure of the problem. As shown below, we can instead define a variational approximation inspired by the sequential factorization of the true posterior distribution.</p><p>Using the independence properties given by the Markovian structure of the model that were discussed in Section 3.1, we can factorize the true intractable posterior distribution as</p><formula xml:id="formula_77">p θ (z 1:T |x 1:T , u 1:T , z 0 ) = T t=1 p θ (z t |z t-1 , x 1:T , u 1:T ) = T t=1 p θ (z t |z t-1 , x t:T , u t:T ) . (4.5)</formula><p>This equation implies that if we know z t-1 , then the posterior over z t does not depend on past inputs and outputs, but only on present and future ones. The state z t-1 in fact captures all the relevant information coming from the past. We can then approximate the true posterior with a structured variational approximation that mimics the factorization in (4.5):</p><formula xml:id="formula_78">q φ (z 1:T |x 1:T , u 1:T , z 0 ) = T t=1 q φ (z t |z t-1 , x t:T , u t:T ) . (4.6)</formula><p>This approximation to the smoothed posterior distribution shares the same parameters φ at each time step, and this allows us to handle sequences of variable length. Similarly to VAEs, we can make this inference procedure scalable by defining q φ (z t |z t-1 , x t:T , u t:T ) as an inference network that returns the parameters of a Gaussian distribution. We will discuss the exact parameterization in detail in Section 4.3.1.2.</p><p>Since both the joint distribution in (4.3) and the posterior approximation in (4.6) factorize over time we can decompose the ELBO as a sum over T terms:</p><formula xml:id="formula_79">u t-1 u t u t+1 a t-1 a t a t+1 z t-1 z t z t+1 x t-1 x t x t+1 (a) Smoothing u t-1 u t u t+1 a t-1 a t a t+1 z t-1 z t z t+1 x t-1 x t x t+1 (b) Filtering</formula><formula xml:id="formula_80">F i (θ, φ) = E q φ (z 1:T |x 1:T ,u 1:T ,z 0 ) log p θ (x 1:T , z 1:T |u 1:T , z 0 ) q φ (z 1:T |x 1:T , u 1:T , z 0 ) = E q φ (z 1:T |x 1:T ,u 1:T ,z 0 ) T t=1 log p θ (x t |z t )p θ (z t |z t-1 , u t ) q φ (z t |z t-1 , x t:T , u t:T ) = T t=1 E q * φ (z t-1 ) E q φ (zt|z t-1 ,x t:T ,u t:T ) log p θ (x t |z t ) + -KL q φ (z t |z t-1 , x t:T , u t:T ) p θ (z t |z t-1 , u t ) ,<label>(4.7)</label></formula><p>where q * φ (z t-1 ) denotes the marginal distribution of z t-1 in the variational approximation to the posterior q φ (z 1:t-1 |x 1:T , u 1:T , z 0 ), given by</p><formula xml:id="formula_81">q * φ (z t-1 ) = q φ (z 1:t-1 |x 1:T , u 1:T , z 0 ) dz 1:t-2 = E q * φ (z t-2 ) q φ (z t-1 |z t-2 , x t-1:T , u t-1:T ) .</formula><p>Interestingly, we can interpret the ELBO in (4.7) as having a VAE at each time step with a time-varying prior that depends on the previous state. Notice in particular the decomposition of each term in the summation in a reconstruction and regularization term.</p><p>While the KL term can be computed analytically, the expectations in the ELBO are still intractable, and we approximate them by sampling from the variational approximation and using Monte Carlo integration as done for VAEs. To reduce the computational cost, it is common to use a single sample at each time step. The parameters θ of the DSSM and φ of the inference network can be learned jointly by maximizing the ELBO using stochastic gradient ascent, using the reparameterization trick to reduce the variance of the gradients. Recall in particular that this scalable gradient-based optimization is only possible since all the distributions involved in the ELBO computation are parameterized by differentiable deep neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.2">Parameterization of the inference network</head><p>In this section we will introduce the parameterization for q φ (z t |z t-1 , x t:T , u t:T ) used in <ref type="bibr">(Fraccaro et al., 2016c, Chapter 5)</ref>, see <ref type="bibr" target="#b2">(Archer et al., 2015;</ref><ref type="bibr" target="#b76">Krishnan et al., 2015;</ref><ref type="bibr" target="#b43">Gao et al., 2016;</ref><ref type="bibr" target="#b77">Krishnan et al., 2017)</ref> for alternative but related ones.</p><p>When deciding the structure of q φ (z t |z t-1 , x t:T , u t:T ), the main challenge to solve is the dependence of this distribution on a variable number of inputs and outputs at each time step t, i.e. x t:T and u t:T . We approximate this dependence of z t on future inputs and outputs in the inference network by introducing an auxiliary deterministic state a t at each time step that belongs to an RNN running backwards in time. We initialize the hidden state of the backward-recursive RNN as a T +1 = 0, and recursively compute</p><formula xml:id="formula_82">a t = g φ (a t+1 , [u t , x t ]) ,<label>(4.8)</label></formula><p>using therefore as input to the RNN the concatenation of the present input and output. The function g φ can be for example an LSTM or GRU cell. The variational approximation then becomes q φ (z t |z t-1 , x t:T , u t:T ) = q φ (z t |z t-1 , a t ), see Figure <ref type="figure" target="#fig_11">4</ref>.2a for a graphical representation.</p><p>We notice that the state z t directly depends on z t-1 and a t . The direct dependence of z t on z t-1 in the variational approximation is used to encode the information coming from the past. The dependence of z t on the present and future inputs and outputs is then encoded in a t , as in (4.8) the concatenation [x t , u t ] contains the information coming from the present, while the hidden state a t+1 encodes the information coming from the future. Similarly to a VAE, we assume that q φ (z t |z t-1 , a t ) is a Gaussian distribution whose mean and log-variance are parameterized as</p><formula xml:id="formula_83">µ (q) t = NN (q) 1 (z t-1 , a t ) , log v (q) t = NN (q)</formula><p>2 (z t-1 , a t ) . (4.9)</p><p>Instead of smoothing, we can do filtering simply by replacing the RNN running backwards in time with a neural network that receives as input the present input and output information, i.e. a t = NN (a) (x t , u t ), see Figure <ref type="figure" target="#fig_11">4</ref>.2b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Tightening the bound with particle filters</head><p>In Section 2.5.1 we have seen that IWAEs extend VAEs by using importance sampling to define a tighter bound to the log-likelihood than the ELB0. The IWAE bound can be applied of course also to DSSMs, but as we will see below we can do even better than that for problems with a sequential structure. In Section 3.5.1.4 we have presented particle filters as an extension of importance sampling to the temporal setting in which we use a resampling step to make sure that the particles are concentrated in regions of high posterior density. For sequential models like DSSM we can then improve the tightness of the bound by extending IWAEs ideas using particle filters instead of importance sampling. This method was recently introduced independently by three different research groups <ref type="bibr">(Maddison et al., 2017a;</ref><ref type="bibr" target="#b81">Le et al., 2018;</ref><ref type="bibr" target="#b106">Naesseth et al., 2018)</ref>.</p><p>In (3.20) we have seen that as a byproduct of particle filtering we obtain an estimator to the marginal likelihood:</p><formula xml:id="formula_84">p θ (x 1:T |u 1:T ) = T t=1 1 R R r=1 w(z (r) 1:t ) . (4.10)</formula><p>As this quantity is unbiased, we can calculate p θ (x 1:T |u 1:T ) by taking the expectation of this estimator with respect to the importance distribution q φ (z 1:T |x 1:T , u 1:T , z 0 ). From this, the new bound can be obtained following the derivation of the ELBO in Section 2.3. Notice in particular that the form of the unnormalized weights in (4.10), w(z 1:t ) = p θ (x 1:t ,z 1:t |u 1:t ) q(z 1:t |x 1:t ,u 1:t ) , is exactly as the term inside the log in (4.4), and this bound reduces therefore to the standard ELBO of a DSSM if we are only considering one particle. The importance distribution q φ (z 1:T |x 1:T , u 1:T , z 0 ), that plays the same role as the variational approximation in this case, can be defined recursively with an inference network q φ (z t |z t-1 , x t , u t ) parameterized by deep neural networks, that approximates the optimal importance distribution p θ (z t |z t-1 , x t , u t ) in (3.19). We can then learn the parameters φ of this distribution together with the parameters θ of the DSSM using stochastic gradient ascent, as discussed in Section 4.3.1.</p><p>We have seen in Section 3.5.1.4 that it is convenient to only perform the resampling step when the effective sample size (ESS) is lower than a certain threshold. The ESS however is calculated using the weights that depend in turn on the parameters θ and φ. This implies that when we compute gradients with respect to these parameters, we will have gradient terms that come from the resampling step. Empirically <ref type="bibr">(Maddison et al., 2017a;</ref><ref type="bibr" target="#b81">Le et al., 2018;</ref><ref type="bibr" target="#b106">Naesseth et al., 2018)</ref> have shown that these gradients have a very high variance, and propose to discard them during training. This introduces small biases in the gradient estimation, but despite this, it allows to obtain convincing improvements in terms of final log-likelihood estimation compared to using the ELBO or the IWAE bound (obtained using the method presented in this section with no resampling step).</p><p>Instead of using sequential Monte Carlo methods (particle filters) to define a tighter bound than the ELBO, <ref type="bibr" target="#b57">Gu et al., (2015)</ref> use them to directly approximate the log-likelihood of a SSM, and learn the importance distribution by minimizing the KL diverge from the posterior's sample-based approximation to the importance distribution (i.e. the opposite KL than the one used in variational methods).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Sequential extensions of variational auto-encoders</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">The VAE-RNN model</head><p>The DSSM model introduced in Section 4.3 can be seen as having a VAE at each time step with a time-varying prior, so that each latent variable z t directly depends on the previous one. An alternative way to introduce correlations among latent variables is by expanding the model hierarchically with a new set of temporally correlated deterministic latent variables, the states of a recurrent neural network (RNN). The VAE-RNN model uses the same VAE at each time step, but with a prior for state z t that depends on the information on the past of the sequence captured in the RNN by the state d t , as illustrated in Figure <ref type="figure" target="#fig_11">4</ref>.3a. The generative model of the VAE-RNN is described by the joint distribution of the outputs and unobserved variables given the inputs and initial state d 0 of the RNN, i.e.</p><formula xml:id="formula_85">p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 ) = p θ (x 1:T |z 1:T )p θ (z 1:T |d 1:T )p θ (d 1:T |u 1:T , d 0 ) d t-1 d t d t+1 z t-1 z t z t+1 x t-1 x t x t+1 u t-1 u t u t+1 VAE RNN (a) Generative model p θ d t-1 d t d t+1 z t-1 z t z t+1 x t-1 x t x t+1 (b) Inference network q φ Figure 4.3: The VAE-RNN model. = T t=1 p θ (x t |z t )p θ (z t |d t )p θ (d t |d t-1 , u t ) . (4.11)</formula><p>where d 1:T can be computed by repeatedly applying the state update equation of the RNN given the inputs,</p><formula xml:id="formula_86">d t = f θ (d t-1 , u t ).</formula><p>We denote as d 1:T the value assumed by d 1:T after repeatedly applying the RNN transitions f θ . The deterministic transitions can then be written from a probabilistic point of view using delta functions centered at d t , i.e. p θ (d</p><formula xml:id="formula_87">t |d t-1 , u t ) = δ(d t -d t ).</formula><p>For simplicity, we assume that the initial state of the RNN is set to 0 (we could otherwise learn it). p θ (z t |d t ) is typically a Gaussian distribution, whose mean and variance depend on d t through deep networks. Notice in particular that given d 1:T the VAE states z 1:T are independent, i.e.</p><formula xml:id="formula_88">p θ (z 1:T |d 1:T ) = T t=1</formula><p>p θ (z t |d t ) . (4.12)</p><p>We can optimize the parameters of the model by extending to the sequential setting the ELBO of the VAE presented in Section 2.4.3, as done for the DSSM in Section 4.3.1. Using Jensen's inequality we can obtain a lower bound for the evidence log p θ (x 1:T |u 1:T , d 0 ):</p><formula xml:id="formula_89">log p θ (x 1:T |u 1:T , d 0 ) = log p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 )dz 1:T dd 1:T = log p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 ) q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 ) q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 )dz 1:T dd 1:T = log E q φ (z 1:T ,d 1:T |x 1:T ,u 1:T ,d 0 ) p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 ) q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 ) ≥ E q φ (z 1:T ,d 1:T |x 1:T ,u 1:T ,d 0 ) log p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 ) q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 ) = F i (θ, φ) , (4.13)</formula><p>where we have introduced a variational approximation q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 ) over all the latent variables of the model, conditioned on the data and the inputs.</p><p>Due to the deterministic nature of the RNN, the true posterior over d 1:T coincides with its prior. Furthermore, using the d-separation properties <ref type="bibr" target="#b44">(Geiger et al., 1990</ref>) of the graphical model in Figure <ref type="figure" target="#fig_11">4</ref>.3a it is easy to show that, conditioned on d 1:T , the latent variables of the VAEs at each time step are independent. The true posterior distribution p θ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 ) then factorizes as</p><formula xml:id="formula_90">p θ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 ) = p θ (z 1:T |x 1:T , d 1:T )p θ (d 1:T |u 1:T , d 0 ) = T t=1 p θ (z t |x t , d t ) p θ (d 1:T |u 1:T , d 0 ) . (4.14)</formula><p>The variational distribution is an approximation to the true posterior distribution, so we define it to mimic the factorization in (4.14): </p><formula xml:id="formula_91">q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 ) = q φ (z 1:T |x 1:T , d 1:T )p θ (d 1:T |u 1:T , d 0 ) = T t=1 q φ (z t |x t , d t ) p θ (d 1:T |u 1:T , d 0 ) . (<label>4</label></formula><formula xml:id="formula_92">F i (θ, φ) = E q φ (z 1:T ,d 1:T |x 1:T ,u 1:T ,d 0 ) log p θ (x 1:T |z 1:T )p θ (z 1:T |d 1:T ) q φ (z 1:T |x 1:T , d 1:T ) = E q φ (z 1:T |x 1:T , d 1:T ) log p θ (x 1:T |z 1:T )p θ (z 1:T | d 1:T ) q φ (z 1:T |x 1:T , d 1:T ) = T t=1 E q φ (zt|xt, dt) log p θ (x t |z t )p θ (z t | d t ) q φ (z t |x t , d t ) = T t=1 E q φ (zt|xt, dt) [log p θ (x t |z t )] -KL q φ (z t |x t , d t )||p θ (z t | d t )</formula><p>After computing d 1:T , we can then rewrite the ELBO as the one obtained if we had T independent data points. As RNNs are differentiable the gradients needed to jointly learn the parameters of the model and the inference network can still be computed using back-propagation and the reparameterization trick as for the VAE in Section 2.4.3. The VAE-RNN model will be used as a baseline when modelling simple videos of moving objects in Section 6.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Variational recurrent neural networks</head><p>In the previous section we have shown that RNNs can be used to extend VAEs to handle sequential data by defining a hierarchical time-varying prior. The VAE-RNN model can however be also understood the other way around, as using VAEs to extend RNNs to handle more complex data distribution. Standard RNNs typically use in fact Gaussian output distributions (or mixture of Gaussians), and as such they may struggle with highly multimodal data distributions. Adding a VAE to the output of the RNN we can define a very flexible architecture that is suitable to model a wide range of complex data distributions. The model presented in this section is better understood using this latter interpretation of the VAE-RNN model.</p><p>With respect to the standard RNN architecture in Figure <ref type="figure" target="#fig_11">4</ref>.1b, we see that in the VAE-RNN model of Figure <ref type="figure" target="#fig_11">4</ref>.3a there is no direct dependency from the deterministic hidden states of the RNN d t to the outputs x t . A natural first extension to the VAE-RNN model is therefore the addition of this missing connection, so that the likelihood of the model becomes p θ (x t |z t , d t ) instead of p θ (x t |z t ). This seemingly minor change is very relevant from the modelling point of view: if x t does not directly depend on d t , z t has to encode all the relevant information on the past of the sequence that is captured by d t . If x t is connected to both d t and z t on the other hand, the model can use the two sets of latent variables to separately encode in each of them the different aspects of the data they are better at modelling. In particular, the deterministic states d t can be used to capture the overall structure of the data using the flexibility and the power of RNN architectures, while the stochastic latent variables z t are well suited to model the variability in the data. Notice that typically the dimensionality of d t needs to be much higher that the one of z t (e.g. 1000 vs 100 dimensions). Being able to capture both aspects is fundamental for example when modelling speech. All speech waveforms share a common structure that follows from the rules of spoken languages, and contain very complex long-term dependencies across time steps. Every person has however its own way to speak, meaning that there is a lot of variability in how different people -and even in how the same person but under different circumstancespronounce the same sentence. While RNNs are ideal to model the high level structure of the waveforms, as its hidden states are inherently deterministic they would struggle to also model at the same time all the nuances and variations across different speakers in the data. For this, extending the deterministic state d t with a stochastic component z t that is able to naturally encode the variability in the data is fundamental.</p><p>The speech modelling example can be also used to justify another possible extension to the VAE-RNN model. As we said, the stochastic latent variables z t model the variability in the data, for example due to the particular vocal characteristics of the speaker. For a given sequence it is then reasonable to assume that the variability is consistent over time, i.e. that each latent variable z t is directly affected by the value of z 1:t-1 . This is however not the case in the generative model of the VAE-RNN in Figure <ref type="figure" target="#fig_11">4</ref>.3a, where to obtain the prior p θ (z t |d t ) we only need to compute the RNN states d 1:t given the inputs, and not any of the previous states z 1:t-1 . Below we will then add an arrow from z t-1 to d t , so that z t will depend on z t-1 indirectly through</p><formula xml:id="formula_93">d t = f θ (d t-1 , z t-1 , u t ).</formula><p>The variational recurrent neural network (VRNN) <ref type="bibr" target="#b21">(Chung et al., 2015)</ref> can be seen as an extension of the VAE-RNN model where we add the additional dependencies of x t on d t and of d t on z t-1 as discussed above and depicted in Figure <ref type="figure" target="#fig_11">4</ref>.4a.<ref type="foot" target="#foot_7">foot_7</ref> The generative model is then defined by the joint probability Similarly to the VAE-RNN model, to take into account the fact that the RNN states are deterministic we define p θ (d t |z t-1 , d t-1 , u t ) as a delta function whose center is computed with the recursion</p><formula xml:id="formula_94">p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 , z 0 ) = p θ (x 1:T |z 1:T , d 1:T )p θ (z 1:T , d 1:T |u 1:T , d 0 , z 0 ) = T t=1 p θ (x t |z t , d t )p θ (z t |d t )p θ (d t |z t-1 , d t-1 , u t ) . (4.16) d t-1 d t d t+1 z t-1 z t z t+1 x t-1 x t x t+1 u t-1 u t u t+1 (a) Generative model p θ d t-1 d t d t+1 z t-1 z t z t+1 x t-1 x t x t+1 u t-1 u t u t+1 (b) Inference network q φ</formula><formula xml:id="formula_95">d t = f θ (d t-1 , z t-1 , u t ).</formula><p>The posterior approximation chosen in <ref type="bibr" target="#b21">(Chung et al., 2015)</ref> can be written as</p><formula xml:id="formula_96">q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 , z 0 ) = T t=1 q φ (z t |x t , d t )p θ (d t |z t-1 , d t-1 , u t ) .</formula><p>(4.17)</p><p>Recalling that from Bayes' rule we know that the true posterior will be proportional to the joint distribution, i.e. p θ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 , z 0 ) ∝ p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 , z 0 ), we see that in the VRNN we introduce the inference network q φ (z t |x t , d t ) to approximate the unnormalized factor p θ (x t |z t , d t )p θ (z t |d t ) in (4.16). The specific form of q φ (z t |x t , d t ) is typically chosen as in the VAE-RNN as a Gaussian whose mean and variance depend on x t and d t through deep networks. Now that we have defined both the joint and the variational approximation, we can compute the ELBO as</p><formula xml:id="formula_97">F i (θ, φ) = E q φ (z 1:T ,d 1:T |x 1:T ,u 1:T ,d 0 ,z 0 ) log p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 , z 0 ) q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 , z 0 ) = E q φ (z 1:T ,d 1:T |x 1:T ,u 1:T ,d 0 ,z 0 ) T t=1 log p θ (x t |z t , d t )p θ (z t |d t )) q φ (z t |x t , d t ) .</formula><p>Unlike the VAE-RNN model, where samples from the variational approximation could be computed in parallel given the deterministic units, due to the connection from z t-1 to d t in the VRNN the sample at time t will depend on the past samples as well. Samples from q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 , z 0 ) can be easily obtained sequentially by ancestral sampling as illustrated in Algorithm 1. Tighter bounds for the VRNN can be obtained using particles filters as discussed in Section 4.3.2, see <ref type="bibr">(Maddison et al., 2017a)</ref> for an example of application. We will use the VRNN as a baseline in the speech modelling experiments of Section 5.4.</p><p>We finally notice that the VRNN can be seen as a DSSM in which the state s t is split in a stochastic and in a deterministic component, i.e. s t = [z t , d t ]. A graphical representation can be Algorithm 1 Sampling procedure for the Gaussian posterior approximation q φ (z 1:T , d 1:T |x 1:T , u 1:T , d 0 , z 0 ) of a VRNN.</p><p>1: inputs: u 1:T and x 1:T 2: initialize d 0 and z 0 3: for t = 1 to T do 4:</p><formula xml:id="formula_98">d t = f θ (d t-1 , z t-1 , u t ) % RNN recursion 5: µ (q) t = NN (q) 1 (d t , x t ) % Posterior mean 6: log v (q) t = NN (q)</formula><p>2 (d t , x t ) % Posterior log-variance 7:</p><formula xml:id="formula_99">z t ∼ N (z t ; µ (q) t , v<label>(q)</label></formula><p>t ) % Posterior sample 8: end for found in Figure <ref type="figure" target="#fig_11">4</ref>.5. The transition distribution is assumed to factorize in the following way:</p><formula xml:id="formula_100">d t-1 z t-1 s t-1 d t z t s t d t+1 z t+1 s t+1 x t-1 x t x t+1 u t-1 u t u t+1</formula><formula xml:id="formula_101">p θ (s t |s t-1 , u t ) = p θ (z t , d t |z t-1 , d t-1 , u t ) = p θ (z t |d t )p θ (d t | z t-1 i , d t-1 i s t-1 i , u t ) ,</formula><p>so that the dependence on the past and inputs is only captured by the deterministic component, that is then used to condition the stochastic one. The emission distribution depends on both components, i.e. p θ (x t |s t ) = p θ (x t |z t , d t ), and this leads to a joint distribution that coincides with (4.16):</p><formula xml:id="formula_102">p θ (x 1:T , s 1:T |s 1:T , s 0 ) = T t=1 p θ (x t |s t )p θ (s t |s t-1 , u t ) = T t=1 p θ (x t |z t , d t )p θ (z t |d t )p θ (d t |z t-1 , d t-1 , u t ) .</formula><p>In a VRNN, the state z t depends on z t-1 indirectly through the deterministic RNN state d t . The RNN states represent therefore a deterministic bottleneck through which all the stochasticity has to pass, making it difficult for the VRNN to properly model how the uncertainty in the latent variables propagates across time steps. As shown in the next section, this can be done by making z t directly depend on z t-1 as in a DSSM, which is also a more natural way to model temporal correlations among latent states. While this allows us to define a more expressive model than the VRNN, this dependency makes inference harder, as we now have to perform filtering and smoothing over a chain of latent variables as in Section 4.3.1. </p><formula xml:id="formula_103">d t-1 d t d t+1 z t-1 z t z t+1 x t-1 x t x t+1 u t-1 u t u t+1 (a) Generative model p θ d t-1 d t d t+1 a t-1 a t a t+1 z t-1 z t z t+1 x t-1 x t x t+1 (b) Inference network q φ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Stochastic recurrent neural networks</head><p>Stochastic recurrent neural networks are introduced in detail in the research paper in Chapter 5.</p><p>Here we will only briefly summarize the main ideas behind this model, mostly focusing on how it relates to the other models presented in this chapter.</p><p>Stochastic recurrent neural networks (SRNN) <ref type="bibr" target="#b39">(Fraccaro et al., 2016c)</ref> are formed by staking an RNN and a DSSM, see Figure <ref type="figure" target="#fig_11">4</ref>.6a for a graphical representation. Instead of the arrow from z t-1 to d t as in the VRNN model of Figure <ref type="figure" target="#fig_11">4</ref>.4a, in a SRNN z t-1 is directly connected to z t . SRNNs combine the advantages of RNNs and DSSMs in a principled way: the RNN can be used to capture complex long-term dependencies in its deterministic states, while the DSSM can model uncertainty in the latent representation through the stochastic states. The generative model of the SRNN model is given by</p><formula xml:id="formula_104">p θ (x 1:T , z 1:T , d 1:T |u 1:T , d 0 , z 0 ) = p θ (x 1:T |z 1:T , d 1:T )p θ (z 1:T |d 1:T , z 0 )p θ (d 1:T |u 1:T , d 0 ) = T t=1 p θ (x t |z t , d t )p θ (z t |z t-1 , d t )p θ (d t |d t-1 , u t ) . (4.18)</formula><p>We notice in particular that the transition density of the DSSM now depends on the deterministic states of the RNN, i.e. p θ (z</p><formula xml:id="formula_105">t |z t-1 , d t ) = N (z t ; µ (p) t , v (p) t ) with µ (p) t = NN (p) 1 (z t-1 , d t ) , log v (p) t = NN (p) 2 (z t-1 , d t ) . (4.19)</formula><p>The DSSM can therefore utilize the long-term information that is captured by the RNN. Furthermore, in the SRNN the RNN transitions p θ (d t |d t-1 , u t ) are entirely deterministic over time since they no longer depend on the noisy samples of z t-1 as in the VRNN.</p><p>The clear separation between deterministic and stochastic states in a SRNN allows us to perform inference and parameter learning extending the ideas presented in Section 4.3.1 for DSSMs. As the states d 1:T are deterministic and do not depend on the stochastic states their posterior coincides with their prior, and we can therefore write the posterior distribution over the latent variables of the SRNN as:</p><formula xml:id="formula_106">p θ (z 1:T , d 1:T |x 1:T , u 1:T , z 0 , d 0 ) = p θ (z 1:T |d 1:T , x 1:T , z 0 )p θ (d 1:T |u 1:T , d 0 ) . (4.20)</formula><p>In (4.20) the first term represents the intractable posterior over the states of the DSSM, while the second term represents the prior RNN transition probabilities. A similar factorization was used in (4.14) for the VAE-RNN model. We assume that the variational approximation factorizes similarly to the posterior in (4.20), i.e.</p><p>q φ (z 1:T , d 1:T |x 1:T , u 1:T , z 0 , d 0 ) = q φ (z 1:T |d 1:T , x 1:T , z 0 )p θ (d 1:T |u 1:T , d 0 ) . (4.21)</p><p>During inference, the states d 1:T at all time steps can be easily computed given only the inputs of the model with the RNN recursions that define p θ (d t |d t-1 , u t ). Once these are known, the SRNN can be seen as a DSSM whose inputs are the RNN states, and we can therefore use the same amortized inference procedure as for the DSSM in Section 4.3.1. In particular, we can use the same inference networks for filtering and smoothing, that were justified using the conditional independence properties of the true posterior distribution given by the Markovian structure of the model. In Figure <ref type="figure" target="#fig_11">4</ref>.6b we show the backward-recursive inference network used for smoothing, that allows us to take also into account information coming from the future inputs and outputs when computing the approximate posterior. As for the VRNN, also for the SRNN we can obtain a tighter lower bound using particle filters (Section 4.3.2). As shown in Section 5.4, SRNNs achieve state of the art performances in speech modelling (outperforming VRNNs by a large margin), and perform comparably to related methods for polyphonic music modelling.</p><p>A number of works have recently built on the SRNN model presented in this section. <ref type="bibr" target="#b52">(Goyal et al., 2017)</ref> extends the VRNN model of Section 4.4.2 with SRNN's backwards-recurring RNN, adding an auxiliary term in the ELBO that forces the latent variables to encode information about the future. This idea if further developed in the Variational Bi-LSTM model of <ref type="bibr" target="#b131">(Shabanian et al., 2017)</ref>. Finally, <ref type="bibr" target="#b91">(Liu et al., 2017)</ref> builds an architecture similar to the SRNN, using however an Hidden Markov Model with discrete random variables instead of a DSSM, that is trained using a continuous relaxation of the discrete variables defined with the Gumbel-Softmax distribution <ref type="bibr">(Maddison et al., 2017b;</ref><ref type="bibr" target="#b64">Jang et al., 2016)</ref>.</p><p>Apart from the the models already presented in this chapter, the extension of RNNs with stochastic units has been also explored in several other works. STORN <ref type="bibr" target="#b7">(Bayer and Osendorfer, 2014)</ref> and DRAW <ref type="bibr" target="#b56">(Gregor et al., 2015)</ref> use Gaussian stochastic units independent between time steps as input to the deterministic units of an RNN. <ref type="bibr" target="#b42">(Gan et al., 2015)</ref> uses a recurrent model with discrete latent units that is optimized using the NVIL algorithm <ref type="bibr" target="#b102">(Mnih and Gregor, 2014)</ref>. <ref type="bibr" target="#b154">(Zheng et al., 2017)</ref> defines a combination of SSMs and LSTMs that is trained with a stochastic EM approach, where the expectation in E-step is approximated using samples from sequential Monte Carlo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Learning disentangled representations with structured priors</head><p>All the models presented so far in this chapter are very flexible architectures that can be used to model a wide range of data distributions. However, to be able to do so they are often defined with deep neural networks with a very high number of parameters, and this implies that (1) they require a lot of data and (2) it is difficult to interpret what they are learning. As we will show below, we can often counteract this data inefficiency and black-box nature by carefully inserting some structure in the model, e.g. using domain knowledge on the task at hand, that helps the model to learn disentangled representations. Each latent variable will then represent a meaningful and interpretable concept, and training will often require less data as this additional prior knowledge encoded in the structure of the model will simplify the learning task.</p><formula xml:id="formula_107">z t-1 z t z t+1 a t-1 a t a t+1 x t-1 x t x t+1 u t-1 u t u t+1 VAE LGSSM</formula><p>In Section 4.6.1 we will focus on unsupervised learning of disentangled visual and dynamics representations in the sequential setting by carefully designing a model that combines LGSSMs and VAEs. We will then briefly show in Section 4.6.2 that we can use probabilistic graphical models to introduce structure to the model. Recent works have also focused on using similar ideas in the static setting, e.g. in <ref type="bibr">(Higgins et al., 2017a;</ref><ref type="bibr" target="#b26">Deng et al., 2017)</ref>. In particular, <ref type="bibr">Higgins et al., (2017a)</ref> learn to disentangle representations in a standard VAE by modifying the ELBO rather than designing the model with some structure in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">Kalman variational auto-encoders</head><p>Kalman variational auto-encoders are introduced in detail in the research paper in Chapter 6.</p><p>Here we will only briefly summarize the main ideas behind this model, mostly focusing on how it relates to the other models presented in this chapter.</p><p>In Section 3.4 we have considered the experiment of tracking a ball given noisy observations of its (x, y) coordinates. We now assume that instead of these 2-dimensional observations we observe at each time step a 32x32 image x t of the ball flying in vacuum, as illustrated in Figure <ref type="figure">3</ref>.6.</p><p>We then want to model videos formed by 1024-dimensional frames. In Section 3.4 we have seen that a LGSSM is ideal to represent the 2-dimensional trajectory of the ball, as we can derive its parameterization from Newton's equations of motion. However, to model the high-dimensional images we need a non-linear emission distribution. Can we exploit the prior knowledge on the physics of flying ball that is encoded in the LGSSM while dealing with high-dimensional observations? As we will see below, we can do this by constructing a model that disentangles visual and dynamic information.</p><p>If we compress the high-dimensional information in the image into a 2-dimensional latent variable representing the position of the ball, we can model the trajectories in this learned manifold with a LGSSM and perform filtering, smoothing and missing data imputation as described in Section 3.4. This is the key intuition behind a Kalman variational auto-encoder (KVAE) <ref type="bibr" target="#b35">(Fraccaro et al., 2017)</ref>, that factorizes the latent structure at each time step in a visual and dynamic component as illustrated in Figure <ref type="figure" target="#fig_11">4</ref>.7. Similarly to the VAE-RNN model of Section 4.4.1, a KVAE has a VAE at each time steps, that encodes the high-dimensional observations into a low dimensional latent state a t which learns to capture the relevant visual information in the observations. The prior over these latent states is time-varying, and parameterized with a LGSSM with states z t that models the temporal dynamics of the system. As shown below, we can learn jointly the parameters of both the VAE and the LGSSM. Notice that by working in this lower dimensional manifold instead of in image-space, we also avoid the computational issues due to the cubic scaling of the Kalman filter with the output dimensionality discussed in Section 3.4.1.</p><p>In the ball tracking experiment we set for example a t ∈ R 2 and z t ∈ R 4 . By constraining the dimensionality of these vectors we force the model to learn to use a t to model the noisy position of the ball in the frame (in a space that is possibly rotated and scaled w.r.t the (x, y) plane in Figure <ref type="figure">3</ref>.2), and z t to model the position and velocity of the ball in this new space similarly to the example in Section 3.4. While we do not explicitly tell the model to use these latent variables in this way, the model will learn to do it as it is the only way to maximize the ELBO introduced below in (4.27) with such low-dimensional latent states. We could of course also use much higher dimensional latent spaces, but training the KVAE would become more difficult, computationally expensive and require more data.</p><p>More in detail, we define the LGSSM with parameters γ = [γ 1 , .., γ T ] as in Section 3.4:</p><formula xml:id="formula_108">p γ (a 1:T , z 1:T |u 1:T ) = p γ (a 1:T |z 1:T ) p γ (z 1:T |u 1:T ) = T t=1 p γt (a t |z t ) • p(z 1 ) T t=2 p γt (z t |z t-1 , u t ) , (4.22)</formula><p>where the transition and emission distributions are respectively</p><formula xml:id="formula_109">p γt (z t |z t-1 , u t ) = N (z t ; A t z t-1 + B t u t , Q t ) (4.23) p γt (a t |z t ) = N (a t ; C t z t , R t ) . (4.24)</formula><p>Given the latent outputs of the LGSSM we model the observations with the VAE decoder p θ (x t |a t ), i.e. p θ (x 1:T |a 1:T ) = T t=1 p θ (x t |a t ). The joint distribution of the KVAE is the product of these distributions:</p><formula xml:id="formula_110">p(x 1:T , a 1:T , z 1:T |u 1:T ) = p θ (x 1:T |a 1:T ) p γ (a 1:T |z 1:T ) p γ (z 1:T |u 1:T ) .</formula><p>We can learn the parameters of the VAE and the LGSSM by introducing a variational approximation q(a 1:T , z 1:T |x 1:T , u 1:T ) and maximizing the ELBO obtained as usual using Jensen's inequality: log p(x 1:T |u 1:T ) = log p(x 1:T , a 1:T , z 1:T |u 1:T ) ≥ E q(a 1:T ,z 1:T |x 1:T ,u 1:T ) log p θ (x 1:T |a 1:T )p γ (a 1:T |z 1:T )p γ (z 1:T |u 1:T ) q(a 1:T , z 1:T |x 1:T , u 1:T ) = F(θ, γ, φ) .</p><p>(4.25)</p><p>We choose a variational approximation that allows us to exploit the knowledge we have on the exact posterior of a LGSSM. If we knew the latent variables of the VAE a 1:T , we could compute the conditional posterior over the LGSSM states p γ (z 1:T |a 1:T , u 1:T ) with the Kalman filtering and smoothing algorithm introduced in Section 3.4.1. We then factorize the variational distribution as q(a 1:T , z 1:T |x 1:T , u 1:T ) = q φ (a 1:T |x 1:T ) p γ (z 1:T |a 1:T , u 1:T ) = T t=1 q φ (a t |x t ) p γ (z 1:T |a 1:T , u 1:T ) , (4.26)</p><p>where q φ (a t |x t ) is the VAE inference network. In this way we can easily get samples form the posterior approximation by first sampling a (s) 1:T from the VAE inference network given the observations x 1:T , and then sampling from the exact posterior p γ (z 1:T |a (s) 1:T , u 1:T ). With this choice of the joint and variational distributions the ELBO in (4.25) becomes</p><formula xml:id="formula_111">F(θ, γ, φ) = E q φ (a 1:T |x 1:T ) log p θ (x 1:T |a 1:T ) q φ (a 1:T |x 1:T ) + +E pγ (z 1:T |a 1:T ,u 1:T ) log p γ (a 1:T |z 1:T )p γ (z 1:T |u 1:T ) p γ (z 1:T |a 1:T , u 1:T ) . (4.27)</formula><p>We can perform end-to-end training of this model and learn the parameters θ and φ of the VAE and γ of the LGSSM by jointly maximizing the ELBO. The intractable expectations can be computed with Monte Carlo integration (even with a single sample) and we use the reparameterization trick to obtain low-variance gradients.</p><p>Often the dynamics of the objects are non-linear, e.g. when the ball hits a wall, and the LGSSM assumptions no longer hold. In Section 6.3.3 we will show that we can deal with these situations by non-linearly changing the parameters γ t of the LGSSM over time as a function of the latent encodings a 1:t-1 up to time t -1. Importantly, this allows us to preserve the linear dependency between consecutive states in the LGSSM, and still be able to use the Kalman filtering and smoothing algorithms for posterior inference and missing data imputation. Results on using the KVAE to model the (non-linear) dynamics of the moving ball can be found in Section 6.5.</p><p>A recent related work can be found in <ref type="bibr" target="#b86">(Li and Mandt, 2018)</ref>, that shows how a careful model design can be used to also disentangle a static component in the sequence by extending the model with a time-invariant latent variable. This allows for example to deal with sequences of objects with different shapes and colors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">Structured priors with probabilistic graphical models</head><p>Probabilistic graphical models (PGMs) are a very general framework to represent relationships among random variables by defining joint probability distributions as a product of factors each of which only depends on a subset of the variables, see <ref type="bibr" target="#b11">(Bishop, 2006)</ref> for a comprehensive review on the topic. Both latent variable models and state-space models can be seen as special cases of PGMs.</p><p>As shown in <ref type="bibr" target="#b65">(Johnson et al., 2016;</ref><ref type="bibr" target="#b88">Lin et al., 2018)</ref> we can combine VAEs with PGMs in which we express prior knowledge on the application at hand, as needed when learning disentangled representation and interpretable models. The PGM is used to define a hierarchical prior distribution that helps to extract useful structure from the data (unlike the Gaussian prior of a VAE). To approximate the intractable posterior over the latent variables of the PGM, we could in principle follow a black-box approach using inference networks as for most of the models presented in this thesis. However, <ref type="bibr" target="#b65">(Johnson et al., 2016;</ref><ref type="bibr" target="#b88">Lin et al., 2018)</ref> argue that better posterior approximations can be defined by exploiting the structure of the PGM and existing approximate inference procedures for it, and combine therefore amortized inference using inference networks and Variational Message Passing (Winn and <ref type="bibr" target="#b150">Bishop, 2005)</ref>. The forward-backward procedure of the Kalman smoother is a message passing algorithm, and the KVAE presented in 4.6.1 can therefore also be seen as a special case of this framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Sequential models with external memory architectures</head><p>Some applications require models with a particularly high-memory capacity. In reinforcement learning (RL) for example, we may want to build agents that can remember a large number of past experiences and use this knowledge to better plan the sequence of actions needed to solve new tasks. In this cases, using RNNs with memory cells such as LSTMs <ref type="bibr" target="#b63">(Hochreiter and Schmidhuber, 1997)</ref> or GRUs <ref type="bibr" target="#b20">(Chung et al., 2014)</ref> as in VRNNs and SRNNs is typically not enough. To be able to increase the memory capacity in these architectures we would need in fact to largely increase the dimensionality of the RNN states d t . However, the scaling of the number of parameters of the RNN is quadratic with respect to the dimensionality of d t , and this would make learning impracticable both in terms of computational requirements and in terms of the amount of data needed to learn these models. In the static setting, a recent trend in the deep learning community to deal with high memory capacities is to design data structures that work as external memory architectures and are easy to integrate with neural networks <ref type="bibr" target="#b54">(Graves et al., 2014;</ref><ref type="bibr" target="#b139">Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b100">Miller et al., 2016;</ref><ref type="bibr" target="#b55">Graves et al., 2016;</ref><ref type="bibr">Li et al., 2016;</ref><ref type="bibr" target="#b12">Bornschein et al., 2017)</ref>. These ideas have been extended to the sequential setting by <ref type="bibr" target="#b45">Gemici et al., (2017)</ref>, that learn to write/read from external memories using differentiable memory addressing mechanisms.</p><p>In Section 4.7.1 we present a generative temporal model for RL agents walking in partiallyobserved 3D environments, which combines a structured SSM prior similarly to the KVAE of Section 4.6.1 and a non-parametric memory used to store what the agent sees in the environment at each time step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.1">Generative temporal models with spatial memory</head><p>Generative temporal models with spatial memory are introduced in detail in the research paper in Chapter 7. Here we will only briefly summarize the main ideas behind this model, mostly focusing on how it relates to the other models presented in this chapter.</p><p>Imagine to be training an RL agent to walk and explore a large 3D environment for hundreds of steps and successively predict future observations given a specific set of actions that bring it to a previously visited location. The input u t to the model at each time step is an action that makes the agent move/rotate in any direction, while the output x t is what the agent is observing. This task would be simple to solve if the agent could remember at each time step both its location and the observations. However, the true location is not known, and has to be inferred from the</p><formula xml:id="formula_112">z t-1 z t z t+1</formula><p>Memory Memory Memory sequence of actions and some knowledge on the physics of the moving agent. As explained below, we can solve this task by carefully designing the model with a structured prior as discussed in Section 4.6.</p><formula xml:id="formula_113">a t-1 a t a t x t-1 x t x t+1 u t-1 u t u t+1 VAE SSM</formula><p>We model the agent dynamics with a SSM with a 3-dimensional state z t , so that the model can learn to use two components to represent the position of the agent in the environment and the third component to represent in which direction the agent is looking. The transition probabilities can be used to model how each action changes the state of the agent, and its parameters can be learned from data. Also, instead of remembering the full high-dimensional observations, it is easier for the model to remember a compressed representation, that can be obtained for example with a VAE with latent state a t . The resulting model is the generative temporal model with spatial memory (GTM-SM), that is shown in Figure <ref type="figure" target="#fig_11">4</ref>.8. We can notice that it is very close to the KVAE introduced in Section 4.6.1, with two important differences:</p><p>1. The transitions need to be non-linear, as they need to model the agent's movement that is subject to momentum, friction and saturation. As opposed to the KVAE we are therefore not able to use a LGSSM and leverage its exact inference procedure.</p><p>2. While exploring the environment, the agent needs to be able to memorize at each time step its location (the state of the SSM) and the encoded observation (the latent variable from the VAE). These learned and disentangled representations of the environment are stored in a non-parametric spatial memory called differentiable neural dictionary (DND) <ref type="bibr" target="#b115">(Pritzel et al., 2017)</ref>. While predicting a future observation x t the agent can then infer its future state z t given the new sequence of actions, and retrieve from memory what it had seen before in that location (or close to it). To model this, the emission distribution of the SSM, i.e. the VAE prior, needs to also depend on the memory: p θ (a t |z t , Memory).</p><p>This model is presented in detail in Chapter 7, where we can also see that it is able to coherently predict over hundreds of time steps across a range of partially-observed 2D and 3D environments (Section 7.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Lessons learned in training sequential deep latent variable models</head><p>The implementation of this class of models is fairly simple, thanks to the availability of deep learning libraries that use automatic differentiation to compute the gradients needed during training. However, getting the models to perform well may be much more challenging and require some experience. We therefore share below some lessons learned with a lot of trial an error on how to train deep latent variable models for sequential data.</p><p>Most of the challenges faced during training are due to the usage of deep neural networks within the probabilistic model. While their flexibility is beneficial in terms of modelling power, the behavior of complex neural architectures such as the ones presented in this thesis can be difficult to predict. It is then fundamental to understand in depth the role of all the components that form model, inference network and cost function, and how they interact and influence each other.</p><p>To achieve this it can be beneficial to:</p><p>• Start from toy examples the model has to be able to solve. This allows to become more familiar with the working principles of the model, and to detect many of the modelling issues that would be impossible to isolate in more complex applications. Also, toy examples are often very fast to run, and can produce lots of intuitions and visualizations that can be used to assess the performance of the model on more complex tasks (as well as used when writing the paper to give intuition to the reader). The complexity of the toy example can be often increased as we start learning how to train the model, until the point at which the complexity is similar to the one of the original task we want to solve. If the model does not perform well in a basic toy example it is often pointless to try it as it is on more complex tasks.</p><p>• During training it is very informative to monitor the evolution of lots of statistics, such as the variance of all the distributions in the model, the various term that form the ELBO and the norm of the gradients. We ideally want one informative statistic for each component of the model, inference network and cost function.</p><p>Following these suggestions it is easier to assess if parts of the network are not being used or do not work as we expected, as well as to come up with some tricks that can be used to improve the training procedure. Also, they can give a better idea on how to tune some of the hyperparameters of the model.</p><p>This approach is of course more challenging and time consuming than the more traditional empirical deep learning approach in which we try many different complex neural architectures until the performances are good. However, our experience with these models suggests that while in theory big neural networks could learn to automatically do these very complex tasks, in practice they rarely do. In the following we will see that in this case the only way to achieve good performances is to have a deep understanding of the models and of their training dynamics and use it to come up with principled training tricks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.1">Training tricks</head><p>We now present some of the issues we found when training some of the architectures presented in this chapter, focusing on how to detect them, providing some intuition on why they appear and listing some of the tricks we found useful to solve them. Coming up with the right training tricks to best learn complex deep learning models has become a fundamental step in a researcher's agenda, as they can make huge differences in terms of final performances. For the deep latent variable models for sequential data presented in this chapter some of the tricks are the same as the ones typically used for VAEs. There is however an additional challenge given by the fact that in this case we are dealing with learned time-varying priors, as opposed to the fixed isotropic Gaussian prior typically used in VAEs.</p><p>One of the main issues encountered while training deep latent variable models is their difficulty in learning to fully exploit the stochasticity in the latent states. It is common to notice that in the beginning of training the KL term in the ELBO becomes very small and never recovers. This suggests that in many of the dimensions of the latent variable the variational approximation coincides with the prior, making the corresponding unit essentially inactive <ref type="bibr" target="#b15">(Burda et al., 2015;</ref><ref type="bibr" target="#b137">Sønderby et al., 2016b)</ref>. From an optimization point of view we can see this as an initially attractive local minimum, as in this case there will be no penalty in the ELBO from the KL term (we are maximizing the ELBO, in which there is a minus in front of the non-negative KL term).</p><p>In this case a common solution to mitigate this issue is to decrease the importance of minimizing the KL term in the beginning of training by:</p><p>• Multiplying the KL term by a constant β that is annealed from 0 to 1 during training <ref type="bibr" target="#b14">(Bowman et al., 2015;</ref><ref type="bibr" target="#b137">Sønderby et al., 2016b)</ref> • Modifying the ELBO so that decreasing the KL term below a given threshold is no longer advantageous, as in the free bits approach of <ref type="bibr" target="#b74">Kingma et al., (2016)</ref>.</p><p>In temporal models for which we are learning the time-varying prior, small values of the KL term can be also caused by the fact that for the model it may be particularly challenging to learn to approximate the posterior. In particular it may be difficult for the variational approximation to keep track of the changes in the posterior distribution caused by the non-stationary time-varying prior. This is the case for example in DSSMs and SRNNs. An effective solution to make it easier for the model to learn a good variational approximation and therefore exploit the stochasticity is to</p><p>• learn only the residual between the mean of the predictive prior distribution µ (p)</p><p>t and the the mean of the variational approximation µ (q) t at each time step <ref type="bibr" target="#b39">(Fraccaro et al., 2016c)</ref>. We then modify (4.9) to µ</p><formula xml:id="formula_114">(q) t = µ (p) t + NN (q) 1 (z t-1 , a t ) .</formula><p>For models for which there is a fully deterministic path from u t to x t powerful enough to explain most of the structure in the data, such as the RNN in the VRNN and in the SRNN, it is possible that the model learns not use stochastic part at all. This was also noticed in <ref type="bibr" target="#b17">(Chen et al., 2017)</ref> in the static setting for models with very expressive decoders. This issue is often accompanied in the temporal setting both by small KL terms and very small learned variances of the distributions over the latent variables that make the model essentially deterministic. A possible way to partially prevent this from happening is by:</p><p>• Lower bounding the variances to a given value or fixing them, so that it is not possible for the model to completely disregard the stochasticity.</p><p>• Using some of the tricks presented above to avoid small KL terms.</p><p>A particular attention should be used for models in which the various components of the ELBO depend on vectors with very different dimensionalities. For KVAEs and GTMs-SM for example, the KL term depends on the low-dimensional SSM states whereas the observations in the VAE reconstruction term are high-dimensional images. In the ELBO therefore the reconstruction term will dominate, and the training algorithm will then mostly focus in optimizing the VAE and not the SSM. Possible solutions in this case are:</p><p>• Re-weighting of the terms in the ELBO, and in particular only considering a fraction of the reconstruction term of the VAEs during training (e.g. by multiplying it by 0.3). In this way we can in fact help the model to focus on learning the SSM temporal dynamics as well <ref type="bibr" target="#b35">(Fraccaro et al., 2017)</ref>.</p><p>• Alternate the updates of VAE and SSM parameters, so that we make sure that in some updates the SSM is being optimized as well <ref type="bibr" target="#b35">(Fraccaro et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Summary and discussion</head><p>In this chapter we have introduced a family of sequential deep latent variable models for unsupervised learning of complex data distributions from large unlabelled datasets. In Sections 4.2 and 4.3 we have discussed recurrent neural networks and deep state-space models that, together with VAEs, form the building blocks for the more complex architectures presented in the rest of the chapter. The VAE-RNN model, introduced in Section 4.4.1, is a basic temporal extension of VAEs that uses an RNN to model the dependencies between latent variables at different time steps. In Section 4.4.2 we then argued that in some cases the VAE-RNN model is not enough to model accurately the temporal variability in the data, and defined the VRNN as a more expressive architecture that makes z t depend on z t-1 indirectly through the deterministic RNN state d t .</p><p>The SRNN model of Section 4.5 improves on the VRNN by adding a direct dependency between latent variables at consecutive time steps. The resulting architecture is then obtained stacking an RNN and a DSSM, and has a clear separation between deterministic and stochastic variables that is beneficial at inference time. We have then seen in Section 4.6 that using structured priors we can define architectures capable of learning disentangled representations that are more interpretable and data-efficient. In particular, we have constructed the KVAE model by using a</p><p>LGSSM to parameterize the prior of the same VAE repeated at each time step, and showed that we can leverage the exact inference and missing data imputation capabilities of the LGSSM. To deal with applications that require a high memory capacity we have shown in Section 4.7 that we can exploit external memory architectures, such as the DND memory used in the GTM-SM model. Due to the complexity of these models defining and training them can be challenging. In Section 4.8 we have then discussed some suggestions and training tricks that have proven useful when working with such models.</p><p>All the models presented in this chapter were obtained following the same very general procedure. We always start defining the joint distribution of the model in which we encode all the modelling assumptions that are suitable for the particular application at hand. To learn the parameters of the model using Maximum Likelihood, we need to compute the data log-likelihood by marginalizing the joint distribution over the latent variables. Since this integral is often intractable, we define a variational approximation over the latent variables of the model conditioned on the inputs and outputs, and use Jensen's inequality to derive the ELBO, the objective function used during training. When can design a variational distribution that better approximates the true posterior distribution by making use of the independence properties among the variables of the model. The scalability of the models is ensured using inference networks to define scalable and flexible variational approximations parameterized by deep neural networks. As both the generative model and the variational approximation are defined using neural network architectures, we can train their parameters jointly using stochastic gradient ascent, computing their gradients efficiently on GPU.</p><p>In the following chapters we will present in detail some of the models briefly described above, namely Stochastic recurrent neural networks <ref type="bibr">(Fraccaro et al., 2016c, Chapter 5)</ref>, Kalman variational auto-encoders <ref type="bibr">(Fraccaro et al., 2017, Chapter 6</ref>) and generative temporal models with spatial memory <ref type="bibr">(Fraccaro et al., 2018, Chapter 7)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Introduction</head><p>Recurrent neural networks (RNNs) are able to represent long-term dependencies in sequential data, by adapting and propagating a deterministic hidden (or latent) state <ref type="bibr" target="#b19">(Cho et al., 2014;</ref><ref type="bibr" target="#b63">Hochreiter and Schmidhuber, 1997)</ref>. There is recent evidence that when complex sequences such as speech and music are modeled, the performances of RNNs can be dramatically improved when uncertainty is included in their hidden states <ref type="bibr" target="#b7">(Bayer and Osendorfer, 2014;</ref><ref type="bibr" target="#b13">Boulanger-Lewandowski et al., 2012;</ref><ref type="bibr" target="#b21">Chung et al., 2015;</ref><ref type="bibr" target="#b32">Fabius and Amersfoort, 2014;</ref><ref type="bibr" target="#b42">Gan et al., 2015;</ref><ref type="bibr" target="#b57">Gu et al., 2015)</ref>. In this paper we add a new direction to the explorer's map of treating the hidden RNN states as uncertain paths, by including the world of state space models (SSMs) as an RNN layer. By cleanly delineating a SSM layer, certain independence properties of variables arise, which are beneficial for making efficient posterior inferences. The result is a generative model for sequential data, with a matching inference network that has its roots in variational auto-encoders (VAEs).</p><p>SSMs can be viewed as a probabilistic extension of RNNs, where the hidden states are assumed to be random variables. Although SSMs have an illustrious history <ref type="bibr" target="#b124">(Roweis and Ghahramani, 1999)</ref>, their stochasticity has limited their widespread use in the deep learning community, as inference can only be exact for two relatively simple classes of SSMs, namely hidden Markov models and linear Gaussian models, neither of which are well-suited to modeling long-term dependencies and complex probability distributions over high-dimensional sequences. On the other hand, modern RNNs rely on gated nonlinearities such as long short-term memory (LSTM) <ref type="bibr" target="#b63">(Hochreiter and Schmidhuber, 1997)</ref> cells or gated recurrent units (GRUs) <ref type="bibr" target="#b20">(Chung et al., 2014)</ref>, that let the deterministic hidden state of the RNN act as an internal memory for the model. This internal memory seems fundamental to capturing complex relationships in the data through a statistical model.</p><p>This paper introduces the stochastic recurrent neural network (SRNN) in Section 5.3. SRNNs combine the gated activation mechanism of RNNs with the stochastic states of SSMs, and are formed by stacking a RNN and a nonlinear SSM. The state transitions of the SSM are nonlinear and are parameterized by a neural network that also depends on the corresponding RNN hidden state. The SSM can therefore utilize long-term information captured by the RNN.</p><p>We use recent advances in variational inference to efficiently approximate the intractable posterior distribution over the latent states with an inference network <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref>. The form of our variational approximation is inspired by the independence properties of the true posterior distribution over the latent states of the model, and allows us to improve inference by conveniently using the information coming from the whole sequence at each time step. The posterior distribution over the latent states of the SRNN is highly non-stationary while we are learning the parameters of the model. To further improve the variational approximation, we show that we can construct the inference network so that it only needs to learn how to compute the mean of the variational approximation at each time step given the mean of the predictive prior distribution.</p><p>In Section 5.4 we test the performances of SRNN on speech and polyphonic music modeling tasks. SRNN improves the state of the art results on the Blizzard and TIMIT speech data sets by a large margin, and performs comparably to competing models on polyphonic music modeling. Finally, other models that extend RNNs by adding stochastic units will be reviewed and compared to</p><formula xml:id="formula_115">d t-1 d t d t+1 x t-1 x t x t+1 u t-1 u t u t+1 (a) RNN z t-1 z t z t+1 x t-1 x t x t+1 u t-1 u t u t+1 (b) SSM Figure 5</formula><p>.1: Graphical models to generate x 1:T with a recurrent neural network (RNN) and a state space model (SSM). Diamond-shaped units are used for deterministic states, while circles are used for stochastic ones. For sequence generation, like in a language model, one can use</p><formula xml:id="formula_116">u t = x t-1 .</formula><p>SRNN in Section 5.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Recurrent Neural Networks and State Space Models</head><p>Recurrent neural networks and state space models are widely used to model temporal sequences of vectors x 1:T = (x 1 , x 2 , . . . , x T ) that possibly depend on inputs u 1:T = (u 1 , u 2 , . . . , u T ). Both models rest on the assumption that the sequence x 1:t of observations up to time t can be summarized by a latent state d t or z t , which is deterministically determined (d t in a RNN) or treated as a random variable which is averaged away (z t in a SSM). The difference in treatment of the latent state has traditionally led to vastly different models: RNNs recursively compute d t = f (d t-1 , u t ) using a parameterized nonlinear function f , like a LSTM cell or a GRU. The RNN observation probabilities p(x t |d t ) are equally modeled with nonlinear functions. SSMs, like linear Gaussian or hidden Markov models, explicitly model uncertainty in the latent process through z 1:T . Parameter inference in a SSM requires z 1:T to be averaged out, and hence p(z t |z t-1 , u t ) and p(x t |z t ) are often restricted to the exponential family of distributions to make many existing approximate inference algorithms applicable. On the other hand, averaging a function over the deterministic path d 1:T in a RNN is a trivial operation. The striking similarity in factorization between these models is illustrated in Figures 5.1a and 5.1b.</p><p>Can we combine the best of both worlds, and make the stochastic state transitions of SSMs nonlinear whilst keeping the gated activation mechanism of RNNs? Below, we show that a more expressive model can be created by stacking a SSM on top of a RNN, and that by keeping them layered, the functional form of the true posterior distribution over z 1:T guides the design of a backward-recursive structured variational approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Stochastic Recurrent Neural Networks</head><p>We define a SRNN as a generative model p θ by temporally interlocking a SSM with a RNN, as illustrated in Figure <ref type="figure">5</ref>.2a. The joint probability of a single sequence and its latent states,</p><formula xml:id="formula_117">d t-1 d t d t+1 z t-1 z t z t+1 x t-1 x t x t+1 u t-1 u t u t+1 (a) Generative model p θ d t-1 d t d t+1 a t-1 a t a t+1 z t-1 z t z t+1 x t-1 x t x t+1 (b) Inference network q φ Figure 5</formula><p>.2: A SRNN as a generative model p θ for a sequence x 1:T . Posterior inference of z 1:T and d 1:T is done through an inference network q φ , which uses a backward-recurrent state a t to approximate the nonlinear dependence of z t on future observations x t:T and states d t:T ; see Equation (5.7).</p><p>assuming knowledge of the starting states z 0 = 0 and d 0 = 0, and inputs u 1:T , factorizes as</p><formula xml:id="formula_118">p θ (x 1:T , z 1:T , d 1:T |u 1:T , z 0 , d 0 ) = p θx (x 1:T |z 1:T , d 1:T ) p θz (z 1:T |d 1:T , z 0 ) p θ d (d 1:T |u 1:T , d 0 ) = T t=1 p θx (x t |z t , d t ) p θz (z t |z t-1 , d t ) p θ d (d t |d t-1 , u t ) .</formula><p>(5.1)</p><p>The SSM and RNN are further tied with skip-connections from d t to x t . The joint density in (5.1) is parameterized by θ = {θ x , θ z , θ d }, which will be adapted together with parameters φ of a so-called "inference network" q φ to best model N independently observed data sequences {x i 1:T i } N i=1 that are described by the log marginal likelihood or evidence</p><formula xml:id="formula_119">L(θ) = log p θ {x i 1:T i } | {u i 1:T i , z i 0 , d i 0 } N i=1 = i log p θ (x i 1:T i |u i 1:T i , z i 0 , d i 0 ) = i L i (θ) . (5.2)</formula><p>Throughout the paper, we omit superscript i when only one sequence is referred to, or when it is clear from the context. In each log likelihood term L i (θ) in (5.2), the latent states z 1:T and d 1:T were averaged out of (5.1). Integrating out d 1:T is done by simply substituting its deterministically obtained value, but z 1:T requires more care, and we return to it in Section 5.3.2. Following Figure <ref type="figure">5</ref>.2a, the states d 1:T are determined from d 0 and u 1:T through the recursion</p><formula xml:id="formula_120">d t = f θ d (d t-1 , u t ).</formula><p>In our implementation f θ d is a GRU network with parameters θ d . For later convenience we denote the value of d 1:T , as computed by application of f θ d , by d 1:T . Therefore Unlike the <ref type="bibr">VRNN (Chung et al., 2015)</ref>, z t directly depends on z t-1 , as it does in a SSM, via p θz (z t |z t-1 , d t ). This split makes a clear separation between the deterministic and stochastic parts of p θ ; the RNN remains entirely deterministic and its recurrent units do not depend on noisy samples of z t , while the prior over z t follows the Markov structure of SSMs. The split allows us to later mimic the structure of the posterior distribution over z 1:T and d 1:T in its approximation q φ . We let the prior transition distribution p θz (z</p><formula xml:id="formula_121">p θ d (d t |d t-1 , u t ) = δ(d t -d t ), i.e.</formula><formula xml:id="formula_122">t |z t-1 , d t ) = N (z t ; µ (p) t , v<label>(p)</label></formula><p>t ) be a Gaussian with a diagonal covariance matrix, whose mean and log-variance are parameterized by neural networks that depend on z t-1 and d t ,</p><formula xml:id="formula_123">µ (p) t = NN (p) 1 (z t-1 , d t ) , log v (p) t = NN (p) 2 (z t-1 , d t ) , (5.3)</formula><p>where NN denotes a neural network. Parameters θ z denote all weights of NN 2 , which are two-layer feed-forward networks in our implementation. Similarly, the parameters of the emission distribution p θx (x t |z t , d t ) depend on z t and d t through a similar neural network that is parameterized by θ x .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Variational inference for the SRNN</head><p>The stochastic variables z 1:T of the nonlinear SSM cannot be analytically integrated out to obtain L(θ) in (5.2). Instead of maximizing L with respect to θ, we maximize a variational evidence lower bound (ELBO) F(θ, φ) = i F i (θ, φ) ≤ L(θ) with respect to both θ and the variational parameters φ <ref type="bibr" target="#b66">(Jordan et al., 1999)</ref>. The ELBO is a sum of lower bounds F i (θ, φ) ≤ L i (θ), one for each sequence i,</p><formula xml:id="formula_124">F i (θ, φ) = q φ (z 1:T , d 1:T |x 1:T , A) log p θ (x 1:T , z 1:T , d 1:T |A) q φ (z 1:T , d 1:T |x 1:T , A) dz 1:T dd 1:T ,<label>(5.4)</label></formula><p>where A = {u 1:T , z 0 , d 0 } is a notational shorthand. Each sequence's approximation q φ shares parameters φ with all others, to form the auto-encoding variational Bayes inference network or variational auto encoder (VAE) <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> shown in Figure <ref type="figure">5</ref>.2b. Maximizing F(θ, φ) -which we call "training" the neural network architecture with parameters θ and φ -is done by stochastic gradient ascent, and in doing so, both the posterior and its approximation q φ change simultaneously. All the intractable expectations in (5.4) would typically be approximated by sampling, using the reparameterization trick <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> or control variates <ref type="bibr" target="#b110">(Paisley et al., 2012)</ref> to obtain lowvariance estimators of its gradients. We use the reparameterization trick in our implementation.</p><p>Iteratively maximizing F over θ and φ separately would yield an expectation maximization-type algorithm, which has formed a backbone of statistical modeling for many decades <ref type="bibr" target="#b25">(Dempster et al., 1977)</ref>. The tightness of the bound depends on how well we can approximate the i = 1, . . . , N factors p θ (z i 1:T i , d i 1:T i |x i 1:T i , A i ) that constitute the true posterior over all latent variables with their corresponding factors q φ (z i</p><formula xml:id="formula_125">1:T i , d i 1:T i |x i 1:T i , A i ).</formula><p>In what follows, we show how q φ could be judiciously structured to match the posterior factors.</p><p>We add initial structure to q φ by noticing that the prior p θ d (d 1:T |u 1:T , d 0 ) in the generative model is a delta function over d 1:T , and so is the posterior p θ (d 1:T |x 1:T , u 1:T , d 0 ). Consequently, we let the inference network use exactly the same deterministic state setting d 1:T as that of the generative model, and we decompose it as</p><formula xml:id="formula_126">q φ (z 1:T , d 1:T |x 1:T , u 1:T , z 0 , d 0 ) = q φ (z 1:T |d 1:T , x 1:T , z 0 ) q(d 1:T |x 1:T , u 1:T , d 0 ) = p θ d (d 1:T |u 1:T ,d 0 )</formula><p>.</p><p>(5.5)</p><p>This choice exactly approximates one delta-function by itself, and simplifies the ELBO by letting them cancel out. By further taking the outer average in (5.4), one obtains</p><formula xml:id="formula_127">F i (θ, φ) = E q φ log p θ (x 1:T |z 1:T , d 1:T ) -KL q φ (z 1:T | d 1:T , x 1:T , z 0 ) p θ (z 1:T | d 1:T , z 0 ) , (5.6)</formula><p>which still depends on θ d , u 1:T and d 0 via d 1:T . The first term is an expected log likelihood under q φ (z 1:T | d 1:T , x 1:T , z 0 ), while KL denotes the Kullback-Leibler divergence between two distributions.</p><p>Having stated the second factor in (5.5), we now turn our attention to parameterizing the first factor in (5.5) to resemble its posterior equivalent, by exploiting the temporal structure of p θ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Exploiting the temporal structure</head><p>The true posterior distribution of the stochastic states z 1:T , given both the data and the deterministic states d 1:T , factorizes as p θ (z</p><formula xml:id="formula_128">1:T |d 1:T , x 1:T , u 1:T , z 0 ) = t p θ (z t |z t-1 , d t:T , x t:T ).</formula><p>This can be verified by considering the conditional independence properties of the graphical model in Figure <ref type="figure">5</ref>.2a using d-separation <ref type="bibr" target="#b44">(Geiger et al., 1990)</ref>. This shows that, knowing z t-1 , the posterior distribution of z t does not depend on the past outputs and deterministic states, but only on the present and future ones; this was also noted in <ref type="bibr" target="#b76">(Krishnan et al., 2015)</ref>. Instead of factorizing q φ as a mean-field approximation across time steps, we keep the structured form of the posterior factors, including z t 's dependence on z t-1 , in the variational approximation</p><formula xml:id="formula_129">q φ (z 1:T |d 1:T , x 1:T , z 0 ) = t q φ (z t |z t-1 , d t:T , x t:T ) = t q φz (z t |z t-1 , a t = g φa (a t+1 , [d t , x t ])) ,<label>(5.7)</label></formula><p>where [d t , x t ] is the concatenation of the vectors d t and x t . The graphical model for the inference network is shown in Figure <ref type="figure">5</ref>.2b. Apart from the direct dependence of the posterior approximation at time t on both d t:T and x t:T , the distribution also depends on d 1:t-1 and x 1:t-1 through z t-1 . We mimic each posterior factor's nonlinear long-term dependence on d t:T and x t:T through a backward-recurrent function g φa , shown in (5.7), which we will return to in greater detail in Section 5.3.3. The inference network in Figure <ref type="figure">5</ref>.2b is therefore parameterized by φ = {φ z , φ a } and θ d .</p><p>In (5.7) all time steps are taken into account when constructing the variational approximation at time t; this can therefore be seen as a smoothing problem. In our experiments we also consider filtering, where only the information up to time t is used to define q φ (z t |z t-1 , d t , x t ). As the parameters φ are shared across time steps, we can easily handle sequences of variable length in both cases.</p><p>As both the generative model and inference network factorize over time steps in (5.1) and (5.7), the ELBO in (5.6) separates as a sum over the time steps</p><formula xml:id="formula_130">F i (θ, φ) = t E q * φ (z t-1 ) E q φ (zt|z t-1 , d t:T ,x t:T ) log p θ (x t |z t , d t ) + -KL q φ (z t |z t-1 , d t:T , x t:T ) p θ (z t |z t-1 , d t ) , (5.8)</formula><p>where q * φ (z t-1 ) denotes the marginal distribution of z t-1 in the variational approximation to the posterior q φ (z 1:t-1 | d 1:T , x 1:T , z 0 ), given by</p><formula xml:id="formula_131">q * φ (z t-1 ) = q φ (z 1:t-1 | d 1:T , x 1:T , z 0 ) dz 1:t-2 = E q * φ (z t-2 ) q φ (z t-1 |z t-2 , d t-1:T , x t-1:T ) .</formula><p>(5.9)</p><p>We can interpret (5.9) as having a VAE at each time step t, with the VAE being conditioned on the past through the stochastic variable z t-1 . To compute (5.8), the dependence on z t-1 needs to be integrated out, using our posterior knowledge at time t -1 which is given by q * φ (z t-1 ). We approximate the outer expectation in (5.8) using a Monte Carlo estimate, as samples from q * φ (z t-1 ) can be efficiently obtained by ancestral sampling. The sequential formulation of the inference model in (5.7) allows such samples to be drawn and reused, as given a sample z</p><formula xml:id="formula_132">(s) t-2 from q * φ (z t-2 ), a sample z (s) t-1 from q φ (z t-1 |z (s)</formula><p>t-2 , d t-1:T , x t-1:T ) will be distributed according to q * φ (z t-1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Parameterization of the inference network</head><p>The variational distribution q φ (z t |z t-1 , d t:T , x t:T ) needs to approximate the dependence of the true posterior p θ (z t |z t-1 , d t:T , x t:T ) on d t:T and x t:T , and as alluded to in (5.7), this is done by running a RNN with inputs d t:T and x t:T backwards in time. Specifically, we initialize the hidden state of the backward-recursive RNN in Figure <ref type="figure">5</ref>.2b as a T +1 = 0, and recursively compute a t = g φa (a t+1 , [ d t , x t ]). The function g φa represents a recurrent neural network with, for example, LSTM or GRU units. Each sequence's variational approximation factorizes over time with q φ (z 1:T |d 1:T , x 1:T , z 0 ) = t q φz (z t |z t-1 , a t ), as shown in (5.7). We let q φz (z t |z t-1 , a t ) be a Gaussian with diagonal covariance, whose mean and the log-variance are parameterized with φ z as</p><formula xml:id="formula_133">µ (q) t = NN (q) 1 (z t-1 , a t ) , log v (q) t = NN (q) 2 (z t-1 , a t ) .</formula><p>(5.10)</p><p>Instead of smoothing, we can also do filtering by using a neural network to approximate the dependence of the true posterior p θ (z t |z t-1 , d t , x t ) on d t and x t , through for instance a t = NN (a) (d t , x t ).</p><p>Improving the posterior approximation. In our experiments we found that during training, the parameterization introduced in (5.10) can lead to small values of the KL term KL(q φ (z t |z t-1 , a t ) p θ (z t |z t-1 , d t )) in the ELBO in (5.8). This happens when g φ in the inference network does not rely on the information propagated back from future outputs in a t , but it is mostly using the hidden state d t to imitate the behavior of the prior. The inference network could therefore get stuck by trying to optimize the ELBO through sampling from the prior of the model, making the variational approximation to the posterior useless. To overcome this issue, we directly include some knowledge of the predictive prior dynamics in the parameterization of the inference network, using our approximation of the posterior distribution q * φ (z t-1 ) over the previous latent states. In the spirit of sequential Monte Carlo methods <ref type="bibr" target="#b28">(Doucet et al., 2001)</ref>, we improve the parameterization of q φ (z t |z t-1 , a t ) by using q * φ (z t-1 ) from (5.9). As we are constructing the variational distribution sequentially, we approximate the predictive prior mean, i.e. our "best guess" on the prior dynamics of z t , as</p><formula xml:id="formula_134">µ (p) t = NN (p) 1 (z t-1 , d t ) p(z t-1 |x 1:T ) dz t-1 ≈ NN (p) 1 (z t-1 , d t ) q * φ (z t-1 ) dz t-1 ,<label>(5.11)</label></formula><p>where we used the parameterization of the prior distribution in (5.3). We estimate the integral required to compute µ (p)</p><p>t by reusing the samples that were needed for the Monte Carlo estimate</p><p>Algorithm 2 Inference of SRNN with Res q parameterization from (5.12).</p><p>1: inputs: d 1:T and a 1:T 2: initialize z 0 3: for t = 1 to T do 4:</p><formula xml:id="formula_135">µ (p) t = NN (p) 1 (z t-1 , d t ) 5: µ (q) t = µ (p) t + NN (q) 1 (z t-1 , a t ) 6: log v (q) t = NN (q) 2 (z t-1 , a t ) 7: z t ∼ N (z t ; µ (q) t , v<label>(q)</label></formula><p>t ) 8: end for of the ELBO in (5.8). This predictive prior mean can then be used in the parameterization of the mean of the variational approximation q φ (z t |z t-1 , a t ),</p><formula xml:id="formula_136">µ (q) t = µ (p) t + NN (q) 1 (z t-1 , a t ) ,</formula><p>(5.12)</p><p>and we refer to this parameterization as Res q in the results in Section 5.4. Rather than directly learning µ (q)</p><p>t , we learn the residual between µ (p)</p><p>t and µ (q)</p><p>t . It is straightforward to show that with this parameterization the KL-term in (5.8) will not depend on µ</p><formula xml:id="formula_137">(p) t , but only on NN (q) 1 (z t-1 , a t ).</formula><p>Learning the residual improves inference, making it seemingly easier for the inference network to track changes in the generative model while the model is trained, as it will only have to learn how to "correct" the predictive prior dynamics by using the information coming from d t:T and x t:T . We did not see any improvement in results by parameterizing log v (q) t in a similar way. The inference procedure of SRNN with Res q parameterization for one sequence is summarized in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>In this section the SRNN is evaluated on the modeling of speech and polyphonic music data, as they have shown to be difficult to model without a good representation of the uncertainty in the latent states <ref type="bibr" target="#b7">Bayer and Osendorfer, 2014;</ref><ref type="bibr" target="#b21">Chung et al., 2015;</ref><ref type="bibr" target="#b32">Fabius and Amersfoort, 2014;</ref><ref type="bibr" target="#b42">Gan et al., 2015;</ref><ref type="bibr" target="#b57">Gu et al., 2015.</ref> We test SRNN on the Blizzard (King and <ref type="bibr" target="#b71">Karaiskos, 2013)</ref> and TIMIT raw audio data sets (Table <ref type="table">5</ref>.1) used in <ref type="bibr" target="#b21">(Chung et al., 2015)</ref>. The preprocessing of the data sets and the testing performance measures are identical to those reported in <ref type="bibr" target="#b21">(Chung et al., 2015)</ref>. Blizzard is a dataset of 300 hours of English, spoken by a single female speaker. TIMIT is a dataset of 6300 English sentences read by 630 speakers. As done in <ref type="bibr" target="#b21">(Chung et al., 2015)</ref>, for Blizzard we report the average log-likelihood for half-second sequences and for TIMIT we report the average log likelihood per sequence for the test set sequences. Note that the sequences in the TIMIT test set are on average 3.1s long, and therefore 6 times longer than those in Blizzard. For the raw audio datasets we use a fully factorized Gaussian output distribution. Additionally, we test SRNN for modeling sequences of polyphonic music (Table <ref type="table">5</ref>.2), using the four data sets of MIDI songs introduced in (Boulanger- <ref type="bibr" target="#b13">Lewandowski et al., 2012)</ref>. Each data set contains more than 7 hours of polyphonic music of varying complexity: folk tunes (Nottingham data set), the four-part chorales by J. S. Bach (JSB chorales), orchestral music (MuseData) and classical piano music (Piano-midi.de). For polyphonic music we use a Bernoulli output distribution to model the binary sequences of piano notes. In our experiments we set u t = x t-1 , but u t could also be used to represent additional input information to the model.</p><p>All models where implemented using Theano <ref type="bibr" target="#b5">(Bastien et al., 2012)</ref>, Lasagne <ref type="bibr" target="#b27">(Dieleman et al., 2015)</ref> and Parmesan<ref type="foot" target="#foot_8">foot_8</ref> . Training using a NVIDIA Titan X GPU took around 1.5 hours for TIMIT, 18 hours for Blizzard, less than 15 minutes for the JSB chorales and Piano-midi.de data sets, and around 30 minutes for the Nottingham and MuseData data sets. To reduce the computational requirements we use only 1 sample to approximate all the intractable expectations in the ELBO (notice that the KL term can be computed analytically). Further implementation and experimental details can be found in the Supplementary Material.</p><p>Blizzard and TIMIT. Table <ref type="table">5</ref>.1 compares the average log-likelihood per test sequence of SRNN to the results from <ref type="bibr" target="#b21">(Chung et al., 2015)</ref>. For RNNs and VRNNs the authors of <ref type="bibr" target="#b21">(Chung et al., 2015)</ref> test two different output distributions, namely a Gaussian distribution (Gauss) and a Gaussian Mixture Model (GMM). VRNN-I differs from the VRNN in that the prior over the latent variables is independent across time steps, and it is therefore similar to STORN <ref type="bibr" target="#b7">(Bayer and Osendorfer, 2014)</ref>. For SRNN we compare the smoothing and filtering performance (denoted as smooth and filt in Table <ref type="table">5</ref>.1), both with the residual term from (5.12) and without it (5.10) (denoted as Res q if present). We prefer to only report the more conservative evidence lower bound for SRNN, as the approximation of the log-likelihood using standard importance sampling is known to be difficult to compute accurately in the sequential setting <ref type="bibr" target="#b28">(Doucet et al., 2001)</ref>. We see from Table <ref type="table">5</ref>.1 that SRNN outperforms all the competing methods for speech modeling. As the test sequences in TIMIT are on average more than 6 times longer than the ones for Blizzard, the results obtained with SRNN for TIMIT are in line with those obtained for Blizzard. The VRNN, which performs well when the voice of the single speaker from Blizzard is modeled, seems to encounter difficulties when modeling the 630 speakers in the TIMIT data set. As expected, for SRNN the variational approximation that is obtained when future information is also used (smoothing) is better than the one obtained by filtering. Learning the residual between the prior mean and the mean of the variational approximation, given in (5.12), further improves the performance in 3 out of 4 cases.</p><p>In the first two lines of Figure <ref type="figure">5</ref>.3 we plot two raw signals from the Blizzard test set and the average KL term between the variational approximation and the prior distribution. We see that the KL term increases whenever there is a transition in the raw audio signal, meaning that the inference network is using the information coming from the output symbols to improve inference. Finally, the reconstructions of the output mean and log-variance in the last two lines of Figure <ref type="figure">5</ref>.3 look consistent with the original signal. Polyphonic music. Table <ref type="table">5</ref>.2 compares the average log-likelihood on the test sets obtained with SRNN and the models introduced in <ref type="bibr" target="#b7">(Bayer and Osendorfer, 2014;</ref><ref type="bibr" target="#b13">Boulanger-Lewandowski et al., 2012;</ref><ref type="bibr" target="#b42">Gan et al., 2015;</ref><ref type="bibr" target="#b57">Gu et al., 2015)</ref>. As done for the speech data, we prefer to report the more conservative estimate of the ELBO in Table <ref type="table">5</ref>.2, rather than approximating the log-likelihood with importance sampling as some of the other methods do. We see that SRNN performs comparably to other state of the art methods in all four data sets. We report the results using smoothing and learning the residual between the mean of the predictive prior and the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Blizzard TIMIT</p><formula xml:id="formula_138">SRNN (smooth+Resq) ≥11991 ≥ 60550 SRNN (smooth) ≥ 10991 ≥ 59269 SRNN (filt+Res q ) ≥ 10572 ≥ 52126 SRNN (filt) ≥ 10846 ≥ 50524 VRNN-GMM ≥ 9107 ≥ 28982 ≈ 9392 ≈ 29604 VRNN-Gauss ≥ 9223 ≥ 28805 ≈ 9516 ≈ 30235 VRNN-I-Gauss ≥ 8933 ≥ 28340 ≈ 9188 ≈ 29639 RNN-GMM 7413 26643 RNN-Gauss 3539 -1900</formula><p>Table <ref type="table">5</ref>.1: Average log-likelihood per sequence on the test sets. For TIMIT the average test set length is 3.1s, while the Blizzard sequences are all 0.5s long. The non-SRNN results are reported as in <ref type="bibr" target="#b21">(Chung et al., 2015)</ref>. Smooth: g φa is a GRU running backwards; filt: g φa is a feed-forward network; Res q : parameterization with residual in (5.12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>Nottingham JSB chorales MuseData Piano-midi.de SRNN (smooth+Res q ) ≥ -2.94 ≥ -4.74 ≥ -6.28 ≥ -8.  <ref type="bibr" target="#b42">(Gan et al., 2015)</ref>, NASMC from <ref type="bibr" target="#b57">(Gu et al., 2015)</ref>, STORN from <ref type="bibr" target="#b7">(Bayer and Osendorfer, 2014)</ref>, <ref type="bibr">RNN-NADE and RNN from (Boulanger-Lewandowski et al., 2012)</ref>.</p><p>mean of the variational approximation, but the performances using filtering and directly learning the mean of the variational approximation are now similar. We believe that this is due to the small amount of data and the fact that modeling MIDI music is much simpler than modeling raw speech signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Related work</head><p>A number of works have extended RNNs with stochastic units to model motion capture, speech and music data <ref type="bibr" target="#b7">(Bayer and Osendorfer, 2014;</ref><ref type="bibr" target="#b21">Chung et al., 2015;</ref><ref type="bibr" target="#b32">Fabius and Amersfoort, 2014;</ref><ref type="bibr" target="#b42">Gan et al., 2015;</ref><ref type="bibr" target="#b57">Gu et al., 2015)</ref>. The performances of these models are highly dependent on how the dependence among stochastic units is modeled over time, on the type of interaction between stochastic units and deterministic ones, and on the procedure that is used to evaluate the typically intractable log likelihood. Figure <ref type="figure">5</ref>.4 highlights how SRNN differs from some of these works. </p><formula xml:id="formula_139">d t d t-1 x t u t z t (a) STORN z t-1 d t d t-1 z t x t u t (b) VRNN z t-1 z t x t u t (c) Deep Kalman Filter</formula><p>Figure <ref type="figure">5</ref>.4: Generative models of x 1:T that are related to SRNN. For sequence modeling it is typical to set u t = x t-1 .</p><p>In STORN <ref type="bibr" target="#b7">(Bayer and Osendorfer, 2014</ref>) (Figure <ref type="figure">5</ref>.4a) and DRAW <ref type="bibr" target="#b56">(Gregor et al., 2015)</ref> the stochastic units at each time step have an isotropic Gaussian prior and are independent between time steps. The stochastic units are used as an input to the deterministic units in a RNN. As in our work, the reparameterization trick <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> is used to optimize an ELBO.</p><p>The authors of the VRNN (Chung et al., 2015) (Figure <ref type="figure">5</ref>.4b) note that it is beneficial to add information coming from the past states to the prior over latent variables z t . The VRNN lets the prior p θz (z t |d t ) over the stochastic units depend on the deterministic units d t , which in turn depend on both the deterministic and the stochastic units at the previous time step through the recursion</p><formula xml:id="formula_140">d t = f (d t-1 , z t-1 , u t ).</formula><p>The SRNN differs by clearly separating the deterministic and stochastic part, as shown in Figure <ref type="figure">5</ref>.2a. The separation of deterministic and stochastic units allows us to improve the posterior approximation by doing smoothing, as the stochastic units still depend on each other when we condition on d 1:T . In the VRNN, on the other hand, the stochastic units are conditionally independent given the states d 1:T . Because the inference and generative networks in the VRNN share the deterministic units, the variational approximation would not improve by making it dependent on the future through a t , when calculated with a backward GRU, as we do in our model. Unlike STORN, DRAW and VRNN, the SRNN separates the "noisy" stochastic units from the deterministic ones, forming an entire layer of interconnected stochastic units. We found in practice that this gave better performance and was easier to train. The works by <ref type="bibr" target="#b2">(Archer et al., 2015;</ref><ref type="bibr" target="#b76">Krishnan et al., 2015)</ref> (Figure <ref type="figure">5</ref>.4c) show that it is possible to improve inference in SSMs by using ideas from VAEs, similar to what is done in the stochastic part (the top layer) of SRNN. Towards the periphery of related works, <ref type="bibr" target="#b57">(Gu et al., 2015)</ref> approximates the log likelihood of a SSM with sequential Monte Carlo, by learning flexible proposal distributions parameterized by deep networks, while <ref type="bibr" target="#b42">(Gan et al., 2015)</ref> uses a recurrent model with discrete stochastic units that is optimized using the NVIL algorithm <ref type="bibr" target="#b102">(Mnih and Gregor, 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Conclusion</head><p>This work has shown how to extend the modeling capabilities of recurrent neural networks by combining them with nonlinear state space models. Inspired by the independence properties of the intractable true posterior distribution over the latent states, we designed an inference network in a principled way. The variational approximation for the stochastic layer was improved by using the information coming from the whole sequence and by using the Res q parameterization to help the inference network to track the non-stationary posterior. SRNN achieves state of the art performances on the Blizzard and TIMIT speech data set, and performs comparably to competing methods for polyphonic music modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental setup</head><p>Blizzard and TIMIT. The sampling rate is 16KHz and the raw audio signal is normalized using the global mean and standard deviation of the traning set. We split the raw audio signals in chunks of 2 seconds. The waveforms are then divided into non-overlapping vectors of size 200. The RNN thus runs for 160 steps<ref type="foot" target="#foot_9">foot_9</ref> . The model is trained to predict the next vector (x t ) given the current one (u t ). During training we use backpropagation through time (BPTT) for 0.5 seconds, i.e we have 4 updates for each 2 seconds of audio. For the first 0.5 second we initialize hidden units with zeros and for the subsequent 3 chunks we use the previous hidden states as initialization.</p><p>For Blizzard we split the data using 90% for training, 5% for validation and 5% for testing. For testing we report the average log-likelihood per 0.5s sequences. For TIMIT we use the predefined test set for testing and split the rest of the data into 95% for training and 5% for validation. The training and testing setup are identical to the ones for Blizzard. For TIMIT the test sequences have variable length and are on average 3.1s, i.e. more than 6 times longer than Blizzard.</p><p>We model the output using a fully factorized Gaussian distribution for p θx (x t |z t , d t ). The deterministic RNNs use GRUs <ref type="bibr" target="#b20">(Chung et al., 2014)</ref>, with 2048 units for Blizzard and 1024 units for TIMIT. In both cases, z t is a 256-dimensional vector. All the neural networks have 2 layers, with 1024 units for Blizzard and 512 for TIMIT, and use leaky rectified nonlinearities with leakiness 1 3 and clipped at ±3. In both generative and inference models we share a neural network to extract features from the raw audio signal. The sizes of the models were chosen to roughly match the number of parameters used in <ref type="bibr" target="#b21">(Chung et al., 2015)</ref>. In all experiments it was fundamental to gradually introduce the KL term in the ELBO, as shown in <ref type="bibr" target="#b14">(Bowman et al., 2015;</ref><ref type="bibr">Sønderby et al., 2016a;</ref><ref type="bibr" target="#b119">Raiko et al., 2007)</ref>. We therefore multiply a temperature β to the KL term, i.e. βKL, and linearly increase β from 0.2 to 1 in the beginning of training (for Blizzard we increase it by 0.0001 after each update, while for TIMIT by 0.0003). In both data sets we used the ADAM optimizer <ref type="bibr" target="#b75">(Kingma and Ba, 2014)</ref>. For Blizzard we use a learning rate of 0.0003 and batch size of 128, for TIMIT they are 0.001 and 64 respectively. Polyphonic music. We use the same model architecture as in Section 5.4, except for the output Bernoulli variables used to model the active notes. We reduced the number of parameters in the model to 300 deterministic hidden units for the GRU networks, and 100 stochastic units whose distributions are parameterized with neural networks with 1 layer of 500 units. Abstract: This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Introduction</head><p>From the earliest stages of childhood, humans learn to represent high-dimensional sensory input to make temporal predictions. From the visual image of a moving tennis ball, we can imagine its trajectory, and prepare ourselves in advance to catch it. Although the act of recognising the tennis ball is seemingly independent of our intuition of Newtonian dynamics (L. G. <ref type="bibr" target="#b78">Ungerleider and L. G. Haxby, 1994)</ref>, very little of this assumption has yet been captured in the end-to-end models that presently mark the path towards artificial general intelligence. Instead of basing inference on any abstract grasp of dynamics that is learned from experience, current successes are autoregressive: to imagine the tennis ball's trajectory, one forward-generates a frame-by-frame rendering of the full sensory input <ref type="bibr" target="#b18">(Chiappa et al., 2017;</ref><ref type="bibr" target="#b33">Finn et al., 2016;</ref><ref type="bibr" target="#b108">Oh et al., 2015;</ref><ref type="bibr" target="#b114">Patraucean et al., 2015;</ref><ref type="bibr" target="#b138">Srivastava et al., 2015;</ref><ref type="bibr" target="#b140">Sun et al., 2016)</ref>.</p><p>To disentangle two latent representations, an object's, and that of its dynamics, this paper introduces Kalman variational auto-encoders (KVAEs), a model that separates an intuition of dynamics from an object recognition network (section 6.3). At each time step t, a variational auto-encoder <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> compresses high-dimensional visual stimuli x t into latent encodings a t . The temporal dynamics in the learned a t -manifold are modelled with a linear Gaussian state space model that is adapted to handle complex dynamics (despite the linear relations among its states z t ). The parameters of the state space model are adapted at each time step, and non-linearly depend on past a t 's via a recurrent neural network. Exact posterior inference for the linear Gaussian state space model can be performed with the Kalman filtering and smoothing algorithms, and is used for imputing missing data, for instance when we imagine the trajectory of a bouncing ball after observing it in initial and final video frames (section 6.4). The separation between recognition and dynamics model allows for missing data imputation to be done via a combination of the latent states z t of the model and its encodings a t only, without having to forward-sample high-dimensional images x t in an autoregressive way. KVAEs are tested on videos of a variety of simulated physical systems in section 6.5: from raw visual stimuli, it "end-to-end" learns the interplay between the recognition and dynamics components. As KVAEs can do smoothing, they outperform an array of methods in generative and missing data imputation tasks (section 6.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Background</head><p>Linear Gaussian state space models. Linear Gaussian state space models (LGSSMs) are widely used to model sequences of vectors a = a</p><formula xml:id="formula_141">1:T = [a 1 , .., a T ].</formula><p>LGSSMs model temporal correlations through a first-order Markov process on latent states z = [z 1 , .., z T ], which are potentially further controlled with external inputs u = [u 1 , .., u T ], through the Gaussian distributions</p><formula xml:id="formula_142">p γt (z t |z t-1 , u t ) = N (z t ; A t z t-1 + B t u t , Q) (6.1) p γt (a t |z t ) = N (a t ; C t z t , R) . (6.2) Matrices γ t = [A t , B t , C t ]</formula><p>are the state transition, control and emission matrices at time t. Q and R are the covariance matrices of the process and measurement noise respectively. With a starting state z 1 ∼ N (z 1 ; 0, Σ), the joint probability distribution of the LGSSM is given by where γ = [γ 1 , .., γ T ].</p><formula xml:id="formula_143">p γ (a, z|u) = p γ (a|z) p γ (z|u) = T t=1 p γt (a t |z t ) • p(z 1 ) T t=2 p γt (z t |z t-1 , u t ) ,<label>(6.3)</label></formula><formula xml:id="formula_144">z t-1 z t z t+1 a t-1 a t a t+1 x t-1 x t x t+1 u t-1 u t u t+1</formula><p>LGSSMs have very appealing properties that we wish to exploit: the filtered and smoothed posteriors p(z t |a 1:t , u 1:t ) and p(z t |a, u) can be computed exactly with the classical Kalman filter and smoother algorithms, and provide a natural way to handle missing data.</p><p>Variational auto-encoders. A variational auto-encoder (VAE) <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref> defines a deep generative model p θ (x t , a t ) = p θ (x t |a t )p(a t ) for data x t by introducing a latent encoding a t . Given a likelihood p θ (x t |a t ) and a typically Gaussian prior p(a t ), the posterior p θ (a t |x t ) represents a stochastic map from x t to a t 's manifold. As this posterior is commonly analytically intractable, VAEs approximate it with a variational distribution q φ (a t |x t ) that is parameterized by φ. The approximation q φ is commonly called the recognition, encoding, or inference network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Kalman Variational Auto-Encoders</head><p>The useful information that describes the movement and interplay of objects in a video typically lies in a manifold that has a smaller dimension than the number of pixels in each frame. In a video of a ball bouncing in a box, like Atari's game Pong, one could define a one-to-one mapping from each of the high-dimensional frames x = [x 1 , .., x T ] into a two-dimensional latent space that represents the position of the ball on the screen. If the position was known for consecutive time steps, for a set of videos, we could learn the temporal dynamics that govern the environment. From a few new positions one might then infer where the ball will be on the screen in the future, and then imagine the environment with the ball in that position.</p><p>The Kalman variational auto-encoder (KVAE) is based on the notion described above. To disentangle recognition and spatial representation, a sensory input x t is mapped to a t (VAE), a variable on a low-dimensional manifold that encodes an object's position and other visual properties. In turn, a t is used as a pseudo-observation for the dynamics model (LGSSM). x t represents a frame of a video 1 x = [x 1 , .., x T ] of length T . Each frame is encoded into a point a t on a low-dimensional manifold, so that the KVAE contains T separate VAEs that share the same decoder p θ (x t |a t ) and encoder q φ (a t |x t ), and depend on each other through a time-dependent prior over a = [a 1 , .., a T ]. This is illustrated in figure <ref type="figure" target="#fig_22">6</ref>.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Generative model</head><p>We assume that a acts as a latent representation of the whole video, so that the generative model of a sequence factorizes as p θ (x|a) = T t=1 p θ (x t |a t ). In this paper p θ (x t |a t ) is a deep neural network parameterized by θ, that emits either a factorized Gaussian or Bernoulli probability vector depending on the data type of x t . We model a with a LGSSM, and following (6.3), its prior distribution is p γ (a|u) = p γ (a|z) p γ (z|u) dz , (6.4) so that the joint density for the KVAE factorizes as p(x, a, z|u) = p θ (x|a) p γ (a|z) p γ (z|u). A</p><p>LGSSM forms a convenient back-bone to a model, as the filtered and smoothed distributions p γ (z t |a 1:t , u 1:t ) and p γ (z t |a, u) can be obtained exactly. Temporal reasoning can be done in the latent space of z t 's and via the latent encodings a, and we can do long-term predictions without having to auto-regressively generate high-dimensional images x t . Given a few frames, and hence their encodings, one could "remain in latent space" and use the smoothed distributions to impute missing frames. Another advantage of using a to separate the dynamics model from x can be seen by considering the emission matrix C t . Inference in the LGSSM requires matrix inverses, and using it as a model for the prior dynamics of a t allows the size of C t to remain small, and not scale with the number of pixels in x t . While the LGSSM's process and measurement noise in (6.1) are typically formulated with full covariance matrices <ref type="bibr" target="#b124">(Roweis and Ghahramani, 1999)</ref>, we will consider them as isotropic in a KVAE, as a t act as a prior in a generative model that includes these extra degrees of freedom.</p><p>What happens when a ball bounces against a wall, and the dynamics on a t are not linear any more? Can we still retain a LGSSM backbone? We will incorporate nonlinearities into the LGSSM by regulating γ t from outside the exact forward-backward inference chain. We revisit this central idea at length in section 6.3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Learning and inference for the KVAE</head><p>We learn θ and γ from a set of example sequences {x (n) } by maximizing the sum of their respective log likelihoods L = n log p θγ (x (n) |u (n) ) as a function of θ and γ. For simplicity in the exposition we restrict our discussion below to one sequence, and omit the sequence index n. The log likelihood or evidence is an intractable average over all plausible settings of a and z, and exists as the denominator in Bayes' theorem when inferring the posterior p(a, z|x, u). A more tractable approach to both learning and inference is to introduce a variational distribution q(a, z|x, u) that of high dimensional data.</p><p>approximates the posterior. The evidence lower bound (ELBO) F is log p(x|u) = log p(x, a, z|u)</p><p>≥ E q(a,z|x,u) log p θ (x|a)p γ (a|z)p γ (z|u) q(a, z|x, u) = F(θ, γ, φ) , (6.5) and a sum of F's is maximized instead of a sum of log likelihoods. The variational distribution q depends on φ, but for the bound to be tight we should specify q to be equal to the posterior distribution that only depends on θ and γ. Towards this aim we structure q so that it incorporates the exact conditional posterior p γ (z|a, u), that we obtain with Kalman smoothing, as a factor of γ: q(a, z|x, u) = q φ (a|x) p γ (z|a, u) = T t=1 q φ (a t |x t ) p γ (z|a, u) . (6.6)</p><p>The benefit of the LGSSM backbone is now apparent. We use a "recognition model" to encode each x t using a non-linear function, after which exact smoothing is possible. In this paper q φ (a t |x t ) is a deep neural network that maps x t to the mean and the diagonal covariance of a Gaussian distribution. As explained in section 6.4, this factorization allows us to deal with missing data in a principled way. Using (6.6), the ELBO in (6.5) becomes</p><formula xml:id="formula_145">F(θ, γ, φ) = E q φ (a|x) log p θ (x|a) q φ (a|x) + E pγ (z|a,u) log p γ (a|z)p γ (z|u) p γ (z|a, u) . (6.7)</formula><p>The lower bound in (6.7) can be estimated using Monte Carlo integration with samples { a (i) , z (i) } I i=1 drawn from q, F(θ, γ, φ) = 1 I i log p θ (x| a (i) ) + log p γ ( a (i) , z (i) |u)log q φ ( a (i) |x)log p γ ( z (i) | a (i) , u) . (6.8)</p><p>Note that the ratio p γ ( a (i) , z (i) |u)/p γ ( z (i) | a (i) , u) in (6.8) gives p γ ( a (i) |u), but the formulation with { z (i) } allows stochastic gradients on γ to also be computed. A sample from q can be obtained by first sampling a ∼ q φ (a|x), and using a as an observation for the LGSSM. The posterior p γ (z| a, u) can be tractably obtained with a Kalman smoother, and a sample z ∼ p γ (z| a, u) obtained from it. Parameter learning is done by jointly updating θ, φ, and γ by maximising the ELBO on L, which decomposes as a sum of ELBOs in (6.7), using stochastic gradient ascent and a single sample to approximate the intractable expectations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3">Dynamics parameter network</head><p>The LGSSM provides a tractable way to structure p γ (z|a, u) into the variational approximation in (6.6). However, even in the simple case of a ball bouncing against a wall, the dynamics on a t are not linear anymore. We can deal with these situations while preserving the linear dependency between consecutive states in the LGSSM, by non-linearly changing the parameters γ t of the model over time as a function of the latent encodings up to time t -1 (so that we can still define a generative model). Smoothing is still possible as the state transition matrix A t and others in γ t do not have to be constant in order to obtain the exact posterior p γ (z t |a, u). Recall that γ t describes how the latent state z t-1 changes from time t -1 to time t. In the more general setting, the changes in dynamics at time t may depend on the history of the system, encoded in a 1:t-1 and possibly a starting code a 0 that can be learned from data. If, for instance, we see the ball colliding with a wall at time t -1, then we know that it will bounce at time t and change direction. We then let γ t be a learnable function of a 0:t-1 , so that the prior in (6.3) becomes p γ (a, z|u) = T t=1 p γt(a 0:t-1 ) (a t |z t ) • p(z 1 ) T t=2 p γt(a 0:t-1 ) (z t |z t-1 , u t ) . (6.9)</p><p>During inference, after all the frames are encoded in a, the dynamics parameter network returns γ = γ(a), the parameters of the LGSSM at all time steps. We can now use the Kalman smoothing algorithm to find the exact conditional posterior over z, that will be used when computing the gradients of the ELBO.</p><p>In our experiments the dependence of γ t on a 0:t-1 is modulated by a dynamics parameter network α t = α t (a 0:t-1 ), that is implemented with a recurrent neural network with LSTM cells that takes at each time step the encoded state as input and recurses d t = LSTM (a t-1 , d t-1 ) and α t = softmax(d t ), as illustrated in figure <ref type="figure" target="#fig_22">6</ref>.2. The output of the dynamics parameter network is weights that sum to one, K k=1 α (k)</p><p>t (a 0:t-1 ) = 1. These weights choose and interpolate between K different operating modes:</p><formula xml:id="formula_146">A t = K k=1 α (k) t (a 0:t-1 )A (k) , B t = K k=1 α (k) t (a 0:t-1 )B (k) , C t = K k=1 α (k)</formula><p>t (a 0:t-1 )C (k) . (6.10)</p><p>We globally learn K basic state transition, control and emission matrices A (k) , B (k) and C (k) , and interpolate them based on information from the VAE encodings. The weighted sum can be interpreted as a soft mixture of K different LGSSMs whose time-invariant matrices are combined using the time-varying weights α t . In practice, each of the K sets {A (k) , B (k) , C (k) } models different dynamics, that will dominate when the corresponding α (k) t is high. The dynamics parameter network resembles the locally-linear transitions of <ref type="bibr" target="#b70">(Karl et al., 2017;</ref><ref type="bibr" target="#b149">Watter et al., 2015)</ref>; see section 6.6 for an in depth discussion on the differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Missing data imputation</head><p>Let x obs be an observed subset of frames in a video sequence, for instance depicting the initial movement and final positions of a ball in a scene. From its start and end, can we imagine how the ball reaches its final position? Autoregressive models like recurrent neural networks can only forward-generate x t frame by frame, and cannot make use of the information coming from the final frames in the sequence. To impute the unobserved frames x un in the middle of the sequence, we need to do inference, not prediction.</p><p>The KVAE exploits the smoothing abilities of its LGSSM to use both the information from the past and the future when imputing missing data. In general, if x = {x obs , x un }, the unobserved frames in x un could also appear at non-contiguous time steps, e.g. missing at random. Data can be imputed by sampling from the joint density p(a un , a obs , z|x obs , u), and then generating x un from a un . We factorize this distribution as p(a un , a obs , z|x obs , u) = p γ (a un |z) p γ (z|a obs , u) p(a obs |x obs ) , (6.11)</p><p>and we sample from it with ancestral sampling starting from x obs . Reading (6.11) from right to left, a sample from p(a obs |x obs ) can be approximated with the variational distribution q φ (a obs |x obs ).</p><p>Then, if γ is fully known, p γ (z|a obs , u) is computed with an extension to the Kalman smoothing algorithm to sequences with missing data, after which samples from p γ (a un |z) could be readily drawn.</p><p>However, when doing missing data imputation the parameters γ of the LGSSM are not known at all time steps. In the KVAE, each γ t depends on all the previous encoded states, including a un , and these need to be estimated before γ can be computed. In this paper we recursively estimate γ in the following way. Assume that x 1:t-1 is known, but not x t . We sample a 1:t-1 from q φ (a 1:t-1 |x 1:t-1 ) using the VAE, and use it to compute γ 1:t . The computation of γ t+1 depends on a t , which is missing, and an estimate a t will be used. Such an estimate can be arrived at in two steps. The filtered posterior distribution p γ (z t-1 |a 1:t-1 , u 1:t-1 ) can be computed as it depends only on γ 1:t-1 , and from it, we sample z t ∼ p γ (z t |a 1:t-1 , u 1:t ) = p γt (z t |z t-1 , u t ) p γ (z t-1 |a 1:t-1 , u 1:t-1 ) dz t-1 (6.12)</p><p>and sample a t from the predictive distribution of a t ,</p><formula xml:id="formula_147">a t ∼ p γ (a t |a 1:t-1 , u 1:t ) = p γt (a t |z t ) p γ (z t |a 1:t-1 , u 1:t ) dz t ≈ p γt (a t | z t ) . (6.13)</formula><p>The parameters of the LGSSM at time t + 1 are then estimated as γ t+1 ([a 0:t-1 , a t ]). The same procedure is repeated at the next time step if x t+1 is missing, otherwise a t+1 is drawn from the VAE. After the forward pass through the sequence, where we estimate γ and compute the filtered posterior for z, the Kalman smoother's backwards pass computes the smoothed posterior. While the smoothed posterior distribution is not exact, as it relies on the estimate of γ obtained during the forward pass, it improves data imputation by using information coming from the whole sequence; see section 6.5 for an experimental illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Experiments</head><p>We motivated the KVAE with an example of a bouncing ball, and use it here to demonstrate the model's ability to separately learn a recognition and dynamics model from video, and use it to impute missing data. To draw a comparison with deep variational Bayes filters (DVBFs) <ref type="bibr" target="#b70">(Karl et al., 2017)</ref>, we apply the KVAE to (Karl et al., 2017)'s pendulum example. We further apply the model to a number of environments with different properties to demonstrate its generalizability.</p><p>All models are trained end-to-end with stochastic gradient descent. Using the control input u t in (6.1) we can inform the model of known quantities such as external forces, as will be done in the pendulum experiment. In all the other experiments, we omit such information and train the models fully unsupervised from the videos only. Further implementation details can be found in the supplementary material (appendix 6.8) and in the Tensorflow <ref type="bibr" target="#b0">(Abadi et al., 2015)</ref> code released at github.com/simonkamronn/kvae.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.1">Bouncing ball</head><p>We simulate 5000 sequences of 20 time steps each of a ball moving in a two-dimensional box, where each video frame is a 32x32 binary image. A video sequence is visualised as a single image in figure <ref type="figure" target="#fig_22">6</ref>.4d, with the ball's darkening color reflecting the incremental frame index. In this set-up the initial position and velocity are randomly sampled. No forces are applied to the ball, except for the fully elastic collisions with the walls. The minimum number of latent dimensions that the KVAE requires to model the ball's dynamics are a t ∈ R<ref type="foot" target="#foot_11">foot_11</ref> and z t ∈ R 4 , as at the very least the ball's position in the box's 2d plane has to be encoded in a t , and z t has to encode the ball's position and velocity. The model's flexibility increases with more latent dimensions, but we choose these settings for the sake of interpretable visualisations. The dynamics parameter network uses K = 3 to interpolate three modes, a constant velocity, and two non-linear interactions with the horizontal and vertical walls.</p><p>We compare the generation and imputation performance of the KVAE with two recurrent neural network (RNN) models that are based on the same auto-encoding (AE) architecture as the KVAE and are modifications of methods from the literature to be better suited to the bouncing ball experiments. 2 In the AE-RNN, inspired by the architecture from <ref type="bibr" target="#b138">(Srivastava et al., 2015)</ref>, a pretrained convolutional auto-encoder, identical to the one used for the KVAE, feeds the encodings to an LSTM network <ref type="bibr" target="#b63">(Hochreiter and Schmidhuber, 1997)</ref>. During training the LSTM predicts the next encoding in the sequence and during generation we use the previous output as input to the current step. For data imputation the LSTM either receives the previous output or, if available, the encoding of the observed frame (similarly to filtering in the KVAE). The VAE-RNN is identical to the AE-RNN except that uses a VAE instead of an AE, similarly to the model from <ref type="bibr" target="#b21">(Chung et al., 2015)</ref>.</p><p>Figure <ref type="figure" target="#fig_22">6</ref>.3a shows how well missing frames are imputed in terms of the average fraction of incorrectly guessed pixels. In it, the first 4 frames are observed (to initialize the models) after which the next 16 frames are dropped at random with varying probabilities. We then impute the missing frames by doing filtering and smoothing with the KVAE. We see in figure <ref type="figure" target="#fig_22">6</ref>.3a that it is beneficial to utilize information from the whole sequence (even the future observed frames), and a KVAE with smoothing outperforms all competing methods. Notice that dropout probability 1 corresponds to pure generation from the models. Figure <ref type="figure" target="#fig_22">6</ref>.3b repeats this experiment, but makes it more challenging by removing an increasing number of consecutive frames from the Notice that the a t 's lie on a manifold that can be rotated and stretched to align with the frames of the video. middle of the sequence (T = 20). In this case the ability to encode information coming from the future into the posterior distribution is highly beneficial, and smoothing imputes frames much better than the other methods. Figure <ref type="figure" target="#fig_22">6</ref>.3c graphically illustrates figure 6.3b. We plot three trajectories over a t -encodings. The generated trajectories were obtained after initializing the KVAE model with 4 initial frames, while the smoothed trajectories also incorporated encodings from the last 4 frames of the sequence. The encoded trajectories were obtained with no missing data, and are therefore considered as ground truth. In the first three plots in figure <ref type="figure" target="#fig_22">6</ref>.3c, we see that the backwards recursion of the Kalman smoother corrects the trajectory obtained with generation in the forward pass. However, in the fourth plot, the poor trajectory that is obtained during the forward generation step, makes smoothing unable to follow the ground truth.</p><p>The smoothing capabilities of KVAEs make it also possible to train it with up to 40% of missing data with minor losses in performance (appendix 6.10 in the supplementary material). Links to videos of the imputation results and long-term generation from the models can be found in appendix 6.9 and at sites.google.com/view/kvae.</p><p>Understanding the dynamics parameter network. In our experiments the dynamics parameter network α t = α t (a 0:t-1 ) is an LSTM network, but we could also parameterize it with any differentiable function of a 0:t-1 (see appendix 6.11 in the supplementary material for a comparison of various architectures). When using a multi-layer perceptron (MLP) that depends on the previous encoding as mixture network, i.e. α t = α t (a t-1 ), figure 6.4 illustrates how the network chooses the mixture of learned dynamics. We see that the model has correctly learned </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Test to choose a transition that maintains a constant velocity in the center (k = 1), reverses the horizontal velocity when in proximity of the left and right wall (k = 2), reverses the vertical velocity when close to the top and bottom (k = 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.2">Pendulum experiment</head><p>We test the KVAE on the experiment of a dynamic torque-controlled pendulum used in <ref type="bibr" target="#b70">(Karl et al., 2017)</ref>. Training, validation and test set are formed by 500 sequences of 15 frames of 16x16 pixels. We use a KVAE with a t ∈ R 2 , z t ∈ R<ref type="foot" target="#foot_12">foot_12</ref> and K = 2, and try two different encoder-decoder architectures for the VAE, one using a MLP and one using a convolutional neural network (CNN).</p><p>We compare the performaces of the KVAE to DVBFs <ref type="bibr" target="#b70">(Karl et al., 2017)</ref> and deep Markov models 3 (DMM) <ref type="bibr" target="#b77">(Krishnan et al., 2017)</ref>, non-linear SSMs parameterized by deep neural networks whose intractable posterior distribution is approximated with an inference network. In table 6.1 we see that the KVAE outperforms both models in terms of ELBO on a test set, showing that for the task in hand it is preferable to use a model with simpler dynamics but exact posterior inference.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.3">Other environments</head><p>To test how well the KVAE adapts to different environments, we trained it end-to-end on videos of (i) a ball bouncing between walls that form an irregular polygon, (ii) a ball bouncing in a box and subject to gravity, (iii) a Pong-like environment where the paddles follow the vertical position of the ball to make it stay in the frame at all times. Figure <ref type="figure" target="#fig_22">6</ref>.5 shows that the KVAE learns the dynamics of all three environments, and generates realistic-looking trajectories. We repeat the imputation experiments of figures 6.3a and 6.3b for these environments in the supplementary material (appendix 6.12), where we see that KVAEs outperform alternative models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Related work</head><p>Recent progress in unsupervised learning of high dimensional sequences is found in a plethora of both deterministic and probabilistic generative models. The VAE framework is a common work-horse in the stable of probabilistic inference methods, and it is extended to the temporal setting by <ref type="bibr" target="#b2">(Archer et al., 2015;</ref><ref type="bibr" target="#b21">Chung et al., 2015;</ref><ref type="bibr" target="#b39">Fraccaro et al., 2016c;</ref><ref type="bibr" target="#b70">Karl et al., 2017;</ref><ref type="bibr" target="#b77">Krishnan et al., 2017)</ref>. In particular, deep neural networks can parameterize the transition and emission distributions of different variants of deep state-space models <ref type="bibr" target="#b39">(Fraccaro et al., 2016c;</ref><ref type="bibr" target="#b70">Karl et al., 2017;</ref><ref type="bibr" target="#b77">Krishnan et al., 2017)</ref>. In these extensions, inference networks define a variational approximation to the intractable posterior distribution of the latent states at each time step. For the tasks in section 6.5, it is preferable to use the KVAE's simpler temporal model with an exact (conditional) posterior distribution than a highly non-linear model where the posterior needs to be approximated. A different combination of VAEs and probabilistic graphical models has been explored in <ref type="bibr" target="#b65">(Johnson et al., 2016)</ref>, which defines a general class of models where inference is performed with message passing algorithms that use deep neural networks to map the observations to conjugate graphical model potentials.</p><p>In classical non-linear extensions of the LGSSM like the extended Kalman filter and in the locally-linear dynamics of <ref type="bibr" target="#b70">(Karl et al., 2017;</ref><ref type="bibr" target="#b149">Watter et al., 2015)</ref>, the transition matrices at time t have a non-linear dependence on z t-1 . The KVAE's approach is different: by introducing the latent encodings a t and making γ t depend on a 1:t-1 , the linear dependency between consecutive states of z is preserved, so that the exact smoothed posterior can be computed given a, and used to perform missing data imputation.</p><p>LGSSM with dynamic parameterization have been used for large-scale demand forecasting in <ref type="bibr" target="#b130">(Seeger et al., 2016)</ref>. <ref type="bibr" target="#b89">(Linderman et al., 2017)</ref> introduces recurrent switching linear dynamical systems, that combine deep learning techniques and switching Kalman filters <ref type="bibr" target="#b104">(Murphy, 1998)</ref> to model low-dimensional time series. <ref type="bibr" target="#b61">(Haarnoja et al., 2016)</ref> introduces a discriminative approach to estimate the low-dimensional state of a LGSSM from input images. The resulting model is reminiscent of a KVAE with no decoding step, and is therefore not suited for unsupervised learning and video generation. Recent work in the non-sequential setting has focused on disentangling basic visual concepts in an image <ref type="bibr">(Higgins et al., 2017a)</ref>. <ref type="bibr" target="#b43">(Gao et al., 2016</ref>) models neural activity by finding a non-linear embedding of a neural time series into a LGSSM.</p><p>Great strides have been made in the reinforcement learning community to model how environments evolve in response to action <ref type="bibr" target="#b18">(Chiappa et al., 2017;</ref><ref type="bibr" target="#b108">Oh et al., 2015;</ref><ref type="bibr" target="#b114">Patraucean et al., 2015;</ref><ref type="bibr" target="#b140">Sun et al., 2016;</ref><ref type="bibr" target="#b147">Wahlström et al., 2015)</ref>. In similar spirit to this paper, <ref type="bibr" target="#b147">(Wahlström et al., 2015)</ref> extracts a latent representation from a PCA representation of the frames where controls can be applied. <ref type="bibr" target="#b18">(Chiappa et al., 2017)</ref> introduces action-conditional dynamics parameterized with LSTMs and, as for the KVAE, a computationally efficient procedure to make long term predictions without generating high dimensional images at each time step. As autoregressive models, <ref type="bibr" target="#b138">(Srivastava et al., 2015)</ref> develops a sequence to sequence model of video representations that uses LSTMs to define both the encoder and the decoder. <ref type="bibr" target="#b33">(Finn et al., 2016)</ref> develops an action-conditioned video prediction model of the motion of a robot arm using convolutional LSTMs that models the change in pixel values between two consecutive frames.</p><p>While the focus in this work is to define a generative model for high dimensional videos of simple physical systems, several recent works have combined physical models of the world with deep learning to learn the dynamics of objects in more complex but low-dimensional environments <ref type="bibr" target="#b6">(Battaglia et al., 2016;</ref><ref type="bibr" target="#b16">Chang et al., 2017;</ref><ref type="bibr" target="#b40">Fragkiadaki et al., 2016;</ref><ref type="bibr" target="#b151">Wu et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">Conclusion</head><p>The KVAE, a model for unsupervised learning of high-dimensional videos, was introduced in this paper. It disentangles an object's latent representation a t from a latent state z t that describes its dynamics, and can be learned end-to-end from raw video. Because the exact (conditional) smoothed posterior distribution over the states of the LGSSM can be computed, one generally sees a marked improvement in inference and missing data imputation over methods that don't have this property. A desirable property of disentangling the two latent representations is that temporal reasoning, and possibly planning, could be done in the latent space. As a proof of concept, we have been deliberate in focussing our exposition to videos of static worlds that contain a few moving objects, and leave extensions of the model to real world videos or sequences coming from an agent exploring its environment to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.9">Videos</head><p>Videos are generated from all models by initializing with 4 frames and then sampling. The filtering and smoothing versions are allowed to observe part of the sequence depending on the masking scheme. All the filtering and smoothing videos are generated from sequences applied with a random mask with a masking probability of 80% (as in figure <ref type="figure" target="#fig_22">6</ref>.3a) except for the videos with the suffix consecutive in which only the first and last 4 frames are observed (as in figure <ref type="figure" target="#fig_22">6</ref>.3b). Only the KVAE models have smoothing videos. For the bouncing ball experiment (named box in the attached folder), we also show the videos from a model trained with 40% missing data.</p><p>In most videos the black ball is the ground truth, and the red is the one generated from the model, except for the ones marked long_generation in which the true sequence is not shown.</p><p>Videos are available from Google Drive and the website sites.google.com/view/kvae.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.10</head><p>Training with missing data.</p><p>The smoothed posterior described in section 6.4 can also be used to train the KVAE with missing data. In this case, we only need to modify the ELBO by masking the contribution of the missing data points in the joint probability distribution and variational approximation:</p><formula xml:id="formula_148">p(x, a, z, u) = p(z 1 ) T t=2 p γt (z t |z t-1 , u t ) T t=1 p γt (a t |z t ) It T t=1 p θ (x t |a t ) It q φ (a|x) = T t=1 q φ (a t |x t ) It ,</formula><p>where I t is 0 if the data point is missing, 1 otherwise. Figure <ref type="figure" target="#fig_22">6</ref>.6 illustrates a slight degradation in performance when training with respectively 30% and 40% missing data but, remarkably, the accuracy is still better when using smoothing in these conditions than with filtering with all training data available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11">Dynamics parameter network architecture</head><p>As the α-network governs the non-linear dynamics, it has a significant impact on the modelling capabilities. Here we list the architectural choices considered:</p><p>• MLP with two hidden layers.</p><p>• Recurrent Neural Networks with LSTM units.</p><p>• 'First in, first out memory' (FIFO) MLP with access to 5 time steps. In all cases, we can also model α as an (approximate) discrete random variable using the the Concrete distribution <ref type="bibr">(Maddison et al., 2017b;</ref><ref type="bibr" target="#b64">Jang et al., 2016)</ref>. In this case we can recover an approximation to the switching Kalman filter <ref type="bibr" target="#b104">(Murphy, 1998)</ref>.</p><p>In figure <ref type="figure" target="#fig_22">6</ref>.7 the different choices are tested against each other on the bouncing ball data. In this case all the alternative choices result in poorer performances than the LSTM chosen for all the other experiments. We believe that LSTMs are able to better model the discretization errors coming from the collisions and the 32x32 rendering of the trajectories computed by the physics engine. Abstract: In model-based reinforcement learning, generative and temporal models of environments can be leveraged to boost agent performance, either by tuning the agent's representations during training or via use as part of an explicit planning mechanism. However, their application in practice has been limited to simplistic environments, due to the difficulty of training such models in larger, potentially partially-observed and 3D environments. In this work we introduce a novel action-conditioned generative model of such challenging environments. The model features a non-parametric spatial memory system in which we store learned, disentangled representations of the environment. Low-dimensional spatial updates are computed using a state-space model that makes use of knowledge on the prior dynamics of the moving agent, and high-dimensional visual observations are modelled with a Variational Auto-Encoder. The result is a scalable architecture capable of performing coherent predictions over hundreds of time steps across a range of partially observed 2D and 3D environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.12">Imputation in all environments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Introduction</head><p>Consider a setup in which an agent walks and observes an environment (e.g., a three-dimensional maze) for hundreds of time steps, and is then asked to predict subsequent observations given a sequence of actions. This is a challenging task, as it requires the ability to first remember the visual observations and the position in which they were observed in the environment, and secondly to predict where a possibly long sequence of actions would bring the agent in the environment.</p><p>Building models that can solve this problem can be useful for model-based reinforcement learning involving spatial tasks that require long-term memories and other spatial downstream goals <ref type="bibr" target="#b142">(Sutton, 1990;</ref><ref type="bibr" target="#b23">Deisenroth and Rasmussen, 2011;</ref><ref type="bibr" target="#b84">Levine and Abbeel, 2014;</ref><ref type="bibr" target="#b149">Watter et al., 2015;</ref><ref type="bibr" target="#b147">Wahlström et al., 2015;</ref><ref type="bibr">Lenz et al., 2015;</ref><ref type="bibr">Higgins et al., 2017b;</ref><ref type="bibr" target="#b34">Finn and Levine, 2017)</ref>. This requires however agents that are able to remember the past over hundreds of steps, that know both where they are in the environment and how each action changes their position, and that can coherently predict hundreds of steps into the future. Therefore the main focus of this work is to develop an action-conditioned generative model that is able to memorize all the required information while exploring the environment and successively use it in the prediction phase for long-term generation of high-dimensional visual observations.</p><p>Recently, several powerful generative models for sequential data have been proposed in a wide range of applications, such as modelling speech, handwriting, polyphonic music and videos <ref type="bibr" target="#b21">(Chung et al., 2015;</ref><ref type="bibr" target="#b39">Fraccaro et al., 2016c;</ref><ref type="bibr" target="#b108">Oh et al., 2015;</ref><ref type="bibr" target="#b18">Chiappa et al., 2017)</ref>. They build on recurrent neural architectures such as Long Short-Term Memory (LSTM) <ref type="bibr" target="#b63">(Hochreiter and Schmidhuber, 1997)</ref> or Gated Recurrent Units (GRU) <ref type="bibr" target="#b20">(Chung et al., 2014)</ref>, that use an internal state vector to perform computations and store the long-term information needed when making predictions.</p><p>Since the number of parameters in these models scales quadratically with the dimensionality of the state vector, they are not suitable for applications that require high memory capacity, such as the one considered in this paper. The high dimensional state vector needed to be able to memorize the hundreds of time steps in which the agent has visited the whole environment, make these models in practice both very slow and hard to train. An alternative approach is to use an external memory architecture, for storing of large amount of information while drastically reducing the number of parameters with respect to models with similar memory capacity that build on LSTMs or GRUs. <ref type="bibr" target="#b45">Gemici et al., (2017)</ref> present a general architecture for generative temporal models with external memory, and test four different types of memories that are dynamically updated at each time step <ref type="bibr" target="#b54">(Graves et al., 2014;</ref><ref type="bibr" target="#b55">Graves et al., 2016;</ref><ref type="bibr" target="#b127">Santoro et al., 2016)</ref>. They focus on differentiable addressing mechanisms for memory storage and retrieval (soft-attention), that are based on deep neural networks that learn to write information to the memory and read from it. While this approach is very general and can be used to model complex long-term temporal dependencies in a wide range of applications, it has not been successful in modeling the data coming from an agent freely moving in a 3d maze, even for a single room [private communications with the authors of <ref type="bibr" target="#b45">(Gemici et al., 2017)</ref>].</p><p>To define a scalable model capable of exploring larger environments and coherently predicting hundreds of time steps in the future, in this work we build a spatial memory architecture that exploits some knowledge of the specific structure of the problem in consideration. In particular, at each time step we split the internal latent representation of the system in to two separate vectors, a low-dimensional one that encodes the position of the agent in the environment and a high dimensional one that encodes what the agent is seeing. We model the low dimensional dynamics of the agent with a state-space model in which we encode prior information on the physical principles that govern the agent's movements, and learn a higher dimensional latent representation of the visual input (the frames from the environment) with a Variational Auto-Encoder <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref>. While exploring the environment, at each time step we store the position of the agent and the corresponding visual information in a Differentiable Neural Dictionary (DND) <ref type="bibr" target="#b115">(Pritzel et al., 2017)</ref>, a scalable non-parametric memory developed for episodic control. The resulting model is able to coherently generate hundreds of time steps into the future in simulated 3D environments, by retrieving at each time step the observations stored in memory that were collected when passing in nearby positions during the exploration phase. Making predictions with our model is scalable because of the efficient rollouts in a low dimensional space made possible by the state-space assumption and the efficient retrieval of the necessary information from DND. The proposed model can be trained end-to-end on videos with corresponding action sequences of agents walking in an environment. Importantly, unlike the work in <ref type="bibr" target="#b45">(Gemici et al., 2017)</ref> we do not need to learn a complex memory addressing mechanisms, as in our model the DND represents a non-parametric component where we store encodings of the positions and visual information that are learned from the data in an unsupervised way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Background</head><p>We now provide a brief overview of the building blocks for the model introduced in section 7.3, namely variational auto-encoders, the DND memory and state-space models.</p><p>Variational auto-encoders. Variational auto-encoders (VAEs) <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014</ref>) define a generative model for high-dimensional data x t by introducing a latent state z t . The joint probability distribution p θ (x t , z t ) is factorized as p θ (x t , z t ) = p θ (x t |z t )p(z t ), where p(z t ) is the prior of the latent state and the decoder p θ (x t |z t ) defines a mapping using deep neural networks parameterized by θ from the states z t to the data x t . In a VAE, the intractable posterior distribution over the latent states is approximated using the variational distribution q φ (z t |x t ), also known as the encoder or inference network. The parameters θ and φ of the decoder and the encoder, respectively, are learned jointly by maximizing the Evidence Lower Bound (ELBO) with stochastic gradient ascent.</p><p>DND memory. The Differentiable Neural Dictionary (DND) is a scalable, non-parametric memory module first introduced in Reinforcement Learning (RL) to allow agents to store and retrieve their experiences of an environment <ref type="bibr" target="#b115">(Pritzel et al., 2017)</ref>. The write operation consists of inserting (key, value) pairs into the memory; similarly to a dictionary, this associates a value to each key. Given a query key, we can then read from the memory by finding among the keys stored in the DND the nearest neighbours to the query key and returning the corresponding values. The DND can be used in applications that require very large memories, since the nearest-neighbour search can be efficiently approximated using space-partitioning data structures, such as kd-trees <ref type="bibr" target="#b9">(Bentley, 1975)</ref>.</p><p>State-space models. State-space models (SSM) are a class of probabilistic graphical models widely used in the temporal setting to model sequences of vectors z 1:T = [z 1 , .., z T ] conditioned on some actions a 1:T = [a 1 , . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Model</head><p>An important component of model-based reinforcement learning is the ability to plan many steps ahead in time leveraging previous experiences <ref type="bibr" target="#b142">(Sutton, 1990;</ref><ref type="bibr" target="#b117">Racanière et al., 2017)</ref>. This requires agents that can remember the past and use it to predict what may happen in the future given certain actions. With this purpose in mind, we define an action-conditioned generative model with memory, that can be used within RL agents for model-based planning.</p><p>The input of our model consists of T -step videos with corresponding action sequences, generated by an agent acting in an environment. We split each sequence of T time steps into two parts, corresponding to two different model phases:</p><p>1. Memorization phase. For t = 1, .., τ , the model receives at each time step a frame x t and action a t (e.g. move forwards/backwards, rotate left/right) that led to it. In this phase, the model has to store in memory all the information needed in the following prediction phase. During this phase the agent sees most of the environment (but from a restricted set of viewpoints), in order to give the model sufficient information to make accurate predictions in the subsequent phase.</p><p>2. Prediction phase. For t = τ + 1, .., T , the model receives the actions a τ +1:T that move the data-generating agent across the previously explored environment (although perhaps viewed from a different angle) and needs to predict the observations x τ +1:T using the information about the past that is stored in the memory.</p><p>Storing what the agent sees at each time step is not sufficient: in order to retrieve the correct information from memory when returning to the same location during the prediction phase, we also need to store where the agent is. The location of the agent is a latent variable that can be inferred given the actions as explained in the rest of this section.</p><p>As shown in Figure <ref type="figure">7</ref>.1a, in a Generative Temporal Model with Spatial Memory (GTM-SM) we introduce two sets of latent variables that disentangle visual and dynamics information, similarly to <ref type="bibr" target="#b35">(Fraccaro et al., 2017)</ref>. At each time step we have a VAE whose latent state z t is an encoding of the frame of the video and therefore captures the visual information. The priors of the VAEs are temporally dependent through their dependence on the states s t of the SSM, a latent representation of the location of the agent in the environment. The transition density of the SSM is used to include prior knowledge on the environment dynamics, i.e. the underlying physics.</p><p>During the initial memorization phase, the GTM-SM infers the states s 1:τ of the agent (i.e. the position) and the frame encodings z 1:τ , and stores these (s i , z i ) pairs as (key, value) in the DND memory. Probabilistically, we can view this as inserting an approximation of the intractable the posterior p(s 1:τ , z 1:τ |x 1:τ , a 1:τ ) into the DND; see Section 7.3.3 for details. As the latent variables are stochastic, in practice we store in memory the sufficient statistics of the distribution (e.g. the mean and variance in the case of Gaussian variables). To keep the notation simple, we will refer to the information in the DND by the name of the random variable (as done in Figure <ref type="figure">7</ref>.1b), rather than introducing a new symbol for the sufficient statistics. An alternative is to insert one or more samples from the distribution into the memory instead, but this would introduce some sampling noise.</p><p>In the subsequent prediction phase, we forward-generate from the SSM using the actions a τ +1:T to predict s τ +1:T , and we use the VAE's generative model to generate the frames x τ +1:T given the predicted states and the information from the first τ time steps stored in the DND memory; see Section 7.3.1 for details. In our experiments, a low-dimensional state vector s t (2-or 3-dimensional) suffices. Because of this, we can perform efficient rollouts in latent space without the need to generate high-dimensional frames at each time step as in autoregressive models <ref type="bibr" target="#b108">(Oh et al., 2015;</ref><ref type="bibr" target="#b18">Chiappa et al., 2017;</ref><ref type="bibr" target="#b45">Gemici et al., 2017)</ref>. Also, thanks to the scalability properties of the DND memory, we can efficiently explore very large environments.</p><p>There are three key components that define the GTM-SM and that will be introduced in the following, namely the generative model, the inference network, and the past encoder. As we will see, these components share many parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Generative model</head><p>For brevity, we write the observations and actions in the memorization phase as v = {x 1:τ , a 1:τ } and we write the observations and actions in the prediction phase as x = x τ +1:T and a = a τ +1:T respectively. Letting θ be the parameters of the generative model, we model p θ (x|a, v) as follows.   agents walking in the environments, that are split so that both the memorization and prediction phase are hundreds of time steps. Experimental details can be found in Appendix 7.7 in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.1">Image navigation experiment</head><p>In this experiment the data-generating agent walks on top of an image and observes a cropped version of the image (centered at the agent's position). As illustrated in Figure <ref type="figure">7</ref>.2a, the 2D environment is a 32x32 image from the CelebA dataset <ref type="bibr" target="#b93">(Liu et al., 2015)</ref> and the agent sees an 8x8 crop (the yellow square in the figure). There are five possible actions: move one step up/down/left/right or stay still. At each time step we sample a random action, but to favor exploring the whole environment the action is repeated in the subsequent time steps. The number of repetitions is sampled from a Poisson distribution. The agent cannot walk outside of the image: the "move right" action, for example, does not change the position of an agent on the right edge of the image. We can interpret this as an environment with walls. The agent walks on the image while adding information in the DND memory for τ = 256 time steps. We experimentally determined that this suffices to ensure that the agent usually reaches most positions in the environment. During training the prediction phase has 32 time steps; during testing we instead generate from the model for 256 time steps, so that T = 512. In each of the two dimensions, there are nine possible positions (the crops can overlap). This is illustrated in Figure <ref type="figure">7</ref>.2b, which shows the ground truth positions that the agent has visited in the 256 steps of the memorization phase of a test sequence.</p><p>We use a 2-dimensional state space that the GTM-SM learns to use to represent the position of the agent. With no walls in the environment all possible transitions are linear, and they can be modelled as s t = s t-1 + M a t + ε t with ε t ∼ N (0, r 2 I). In all experiments we use small values for r 2 , that make the transitions close to being deterministic. The transition matrix M can be learned from the data, and describes how to update the state given each of the 5 actions (M a t is the displacement at time t). The environment in our experiment has walls however, and we need the model to be able to learn not to move with actions that would make it hit a wall. We do this by multiplying the displacement by a neural network σ d that receives as input the projected position of the agent after taking the action and outputs a value between 0 and 1, and that can therefore learn to cancel out any displacements that would bring the agent out of the environment. These non-linear transitions are therefore modelled as</p><formula xml:id="formula_149">s t = s t-1 + M a t • σ d (s t-1 + M a t ) + ε t . (7.</formula><p>3)</p><p>The VAE prior used in this experiments is obtained by creating a mixture distribution from the sufficient statistics of the frame encodings retrieved from the DND memory, whose weights are inversely proportional to the squared distances d (k) between s t and the retrieved elements s w k N (z t |z (k) ) ; w k ∝ 1 d (k) 2 + δ δ = 10 -4 is added for numerical stability <ref type="bibr" target="#b115">(Pritzel et al., 2017)</ref>. In the DND memory we store sufficient statistics, but in this experiment we use the Euclidean distance between means in the nearest-neighbor search. (Alternatively, we could use the KL divergence between the distributions).</p><p>In Figure <ref type="figure">7</ref>.2c we show an example of the states inferred by the model for a test sequence. We see that the model has learned the correct transitions, in a state space that is rotated and stretched with respect to the ground truth one. To test the memorization and prediction capabilities of the GTM-SM, Figure <ref type="figure">7</ref>.2d shows a comparison between the ground truth frames of the video and the predicted ones during the prediction phase. The model produces almost perfect predictions, even after more than 200 generation steps (t = 471). This shows that it has learned to store all relevant information in the DND, as well as retrieve all relevant information from it. Videos of long-term generations from the model are available in the supplementary material, see Appendix 7.8 for details. The state-of-the-art generative temporal models with memory introduced in <ref type="bibr" target="#b45">(Gemici et al., 2017)</ref>, are not able to capture the spatial structure of large environments as in the GTM-SM, and would therefore struggle to coherently generate hundreds of time steps into the future. The MNIST maze experiment in <ref type="bibr" target="#b45">(Gemici et al., 2017)</ref> can be seen as a simpler version of the image navigation experiment presented above, with agents moving on a 4x4 grid, linear transitions and 25-step sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.2">Labyrinth experiments</head><p>We now show that the GTM-SM is able to remember the past and perform spatio-temporally coherent generations over hundreds of time steps in simulated 3D environments. We use the Labyrinth environment <ref type="bibr" target="#b103">(Mnih et al., 2016;</ref><ref type="bibr" target="#b8">Beattie et al., 2016)</ref>, procedurally-generated 3D mazes with random textures, objects and wall configurations. There are eight possible actions that can both move and rotate the agent in the maze, and we observe images from a first-person point of view. Labyrinth can be seen as a 3D extension of the image navigation experiments in Section vector between 0 and 1 of the same size of d t (σ is the sigmoid function and represents the element-wise product). To deal with saturation, we then limit the range of the displacements by squashing them through a tanh non-linearity that is pre-multiplied by a learned vector c s . The resulting transition model then becomes</p><formula xml:id="formula_150">s t = s t-1 + R(s<label>(3)</label></formula><p>t-1 ) c s tanh(σ(c f ) d t-1 + M a t ) dt +ε t with M , c s and c f parameters to be learned. This is a very challenging task, as from only one-hot encoded actions and the frames of the video we need to learn a complex transition model. Moreover, due to the low resolution of the images (32x32), small variations in state-space may be impossible to infer using only the images. To solve this, we make the reasonable assumption that at training time the agent feels its movement, i.e. the displacements. We then add a regression loss as an extra term to the objective function, that helps the GTM-SM to learn transition parameters such that the estimated d t is close to its true value. Notice that the true displacements information is only added as a target in the loss, and never passed directly into the model. The pre-trained agent does not hit walls, therefore we do not need to handle non-linearities as in (7.3).</p><p>We let the agent walk around the room while adding information in the DND memory for τ = 150 time steps, and then predict during testing the following 150 time steps (T = 300). In Figure <ref type="figure">7</ref>.3b, we notice that the GTM-SM is able to learn a very accurate transition model, that provides a sufficiently good approximation of the true state even after t = 297 time steps. In Figure <ref type="figure">7</ref>.3d we can appreciate the memorization and long-term generation capabilities of the GTM-SM by looking at the comparison between the true and predicted frames of the video in the end of the prediction phase (t 284:299 ). We also notice in the predicted frames, that the model correctly draws the walls and the floors but fails to render the objects, probably due to difficulties in modelling with the VAE the very diverse and complex textures that form objects in this environment. We also tested the same trained model on longer videos of larger environments with multiple rooms (τ = 150 and T = 450). As explained in detail in Appendix 7.9, the model is able to correctly predict the textures of the environment even after 300 time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Related work</head><p>A number of recent works have augmented deep generative models with learned external memories, both in the static setting <ref type="bibr">(Li et al., 2016;</ref><ref type="bibr" target="#b12">Bornschein et al., 2017)</ref> and in the temporal one <ref type="bibr" target="#b45">(Gemici et al., 2017)</ref>. More in general, neural networks have been combined with different memories in a wide range of tasks such as supervised learning <ref type="bibr" target="#b54">(Graves et al., 2014;</ref><ref type="bibr" target="#b55">Graves et al., 2016)</ref>, reinforcement learning <ref type="bibr" target="#b107">(Oh et al., 2016;</ref><ref type="bibr" target="#b115">Pritzel et al., 2017;</ref><ref type="bibr" target="#b113">Parisotto and Salakhutdinov, 2018)</ref>, one-shot learning <ref type="bibr" target="#b127">(Santoro et al., 2016)</ref>, question answering and language modelling <ref type="bibr" target="#b139">(Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b100">Miller et al., 2016)</ref>. Each memory architecture uses different addressing mechanisms to write or read information, that are usually chosen depending on the specific application being considered. As discussed in the introduction, our work is closely related to <ref type="bibr" target="#b45">(Gemici et al., 2017)</ref>, but more suitable for long-term generation for this task and more scalable thanks to the usage of the spatial memory architecture that exploits knowledge on the dynamics of the agent and does not require to learn a parametric memory addressing scheme.</p><p>In the deep reinforcement learning community, several works have exploited different memory architectures to store long term information to be used within an agent's policy, such as in <ref type="bibr" target="#b152">(Zaremba and Sutskever, 2015;</ref><ref type="bibr" target="#b107">Oh et al., 2016)</ref>. In particular, in <ref type="bibr">(Gupta et al., 2017a;</ref><ref type="bibr">Gupta et al., 2017b;</ref><ref type="bibr" target="#b153">Zhang et al., 2017;</ref><ref type="bibr" target="#b113">Parisotto and Salakhutdinov, 2018)</ref> the memory architectures have a fixed number of slots that are spatially structured as a 2D grid, and can therefore store information on the moving agent. Similarly to the GTM-SM, these memories are built to exploit the spatial structure of the problem, although for the different task of constructing agents that can learn to navigate and explore the environment, as opposed to the focus on generative modelling of this paper. Simultaneous Localization And Mapping (SLAM) <ref type="bibr" target="#b135">(Smith et al., 1987;</ref><ref type="bibr" target="#b83">Leonard and Durrant-Whyte, 1991</ref>) is a popular technique used in robotics to estimate the position of a robot and the map of the environment at the same time using sensor data, recently applied to deep reinforcement learning for example in <ref type="bibr" target="#b10">(Bhatti et al., 2016;</ref><ref type="bibr" target="#b153">Zhang et al., 2017)</ref>. It is reminiscent to the memorization phase of the GTM-SM, that could be therefore extended using ideas introduced in the visual SLAM community <ref type="bibr" target="#b143">(Taketomi et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Conclusion</head><p>In this work we introduced the Generative Temporal Model with Spatial Memory, an actionconditioned generative model that uses a scalable non-parametric memory to store spatial and visual information. Our experiments on simulated 2D and 3D environments show that the model is able to coherently memorize and perform long-term generation. To our knowledge this is the first published work that builds a generative model for agents walking in an environment that, thanks to the separation of the dynamics and visual information in the DND memory, can coherently generate for hundreds of time steps in a scalable way. Future work will focus on exploiting these capabilities in model-based planning by integrating the GTM-SM within an RL agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary material 7.7 Experimental details</head><p>The models used in all experiments are implemented in Tensorflow <ref type="bibr" target="#b0">(Abadi et al., 2015)</ref> and use the Adam optimizer <ref type="bibr" target="#b75">(Kingma and Ba, 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7.1">Image navigation experiment</head><p>The training and test data sets are procedurally generated by sampling a random trajectory in randomly chosen images from the CelebA data set. The actions at each time steps are one-hot encoded (vector of size 5). The memorization phase is 256 time steps, while the prediction one has 32 time steps during training and 256 during testing.</p><p>The VAE decoder and encoder use a 3-layered convolutional architecture to parameterize mean and variance of 16-dimensional latent states, but we noticed in practice that for this experiment even standard fully connected architectures perform well. In the transition model the standard deviation of the model is r = 10 -3 . In the DND we retrieve the 5 nearest neighbour and use Euclidean distances between means.</p><p>The initial learning rate is 10 -3 , and we anneal it linearly to 5 • 10 -5 during the first 50000 updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7.2">Labyrinth experiments</head><p>The data sets used for the labyrinth experiments contain 120000 action-conditioned videos, of which we use 100000 for training and 20000 for testing. Each video for the rotating agent experiments contains 80 frames. To form a training sequence we select randomly 49 consecutive frames of a video, that we split in 33 frames for the memorization phase and 16 for the prediction one. During testing, the prediction phase has 45 time steps. For the walking agent experiment the videos are 300 time steps. Similarly to the rotation experiment, to form a training sequence we get consecutive sequences of 150+32 time steps (memorization and prediction phase respectively).</p><p>During testing, we use 150 frames for the prediction phase.</p><p>The transition noise of the SSM has standard deviation r = 10 -2 . To compute distances in the DND we map the state vectors to</p><formula xml:id="formula_151">s t =      s (1) t s (2) t cos(s<label>(3)</label></formula><p>t ) sin(s</p><formula xml:id="formula_152">(3) t )     </formula><p>, and optionally pass the resulting vector through a linear layer. This gives a 5-dimensional vector in a learned manifold in which we use the Euclidean distance (in our experiments, the model performed well even without the linear layer). In the DND we retrieve the 4 nearest neighbours.</p><p>In the VAE, we use convolutional encoder and decoder, and 64-dimensional latent state. The VAE prior p θ (z t |s t , m) used in the Labyrinth experiments is slightly more involved than the mixture prior used in the image navigation one. We first map the data retrieved from memory {s i , z i } with a MLP to an embedding vector h t , and then combine the embedding h t with the current state s t , mapping the result to the mean and variance of the Gaussian prior h t = f ({s i , z i }) p θ (z t |s t , m) = N (µ(h t , s t ), σ(h t , s t )).</p><p>The initial learning rate is set to 3 • 10 -3 , and we linearly anneal it to 5 • 10 -5 during the first 100000 updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.10">Inference network using landmark information</head><p>We now introduce an alternative inference network that uses the information in the DND memory to improve inference in cases in which the SSM transition model is not powerful enough to infer the correct position of the agent. We factorize the variational approximation q φ (z, s|x, a, v) as q φ (z, s|x, a, v) = q φ (z|x)q φ (s|z, a, v) = T t=τ +1 q φ (z t |x t )q φ (s t |s t-1 , a t , z t , m) .</p><p>A graphical representation of the inference network of the GTM-SM is shown in Figure <ref type="figure">7</ref>.5. q φ (z t |x t ) is an inference network that outputs the mean and variance of a Gaussian distribution, as typically done in VAEs. The structured variational approximation q φ (s t |s t-1 , a t , z t , m) retains the temporal dependency among the state variables and exploits the information stored in the memory m. We define this approximation to depend on:</p><p>1. The prior belief p θ (s t |s t-1 , a t ). If at time t -1 we were at a given position, this dependence captures the fact that at time t we cannot be too far from it. This is the same dependence we used in Section 7.3.2.</p><p>2. Landmark information, obtained by querying the DND memory in the reverse direction with respect to the VAE prior, i.e., considering the frame encodings z i as keys and the states s i as values. At each time step the agent can then check whether it has already seen the current frame encoding z t in the past, and exploit this information when computing the inferred position of the agent. We use z t to query the reversed-DND, retrieving triplets {(δ (k) , z (k) , s (k) ), k = 1, .., K } that are used in the computation of the parameters of q φ (s t |s t-1 , a t , z t , m). Here, δ (k) i represents a distance in z-space.</p><p>We define q φ (s t |s t-1 , a t , z t , m) to be a Gaussian density, whose mean µ q and variance σ 2 q are the outputs of a neural network that merges the sufficient statistics µ p and σ 2 p of the prior p θ (s t |s t-1 , a t ), and the ones of the states s (k) i retrieved using landmark information: µ k , σ 2 k , k = 1 : K . We assume that we stored in the DND the mean and the variance of Gaussian latent states. The posterior mean is obtained as</p><formula xml:id="formula_153">µ q = µ p + K k=1 β k (µ k -µ p ) ,</formula><p>where β k ∈ [0, 1] is the output of a simple neural network with input δ (k) i . The inference network can then learn to assign a high value to β k whenever the distance in z-space is small (i.e. the current observation is similar to a frame stored in the DND), so that the prior mean is moved in the direction of µ k . Similarly, the posterior variance can be computed starting from the prior variance using another neural network: log σ 2 q = log σ 2 p + N N (δ 1:K i , σ 2 1:K , σ 2 p ). with q φ (s t ) = q φ (s t |s t-1 , a t , z t , m 1:t-1 )q φ (s t-1 ) ds t-1 .</p><p>Notice in particular the additional KL term for the SSM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.10.1">Image navigation with obstacles</head><p>We extend the image navigation experiments of Section 7.4.1 adding obstacles to the environment as illustrated in Figure <ref type="figure">7</ref>.6 (left). We use displacement information as in the Labyrinth experiment of Section 7.4.2.2. The obstacles appear in random positions in each sequence, therefore we cannot learn a prior transition model that captures these non-linear dynamics. However, when doing inference the model can use its knowledge on the current frame x t (that is not available during the prediction phase) to infer its position by exploiting landmark information.</p><p>To illustrate this we can look at the example in Figure <ref type="figure">7</ref>.6 (right). At time t -1, the position s t-1 of the agent coincides with the red star. The agent's position together with the corresponding observation x t-1 (the yellow square) will be inserted in the DND memory. At time t, the agent receives a "move left" action; the prior transition probabilities will then predict that the agent has to move to the left (the green hexagon). Due to the presence of the obstacle however, the agent does not move, meaning that x t will be the same as x t-1 . Querying the DND in the reverse direction the model will then know that the inferred state (the blue dot) should be the same as the position at the previous time step that was stored in the DND (the red star).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part III</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Closing</head><p>Chapter 8</p><p>Conclusions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Contributions</head><p>The ever-increasing availability of unlabelled sequential data is driving the development of mathematical models and methods that can be used to analyze it in a general and scalable way. This thesis represents a step in this direction, inspired by the recent successes in probabilistic modelling and deep learning.</p><p>In the first part of the thesis we developed a unified framework that merges ideas from latent variable models, state-space models and deep learning, and defined a broad class of deep latent variable models for sequential data that are:</p><p>1. Flexible. These models can fit complex data distributions in a wide range of applications. We achieve this by constructing probabilistic sequential models in which we use deep neural networks to parameterize the conditional distributions that define them. Deep learning architectures form very expressive function approximators, and allow the model to learn to perform an automatic feature extraction that is fundamental for the models to be broadly applicable. Also, new advancements in deep learning can be easily incorporated in this framework.</p><p>2. Scalable. Since both the generative model and the posterior approximation are defined with deep neural networks, we can perform end-to-end training using gradient-based optimization of the ELBO, computing the required gradients efficiently with GPU implementations of the back-propagation algorithm. The usage of mini-batches and amortized inference techniques allows us to train these probabilistic models in a scalable way on very large data sets.</p><p>3. Easy to implement. These models can be implemented using existing deep learning libraries, that use automatic differentiations techniques to automatically compute the gradients of any differentiable architecture. Thanks to the usage of inference networks, probabilistic inference can be seen as a simple black-box operation, as opposed to the model-specific calculations required by other approximate inference techniques such as mean-field variational inference or MCMC methods.</p><p>In the second part of the thesis we further presented three papers that introduce in depth novel models belonging to this framework. In <ref type="bibr">(Fraccaro et al., 2016c, Chapter 5)</ref> we showed how we can combine the power of RNNs in capturing long-term dependencies in the data with the ability of DSSMs to model the uncertainty in the learned latent representation. <ref type="bibr">(Fraccaro et al., 2017, Chapter 6</ref>) then discusses how incorporating structure to the model we can learn disentangled and more interpretable visual and dynamics representations. Finally, in <ref type="bibr">(Fraccaro et al., 2018, Chapter 7)</ref> we discussed the usage of an external memory architecture to deal with applications that require a high memory capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Open questions and future work</head><p>It is well known by researchers that every new advancement in a field comes with a new set of open questions that are often harder to answer than the initial ones. For the sequential deep latent variable models introduced in this thesis there are a number of open questions whose answer would allow us to achieve a better understanding of their working principles as well as to better exploit their modelling power. We divide them in two groups: modelling and inference and learning.</p><p>Modelling:</p><p>• The selection of the best model parameterization to use for a given application can be difficult. This class of models in fact inherits from its deep learning component all the challenges related to the specification of the exact network architecture, e.g. number of layers, units and the type of activation function to use. In particular, the choice of the specific parameterization of the transition/emission distributions has a large impact in terms of performances. It is then fundamental to verify if there are better default choices that consistently perform better than the ones presented in this thesis.</p><p>• As discussed in Section 4.8, if we are not careful enough during training, often the model tends to set all the variances to a very low value, making the model basically deterministic. Instead of solving this issue at training time, we may be able to define architectures that can natively better exploit the stochasticity.</p><p>• It is often difficult to understand if for a particular application it is important to model stochasticity in the latent states, e.g. whether one should use an RNN or an SRNN. This is part of an even broader question on which is the exact role played by the stochastic component in such architectures. Is it really modelling uncertainty or is it just introducing some "tailored noise" that is beneficial at training time?</p><p>• More work is needed to fully understand whether the uncertainties learned by these models are meaningful and well calibrated.</p><p>Inference and learning:</p><p>• In these models, we use inference networks to parameterize Gaussian variational approximations, and inherit therefore the same issues and possible solutions discussed for VAEs in Section 2.5. More research is needed in this direction to define even better objective functions and scalable methods to build more flexible posterior approximations.</p><p>• In this thesis we have only focused on variational methods, as they provided a scalable way to perform approximate inference. A possible line of research is to focus on more efficient ways to perform other approximate inference methods (such as MCMC), similarly to the usage of the particle filters with learned importance distribution discussed in Section 4.3.2. In some cases it is in fact desirable to be able to use more computationally expensive inference methods in order to achieve better performances.</p><p>• As discussed in Section 4.6.2, probabilistic graphical models provide a principled way to introduce prior knowledge and structure in the model, and we can leverage existing messagepassing algorithms to perform approximate inference. A fundamental but challenging step for the more widespread usage of such techniques is the implementation of a message-passing library that integrates well with existing deep learning libraries.</p><p>• As always when using deep learning, training tricks can make a huge difference in terms of final performances of the model. In Section 4.8 we have introduced some of them, but it would be interesting to find even better ones derived from a deeper theoretical understanding of the learning process.</p><p>The application of these model to even more complex and challenging tasks can drive the research on many of the open questions presented above. Of particular interest is the usage of this class of models in applications for which we know that a correct model for the uncertainty is fundamental. This is the case for example in model-based reinforcement learning, where these models could be used within an agent for planning and reasoning under uncertainty.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 . 2 :</head><label>22</label><figDesc>Figure 2.2: Latent representations of different MNIST digits from 0 to 3 obtained passing the images through the inference network (left). Generated samples of MNIST digits obtained passing the elements of a 10 × 10 grid in latent space through the decoder (right).</figDesc><graphic coords="32,324.38,113.36,135.38,135.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 . 1 :</head><label>31</label><figDesc>Figure 3.1: A graphical representation of a state-space model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 . 2 :</head><label>32</label><figDesc>Figure 3.2: Ball tracking example, (x, y) plane.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 . 3 :</head><label>33</label><figDesc>Figure 3.3: Inference in the ball tracking example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 . 4 :</head><label>34</label><figDesc>Figure 3.4: Missing data imputation in the ball tracking example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 . 5 :</head><label>35</label><figDesc>Figure 3.5: Parameter learning in the ball tracking example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 . 6 :</head><label>36</label><figDesc>Figure 3.6: Tracking a ball in a video. At each time step t we observe a single frame of the video.</figDesc><graphic coords="49,84.11,106.29,57.72,57.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Posterior inference with a LGSSM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 . 7 :</head><label>37</label><figDesc>Figure 3.7: Ball tracking example with air resistance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 3 . 8 :</head><label>38</label><figDesc>Figure 3.8: Tracking the ball with a non-linear model and the Unscented Kalman filter/smoother.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 4</head><label>4</label><figDesc>Figure 4.1: A graphical representation of a recurrent neural network. Diamond-shaped units denote deterministic states.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4 . 2 :</head><label>42</label><figDesc>Figure 4.2: Inference networks for smoothing and filtering in a deep state-space model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 4 . 4 :</head><label>44</label><figDesc>Figure 4.4: Variational recurrent neural network (VRNN). The blue arrows are the additional dependencies introduced with respect to the VAE-RNN model of Figure 4.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 4 . 5 :</head><label>45</label><figDesc>Figure 4.5: VRNN in state-space form.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 4 . 6 :</head><label>46</label><figDesc>Figure 4.6: A stochastic recurrent neural network. The red arrows denote the different dependencies introduced with respect to the VRNN model of Figure 4.4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 4 . 7 :</head><label>47</label><figDesc>Figure 4.7: A Kalman variational auto-encoder. Solid arrows represent the generative model while dashed arrows represent the VAE inference network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 4 . 8 :</head><label>48</label><figDesc>Figure 4.8: A generative temporal model with spatial memory. Solid arrows represent the generative model while dashed arrows represent the VAE inference network. Green lines represent the additional dependencies with respect to the KVAE model of Figure 4.7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>d 1:T follows a delta distribution centered at d 1:T .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 5 . 3 :</head><label>53</label><figDesc>Figure 5.3: Visualization of the average KL term and reconstructions of the output mean and log-variance for two examples from the Blizzard test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>a • Simon Kamronn a • Ulrich Paquet b • Ole Winther a a DTU Compute, Technical University of Denmark, Denmark b Google DeepMind, United Kingdom Publication Status: Published in Advances in Neural Information Processing Systems 30, NIPS 2017. Selected for spotlight presentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 6</head><label>6</label><figDesc>Figure 6.1: A KVAE is formed by stacking a LGSSM (dashed blue), and a VAE (dashed red). Shaded nodes denote observed variables. Solid arrows represent the generative model (with parameters θ) while dashed arrows represent the VAE inference network (with parameters φ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>( a )</head><label>a</label><figDesc>Frames x t missing completely at random. (b) Frames x t missing in the middle of the sequence. (c) Comparison of encoded (ground truth), generated and smoothed trajectories of a KVAE in the latent space a. The black squares illustrate observed samples and the hexagons indicate the initial state.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 6 . 3 :</head><label>63</label><figDesc>Figure 6.3: Missing data imputation results.</figDesc><graphic coords="106,80.05,242.29,444.46,109.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>Figure 6.4: A visualisation of the dynamics parameter network α (k) t (a t-1 ) for K = 3, as a function of a t-1 . The three α (k) t 's sum to one at every point in the encoded space. The greyscale backgrounds in a) to c) correspond to the intensity of the weights α (k) t , with white indicating a weight of one in the dynamics parameter network's output. Overlaid on them is the full latent encoding a. d) shows the reconstructed frames of the video as one image.</figDesc><graphic coords="107,60.33,99.21,108.85,108.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>( a )</head><label>a</label><figDesc>Irregular polygon. (b) Box with gravity.(c) Pong-like environment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 6 . 5 :</head><label>65</label><figDesc>Figure 6.5: Generations from the KVAE trained on different environments. The videos are shown as single images, with color intensity representing the incremental sequence index t. In the simulation that resembles Atari's Pong game, the movement of the two paddles (left and right) is also visible.</figDesc><graphic coords="108,78.73,99.21,140.60,140.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head></head><label></label><figDesc>Figure 6.6: Training with missing data</figDesc><graphic coords="112,87.31,162.11,213.16,159.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head></head><label></label><figDesc>a • Danilo Rezende b • Yori Zwols b • Alexander Pritzel b • Ali Eslami b • Fabio Viola b a DTU Compute, Technical University of Denmark, Denmark b Google DeepMind, United Kingdom Publication Status: Published in the Proceedings of the 35th International Conference on Machine Learning, ICML 2018. Selected for long talk. Work done during an internship at Google DeepMind.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head></head><label></label><figDesc>Inferred positions during the 256 steps of the memorization phase, s t = (s 1 , s 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 7 . 2 :</head><label>72</label><figDesc>Figure 7.2: Image navigation experiment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head></head><label></label><figDesc>θ (z t |s t , m) = K k=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>.15)In (4.15) we have introduced the VAE inference network q φ (z t |x t , d t ) that, unlike the inference network used in the static case (Section 2.4.2), now also depends on the RNN state d t . A graphical representation can be found in Figure4.3b. Similarly to the inference network introduced in Section 2.4.2, we can define q φ (z t |x t , d t ) as a Gaussian distribution whose mean and diagonal covariance depend on the concatenation of x t and d t through a deep network parameterized by φ.</figDesc><table /><note><p><p>Using (4.11</p>) and (4.15) in (4.13), the prior p θ (d 1:T |u 1:T , d 0 ) cancels out, and the ELBO becomes</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>The dependence of z t on s t and the DND memory m in the VAE prior p(z t |s t , m). This corresponds to the red rectangle in Figure7.1a. Here, the memory contains the first τ = 256 time steps of the video, and we retrieve the K = 3 closest neighbours to s t (d is the distance).</figDesc><table><row><cell></cell><cell></cell><cell cols="2">DND memory</cell></row><row><cell>a t-1</cell><cell>a t</cell><cell>m</cell><cell></cell></row><row><cell></cell><cell></cell><cell>s 1</cell><cell>z 1</cell><cell>a t-1</cell><cell>a t</cell></row><row><cell></cell><cell>SSM</cell><cell>s 2</cell><cell>z 2</cell></row><row><cell cols="2">s t-1 Memory Memory s t z t-1 z t x t-1 x t VAE (a) Generative model of the</cell><cell cols="3">s t (b) s t-1 s 3 s 4 s 5 s 6 s 7 s 8 . . . s 256 z 3 z 4 z 5 z 6 z 7 z 8 . . . z 256 d 2 d 6 d 125 s 2 s 6 s 125 z 2 z 6 z 125 z t z t-1 x t-1 (c) Inference network for s t z t x t</cell></row><row><cell cols="2">GTM-SM. Red arrows</cell><cell></cell><cell></cell><cell>the GTM-SM.</cell></row><row><cell cols="2">represent dependencies</cell><cell></cell><cell></cell></row><row><cell cols="2">on the DND memory.</cell><cell></cell><cell></cell></row><row><cell cols="2">Dashed arrows repre-</cell><cell></cell><cell></cell></row><row><cell cols="2">sent the VAE inference</cell><cell></cell><cell></cell></row><row><cell>network.</cell><cell></cell><cell></cell><cell></cell></row></table><note><p><p>., a T ]. SSMs introduce at each time step a continuous stochastic variable s t , used as a latent representation of the state of the system. The temporal dynamics of Figure 7.1: Generative Temporal Model with Spatial Memory</p>the system are described by the transition density p(s t |s t-1 , a t ) of the SSM, that defines how to update the state at time t given the previous state s t-1 and the current action a t . The output variable z t depends on the state s t through the emission density p(z t |s t ).</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Comparison between true and predicted frames during the prediction phase of a test sequence (time steps t 257:264 and t 464:471 ).</figDesc><table><row><cell>True Predicted</cell><cell>t=257</cell><cell>t=264</cell><cell>... ...</cell><cell>t=464</cell><cell>t=471</cell></row><row><cell>(d)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Figure 7.5: Inference network for the GTM-SM using landmark information. Blue arrows represent dependencies on the reversed DND memory.With this choice for the inference network, the ELBO of the GTM-SM becomesF(θ, φ) = q φ (zt|xt) [log p θ (x t |z t )] -E q φ (st) [KL[q φ (z t |x t )||p θ (z t |s t , m)]] + -E q φ (s t-1 ) [KL [q φ (s t |s t-1 , a t , z t , m)||p θ (s t |s t-1 , a t )]] .</figDesc><table><row><cell>a t-1</cell><cell>a t</cell></row><row><cell>s t-1</cell><cell>s t</cell></row><row><cell cols="2">Memory Memory</cell></row><row><cell>z t-1</cell><cell>z t</cell></row><row><cell>x t-1</cell><cell>x t</cell></row><row><cell>T</cell><cell></cell></row><row><cell>t=τ +1</cell><cell></cell></row></table><note><p>E</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In other words, I have collected in this thesis all the knowledge I wish I had before starting to work on these topics.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>Variational inference can also be used with other divergences, see for example(Li and Turner,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>2016).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>In a standard auto-encoder the loss function typically used during training is in fact given by the reconstruction term in (2.12).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_4"><p>Before the advent of deep learning, HMMs have been widely used for speech recognition(Gales and Young,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>2008).Instead of using the raw waveform as observation, these systems typically use a frequency-domain representation of it (e.g. cepstral coefficients). Instead of modelling words in the latent states, it is more common to model phonemes. For clarity in the exposition, this is not discussed in this simplified example.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_6"><p>The same equations introduced in Section 2.3.1 apply, if we consider x = x1:T and z = z1:T .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_7"><p>To be consistent with the notation used throughout the whole thesis, we have changed the name of some variables with respect to the original paper of<ref type="bibr" target="#b21">Chung et al., (2015)</ref>. Also, we have generalized the model to have inputs ut instead of only presenting the special case ut = xt-1 as in the original paper.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_8"><p>github.com/casperkaae/parmesan. The code for SRNN is available at github.com/marcofraccaro/srnn.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_9"><p>2s•16Khz / 200 = 160</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_10"><p>While our main focus in this paper are videos, the same ideas could be applied more in general to any sequence</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_11"><p>We also experimented with the SRNN model from<ref type="bibr" target="#b39">(Fraccaro et al., 2016c)</ref> as it can do smoothing. However, the model is probably too complex for the task in hand, and we could not make it learn good dynamics.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_12"><p>Deep Markov models were previously referred to as deep Kalman filters.</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The results presented in this thesis would not have been possible without the support, collaborations, discussions and ideas of many different people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements ix</head></div>
			</div>


			<div type="funding">
<div><p>It constitutes a partial fulfillment of the requirements for acquiring a Ph.D. at the <rs type="affiliation">Technical University of Denmark</rs>. This PhD project was financed by <rs type="funder">Microsoft Research</rs> through <rs type="grantName">its PhD Scholarship Programme</rs> and by <rs type="funder">DTU Compute</rs>, and was supervised by <rs type="person">Ole Winther</rs> (<rs type="affiliation">DTU Compute</rs>) and <rs type="institution">Ulrich Paquet (Microsoft Research, now at Google DeepMind)</rs>. The PhD project was carried out at DTU during the period October 2014 -April 2018, except for two three-months leaves of absence taken for internships at <rs type="institution">Microsoft Research Cambridge</rs> (summer 2015, supervised by <rs type="person">Tom Minka</rs>) and <rs type="funder">Google DeepMind</rs> (summer 2017, supervised by Danilo Rezende).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_P6WrzU3">
					<orgName type="grant-name">its PhD Scholarship Programme</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contents</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary (English) i</head><p>Resumé (Summary in Danish) iii</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>List of Publications v Preface vii</head><p>Part II Abstract: How can we efficiently propagate uncertainty in a latent state representation with recurrent neural networks? This paper introduces stochastic recurrent neural networks which glue a deterministic recurrent neural network and a state space model together to form a stochastic and sequential neural generative model. The clear separation of deterministic and stochastic layers allows a structured variational inference network to track the factorization of the model's posterior distribution. By retaining both the nonlinear recursive structure of a recurrent neural network and averaging over the uncertainty in a latent path, like a state space model, we improve the state of the art results on the Blizzard and TIMIT speech modeling data sets by a large margin, while achieving comparable performances to competing methods on polyphonic music modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research papers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary material 6.8 Experimental details</head><p>We will describe here some of the most important experimental details. The rest of the details can be found in the code at github.com/simonkamronn/kvae.</p><p>Data generation. All the videos were generated using the physics engine Pymunk. We generated 5000 videos for training and 1000 for testing.</p><p>Encoder/Decoder architecture for the KVAE. As we only use image-based observations, the encoder is fixed to a three layer convolutional neural network with 32 units in each layer, kernel-size of 3x3, stride of 2, and ReLU activations. The decoder is an equally sized network using the Sub-Pixel <ref type="bibr" target="#b132">(Shi et al., 2016)</ref> procedure for deconvolution. In the pendulum experiment however we also test MLPs.</p><p>Optimization. As optimizer we use ADAM <ref type="bibr" target="#b75">(Kingma and Ba, 2014)</ref> with an initial learning rate of 0.007 and an exponential decay scheme with a rate of 0.85 every 20 epochs. Training one epoch takes 55 seconds on an NVIDIA Titan X and the model converges in roughly 80 epochs.</p><p>Training tricks for end-to-end learning. The biggest challenge of this optimization problem is how to avoid poor local minima, for example where all the focus is given to the reconstruction term, at the expense of the prior dynamics given by the LGSSM. To achieve a quick convergence in all the experiments we found it helpful to</p><p>• downweight the reconstruction term from of VAEs during training, that is scaled by 0.3. By doing this, we can in fact help the model to focus on learning the temporal dynamics.</p><p>• learn for the first few epochs only the the VAE parameters θ and φ and the globally learned matrices A (k) , B (k) and C (k) , but not the parameters of the dynamics parameter network α t (a 0:t-1 ). After this phase, all parameters are learned jointly. This allows the model to first learn good VAE embeddings and the scale of the prior, and then learn how to utilize the K different dynamics.</p><p>Choice of hyperparameters for the LGSSM. In most of the experiments we used a t ∈ R 2 , z t ∈ R 4 and K = 3. In the gravity experiments we used however z t ∈ R 5 as the model has no controls applied to it and needs to be able to learn a bias term due to the presence of the external force of gravity. The polygon experiments uses K = 7 as it needs to learn more complex dynamics.</p><p>In general, we did not find difficult to tune the parameters of the KVAE, as the model can learn to prune unused components (if flexible enough). We introduce two sets of latent variables: the frame encodings z = z τ +1:T and the SSM states s = s τ +1:T , and define the joint probability density p θ (x, z, s|a, v) following the factorization shown in Figure <ref type="figure">7</ref>.1a: </p><p>., τ , between s t and all the states s i in the DND memory. We then retrieve from the memory the K nearest states and the corresponding frame encodings, thus forming a set of triplets {(d (k) , s (k) , z (k) ), k = 1, .., K} that will be used as conditioning variables when computing the parameters of the VAE prior p θ (z t |s t , m). Using low-dimensional s t and prior knowledge of the environment dynamics when defining p θ (s t |s t-1 , a t ), we can make the GTM-SM learn to use s t to represent its position in the environment. At each time step the model will then retrieve from the memory what it has seen when it was previously close to the same location, and use this information to generate the current frame x t . The exact form of the VAE prior p θ (z t |s t , m) and transition model p θ (s t |s t-1 , a t ) is environment-dependent, and will be therefore introduced separately for each experiment in Section 7.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">Inference network</head><p>Due to the non-linearities in the VAE and the fact that p θ (z t |s t , m) depends on the DND memory, the posterior distribution p θ (z, s|x, a, v) of the GTM-SM is intractable. We therefore introduce a variational approximation q φ (z, s|x, a) that factorizes as</p><p>A graphical representation of the inference network of the GTM-SM is shown in Figure <ref type="figure">7</ref>.1c. q φ (z t |x t ) is an inference network that outputs the mean and variance of a Gaussian distribution, as typically done in VAEs. In (7.2) we then use the SSM transition probabilities, and we are therefore assuming that the GTM-SM can learn the prior dynamics of the moving agents accurately enough to infer the position of the agent given the sequence of actions. Notice that without this assumption it would be impossible to perform long term generation with the model during the prediction phase. In this phase, we can in fact only rely on the generative model, and not on the inference network as we do not know what the agent is seeing at each time step. To relax this assumption, the inference network could be extended to make use of the information stored in memory, for example by using landmark information when inferring the current position of the agent. This is discussed more in detail in Appendix 7.10 in the supplementary material, together with an initial experiment to assess the feasibility of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.3">Past encoder</head><p>The past encoder is used during the memorization phase to extract the information to store in the DND memory. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.4">Training</head><p>We learn the parameters θ and φ of the GTM-SM by maximizing the ELBO, a lower bound to the log-likelihood log p θ (x|a, v) obtained using Jensen's inequality and the inference network introduced in Section 7.3.2:</p><p>Exploiting the temporal factorization of both the joint distribution p θ (x, z, s|a, v) and the variational approximation q φ (z, s|x, a, v), we obtain after some calculations:</p><p>The ELBO is then formed by two terms: a reconstruction term and a KL divergence for the VAE. F(θ, φ) can be maximized with stochastic gradient ascent, approximating the intractable expectations with Monte Carlo integration with a single sample and using the reparameterization trick to obtain low-variance gradients <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b122">Rezende et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Experiments</head><p>We test the memorization and long-term generation capabilities of the GTM-SM on several 2D and 3D environments of increasing complexity. We use videos with action data from RL  First, the state of the agent is no longer only described by the position, but also from the direction in which the agent is looking and moving. We need to take into account two different coordinate systems, a global one that coincides with the state-space (s-space), and one that is fixed with the agent (agent-space). In the image navigation experiments these coordinate systems coincided. The actions act in agent-space, e.g. a "move right" action will make the agent go right in its reference frame, but depending on its orientation this could correspond to a move to the left in s-space. To deal with this issues we can introduce a rotation matrix R in the state transition equation, that translates a displacement M a t in agent-space to a displacements RM a t in s-space.</p><p>More in detail, we consider a 3-dimensional state-space, and define the state transition equations as</p><p>with s</p><p>(3)</p><p>t-1 being the 3rd component of the vector s t-1 and R(s</p><p>As for the image navigation experiment, we learn the parameters of M . While we do not explicitly tell the GTM-SM to use the first two component of the state vector as a position and the third one as an angle, the model will learn to use them in this way in order to maximize the ELBO. In the nearest neighbor search in the DND memory we need to take into account the periodicity of the angle, e.g. that an agent oriented at 30 • or 390 • is actually looking in the same direction. When computing distances, instead of using s</p><p>(3) t</p><p>we then use cos(s</p><p>t ) and sin(s</p><p>t ), that are possibly passed together with the first two components of s t through a linear layer that maps the resulting vector in a learned space where we use the Euclidean distance.</p><p>The second challenge arises from the fact that, unlike the image navigation experiment where there were a limited a number of possible positions for the agent, in the 3D labyrinth environment it is not reasonable to assume that during the memorization phase the agent will pass in all positions and look from them in all directions. To deal with this issue, we use as VAE prior p θ (z t |s t , m) a neural architecture that given the frames from the closest positions retrieved from the DND memory learns to combine the different views taking into account projective transformations. Details can be found in Appendix 7.7.2. Videos of long-term generations for these experiments are available in the supplementary material, see Appendix 7.8 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.2.1">Rotating agent in Labyrinth</head><p>In the first experiment we test the abilities of the GTM-SM to learn to model rotations with the transition model in (7.4) as well as to combine the information from different views. We use videos with action data of an agent that does two complete rotations while standing still in the same position. The rotational period is around 41 time steps, but we only store in memory the first τ = 33 (approximately 300 • ). We then ask the model to generate the remaining 60 • to finish the first rotation and a whole new rotation. From Figure <ref type="figure">7</ref>.3a we see an example of an observation from the test data and that the model has correctly learned to use the third component of the state vector s t to represent the orientation of the agent. In the prediction phase in Figure <ref type="figure">7</ref>.3c, we notice that the predictions from the model are very close to the ground truth, meaning that the model has learned to use the memory correctly. In particular, despite the fact that the frames from t = 33 to t = 41 were never seen during the memorization phase, the GTM-SM has learned to combine the information from other views. Notice that this experiment can be seen as a more challenging version of the Labyrinth rotation experiment of <ref type="bibr" target="#b45">(Gemici et al., 2017)</ref>, that used a fully observed first rotation with a rotational period of 15 time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.2.2">Walking agent in Labyrinth</head><p>We now use videos of a pre-trained RL agent walking in a room and solving a scavenger hunt task. In this case it is fundamental to extend the transition equation in (7.4) to model more carefully the physics of the walking agent, that make the displacement at a given time step depend not only on the current action, but also on the displacement at the previous time step. The agent is subject to momentum and friction, so that if it is moving in a certain direction at time t -1, it will still continue to move a bit in the same direction even at time t, regardless of the action a t . Also, despite the momentum, the displacement of the agent cannot increase indefinitely, i.e. there is saturation. We can model this by extending the way the displacement d t = M a t is calculated in (7.4). To take into account momentum and friction, we first add to d t = M a t a damped version of the displacement at the previous time step, i.e. σ(c f ) d t-1 , where σ(c f ) is a learned  In all folders, the first video corresponds to the test sequence used to produce the figures in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.8">Videos of long-term generation</head><p>7.9 Walking agent in Labyrinth (multiple rooms)</p><p>We consider the same trained model used for the results in section 7.4.2.2. In section 7.4.2.2, this model was tested on videos of length T = 300 of an agent walking in a single room, with both memorization and prediction phase of 150 time steps. To asses the long-term memorization and localization capabilities of the GTM-SM, we now test it on videos of the same agent walking in larger environments with multiple rooms. Each video is T = 450 time steps; we store 150 time steps in memory and we predict for 300 more. As the model is trained on single rooms, we cannot expect the VAE to correctly generate the corridors between rooms, but we can expect the model to be able to know its position and the textures in the room (i.e. the color of the walls and of the floor).</p><p>In Figure <ref type="figure">7</ref>.4 we show the predictions from the model after more than 250 time steps from the end of the memorization phase. As expected, the model fails in drawing the walls that form the corridor between the two rooms. However, we see that the GTM-SM correctly remembers the texture of rooms that it has previously visited and is able to predict the change in the color of the floor in the corridor. This is better viewed looking at the videos of this experiment, available in the folder videos/labyrinth_walk_multirooms/ in the supplementary material. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<title level="m">TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An Auxiliary Variational Method</title>
		<author>
			<persName><forename type="first">F</forename><surname>Agakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Black box variational inference for state space models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07367</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Inference and estimation in probabilistic time series models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Bayesian Time Series Models</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unified Inference for Variational Bayesian Linear Gaussian State-Space Models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007">2007. 19</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Theano: new features and speed improvements</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bergeron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.5590</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Interaction Networks for Learning about Objects, Relations and Physics</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Variational Algorithms for Approximate Bayesian Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Osendorfer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.7610</idno>
		<editor>Beal M. J.</editor>
		<imprint>
			<date type="published" when="2003">2014. 2003</date>
		</imprint>
		<respStmt>
			<orgName>Gatsby Computational Neuroscience Unit, University College London</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
	<note>Learning stochastic recurrent networks</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">DeepMind Lab</title>
		<author>
			<persName><forename type="first">C</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Teplyashin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lefrancq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Valdés</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sadik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>York</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gaffney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Petersen</surname></persName>
		</author>
		<idno>CoRR abs/1612.03801</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multidimensional Binary Search Trees Used for Associative Searching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bentley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Playing Doom with SLAM-Augmented Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Miksik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nardelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Siddharth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00380</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning (Information Science and Statistics)</title>
		<meeting><address><addrLine>Secaucus, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag New York, Inc. isbn</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">387310738</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Variational Memory Addressing in Generative Models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jimenez Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription</title>
		<author>
			<persName><forename type="first">N</forename><surname>Boulanger-Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6392</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Generating Sentences from a Continuous Space</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06349</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Importance Weighted Autoencoders</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A Compositional Object-Based Approach to Learning Physical Dynamics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno>ICLR. References</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Variational Lossy Autoencoder</title>
		<author>
			<persName><forename type="first">Chen</forename><forename type="middle">X</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Recurrent Environment Simulators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Racanière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ç</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="page" from="1724" to="1734" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName><forename type="first">Chung</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A recurrent latent variable model for sequential data</title>
		<author>
			<persName><forename type="first">Chung</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="page" from="2962" to="2970" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Inference Suboptimality in Variational Autoencoders</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03558</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">PILCO: A Model-based and Data-efficient Approach to Policy Search</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Deisenroth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on International Conference on Machine Learning. ICML&apos;11</title>
		<meeting>the 28th International Conference on International Conference on Machine Learning. ICML&apos;11</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequential Monte Carlo samplers</title>
		<author>
			<persName><forename type="first">Del</forename><surname>Moral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jasra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="411" to="436" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistiical Society</title>
		<imprint>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Factorized Variational Autoencoders for Modeling Audience Reactions to Movies</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Navarathna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Battenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<title level="m">Lasagne: First release</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An Introduction to Sequential Monte Carlo Methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sequential Monte Carlo Methods in Practice. Statistics for Engineering and Information Science</title>
		<imprint>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A Tutorial on Particle Filtering and Smoothing: Fifteen years Later</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johansen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On Sequential Monte Carlo Sampling Methods for Bayesian Filtering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Godsill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Andrieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Durbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koopman</surname></persName>
		</author>
		<title level="m">Time Series Analysis by State Space Methods: Second Edition. Oxford Statistical Science Series</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>OUP</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Variational Recurrent Auto-Encoders</title>
		<author>
			<persName><forename type="first">O</forename><surname>Fabius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6581</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Unsupervised Learning for Physical Interaction through Video Prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep visual foresight for planning robot motion</title>
		<author>
			<persName><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="2786" to="2793" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kamronn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30, NIPS</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">An Adaptive Resample-Move Algorithm for Estimating Normalizing Constants</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.01972</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<title level="m">Indexable Probabilistic Matrix Factorization for Maximum Inner Product Search</title>
		<imprint>
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generative Temporal Models with Spatial Memory for Partially Observed Environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning, ICML. Proceedings of Machine Learning Research</title>
		<meeting>the 35th International Conference on Machine Learning, ICML. Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Sequential Neural Models with Stochastic Layers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016c</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning Visual Predictive Models of Physics for Playing Billiards</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The Application of Hidden Markov Models in Speech Recognition. Foundations and trends in signal processing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Now Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep temporal sigmoid belief networks for sequence modeling</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="page" from="2458" to="2466" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Linear dynamical neural population models through nonlinear embeddings</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Identifying independence in Bayesian Networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="507" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Generative Temporal Models with Memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gemici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.04649</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Amortized Inference in Probabilistic Reasoning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 36th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2014">2014. CogSci 2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="517" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Parameter Estimation for Linear Dynamical Systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">University of Toronto technical report CRGTR</title>
		<imprint>
			<biblScope unit="volume">962</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Variational Learning for Switching State-Space Models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Neural Compuation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning Nonlinear Dynamical Systems Using an EM Algorithm</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 Conference on Advances in Neural Information Processing Systems II</title>
		<meeting>the 1998 Conference on Advances in Neural Information Processing Systems II</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Following a moving target -Monte Carlo inference for dynamic Bayesian models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Gilks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berzuini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generative Adversarial Nets</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Z-Forcing: Training Stochastic Recurrent Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>Côté</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Generating Sequences With Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<idno>arXiv:1308.085</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Neural Turing Machines</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Hybrid computing using a neural network with dynamic external memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grabska-Barwińska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Agapiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">DRAW: A recurrent neural network for image generation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Neural Adaptive Sequential Monte Carlo</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2611" to="2619" />
		</imprint>
		<respStmt>
			<orgName>NIPS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">PixelVAE: A Latent Variable Model for Natural Images</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Taiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05013.References</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Cognitive mapping and planning for visual navigation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Unifying Map and Landmark based Representations for Visual Navigation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.08125</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Haarnoja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ajay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<title level="m">Backprop KF: Learning Discriminative Deterministic State Estimators</title>
		<imprint>
			<publisher>NIPS</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</title>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Matthey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Burgess</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08">2017. 2017. 2017. August 2017</date>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
	<note>DARLA: Improving Zero-Shot Transfer in Reinforcement Learning</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<idno type="ISSN">0899-7667</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Composing graphical models with neural networks for structured representations and fast inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Wiltschko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">An introduction to variational methods for graphical models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="233" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">A New Extension of the Kalman Filter to Nonlinear Systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Julier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Uhlmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A New Approach to Linear Filtering and Prediction Problems</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ASME -Journal of Basic Engineering</title>
		<imprint>
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">On Particle Methods for Parameter Estimation in State-Space Models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kantas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chopin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data</title>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Soelch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Smagt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The Blizzard Challenge</title>
		<author>
			<persName><forename type="first">King</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Karaiskos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Ninth Annual Blizzard Challenge</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Semi-Supervised Learning with Deep Generative Models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Improved Variational Inference with Inverse Autoregressive Flow</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Deep Kalman Filters</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05121</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Structured Inference Networks for Nonlinear State Space Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Ungerleider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Haxby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="157" to="165" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
	<note>What&quot; and &quot;where&quot; in the human brain</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Labbe</surname></persName>
		</author>
		<ptr target="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python" />
		<title level="m">Kalman and Bayesian Filters in Python</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">The Neural Autoregressive Distribution Estimator</title>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Auto-Encoding Sequential Monte Carlo</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Igl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">DeepMPC: Learning Deep Latent Features for Model Predictive Control</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics: Science and Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Lenz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Knepper</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Saxena</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2010">2010. 2015</date>
		</imprint>
	</monogr>
	<note>MNIST handwritten digit database</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Mobile robot localization by tracking geometric beacons</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Durrant-Whyte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Robotics and Automation</title>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Learning to Generate with Memory</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning, ICML</title>
		<meeting>the 33nd International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">A Deep Generative Model for Disentangled Representations of Sequential Data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02991</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">RéNyi Divergence Variational Inference</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Neural Information Processing Systems. NIPS&apos;16</title>
		<meeting>the 30th International Conference on Neural Information Processing Systems. NIPS&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Variational Message Passing with Structured Inference Networks</title>
		<author>
			<persName><forename type="first">Lin</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hubacher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Bayesian Learning and Inference in Recurrent Switching Linear Dynamical Systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">On the Limited Memory BFGS Method for Large Scale Optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<editor>Math. Program</editor>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Stochastic Sequential Neural Networks with Structured Inference</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08695</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Sequential Monte Carlo methods for dynamic systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1032" to="1044" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Deep Learning Face Attributes in the Wild</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">CaGeM: A Cluster Aware Deep Generative Model</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Advances in Approximate Bayesian Inferences</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Auxiliary Deep Generative Models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Filtering Variational Objectives</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Discovery of the Kalman filter as a practical tool for aerospace and industry</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Schmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Mchutchon</surname></persName>
		</author>
		<title level="m">Nonlinear Modelling and Control using Gaussian Processes</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Key-Value Memory Networks for Directly Reading Documents</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-H</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Variational Boosting: Iteratively Refining Posterior Approximations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Foti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2420" to="2429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.0030.References</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Asynchronous Methods for Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Switching Kalman Filters</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<title level="m">Machine Learning: A probabilistic perspective</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">9780262018029</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Variational Sequential Monte Carlo</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Naesseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>AISTATS)</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Control of Memory, Active Perception, and Action in Minecraft</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chockalingam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning, ICML</title>
		<meeting>the 33nd International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Action-Conditional Video Prediction using Deep Networks in Atari Games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Perturbation Theory for Variational Inference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Opper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Susemihl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Advances in Approximate Bayesian Inferences</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Variational Bayesian Inference with Stochastic Search</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Masked Autoregressive Flow for Density Estimation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlakou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">An efficient implementation of Riemannian Manifold Hamiltionian Monte Carlo for Gaussian Process Models</title>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Neural Map: Structured Memory for Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Parisotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">Spatio-temporal video autoencoder with differentiable memory</title>
		<author>
			<persName><forename type="first">V</forename><surname>Patraucean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Handa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06309</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Neural Episodic Control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning. Proceedings of Machine Learning Research</title>
		<meeting>the 34th International Conference on Machine Learning. Machine Learning Research</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Readings in Speech Recognition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Waibel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K.-F</forename><surname>Lee</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Imagination-Augmented Agents for Deep Reinforcement Learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Racanière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reichert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Puigdomènech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Variational Bayesian Learning of Nonlinear Hidden State-space Models for Model Predictive Control</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tornio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Building blocks for variational Bayesian learning of latent variable models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="155" to="201" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title level="m" type="main">Hierarchical Variational Models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02386</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Maximum Likelihood Estimates of Linear Dynamic Systems</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Rauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Striebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Institute of Aeronautics and Astronautics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Variational Inference with Normalizing Flows</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">A unifying review of linear Gaussian models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="305" to="345" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Learning representations by backpropagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Markov Chain Monte Carlo and Variational Inference: Bridging the Gap</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
	<note>ICML&apos;15</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title level="m" type="main">One-shot Learning with Memory-Augmented Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06065</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Unscented Rauch-Tung-Striebel Smoother</title>
		<author>
			<persName><forename type="first">S</forename><surname>Särkkä</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title level="m" type="main">Bayesian Filtering and Smoothing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Särkkä</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Flunkert</surname></persName>
		</author>
		<title level="m">Bayesian Intermittent Demand Forecasting for Large Inventories</title>
		<imprint>
			<publisher>NIPS</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">Variational Bi-LSTMs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shabanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05717</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Real-time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network</title>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">An approach to time series smoothing and forecasting using the EM algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Shumway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Stoffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Time Series Analysis</title>
		<imprint>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Application of Statistical Filter Theory to the Optimal Estimation of Position and Velocity on Board a Circumlunar Vehicle</title>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">S N</forename><surname>Aeronautics</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Administration</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NASA technical report. National Aeronautics and Space Administration</title>
		<imprint>
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Estimating uncertain spatial relationships in robotics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Self</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheeseman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 1987 IEEE International Conference on Robotics and Automation</title>
		<meeting>1987 IEEE International Conference on Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title level="m" type="main">How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02282</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Ladder Variational Autoencoders</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">Unsupervised Learning of Video Representations using LSTMs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mansimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhudinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">End-to-end Memory Networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems. NIPS&apos;15</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Learning to Filter with Predictive State Inference Machines</title>
		<author>
			<persName><forename type="first">Sun</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Venkatraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Boots</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Machine Learning</title>
		<meeting>the Seventh International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Visual SLAM algorithms: a survey from 2010 to</title>
		<author>
			<persName><forename type="first">T</forename><surname>Taketomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Uchiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ikeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPSJ Transactions on Computer Vision and Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016">2017. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">An Unsupervised Ensemble Learning Method for Nonlinear Dynamic State-Space Models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Pixel Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">Oord</forename><forename type="middle">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning. ICML&apos;16</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning. ICML&apos;16</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">The Unscented Particle Filter</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Der Merwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Neural Information Processing Systems. NIPS&apos;00. References</title>
		<meeting>the 13th International Conference on Neural Information Processing Systems. NIPS&apos;00. References</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title level="m" type="main">From Pixels to Torques: Policy Learning with Deep Dynamical Models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Wahlström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Schön</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Deisenroth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02251</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">The Unscented Kalman Filter</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Der Merwe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Kalman Filtering and Neural Networks. Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Watter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boedecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<title level="m">Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images</title>
		<imprint>
			<publisher>NIPS</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Variational Message Passing</title>
		<author>
			<persName><forename type="first">Winn</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Yildirim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title level="m" type="main">Reinforcement Learning Neural Turing Machines</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00521</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title level="m" type="main">Neural SLAM: Learning to Explore with External Memory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boedecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09520</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11179</idno>
		<title level="m">State Space LSTM Models with Particle MCMC Inference</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
