<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active Learning for Discrete Latent Variable Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-06-06">June 6, 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Aditi</forename><surname>Jha</surname></persName>
							<email>aditijha@princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Princeton Neuroscience Institute</orgName>
								<address>
									<settlement>Princeton</settlement>
									<country>University</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zoe</forename><forename type="middle">C</forename><surname>Ashwood</surname></persName>
							<email>zashwood@princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Princeton Neuroscience Institute</orgName>
								<address>
									<settlement>Princeton</settlement>
									<country>University</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jonathan</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
							<email>pillow@princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Princeton Neuroscience Institute</orgName>
								<address>
									<settlement>Princeton</settlement>
									<country>University</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Active Learning for Discrete Latent Variable Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-06-06">June 6, 2023</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2202.13426v2[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Active learning seeks to reduce the amount of data required to fit the parameters of a model, thus forming an important class of techniques in modern machine learning. However, past work on active learning has largely overlooked latent variable models, which play a vital role in neuroscience, psychology, and a variety of other engineering and scientific disciplines.</p><p>Here we address this gap by proposing a novel framework for maximummutual-information input selection for discrete latent variable regression models. We first apply our method to a class of models known as "mixtures of linear regressions" (MLR). While it is well known that active learning confers no advantage for linear-Gaussian regression models, we use Fisher information to show analytically that active learning can nevertheless achieve large gains for mixtures of such models, and we validate this improvement using both simulations and real-world data. We then consider a powerful class of temporally structured latent variable models given by a Hidden Markov Model (HMM) with generalized linear model (GLM) observations, which has recently been used to identify discrete states from animal decisionmaking data. We show that our method substantially reduces the amount of data needed to fit GLM-HMM, and outperforms a variety of approximate methods based on variational and amortized inference. Infomax learning for latent variable models thus offers a powerful for characterizing temporally structured latent states, with a wide variety of applications in neuroscience and beyond.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Obtaining labeled data is a key challenge in many scientific and machine learning applications. Active learning provides a solution to this problem, allowing researchers to identify the most informative data points and thereby minimize the number of examples needed to fit a model. Bayesian active learning, also known as optimal or adaptive experimental design <ref type="bibr" target="#b68">(Verdinelli and Kadane, 1992;</ref><ref type="bibr" target="#b11">Chaloner and Verdinelli, 1995;</ref><ref type="bibr" target="#b13">Cohn et al., 1996;</ref><ref type="bibr" target="#b61">Ryan et al., 2016)</ref>, has had a major impact on a variety of disciplines, including neuroscience <ref type="bibr" target="#b42">(Lewi et al., 2007;</ref><ref type="bibr" target="#b43">Lewi et al., 2009;</ref><ref type="bibr" target="#b44">Lewi et al., 2011;</ref><ref type="bibr" target="#b17">DiMattina and Zhang, 2011;</ref><ref type="bibr" target="#b28">Gollisch and Herz, 2012;</ref><ref type="bibr" target="#b65">Shababo et al., 2013;</ref><ref type="bibr" target="#b18">DiMattina and Zhang, 2013;</ref><ref type="bibr" target="#b37">Kim et al., 2014;</ref><ref type="bibr" target="#b53">Park et al., 2014;</ref><ref type="bibr" target="#b56">Pillow and Park, 2016)</ref>, psychology <ref type="bibr" target="#b69">(Watson and Pelli, 1983;</ref><ref type="bibr" target="#b51">Myung et al., 2013;</ref><ref type="bibr" target="#b16">DiMattina, 2015;</ref><ref type="bibr" target="#b70">Watson, 2017;</ref><ref type="bibr" target="#b3">Bak and Pillow, 2018)</ref>, genomics <ref type="bibr" target="#b66">(Steinke et al., 2007)</ref> and compressed sensing <ref type="bibr" target="#b62">(Seeger, 2008;</ref><ref type="bibr" target="#b63">Seeger and Nickisch, 2008;</ref><ref type="bibr" target="#b67">Vasisht et al., 2014)</ref>.</p><p>The general setting for Bayesian active learning involves a probabilistic model P (y | x, θ), in which a parameter vector θ governs the probabilistic relationship between inputs x and labels or outputs y. To improve learning of θ, we wish to select inputs {x t } that will allow us to best estimate θ from the resulting dataset {x i , y i } t i=1 . In standard "fixed-design" experiments, the inputs are selected in advance, or drawn randomly from a predetermined distribution. In adaptive or "closed-loop" experiments, by contrast, the inputs are selected adaptively during the experiment based on the measurements obtained so far. Bayesian active learning methods provide a framework for optimally selecting these inputs, where optimality is defined by a utility function that characterizes the specific learning objective <ref type="bibr" target="#b49">(MacKay, 1992;</ref><ref type="bibr" target="#b13">Cohn et al., 1996;</ref><ref type="bibr" target="#b60">Roy and McCallum, 2001;</ref><ref type="bibr" target="#b56">Pillow and Park, 2016)</ref>.</p><p>Despite a burgeoning literature, the active learning field has devoted relatively little attention to latent variable models <ref type="bibr" target="#b13">(Cohn et al., 1996;</ref><ref type="bibr" target="#b30">Hefang et al., 2000;</ref><ref type="bibr" target="#b0">Anderson and Moore, 2005)</ref>. Latent variable models (LVMs) represent a class of highly expressive models with a vast range of applications. In neuroscience in particular, they have provided powerful descriptions of both neural population activity <ref type="bibr" target="#b59">(Rainer and Miller, 2000;</ref><ref type="bibr" target="#b35">Kemere et al., 2008;</ref><ref type="bibr" target="#b50">Miller and Katz, 2010;</ref><ref type="bibr" target="#b75">Yu et al., 2009;</ref><ref type="bibr" target="#b12">Chen et al., 2009;</ref><ref type="bibr" target="#b19">Escola et al., 2011;</ref><ref type="bibr" target="#b48">Linderman et al., 2016;</ref><ref type="bibr" target="#b27">Glaser et al., 2020;</ref><ref type="bibr" target="#b76">Zoltowski et al., 2020;</ref><ref type="bibr" target="#b33">Jha et al., 2021)</ref> and animal behavior <ref type="bibr" target="#b73">(Wiltschko et al., 2015;</ref><ref type="bibr" target="#b9">Calhoun et al., 2019;</ref><ref type="bibr" target="#b1">Ashwood et al., 2021;</ref><ref type="bibr" target="#b8">Bolkan et al., 2022;</ref><ref type="bibr" target="#b72">Weilnhammer et al., 2021;</ref><ref type="bibr" target="#b78">Zucchini et al., 2008)</ref>.</p><p>The key feature of latent-variable-based regression models is that the relationship between input x and output y is mediated by an unobserved or hidden state variable z. This provides such models with the flexibility to describe internal states of the system that cannot be observed directly. However, this flexibility comes with a cost: the likelihood (and by extension, the posterior) in LVMs is usually not available in closed-form. This complicates posterior inference and the calculation of expected utility, both of which are required for Bayesian active learning algorithms.</p><p>To address this gap in the literature, we introduce a Bayesian active learning framework for discrete latent variable models. We develop methods based on both MCMC sampling and variational inference to efficiently compute information gain and select informative inputs in adaptive experiments. We illustrate our framework with applications to two specific families of latent variable models:</p><p>(1) a mixture of linear regressions (MLR) model; and (2) input-output Hidden Markov Models with generalized linear model (GLM) observations (GLM-HMM). We compare the efficiency of different methods, including a recent method based on amortized inference using deep networks <ref type="bibr" target="#b23">(Foster et al., 2021)</ref>, and show that in both model families our approach provides dramatic speedups in learning over previous methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Bayesian active learning methods have been developed for a wide range of different models, from generalized linear models <ref type="bibr" target="#b10">(Chaloner et al., 1984;</ref><ref type="bibr" target="#b52">Paninski, 2005;</ref><ref type="bibr" target="#b36">Khuri et al., 2006;</ref><ref type="bibr" target="#b42">Lewi et al., 2007;</ref><ref type="bibr" target="#b43">Lewi et al., 2009;</ref><ref type="bibr" target="#b44">Lewi et al., 2011;</ref><ref type="bibr" target="#b2">Bak et al., 2016;</ref><ref type="bibr" target="#b3">Bak and Pillow, 2018)</ref> to neural networks <ref type="bibr" target="#b13">(Cohn et al., 1996;</ref><ref type="bibr" target="#b17">DiMattina and Zhang, 2011;</ref><ref type="bibr" target="#b18">DiMattina and Zhang, 2013;</ref><ref type="bibr" target="#b15">Cowley et al., 2017;</ref><ref type="bibr" target="#b25">Gal et al., 2017;</ref><ref type="bibr" target="#b38">Kirsch et al., 2019;</ref><ref type="bibr" target="#b74">Wu et al., 2021)</ref>. One body of work has focused on Bayesian active learning for models with implicit likelihoods <ref type="bibr" target="#b39">(Kleinegesse and Gutmann, 2020;</ref><ref type="bibr" target="#b32">Ivanova et al., 2021)</ref>. Another recent line of work has focused on general-purpose real-time active learning using amortized inference in deep neural networks, an approach known as Deep Adaptive Design (DAD) <ref type="bibr" target="#b23">(Foster et al., 2021)</ref>. However, the literature on active learning for latent variable models is sparse, limited to a few specific model classes and tasks such as density modeling <ref type="bibr" target="#b13">(Cohn et al., 1996;</ref><ref type="bibr" target="#b30">Hefang et al., 2000)</ref> and state estimation for standard HMMs <ref type="bibr" target="#b0">(Anderson and Moore, 2005)</ref>. The approach we develop here grows out of previous work on Bayesian active learning methods for generalized linear models <ref type="bibr" target="#b42">(Lewi et al., 2007;</ref><ref type="bibr" target="#b43">Lewi et al., 2009;</ref><ref type="bibr" target="#b31">Houlsby et al., 2011;</ref><ref type="bibr" target="#b3">Bak and Pillow, 2018)</ref>. However, our contribution is novel as we tailor Bayesian active learning for latent variable models, especially those used in neuroscience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discrete latent variable models (LVMs)</head><p>Before turning to the problem of active learning, we provide a brief description of discrete latent variable regression models. The model has two basic components: a prior over the latent variable and a conditional distribution of the response given the stimulus and latent. Formally, this model architecture can be expressed by a pair of equations:</p><formula xml:id="formula_0">z ∼ P (z | θ) (1) y | x, z ∼ P (y | x, z, θ),<label>(2)</label></formula><p>where z ∈ {1, ..., K} is a discrete latent variable governing the internal state of the system, x ∈ R D is the input or stimulus, y ∈ Y is the response (which may be continuous or discrete), and θ ∈ Ω denotes a set of model parameters governing both prior and conditional response distributions. Fig. <ref type="figure" target="#fig_1">1A</ref> shows an illustration of an example discrete latent variable model, where the conditional distribution of the response given the stimulus and latent is given by a generalized linear model. The discrete latent variable z governs which of the three generalized linear models determines the response for a given trial. Finally, in a latent variable model, the conditional probability of the response given the stimulus requires marginalizing over the latent variable:</p><formula xml:id="formula_1">P (y | x, θ) = K k=1 P (y | x, z = k, θ)P (z = k | θ).</formula><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Infomax learning</head><p>The general goal of active learning is to select inputs that will allow us to infer the model parameters θ in as few trials as possible. Bayesian active learning formalizes this in terms of a utility function that specifies the goal of learning, e.g., to maximize mutual information <ref type="bibr" target="#b43">(Lewi et al., 2009)</ref>, minimize mean-squared error <ref type="bibr" target="#b40">(Kuck et al., 2006)</ref>, or minimize prediction error <ref type="bibr" target="#b13">(Cohn et al., 1996;</ref><ref type="bibr" target="#b60">Roy and McCallum, 2001</ref>).</p><p>Here we select as utility the mutual information between response y and the model parameters θ conditioned on the input x. Intuitively, this corresponds to selecting the stimulus for which the resulting response will provide the greatest reduction in uncertainty about the model parameters, quantified in bits. Active learning with mutual information as utility is commonly known as infomax learning, and it has been widely applied in both machine learning and neuroscience settings <ref type="bibr" target="#b49">(MacKay, 1992;</ref><ref type="bibr" target="#b42">Lewi et al., 2007;</ref><ref type="bibr" target="#b43">Lewi et al., 2009;</ref><ref type="bibr" target="#b53">Park et al., 2014;</ref><ref type="bibr" target="#b31">Houlsby et al., 2011;</ref><ref type="bibr" target="#b56">Pillow and Park, 2016;</ref><ref type="bibr" target="#b3">Bak and Pillow, 2018;</ref><ref type="bibr" target="#b17">DiMattina and Zhang, 2011)</ref>.</p><p>Typical frameworks for infomax learning involve a "greedy" approach, where inputs are selected one-at-a-time to maximize information provided by y about θ on each trial. In this setting, the experimenter selects the stimulus x t on trial t according to:</p><formula xml:id="formula_2">x t = arg max x I(θ, y t | x, D t-1 ),<label>(4)</label></formula><p>where I represents mutual information, y t is the (as yet unobserved) response on trial t, and we have also conditioned on D t-1 = {(x τ , y τ )} t-1 τ =1 , the stimulus-response collected previously in the experiment. This selection rule is equivalent to saying that we maximize the expected information gain about θ, or minimize the expected entropy of the posterior over θ <ref type="bibr" target="#b49">(MacKay, 1992)</ref>.</p><p>The mutual information (also known as Shannon information) between y t and θ given x and D t-1 , can be written in several equivalent forms <ref type="bibr" target="#b14">(Cover and Thomas, 1991)</ref>, one of which is:</p><formula xml:id="formula_3">I(θ, y t | x, D t-1 ) = H(y t ; x, D t-1 ) -H(y t | θ ; x, D t-1 )<label>(5)</label></formula><p>where</p><formula xml:id="formula_4">H(y t | θ ; x, D t-1 ) = - Ω Y P (y t , θ | θ, x, D t-1 ) log P (y t , | θ, x, D t-1 ) dy t dθ (6)</formula><p>denotes the conditional entropy of y given θ, and</p><formula xml:id="formula_5">H(y t ; x, D t-1 ) = - Y P (y t | x, D t-1 ) log P (y t | x, D t-1 ) dy t (7)</formula><p>is the marginal entropy of y, with both terms conditioned on the stimulus x and previously collected data D t-1 . In the above expressions, the integrals over y can be replaced by sums when y is discrete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Infomax learning for discrete LVMs</head><p>The challenge in applying infomax learning to latent variable models is that the posterior over the model parameters, p(θ | D t-1 ), as well as the conditional response distribution, p(y t | θ, x, D t-1 ), are not available in closed form, due to the fact that they require marginalization over the latent variable. In fact, for discrete latent variable models, these distributions are not even guaranteed to be unimodal (unlike in generalized linear regression models). Furthermore, the marginal response distribution P (y t | x, D t-1 ) in eq. 7, requires marginalizing the conditional response distribution over the parameters:  Here the discrete latent variable z determines which of the three generalized linear models at the bottom determines the input-output mapping on any trial. (B) Infomax learning for discrete latent variable models. On trial t, present an input x t to the system of interest (e.g., a mouse performing a decisionmaking task) and record its response y t . We assume this response depends on the stimulus (input) as well as an internal or latent state z t , as specified by the model P (y t | x t , z t , θ). Second, update the posterior distribution over model parameters θ given the data collected so far in the experiment, D t = {x 1:t , y 1:t } using either MCMC sampling or variational inference. Third, select the input for the next trial that maximizes information gain, or the mutual information between the next response y t+1 and the model parameters θ.</p><formula xml:id="formula_6">P (y t | x, D t-1 ) = P (y t | θ, x, D t-1 ) P (θ | D t-1 ) dθ,<label>(8)</label></formula><p>which exacerbates the problem of rapidly computing and optimizing the mutual information between trials.</p><p>To overcome this challenge, we develop two different approaches for infomax active learning in discrete latent variable models: one based on sampling <ref type="bibr" target="#b31">(Houlsby et al., 2011;</ref><ref type="bibr" target="#b3">Bak and Pillow, 2018)</ref> and another based on variational inference (VI) <ref type="bibr" target="#b7">(Blei et al., 2017)</ref>, which we describe in the next two sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Sampling-based approach</head><p>First, we propose a method for infomax learning of discrete latent variable models that relies on Markov Chain Monte Carlo (MCMC) sampling. Specifically, we use Gibbs sampling to draw samples of θ from P (θ | D t-1 ), the posterior distribution over parameters given the data collected so far in the experiment. These samples are then used to evaluate the conditional mutual information gain, as described below.</p><p>Gibbs sampling allows us to obtain an alternating chain of samples of the latents z 1:t-1 and the model paramater θ from their joint conditional distribution P (θ, z 1:t-1 | x, D t-1 ). As a result, we can get M samples of the model parameter from its posterior at a given trial t, {θ j } M j=1 ∼ P (θ | D t-1 ) (effectively marginalizing over the latents). This, however, is not trivial for models where the conditional P (θ | z 1:t , D t-1 ) is not available in closed form (such as GLM-HMMs). We developed a modified version of Gibbs sampling for such cases, which we discuss in detail later in sec. 7.</p><p>Each sample, θ j , obtained using Gibbs sampling parameterizes a model with conditional probability of the response y given by P (y | θ j , x, D t-1 ), which can be evaluated by marginalizing over the discrete latents (using eq. 3). This, then, allows us to compute the marginal likelihood of the response y:</p><formula xml:id="formula_7">P (y | x, D t-1 ) ≈ 1 M M j=1 P (y | θ j , x, D t-1 )<label>(9)</label></formula><p>Using the conditional and marginal likelihoods, we can next compute sample-based versions of the entropy terms (eqs. 6 and 7) as follows:</p><formula xml:id="formula_8">H(y | θ ; x, D t-1 ) ≈ 1 M M j=1 Y P (y | θ j , x, D t-1 ) log P (y | θ j , x, D t-1 )dy<label>(10)</label></formula><p>and</p><formula xml:id="formula_9">H(y ; x, D t-1 ) = P (y | x, D t-1 ) log P (y | x, D t-1 )dy (11) ≈ Y 1 M M j=1 P (y | θ j , x, D t-1 ) log 1 M M j=1 P (y | θ j , x, D t-1 ) dy. (<label>12</label></formula><formula xml:id="formula_10">)</formula><p>Substituting the above equations into the expression for mutual information (eq. 5), we obtain a convenient form for the mutual information that we use in our experiments:</p><formula xml:id="formula_11">I(θ ; y | x, D t-1 ) ≈ 1 M M j=1 D KL P (y | θ j , x, D t-1 ) || P (y | x, D t-1 )<label>(13)</label></formula><p>where D KL is the Kullback-Leibler divergence (KL divergence, a measure of how different one probability distribution is from another, when both are defined on the same sample space). Here:</p><formula xml:id="formula_12">D KL P (y | θ j , x, D t-1 ) || P (y | x, D t-1 ) = Y P (y | θ j , x, D t-1 ) log P (y | θ j , x, D t-1 ) P (y | x, D t-1 ) . (<label>14</label></formula><formula xml:id="formula_13">)</formula><p>In all our experiments, y ∈ R, so we discretize y allowing us to replace the integrals over y in the above expressions with summations.</p><p>Eq. 13 makes clear that information-based active learning can be equivalently seen as comparing the prediction of the models given by each of the M samples, P (y | θ j , x, D t-1 ), with the average model prediction P (y | x, D t-1 ), and choosing the input which maximizes the average difference between predictions of individual models and the consensus model. This shows that infomax learning can also be seen as a form of "query-by-committee" <ref type="bibr" target="#b64">(Settles, 2009)</ref>. This sample-based formulation of infomax learning is also referred to as Bayesian Active Learning by Disagreement <ref type="bibr" target="#b31">(Houlsby et al., 2011;</ref><ref type="bibr" target="#b25">Gal et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Variational approach</head><p>While Gibbs sampling allows us to accurately draw samples of the model parameter θ from its posterior P (θ | D t-1 ), it is often slow and computationally inefficient. As an alternative, we therefore explored the use of variational inference (VI) <ref type="bibr" target="#b7">(Blei et al., 2017)</ref> to compute a computationally efficient approximation to the posterior distribution over the model parameters P (θ | D t-1 ). VI is typically faster than Gibbs sampling, but may be less accurate as it requires use of a simplified approximation to the posterior distribution over model parameters.</p><p>Here we use mean-field variational inference, which assumes that the model parameters and the latents are independent of each other:</p><formula xml:id="formula_14">q(θ, z 1:t-1 ) = q 1 (θ)q 2 (z 1:t-1 )<label>(15)</label></formula><p>where q 1 and q 2 represent the approximate variational posteriors over θ and z 1:t-1 respectively. We first assume simple tractable distributions to be the prior distributions over θ (such as a multivariate Gaussian) and over the latents (such as an independent categorical distribution for z at every trial). We then use coordinate ascent to optimize the parameters of these assumed distributions in order to minimize the Kullback-Leibler divergence between the approximate and true posteriors:</p><formula xml:id="formula_15">q * 1 (θ)q * 2 (z 1:t-1 ) = arg min q * 1 (θ)q * 2 (z 1:t-1 ) D KL (q * 1 (θ)q * 2 (z 1:t-1 ) || P (θ, z 1:t-1 | D t-1 )) (16)</formula><p>We describe the coordinate ascent update steps in detail for the model classes that we consider in the appendix (sec. A6 and sec. A2).</p><p>However, having an approximate posterior over θ is insufficient to compute mutual information in closed form in the setting of discrete LVMs. The conditional response distribution p(y t | x, D t-1 ) is still not available in closed form, and is required to compute the conditional entropy of y given θ, as well as the marginal entropy of y. Hence, we instead draw samples of the model parameter {θ j } M j=1 from q * 1 (θ) (as opposed to the true posterior in case of Gibbs sampling, which makes VI much faster) and then use these samples to compute mutual information as described above in eq. 13.</p><p>To summarize, Figure <ref type="figure" target="#fig_1">1B</ref> shows an illustration of infomax active learning for discrete LVMs in the context of a neuroscience experiment. The animal receives an input x t and generates a response y t on each trial t. In the sampling-based approach, we then use samples of the joint distribution over latents z and parameters θ to evaluate the expectations required for computing mutual information. In the variational inference-based approach, we compute an approximate posterior over θ given D t and then draw samples from it to evaluate mutual information, as given in eq. 13. Finally, we select the stimulus for trial t + 1 which maximizes the conditional mutual information between the response and model parameters,</p><formula xml:id="formula_16">I(y t+1 , θ | x, D t ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Mixture of linear regressions (MLR)</head><p>We now illustrate the power of our proposed infomax learning frameworks with applications to specific latent variable models, the first of which is a mixture of linear regressions (MLR) model. This model has a rich history in machine learning <ref type="bibr" target="#b46">(Li and Liang, 2018;</ref><ref type="bibr" target="#b24">Gaffney and Smyth, 1999;</ref><ref type="bibr" target="#b5">Bengio and Frasconi, 1995)</ref>.It consists of an independent mixture of K distinct linear-Gaussian regression models (Fig. <ref type="figure" target="#fig_2">2A</ref>). Given an input, x ∈ R D , the corresponding output observation y ∈ R arises from one of the K components as determined by the latent state z ∈ {1, ..K}. Formally, the model can be described as:</p><formula xml:id="formula_17">z t ∼ Cat(π) (<label>17</label></formula><formula xml:id="formula_18">)</formula><formula xml:id="formula_19">y t | (x t , z t = k) ∼ N (x t ⊤ w k , σ 2 ) (<label>18</label></formula><formula xml:id="formula_20">)</formula><p>where π ∈ ∆ K-1 denotes a discrete or categorical distribution over the set of K mixing components, and w k ∈ R D denotes the weights of the linear regression model in state k. The model parameters to be learned are thus given by θ = {w 1:K , π}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Fisher information analysis</head><p>Before applying our algorithm to the MLR model, it is worth asking whether there is any hope that infomax learning will be helpful in this setting. In the standard linear-Gaussian regression model, it is straightforward to see that posterior covariance of model parameters, given by (C</p><formula xml:id="formula_21">-1 0 + 1 σ 2 T t=1 x t x t ⊤ ) -1</formula><p>where C 0 is the prior covariance, is independent of the outputs {y t }. This means that an optimal design can be planned out prior to the experiment, and there is no benefit to taking into account the output y t when selecting the next input x t+1 <ref type="bibr" target="#b10">(Chaloner et al., 1984;</ref><ref type="bibr" target="#b49">MacKay, 1992)</ref>. Adaptive experimental design thus provides no benefit for the standard linear-Gaussian regression model. Intriguingly, however, this does not hold for the MLR model.</p><p>To quantify the asymptotic performance of infomax learning for the MLR model, and to gain insight into which inputs are most informative, we can examine the Fisher information of the MLR model <ref type="bibr" target="#b52">(Paninski, 2005)</ref>. The Fisher information matrix for a model with parameters θ is a matrix with i, j'th element</p><formula xml:id="formula_22">J ij = E ∂ ∂θ i log P (y | x, θ) ∂ ∂θ j log P (y | x, θ)</formula><p>, where expectation is taken with respect to P (y | x, θ). For an MLR model in D dimensions with K components, the Fisher information matrix for the weights given an input vector x is a KD×KD matrix whose i, j'th block is given by:</p><formula xml:id="formula_23">J [i,j] (x) = 1 σ 4 E (y-x ⊤ w i )(y-x ⊤ w j )P (z = i | y, x, θ)P (z = j | y, x, θ) xx ⊤ , (<label>19</label></formula><formula xml:id="formula_24">)</formula><p>where expectation is taken with respect to the marginal response distribution (see Appendix A4 for details). Although this expectation cannot generally be computed analytically <ref type="bibr" target="#b4">(Behboodian, 1972)</ref>, we can compute it for two extremal cases of interest: (1) perfect identifiability, when the response y gives perfect information about the latent variable; and (2) perfect non-identifiability, when the response provides no information about the latent variable.</p><p>To illustrate these two cases, Fig. <ref type="figure" target="#fig_2">2B</ref> shows an example MLR model with two 2D weight vectors pointing in opposite directions along the x 1 axis. If observation noise variance σ 2 is small, a unit vector input with 0 degree orientation renders the latent state perfectly identifiable, since the response will be large and positive if z = 1 and large and negative if z = 2. On the other hand, an input at 90 or 270 degrees gives rise to perfect non-identifiability; these inputs are orthogonal to both w 1 and w 2 , so observing the output y will provide no information about which model component (weights w 1 or w 2 ) produced it.</p><p>In the case of perfect identifiability, the Fisher information matrix simplifies to a block diagonal matrix with 1 σ 2 π i xx ⊤ in its ith block (see A4). The trace of the Fisher information matrix, which quantifies the total Fisher information provided by this input, is 1 σ 2 ||x|| 2 , which remarkably, is the same Fisher information as in the standard (non-mixture) linear regression model. In the case of non-identifiability, on the other hand, the Fisher information is a rank-1 matrix with block i, j given by 1 σ 2 π i π j xx ⊤ . In the case where all class prior probabilites are equal (π i = 1/K ∀i), the trace is only 1 Kσ 2 ||x|| 2 , revealing that non-identifiable inputs can provide as little as 1/K as much Fisher information as inputs with perfect identifiability. The dependence on the number of components, K, is worth noting as it suggests that active learning yields larger improvements for models with more components.</p><p>Figure <ref type="figure" target="#fig_2">2C</ref> shows the (numerically computed) Fisher information as a function of input angle for the MLR model shown in panel B, for different noise levels σ 2 . This confirms the analytic result that Fisher information for this 2-state MLR model is 1/2 its maximal value for inputs in the "non-identifiable" region, and shows that this sub-optimal region grows wider as noise variance increases. This analysis confirms that active learning can improve MLR model fitting, and shows that the most informative inputs are those that (in addition to have large L 2 norm) provide information about the discrete latent variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Infomax learning algorithm for MLR</head><p>To perform infomax learning for MLR models, we used Gibbs sampling <ref type="bibr" target="#b6">(Bishop, 2006)</ref> to obtain samples from the posterior over model parameters. This involved sampling from the joint distribution over the latents z and the model parameters θ = {w 1:K , π}, conditioned on the data. As an alternate strategy, we also drew samples of the model parameters from a variational approximation to its posterior (see A1 and A2 for details). Next, using M samples of the model parameters, {w j 1:K , π j } M j=1 , we computed the mutual information between the system's output and the parameters (Eq. 13) for a grid of candidate inputs by substituting the likelihood term, P (y | θ j , x, D t ) = K k=1 π j k N (y | w j k • x, 1), into Eq. 13. Finally, we selected the input x that maximized Eq. 13 and presented it to the system on the next trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Numerical experiments for MLRs</head><p>To evaluate our active learning framework for MLRs, we first performed two simulations. In our first experiment, illustrated in Fig. <ref type="figure" target="#fig_2">2B</ref>, we considered a grid of possible inputs on the unit circle, spaced 10 • apart. (This was motivated by the fact that the optimal stimuli for the linear regression model have maximal L 2 norm, and thus lie on the surface of a hypersphere centered at zero). On every trial, we selected an input from this set and sampled the output from one of K = 2 regression models. We fixed the state probabilities as π = [0.6, 0.4]. The regression models had the form: y t = w k ⊤ x t + ϵ where we fixed the generative parameters as:</p><formula xml:id="formula_25">w 1 = [-1, 0], w 2 = [1,</formula><p>0] and ϵ ∼ N (0, 0.1).</p><p>Our second experiment followed the same setup, but selected inputs from a set of 1000 candidate points sampled uniformly on the 10-D hyper-sphere. The output again arse from one of the two regression models, now with weights oriented along Figure <ref type="figure">3</ref>: Histogram showing inputs selected by our active learning method (over the course of 200 trials) on mixture of linear regressions (MLRs), when inputs lie on a 2D circle (see Fig. <ref type="figure" target="#fig_2">2</ref>). We find a drop in probability at 90 • , this is also predicted by the Fisher Information analysis discussed in text for infomax (using Gibbs sampling). However, we do not see such a trend while using DAD. Inputs selected by DAD were distributed over the unit circle with modes at multiple of 30 • . (DAD requires a continuous range of inputs, hence it select inputs from all over the unit circle as opposed to a discrete list.)</p><p>the first two major axes, w 1 = [1, 0, ..., 0] and w 2 = [0, 1, 0...0], again with mixing weights π = [0.6, 0.4].</p><p>The task at hand is to learn the generative parameters of the model: {w 1 , w 2 , π}. We compared several input-selection strategies including our infomax learning methods (using Gibbs sampling and variational inference), a random sampling approach which selected inputs uniformly from the set of all possible inputs, and the Deep Adaptive Design (DAD) method proposed by <ref type="bibr" target="#b23">(Foster et al., 2021)</ref>. We adapted the code for DAD to use it for input selection in MLRs (details in A3). In all cases, after input selection, at each trial we inferred the model parameters using Gibbs sampling.</p><p>A natural quantity to track during infomax learning is the entropy of the posterior distribution over the model parameters θ <ref type="bibr" target="#b3">(Bak and Pillow, 2018)</ref>, which we approximate as log(|cov(θ)|) (we drop the additional term D 2 (1 + 2π) as it is constant for our experiments). We computed the sample estimate of this posterior entropy using the M = 500 samples obtained from Gibbs sampling at every trial. We found that posterior entropy decreased fastest for infomax with Gibbs sampling ("Gibbs-infomax", top panel of Fig. <ref type="figure" target="#fig_2">2D</ref>). In 10-d, this difference was even more prominent (top panel of Fig. <ref type="figure" target="#fig_2">2E</ref>). We also tracked the root mean squared error (RMSE) between the true and estimated parameters. The bottom panel of Fig. <ref type="figure" target="#fig_2">2D</ref> shows that for the 2D simulation, RMSE decreased fastest for Gibbs-infomax stimulus selection.</p><p>Finally, Figure <ref type="figure" target="#fig_2">2E</ref> shows that in a model with 10D inputs, RMSE decreased fastest for Gibbs-infomax, followed by infomax with variational inference ("VIinfomax"). This shows that evaluating information gain using samples from the true posterior produced substantially better learning than with samples from the variational posterior. Furthermore, while DAD was comparable to VI-infomax learning 2 dimensions, it did not perform well for high-dimensional inputs. We feel these results were particularly impressive given that RMSE was not the objective function we optimized. Overall, our proposed Gibb-infomax algorithm produced highly sample-efficient learning of MLRs in comparison to other methods.</p><p>In case of 2D inputs, this improvement can be attributed to the fact that Fisher Information drops dramatically when the angle between the weight vectors and the input is close to 90 • or 270 • (as discussed above). Hence, our active learning strategy outperformed random sampling by avoiding the uninformative inputs orthogonal to the model weights. Fig. <ref type="figure">3</ref> shows that our algorithm did indeed avoid these inputs. As the Fisher information analysis given above makes clear, higher dimensionality leads to increased probability that randomly selected inputs will fall in the region of non-identifiability (i.e., be orthogonal to all of the model weight vectors w k ), given that random vectors in high dimensions have high probability of being orthogonal <ref type="bibr" target="#b29">(Gorban and Tyukin, 2018)</ref>. This aligns with our finding that the benefits of active learning are more pronounced in higher dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Application: CA Housing Dataset</head><p>Finally, we applied infomax learning to the California housing dataset of (Kelley Pace and <ref type="bibr" target="#b34">Barry, 1997)</ref>. This dataset contains the median house price, in 1990, as well as 8 predictors of house price for 20,640 census block groups. The dataset is accessible via scikit-learn <ref type="bibr" target="#b54">(Pedregosa et al., 2011)</ref>. We fit MLRs with different numbers of states to a reduced dataset of 5000 samples and found that a 3 state MLR described the CA housing dataset well (Figure <ref type="figure" target="#fig_3">4C</ref>), and offered a dramatic improvement in predictive power relative to standard linear regression (a 1 state MLR). Figures <ref type="figure" target="#fig_3">4A</ref> and<ref type="figure" target="#fig_3">4B</ref> show the best fitting mixing weights and state weights for this 3 state MLR. Next, we wanted to understand if infomax learning would allow us to learn the best-fitting 3 state MLR parameters with fewer samples. Figures <ref type="figure" target="#fig_3">4D</ref> and<ref type="figure" target="#fig_3">4E</ref> show that Gibbs-infomax learning did indeed substantially reduce the number of samples required to learn the model parameters.</p><p>In Figure <ref type="figure" target="#fig_3">4B</ref>, it is clear that the three discrete states differed most according to the weights placed on the 'AveOccup' (average occupancy), 'Latitude' and 'Longitude' covariates. Intriguingly, in Figure <ref type="figure" target="#fig_3">4F</ref>, we see that the inputs selected by infomax learning had greater variance for the Latitude and Longitude covariates compared to those selected with random sampling (the red crosses are always above the blue dots). This is a useful external validation that infomax selects inputs in a manner that accords with intuition.   <ref type="bibr" target="#b34">and Barry, 1997)</ref>. (A) Best fitting mixing weights for 3 state MLR to 5000 samples of the dataset. (B) Best fitting state weights for 3 state MLR to 5000 samples of the CA housing dataset. Orange, green and blue represent states 1, 2 and 3 respectively. Black represents the linear regression fit. (C) BIC as number of MLR states is varied from 1 (standard linear regression) to 5. We select the 3 state model as BIC begins to level off beyond 3 states. (D) Posterior entropy between the 3 state MLR parameters obtained using 5000 samples (parameters shown in (A) and (B)) and recovered parameters as a function of the number of samples for random sampling (blue) and infomax with gibbs sampling (red). Error bars reflect 95% confidence interval of the mean across 10 experiments. (E) The same as in (D) but for the RMSE (root mean squared error). (F) Visualization of standard deviation of 500 inputs selected by both infomax (red) and random sampling (blue). Each dot corresponds to a different experiment. Examining (B), it is clear that the 3 states differ most according to the weights placed on the 'AveOccup', 'Latitude' and 'Longitude' covariates. All 10 infomax experiments select inputs with greater variance for the latitude and longitude covariates than are selected by the random sampling experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Input-Output Hidden Markov Models (IO-HMM)</head><p>The Input-Output Hidden Markov Model (IO-HMM) represents a powerful extension of the standard HMM <ref type="bibr" target="#b5">(Bengio and Frasconi, 1995)</ref>. A standard HMM has K discrete states, a fixed transition matrix that describes the probability of transitions between states, and a distribution over outputs for each state. Crucially, at each time step t, the observed output y t in a standard HMM depends only on the current state, z t ∈ {1, ..K}. IO-HMMs have an additional component: an external input Here, the likelihood for the GLM-HMM is:</p><formula xml:id="formula_26">P (y | θ j , x, D t ) = K k=1 P (z = k | D t , θ j )P (y | x, z = k) (<label>21</label></formula><formula xml:id="formula_27">)</formula><p>where P (z = k | D t , θ j ) can readily be obtained using the forward-backward algorithm and P (y | x, z = k) is the Bernoulli-GLM likelihood function <ref type="bibr">(Eq. 20)</ref>.</p><p>We computed the mutual information over a discrete set of candidate inputs and the selected the most informative input to present on the subsequent trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Numerical experiments with GLM-HMM</head><p>We sampled data from the 3-state GLM-HMM (Fig. <ref type="figure" target="#fig_4">5B</ref>). We set the model parameters to closely approximate those inferred from mice performing a binary sensory decision-making task <ref type="bibr" target="#b1">(Ashwood et al., 2021)</ref>. Each GLM has a weight (w k ) associated with the external stimulus as well as a bias parameter (b k ), such that the GLM weight vector is</p><formula xml:id="formula_28">w k = {w k , b k }.</formula><p>The input stimuli (x t ) are thus 1-dimensional, such that the choice probability can be formally written as:</p><formula xml:id="formula_29">P (y t = 1 | x t , z t = k) = 1 1 + exp -w k xt+b k (22)</formula><p>In our experiment, we selected inputs from a grid of stimuli over the range [-5, 5], spaced 0.01 units apart. Similar to the MLR setting, the task here is to recover the true parameters of the GLM-HMM used to simulate data. We compared the performance of our infomax learning methods (based on either Gibbs sampling or variational inference) as well as a "random sampling" approach in which inputs were sampled uniformly at random. Deep Adaptive Design (DAD) <ref type="bibr" target="#b23">(Foster et al., 2021)</ref> is not applicable in this setting as it assumes trials to be i.i.d., and thus we did not consider it. We examined the performance of these three methods, and found that the posterior entropy over the model parameters decreased fastest under Gibbs-infomax, followed by VI-infomax, and was slowest with random sampling (Fig. <ref type="figure" target="#fig_4">5C</ref>, left). We also observed that the RMSE between the true and inferred parameters decreased much faster for our active learning methods (with best performance under Gibbsinfomax) as compared to random sampling, both for the transition matrix A (middle panel of Fig. <ref type="figure" target="#fig_4">5C</ref>) and the GLM weights (right panel of Fig. <ref type="figure" target="#fig_4">5C</ref>). This suggests that our infomax learning method can be used to fit GLM-HMMs using fewer samples. It also reinforces our previous result that sampling from the exact posterior substantially benefits infomax learning as compared to using the variational posterior. At time step t, a system generates output y t based on its input, x t , as well as its latent state at that time step, z t . The system then either remains in the same state, or transitions into a new state at trial t + 1, with the transition probabilities given by matrix A. (B) Example settings for the transition matrix and state GLMs for a 3 state GLM-HMM. These are the settings we use to generate output data for the analyses shown in panels C and D. (C) Left: posterior entropy over the course of 1000 trials for random sampling (blue), infomax with a single GLM (grey), infomax for the full GLM-HMM using variational inference (VI) and Gibbs sampling (magenta and red respectively). Middle: root mean squared error for the recovered transition matrix for each of the three input-selection schemes (random/infomax with GLM/infomax with GLM-HMM (Gibbs)/infomax with GLM-HMM (VI)). Right: root mean squared error for the weight vectors of the GLM-HMM for each of the input-selection schemes. (D) Selected inputs for random sampling (blue), active learning when there is model mismatch and the model used for infomax is a single GLM (gray), active learning with infomax (using Gibbs sampling) and the full GLM-HMM (red). Selected inputs over the course of 1000 trials are plotted, and are shown on top of the generative GLM curves.</p><p>To understand why our framework outperforms random sampling for the GLM-HMM, we plotted histograms of the inputs selected by random sampling and by Gibbs-infomax (Fig. <ref type="figure" target="#fig_4">5D</ref>). While random sampling selected inputs from the entire input domain, infomax learning rarely selected inputs with a magnitude greater than 3. For positive inputs &gt; 3, the sigmoid nonlinearity (Eq. 22) saturated for all three models, so that sampled y t are 1 with high probability and are thus uninformative about the latent state. Similarly, for large-magnitude negative inputs, the y t samples are 0 with high probability for all three states. As such, the outputs generated by these provide virtually no information about the latents (necessary for updating the transition matrix) or the GLM weights. Overall, infomax learning substantially reduced the number of samples required to learn the parameters of the GLM-HMM.</p><p>To make our method practical for closed-loop experiments, it is critical for it to compute new inputs quickly. For example, in the case of mouse decision-making experiments, consecutive trials occur within 1-10 seconds <ref type="bibr" target="#b57">(Pinto et al., 2018;</ref><ref type="bibr" target="#b41">Laboratory et al., 2020)</ref>. While our current implementation requires up to 20s per trial (on an 1.7GHz quad-core i7 laptop), we show in the appendix (A7) that running five parallel chains of 100 samples each provides a 5x speedup over the current implementation with a single chain of 500 Gibbs samples. Additionally, we also performed infomax learning for a special case of GLM-HMMs: mixtures of GLMs. We show in 7.4 that our method outperforms random sampling in terms of posterior entropy and error in recovering the model parameters. These results provide further evidence that our infomax learning method is applicable across model settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Consequences of ignoring latent states</head><p>To assess the importance of latent structure on active learning methods, we benchmarked our method against an additional input-selection scheme: infomax under conditions of model mismatch. Specifically, we compared to a strategy where inputs were selected by infomax under the (mismatched) assumption that responses arose from a single Bernoulli-GLM, with no latent states. This allowed us to explore the effect of ignoring the presence of latent variables when selecting inputs.</p><p>Fig. <ref type="figure" target="#fig_4">5D</ref> shows that the inputs selected by Bernoulli-GLM infomax learning differed substantially from those selected by the full GLM-HMM infomax algorithm. In particular, the Bernoulli-GLM method avoided selecting inputs in both the center and the outer edges of the input domain. In virtue of neglecting the outer edges, it outperformed random input selection (compare the grey and blue lines in all panels of Fig. <ref type="figure" target="#fig_4">5C</ref>). However, the full GLM-HMM infomax method still performed best for learning the weights and transition matrix of the true model (red lines in Fig. <ref type="figure" target="#fig_4">5C</ref>). The significant drop in the performance when ignoring the presence of latent states thus highlights the importance of developing active learning methods tailored specifically for latent variable models.  (Top) the true latent states of the data-generating GLM-HMM for 100 trials. (Middle) the inferred posterior probabilities of states using an GLM-HMM, trained using infomax learning on 400 trials from the data-generating GLM-HMM. (Bottom) the same for an GLM-HMM trained using random sampling on 400 trials from the datagenerating GLM-HMM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Downstream application: latent state inference</head><p>GLM-HMMs are often used to infer the underlying latent states during the course of an experiment. To demonstrate the utility of our active learning approach for downstream tasks, we compare infomax learning and random sampling for predicting latent states across trials. We use the same generative GLM-HMM as shown in Fig. <ref type="figure" target="#fig_4">5B</ref>, and train two new distinct GLM-HMMs using 400 input-output samples from the generative model. One of the GLM-HMMs is trained using inputs selected by infomax learning (with Gibbs sampling), while the other is trained using random input selection. Next, we generate a set of 100 trials from the generative model, and use the two GLM-HMMs to predict the posterior probabilities of states at each trial. Fig. <ref type="figure" target="#fig_6">6</ref> shows that the GLM-HMM trained using infomax learning is able to predict the true states drastically better than that trained using random selection using the same number of trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Infomax for Mixture of GLMs (MGLMs)</head><p>Finally, we evaluate infomax on a special case of GLM-HMMs: a mixture of Bernoulli-GLMs (MGLMs). Compared to standard GLM-HMMs, MGLMs assume that the probability that the system transitions to state k at trial t+1 is independent of the system's state at trial t. MGLMs arise in a number of settings including in medicine, transport modeling and in marketing <ref type="bibr" target="#b20">(Farewell and Sprott, 1988;</ref><ref type="bibr" target="#b21">Follmann and Lambert, 1989;</ref><ref type="bibr" target="#b22">Follmann and Lambert, 1991;</ref><ref type="bibr" target="#b71">Wedel and DeSarbo, 1995;</ref><ref type="bibr" target="#b45">Li, 2018)</ref>. Formally, MGLMs contain K distinct GLM observation models where the state of the model, z ∈ {1, ...K}, is independently sampled at each time step from a distribution π ∈ ∆ K-1 . Similar to the GLM-HMM setup, observations are generated according to a Bernoulli GLM as in Eq. 20. Infomax learning using Gibbs sampling for MGLMs involves similar steps to those required for GLM-HMMs and is described in A8. We perform an experiment to assess the effectiveness of our active learning method in this setting. Data was generated from a 2-state MGLM model (shown in Fig. <ref type="figure" target="#fig_7">7A</ref>) with π = [0.6, 0.4] and the GLM weights w 1 = [3, -6], w 2 = <ref type="bibr">[3,</ref><ref type="bibr">6]</ref>. We find that our active learning method is better than random sampling at inferring the parameters of this model (Fig. <ref type="figure" target="#fig_7">7B,</ref><ref type="figure">C</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>We have developed novel methods for Bayesian active learning in discrete latent variable models (LVMs). We applied these methods to two classes of models: mixture of linear regressions and input-output HMMs. We showed that infomax learning consistently achieved lower error and lower posterior entropy than random input selection. Our method also outperformed active learning methods that ignored the presence of latent variables and, for the case of MLRs, the DAD method of <ref type="bibr" target="#b23">(Foster et al., 2021)</ref>.</p><p>Given the importance of LVMs in neuroscience <ref type="bibr" target="#b19">(Escola et al., 2011;</ref><ref type="bibr" target="#b9">Calhoun et al., 2019;</ref><ref type="bibr" target="#b1">Ashwood et al., 2021;</ref><ref type="bibr" target="#b8">Bolkan et al., 2022)</ref> and other scientific domains, we envisage broad applicability of our method. One exciting application is to adaptively select stimuli in animal decision-making tasks. While recent work has shown that the behavior of mice can be well-described with a multi-state GLM-HMM <ref type="bibr" target="#b1">(Ashwood et al., 2021;</ref><ref type="bibr" target="#b8">Bolkan et al., 2022)</ref>, they required large amounts of data collected from multiple sessions across days. Using our framework, it may be possible to learn these parameters using data from a single day, reducing the time and cost of experiments and thereby speeding up scientific discovery. Now, we briefly discuss some limitations of our work. First, we considered scalar output observations. Extending to higher-dimensional outputs may require alternate methods for computing information, since numerical integration in high-d is difficult. Second, we selected maximally informative inputs from a discrete set of candidate inputs on each trial. Future work may instead use optimization to find optimal inputs in a continuous input space. A final direction for future work is to consider GLM-HMMs in which state transitions also depend on the input. Despite these limitations, our method substantially speeds up the learning of systems characterized by latent variable models, and will be highly beneficial in neuroscience and other fields with time-consuming or expensive experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3 Training details for Deep Adaptive Design (DAD)</head><p>We downloaded the code for DAD, and adapted it to perform input selection for MLRs (which we attach with the supplement). The parameters of the MLR model were set to the same values as described in sec. 6.3. Since the DAD model requires continuous inputs, rather than a discrete list of inputs, we allow it to choose inputs from the unit circle in 2d and the unit hypersphere in 10d, rather than restricting it to the discrete set of stimuli in sec. 6.3.</p><p>The DAD model has two components: the encoder network which takes in inputobservation pairs {x, y} and outputs an encoding for this. This is a feedforward neural network. We set this network to have 3 layers: the input layer which has 3 nodes for the first MLR experiment (2d inputs and 1d observations) and 11 nodes for the second experiment (10-d inputs and 1d observations), a hidden layer with 256 nodes and ReLu activation function, and a linear output layer with 16 nodes.</p><p>Following this, the encoded history is taken as input by an emitter network. This network outputs the input for the next trial: x t . The input layer of this feedforward network has the same dimensionality as the output of the embedding layer, i.e. 16 nodes. It has one hidden layer with ReLu activation and 256 nodes, followed by a linear output layer with as many nodes as the dimensionality of the input to the MLR model. We normalize the output of this network, to ensure that the selected x t lies on the unit circle/unit hypersphere.</p><p>We do a hyperparameter optimization to select the number of hidden layers and nodes from the range of values used in the experiments (no. of hidden layers: 1-3, no. of nodes per layer: 16/128/256) in the original DAD <ref type="bibr" target="#b23">(Foster et al., 2021)</ref> paper.</p><p>To compute the sPCE loss that DAD uses to optimize the two neural networks, we use 500 samples each to compute the inner and outer expectation in the loss function. Since our experiments involve large number of trials (T = 200), we use score gradient estimator to compute the gradients that are backpropagated while training. Finally, we train the model using Adam (with betas set to 0.8, 0.998), and use exponential learning rate annealing (where the initial learning rate is set to 1e-4 post a search over the range 1e-5-1e-3, and γ = 0.96) for a total of 50000 gradient steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4 Fisher Information for MLRs</head><p>Here we derive the Fisher information for the weights of the MLR model (shown in Fig. <ref type="figure" target="#fig_2">2B</ref> of the main text).</p><p>We consider a model consisting of a mixture of K linear regression models in a D-dimensional input space, defined by weights {w 1 , w 2 , . . . , w K }. The full model weights take the form of a length-KD vector formed by stacking the weights for each component:</p><formula xml:id="formula_30">w =    w 1 . . . w K    . (A10)</formula><p>The Fisher information J is a KD × KD matrix carrying the expectation for the product of partial derivatives of the log-likelihood with respect to each element of w. We will derive the D × D blocks of the Fisher information matrix for each pair of components in {1, . . . , K}.</p><p>The block of partial derivatives for component j is given by:</p><formula xml:id="formula_31">∂ ∂w j log p(y | x, θ) = 1 σ 2 (y -x ⊤ w j )x π j exp -1 2σ 2 (y -x ⊤ w j ) 2 P (y | x, θ) = 1 σ 2 (y -x ⊤ w j )x P (y | x, z = j, θ)P (z = j | π) P (y | x, θ) = 1 σ 2 (y -x ⊤ w j )x P (z = j | y, x, θ) . (A11)</formula><p>Plugging this into the formula for Fisher information, we obtain the following expression for the i, j'th block of the Fisher information matrix:</p><formula xml:id="formula_32">J [i,j] (x) = 1 σ 4 E (y -x ⊤ w i )(y -x ⊤ w j )P (z = i | y, x, θ)P (z = j | y, x, θ) xx ⊤ , (<label>A12</label></formula><p>) where expectation is taken with respect to the marginal distribution P (y | x, θ). This expectation cannot in general be computed in closed form (see <ref type="bibr" target="#b4">(Behboodian, 1972)</ref>). However, we considered two special cases in the text where an analytic expression is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4.1 Perfect identifiability</head><p>First, the case of "perfect identifiabilty" arises when the conditional distributions P (y | x, z = j, θ) are well-separated for the different classes of latent variable z, or equivalently, the posterior class probabilities P (z = j | y, x, θ) are effectively 0 or 1 for virtually all output values y. In practice, this arises for inputs x such that the conditional means {x ⊤ w 1 , x ⊤ w 2 , . . . , x ⊤ w K } are well separated relative to the noise standard deviation σ (e.g., more than 2σ apart). In this case, the off-diagonal blocks of the Fisher information matrix are zero, since P (z = i | y, x, θ)P (z = j | y, x, θ) ≈ 0 for i ̸ = j. The diagonal blocks, by contrast, The Fisher information matrix can be written in Kronecker form:</p><formula xml:id="formula_33">J = 1 σ 2 (ππ ⊤ ) ⊗ xx ⊤ , (A17) which has trace Tr[J] = 1 σ 2 (π ⊤ π)x ⊤ x. (<label>A18</label></formula><formula xml:id="formula_34">)</formula><p>This expression is minimal when the prior probabilities are all equal to 1/K, in which case</p><formula xml:id="formula_35">π ⊤ π = 1/K, giving Tr[J] = 1 Kσ 2 x ⊤ x.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A5 Gibbs Sampling For GLM-HMMs</head><p>We provide a complete description of Gibbs sampling for GLM-HMMs in Alg. 1. It uses outputs y 1:T and inputs x 1:T , along with the prior over model parameters to provide M samples of the latent states {z 1:T } j as well as of the model parameters {w 1:K , A, π} j . We assume the model has K distinct latent states. Sampling the latent states (Alg. 3) requires using backward messages, B t,k = P (y t+1:T | x 1:T , z t = k), which can be obtained using standard forward-backward algorithm <ref type="bibr" target="#b6">(Bishop, 2006)</ref>. To sample the weights of the GLMs per state, we use the Laplace approximation followed by an acceptance-rejection step detailed in Alg. 2. We fix the Dirichlet prior α ∈ R K+1×K over the rows of the transition matrix, A, and the initial state distribution, π to be a matrix of ones. The GLM weights have an identical prior: N (0, 10). Further, we run Gibbs sampling for 500 iterations and discard the first 100.</p><p>Algorithm 1 GLM-HMM Gibbs Sampling 1: Input: Observations y 1:T , Inputs x 1:T , Prior hyperparameters: α, w 0 , σ 0 2: Output: Samples {(z 1:T , w 1:K , A, π) (j) } 3: Initialize z 1:T , w 1:K , A, π 4: for j ← 1, ...M do 5:</p><p>for k ← 1, ...K do 6:</p><p>w j k ← GLMsampleposterior({y t , x t | z t = k} 1:T , w 0 , σ 0 , w j-1 k )</p><p>7:</p><p>A j k,: ← sample Dir(α k,: + n k,: ) → where n kl = t I(z t = k, z t+1 = l) 8:</p><p>z j 1:T ← IOHMMsamplestate(π, A, L) → s.t. L t,k = P (y t | x t , w k ) 9:</p><p>π j ← sample Dir(α 0,: + I z 1 )</p><p>Algorithm 2 GLM sample weight from posterior 1: Input: Observations y 1:T ′ , Inputs x 1:T ′ , Prior: w 0 , σ 0 , Previous estimate of w: w old 2: Output: {w} 3: function GLMsampleposterior( (y 1:T ′ , x 1:T ′ , w 0 , σ 0 , w old )) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A6 Variational inference for GLM-HMMs</head><p>For a GLM-HMM with K distinct states and Bernoulli-GLM observations, we want to learn variational posteriors for the initial state distribution π 0 ∈ ∆ K-1 , the transition matrix A ∈ R K×K and the weights of the GLMs, w 1:K ∈ R D . To do so, we use inputs to the model x 1:T and their corresponding observations y 1:T . The unknown latent states corresponding to these trials are represented by z 1:T . Let's first first define prior distributions over the model parameters:</p><p>π 0 ∼ Dir(α 0 ) (A19) A j,: = π j = ∼ Dir(α j ) j = 1...K (A20) w k ∼ N (w 0 , σ 2 0 I) k = 1...K (A21) the model's parameters, discarding the initial 200 burn-in samples. If we instead run 5 parallel chains, each of length 140 and discard the first 40 samples as burn-in, we would still be able to obtain 500 samples of the model parameters to perform infomax learning, but this provides a 5X improvement in speed, leading to ∼ 4 secs per trial for input selection. We verify in Fig. <ref type="figure" target="#fig_1">A1</ref> that the perform of infomax while using parallel chains of Gibbs is comparable to that using a single long chain (compare the red and violet traces).</p><p>Finally, in all our experiments, we use our Laplace-based Gibbs sampling approach for GLM-HMMs (detailed in sec. A5). We compared this to Polya-Gamma augmented Gibbs sampling <ref type="bibr" target="#b58">(Polson et al., 2013;</ref><ref type="bibr" target="#b55">Pillow and Scott, 2012)</ref>, an established technique in the literature to sample from logistic models. In this case, weights of the GLM are sampled using Polya-Gamma augmentation, while the strategy for sampling the latents and the state transitions remain the same as in algorithm 1. We show in Fig. <ref type="figure" target="#fig_1">A1</ref> that our approach is comparable to Polya-Gamma augmentation in terms of both posterior entropy and error in recovering the model parameters (compare the peach and red curves). This empirically verifies the utility of our Laplace-based Gibbs sampling approach for GLM-HMMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A8 Gibbs Sampling for MGLMS</head><p>Gibbs sampling for MGLMs is similar to that for GLM-HMMs except that now the states can be sampled independently of each other. Alg. 4 provides full details. We set a Dirichlet prior over the initial state distribution, with α 0 = 1 ∈ R K , and that over the weights to be N (0, 10). Here, we run Gibbs sampling for 700 iterations and discard the first 200 as burn-in (MGLMs require a longer burn-in period).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 4 MGLMs Gibbs Sampling</head><p>1: Input: Observations y 1:T , Inputs x 1:T , Priors: α 0 , w 0 , σ 0 2: Output: Samples {(z 1:T , w 1:K , π) (j) } 3: Initialize z 1:T , w 1:K , A, π 4: for j ← 1, ...M do 5:</p><p>for k ← 1, ...K do 6:</p><p>w j k ← GLMsampleposterior({y t , x t | z t = k} 1:T , w 0 , σ 0 , w j-1 k )</p><p>7:</p><p>π j ← sample Dir(α 0 + n) → where n k = t I(z t = k) </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Discrete latent variable regression models and infomax learning. (A) Schematic of a discrete latent variable model for regression settings. The response y of the model given a stimulus x and a latent z is produced by generalized linear models.Here the discrete latent variable z determines which of the three generalized linear models at the bottom determines the input-output mapping on any trial. (B) Infomax learning for discrete latent variable models. On trial t, present an input x t to the system of interest (e.g., a mouse performing a decisionmaking task) and record its response y t . We assume this response depends on the stimulus (input) as well as an internal or latent state z t , as specified by the model P (y t | x t , z t , θ). Second, update the posterior distribution over model parameters θ given the data collected so far in the experiment, D t = {x 1:t , y 1:t } using either MCMC sampling or variational inference. Third, select the input for the next trial that maximizes information gain, or the mutual information between the next response y t+1 and the model parameters θ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Infomax learning for mixture of linear regressions (MLR) models. (A)Model schematic. At time step t, the system is in state z t = k with probability π k . The system generates output y t using state-dependent weights w k and independent additive Gaussian noise (Eq. 18). (B) Example 2-state model with two-dimensional weights w 1 = (1, 0) and w 2 = (-1, 0). We consider possible inputs on the unit circle, which are the information-maximizing inputs for linear Gaussian models under an L 2 norm constraint. (C) Fisher information as a function of the angle between w 1 and the input presented to the system, for different noise variances σ 2 . (D) Comparison between infomax active learning (using Gibbs sampling and VI), DAD and random sampling for the 2D MLR model shown above with mixing probabilities π = [0.6, 0.4] and noise variance σ 2 = 0.1. Error bars reflect 95% confidence interval (standard error) of the mean across 20 experiments. (E) Performance comparison for the same 2-state model but with 10-dimensional weight vectors and inputs. The possible inputs to the system were uniform samples from the 10-D unit hyper-sphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Application of infomax learning to CA Housing Dataset (Kelley Pace and<ref type="bibr" target="#b34">Barry, 1997)</ref>. (A) Best fitting mixing weights for 3 state MLR to 5000 samples of the dataset. (B) Best fitting state weights for 3 state MLR to 5000 samples of the CA housing dataset. Orange, green and blue represent states 1, 2 and 3 respectively. Black represents the linear regression fit. (C) BIC as number of MLR states is varied from 1 (standard linear regression) to 5. We select the 3 state model as BIC begins to level off beyond 3 states. (D) Posterior entropy between the 3 state MLR parameters obtained using 5000 samples (parameters shown in (A) and (B)) and recovered parameters as a function of the number of samples for random sampling (blue) and infomax with gibbs sampling (red). Error bars reflect 95% confidence interval of the mean across 10 experiments. (E) The same as in (D) but for the RMSE (root mean squared error). (F) Visualization of standard deviation of 500 inputs selected by both infomax (red) and random sampling (blue). Each dot corresponds to a different experiment. Examining (B), it is clear that the 3 states differ most according to the weights placed on the 'AveOccup', 'Latitude' and 'Longitude' covariates. All 10 infomax experiments select inputs with greater variance for the latitude and longitude covariates than are selected by the random sampling experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Infomax for GLM-HMMs. (A) Data generation process for the GLM-HMM. At time step t, a system generates output y t based on its input, x t , as well as its latent state at that time step, z t . The system then either remains in the same state, or transitions into a new state at trial t + 1, with the transition probabilities given by matrix A. (B) Example settings for the transition matrix and state GLMs for a 3 state GLM-HMM. These are the settings we use to generate output data for the analyses shown in panels C and D. (C) Left: posterior entropy over the course of 1000 trials for random sampling (blue), infomax with a single GLM (grey), infomax for the full GLM-HMM using variational inference (VI) and Gibbs sampling (magenta and red respectively). Middle: root mean squared error for the recovered transition matrix for each of the three input-selection schemes (random/infomax with GLM/infomax with GLM-HMM (Gibbs)/infomax with GLM-HMM (VI)). Right: root mean squared error for the weight vectors of the GLM-HMM for each of the input-selection schemes. (D) Selected inputs for random sampling (blue), active learning when there is model mismatch and the model used for infomax is a single GLM (gray), active learning with infomax (using Gibbs sampling) and the full GLM-HMM (red). Selected inputs over the course of 1000 trials are plotted, and are shown on top of the generative GLM curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Inferring latent states.(Top) the true latent states of the data-generating GLM-HMM for 100 trials. (Middle) the inferred posterior probabilities of states using an GLM-HMM, trained using infomax learning on 400 trials from the data-generating GLM-HMM. (Bottom) the same for an GLM-HMM trained using random sampling on 400 trials from the datagenerating GLM-HMM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Infomax learning for mixture of GLMs (MGLMs): (A) Data generation model. Example settings for a 2-state MGLM along with the mixing weights for the two states. (B) Posterior entropy of model parameters over the course of 2000 trials for random sampling (blue) and infomax learning for MGLM (blue). (C) Root mean squared error for the recovered GLM weights and mixing weights for each of the two input-selection schemes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>) = T ′ t=1 log P (y = y t | x t , w) 5: w MAP ← argmax w (L(w) + log N (w; w 0 * , w old ) ← min 1, p(w * |y 1:T ′ ,x 1:T ′ )N (w old ;w MAP ,C) p(w old |y 1:T ′ ,x 1:T ′ )N (w * ;w MAP ,C) → p: unnormalized posterior 9: if α(w * , w old ) ≥ U (0, 1) then 10: w ← w * 11: else 12: w ← w old Algorithm 3 GLM-HMM State sequence sampling Input: Initial state dist. π, Transition matrix A, Likelihood matrix L ∈ R T ×K Output: z 1:T function IOHMMsamplestate((π, A, L) ) B ← HMM-Backwardmessages(A, L) → B t,k = P (y t+1:T | x 1:T , z t = k) (Bishop, 2006) z 1 ← sample π k B 1,k L 1,k over k ∈ {1, ...K} for t ← 2, ...T do z t ← sample A z t-1 ,k B t,k L t,k over k ∈ {1, ...K}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>← sample P (z t | y t , x t )∀ t = {1 : T } → s.t. P (z t = k | y t , x t ) = P (y=yt|xt,w k )π k k P (y=yt|xt,w k )π k</figDesc><table><row><cell>8:</cell><cell>z j t</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>vector presented at every time step: x t ∈ R D . As a result, both state transitions and observations can depend on the input vector.</p><p>Recent work in neuroscience has focused on a class of IO-HMMs in which the input-output mapping is parametrized by a generalized linear model (GLM), resulting in a model known as the GLM-HMM <ref type="bibr" target="#b19">(Escola et al., 2011;</ref><ref type="bibr" target="#b9">Calhoun et al., 2019;</ref><ref type="bibr" target="#b1">Ashwood et al., 2021;</ref><ref type="bibr" target="#b8">Bolkan et al., 2022)</ref>. Here, we consider the Bernoulli GLM-HMM, which assumes that the outputs are binary, y t ∈ {0, 1}, and are produced according to state-specific GLM weights, w k ∈ R D :</p><p>We assume that, as in the standard HMM, state transitions are governed by a stationary, input-independent transition matrix, A ∈ R K×K , where A il = P (z t = l | z t-1 = i). The first state z 1 has prior distribution π ∈ ∆ K-1 . The GLM-HMM model parameters are thus θ = {w 1:K , A, π}.</p><p>To perform infomax learning for GLM-HMMs, we use Gibbs sampling to iteratively sample the latent states {z 1 , . . . z t } for all trials observed so far given the model parameters θ, and the model parameters θ given the sampled latents after each trial (step 2 in Fig. <ref type="figure">1</ref>). Gibbs sampling-based inference for HMMs is wellknown <ref type="bibr" target="#b26">(Ghahramani, 2001)</ref>. However, when we use Bernoulli-GLM observations, the conditional distribution over {w 1:K } is no longer available in closed form since there is no conjugate prior distribution for the weights of a Bernoulli GLM. Thus, we developed a method for sampling {w 1:K } using Laplace approximation (see Appendix A5 for details). An alternative strategy for sampling from logistic models involves using Polya-Gamma augmentation <ref type="bibr" target="#b58">(Polson et al., 2013;</ref><ref type="bibr" target="#b55">Pillow and Scott, 2012)</ref>. We compared these two approaches and found that our Laplace-based approach performed equally well to Polya-Gamma augmentation (see A7), thus empirically validating our method.</p><p>For comparison, we also developed an approximate infomax learning algorithm using variational inference (VI). We used mean-field VI to obtain posterior distributions over the model parameters θ. Because there is no conjugate prior for the GLM weights {w 1:K }, we used the Laplace approximation to approximate their posteriors (see A6). After updating the variational posterior distribution on each time step, we drew samples of model parameters from their variational posteriors in order to evaluate the information gain associated with each candidate stimulus.</p><p>During infomax learning with GLM-HMMs (step 3 of Fig. <ref type="figure">1</ref>), we used M = 500 samples of the model parameters, {w j 1:K , A j , π j } M j=1 , to compute the mutual information between the output and the model parameters according to Eq. 13.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix A1 Gibbs Sampling for MLRs</head><p>Here, we describe Gibbs Sampling algorithm for Mixture of Linear Regressions models. Given T trials, for each input-output pair, x t ∈ R D and y t ∈ R, we sample class-belongings, z t ∈ {1, ..K}, from:</p><p>Next, we sample new estimates of the mixing parameters from:</p><p>where</p><p>Finally, we assume a Gaussian prior, N (w 0 , σ 2 0 I), over the weights associated with each latent class and sample a new estimate for them as follows:</p><p>Here, the rows of X k ∈ T k × D and Y k ∈ T k × 1 contain inputs and outputs at time points where z = k, respectively. We fix w 0 = 0 and σ 2 0 = 10 in our experiments. We perform this procedure M times in order to obtain M samples of the model parameters, {w j 1:K , π j } M j=1 , where M = 500 (excluding 100 burn-in samples) in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2 Variational inference for MLRs</head><p>Here, we describe mean-field variational inference for MLRs, which we use to derive posterior distributions over the model's parameters. Following mean-field approximation, we assume independence between all the model parameters and the latent variables.</p><p>Given T trials, for each input-output pair, x t ∈ R D and y t ∈ R, we assume that it's mixture assignment z t ∈ {1, ...K} is governed by an independent categorical distribution q(z t ; ϕ t ), where ϕ t ∈ ∆ K-1 . We, further, assume that the weight w k ∈ R D of the k-th linear regression model has a normal posterior distribution q(w k ; µ k , Σ k ), with mean µ k ∈ R D and covariance Σ k ∈ R D×D . Hence:</p><p>Let us vertically stack ϕ t for t ∈ 1 : T and denote this by a matrix ϕ of size T × K. Similarly, let X ∈ R T ×D represent the design matrix with all inputs stacked, and Y ∈ R T ×1 contain all observations. Also, we know that each of the linear regressions in the MLR model has Gaussian noise with variance σ 2 .</p><p>We update the variational parameters ϕ t , µ 1:K and Σ 1:K iteratively using the update rules described below. For each t ∈ {1..T },</p><p>Next, for each k ∈ {1...K}, we assume a Gaussian prior distribution over the weights: N (w 0 , σ 2 0 I), we update the variational parameters governing the weights as follows:</p><p>We fix w 0 = 0 and σ 2 = 10 in our experiments. We repeat these updates until either the log-likelihood of the data arising from the model has converged or a limit of 500 iterations has reached.</p><p>Once the variational posteriors have been learned, we draw M samples each, for the weights w 1:K and the mixture assignments z 1:T . Finally, using the mixture assignments, we obtain M samples for the mixing probability π by computing the proportion of trials assigned to each state. We set M = 500 in our experiments, thus obtaining {w j 1:K , π j } 500 j=1 .</p><p>can be computed in closed form:</p><p>We can write the Fisher information matrix efficiently as:</p><p>where ⊗ denotes the Kronecker product. The trace of the Fisher information is</p><p>which is the trace of the Fisher information matrix in the standard linear-Gaussian regression model. This confirms-as one might expect-that in the case of perfect identifiability we have the same amount of Fisher information as in a model without latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4.2 Non-identifiability</head><p>Second, the case of "non-identifiabilty" arises when the conditional distributions P (y | x, z = j, θ) are identical for the different classes of latent variable z, meaning the output y carries no information about the mixing component that generated it. This arises when the linear projection of x onto all of the weight vectors is identical,</p><p>. This arises, for example, when the stimulus is orthogonal to all of the weight vectors, which occurs with high probability in high-dimensional settings.</p><p>In this case we can also compute the Fisher information in closed form. We obtain, for block i, j of the Fisher information matrix:</p><p>where we have used the fact that x ⊤ w i = x ⊤ w j and that the product of posterior probabilities P (z = i | y, x, θ)P (z = j | y, x, θ) is equal to the product of prior probabilities π i π j in the setting where the output y carries no information about the latent z.</p><p>where α 0 ∈ R K and α j ∈ R K and contain positive real numbers only, w 0 ∈ R D , σ 0 ∈ R. Now, let us define a variational posterior over the parameters and latent states of the GLM-HMM as follows:</p><p>Here, we assume that the latents are independent of the model parameters, which reflects the mean-field assumption. Next, we develop a coordinate ascent algorithm to iteratively learn the variational posteriors.</p><p>We will initialize q(π 0 ), q(A), q(w k ) to their prior distributions. Then, in the first step, we compute the following quantities:</p><p>The Dirichlet distributions over π 0 and A j,: provide closed form updates for π0 and Ãj,: (in particular, for a D-dimensional vector x ∼ Dir(γ), E[ln</p><p>where ψ is the digamma function). To compute Lt,k , which is not available in closed form in the case of GLM observations, we obtain a sample estimate of the expectations using 10 samples. Next, using the quantities computed above, we run forward-backward algorithm for GLM-HMMs <ref type="bibr" target="#b6">(Bishop, 2006)</ref>, and obtain the forward and backward messages F, B ∈ R T ×K . This leads to the following distributions over the latent states.</p><p>Now, we are ready to update the variational distributions over the model parameters:</p><p>And finally, the variational approximation over the GLM weights is as follows:</p><p>Unlike typical Gaussian HMMs, this is not available in closed form because the likelihood of a Bernoulli-GLM does not have a conjugate prior. To deal with this, we approximate q(w k ) by a Gaussian distribution using Laplace approximation.</p><p>We repeat the update equations from eq. A23 to eq. A31 iteratively until the log-likehood of the data from the model converges or a maximum of 500 iterations is reached.</p><p>Once we have obtained a variational distribution for all the model parameters, we can draw M samples of {π j 0 , A, w j 1:K } M j=1 from their variational posteriors. We set M = 500 for our experiments. Left panel shows the posterior entropy of model parameters over the course of 1000 trials when performing infomax learning using our Laplace-based Gibbs sampling approach with a single long chain (red), using parallel chains of our Laplace-based Gibbs sampler (violet), using Polya-Gamma augmented Gibbs sampling (peach), and using random sampling (blue). Middle and right panels show error in recovering the transition matrix and the weights of the GLMs using the same set of methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A7 Additional analyses for GLM-HMMs</head><p>Here, we compare our infomax learning method using variants of Gibbs sampling. In all our experiments in sec. 7.1, we run a single chain to obtain 500 samples of</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Active learning for hidden markov models: Objective functions and algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning, ICML &apos;05</title>
		<meeting>the 22nd International Conference on Machine Learning, ICML &apos;05</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Mice alternate between discrete strategies during perceptual decision-making. bioRxiv</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Ashwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">I B</forename><surname>Laboratory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Churchland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<idno>10.19.346353</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page">2020</biblScope>
		</imprint>
		<respStmt>
			<orgName>Cold Spring Harbor Laboratory</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptive optimal training of animal behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Akrami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1939" to="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive stimulus selection for multialternative psychometric functions with lapses</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Information matrix for a mixture of two normal distributions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Behboodian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical computation and simulation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="295" to="314" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An Input Output HMM Architecture</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Touretzky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Leen</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="427" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Variational inference: A review for statisticians</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">518</biblScope>
			<biblScope unit="page" from="859" to="877" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Opponent control of behavior by dorsomedial striatal pathways depends on task demands and internal state</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bolkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Ashwood</surname></persName>
		</author>
		<author>
			<persName><surname>Iravedra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Zimmerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Engelhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<biblScope unit="page" from="2021" to="2027" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised identification of the internal states that shape natural behavior</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Calhoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2040" to="2049" />
			<date type="published" when="2019">2019</date>
			<publisher>Number: 12 Publisher: Nature Publishing Group</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimal bayesian experimental design for linear models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaloner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="283" to="300" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bayesian Experimental Design: A Review</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaloner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Verdinelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="304" />
			<date type="published" when="1995">1995</date>
			<publisher>Publisher: Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discrete-and continuous-time probabilistic models and algorithms for inferring neuronal up and down states</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Brown</surname></persName>
		</author>
		<idno type="PMID">19323637</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1797" to="1862" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Active Learning with Statistical Models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="129" to="145" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptive stimulus selection for optimizing neural population responses</title>
		<author>
			<persName><forename type="first">B</forename><surname>Cowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Clemens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Byron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1395" to="1405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast adaptive estimation of multidimensional psychometric functions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dimattina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5" to="5" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Active data collection for efficient estimation and comparison of nonlinear neural models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dimattina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2242" to="2288" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adaptive stimulus optimization for sensory systems neuroscience</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dimattina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in neural circuits</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hidden Markov models for the stimulus-response relationships of multistate neural systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Escola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fontanini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1071" to="1132" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The Use of a Mixture Model in the Analysis of Count Data</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">T</forename><surname>Farewell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Sprott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1191" to="1194" />
			<date type="published" when="1988">1988</date>
			<publisher>Wiley, International Biometric Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generalizing logistic regression by nonparametric mixing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Follmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">405</biblScope>
			<biblScope unit="page" from="295" to="300" />
			<date type="published" when="1989">1989</date>
			<publisher>Taylor &amp; Francis Group</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Identifiability of finite mixtures of logistic regression models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Follmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lambert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="375" to="381" />
			<date type="published" when="1991">1991</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep Adaptive Design: Amortizing Sequential Bayesian Experimental Design</title>
		<author>
			<persName><forename type="first">A</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rainforth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="3384" to="3395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Trajectory clustering with mixtures of regression models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gaffney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the fifth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.02910</idno>
		<idno>arXiv: 1703.02910</idno>
		<title level="m">Deep Bayesian Active Learning with Image Data</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An introduction to hidden markov models and bayesian networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJPRAI</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="9" to="42" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Recurrent switching dynamical systems models for multiple interacting neural populations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Whiteway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Linderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The iso-response method: measuring neuronal stimulus integration with closed-loop experiments</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gollisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Herz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in neural circuits</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Blessing of dimensionality: mathematical foundations of the statistical physics of data</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gorban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">Y</forename><surname>Tyukin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03421</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="page">20170237</biblScope>
			<date type="published" when="2018">2018. 2118</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bayesian two-stage optimal design for mixture models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hefang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Keying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Computation and Simulation</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="231" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lengyel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1112.5745</idno>
		<idno>arXiv: 1112.5745</idno>
		<title level="m">Bayesian Active Learning for Classification and Preference Learning</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kleinegesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rainforth</surname></persName>
		</author>
		<title level="m">Implicit Deep Adaptive Design: Policy-Based Experimental Design without Likelihoods</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Factor-analytic inverse regression for high-dimension, small-sample dimensionality reduction</title>
		<author>
			<persName><forename type="first">A</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="4850" to="4859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<author>
			<persName><forename type="first">R</forename><surname>Kelley Pace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sparse spatial autoregressions</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="291" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Detecting neural-state transitions using hidden markov models for motor cortical prostheses</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kemere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neurophysiology</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2441" to="2452" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Design issues for generalized linear models: A review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Khuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="page" from="376" to="399" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A hierarchical adaptive approach to optimal experimental design</title>
		<author>
			<persName><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myung</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2465" to="2492" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alché-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bayesian Experimental Design for Implicit Models by Mutual Information Neural Estimation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kleinegesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Gutmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5316" to="5326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Smc samplers for bayesian optimal nonlinear design</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2006 IEEE Nonlinear Statistical Signal Processing Workshop</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="99" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">I B</forename><surname>Laboratory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aguillon-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Angelaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bonacchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cazettes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Chapuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Churchland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Dewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Faulkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Haetzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khanal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Krasniak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Laranjeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Mainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Meijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Miska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Mrsic-Flogel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Murakami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pan-Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Z</forename><surname>Socha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Terry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Urai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Vergara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Wool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zador</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>A standardized and reproducible method to measure decision-making in mice. bioRxiv, page 2020.01.17.909838</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient active learning with generalized linear models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lewi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Butera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="267" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sequential optimal design of neurophysiology experiments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lewi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Butera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="619" to="687" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Automating the design of informative sequences of sensory stimuli</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lewi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M N</forename><surname>Woolley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Neurosci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="181" to="200" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Application of Finite Mixture of Logistic Regression for Heterogeneous Merging Behavior Analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<idno>1436521. Publisher: Hindawi</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Advanced Transportation</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning mixtures of linear regressions with nearly optimal complexity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference On Learning Theory</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1125" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName><surname>Pmlr</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A bayesian nonparametric approach for uncovering rat hippocampal population codes during spatial navigation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neuroscience methods</title>
		<imprint>
			<biblScope unit="volume">263</biblScope>
			<biblScope unit="page" from="36" to="47" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Information-Based Objective Functions for Active Data Selection</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J C</forename><surname>Mackay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="590" to="604" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Stochastic transitions between neural states in taste processing and decision-making</title>
		<author>
			<persName><forename type="first">P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2559" to="2570" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A Tutorial on Adaptive Design Optimization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Myung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cavagnaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical psychology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="53" to="67" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Asymptotic theory of information-theoretic experimental design</title>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1480" to="1507" />
			<date type="published" when="2005">2005</date>
			<publisher>Publisher: MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Bayesian active learning of neural firing rate maps with transformed gaussian process priors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Horwitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1519" to="1541" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Scikitlearn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Fully Bayesian inference for neural models with negative-binomial spiking</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pillow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Adaptive bayesian methods for closed-loop neurophysiology</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Closed Loop Neuroscience</title>
		<editor>
			<persName><forename type="first">A</forename><surname>El Hady</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">An Accumulation-of-Evidence Task Using Visual Pulses for Mice Navigating in Virtual Reality</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Koay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Engelhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Deverett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Thiberge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Tank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Brody</surname></persName>
		</author>
		<idno>12. Publisher: Frontiers</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Behavioral Neuroscience</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Bayesian inference for logistic models using pólya-gamma latent variables</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Windle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">504</biblScope>
			<biblScope unit="page" from="1339" to="1349" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Neural ensemble states in prefrontal cortex identified using a hidden markov model with a modified em algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rainer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="961" to="966" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Toward optimal active learning through monte carlo estimation of error reduction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="page" from="441" to="448" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A review of modern computational algorithms for bayesian optimal design</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Drovandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcgree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Pettitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Statistical Review / Revue Internationale de Statistique</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="128" to="154" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Bayesian inference and optimal design for the sparse linear model</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="759" to="813" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Compressed sensing and bayesian experimental design</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="912" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<idno>1648</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Computer Sciences Technical Report</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shababo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pakman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1304" to="1312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Experimental design for efficient identification of gene regulatory networks using sparse bayesian models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Steinke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Seeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tsuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Systems Biology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Active learning for sparse bayesian multilabel classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vasisht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Damianou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="472" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Bayesian designs for maximizing information and outcome</title>
		<author>
			<persName><forename type="first">I</forename><surname>Verdinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kadane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">418</biblScope>
			<biblScope unit="page" from="510" to="515" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">QUEST: a Bayesian adaptive psychophysical method</title>
		<author>
			<persName><forename type="first">A</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="113" to="120" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Quest+: A general multidimensional bayesian adaptive psychometric method</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A mixture likelihood approach for generalized linear models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of classification</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="55" />
			<date type="published" when="1995">1995</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Humans and mice fluctuate between external and internal modes of sensory processing</title>
		<author>
			<persName><forename type="first">V</forename><surname>Weilnhammer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Stuke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Standvoss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sterzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Wiltschko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Iurilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Katon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Pashkovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">E</forename><surname>Abraira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Datta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mapping sub-second structure in mouse behavior</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1121" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chinazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vespignani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-A</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Deep bayesian active learning for accelerating stochastic simulation</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sahani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">614</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">A general recurrent state space framework for modeling neural dynamics during decision-making</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Zoltowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Linderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Iii</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="11680" to="11691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Modeling time series of animal behavior by means of a latent-state model with feedback</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zucchini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Raubenheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="807" to="815" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
