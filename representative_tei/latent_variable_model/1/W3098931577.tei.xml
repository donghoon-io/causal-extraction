<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recruitment Market Trend Analysis with Sequential Latent Variable Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2017-12-08">8 Dec 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chen</forename><surname>Zhu</surname></persName>
							<email>zhuchen02@baidu.com</email>
						</author>
						<author>
							<persName><forename type="first">Hengshu</forename><surname>Zhu</surname></persName>
							<email>zhuhengshu@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Baidu Research-Big Data Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
							<email>hxiong@rutgers.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<addrLine>KDD &apos;16 August 13-17</addrLine>
									<postCode>2016</postCode>
									<settlement>San Francisco</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pengliang</forename><surname>Ding</surname></persName>
							<email>dingpengliang@baidu.com</email>
						</author>
						<author>
							<persName><forename type="first">Fang</forename><surname>Xie</surname></persName>
							<email>xiefang@baidu.com</email>
						</author>
						<title level="a" type="main">Recruitment Market Trend Analysis with Sequential Latent Variable Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-12-08">8 Dec 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/2939672.2939689</idno>
					<idno type="arXiv">arXiv:1712.02975v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Trend Analysis</term>
					<term>Recruitment Market</term>
					<term>Latent Variable Model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recruitment market analysis provides valuable understanding of industry-specific economic growth and plays an important role for both employers and job seekers. With the rapid development of online recruitment services, massive recruitment data have been accumulated and enable a new paradigm for recruitment market analysis. However, traditional methods for recruitment market analysis largely rely on the knowledge of domain experts and classic statistical models, which are usually too general to model large-scale dynamic recruitment data, and have difficulties to capture the fine-grained market trends. To this end, in this paper, we propose a new research paradigm for recruitment market analysis by leveraging unsupervised learning techniques for automatically discovering recruitment market trends based on large-scale recruitment data. Specifically, we develop a novel sequential latent variable model, named MTLVM, which is designed for capturing the sequential dependencies of corporate recruitment states and is able to automatically learn the latent recruitment topics within a Bayesian generative framework. In particular, to capture the variability of recruitment topics over time, we design hierarchical dirichlet processes for MTLVM. These processes allow to dynamically generate the evolving recruitment topics. Finally, we implement a prototype system to empirically evaluate our approach based on real-world recruitment data in China. Indeed, by visualizing the results from MTLVM, we can successfully reveal many interesting findings, such as the popularity of LBS related jobs reached the peak in the 2nd half of 2014, and decreased in 2015.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The scarcity of skilled talents has stimulated the global recruitment industry in the past few years. An article from Forbes reported that, US corporations spend nearly $ 72 billion each year on a variety of recruiting services, and the worldwide number is likely three times bigger <ref type="bibr" target="#b4">[4]</ref>. Along this line, a growing challenge is to provide an effective trend analysis of recruitment market, such as forecasting recruitment demand and predicting market status. Both employers and job seekers can benefit from the study of recruitment market trends. Moreover, at the macro level, this analysis can also provide valuable understanding of industry-specific economic growth for business analysts.</p><p>With the rapid development of online recruitment services, such as Linkedin <ref type="bibr" target="#b6">[7]</ref>, Dice <ref type="bibr" target="#b3">[3]</ref>, and Lagou <ref type="bibr" target="#b5">[6]</ref>, massive recruitment posting data have been accumulated. For example, as of the end of 2015, there are more than 1.3 million job positions from 100K+ companies across more than 20 Internet-related industries, such as mobile Internet, online-to-offline (O2O), and cloud computing, available at Lagou <ref type="bibr" target="#b5">[6]</ref>-a Chinese tech hiring service website. These huge data enable a new paradigm for studying recruitment market trends in a holistic and fine-grained manner.</p><p>Recruitment market analysis is a classic topic in human capital economics, where recruitment market is either treated as a factor of macro economic phenomenons or the analysis is focused on advising people to make the best job decisions in a general economic framework <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29]</ref>. However, previous studies rely largely on the knowledge of domain experts and classic statistical models, and thus usually too general to capture the high variability of recruitment market (e.g., the evolution of recruitment topics). Also, these studies have limited efforts on understanding the fine-grained market trends, such as forecasting the recruitment situation for a specific company in the next few months. Therefore, it is very appealing to design a new research paradigm for recruitment market analysis through large-scale analysis on massive recruitment data. Along this line, there are some major challenges. First, how to model the intrinsically sequential dependency of recruitment states (e.g., Hiring Freeze) forming the market trend? Second, how to model the semantic relationship between the market trend and job postings from different companies? Finally, how to model the variability of recruitment postings for a long time period?</p><p>To tackle these challenges, we propose an unsupervised learning approach for recruitment market trend analysis, which can automatically discern the underlying trend of recruitment market. First, we develop a novel sequential market trend latent variable model (MTLVM), which is designed for capturing the temporal dependencies of recruitment states of companies and is able to automatically learn the latent recruitment topics and demands from recruitment data within a Bayesian generative framework. To be more specific, we assume that the current recruitment state of a specific company is influenced by its state in previous epoch, and it will impel the company to review appropriate recruitment demands (e.g., R&amp;D recruitment). Then, different recruitment demands will generate different recruitment topics (e.g., experienced algorithm engineer), which will finally generate the recruitment postings. In particular, to capture the variability of recruitment topics over time, we design a hierarchical dirichlet processes for MTLVM, which can dynamically generate recruitment topics. Finally, we implement an intelligent prototype system to empirically evaluate our approach based on a real-world recruitment data set collected from China for the time period from 2014 to 2015. Indeed, by visualizing the results from MTLVM, we can successfully observe many interesting discoveries, such as the popularity of LBS related jobs reaches the peak in the 2nd half of 2014, and decreases in 2015. Generally, the contributions of this paper can be summarized as follows.</p><p>• To the best of our knowledge, this paper is the first attempt to leverage unsupervised learning approach for automatically modeling the trend of recruit market. This work provides a new research paradigm for recruitment market analysis.</p><p>• We propose a sequential latent variable model, named MTLVM, for learning the latent recruitment states, demands, and topics simultaneously. Particularly, MTLVM can dynamically generate recruitment topics by integrating hierarchical dirichlet processes.</p><p>• We develop a prototype system for empirically evaluate our approach. Indeed, by visualizing the results obtained from MTLVM, we can successfully observe many interesting and useful findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">OVERVIEW</head><p>In this section, we first introduce some preliminaries of recruitment market modeling, and then formally present the overview of our model MTLVM. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries</head><p>Recent years have witnessed the rapid development of online recruitment services, which have already become the most important venue of talent seeking, especially for hightech companies. Therefore, the job posting data from these services can help researchers better understand the trend of recruitment market from the perspectives of not only an individual company but also the whole industry.</p><p>Intuitively, different job postings can indicate different recruitment demands of companies, such as R&amp;D related positions, which usually change over different epochs. For example, Figure <ref type="figure" target="#fig_0">1</ref> demonstrates the trend of the number of job postings related to different skill requirements during January 2014 to November 2015 based on our real-world data set. We can observe that skill "Information Retrieval" becomes less popular, compared with other skills, such as "Data Mining", and "Machine Learning". Meanwhile, "Spark", an emerging technique for big data processing, has attracted more and more attention during these years. Indeed, such evolution of recruitment demands is inherently determined by the change of latent recruitment states of companies at different epochs, which have strong sequential dependency. For example, Alibaba, one of the largest E-Commerce companies in China, hugely enlarged the recruitment in 2014, which is followed by the recruitment state "Hiring Freeze" in 2015. As a result, its recruitment demands related to E-Commerce largely shrank in 2015. To capture the change of recruitment states, and model the semantic relationship between recruitment demand and state, our model MTLVM follows the Beysian latent variable model with first-order Markov assumption, where current state is only determined by the state at previous epoch.</p><p>Indeed, by further analyzing the descriptions of job postings, we observe that the detail of similar recruitment demands (e.g., Recruiting Mobile Software Engineer) will be influenced by the corresponding recruitment states. Thus the corresponding demands usually have high variability, and generate different recruitment topics. For example,  Figure <ref type="figure" target="#fig_1">2</ref> shows the word cloud representation 1 of job postings related to "Mobile Software Engineer" with respect to different epochs. We can observe that, "Mobile Game Development" is a hot topic in the second half of 2014, while "Android based Web Technology" becomes popular in the first half 2015. To model the semantic relationships among recruitment states, recruitment demands, and recruitment topics, our model, MTLVM, follows the idea of Hierarchical Dirichlet Processes, an infinity version of topic modeling, to model the job postings. Therefore the topic number can be automatically determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Overview of MTLVM</head><p>Formally, we regard the m-th job posting of company e at epoch t as a bag of words χe,t,m = {χe,t,m,n}n, where χe,t,m,n is the basic observation in job postings (e.g., keywords in job description), and |χe,t,m| = Ne,t,m. For modeling the trend of recruitment market, we first divide all job postings into different data units {χe,t}e,t with respect to companies and timestamps, which contain job postings of company e at epoch t.</p><p>As introduced above, we assume that the current recruitment state of a specific company is influenced by its state in previous epoch, and it will impel the company to review appropriate recruitment demands. Then, different recruitment demands will generate different recruitment topics, which will finally generate the recruitment postings. Therefore, we define a parameter ce,t to represent the recruitment state of company e at epoch t, where the number 1 All the words are originally in Chinese, and are automatically translated by a commercial translation tool <ref type="bibr" target="#b1">[1]</ref>.</p><p>of unique recruitment states is C. Specifically, at the first epoch, the corresponding ce,1 for all companies is sampled from a uniform distribution. For the following epochs, if company e releases some job postings at previous epoch t -1, namely that χe,t-1 exists, its current recruitment state ce,t is sampled from a multinomial distribution determined by previous state ce,t-1. Otherwise, ce,t is drawn from the overall recruitment state at epoch t -1, i.e., P (ce,t) = C c=1 P (ce,t|ct-1 = c)P (ct-1 = c), where P (ct-1 = c) is the average P (c e ,t-1 ) of company e who has market state c at epoch t -1. In addition, we name the chains consisting of neighbouring χe,t-1 that belong to the same company as a data chain. Therefore, if a company only occasionally releases jobs, it may have more than one data chain according to our formulation.</p><p>Furthermore, we define the generative process of job posting χe,t,m ∈ χe,t of company e at epoch t as follows. First, a recruitment demand De,t,m is generated from the latent factor Gc which is sampled from a Dirichlet Process and determined by the current recruitment state ce,t. Then, we sample a recruitment topic φe,t,m,n from the demand De,t,m for each observation χe,t,m,n. Finally, each observation χe,t,m,n is generated from a multinomial distribution determined by corresponding topic φe,t,m,n. Specifically, Figure <ref type="figure" target="#fig_2">3</ref> shows the graphical representation of MTLVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MODELING THE TREND OF RECRUIT-MENT MARKET</head><p>In this section, we will introduce the technical details of our model MTLVM. And we illustrate the important mathematical notations in Table <ref type="table" target="#tab_2">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Inference</head><p>According to the introduction in Section 2, we can summarize the parameterizations of MTLVM as follows,</p><formula xml:id="formula_0">ρc|α ∼ Diri(α), ce,t|{ρc} C c=1 , ce,t-1 ∼ Multi(ρc e,t-1 ), Q0|H, γ0 ∼ DP(γ0, H), Gc|Q0, γ1 ∼ DP(γ1, Q0), De,t,m|{Gc} C c=1 , γ2, ce,t ∼ DP(γ2, Gc e,t ), φe,t,m,n|Ge,t,m ∼ De,t,m, χe,t,m,n|φe,t,m,n ∼ Multi(φe,t,m,n).</formula><p>Following the above parameterizations, we can get the joint probability distribution of χ and c as</p><formula xml:id="formula_1">P (χ, c|Λ) = e,t P (ce,t|ce,t-1, Λ)P (χe,t|Λ, ce,t) ,<label>(1)</label></formula><p>where Λ is a set of hyper-parameters, including α, H, γ0, γ1, γ2, and c0. Specifically, c0 is a default initial recruitment state and ρc 0 is fixed to (1/C, ..., 1/C). Indeed, the above equation can be divided into two parts, i.e., P (ce,t|ce,t-1, Λ) that follows a multinomial distribution Multi(ρc </p><p>Therefore, the objective of learning MTLVM is to find a set of optimal parameters in P (ce,t|ce,t-1, Λ), P (De,t,m|Λ, Gc e,t ), P (φe,t,m,n|Λ, De,t,m), and P (χe,t,m,n|φe,t,m,n), which can maximize the probability of Equation <ref type="formula" target="#formula_1">1</ref>. In this paper, we propose a two-step framework to learn our model by a Gibbs Sampling method.</p><p>In the first step, we introduce how to optimize the transition matrix ρ, which is constituted of P (ce,t|ce,t-1, Λ), given P (χe,t|Λ, ce,t). Depending on equation 1, we could get the conditional distribution of ce,t P (ce,t = c|c -e,t , χ, Λ) = P (ce,t = c, χe,t|χ -e,t , Λ) P (χe,t|c -e,t , χ -e,t , Λ)</p><p>∝ P (χe,t|ce,t = c, Λ)P (ce,t = c|c -e,t , Λ).</p><p>(</p><formula xml:id="formula_3">)<label>3</label></formula><p>Since P (χe,t|ce,t = c, Λ) is given, the only challenge is to calculate P (ce,t = c|c -e,t , Λ). Here we follow the inference in <ref type="bibr" target="#b15">[16]</ref> and give it directly.</p><formula xml:id="formula_4">P (ce,t = c|c -e,t , χ, Λ) = P (χe,t|ce,t = c, Λ) • q -e,t (c e,t-1 ,c) +α q -e,t (c e,t-1 ) +Cα q -e,t (c,c e,t+1 ) +I(c t-1 =c=c t+1 )+α q -e,t (c) +I(c t-1 =c)+Cα ,<label>(4)</label></formula><p>where q -e,t</p><p>means the number of recruitment states c appearing except ce,t, and q -e,t (c e,t-1 ,c) means the number of pair ce,t-1, c appearing except ce,t.</p><p>In the second step, we introduce how to compute the parameters related to Dirichlet Process in Equation <ref type="formula" target="#formula_2">2</ref>. Indeed, this task can be regarded as an analog of the Chinese Restaurant Process (CRP) <ref type="bibr">[8]</ref>, and the metaphor can be explained as follows. We have C cuisine styles (i.e., recruitment state) and a franchise (i.e., company) with Me,t restaurants (i.e., job postings). Everyday, the franchise will change its cuisine style according to the cuisine styles on last day. In Particular, the menus of different restaurants may be different, even if they share the same cuisine style. At each table of each restaurant, the dish (i.e., topic) is determined by the first customer (i.e., the basic observation in job postings) sitting there, and it is shared among all customers who sit at that table . When a new customer enters the restaurant, she can sit at an occupied table or a new table. If she chooses a new table, she can order a new dish from the menu. According to the above metaphor of CRP, we can easily obtained a Gibbs sampling scheme for posterior sampling given χ <ref type="bibr" target="#b27">[28]</ref>. The detailed definition and inference can be found in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Application of MTLVM</head><p>After learning stage, MTLVM can be used for predicting the future trend of recruitment market, e.g., recruitment states, demands, topics, and basic observations. Specifically, given a company e, we can estimate its current recruitment state ce,t by ce,t = arg max c P (c|χe,t, ce,t-1, ρ, Λ),</p><p>(5) The default initial recruitment state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ne,t,m</head><p>The number of tokens at m-th job posting of company e at epoch t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Me,t</head><p>The number of job postings of company e at epoch t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C</head><p>The number of unique recruitment states.</p><p>where ρ is the transition matrix, and P (ce,t|χe,t, ce,t-1, ρ, Λ) ∝ P (ce,t, χe,t|ce,t-1, ρ, Λ) = P (χe,t|ce,t, Λ)P (ce,t|ce,t-1, ρ).</p><p>Therefore, the probability of recruitment state at the next epoch ce,t+1 can be obtained by P (ce,t+1) = Multi(ρc e,t ). Furthermore, the recruitment topics can be obtained in the same way introduced in Section 3.1. Thus, the probability of a basic observation χ e,t+1,k (e.g., keywords in job description) from company e appearing at epoch t + 1 can be computed by</p><formula xml:id="formula_7">P (χ e,t+1,k |Λ) = C c e,t+1 =1</formula><p>P (χ e,t+1,k |ce,t+1, Λ)P (ce,t+1), <ref type="bibr" target="#b6">(7)</ref> where P (χ e,t+1,k |ce,t+1) can be obtained by Equation <ref type="formula" target="#formula_2">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>In this section, we will study the performance of our model MTLVM on a huge data set collected from a major online recruitment website in China.</p><p>Furthermore, we have developed a web-based prototype system to empirically evaluate our model. This system can visualize the results of our model, provide in-depth analysis of recruitment market analysis, and help people understand the high variability of recruitment market. Figure <ref type="figure" target="#fig_3">4</ref> shows a screenshot of this prototype system. In this system, we show the trend analysis of the entire recruitment market and the detail evolution of recruitment state of companies. All of following visualization results in this section can be obtained by this prototype system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Set and Experimental Setup</head><p>The data set used in our experiments is collected from a major online recruitment website in China and contains 934,761 job postings from 68,302 companies released from January 2014 to November 2015. Specially, Figure <ref type="figure" target="#fig_4">5</ref>(a) to 5(d) demonstrate some statistics of our data set. As mentioned above, "data unit" in Figure <ref type="figure" target="#fig_4">5</ref>(c) means a job posting set χe,t released by company e at epoch t and "data chain" means chains consisting of neighbouring χe,t-1 that belong to the same company. From these statistics we can observe that most of companies only randomly release very few job postings, and therefore cannot represent the trend of recruitment market. To avoid such bias, we only conserve companies which have released more than 100 job postings. Table <ref type="table" target="#tab_3">2</ref> shows the detailed statistics of our raw data set and the filtered data set. By the above pre-process, we filtered about 72% original data; and the number of companies declined by 98.6%. However, the average number of job postings per company increases from 13.7 to 258, and the average length of chain also increases from 1.65 to 5.16, which make it more reasonable for training MTLVM.</p><p>In particular, in each job posting, the keywords in job description (e.g., job responsibility, skill requirements) are treated as basic observations, and all stop words are removed to guarantee the modeling performance. Note that, our model is trained with original Chinese words, and all experimental results were translated into English by a commercial translation tool <ref type="bibr" target="#b1">[1]</ref> for facilitating demonstration.</p><p>In the following subsections, we will comprehensively study the performance of MTLVM in term of trend analysis (e.g., learning recruitment states and recruitment topics). Specially, following <ref type="bibr" target="#b27">[28]</ref>, we set a symmetric Dirichlet distribution with parameters of 0.5 for the prior H over topic distributions. For simplicity, γ0, γ1, and γ2 are set to 1 directly, and another hyperparameter α is also be set to 1 empirically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation of Recruitment Topics</head><p>How to quantitatively evaluate the performance of latent variable models is always an open problem. Although perplexity and held-out likelihood are common measures for evaluating prediction results, they cannot demonstrate how coherent and meaningful the latent factors (e.g., recruitment states and topics) are.</p><p>Therefore, in this paper, we follow the measures introduced in <ref type="bibr" target="#b30">[31]</ref>, which is inspired by <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b12">13]</ref>, for evaluating MTLVM. Specifically, we picked up top 10 keywords for each learned recruitment topic and asked 4 senior experts of human resource to evaluate its value. These experts are first required to judge whether this topic is valuable. If a topic is valuable, they need continue to judge how many words are relevant in the top 10 keyword list. Based on these manually labeled results, the metrics Validity Measure (VM) and Coherence Measure (CM) are defined as V M = # of valid topics # of topics , CM = # of relevant words # of words in valid topics .</p><p>Besides, to evaluate how the number of recruitment states affects the performance, we train MTLVM with different settings of state number, i.e., C = 5, 10, 20 respectively. Furthermore, we select widely used topic model Latent Dirichlet Allocation (LDA) <ref type="bibr" target="#b11">[12]</ref> as baseline. After convergence, the numbers of topic in all our models, i.e., K, are automatically determined as about 100. Therefore, we set K as 100 for LDA.</p><p>Table <ref type="table" target="#tab_4">3</ref> shows the average results of VM and CM. We can observe that in terms of VM, both of MTLVM (C=20) and MTLVM (C=10) outperform LDA a lot, and MTLVM (C=20) has the best performance. In terms of CM, the performance of MTLVM (C=10) is the best, while that of MTLVM (C=20) is worse than LDA. It may be because that too many states will make the model relatively sparse, and thus will make relevant words scattered in different topics. In particular, the performance of MTLVM (C=5) is the worst, which may be because that few states cannot accurately describe the market trend well. Overall, since MTLVM (C=10) has the most balanced results, we set state number C = 10 in all of following experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation of Recruitment States</head><p>Here, we will empirically evaluate the learned recruitment states from several aspects.</p><p>Figure <ref type="figure" target="#fig_5">6</ref> shows the trend of popularity of recruitment states discovered by MTLVM over time. It is obvious that   these states change over time dramatically. Specifically, state #3 kepng a relative high popularity over the long period, while popularity of #6 is always low. Meanwhile, the popularity of state #9 is rising dramatically since February 2015. Several other states, such as state #2, #7, and #10, represent totally opposite trends. Furthermore, Figure <ref type="figure" target="#fig_6">7</ref> shows the transition matrix of recruitment states, where the element of i-th row and j-th column represents the transition probability from state i to state j. We can observe that, all states have the highest transition probabilities to themselves, which is due to the momentum of recruitment market. Also, the color of 3-th, and 9-th columns is relatively deeper, which indicates the importance of states #3, and #9. All of above results show that our model MTLVM has the ability to capture the high variability of recruitment market by discovering these latent recruitment states. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Recruitment State Inspection</head><p>Here, we will test whether the recruitment states discovered by our model are comprehensible. To solve this problem, we select 4 representative recruitment states according to above analysis and show their top 4 topics in figure <ref type="figure">8</ref> by word cloud representations, where the larger words have higher generative probabilities. Meanwhile, Table <ref type="table" target="#tab_5">4</ref> shows the corresponding generative probabilities of these topics.</p><p>We can find that the topic about "programming" always has very high probability in every state. In particular, the top #1 topics in state #1, state #3, and state #9 are the same. That means the demands for R&amp;D related positions are always exuberant, since the high-probability words, "linux" and "mysql", directly indicate the fundamental skill requirements of R&amp;D. Actually, the salary of software engineer has kept rising for a long time, which can support this discovery of our model. These states also show that the work about games and front-end are also very popular, which is consistent with our real-world observations. Next, we further inspect states illustrated in figure <ref type="figure">8</ref>.</p><p>• State #3. It is obvious that the top #1 topic is about R&amp;D. The top #3 topic, containing "data", "analysis", "research", and "algorithm", indicates the demand of recruiting senior researchers or algorithmic engineers.</p><p>The top #4 topic may be about propaganda (e.g., public relationship), because it contains several paperwork and advertising related words, such as "compose", "edit", "WeChat" and "blog"(e.g., social network based advertising). Besides, what makes this state different is the top #2 topic, which contains "human", "resource", "office", and "assist". All of them are about administrative management obviously. Actually, in our model, this topic only exists in this state. Since research development, propagandism, and administrative management are essential to any companies, we can conclude that this state covers the fundamental talent demands for most by high-tech companies. And • State #4. This state is closely related to state #5. We can find that the top #2, #3, and #4 topics are relative normal. And the top #1 topic, which contains "data", "programming", and "algorithm", is apparently about R&amp;D, too. However, what makes this topic different is word "lbs". Location-based Service (LBS), such as map navigation or map localization, is the cornerstone of O2O, which is a kind of business model that uses online and mobile to drive offline local sales and become more and more popular since 2014. In figure <ref type="figure" target="#fig_5">6</ref>, we notice that the popularity of this topic increased in 2014 and declined in 2015. This may be because the industry doorsill of this field is related high, so only a few large companies have capability to get into this field. Actually, only the largest IT companies in China, such as Baidu, Tencent, and sogou, provide such service now.</p><p>• State #5. This is a very Chinese-style recruitment state. In top #4 topic, we find word "O2O" as well as "merchant" and "business". Actually, with the proposal of "Internet Plus" [5], thousands of start-up companies, focusing on O2O, sprung up across the country. Meanwhile, the others topics in this state are related normal in terms of technology. The top #1 and #3 topics are just about some popular programming language, web-framework, and database. It may indicate that "O2O" is just a business concept rather than a technology concept.</p><p>• State #9. As shown in figure <ref type="figure" target="#fig_5">6</ref>, this state exploded since February 2015. In the word cloud representations of its topics, the top #4 is related meaningful. These high frequency words ("Baidu", "data", "mining", "large", "distributed") indicate this is a big data related topic (e.g., large-scale machine learning and data mining). Its trend directly reveals that high-tech companies, such as Baidu, have paid more attention to big data related fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Visualization of Trend over Companies</head><p>Here, we evaluate our model by checking the trend of several representative companies from a few important fields, such as Baidu is a famous high-tech company and Alibaba is the largest E-Commerce company in China. We visualize the evolution of the recruitment states of these companies in figure <ref type="figure" target="#fig_8">9</ref>.</p><p>From figure <ref type="figure" target="#fig_8">9</ref>, we can first observe that state #3 is a very common state among most of companies. It is consistent with the analysis from topics of this state. Besides, we find that state #4, which is relevant to LBS, appears relatively frequently among Baidu, Sogou, and Tencent in 2014. Actually, all of these companies provide map service in China, especially Baidu. Baidu Map is the most popular navigation tool in China and many O2O companies use LBS API provided by Baidu to improve their services. So Baidu has remarkable strengths in LBS and has paid much attention to it indeed. Furthermore, Tencent, as one of the largest IT companies in China, its business is very scattered and covers many fields, such as game, social network, media, and entertainment. This kind of business strategy is directly reflected in Figure <ref type="figure" target="#fig_8">9</ref>, where the recruitment state of Tencent changes frequently. Meanwhile, Baidu, Alibaba and Sogou (another search engine) prefer state #9, which is relevant to big data (e.g., large-scale machine learning and data mining), in 2015. Considering that their core business (search engine and Ecommerce) has several data-related practical applications (advertising and recommender system), the preference is also reasonable. In addition, we happened to find an interesting company, Zuora, whose state is almost state #9. Actually, Zuora is an enterprise software company that aim to automate billing, commerce, and finance operations with a subscription business model. Such business model is naturally related to big data processing and thus has need for senior data-related talents.</p><p>Furthermore, we can observe that state #5, which is related to O2O, appears in company Tuniu, Qunar, and Feiniu frequently. Indeed, all of these companies aim to connect offline merchants and online customers, which is high consistent with O2O. Both of Tuniu and Qunar aim to provide one-stop travel booking service, such as hotel, ticket, car rental, and so on. And Feiniu is a B2C E-commerce wesite which is invested by a large retail corporation. The goal of its establishment is to fuse traditional offline service channel with online sale channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation of of Model Application</head><p>Here, we will evaluate the proposed model by predicting basic observations in future.</p><p>As introduced in Section 3, we make prediction by calculating the probability of basic observations with equation 7. So in this experiment, we will compare the likelihood of overall observations in test set to prove the performance of our model. The test set is built up by the following approach. We extract the recruitment postings in November 2015, the companies of which had also released some jobs in October 2015. It means all of companies in test set have recruitment states in the previous time span. In the end, the test set contains 350 companies and 4002 recruitment postings. Besides, all of recruitment postings between January 2014 and October 2015 are treated as train data.</p><p>We select two model as baselines. One is dynamic Topic Model (DTM) <ref type="bibr" target="#b10">[11]</ref>. DTM is a classic topic model for analyzing evolution of topics. It assumes topics evolve smoothly with respect to time and thus chains topics in adjacent epochs by state space models. Its performance was proved by predicting the next year of Science given all the articles from the previous years in <ref type="bibr" target="#b10">[11]</ref>. It is obvious that DTM cannot be used for prediction directly, but due to its assumption, the topics extracted by it can model future data better than static topic models in some cases. In this experiment, we follow this method to prove the assumption of DTM is not very solid in our problem and indicate the necessity of our model. The code of DTM was got from <ref type="bibr" target="#b2">[2]</ref>. The number of topics is set to 100 and all of other parameters are set to default values.</p><p>In addition, we developed a simple sequence approach, called Byesian multivariate Hidden Markov Model (B-mHMM), as the other baseline. Compared with MTLVM, this baseline associates states with words directly. The joint probability distribution of B-mHMM is as follows P (χ, c|ρ, ι) = e,t P (ce,t|c e,t-1 , ρ) m,n P (χe,t,m,n|ce,t, ι) , <ref type="bibr">(8)</ref> where the first term is the same to equation 1. And as shown in second term, we assume that given the recruitment state, Table <ref type="table" target="#tab_6">5</ref> shows the log likelihood of prediction with respect to different models. The larger number means better performance. Both of B-mHMM and MTLVM outperform DTM largely. It indicates it is reasonable to employ latent recruitment states to model the trend of recruitment markets. And the performance of MTLVM is also better than that of B-mHMM. All of these clearly validate the effectiveness of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head><p>Generally, the related works of this paper can be grouped into two categories, namely recruitment market analysis, and sequential latent variable model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Recruitment Market Analysis</head><p>Traditionally, recruitment market analysis can be regarded as a classic topic in human capital economics, which attracts generations of researchers to contribute ever since Adam Smith. From the Macro perspective, labor is always a crucial element in studying gross economy growth, money market, exchange market and the equilibrium <ref type="bibr" target="#b25">[26]</ref>, ever since Solow proposed his growth model. Therefore, economists usually study topics about, for example, the demographic structure and participation rate of labor, the relation between inflation and unemployment rate, and how labor contributes in gross productivity or expenditures, etc <ref type="bibr" target="#b26">[27]</ref>. In another Micro perspective, which is more relevant to our paper, all studies are set off from a basic market cleaning framework <ref type="bibr" target="#b28">[29]</ref>, where all employees choose their best balance between leisure and work, while all employers hire with budget constrain, and consequently the wage is derived as the marginal labor cost. Later researches improve our understandings by releasing constraints <ref type="bibr" target="#b18">[19]</ref> (e.g., acknowledging the market with segmentations/barriers and as non-cleaning), or by detailed investigations (e.g., forming better utility functions of employees, and studying the actions of employees with game theory). Recently, several researchers in computer science try to employ data mining technology to solve these problems, such as offer categorization <ref type="bibr" target="#b23">[24]</ref>, job skill analysis <ref type="bibr" target="#b21">[22]</ref>.</p><p>However, previous research in economics efforts relies largely on the knowledge of domain experts or classic statistical models, and thus are usually too general to capture the high variability of recruitment market, and neglect the finegrained market trend. On the other hand, the recent research in computer science still focuses on those traditional human resource problems. Therefore, in this paper we pro- pose a new research paradigm for recruitment market analysis by leveraging unsupervised learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Sequential Latent Variable Model</head><p>Indeed, our novel sequential latent variable model MTLVM can be regarded as a combination of both Hidden Markov Model (HMM) and Hierarchical Dirichlet Processes (HDP) within a Bayesian generative framework, which can intrinsically capture the sequential dependency and variability of latent variable (e.g., recruitment states and topics).</p><p>Specially, HMM based sequential latent variable models have been successfully applied to problems in a variety of fields, such as signal processing and speech recognition <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b20">21]</ref>, biometrics <ref type="bibr" target="#b14">[15]</ref>, genetics <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b22">23]</ref>, economics <ref type="bibr" target="#b17">[18]</ref>, and mobile Internet mining <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b32">33]</ref>. For much of their history, HMMs have been implemented by using recursive algorithms developed for parameter estimation <ref type="bibr" target="#b9">[10]</ref>, which are viewed as "black boxes" by many statisticians. In recent years, some researchers proposed to use Bayesian methods to simulate HMM parameters from the posterior distribution, which can provide more scalable and stable process of parameter estimation for HMM <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. Compared with the traditional maximum-likelihood estimation (MLE) based HMM learning solution, the Bayesian methods can directly maximize the probability of the hidden variables given the observed data by integrating over all possible parameter values rather than searching for an optimal set of parameter values. To this end, the model proposed in this paper also follows a Bayesian generative framework.</p><p>Latent Dirichlet Allocation (LDA) <ref type="bibr" target="#b11">[12]</ref> based latent variable models, have become one of the most powerful tools for mining textual data. However, most topic models <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32]</ref> need a predefined parameter to indicate the number of topics, and thus fail to capture the variability of topics. To this end, the Hierarchical Dirichlet Processes (HDP) <ref type="bibr" target="#b27">[28]</ref> is proposed as an infinity version of topic model, which can automatically learn the number of topics. Therefore, in this paper we propose to ingrate HDP into our MTLVM for capturing the variability of latent recruitment topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>In this paper, we provided a large-scale data driven analysis of recruitment market trends. Specifically, we developed a novel sequential latent variable model, named MTLVM, which is designed for capturing the temporal dependencies of corporate recruitment states and is able to automatically learn the latent recruitment topics within a Bayesian generative framework. Moreover, to capture the variability of recruitment topics over time, we designed hierarchical dirichlet processes for MTLVM. These processes allow to dynamically generate recruitment topics. Finally, we implemented a prototype system to empirically evaluate our approach based on large-scale real-world recruitment data. The results showed that our approach could effectively discover recruitment market trends and provide guidances for both job recruiters and job seekers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">APPENDIX</head><p>Here, we will describe an analog of Chinese Restaurant Process (CRP) for P (χe,t|Λ, ce,t) and corresponding inference in detail. Specifically, we first define {ψe,t,m,z}z as variables sampled from Gc e,t for each job posting and |ψe,t,m| = Ze,t,m. Each φe,t,m,n is linked with a ψe,t,m,z and ze,t,m,n is the index of ψe,t,m,z for φe,t,m,n. In other words, we have φe,t,m,n = ψe,t,m,z e,t,m,n . Besides, let ie,t,m,z denote the number of {φe,t,m,n}n linked with ψe,t,m,z. According to CRP, we can integrate out the De,t,m and get the conditional distribution of φe,t,m,n as follows. φe,t,m,n|φe,t,m,1, ..., φe,t,m,n-1, {Gc}c, ce,t, γ2 ∼ Z e,t,m z=1 ie,t,m,z n -1 + γ2 δ ψ e,t,m,z + γ2 n -1 + γ2 Gc e,t ,</p><p>where δ ψ is a probability measure concentrated at ψ.</p><p>If a new ψ is sampled, it indicates the second term on the right-hand side of equation 9 is chosen. Then we need to add Ze,t,m by 1, sample a new ψ by equation 10, and allocate φe,t,m,n to it. If the sampled value is an existed φ, we just need allocate φe,t,m,n to it.</p><p>Second, we define {ηc,s}s as variables sampled from G0 for each recruitment state and |ηc| = Sc. Each ψe,t,m,z is linked with a ηc,s and se,t,m,z is the index of ηc,s for ψe,t,m,z. In other words, ψe,t,m,z = ηc,s e,t,m,z . Besides, let jc,s denote the number of {ψe,t,m,z}e,t,m, which is linked with ηc,s and ce,t = c. Similarly, we can integrate out Gc and get the conditional distribution of ψe,t,m,z as follows. ψe,t,m,z|ψ1,1,1,1, ..., ψe,t,m,z-1, Q0, γ1 ∼ </p><p>The sampling process is similar to φ.</p><p>Third, we let {θ k } k denote the variables sampled from H and |θ| is K. Each ηc,s is linked with a θ k and kc,s is the index of θ k for ηc,s, i.e., ηc,s = θ kc,s . And we also let o k denote the number of {ηc,s}c,s. Now we can write the conditional distribution of ηc,s directly as ηc,s|η1,1, ..., ηc,s-1, H, γ0</p><formula xml:id="formula_10">∼ K k=1 o k K k=1 o k +γ 0 δ θ k + o k K k=1 o k +γ 0 H.<label>(11)</label></formula><p>Next, we will describe a Gibbs sampling method yielded from above. Specifically, we follow the inference method in <ref type="bibr" target="#b27">[28]</ref> and sample z, s, k and θ, rather than dealing with φ, ψ and η directly. Sampling z, s, and k. Relying on equation 9, we can easily compute the conditional distribution of ze,t,m,n by P (ze,t,m,n = z|z -e,t,m,n , s, k, θ, χ) ∝ γ2P (χe,t,m,n|θ ke,s e,t,m,z ) new, i -e,t,m,n e,t,m,z P (χe,t,m,n|θ ke,s e,t,m,z ) used, <ref type="bibr" target="#b11">(12)</ref> where i -e,t,m,n e,t,m,z is ie,t,m,z except the variable φe,t,m,n. The likelihood of ze,t,m,n = z is simply P (χe,t,m,n|θ ke,s e,t,m,z ) given all of other variables. And the prior probability that ze,t,m,n samples an existed ψe,t,m,z is proportional to i -e,t,m,n e,t,m,z is ie,t,m,z. Its prior probability for a new ψ is proportional to γ2. The process of sampling s and k is similar to that of sampling z.</p><p>Sampling θ. Given z, s, and k, {θ k } k are mutually independent. So the conditional distribution for each θ k is only related with all of χ that linked with it. It follows P (θ k |z, t, k, θ -k , χ) ∝ h(θ k ) • c,s:kc,s=k e,t:ce,t=c m,z:se,t,m,z =s n:ze,t,m,n=z P (χe,t,m,n|θk), <ref type="bibr" target="#b12">(13)</ref> where h(θ k ) is the density of measure H at parameter θ k .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The trend of the number of job postings related to different skill requirements over two years, which indicates the demands of recruitment market.</figDesc><graphic coords="2,53.80,69.33,240.95,135.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The word cloud representation of job postings related to "Mobile Software Engineer" with respect to different epochs in our data set, where the size of each keyword is proportional to its frequency.</figDesc><graphic coords="2,322.75,162.52,110.54,82.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The graphical representation of MTLVM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A screenshot of our system for recruitment market analysis.</figDesc><graphic coords="5,59.97,53.80,226.77,170.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The distribution of (a) the number of companies that release job posting in different epochs, (b) the number of companies with respect to the number of their job postings, (c) the number of data units with respect to the number of contained job postings, and (d) the number of data chains with respect to their length.</figDesc><graphic coords="6,58.43,217.15,226.77,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The trend of popularity of recruitment states discovered by our model over time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure7: The transition matrix of recruitment states, where the i, j element means the transition probability from i-th state to j-th state, and deeper color means higher probability.</figDesc><graphic coords="6,58.43,383.35,226.76,109.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>9 Figure 8 :</head><label>98</label><figDesc>Figure 8: The word cloud representations of top 4 topics of selected recruitment states (e.g., #3, #4, #5, #9), where the size of each keyword is proportional to its generative provability. The generative probabilities of these recruitment topics are shown in table 4.figure 6 also indicates state #3 is the most popular.</figDesc><graphic coords="7,58.56,256.64,115.47,64.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Visualization of the change of recruitment states over several companies, with different colors representing different states.</figDesc><graphic coords="9,62.38,48.13,481.88,153.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>sc s=1 jc,s+γ 1 δη c,s + jc,s sc s=1 jc,s+γ 1 Q0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Mathematical Notations. The n-th tokens at m-th job posting of company e at epoch t.χe,t,mThe m-th job posting of company e at epoch t.</figDesc><table><row><cell>Symbol</cell><cell>Description</cell></row><row><cell>χe,t,m,n χe,t</cell><cell>The observation unit containing job postings of</cell></row><row><cell></cell><cell>company e at epoch t.</cell></row><row><cell>χ</cell><cell>The entire data set of job postings.</cell></row><row><cell>ce,t</cell><cell>The recruitment state of company e at epoch t.</cell></row><row><cell>α</cell><cell>The hyperparameter of the Dirichlet prior on ρc.</cell></row><row><cell>ρ</cell><cell>The transition matrix of recruitment state c.</cell></row><row><cell>Gc</cell><cell>The probability measure representing the re-</cell></row><row><cell></cell><cell>cruitment strategy of state c.</cell></row><row><cell>De,t,m</cell><cell>The probability measure representing the re-</cell></row><row><cell></cell><cell>cruitment demand of χe,t,m.</cell></row><row><cell cols="2">φe,t,m,n The recruitment topic of the n-th tokens at m-th</cell></row><row><cell></cell><cell>job posting of company e at epoch t.</cell></row><row><cell>Q 0</cell><cell>The base measure for Dirichlet Process generat-</cell></row><row><cell></cell><cell>ing Gc.</cell></row><row><cell>γ 0</cell><cell>The concentration parameter for Dirichlet Pro-</cell></row><row><cell></cell><cell>cess generating Q 0 .</cell></row><row><cell>γ 1</cell><cell>The concentration parameter for Dirichlet Pro-</cell></row><row><cell></cell><cell>cess generating Gc.</cell></row><row><cell>γ 2</cell><cell>The concentration parameter for Dirichlet Pro-</cell></row><row><cell></cell><cell>cess generating De,t,m.</cell></row><row><cell>H</cell><cell>The base measure for Dirichlet Process generat-</cell></row><row><cell></cell><cell>ing Q 0 .</cell></row></table><note><p>Λ A set of hyperparameters, including α, H, γ 0 , γ 1 , γ 2 , and c 0 . c 0</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The statistics of our real-world data set.</figDesc><table><row><cell></cell><cell cols="2">Raw Data Filtered Data</cell></row><row><cell># job postings</cell><cell>934,761</cell><cell>257,166</cell></row><row><cell># unique companies</cell><cell>68,302</cell><cell>997</cell></row><row><cell># data units</cell><cell>191,549</cell><cell>13,209</cell></row><row><cell># data chains</cell><cell>116,392</cell><cell>2,557</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Average VM/CM comparison.</figDesc><table><row><cell></cell><cell>K</cell><cell>VM</cell><cell>CM</cell></row><row><cell>MTLVM (C=5)</cell><cell>105</cell><cell>0.464</cell><cell>5.044</cell></row><row><cell cols="2">MTLVM (C=10) 100</cell><cell cols="2">0.682 6.783</cell></row><row><cell cols="3">MTLVM (C=20) 118 0.688</cell><cell>6.279</cell></row><row><cell>LDA</cell><cell>100</cell><cell>0.637</cell><cell>6.722</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>The probabilities of top recruitment topics of selected recruitment states (e.g., #1, #3, #4, #9). The corresponding word cloud representations of these topics are shown in figure8.</figDesc><table><row><cell></cell><cell cols="4">state #3 state #4 state #5 state #9</cell></row><row><cell>top #1</cell><cell>0.22493</cell><cell>0.22172</cell><cell>0.18185</cell><cell>0.19441</cell></row><row><cell>top #2</cell><cell>0.12399</cell><cell>0.17637</cell><cell>0.10126</cell><cell>0.12350</cell></row><row><cell>top #3</cell><cell>0.10064</cell><cell>0.11360</cell><cell>0.07735</cell><cell>0.10018</cell></row><row><cell>top #4</cell><cell>0.08932</cell><cell>0.08725</cell><cell>0.07242</cell><cell>0.08021</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>The prediction performance of MTLVM and baseline methods in terms of log likelihood.</figDesc><table><row><cell></cell><cell>log likelihood</cell></row><row><cell>MTLVM</cell><cell>-2095737.793</cell></row><row><cell>B-mHMM</cell><cell>-2133504.721</cell></row><row><cell>DTM</cell><cell>-2599529.728</cell></row><row><cell cols="2">all of observations χe,t,m,n are conditionally independent in</cell></row><row><cell cols="2">B-mHMM and P (χe,t,m,n|ce,t, ι) = M ulti(ιc e,t ). By this</cell></row><row><cell cols="2">baseline, we aim to prove the latent hierarchical structure of</cell></row><row><cell cols="2">our model are meaningful for modeling recruitment markets.</cell></row><row><cell cols="2">Because of the similarity of B-mHMM and MTLVM, The</cell></row><row><cell cols="2">details and inference of B-mHMM follow those of MTLVM</cell></row><row><cell>and are omitted here.</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://fanyi.baidu.com/" />
		<title level="m">Baidu translation</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="https://code.google.com/archive/p/princeton-statistical-learning/downloads" />
		<title level="m">Code of dynamic topic model</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="http://www.dice.com/" />
		<title level="m">Dice</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<ptr target="http://suo.im/gxxz0" />
		<title level="m">Forbes article</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="http://www.lagou.com/" />
		<title level="m">Lagou</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<ptr target="http://www.linkedin.com/" />
		<title level="m">Linkedin</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Exchangeability and related topics</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Aldous</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An unsupervised approach to modeling personalized contexts of mobile users</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="345" to="370" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains. The annals of mathematical statistics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Petrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soules</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Weiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="164" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamic topic models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Reading tea leaves: How humans interpret topic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="288" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stochastic models for heterogeneous dna sequences</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Churchill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of mathematical biology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="94" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bayesian restoration of single-channel patch clamp recordings</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Fredkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="page" from="427" to="448" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A fully bayesian approach to unsupervised part-of-speech tagging</title>
		<author>
			<persName><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual meeting-association for computational linguistics</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">744</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bayesian hidden markov modeling of array cgh data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Neuberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="485" to="497" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A new approach to the economic analysis of nonstationary time series and the business cycle</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="357" to="384" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Nash implementation of competitive equilibria in the job-matching market</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Game Theory</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="453" to="467" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Toward personalized context recognition for mobile users: a semisupervised bayesian hmm approach</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hidden markov models for speech recognition</title>
		<author>
			<persName><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="251" to="272" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Skills in the management oriented is and enterprise system job markets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Litecky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Igou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th annual conference on Computers and People Research</title>
		<meeting>the 50th annual conference on Computers and People Research</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Markovian structures in biological sequence alignments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Neuwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Lawrence</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">445</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bringing order to the job market: Efficient job offer categorization in e-recruitment</title>
		<author>
			<persName><forename type="first">E</forename><surname>Malherbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cataldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ballatore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1101" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A tutorial on hidden markov models and selected applications in speech recognition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="257" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Romer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chow</surname></persName>
		</author>
		<title level="m">Advanced Macroeconomic Theory</title>
		<imprint>
			<publisher>Mcgraw-hill</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Equilibrium unemployment as a worker discipline device</title>
		<author>
			<persName><forename type="first">C</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Stiglitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Economic Review</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="433" to="444" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hierarchical dirichlet processes</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the american statistical association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">476</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Intermediate microeconomics: a modern approach</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Varian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Repcheck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>WW Norton &amp; Company</publisher>
			<biblScope unit="volume">6</biblScope>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.6874</idno>
		<title level="m">Integrating document clustering and topic modeling</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dynamic topic modeling for monitoring market competition from online text and image data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1425" to="1434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tracking the evolution of social emotions with topic models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Popularity modeling for mobile apps: A sequential approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1303" to="1314" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Cybernetics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
