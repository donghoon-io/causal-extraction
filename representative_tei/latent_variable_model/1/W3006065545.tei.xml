<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge-Grounded Response Generation with Deep Attentional Latent-Variable Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-03-23">23 Mar 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hao-Tong</forename><surname>Ye</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kai-Ling</forename><surname>Lo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shang-Yu</forename><surname>Su</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
							<email>y.v.chen@ieee.org</email>
							<affiliation key="aff0">
								<orgName type="institution">National Taiwan University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Knowledge-Grounded Response Generation with Deep Attentional Latent-Variable Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-03-23">23 Mar 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1903.09813v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>End-to-end dialogue generation has achieved promising results without using handcrafted features and attributes specific for each task and corpus. However, one of the fatal drawbacks in such approaches is that they are unable to generate informative utterances, so it limits their usage from some real-world conversational applications. This paper attempts at generating diverse and informative responses with a variational generation model, which contains a joint attention mechanism conditioning on the information from both dialogue contexts and extra knowledge.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Dialogue-related research can be mainly categorized into two branches: (1) task-oriented: the system trying to help users complete a certain task (2) chit-chat: the system that can handle casual conversations that do not belong to any specific domain. Recently, how to bridge these two branches has become a new research direction in conversation modeling, where the system can generate useful and fact-grounded responses via external knowledge without domain constraints <ref type="bibr" target="#b1">(Hori and Hori 2017;</ref><ref type="bibr" target="#b8">Yoshino et al. 2018;</ref><ref type="bibr" target="#b1">Ghazvininejad et al. 2017)</ref>.</p><p>Prior work showed that end-to-end neural models are capable of generating sound responses for chit-chat dialogues in a data-driven way, without using handcrafted features specific for each corpus or different task <ref type="bibr" target="#b8">(Vinyals and Le 2015;</ref><ref type="bibr" target="#b7">Sordoni et al. 2015;</ref><ref type="bibr">Li et al. 2016b;</ref><ref type="bibr" target="#b1">Gao, Galley, and Li 2018)</ref>. However, such systems still highly rely on the information stored in training corpora, which is constrained by time, space, and speakers during data collection. Also, the systems lack the direct access to external information and the knowledge-grounded mechanism; therefore they cannot effectively retrieve real-world common senses and facts in order to respond properly. This fundamental limitation makes the end-to-end systems difficult to complete tasks <ref type="bibr" target="#b2">(Li et al. 2017;</ref><ref type="bibr" target="#b3">Peng et al. 2018)</ref> or generate fact-grounded chitchat <ref type="bibr" target="#b1">(Ghazvininejad et al. 2017)</ref>.</p><p>On the other hand, for traditional dialogue systems, we can easily insert external knowledge and facts into the model with the cost of detailed hand-coding features, which requires a large amount of pre-processing and data labeling.</p><p>For those tasks or corpora related to complex information or professional knowledge, pre-processing and annotations are difficult to acquire, thus making this approach impractical.</p><p>In this work, we propose an end-to-end variational model with the attention mechanism that models the interactions between dialogue contexts and external knowledge. This model is capable of balancing between scalability and generalization of neural models and provides more factual and knowledge-grounded responses compared to the traditional systems. Such extension is especially important for a conversational model deployed in systems requiring more relevant and informative interactions (e.g. the recommendation system).</p><p>To test the ability of generating knowledge-grounded responses, the seventh Dialog System Technology Challenge (DSTC7) proposed a benchmark Reddit dataset, in which the conversations are accompanied with a link to an external webpage that may contain related facts and knowledge. A dataset example is shown in Table <ref type="table" target="#tab_0">1</ref>, where the last two responses share the same contexts, and the fact retrieved by our model contains related knowledge given the conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposed Approach</head><p>The task is to generate a suitable response that contains grounded knowledge or factual information given its conversation contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Framework</head><p>The main difference between this task and others is the context-relevant facts, which are retrieved from the website links mentioned at the beginning of conversations. This external knowledge provides our model cues about how to ground the information in the response. Therefore, we first build a retrieval model to effectively obtain the fact containing the relevant knowledge, and then learn the conversation model to generate the knowledge-grounded response. Below we describe the detail of the proposed conversation model, where given a conversation con texts and its related facts, the goal is to generate the next probable sentence with informative knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conversation:</head><p>til monty python member terry gilliam was author j . k rowling 's first choice to direct the first harry potter movie , but was rejected for chris columbus . inan interview he said " i was the perfect guy to do harry potter ... i mean , chris columbus ' versions are terrible . just dull . pedestrian " <ref type="url" target="https://en.wikipedia.org/wiki/terry">https://en.wikipedia.org/wiki/terry</ref> gilliam --gilliam would have been great -but we 'd still be waiting on the second movie .</p><p>---he should do an animated version ----harry potter &amp; the giant soft gradient foot --they hired chris columbus due to his experience directing child actors .</p><p>---i also think he 's really good at seeing things from a kid 's imagination . those first 2 movies really seemed like someone went into my head and said " ok we 're going to film a movie here!" ---came here to say this. iirc, he was hired specifically because he was good with kids... which gilliam had little experience with. i think they turned out very well, very true to the books. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conversation Model</head><p>For each conversation, our model takes dialogue contexts C and context-relevant facts F as the input, and outputs the fact-grounded response R. Specifically, C = {c i } Nc i=1 , where c n = {c n,j } T c n j=1 is a sequence of word embeddings in the n-th utterance of the conversation. For the fact,</p><formula xml:id="formula_0">F = {f i } N f i=1 , where f n = {f n,j } T f n</formula><p>j=1 is a sequence of word embeddings of n-th fact. The generated response is formulated as R = {r i } T r i=1 . In our model, we treat the conversation utterances and facts as two sequences, with a special token used to separate utterances in a dialogue or a fact; that is, the contexts and facts are turned into C = {c i } N i=1 and F = {f j } M j=1 respectively, where c i and f j are word embedding vectors.</p><p>First, we use two separate encoders, Enc C and Enc H , to encode the dialogue contexts and facts respectively. The encoded contexts and facts</p><formula xml:id="formula_1">H C = {h c i } N i=1 , H F = {h f j } M j=1</formula><p>are fed into the attention module, and then the decoder generates the fact-grounded response. In our model, with the encoded contexts and facts, the decoder generates the response in an auto-regressive way, which is commonly called as a sequence-to-sequence model. For each step, the output of the decoder o t is calculated from previous output o t-1 and the encoded information H C and H F :</p><formula xml:id="formula_2">o t = Dec(o t-1 , Attn(o t-1 , H C , H F )).<label>(1)</label></formula><p>The output of the decoder, o t , is then projected to the vocabulary through a linear layer followed by a softmax activation. The proposed model is illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, where there are several encoders that focus on different types of information. During generation, this model proposes 1) a fact-grounded attention mechanism that can explicitly consider the contexts snd facts and 2) a conditional variational generation model that can produce diverse and informative responses. The detail of two module is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fact-Grounded Attention</head><p>In order to capture the relations between these three types of information, dialogue contexts, facts, and responses, we apply three attention variants to model their interactions (Bahdanau, Cho, and Bengio 2014): context-only attention, parallel attention, and context-guided fact attention detailed below.</p><p>Context-Only Attention One simple attention baseline only uses the information from contexts to generate the response. That is, with the last-step output o t-1 and the encoded information H C , H F , the attention is calculated as:</p><formula xml:id="formula_3">Attn(o t-1 , H C , H F ) = N i=1 α t i h c i , e t i = v T c tanh(W c 1 o t-1 + W c 2 h c i ) + b c , α t = softmax(e t ),<label>(2)</label></formula><p>where v c , W c 1 , W c 2 , and b c are trainable parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parallel Attention</head><p>In order to well utilize the facts, one trivial solution is to consider facts as the additional contexts; that is:</p><formula xml:id="formula_4">Attn(o t-1 , H C , H F ) = N i=1 α t i h c i ; M j=1 β t j h f j m t j = v T f tanh(W f 1 o t-1 + W f 2 h f j ) + b f , β t = softmax(m t ),</formula><p>(3) and α t is the same as the context-only attention.</p><formula xml:id="formula_5">v f , W f 1 , W f 2 , b f are trainable parameters.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context-Guided Fact Attention</head><p>To better model the interaction between contexts and facts, we proposed to use the information from contexts to guide the attention towards facts. Specifically, we modify the attention on facts from the parallel attention as below. We first calculate the attention distribution from contexts to facts,</p><formula xml:id="formula_6">M i,j = v T g tanh(W g 1 h c i + W g 2 h f j ) + b g , m c j = N i=1 M i,j , β c = softmax(m c ).<label>(4)</label></formula><p>Then, for each step, we calculate the attention from the laststep output to facts, and take the mean of two distributions as the final attention distribution on facts:</p><formula xml:id="formula_7">mt i = v T o tanh(W o 1 o t-1 + W o 2 h c i ) + b o , βt = softmax( mt ), β t = βt + β c 2 ,<label>(5)</label></formula><p>where <ref type="figure"></ref>and<ref type="figure">b</ref> o are trainable parameters. Hence, the obtained attention is guided by the contextual information.</p><formula xml:id="formula_8">v g , v o , W g 1 , W g 2 , W o 1 , W o 2 , b g ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conditional Variational Generation</head><p>The conversations in the dataset for the DSTC7 challenge are tree-like structures, where for each context, there may be more than one reference responses. This is also an important perspective for the natural conversations: for arbitrary dialogue contexts, there are usually not only one unique way to respond to it.</p><p>With the above consideration, we take the benefit from the variational autoencoder for this task, which has the better capability of capturing such relation than a simple seq2seq model <ref type="bibr" target="#b1">(Kingma and Welling 2013;</ref><ref type="bibr" target="#b6">Sohn, Lee, and Yan 2015)</ref>. The detail of the variational model is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CVAE for Dialogue Generation</head><p>For each conversation, we represent it via four random variables: the desired response R, the contexts and facts, C and F , and a latent vari- </p><formula xml:id="formula_9">p(R, z | C, F ) = p(R | C, F, z)p(z | C, F ).<label>(6)</label></formula><p>We model the probability p(R | C, F, z) and p(z | C, F ) using the parameters θ and φ respectively. Under the variational autoencoder (VAE) framework, we can interpret θ and φ as the decoder and the encoder; by setting up a Bayesian prior p(z | C, F ), our optimization target p θ (R | C, F ) becomes the variational lower bound (ELBO):</p><formula xml:id="formula_10">log p θ (R | C, F ) ≥ -KL(q φ (z | R, C, F ) p(z | C, F )) + E q φ (z|R,C,F ) [log p θ (R | C, F, z)].<label>(7</label></formula><p>) In our model, the prior p(z | C, F ) is set as N (0, I).</p><p>Annealing Loss of KL Divergence As mentioned above, the optimization target, which is the variational lower bound of log p θ (R | C, F ), is composed of two sub-goals: one is to minimize the KL divergence between the prior and the conditional encoder probability q φ ; another is to maximize the reconstruction probability.</p><p>It is found that the model tends to minimize the KL divergence instead of reducing the reconstruction error during early training, resulting in a KL vanishing issue. In order to alleviate the strong bias on minimization of KL divergence, we apply the annealing loss trick to scale down the effect of the KL term at the beginning of training for improving the performance <ref type="bibr" target="#b0">(Bowman et al. 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training</head><p>The proposed model is trained to generate the responses using the CVAE objective, where the attention mechanisms enforce the responses to cover the fact-related information for knowledge-grounded response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>To evaluate the proposed model, we conduct the experiments on the DSTC7 challenge. The used dataset and the experimental setting are described below. Then the results are analyzed in terms of objective and subjective evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>The dataset used in DSTC7-Track2 is crawled from Reddit with the scripts 1 , which consists of discussions from subreddits like todayilearned, worldnews, movies, etc. In the dataset, the posts include a link to an external webpage, from which the facts for each conversation are then extracted. In order to encourage our conversation model to contain the factual information, we process this dataset to make sure the conversations in which the context and provided facts are relevant. The processing procedure is described as:</p><p>1. Fact relevance: Because the facts are extracted from the HTML source codes of webpages, some of them lack the relevant information (e.g. metadata), we use TF-IDF to rank all facts and keep the top-1 fact as the relevant knowledge for ensuring better data quality.</p><p>2. Knowledge-grounded response: Because the discussions in some conversations may deviate from the original topic, making all facts being irrelevant to the dialogue contexts, we thus filter out data samples where the response and the retrieved fact have no common words without considering punctuations and stopwords<ref type="foot" target="#foot_0">foot_0</ref> . This procedure ensures the training data to match our goal about knowledge-grounded responses.</p><p>Due to the limitation of computation resources (one GTX 1080), we use only a subset of training data, and discard the data samples with the responses longer than 20. Table <ref type="table" target="#tab_1">2</ref> shows the detailed statistics of the dataset after our processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Details</head><p>Considering that the dataset contains a large amount of Internet slangs and spoken English, we train a 100 dimension word embeddings via GLoVe from train and development conversations and facts <ref type="bibr" target="#b4">(Pennington, Socher, and Manning 2014)</ref>. We truncate the context to the last 100 tokens and the fact to the first 500 tokens. The context encoder Enc C is a 2-layer bidirectional GRU (Cho et al. 2014) with hidden size 128; the fact encoder Enc H is a convolutional network with 1,2,3 width filters, and 128 feature maps per filter. The decoder Dec is a 2-layer unidirectional GRU with the hidden size 128. For the CVAE variants, another 2-layer bidirectional GRU with the hidden size 128 is used to encode the responses.</p><p>Our models are trained using the teacher-forcing mechanism to maximize the likelihood of generating R = {r i } T r i=1 . We used adam (Kingma and Ba 2014) with the default setting as our optimizer. During testing, we apply the beam search where the beam size is 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In the experiments, we perform two sets of evaluation, automatic evaluation and human evaluation, to better validate our generated results.</p><p>Automatic Evaluation Our evaluation metrics include BLEU <ref type="bibr" target="#b3">(Papineni et al. 2002)</ref>, METEOR (Banerjee and Lavie 2005), NIST (Doddington 2002), diversity <ref type="bibr">(Li et al. 2016a</ref>) and entropy <ref type="bibr" target="#b8">(Zhang et al. 2018)</ref> scores. We use the implementation in the Python package nlg-eval<ref type="foot" target="#foot_1">foot_1</ref> for BLEU and METEOR scores <ref type="bibr" target="#b5">(Sharma et al. 2017)</ref>, and the NLTK toolkit to calculate NIST scores. Our results are shown in Table <ref type="table" target="#tab_3">3</ref>.  It can be found that the context-guided attention model with CVAE (CG+CVAE) achieves better performance for most metrics in terms of the similarity between the generated responses and the ground truth responses. This justifies the effectiveness of our context-guided attention, because its goal is to generate responses containing more relevant knowledge, and the metrics slightly measure the relatedness. However, the context-only attention with CVAE (CO+VVAE) obtains the higher diversity, which is also important for this generation task. The results show the small improvement achieved by the proposed CVAE model in terms of the generation quality and the diversity.</p><formula xml:id="formula_11">Model B-1 B-2 B-3 B-4 N-1 N-2 N-3 N-4 MET Div-1 Div-2 Ent-1 Ent-2 Ent-3</formula><p>Human Evaluation In order to understand the effect of our fact-grounded attention and variational generation, we conduct human evaluation on three proposed methods: the parallel attention model as our baseline (PA), compared with the parallel attention with variational generation (PA+CVAE), and the context-guided attention (CG). First, we randomly sample 100 testing samples that fulfill the following two conditions: 1. Each response has at least 3 words, because some methods tend to produce very short responses, which is hard to evaluate. 2. Due to the goal about fact-grounded generation, we make sure that the contexts and the retrieved fact have more than 3 common words for each sample, where punctuations and stop-words are not considered. Then we conduct human evaluation for our proposed methods in a similar way to the official evaluation: 1. In addition to relevance and interest, which are asked in official evaluation, we ask the judges to evaluate two additional metrics: fluency and knowledge relatedness (to the retrieved fact) of our response.</p><p>2. Because we only pick one fact based on the contexts as our model input, we directly provide this fact to judges as the extra information for them to better evaluate knowledge relatedness of the response.</p><p>The results are shown in Table <ref type="table" target="#tab_4">4</ref>. The submitted system, the best achieved results, and human performance are also included in Table <ref type="table" target="#tab_4">4</ref> for better comparison. Note that the numbers for two sets of evaluation may not be directly compared but for reference.</p><p>In the offline human evaluation, it is found that the proposed models do not achieve better performance and the difference between all models are small. From the official evaluation, our submitted results are also between disagree (2) and neutral (3) as in our evaluation, but the contextguided attention achieves slightly better numbers than other proposed models shown in the offline setting. Furthermore, the best achieved performance is about 2.94, which is also lower than neutral (3), implying the difficulty of this task. It is clear that there is a huge gap between the currently machine-achieved and human-achieved performance, so this task requires further investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative Analysis</head><p>The above results tell that there is no significant difference between our proposed models and baselines. A sample model responses from the human evaluation set is shown in Table <ref type="table" target="#tab_5">5</ref> for our qualitative analysis. In this example, adding Retrieved top-1 fact: in the united states , centenarians traditionally receive a letter from the president , congratulating them for their longevity . nbc ' s today show has also named new centenarians on air since 1983 . centenarians born in ireland receive a 2,540 " centenarians ' bounty " and a letter from the president of ireland , even if they are resident abroad . [ 63 ] japanese centenarians receive a silver cup and a certificate from the prime minister of japan upon their 100th birthday , honouring them for their longevity and prosperity in their lives . swedish centenarians receive a telegram from the king and queen of sweden .</p><p>[ 64 ] centenarians born in italy receive a letter from the president of italy . in japan , a " national respect for the aged day " has been celebrated every september since 1966 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conversation:</head><p>-til in the united states , people who turn 100 years old receive a letter from the president , congratulating them on their longevity . -same in canada but 90 instead of 100 Ground Truth: is that the canadian exchange rate these days ? PA Response: they are the same thing . PA+CVAE Response: you can have to be a . CG Response: it's not the same thing in the uk . CVAE generates a more diverse response than the parallel attention result, but may not effectively ground the knowledge in the sentence. Also, our context-guided result seems to focus more on the fact compared to other models. However, the ground truth in the data is very difficult to simulate for the current models, because it may need additional knowledge or common sense. From the current results achieved by our model, we conclude that this task still needs further investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We describe a variational knowledge-grounded conversation system, which attempts at modeling the relations between dialogue contexts and external facts in an endto-end fashion. It guides a potential research direction about how external information interacts with dialogues and how the machine can capture such interaction for better knowledge-grounded response generation. In the experiments on DSTC7, the results demonstrate the difficulty of this task, because almost all current models fail to generate reasonable responses. Therefore, the knowledge-grounded dialogue modeling requires further study in order to advance the machine's capacity of producing a informative and knowledgable conversation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the proposed model architecture.</figDesc><graphic coords="3,117.00,54.01,377.97,298.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1</head><label></label><figDesc>https://github.com/DSTC-MSR-NLP/ DSTC7-End-to-End-Conversation-Modeling</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Dataset example from subreddit todayilearned. The horizontal lines indicate the tree-structure of the conversation; we can see that the last two responses share the same contexts. The shown fact retrieved by our model is considered the most relevant to the given conversation among all facts extracted by the official script from the wikipedia page.</figDesc><table><row><cell>Retrieved top-1 fact:</cell></row><row><cell>j . k . rowling , the author of the harry potter series , is a fan of gilliam's work . consequently , he was rowling's first</cell></row><row><cell>choice to direct harry potter and the philosopher's stone in 2000 , but warner bros . ultimately chose chris columbus for</cell></row><row><cell>the job . [ 32 ] in response to this decision , gilliam said that " i was the perfect guy to do harry potter . i remember leaving</cell></row><row><cell>the meeting , getting in my car , and driving for about two hours along mulholland drive just so angry . i mean , chris</cell></row><row><cell>columbus ' versions are terrible . just dull . pedestrian . " [ 33 ] in 2006 , gilliam said that he found alfonso cuarn ' s harry</cell></row><row><cell>potter and the prisoner of azkaban to be " really good ... much closer to what i would've done . " [ 34 ] in retrospect ,</cell></row><row><cell>however , gilliam has stated that he wouldn't have liked to direct any potter film . in a 2005 interview with total film , he</cell></row><row><cell>said that he would not enjoy working on such an expensive project because of interference from studio executives . [ 35 ]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the used dataset.</figDesc><table><row><cell></cell><cell>Time Period</cell><cell cols="2">Before Filter After Filter</cell></row><row><cell cols="2">Train 2015-01∼2016-12</cell><cell>1,101,684</cell><cell>142,750</cell></row><row><cell>Dev</cell><cell>2017-01∼2017-06</cell><cell>116,858</cell><cell>14,875</cell></row></table><note><p>able z. The conditional probability p(R, z | C, F ) can be rewritten as:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>The automatic evaluation results of the baselines and the proposed methods. Baseline is a context-to-response seq2seq model without attention. CO, PA, CG correspond to context-only attention, parallel attention and context-guided attention respectively. (B: BLEU; N: Nist; MET: METEOR)</figDesc><table><row><cell></cell><cell>Model</cell><cell>Context Relevance</cell><cell>Interest</cell><cell>Fluency</cell><cell cols="2">Knowledge Average Relatedness</cell></row><row><cell></cell><cell>PA</cell><cell cols="3">2.47±0.86 2.37±0.75 4.13±0.85</cell><cell>2.19±0.87</cell><cell>2.79</cell></row><row><cell>Offline</cell><cell>PA+CVAE</cell><cell cols="3">2.40±0.81 2.38±0.77 4.00±0.92</cell><cell>2.10±0.86</cell><cell>2.72</cell></row><row><cell></cell><cell>CG</cell><cell cols="3">2.25±0.83 2.18±0.76 3.86±1.07</cell><cell>2.02±0.83</cell><cell>2.58</cell></row><row><cell></cell><cell cols="3">Submitted (CG+CVAE) 2.52±0.04 2.40±0.05</cell><cell>-</cell><cell>-</cell><cell>2.46</cell></row><row><cell>Official</cell><cell>Best</cell><cell cols="2">3.09±0.04 2.87±0.05</cell><cell>-</cell><cell>-</cell><cell>2.94</cell></row><row><cell></cell><cell>Human</cell><cell cols="2">3.61±0.04 3.49±0.04</cell><cell>-</cell><cell>-</cell><cell>3.55</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Human evaluation results in our offline and the official evaluation.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Model response sample.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>We used stopwords defined in spaCy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>https://github.com/Maluuba/nlg-eval</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Meteor: An automatic metric for mt evaluation with improved correlation with human judgments</title>
		<author>
			<persName><forename type="first">Cho</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bengio ; Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<idno>arXiv:1406.1078</idno>
	</analytic>
	<monogr>
		<title level="m">Learning phrase representations using rnn encoderdecoder for statistical machine translation</title>
		<meeting><address><addrLine>Doddington; Doddington, G</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2002">2014. 2014. Lavie 2005. 2005. 2016. 2016. 2014. 2002. 2002</date>
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the second international conference on Human Language Technology Research</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">Galley</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li ; Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Ghazvininejad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01932</idno>
		<idno>arXiv:1312.6114</idno>
	</analytic>
	<monogr>
		<title level="m">A knowledge-grounded neural conversation model</title>
		<imprint>
			<date type="published" when="2013">2018. 2018. 2017. 2017. 2017. 2017. 2014. 2014. 2013. 2013. 2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>End-toend conversation modeling track in dstc6. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01541</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016. 2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="733" to="743" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>End-to-end task-completion neural dialogue systems</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adversarial advantage actorcritic model for task-completion dialogue policy learning</title>
		<author>
			<persName><surname>Papineni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002. 2002. 2018</date>
			<biblScope unit="page" from="6149" to="6153" />
		</imprint>
	</monogr>
	<note>2018 IEEE International Conference on Acoustics, Speech and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName><forename type="first">Socher</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Manning ; Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Relevance of unsupervised metrics in taskoriented dialogue for evaluating natural language generation</title>
		<author>
			<persName><surname>Sharma</surname></persName>
		</author>
		<idno>CoRR abs/1706.09799</idno>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yan ; Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="3483" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A neural network approach to contextsensitive generation of conversational responses</title>
		<author>
			<persName><surname>Sordoni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
	<note>In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A neural conversational model</title>
		<author>
			<persName><forename type="first">Le</forename><forename type="middle">;</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Polymenakos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gunasekara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lasecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05972</idno>
	</analytic>
	<monogr>
		<title level="m">Generating informative and diverse conversational responses via adversarial information maximization</title>
		<imprint>
			<date type="published" when="2015">2015. 2015. 2015. 2018. 2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>The 7th dialog system technology challenge</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
