<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="fr">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Latent Variables modeling Chapters</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Monte-Carlo</forename><surname>Prediction</surname></persName>
						</author>
						<author>
							<persName><forename type="first">D</forename><surname>Kl</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Victor</forename><surname>Berger</surname></persName>
						</author>
						<title level="a" type="main">Latent Variables modeling Chapters</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Les Modèles à Variables Latentes Profonds sont des modèles génératifs combinant les Réseaux Bayésiens avec l'apprentissage profond, illustrés par le célèbre Auto-encodeur Variationnel. Cette thèse se focalise sur leur structure, entendue comme la combinaison de 3 aspects : le graphe du Réseau Bayésien, le choix des familles probabilistes des variables, et l'architecture des réseaux de neurones. Nous démontrons que de nombreux aspects et propriétés de ces modèles peuvent être compris et contrôlés par cette structure, sans altérer l'objectif d'entraînement construit sur l'Evidence Lower Bound.</p><p>La première contribution concerne l'impact du modèle d'observation -la modélisation probabiliste des variables observées -sur le processus d'entraînement : comment il détermine la séparation entre signal et bruit, ainsi que son impact sur la dynamique de l'entraînement lorsque son paramètre d'échelle est appris plustôt que fixé, où il agit alors comme un processus de recuit simulé.</p><p>La seconde contribution, CompVAE, est centrée sur la structure hiérarchique des variables latentes : un modèle génératif conditionné par un multi-ensemble d'élements à combiner dans la génération finale. CompVAE démontre comment des propriétés globales -des manipulations ensemblistes dans ce cas -peuvent être atteintes par la seule conception structurale. Ce modèle est de plus validé empiriquement sur des données réelles, pour la génération de courbes de consommation électrique.</p><p>La troisième contribution, Boltzmann Tuning of Generative Models (BTGM), est un cadre permettant d'ajuster un modèle génératif pré-entraîné selon un critère extérieur, en trouvant les ajustements minimaux nécessaire. Ceci est fait tout en contrôlant finement quelles variables latentes sont ajustées, et comment elles le sont. Nous démontrons empiriquement comment BTGM peut être utilisé pour spécialiser un modèle déjà entraîné, ou pour explorer les parties extrêmes d'une distribution générée.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="fr">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Generative modeling became a very hot topic in the field of deep learning in 2014, with both seminal papers presenting Variational Auto-Encoders (VAEs) <ref type="bibr" target="#b98">[KW14;</ref><ref type="bibr" target="#b147">RMW14]</ref> and Generative Adversarial Networks (GANs) <ref type="bibr" target="#b62">[Goo+14]</ref>. Each paper gave rise to a flourishing framework integrating probabilistic generative principles within deep learning methods.</p><p>This thesis focuses on the VAE framework and more specifically deep Latent Variable Models (LVMs), that elegantly combine the mathematical formalism of Bayesian Networks with the learning methods of artificial deep neural networks. This framework allows one to build powerful and flexible models, naturally amenable to the integration of prior knowledge about the considered data domain, as we aim to show in the following chapters.</p><p>A main research question guiding the organization of the manuscript is how to design deep Latent Variable Models depending on both the specifics of the data and the intended usage of the models, and how to understand their can and their can't. This analysis is conducted in the perspective of Probabilistic Graphical Models (PGM) first, and deep learning second. Focusing on the probabilistic structure of the models allows for a unified understanding of most other aspects, as this structure governs the training procedure and the relation of the model to its training data.</p><p>The applicative motivation for this research is the study of smart energy policies and dimensioning of electrical networks, more specifically the need for programmable generative models (PGMs) in order to produce realistic and exploratory simulations of electrical consumption in power systems<ref type="foot" target="#foot_0">foot_0</ref> . Principled models built in the PGMoriented perspective, presented in the last part of the thesis, aim to answer these needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Organization of this manuscript</head><p>This manuscript is structured in three parts, respectively devoted to i) the theory of deep LVMs as learned models; ii) the relationships of the deep LVM structure with the data; and iii) the design of latent structures in order to encourage or enforce desirable properties in view of the model intended usages.</p><p>Chapter 1 provides a general introduction to probabilistic graphical models (PGMs), at the core of the LVM framework and of this whole manuscript.</p><p>Part I revolves around the construction and analysis of deep LVMs. Chapter 2 introduces the concept of latent variables in a PGM, which can be interpretable or abstract, and their training within the Evidence Lower Bound (ELBO) framework.</p><p>Chapter 0. Introduction Chapter 3 pushes this construction further by combining the ELBO criterion with deep learning in the spirit of the Variational Auto-Encoder (VAE) <ref type="bibr" target="#b98">[KW14;</ref><ref type="bibr" target="#b147">RMW14]</ref>, and analyses the interaction of the inference model with the training process. Chapter 4 introduces the concept of hierarchical deep LVMs, which involves multiple latent variables organized in a hierarchy, and discusses the difficulties encountered when training such models.</p><p>Part II focuses on the relationship between the model and the available data, embodied in the so-called observation model. Chapter 5 presents a few sophisticated observation models from the literature, and discusses the problem of posterior collapse encountered by some of these models. Chapter 6 focuses on a particular type of observation model referred to as quasi-deterministic, which acts as a mere translation layer between the latent space of the model and the observed data, ensuring that all relevant information is captured by the latent variables. By relating these models to the Manifold Hypothesis, this chapter investigates the link between the observation model and the data information, and whether it can (or cannot) be exploited by the deep LVM. The answer to this question is theoretically and empirically shown to depend on the variance of the observation model <ref type="bibr" target="#b16">[BS20b]</ref>. Then, Chapter 7 focuses on this variance and how it can be learned; it illustrates the profound impact of such a learning on the training dynamics of the whole LVM.</p><p>Part III details how hierarchical deep LVMs can be structurally designed to enforce desirable properties from the whole model. Chapter 8 analyses a few examples from the literature, and presents the usage of such models to achieve anomaly detection; this application was motivated by the identification faulty sensors in the CMS experiment at CERN <ref type="bibr" target="#b139">[Pol+19]</ref>. Then, Chapter 9 presents CompVAE <ref type="bibr" target="#b15">[BS20a]</ref>, a deep LVM structure designed to represent a programmable compositional generative model, meant to generate instances aggregating a variable number of entities. This model is detailed and analyzed on 1D and 2D artificial problems, and applied to real world data in the context of electrical distribution networks. Finally, Chapter 10 presents the Boltzmann Tuning of Generative Models (BTGM) approach <ref type="bibr" target="#b17">[BS21]</ref>, aimed to a posteriori refining an already trained LVM and to oversample a part of the corresponding distribution depending on an externally provided criterion. The BTGM approach, stemmed from the practical motivation of identifying the electrical consumption peak, constitutes a principled alternative to rejection-based sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notations</head><p>In the manuscript, random variables are denoted with capital letters (e.g. A, X, Z); their instanciations are denoted with lowercase letters (e.g., a, x, z).</p><p>The probabilistic models are generally denoted p or q; the probability (or probability density) p(X = x, Y = y) associated with a variable assignation is noted p(x, y) for simplicity. By slight abuse of notation, the conditional and marginal distributions derived from this model are noted in the same way, e.g., p(x, z|w) represents the distribution under model p, conditioned on W = w, and where all variables but X and Z have been marginalized.</p><p>Many probabilistic models considered in this work are parameterized; their vector of parameters is generally noted θ or φ, and the parameterized model is Models play an important role in analysis of the world, and are widely used in various forms across the scientific literature. They help understand relations and interactions between the various quantities of interest in a problem analysis by unveiling structure in the data. In many cases these models are probabilistic, either due to the intrinsic stochasticity of the phenomenon at hand or to account for the fact that this phenomenon is only partially known.</p><p>Probabilistic models generally take the form of a joint distribution over descriptive variables<ref type="foot" target="#foot_1">foot_1</ref> X 1 , X 2 , . . . , X N . Due to the usually large number of variables involved, such joint distributions can very quickly become incredibly complex and tedious to manipulate. To address this issue, an approach is to introduce explicit structure into the model, e.g. accounting for some known dependency relations between the variables. Probabilistic graphical models aim at representing such relations using graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Independence relations as graphs</head><p>The probabilistic graphical model framework is as follows. Each variable of the model is represented as a node in the graph. Two nodes are linked by an edge if there is some direct dependency relationship between the two variables. In this representation, there exists a path in the graph between two nodes iff there exists some potential dependency between both variables. On the contrary, if no path exists, then the two variables must be independent.</p><p>Such a representation allows reasoning about subsets of variables, as illustrated in Figure <ref type="figure">1</ref>.1. Large graphical models can be analyzed on a local basis if they are sufficiently sparse. This makes it possible to characterize the behavior of the model to some extend without needing to consider the whole joint distribution. As will be illustrated in the rest of this sections, graphs can directed or undirected, with different interpretations associated with the links. The two main types of graphical models are Bayesian Networks (which are directed graphs) and Markov Random Fields (which are undirected). While the thesis mostly relies on Bayesian Networks, some methods relying on Markov Random Fields are also discussed. Therefore, both frameworks are presented in this chapter, introducing their proper inference and training methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.1">Bayesian Networks</head><p>Bayesian Networks, a prominent type of probabilistic graphical models <ref type="bibr" target="#b92">[KF09]</ref>, are based on Directed Acyclic Graphs (DAG): edges among nodes are oriented (represented as arrows) and the graph does not include any directed cycle. An example of such a network is given in Figure <ref type="figure">1</ref>.2.</p><p>Let us introduce and illustrate the classic Bayesian Network terminology on this example. Each edge defines a directed relation between two nodes. The node from which the edge comes is called the parent and the node to which the arrow points is called the child. In the example graph, S and R are the children of C, H and C are the parents of S. Nodes H, S, C and R are ancestors of W . Similarly, S, R and W are descendants of C. There is no particular named relation between H and R, aside the fact that they are not independent.</p><p>One should note that the independence relations in such a directed graph are not as straightforward as in an undirected case(Figure <ref type="figure">1</ref>.1). An important situation is when two nodes share a child, forming what is known as a v-structure. Example of a Bayesian Network modeling the possible causes of why the grass outside may be wet (W ). The two direct considered causes are the rain (R) and the sprinkler (S). The rain is more likely to occur when the sky is cloudy (C), while the sprinkler is more likely to be used when the sky is clear and the air is hot (H). While the graph may appear cyclic, it is not when you consider the orientation of the edges. For example you cannot loop back to S by only following the arrows. displays two of them: H -S -C and S -W -R. In such a case, the parents are in general not independent given their child. In the running example, knowing that the grass is wet means that for sure either its has rained or the sprinkler has run; if one variable is F alse, then the other must be T rue. However, observing a variable still makes its different children independent of each other and its parents independent from its children, assuming there is no other path in the model linking them. In Figure <ref type="figure">1</ref>.2, observing S and R would make (H, C) independent of W .</p><p>The graph representation of a Bayesian Network specifies the structure of the associated probabilistic model. Formally, this joint probability distribution is defined as the product of conditional distributions over the nodes. Letting π(X i ) denote the set of parent variables of X i , then: p(X 1 , X 2 , . . . , x N ) = N i=1 p(X i |π(X i ))</p><p>(1.1)</p><p>The example network of Figure <ref type="figure">1</ref>.2 can thus be factorized as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>p(A, B, C, D, E) = p(A)p(B)p(C|A, B)p(D|B)p(E|C, D). (1.2)</head><p>This representation allows for drastically compressing the model. Instead of specifying a full probability table over the 5 variables, we can just specify 5 small tables over at most 3 variables each, making the combinatorics of the model much more manageable. In our example, assuming all 5 variables were binary, the full probability table would have 2 5 = 32 entries. By contrast, the factorized representation with 5 tables would involve only 24 entries, only half of which would be actually independent parameters. This difference can grow very quickly with the number of variables and the number of different values each variable can take. Each term p(x i |π(X i )) in the factored distribution can be specified as a probability table in the discrete case. In the following, a more general formulation will be considered to handle both discrete and continuous variables. Each variable X i ∼ P i (X i ; ω i )) follows a given distribution (such as categorical, Gaussian, or Poisson distributions), the parameter of which depends on the value of its parent variables , we associate a parameterized distribution family (ω i = f i (π(X i ))).</p><p>Eventually, the joint distribution p(X 1 . . . X N ) is fully specified from the DAG structure, the parameterized distribution family P i associated to each variable X i and a parameter function f i defining how the parameter of P i (X i ) depends on the parent variables of X i :</p><formula xml:id="formula_0">pP (X 1 . . . X N ) = N i=1 P i X i ; ω i = f i (π(X i )) (1.3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.2">Markov Networks</head><p>Markov Networks, also called Markov Random Fields (MRFs), are the other main type of graphical models <ref type="bibr" target="#b92">[KF09]</ref>. They differ from Bayesian Networks in two ways: firstly, MRFs are represented via undirected graphs (as opposed to directed graphs for BNs). Secondly, while BNs characterize the joint distribution as the product of conditional distributions, MRFs aim to express independence relations, centered on the Markov Property: given a set of variables that splits the graph in two disjoint subsets (a.k.a. separating the graph), the distribution of the two resulting subsets are independent conditionally to the value of the separating variables.</p><p>MRFs are notably used in several statistical physics models. For example Ising networks represent networks of particles that can each be in two states, denoted U p and Down. Interactions between these particles are local: each particle tends to settle in a state depending on the states of its neighbors (as represented by the graph). The study of the produced MRFs allows understanding the large-scale behavior of lattices composed of many such particles.</p><p>Following the example of Figure <ref type="figure">1</ref>.3, conditioning on the variables B and E splits the graph in two subgraphs, {A, D} and {C, F }. Thus, the joint conditional distribution p(A, C, D, F |B, E) factors as: <ref type="figure" target="#fig_69">p(A,</ref><ref type="figure">C,</ref><ref type="figure">D,</ref><ref type="figure">F |B,</ref><ref type="figure" target="#fig_69">E) = p(A,</ref><ref type="figure">D|B,</ref><ref type="figure">E)p(C,</ref><ref type="figure">F |B,</ref><ref type="figure">E)</ref> (1.4)</p><p>In many cases the probability distribution associated with the graphical model can be represented in a factorized form according to the cliques of the graph<ref type="foot" target="#foot_2">foot_2</ref> . Cliques are fully-connected subgraphs: in the model of Figure <ref type="figure">1</ref>.3, {B, D, E} is a clique, while {A, B, D, F } is not (it is missing an edge between A and E).</p><p>For each clique C in the graph, is it possible to define a potential function φ C (X C ) over the values of the variables contained in this clique, such that the whole probability distribution factors as a product of these potentials. These clique potentials reflect the independence assumptions included in the graph structure.</p><formula xml:id="formula_1">p(x 1 , . . . , x N ) = 1 Z C φ C (X C ) (1.5)</formula><p>The normalization constant Z is then defined as the sum of the potential values over all possible assignments of the variables, so that the distribution probability is correctly normalized. As a result, it depends on the potential functions:</p><formula xml:id="formula_2">Z = X∈X C φ C (X C ) (1.6)</formula><p>In Figure <ref type="figure">1</ref>.3, {B, D, E} is a clique, while {A, B, D, F } is not (it is missing an edge between A and E). The joint distribution model thus reads</p><formula xml:id="formula_3">p(A, B, C, D, E, F ) = 1 Z φ ABD φ BDE φ BEF φ BCF (1.7)</formula><p>Note that with no loss of generality, one can consider only the largest cliques in the graph (e.g. φ AB is accounted for by φ ABC ).</p><p>It is emphasized that potentials φ C need not be normalized probability distributions (as opposed to Bayesian Networks). This gives more representation flexibility<ref type="foot" target="#foot_4">foot_4</ref> , at the expense of a loss in interpretability.</p><p>By analogy with statistical physics, it is often convenient to represent the clique potentials in logarithmic form: f C (x C ) = -log φ(x C ), in which case the joint distribution of the model takes the form of a Gibbs distribution:</p><formula xml:id="formula_4">p(x 1 , . . . , x N ) = 1 Z exp - f C (x C ) = 1 Z exp (-E(x 1 , . . . , x N )) (1.8)</formula><p>The sum E(x 1 , . . . , x N ) = f C (x C ) is by analogy named the energy function of the model.</p><p>The computation of the normalization constant Z is, in general, a hard problem: it requires computing and summing the potentials over all possible values of all variables. As a consequence, many algorithms working with Markov Networks are designed to work with the unnormalized probability, thus side-stepping the need to know the value of Z <ref type="bibr" target="#b92">[KF09]</ref>.</p><p>(Restricted) Boltzmann Machines Boltzmann Machines are a special case of Markov Networks where all nodes take binary values, and the energy function decomposes into terms involving only 1 or 2 variables. The general form of a Boltzman Machine energy function thus is:</p><formula xml:id="formula_5">E(x 1 , . . . , x N ) = i&lt;j w ij x i x j + i b i x i</formula><p>(1.9)</p><p>A special case of Boltzmann Machines of special interest in machine learning are the so-called Restricted Boltzmann Machines, or RBMs. They additionally impose that the variables be split into two sets, respectively referred to as "visible" variables {v i } and "hidden" variables {h j } (Figure <ref type="figure">1</ref>.4(b)), and that visible (resp. hidden) variables are independent from each other. Potentials involving two variables thus always involve one hidden and one visible variable. The strongly constrained structure of RBMs make them significantly easier to manipulate than general Boltzmann Machines or Markov networks. They display significant success as a machine learning tool on a large range of problems [HS06; SMH07; LB08].</p><formula xml:id="formula_6">x 1 x 2 x 6 x 3 x 5 x 4 (a) Boltzman Machine v 1 v 2 v 3 h 1 h 2 h 3 h 4 (b) Restricted Boltzmann Machine</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Inference</head><p>A fully-specified graphical model provides a description of the underlying phenomenon. It can also be queried to answer questions such as "Assuming variable X takes the value x, what is the associated conditional probability of variable Y , p(Y |X = x) ?". Answering such queries, referred to as What-If usage, is one of the major assets of graphical models<ref type="foot" target="#foot_5">foot_5</ref> . This kind of questions generally involve a mix of conditioning the model on some variables and marginalizing others, to produce a probability distribution over the variables of interest.</p><p>An early example of such a use case is the design of Bayesian Networks to assist medical diagnostic, such as the Pathfinder models <ref type="bibr" target="#b74">[HN92]</ref>. The relationships between candidate diseases and the associated symptoms are modeled as a Bayesian Network with the help of medical experts, and inference queries on this network allow to infer the most likely diseases given the observed patient symptoms.</p><p>Quite a few approaches have been designed to answer such queries depending on the query and the graph associated to the model. This section presents several of them. They generally apply to both Bayesian Networks and Markov Networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.1">Exact inference on discrete variables</head><p>In the discrete finite case (every variable taking a finite number of values), any such query can be answered by producing the full probability table of the model, although this approach clearly does not scale up with the number of variables and the size of their domain<ref type="foot" target="#foot_6">foot_6</ref> . Depending on the shape of the graph and the kind of query, various algorithms have been developed to efficiently compute these queries.</p><p>Variable Elimination algorithm Some graphs can be processed in an iterative manner, eliminating the variables one after another. Doing so in a carefully chosen order can significantly reduce the total computational cost as it never requires to actually produce the full probability table <ref type="bibr" target="#b185">[ZP94]</ref>. For example, following Figure <ref type="figure">1</ref>.2, the variable A is a good candidate for being marginalized first: being liked to a single other variable doing it is an easy task. On the other hand marginalizing C first would link together variables A, B and E into a complex distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Belief Propagation algorithm</head><p>The belief propagation (BP) algorithm <ref type="bibr" target="#b136">[Pea82]</ref> efficiently applies on tree-structured models. Given any number of observed variables with fixed value, the exact marginal distribution of every other variable is computed. BP can also apply on non tree-structured graphs, in which case it is referred to as Loopy BP and is part of the large family of Approximate Message Passing algorithms <ref type="bibr" target="#b40">[DMM09]</ref>. It does no longer provide any guarantee on the result accuracy and might not converge in the general case, but under some conditions (in particular concerning the graph sparsity), it can still yield satisfactory approximations of the sought results <ref type="bibr" target="#b176">[Wei00]</ref>.</p><p>Junction tree algorithm When considering a non tree-structured BN, the junction tree algorithms proceed by creating additional meta-nodes and grouping initial nodes in such a way that the initial graph induces a tree-structure of the created meta-node graph; the belief propagation algorithm thus applies on the meta-node graph. This general idea comes in diverse variants [LS88; JOA90; She97], differing in how to select and group the nodes: the cost of the belief propagation highly depends on which nodes are grouped together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2">Approximate inference with Monte Carlo methods</head><p>When the model involves continuous variables, or the query or model does not fit well with the previously described algorithm, one can turn to Markov-Chain Monte-Carlo (MCMC) methods in order to sample the sought distribution. These samples can then be used to compute statistical quantities of this distribution, and more generally to approximate the expectation of an arbitrary function under this distribution.</p><p>Markov Chains are the core element of these methods. They are stochastic processes that generate a sequence of values (x (0) , x (1) , . . . ). The process is defined by a transition probability function T (x (t+1) |x (t) ), which describes the probability of the value at step t + 1 given the value at step t. A visual illustration of such a process can be seen in a board game, where each player rolls the die at their turn and moves accordingly: the resulting position depends on the previous position and the result of the die throw.</p><p>As a result, a sample from the chain only depends on the value of the previous sample. This is another form of the Markov Property. Indeed, a Markov Chain can be represented as a Bayesian Network in which each variable X (t) is linked to the previous and next variables in the sequence, X (t-1) and X (t+1) , as illustrated in Figure <ref type="figure">1</ref>.5.</p><p>. . . X (t-1) X (t) X (t+1)   . . . Under some conditions, Markov Chains have a stationary distribution π, defined as:</p><formula xml:id="formula_7">π(x ) = E x∼π T (x |x)</formula><p>(1.10)</p><p>It means that if X (0) is sampled from π and X (1) is sampled from the transition probability T (•|X (0) ), then the distribution of X (1) also is π. In the case of an ergodic Markov Chain (i.e. any value can be reached from any starting point in a finite number of steps), then the stationary distribution π is unique and the long-run samples of the Markov Chain converge in law to it.</p><p>Markov-Chain Monte-Carlo is a family of methods that can be used to approximately sample a given target distribution p. The common principle is to try and design a Markov Chain whose stationary distribution is p. Samples from this Markov Chain can then by used as proxy for samples of p, with two caveats. First, we need to take into account the time of convergence for the Markov Chain: unless the starting point was sampled directly from the stationary distribution (which cannot be the case here), the initial samples are not distributed according it. This generally implies a "burn-in" time: the first K samples of the Markov Chain are discarded (with typical values of K being around 1000). The second caveat is that the successive samples from the Markov Chain are correlated. In order to approximate independent samples from the target distribution, it is further necessary to discard many samples between each one that is kept (for example keeping 1 sample in 100).</p><p>A sufficient condition for p being such a stationary distribution, it that the it satisfies the detailed balance property, making the Markov Chain reversible: ∀x, x : T (x |x)p(x) = T (x|x )p(x )</p><p>(1.11)</p><p>In the context of graphical models, a Markov Chain proceeds by generating X (t+1) (the vector of all node values) from X (t) . As is illustrated by the algorithms presented in the following sections, a strong merit of MCMC-based methods is that many of them only require an unnormalized target distribution, making them widely applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2.1">Gibbs sampling</head><p>In most models, the sampling complexity is due to the correlation of the variables. However each individual variable x i often follows a simple conditional distribution relative to all other variables (noted x -i ): when all variables but one are frozen, the effective size of the graphical model is drastically reduced. Gibbs sampling <ref type="bibr" target="#b58">[GG84]</ref> takes advantage of this property, by updating each x i conditionally to the others, thus generating a sequence of intermediate states: ). Each individual variable updating of this procedure verifies the detailed balance property 6 , ensuring that the Gibbs sampling procedure does indeed converge towards the sought distribution.</p><formula xml:id="formula_8">(x (t+1) 0 , . . . , x (t+1) i-1 , x (t) i , x (t) i+1 , . . . , x (t) n ) → (x<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2.2">Metropolis-Hastings</head><p>Another approach is the Metropolis-Hastings algorithm family <ref type="bibr" target="#b119">[Met+53;</ref><ref type="bibr" target="#b69">Has70]</ref>. In this context, the sampling of the next value is done in two steps. First, a new candidate value is proposed, by sampling some simple distribution g(x |x (t) ), and it is then randomly accepted or refused though a biased coin flip, whose acceptance probability a(x , x (t) ) depends on the original value and the proposed value. If the sample is refused, the next value is taken as equal to the current value x (t+1) = x (t) .</p><p>The transition probability is thus given by T (x |x) = g(x |x)a(x , x), and a common choice to ensure that the detailed balance property is verified is to choose the acceptance ratio as:</p><formula xml:id="formula_9">a(x , x) = min 1, g(x|x )p(x ) g(x |x)p(x)</formula><p>Note that with this choice, the sampling process only needs to compute probability ratios of p: p(x )/p(x), meaning that it is no necessary to know its normalization constant. In particular when the proposal distribution is symmetric (that is g(x |x) = g(x|x )), then the acceptance process simplifies to an acceptance rate equal to p(x )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>p(x)</head><p>with automatic acceptance if the ratio is greater than one. The proposal is always accepted if it has an higher probability than the previous value, and otherwise is all the more likely to be refused that it has a lower probability according to p.</p><p>An example of symmetric proposal probability g(x |x) would for example be a Normal distribution with some fixed variance. In this context, the Metropolis-Hastings algorithm is similar to a Brownian motion biased towards regions of higher probability for the model p to approximate.</p><p>There is a trade-off in the choice of g: if the proposal distribution has a large variance, and proposes new samples that are far from the current value, these samples are likely to fall in a low-probability region and be rejected. On the other hand, having g proposing only samples close to the current value, while increasing the chance that they are accepted, will cause the Markov Chain to explore the space slowly, requiring to discard more samples between two selected ones for these to be considered independent. 6 If T Gibbs i is the operation that updates the i-th variable, then</p><formula xml:id="formula_10">T Gibbs i (x |x) = p(x i |x-i)δ(x -i = x-i), causing both sides of Equation 1.11 to be equal to p(x i |x-i)p(xi|x-i)δ(x -i = x-i)p(x-i).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.2.3">Langevin Monte-Carlo</head><p>One way of choosing a good proposal distribution g in Metropolis-Hastings is based on the Langevin Monte-Carlo (LMC) algorithm <ref type="bibr" target="#b7">[Bes94;</ref><ref type="bibr" target="#b153">RT96;</ref><ref type="bibr" target="#b150">RR98]</ref>. This method makes use of the available information about p to propose better candidate samples, based on the following stochastic differential equation (SDE), where dW represents the derivative of a Brownian motion:</p><formula xml:id="formula_11">dX = 1 2 ∇ X log p(X)dt + dW (1.12)</formula><p>This SDE has two interesting properties: it converges towards a stationary distribution that is equal to p, and ∇ X log p(X) can be computed without knowing the normalization constant of p. Therefore, it suffices to numerically solve this equation to draw samples according to p. LMC however combines the numerical resolution with a Metropolis-Hastings acceptance step, in order to control for the numerical errors caused by discrete-time solving ofthe SDE.</p><p>The resulting process consists in, for some given time step ∆t, proposing a candidate sample x from a current state x as (with ∼ N (0, 1) drawn after a standard Normal distribution):</p><formula xml:id="formula_12">x = x + 1 2 ∆t∇ x log p(x) + √ ∆t (1.13)</formula><p>This corresponds to sampling x from a Normal distribution of mean x+ 1 2 ∆t∇ x log p(x) and of variance ∆t, making the proposal density easy to compute:</p><formula xml:id="formula_13">g(x |x) = 1 √ 2π∆t exp - 1 2∆t x -x - 1 2 ∆t∇ x log p(x) 2 (1.14)</formula><p>This thus defines a proper Metropolis-Hastings scheme, that takes advantage of gradient information from log p to guide the exploration. As a consequence, it only applies on continuous variables. In general, the LMC enjoys a higher acceptance rate than a mainstream Metropolis Hastings mechanism, despite parameter ∆t being very sensitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.3">Variational inference</head><p>Another approach for approximating distribution p is Variational Inference <ref type="bibr" target="#b165">[SJJ96;</ref><ref type="bibr" target="#b11">Bis+98]</ref>. It consists in reframing this approximation problem into an optimization problem: given some convenient class of distributions Q, find q in Q closest to the target distribution p, where the distance is given by the Kullback-Leibler divergence:</p><formula xml:id="formula_14">q = arg min q∈Q D KL (q p) = arg min q E x∼q log q(x) p(x) (1.15)</formula><p>In the particular case where p is sought as a conditional distribution of z given some other variables x, i.e. the goal is to approximate p(z|x), it takes its most known form<ref type="foot" target="#foot_7">foot_7</ref> :</p><formula xml:id="formula_15">q = arg max q∈Q H(q) + E z∼q log p(z, x) (1.16)</formula><p>A main challenge in Variational Inference is the choice of the distribution class Q, sufficiently expressive to yield a good approximation of the target distribution while permitting its efficient optimization.</p><p>Variational Inference is at the core of the presented research, and is presented and discussed in more detail in the following chapters, notably in Section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Training from data</head><p>Informally, the question of learning a graphical model from data can be formulated as: given some dataset D ∈ X N , find a graphical model p that best matches this dataset. This formulation leaves several questions unanswered. How to measure how well does a model p match a dataset? Is the underlying optimization problem a parametric one (find the parameters of a know graph) or a non-parametric one (find the graphical structure as well) ? Can the distribution involve variables that are not observed in the dataset, referred to as hidden variables?</p><p>The case where the distribution involves hidden variables, at the core of this manuscript, is considered in next chapters. In the remainder of this chapter, only observed variables are considered.</p><p>When learning probabilistic models, it is most often convenient to parameterize the search space with a vector of parameters, traditionally noted θ, concatenating the different vectors of parameters involved in the different elements of the model (the conditional distributions of a Bayesian network or the potentials of a Markov network). Therefore all elements formally depend on the same θ, although each term in the learning criterion only depends on a sub-vector of θ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1">Maximum Likelihood training of a graphical model</head><p>One natural criterion for evaluating the quality of a graphical model on data is to measure the likelihood this model assigns to the dataset p(D). Given some model class C, the goal thus becomes to find a model p assigning the highest possible probability to the data:</p><formula xml:id="formula_16">p = arg max p∈C p(D)</formula><p>(1.17)</p><p>Under the assumption of independent and identically distributed samples (iid), one has p(D) = x∈D p(x), making p(D) very small for large D. For numerical stability and general convenience, it is thus customary to instead consider the negative log-likelihood (NLL) of the data:</p><formula xml:id="formula_17">p = arg min p∈C -log p(D) = arg min p∈C x∈D -log p(x) (1.18)</formula><p>This can be reformulated as an expectation on the dataset:</p><formula xml:id="formula_18">p = arg min p∈C E x∈D -log p(x) (1.19)</formula><p>Along this line, this formulation provides a justification for maximum likelihood training: in the large sample limit, the empirical expectation becomes the expectation w.r.t. the underlying distribution generating the dataset. Equation 1.19 then becomes equivalent to seeking the distribution p that minimizes the cross-entropy from p D to p, which is reached by p = p D . Accordingly, whenever sufficient data is available, maximum likelihood optimization can be used for fitting the parameters of the graphical model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1.1">Maximum Likelihood for Bayesian networks</head><p>In the Bayesian Network framework, maximum likelihood optimization can conveniently be applied, using the distribution factorization (Equation 1.1):</p><formula xml:id="formula_19">E x∈D -log p(x) = i E x∈D -log p(x i |π(X i )) (1.20)</formula><p>Each node/variable of a Bayesian Network can thus be trained independently, only requiring to access the values of the variable and its parents. On large Bayesian Networks, this makes it possible to parallelize the training procedure, with significant computational gains on sparse graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1.2">Maximum Likelihood for Markov Models</head><p>Markov Models do not decompose as nicely. From Equation 1.8, it comes:</p><formula xml:id="formula_20">E x∈D -log p(x) = E x∈D E(x) + log Z = E x∈D C f C (x C ) + log Z (1.21)</formula><p>Energy terms f C do separate from one another, but remain coupled through the normalization constant Z, which depends on all the f C .</p><p>While the normalization constant can be omitted in inference tasks, it is an integral part of the training process, and it is necessary to deal with it. Cases where this normalization constant can be explicitly computed are rare. In some cases however, the model can be trained without explicitly computing Z.</p><p>Let parametric model p θ be defined by the energy function E(x; θ) with θ ∈ R M , this model can be trained by gradient descent; the trick is that we can compute the full gradient of the NLL with regards to θ without computing the value of Z: simple algebraic manipulations yield ∇ θ log Z = -Ex∼p θ ∇ θ E(x; θ), and finally the full gradient:</p><formula xml:id="formula_21">∇ θ -log p θ (D) = E x∈D ∇ θ E(x; θ) -E x∼p θ ∇ θ E(x; θ) (1.22)</formula><p>Although the second expectation cannot in general be exactly computed, it can be empirically approximated using the inference methods developed in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.2">Bayesian regularization and Maximium A-Posteriori</head><p>The Maximum Likelihood method is well founded under the assumption of a very large amount of data, that rarely holds in practice. In this context, one can turn to Bayesian inference, learning a probability distribution over parameters θ to account for the uncertainty due to the lack of data. This is done based on Bayes Theorem: P(θ|D) = P(D|θ)P(θ) P(D) (1.23) P(θ) is a prior distribution over the parameters and assumed given as a model hypothesis. P(D|θ) = p θ (D) the likelihood of the data according to the model of parameters θ. Computing the full posterior distribution P(θ|D) is in general intractable, in particular due to the normalization factor P(D). One thus commonly resorts to only finding its optimal value, after the Maximum A-Posteriori (MAP) procedure:</p><formula xml:id="formula_22">θ = arg max θ P(θ|D) (1.24)</formula><p>In NLL terms, it comes:</p><formula xml:id="formula_23">θ = arg min θ [-log p θ (D) -log P(θ)] (1.25)</formula><p>MAP training is thus very similar to Maximum Likelihood, with the addition of thelog P(θ) term in the optimization procedure, acting as a regularizer. Under the iid assumption, dividing Equation 1.25 by the size N of the dataset, it comes:</p><formula xml:id="formula_24">θ = arg min θ E x∈D [-log p θ (x)] - 1 N log P(θ) (1.26)</formula><p>This shows how the prior term impact naturally decreases as the amount of data increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.3">Structure learning</head><p>There exists a large body of work devoted to learning the structure of graphical model. refSurvey on learning GM structure As this issue is outside the scope of the presented work, only an overview of the main approaches designed for BN structure learning will be presented, used as an inspiration for structure learning of Deep Learning based models in Section 4.3.</p><p>The goal is to learn both the graph structure G and its parameters given a dataset D. In a fully Bayesian perspective, we are seeking the posterior P(G|D) or a workable estimate of its mode. Bayes' Theorem decomposes this posterior as a prior over the graphs P(G) and a likelihood term P(D|G), which can be decomposed as an integral over θ G the parameters of the graphical model defined by G:</p><formula xml:id="formula_25">P(D|G) = θ G P(D|θ G , G)P(θ G |G) dθ G (1.27)</formula><p>In order to learn G, some scoring measures are designed and used as proxies for this likelihood term (the prior is supposed to be given, as problem dependent). The main three scoring measures are: the Bayesian Information Criterion, the Akaike Information Criterion, and the Bayesian Dirichlet algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian Information Criterion</head><p>The Bayesian Information Criterion (BIC) <ref type="bibr" target="#b162">[Sch78]</ref>, is an asymptotic approximation of log P(D|G) in the large sample limit. Let k G be the number of learnable parameters in the model induced by G, the BIC is formulated as:</p><formula xml:id="formula_26">BIC(G) = max θ G [log P(D|θ G , G)] - 1 2 k G log |D| (1.28)</formula><p>It is the optimal log-likelihood reached by the model, with a penalization proportional to the number of parameters, and logarithmically growing with the dataset size. The fact that this score does not depend on the exact form of the prior corresponds to the large sample limit assumption. Note also that the likelihood of the dataset grows as O(|D|); the likelihood term dominates on very large datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Akaike Information Criterion</head><p>The Akaike Information Criterion (AIC) <ref type="bibr" target="#b1">[Aka74]</ref> is constructed on information theoretic arguments, aimed to find a model achieving the minimal information loss w.r.t. the real distribution.</p><p>The information loss is measured with the Kullbak-Leibler divergence from P(D|G) to P(D): D KL (P(D) P(D|G)). Like BIC, the AIC considers an approximation in the large sample limit:</p><formula xml:id="formula_27">AIC(G) = max θ G [log P(D|θ G , G)] -k G (1.29)</formula><p>A main difference compared to BIC is that the penalization does not depend on the dataset size. An extensive comparison of the strengths and weaknesses of both methods is given in <ref type="bibr" target="#b4">[BA98;</ref><ref type="bibr" target="#b180">Yan05;</ref><ref type="bibr" target="#b174">Vri12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian Dirichlet</head><p>The Bayesian Dirichlet method <ref type="bibr" target="#b23">[CH92]</ref> focuses on Bayesian Networks with discrete variables. In this case all sub-likelihoods p θ (x i |π(X i )) are categorical distributions, and admit a Dirichlet distribution as conjugate prior. If such a prior is chosen over the parameters, the whole likelihood factors and the graph likelihood P(D|G) can be computed analytically.</p><p>The question of how to efficiently explore the space of potential graphs, and find the graph with the best score is known to be NP-hard <ref type="bibr" target="#b27">[CHM04]</ref>, but several approximate methods give good results [SM06; Jaa+10; CJ11].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Summary</head><p>This chapter presented the Probabilistic Graphical Models framework, focusing on the Bayesian Networks at the core of the presented work. Graphical models allow one to decompose the relations between variables in a model into a sparse set of local dependencies, where each variable only directly depends on a few others. This both enables a compact representation of the model, and makes it possible to locally reason about them to some extent.</p><p>When the goal is to answer queries, e.g. computing conditional distributions in the form P (Y |X) for some subset Y of variables, such models usually require the non-trivial marginalization of some variables. Several algorithms take advantage of the graphical structure to answer the query without needing to produce the full joint distribution, such as the Variable Elimination Algorithm or the Belief propagation Algorithm. Another approach is the use of Markov Chain Monte-Carlo methods to directly produce approximate samples from the sought distribution.</p><p>When the goal is to learn graphical models from datasets, one must distinguish the building of the graph structure itself (usually tackled using complexity minimization) and the learning of its parameters. In the last case, the main approaches rely on Maximum Likelihood, achieving the (approximate) Bayesian inference of the parameters of the model given its structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Latent variables as a modeling tool</head><p>The design of a graphical model is generally driven by our a priori knowledge about the problem at hand, implying that the model will generally be designed based on epistemic and computational considerations. Epistemic information informs model design by mapping variables to interpretable quantities from the real-world process under study. Computational considerations incline to retain structures that can easily be manipulated by our current algorithms and computers, while remaining expressive enough to represent the data. Model design must find some trade-off between both types of considerations, and this might lead to include in the model variables that don not map to any observed data.</p><p>In this section we shall explore the use of two types of latent variables: interpretable ones and abstract ones. 29</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Interpretability</head><p>One immediate reason why one would integrate an interpretable latent variable in a graphical model is if this variable represents a quantity of interest, to be predicted from the data. In this situation the structure of the model is generally based on strong epistemic considerations.</p><p>Similarly, unobserved quantities are not rare in scientific models<ref type="foot" target="#foot_8">foot_8</ref> , and many of these models can be studied though the lens of graphical models.</p><p>In this context, observed and latent variables are generally related in known ways. For instance, in a Bayesian Network, the distribution of an observed variable conditionally to a latent one might be given a priori; or at least its structure might be known and depend on a few parameters. For instance, the gravitational law in Physics specifies how the acceleration depends on the mass of a system, via the gravity constant.</p><p>In many other cases, latent variables are interpretable by construction. Taking for example Latent Dirichlet Allocation for modeling text documents by linking them to topics via their individual words. Each topic k is associated to a latent variable φ k representing the distribution of words associated to it, and each document i is associated to a latent variable θ i representing the distribution of topics associated to it. Then within a document, each word j is associated to a latent variable z i,j representing its topic and an observed variable w i,j representing the word itself. From this description the sampling process is derived as follows. Each topic k has its word distribution sampled from p(φ k ). The topic distribution of document i is sampled from p(θ i ). Then for each word, the topic of that word is sampled from p(z i,j |θ i ), and finally the word itself is sampled following p(w i,j |φ k=z i,j ), yielding the factorization of the whole model and its graphical representation (Figure <ref type="figure" target="#fig_74">2</ref>.1): We generally have an a priori understanding of how an interpretable latent variable should behave, either from domain knowledge, theoretical analysis, or preliminary analysis of the data. This understanding can be leveraged to monitor the behavior of the model and to help training it, depending on the context; for instance (non exhaustive list) the inference algorithm can be adapted to avoid numerical instability if the range of a variable is known in advance, the appropriate number of mixtures in a model can be pre-estimated by eyeballing it from a plot of the data, or appropriate sampling methods can be used depending on the expected rarity of the relevant values.</p><formula xml:id="formula_28">p({φ k } k , {θ i } i , {z i,j } i,j , {w i,j } i,j ) = i,k   p(θ i )p(φ k ) j p(z i,j |θ i )p(w i,j |φ k=z i,j )   (2.1) W i,j Z i,j θ i φ k ∀j ∀j ∀k</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Abstract variables for expressiveness</head><p>In some situations, one might want to consider latent variables with no a priori interpretation. Such variables, more loosely coupled with other variables, often serve to drastically increase the expressiveness of a model while keeping its computational complexity controlled.</p><p>To illustrate this principle, let us consider a finite Gaussian Mixture. Each component i is defined by a mean µ i and a variance σ<ref type="foot" target="#foot_9">foot_9</ref> i . The family of all Gaussian mixtures of a given size is significantly more expressive than a single Gaussian distribution while the computational cost associated with it remains very reasonable, proportional to the number of components. Even when the information of which component a given datapoint belongs to is not of interest, using a mixture can be a relevant way of increasing the space of distributions that the model can represent  This idea can be generalized though the principle of marginalization. Defining a joint distribution p(x, z) over an observed variable x and a latent variable z might yield a complex marginal distribution 3 p(x) = z p(x, z)dz. Such an approach usually involves a latent distribution over the marginalized variable p(z) and a family of simple conditional distributions p(x|z): a graphical model with a latent variable. In this case, latent variable z is abstract: it does not have any intrinsic meaning, and its only role is to be marginalized out to increase the power of the model over the variable of interest x while keeping the computational cost low. One can then think of p(x) as a mixture model with an infinite (and even continuous) number of components, indexed by z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training challenges of Latent Variable Models</head><p>The introduction of latent variables in a graphical model has a significant impact on the training procedures: latent variables are not observed, and appropriate losses must thus be considered. A common approach is based on marginalization, maximizing the likelihood of the observed data according to the (marginalized) model. The marginalization procedure is however generally nontrivial, and poses additional questions in the case of abstract latent variables. By convention, observed variables (respectively latent variables) are noted x i (resp. z j ) in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Likelihood and marginalization</head><p>The graphical model specifies the joint likelihood over all variables p θ (x 1 , . . . , x n , z 1 , . . . , z k ). Training this model relies on estimating the likelihood p θ (x 1 , . . . , x n ) of the data over the observed variables; this estimation is at the core of all training procedures, either based on maximum likelihood, MAP, or fully Bayesian training. The likelihood over observed variables is estimated by marginalization over the latent ones:</p><formula xml:id="formula_29">p θ (x 1 , . . . , x n ) = z 1 ,...,z k p θ (x 1 , . . . , x n , z 1 , . . . , z k )dz 1 . . . dz k (2.2)</formula><p>In some cases, this marginalization can be computed exactly, e.g. in a finite mixture, and the training procedure de scribed in Section 1.3 directly applies. In most cases however, such computation is either intractable or prohibitively expensive, and approximate methods are needed.</p><p>In the case of a graphical model parameterized by continuous variables, the gradient of the likelihood can be estimated by Monte-Carlo sampling, by using the following identity (where x thereafter stands for the set of all observed variables, and z the set of all latent ones):</p><formula xml:id="formula_30">∇ θ log p θ (x) = E z∼p θ (z|x) ∇ θ log p θ (x, z)</formula><p>(2.3) its observed variables. Typically in the context of a mixture model, any permutation of the mixture components yields an equivalent model. This non-identifiability raises difficulties of different types. With respect to the training step, if there exist multiple parameters θ yielding the same marginal likelihood p θ (x), then the underlying optimization problem is not well-defined, admitting numerous local optima and offering less guarantees depending on the optimization algorithm, e.g. gradient ascent or estimation of a Bayesian posterior over the parameters<ref type="foot" target="#foot_11">foot_11</ref> . With respect to the interpretation of the results, different models are learned in different runs, hindering the interpretation of the latent variables. While the trained model might accurately represent the observation density p θ (x), it offers little insight into the underlying generative process.</p><p>Some partial identifiability property can be enforced through setting constraints on either the relationships between observed and latent variables, or the latent distribution p θ (z). Such constraints can be guided by a priori knowledge on the problem, or by the desired properties of the learned latent representation. Both approaches, at the core of the thesis, are investigated in depth in respectively Part II and Part III.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Variational Inference</head><p>Variational inference is an umbrella for a family of approaches, tackling the approximation of probability distribution through solving an optimization problem. In its most general form, it can be formulated as finding the distribution within the selected distribution space, that is closest to the target distribution in terms of the Kullback-Leibler divergence<ref type="foot" target="#foot_12">foot_12</ref> :</p><formula xml:id="formula_31">q = arg min q∈Q D KL (q p) = arg min q∈Q E z∼q log q(z) p(z) (2.4)</formula><p>A significant advantage of this formulation is that the target distribution p does not need to be sampled, nor does it need to be normalized. This makes the approach particularly applicable to graphical models, in particular in the context of conditional queries where normalization raises critical difficulties.</p><p>Given a model p(x, z), with x the observed variables and z the latent ones. Assuming a given value of x, the goal is to approximate the conditional distribution p(z|x) with q(z). Minimizing the KL divergence from it to the approximating distribution q(z) yields the following optimization problem (constant terms relative to z omitted):</p><formula xml:id="formula_32">q x = arg max q∈Q H(q) + E z∼q log p(x, z) (2.5)</formula><p>Accordingly, the optimization of q reflects a trade-off between maximizing the likelihood of the model log p(x, z), and maximizing the entropy H(q). For any given x, the global optimum is reached for q x (z) = p(z|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">The Evidence Lower Bound</head><p>Equation 2.5 can be reformulated to express nice insights into the structure of the sought solution. Expanding the KL divergence between q(z) and p(z|x) gives:</p><formula xml:id="formula_33">D KL (q x (z) p(z|x)) = E z∼qx log q x (z) p(z|x) (2.6) = E z∼qx log q x (z)p(x) p(x, z) (2.7) = E z∼qx log q x (z) p(x, z) + log p(x) (2.8)</formula><p>This can be reformulated as:</p><formula xml:id="formula_34">log p(x) = E z∼qx log p(x, z) q x (z) ELBO +D KL (q x (z) p(z|x)) (2.9)</formula><p>As the KL-divergence is always positive, the first term of the right-hand side of Equation 2.9 sets a lower bound for the log-probability the model assigns to the observed value x, log p(x). This log-probability is also called the evidence of the model, hence giving the name Evidence Lower Bound (ELBO) [BG02; GHB12; KW14; RMW14]. Optimizing the ELBO thus supports both approximations of p(z|x) and log p(x), for any given observation x.</p><p>The ELBO can be written in three different ways:</p><formula xml:id="formula_35">E z∼qx log p(x, z) q x (z) = H(q x ) + E z∼qx log p(z, x) = E z∼qx log p(x|z) -D KL (q x (z) p(z)))</formula><p>(2.10) Depending on the context and which terms can be exactly computed, or approximated more efficiently, one formulation can be more convenient than the others. Most approaches in the literature thus focus on one of these three forms.</p><p>Overall, the ELBO maximization defines a training objective for the graphical model p [BG06; RGB14]: once decently maximized with regard to q, the value of the ELBO can be used as a estimation of the model evidence log p(x), and used as an optimization objective. When considering some training dataset D, one associates to each sample x a distribution q x (z), optimized to approximate the conditional distribution p(z|x). The joint ELBO then reads:</p><formula xml:id="formula_36">log p(D) = x∈D log p(x) ≥ x∈D E z∼qx log p(x, z) q x (z) (2.11)</formula><p>Maximizing the ELBO regarding both p and the set {q x } x∈D achieves the maximum likelihood training of model p. The key issues are the selection of model class Q containing the q x , and the optimization methods used to find q x and p.</p><p>The above sum can also be maximized as an expectation over the dataset, as done in Section 1.3.1:</p><formula xml:id="formula_37">1 |D| log p(D) = E x∈D log p(x) ≥ E x∈D E z∼qx log p(x, z) q x (z) (2.12)</formula><p>When considering an iterative optimization approach, e.g. based on gradient descent, the expectation over the dataset can be approximated by Monte-Carlo, considering a random subsample (mini-batch) instead of the whole dataset. Only the q x associated with the sampled datapoints are then computed in each iteration, drastically speeding-up the training of the model on large datasets <ref type="bibr" target="#b77">[Hof+13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Mean-Field approximation for posteriors</head><p>The simplest and most convenient method, known as mean field approximation <ref type="bibr" target="#b165">[SJJ96]</ref>, considers q as the product of distributions of a single latent variable q(z) = j q j (z j ). Each component q j is sought as a simple (e.g. Gaussian or categorical) distribution, depending on the type of the latent variable. In this case, the entropy term of the ELBO (Equation 2.10) reads as H(q) = j H(q j ), making its analytical expression generally possible. Likewise, the mean field approximation setting easily supports the Monte-Carlo estimation of Ez∼q log p(z, x) in general.</p><p>The main and significant limitation of mean field approximation is that it can only efficiently fit mono-modal distributions: only a single mode of the sought distribution is decently approximated.<ref type="foot" target="#foot_13">foot_13</ref> . When considering multi-modal p(z|x), one thus rather models q as a mixture of factorized distributions[Bis+98; GHB12], still supporting an easy sampling and computation of log q(z). While entropy H(q) is no longer defined in closed form, its Monte-Carlo approximation still applies.</p><p>The particular case of continuous (Gaussian) distributions has been further explored. On the one hand, factorized Gaussian models, with diagonal covariance matrix, are often too poor and do not support correlations among latent variables. On the other hand, multivariate Gaussian distributions have a quadratic complexity in the number of latent variables. A trade-off is offered by considering low-rank covariance matrices <ref type="bibr" target="#b128">[ONS18]</ref>, enabling to capture the main correlations at a reasonable cost.</p><p>Note that Gaussian distributions offer many possibilities for mixture approximations of the posterior thanks to their universal approximation property. Adaptive mixture constructions have been proposed along this line, dynamically adding components to the mixture as needed to improve the approximation [Guo+17; MFA17].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Flexible posterior approximation using Normalizing Flows</head><p>In order to construct approximations q(z) to the conditional distribution p(z|x), a quite different approach is based on the so-called Normalizing Flows <ref type="bibr" target="#b145">[RM15]</ref>, where q(z) is based on a standard distribution (e.g. centered Gaussian) π, and z is obtained by applying some transformation z = f ( ), with π a fixed distribution of noise.</p><p>The optimization problem thus consists in finding an appropriate f . In order to compute the density q(z), f is required to be invertible. Under this assumption, q(z) can be computed in close form, involving the determinant of the Jacobian matrix ∇ f of f :</p><formula xml:id="formula_38">q(z) = π( )|∇ f | -1 (2.13)</formula><p>This formula and the choice of a class of functions for which the determinant can easily be computed is at the core of Normalizing Flows (NF). Due to the invertibility constraint, NF only apply to continuous variables. In the NF framework, the ELBO reads:</p><formula xml:id="formula_39">log p(x) ≥ H(π) + E z∼q log |∇ f | + log p(x, z) (2.14)</formula><p>Within this generic NF framework, a number of approaches have been developed, using carefully structured artificial neural networks (e.g. based on autoregressive principles) to model the function f [RM15; DKB15; LW17; Kin+17; Ber+19; Dur+19]. These approaches offer versatile approximations q, well-suited to models with abstract continuous latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Model training with Expectation-Maximization</head><p>The famed Expectation-Maximization (EM) algorithm is an iterative algorithm, used to train a parametric model p θ by alternating an "Expectation" step and a "Maximization" step <ref type="bibr" target="#b39">[DLR77]</ref>. As will be seen in Section 2.4.2, it is closely related to ELBO training.</p><p>Let θ (t) denote the parameter vector of the model at step t. The Expectation step relies on a score function L, which assigns a score to every possible θ in the parameter space:</p><formula xml:id="formula_40">L θ; θ (t) = x∈D   E z∼p θ (t) (z|x) log p θ (x, z)   (2.15)</formula><p>Note that in particular L θ (t) ; θ (t) = log p θ (t) (D) is the evidence of the model for the vector of parameters θ (t) .</p><p>Then the Maximization step determines the value of θ maximizing L, and sets θ (t+1) to this optimal value. θ (t+1) = arg max θ L θ; θ (t)  (2.16)</p><p>The Expectation-Maximization scheme is iterated until convergence of θ t .</p><p>The justification of the algorithm goes as follows. Ez∼q log p(x, z) is maximal w.r.t. p when q(z) = p(z|x). Therefore, the function η → L θ (t+1) ; η reaches its maximum for η = θ (t+1) . From the definition of the Maximization step, it then comes:</p><formula xml:id="formula_41">log p θ (t+1) (D) = L θ (t+1) ; θ (t+1)</formula><p>(2.17)</p><formula xml:id="formula_42">≥ L θ (t+1) ; θ (t) (2.18) ≥ L θ (t) ; θ (t) (2.19) log p θ (t+1) (D) ≥ log p θ (t) (D) (2.20)</formula><p>In other words, the model evidence (the log-likelihood of the data) monotonically increases in each EM iteration. The algorithm thus is guaranteed to converge toward a local optimum, except if the evidence can diverge towards +∞; in this latter case, the algorithm is prone to severe overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Exact inference in Gaussian Mixture Models</head><p>EM classically considers Gaussian Mixture Models as model space, as this space allows analytic solving of both expectation and maximization steps.</p><p>Let us consider a mixture model of K multivariate Gaussian distributions, represented as a graphical model with two variables: I the mixture index, and X the observed value. The model thus factors as p θ (x, i) = p θ (x|i)p θ (i). The latent distribution is a categorical one with K values. Let α i denote its parameters, that is,</p><formula xml:id="formula_43">p θ (t) (i) = α (t)</formula><p>i . The observation distribution is a multivariate Gaussian of mean µ i and covariance matrix Σ i :</p><formula xml:id="formula_44">p θ (t) (x|i) = N (x; µ (t) i , Σ<label>(t)</label></formula><p>i ). The overall parameter vector is thus composed of the K weights of the latent distribution, K mean vectors, and</p><formula xml:id="formula_45">K covariance matrices: θ = ({α i } K i=1 , {µ i } K i=1 , {Σ i } K i=1</formula><p>). In the expectation step, p θ (t) (i|x) is computed for each datapoint, using Bayes Theorem:</p><formula xml:id="formula_46">p θ (t) (i|x) = p θ (t) (x|i)p θ (t) (i) p θ (t) (x) = α (t) i N (x; µ (t) i , Σ (t) i ) K j=1 α (t) j N (x; µ (t) j , Σ (t) j ) = w (t) i (x) (2.21)</formula><p>The objective function of the maximization step reads:</p><formula xml:id="formula_47">L θ; θ (t) = E x∈D K i=1 w (t) i (x) log α i + log N (x; µ i , Σ i ) (2.22)</formula><p>Note that, thanks to the factorization of the model, parameters α, and each (µ i , Σ i ) pair can be optimized independently: the latent parameter α i is set to the mass ratio of the posteriors for the i-th cluster across the dataset and each Gaussian distribution N (µ i , Σ i ) is fitted by maximum likelihood to the dataset with importance weights w</p><formula xml:id="formula_48">(t) i (x): α (t+1) i = E x∈D w (t) i (x) (2.23) µ (t+1) i = E x∈D w (t) i (x) x (2.24) Σ (t+1) i = E x∈D w (t) i (x)(x -µ (t+1) i )(x -µ (t+1) i ) T (2.25)</formula><p>Along these equations, the algorithm iteratively computes the |D| × K matrix of weights w (t) i (x), and updates the parameters α, µ, Σ, until convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Approximate inference with Variational EM</head><p>In some cases, the conditional distribution p θ (t) (z|x) cannot be exactly computed, preventing the objective function L from being computed as well. In this context, the EM algorithm can be reframed using the ELBO, defining a Variational EM Algorithm. Note that a number of EM variants have been referred to as "Variational EM"; in the following, Variational EM is meant as a generic variational approach based on the EM principles.</p><p>As described in Section 2.3.1, the family Q (t) made of all q (t)</p><p>x , variational approximation of p θ (t) (z|x) for each datapoint x, is maintained.</p><p>Given the family Q (t) and the model parameters θ (t) , the ELBO is used to lower bound the model evidence:</p><formula xml:id="formula_49">log p θ (t) (D) ≥ x∈D E z∼q (t) x log p θ (t) (x, z) q (t) x (z) = L ELBO (Q (t) ; θ (t) ) (2.26)</formula><p>The two steps of the EM algorithm then naturally appear from this formulation: the Expectation step maximizes L ELBO with regard to Q, and the Maximization step optimizes it with regard to θ:</p><formula xml:id="formula_50">Q (t+1) = arg max Q L ELBO (Q; θ (t) ) ; θ (t+1) = arg max θ L ELBO (Q (t+1) ; θ) (2.27)</formula><p>This formulation makes it clear that the ELBO monotonically increases as the algorithm unfolds. Variational EM thus appears as a special case of ELBO training, alternatively optimizing the variational approximations q x and the model p θ .</p><p>When the exact conditional distribution of the latent variables can be exactly computed, the ELBO boils down to the model evidence, and Variational EM coincides with EM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Summary</head><p>This chapter describes why and how to use latent variables in graphical models. Latent variables, not observed in the data, are meant to either reflect hidden factors (considering the phenomenon at hand as a partially observed one) or increase the expressive power of the model while keeping its computational cost low.</p><p>Unless latent variables can be analytically marginalized to compute the model evidence over the dataset log p θ (D), one resorts to estimating it using the Evidence Lower Bound (ELBO) with a family of auxiliary inference distributions {q x } x∈D (Equation 2.11). Optimizing the ELBO with regards to both p θ and {q x } x∈D allows one to both train the generative model by likelihood optimization, and build an approximation of the posterior distribution of the latent variables given the observed ones, as the set {q x } x∈D .</p><p>Notably, the Expectation-Maximization (EM) algorithm can be seen as a special case of this principle, where the model and the inference distributions are trained iteratively, maximizing the ELBO with regards to either one alternatively. The mainstream EM algorithm corresponds to the case where both maximization steps can be solved analytically. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Variational Auto-Encoder</head><p>The Variational Auto-Encoder (VAE) [RMW14; KW14] is an instantiates the simplest LVM structure: an observed variable X and a latent variable Z, linked as a Bayesian Network Z → X. The model thus factors as p θ (x, z) = p θ (x|z)p θ (z). Deep learning is leveraged to implement p θ (x|z) (Section 1.1.1): given a parametric family P ω (x) of distributions (e.g. Gaussian), a function f θ : z → ω is used to map the latent variable z onto the parameters ω of the chosen family, as illustrated by Figure <ref type="figure">3</ref>.1. It results that p θ (x|z) = P ω=f θ (z) (x). The function f θ is implemented using an artificial neural network and trained by maximizing the ELBO. The main two ideas used in the VAE concern the construction of the inference model q which approximates p θ (z|x): Amortized Inference and the Reparameterization Trick.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Amortized Inference</head><p>While Bayesian inference is in general a hard and computationally expensive problem, it is believed that human cognition performs it (at least approximately) routinely with much efficiency. Human beings generally face and solve many instances of very similar problems (such as recognizing an object in a visual scene). Under the assumption that similar problems have similar solutions, results of past inferences can generally be re-used to solve future ones more efficiently. This action of re-using past inference is referred to as amortized inference, as the cost is the initial inferences is amortized by its subsequent reuse. Some evidence has been presented that human beings do actually rely on such re-use, at least to some extent <ref type="bibr" target="#b57">[GG14]</ref>.</p><p>The general principle of amortized inference in a Bayesian Netowrk setting consists in analyzing the graphical model beforehand and inverting it, thus making it possible to perform quick approximate inference queries using the resulting inverted graph <ref type="bibr" target="#b169">[STG13]</ref>. The more queries are answered using the inverted graph, the more the inverting cost is amortized.</p><p>In the VAE setting, the assumption translates to considering that p θ (z|x) varies smoothly with x. In other words, letting x and x denote two similar observed instances, the associated conditional distributions p θ (z|x) and p θ (z|x ) should also be similar to each other. This prompts the idea of jointly learning all q x (z) approximations. Like for p θ (x|z), the conditional distribution p θ (z|x) is approximated by choosing a parametric family and training a neural network mapping x to the parameters of the considered family. By opposition to the generative model, this construct is traditionally named the inference model, and noted q φ (z|x), with φ the trainable parameters of the associated neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">The Reparametrization Trick</head><p>The Reparameterization Trick is a method to compute the gradient of an expectation with respect to the parameters of the distribution: ∇ φ Ez∼q φ g(z), as appears in the ELBO. In order to train the inference model using stochastic gradient descent (as usual for neural networks), then this gradient needs to be computed. A well known method to do so is the so-called Log-Trick, which relies on the following identity:</p><formula xml:id="formula_51">∇ φ E z∼q φ g(z) = E z∼q φ g(z)∇ φ log q φ (z) (3.1)</formula><p>This identity however leads to an estimation of the gradient with very high variance<ref type="foot" target="#foot_14">foot_14</ref> , making it a poor candidate to do Monte-Carlo estimation. The Reparametrization Trick <ref type="bibr" target="#b98">[KW14]</ref> instead tries to express the distribution q φ as some noise sampled from a fixed base distribution ∼ π, and then transformed by a function z = h φ ( ). This is similar to Normalizing Flows (Section 2.3.3), which were inspired from it. Accordingly, the expectation is expressed over the base distribution π, which does not depend on the parameters φ, allowing the gradient operator to commute with it:</p><formula xml:id="formula_52">∇ φ E z∼q φ g(z) = ∇ φ E ∼π g(h φ ( )) = E ∼π ∇ φ g(h φ ( )) (3.2)</formula><p>This estimator has much better variance characteristics <ref type="bibr" target="#b178">[Xu+19]</ref>, and can in practice be efficiently implemented in deep learning software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Link with Auto-Encoders</head><p>Combining the above, the VAE proceeds as illustrated on Figure <ref type="figure">3</ref>.2: first, the datapoint x is processed by the inference network, predicting the inference distribution q φ (z|x) from which a latent sample z is sampled. This sample is then processed by the generative network to compute the evidence log p θ (x|z). Both networks are jointly trained by stochastic gradient descent to maximize the ELBO, where the expectation over z is often approximated by a single sample of q φ (z|x):</p><formula xml:id="formula_53">ELBO(θ, φ) = E x∈D        E z∼q φ (z|x) log p θ (x|z) Reconstruction loss -D KL (q φ (z|x) p θ (z)) Latent regularization        (3.3)</formula><p>The inference and generative networks can respectively be viewed as probabilistic encoder and decoder. Along this line, the ELBO decomposes into a reconstruction loss and a latent regularization term (Equation 3.3). The training process aims to trading-off the reconstruction loss and the compression of the latent information, as measured by the D KL term, akin a regularized auto-encoder. This parallel explains the origin of the VAE name.</p><p>Gaussian VAE VAEs classically use Gaussians as base distributions, with p θ (z) set to N (0; I), and p θ (x, z) set to N (dec θ (x), σ 2 ), with dec θ the output of the decoder network; σ is a hyperparameter of the model. Likewise, the inference model q φ (z|x) is classically implemented as N (µ φ (x), σ 2 φ (x), with µ φ (x) and diagonal covariance</p><p>x Encoder q φ (z|x)</p><formula xml:id="formula_54">Decoder p θ (x|z) z p θ (z) D KL (q φ (z|x) p θ (z)) log p θ (x|z)</formula><p>Figure <ref type="figure">3</ref>.2: VAE architecture: the encoder (resp. decoder) module is a neural network taking x (resp z) as input and computing the parameters of distribution q φ (z|x) (resp., p θ (x|z)). Dashed rectangles represent probability distributions and dotted arrows represent the computation of loss terms. matrix σ 2 φ (x) the output of the encoder network. In this case, the reparameterization trick simply is:</p><formula xml:id="formula_55">z = µ φ (x) + σ φ (x)</formula><p>with ∼ N (0; I) and denoting the element-wise vector product. Likewise, the KL-divergence between q φ (z|x) and p θ (z) can be computed analytically.</p><p>The loss to be minimized is then the opposite of the ELBO, yielding the following loss (where j runs across the dimensions of the latent variable Z):</p><formula xml:id="formula_56">L(θ, φ) = E x∼D ∼N (0,I)        1 2σ 2 x -dec θ (z) 2 Reconstruction loss + 1 2 K j=1 µ 2 φ,j (x) + σ 2 φ,j (x) -log σ 2 φ,j (x) -1 Latent regularization       </formula><p>(3.4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Advanced latent models</head><p>While Gaussian VAEs are easy to both implement and train, and yield some impressive results <ref type="bibr" target="#b98">[KW14]</ref>, the Gaussiam structure might fail to represent complex distributions, e.g., images: the too simple approximation of the conditional latent can make the ELBO too loose a bound, in which case the model is susceptible to generate non-realistic samples <ref type="bibr" target="#b0">[AB17]</ref>. This limitation raises the question of developing more elaborate representations of the latent distribution. The main two directions explored in the literature to this aim include constructing more powerful representations for q φ (z|x), or learning also p θ (z) to accommodate for the limited expressiveness of q φ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Powerful encoders and complex latent spaces</head><p>This section provides a (non exhaustive) overview of some approaches aimed to designing a more powerful inference model. Note that these approaches are not necessarily incompatible, and can be combined together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conditional Normalizing Flows.</head><p>A powerful framework for inference models is that of the Normalizing Flows (Section 2.3.3): a flexible and powerful approximation q φ (z|x) is obtained via z = f φ ( , x), where f φ is only required to be invertible with regard to . Note that this usage was the initial motivation for the introduction of Normalizing Flows <ref type="bibr" target="#b145">[RM15]</ref>. This formulation drastically increases the expressive power of the inference model, enabling very sharp boundaries in the latent space, as shown by <ref type="bibr" target="#b96">[Kin+17]</ref>, at the expense of some (significant) increase in the number of layers of the encoder network.</p><p>Importance Weighted AE proceeds by replacing the p θ (x,z) q φ (z|x) in the ELBO by an empirical average over k z i samples <ref type="bibr" target="#b10">[BGS16]</ref>:</p><formula xml:id="formula_57">L k = x∈D E (z 1 ,...,z k )∼q φ (•|x) log 1 k k i=1 p θ (x, z i ) q φ (z i |x) (3.5)</formula><p>This new formulation, still a lower-bound of the model evidence log p θ (D), becomes tighter and tighter as k increases, as the sum in the logarithm better estimates p θ (x). Indeed, when k goes to infinity, it comes:</p><formula xml:id="formula_58">lim k→∞ 1 k k i=1 p θ (x, z i ) q φ (z i |x) = E z∼q φ p θ (x, z) q φ (z|x) = z q φ (z|x) p θ (x, z) q φ (z|x) dz = z p θ (x, z) dz = p θ (x)</formula><p>This tighter estimate allows to overcome a poor quality inference model, and increase the quality of the learned model. While the Importance Weighed AE was originally formulated as an alternative lower bound to the ELBO, it has since then been re-interpreted as equivalent to using the classic ELBO with an augmented inference model <ref type="bibr" target="#b32">[CMD17]</ref>: the k samples from q φ (z|x) are aggregated into a single sample from an augmented distribution q EW (z|x), which is closer to the model posterior p θ (z|x).</p><p>MCMC refinement of samples. Noting that neural networks are by construction differentiable, one can compute ∇ z p θ (x|z), opening the door to the use of efficient MCMC methods to directly sample from p θ (z|x). Such Monte-Carlo methods allow an extremely tight evaluation of the ELBO, e.g. using Langevin dynamics <ref type="bibr" target="#b68">[Han+17]</ref>, or using Hamiltonian Monte Carlo to improve the initial proposal of an inference network <ref type="bibr" target="#b22">[CDS18]</ref>.</p><p>Another direction is that of Semi-Amortized VAEs <ref type="bibr" target="#b94">[Kim+18]</ref>, using stochastic variational inference <ref type="bibr" target="#b77">[Hof+13]</ref> to improve the variational parameters of q φ (z|x) predicted by the neural network, rather than working directly on the samples.</p><p>The use of Monte-Carlo methods however comes at a significant computing cost, requiring back-propagation through the neural networks to compute the gradient for every one of the (many) samples.</p><p>Non-euclidean latent spaces. In order to match the complex topology of some datasets, distributions constructed on non-Euclidean spaces have also been proposed recently. The Poincaré VAEs <ref type="bibr" target="#b116">[Mat+19a]</ref> build an hyperbolic latent space with negative curvature, better suited to tree-structured data than a flat Gaussian latent<ref type="foot" target="#foot_15">foot_15</ref> .</p><p>[Fal+19] introduces a general method for transposing distributions defined on an Euclidean space into an arbitrary Lie Group, including the reparametrization trick.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Learned latent distributions</head><p>While above methods might change the structure of the latent space, governing the latent distribution p θ (z), this latent distribution remains fixed during the training. Often called a "prior" in the literature, this distribution is only a prior in the Bayesian sense with regards to the inference of z given x, not with regards to the learning of the model parameters θ. It can be learned just as every other part of the model, and this section presents some of the methods developed to do so.</p><p>A general incentive for learning the latent distribution is to account for some wellseparated modes of the true distribution. If the latent distribution cannot capture several modes (as is the case for Gaussian distributions), this makes it difficult to learn the whole model: One possibility is that the generative network p θ (x|z) learns a quickly varying function, able to separate in the data space values that are close to each other in the latent. This ability requires a significant expressive power from the neural network<ref type="foot" target="#foot_16">foot_16</ref> . Another possibility is that large parts of the latent space with non-zero mass according to p θ (z) be avoided by q φ (z|x), achieving the separation of the data (Figure <ref type="figure">3</ref>.3). This option is the one empirically observed when training Gaussian VAEs from multimodal data. When latent z samples fall in these avoided regions, they yield samples x ∼ p θ (x|z) that are generally unrealistic, illustrating that the ELBO remains loose in this context.</p><p>While the methods described below can in principle be combined with the ones from in the previous section, their combination raises difficulties: learning both q φ (z|x) and p θ (z) as complex distributions often results in training instabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixture-based latent distributions.</head><p>A simpler way to handle multi-modal data is to model p θ (z) as a mixture model. As fitting a mixture model by gradient descent is difficult, more elaborate methods have been considered, e.g., modeling the mixture as part of the graphical model [Dil+17; Don+19] (see next chapter for the use of Deep LVM with several nodes) or adapting the ELBO to directly integrate the mixture latent <ref type="bibr" target="#b67">[Guo+20]</ref>.</p><p>Linking the latent to the inference model. As illustrated by the VampPrior <ref type="bibr" target="#b171">[TW18]</ref>, this approach implicitly defines the latent distribution p(z) from the inference model q φ (z|x), as a mixture of inference predictions from few artificial inputs Figure <ref type="figure">3</ref>.3: Illustration of a possible mismatch in the inference density compared to the latent distribution. The grey background represents the latent density p θ (z), while the red lines represent the inference density q φ (z|x) averaged over the dataset. The inference density is here split in two regions (top and bottom) separated by a low-probability band, which represent two modes in the dataset that the model couldn't join continuously.</p><p>(x 1 , . . . , xK ): p(z) = 1 K i q φ (z|x i ). Learning the latent distribution thus amounts to learning the artificial inputs, which is done by back-propagation through the inference network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implicit latents with an energy model.</head><p>A very versatile approach is to learn the latent distribution through an energy model: learn some function E : Z → R, and implicitly define the distribution as</p><formula xml:id="formula_59">p(z) ∝ exp(-E(z))</formula><p>While this formulation can in principle accommodate most latent structures, it raises two difficulties. Firstly, the latent distribution can hardly be directly sampled, requiring the use of Monte-Carlo methods. Secondly, designing a proper optimization procedure to learn the energy function E is highly non-trivial. Some approaches learn it by estimating the gradient online using Equation 1.22 <ref type="bibr" target="#b134">[Pan+20]</ref>; other approaches fit a posteriori the energy function on a already trained model to fine-tune it <ref type="bibr" target="#b179">[XYA20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discrete latent variables</head><p>All above methods, relying on the reparametrization trick to compute gradients, are limited to continuous latent spaces. However, some datasets are better handled by using discrete structures, raising the issue of whether Deep LVMs can be used with discrete latent variables.</p><p>When considering a small latent domain, the expectation over q φ (z|x) can be easily and exactly computed from the vector of probabilities of the discrete distribution.</p><p>The difficulty arises when considering a large latent domain, e.g. Z = {0, 1} K . In this case, the cost of exactly computing the expectation is prohibitive, being exponential in the dimension K of the latent space. <ref type="foot" target="#foot_17">4</ref>Two main approaches have stood out to tackle the problem of large discrete latent space: the Gumbel-Softmax, and the so-called Discrete VAE.</p><p>Gumbel Softmax This approach relies on the standard Gumbel distribution, whose cumulative distribution function is G(x) = e -e -x . It can be used for approximating a one-hot encoding of a categorical distribution<ref type="foot" target="#foot_18">foot_18</ref>  <ref type="bibr" target="#b87">[JGP17]</ref>.</p><p>Let us consider a categorical distribution defined by the probability vector (π 1 , π 2 , . . . , π K ), and let (g 1 , g 2 , . . . , g k ) be K independent samples from the standard Gumbel distribution. Let vector z be defined by softmax from the vector of coordinates (g i + log π i )/τ , with τ &gt; 0 a hyperparameter of the model:</p><formula xml:id="formula_60">z i = exp ((g i + log π i )/τ ) K j=1 exp ((g j + log π j )/τ ) (3.6)</formula><p>By definition of the softmax, all coordinates of z belong to (0, 1), and they sum to 1. Formally, z converges to a one-hot vector as τ → 0. Further, the distribution of such zs matches a one-hot encoding of samples from the categorical distribution defined by the probabilities π i .</p><p>This property thus supports a continuous approximation of a one-hot-encoded categorical distribution; this continuous approximation can be used with the reparameterization trick to train a VAE <ref type="bibr" target="#b111">[Lor+19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discrete VAE</head><p>The Discrete VAE <ref type="bibr" target="#b148">[Rol17]</ref> and its refinements [Vah+18; VAM18] take a different approach, where the latent space involves a set of K binary variables (z ∈ {0, 1} K ). Each latent coordinate z i is paired with a continuous one ζ i ∈ [0; 1], where z i depends on ζ i after some appropriate fixed distribution p(z i |ζ i ). In the final generative step, x is generated from the continuous vector ζ, as illustrated on Figure <ref type="figure">3</ref>.4.</p><p>The inference model involves the inference distribution q φ (z i = 1|x). Thanks to the fixed dependency among z i and ζ i , q φ (ζ i |x) can be analytically expressed as a function of q φ (z i = 1|x)<ref type="foot" target="#foot_19">foot_19</ref> . The chained dependencies thus allow the gradient to flow and learn q φ through the discrete variable z.</p><p>This discrete structure is combined with a latent distribution p θ (z) learned as a Restricted Boltzmann Machine (Section 1.1.2), in order to capture complex correlations. The encoder and decoder are trained as a regular VAE by optimizing the ELBO and the latent RBM is trained at the same time by maximum likelihood using samples from the encoder q φ (z|x) as a dataset. </p><formula xml:id="formula_61">z 1 z 2 z 3 ζ 1 ζ 2 ζ 3 x (a) Generative model z 1 z 2 z 3 ζ 1 ζ 2 ζ 3 x (b) Inference model</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Impact of the Inference Model</head><p>In general<ref type="foot" target="#foot_20">foot_20</ref> , q φ lies in some selected class of distributions Q. This restriction has an impact on the training dynamics of the model, as it controls the quality of approximation of p θ (z|x), permitted by Q. This impact can be understood as a kind of posterior regularization <ref type="bibr" target="#b54">[Gan+10]</ref>, as analyzed by <ref type="bibr" target="#b164">[Shu+18]</ref>.</p><p>Considering the training ELBO for the whole dataset:</p><formula xml:id="formula_62">ELBO(θ, φ) = x∈D E z∼q φ (z|x) log p θ (x, z) q φ (z|x) = log p θ (D) - x∈D D KL (q φ (z|x) p θ (z|x))</formula><p>(3.7) Let us introduce for any distribution r(z) its "bias" relative to the class Q as:</p><formula xml:id="formula_63">D Q (r) = min q∈Q D KL (q(z) r(z)) (3.8)</formula><p>By training the inference model until ELBO-optimality (reaching the optimal parameters φ (θ)) then for all x, the term D KL (q φ (z|x) p θ (z|x)) is minimized and thus equal to D Q (p θ (•|x)). The ELBO can thus be reformulated as:</p><formula xml:id="formula_64">ELBO(θ, φ (θ)) = log p θ (D) - x∈D D Q (p θ (•|x)) (3.9)</formula><p>Along this line, using a restricted class of inference model is thus similar to Posterior Regularization: the model is trained to maximize the likelihood of the dataset log p θ (D), augmented with a penalization reflecting the bias of its latent conditional relative to Q. The more expressive Q, the weaker the regularization is, to the point of completely disappearing for very expressive inference models such as MCMC. Further restricting the class Q has been additionally shown as a way to improve generalization in VAEs <ref type="bibr" target="#b164">[Shu+18]</ref>.</p><p>This regularization, constraining the abstract latent variable z, can serve to mitigate the pitfalls linked to non-identifiable latent variables (Section 2.2.2). Imposing a restrictive class Q can thus be used to enforce desirable properties in the learned model. For example if Q only contains distributions with a single mode, then the model is drawn toward learning a latent representation such that p θ (z|x) has a single mode as well. Several approaches to exploit this regularization mechanism are discussed by <ref type="bibr" target="#b164">[Shu+18]</ref>.</p><p>Likewise, disentanglement of the latent factors has been observed in factorized Gaussian VAEs <ref type="bibr" target="#b117">[Mat+19b]</ref>. It has been suggested that inductive biases are in fact necessary to encourage such desirable properties in the latent representations <ref type="bibr" target="#b110">[Loc+19]</ref>. Along this line, the choice of a restrictive class Q is viewed as an alternative (compared to modifying the ELBO criterion) to enforce the desired biases [Hig+17; Che+18a].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Summary</head><p>This chapter introduces the Variational Auto-Encoder (VAE), transposing latent variable models in the deep learning setting. In the basic case of a Bayesian Network with a single observed and a single latent variable (both of which can be multidimensional), VAE mainly relies on: i) amortized inference, consisting in learning the inference model q as a function of the observed variable x (as opposed to learning a different q x approximation for each datapoint); ii) the reparameterization trick, aimed to express expectations over q(z|x) as expectations over a fixed base distribution, whose samples are transformed by a differentiable operation, significantly lowering the variance of the gradient estimation.</p><p>The VAE can thus be viewed as a regularized Auto-Encoder with a distribution / sampling mechanism at its core. Numerous efforts have been made to address the limitations related to the original use of Gaussian distribution, and design appropriate inference model q φ (z|x) and latent distribution p θ (z), depending on the data domain.</p><p>An aspect of the chapter is to show how, within the Posterior Regularization framework, the use of a limited inference model q φ can shape the distribution and favor desirable properties such as latent disentanglement. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The ELBO with hierarchical latent variables</head><p>In the previous sections, the ELBO involves two (multi-dimensional) variables x and z. However this framework can be generalized and involve an arbitrary number of observed and latent variables. Let p denote a model with K observed variables x 1 , . . . , x K and L hidden variables z 1 , . . . , z L , then for any distribution q over the hidden variables:</p><formula xml:id="formula_65">log p(x 1 , . . . , x K ) ≥ E z1,...,z L ∼q log p(x1, . . . , x K , z 1 , . . . , z L ) q(z1, . . . , z L ) (4.1)</formula><p>Along this more general formulation, the VAE is extended to handle complex relations among latent and observed variables, referred to Hierarchical Deep LVMs, where the hierarchy relates to the structure involving the (usually latent) variables. Such a generative model is specified as a generic graphical model, usually a Bayesian Network, defining some factorization of the distribution p θ . The main specificity is that conditional distributions are implemented and trained as neural networks, akin to the VAE decoder. After the amortized inference principle (Section 3.1.1), an inference model is sought as</p><formula xml:id="formula_66">q φ (z 1 , . . . , z L |x 1 , . . . , x L ).</formula><p>The inference model is generally also factorized a a Bayesian Network, for considering a joint probability over all latent variables can be very impractical. The main design issue is that of the most appropriate factorization of the inference 51 model. While the factorization of the generative model p θ is guided by domain knowledge and other epistemic considerations, the factorization of the inference model q φ primarily aims at efficiently approximating the conditional distribution p θ (z 1 , . . . , z L |x 1 , . . . , x K ).</p><p>A principled approach for designing the inference model is the Natural Minimal I-map generator (NaMI) algorithm <ref type="bibr" target="#b175">[Web+18]</ref>. This principle operates on the graph defining p θ in order to produce a new graph usable for q φ that is minimally faithful with regard to p θ .</p><p>The graphical model representing q φ is said to be faithful to the one underlying p θ if all independence relations of q φ are also present in p θ : in other words if q φ does not introduce new independence relations between variables relative to p θ . It is however allowed to have fewer such relations. For example, having q φ be a fully connected graph is a trivial way to make it faithful.</p><p>In addition, NaMI seeks to produce a graph q φ that is minimally faithful, that is that has the smallest possible number of edge while still being faithful to p θ . A graph is said to be minimally faithful if it is faithful, but removing any of its edge would make it unfaithful. Note that this is a local property, not a global one. Hence there can exist many graphs that are each minimally faithful with regard to p θ . NaMI thus seeks to create one such graph.</p><p>The general process of NaMI can be summarized as follows. Starting from the original graphical model (Figure <ref type="figure">4</ref>.1(a)), first the arrows on all edges are removed to produce an undirected graph. Then this graph is moralized: an edge is added between each pair of node which share a child in the original graph. The resulting undirected graph is then the skeleton on which the graph for the inference model q φ is built: the last stage consists in directing the edges to produce a new Bayesian Network. This is done by iterating on all latent nodes of the graph and for each directing all not-yet-directed of its edge towards it. For example, in the graph presented on Figure <ref type="figure">4</ref>.1(b), the latent nodes were visited in the order Z 1 , Z 2 , Z 3 , while on figure Figure <ref type="figure">4</ref>.1(c) the order was Z 3 , Z 2 , Z 1 . Two main properties of this procedure can be noted. First of all, in the produced graph the observed variables don't have any parent: this reflects the fact that this graph represents a conditional distribution of the latent variables given the observed one. Secondly, the resulting graph depends on the order in which the latent variables are processed: each ordering potentially produces a different Bayesian Network.</p><formula xml:id="formula_67">Z 1 X 1 Z 2 Z 3 X 2 (a) Generative graph Z 1 X 1 Z 2 Z 3 X 2 (b) Forward-NaMI Z 1 X 1 Z 2 Z 3 X 2 (c) Reverse-NaMI</formula><p>NaMI identifies two special ordering, referred to as forward-NaMI and reverse-NaMI, both relying on a topological ordering of the nodes in the original graph<ref type="foot" target="#foot_21">foot_21</ref> . Forward-NaMI processes the latent nodes in the same order as the topological ordering, while reverse-NaMI processes them in reverse order. Note that as a result, Forward-NaMI tends to overall reverse the structure of the original graph and reverse-NaMI tends to follow it, as illustrated in Figure <ref type="figure">4</ref>.1.</p><p>Note that one might prefer considering more sparse graphs than the NaMI ones: by using a graph with less edges, one sets more constraints on the learned model, as discussed in Section 3.4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimization of hierarchical structures</head><p>While the vanilla VAE (Chapter 3) can usually be trained in an easy and stable way using stochastic gradient descent, the training of hierarchical models raises stability issues, some typical from Deep Learning in general, and some specific to the LVM structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Gradient flow</head><p>A main stability issue faced by Deep Learning is related to the so-called vanishing gradients phenomenon <ref type="bibr" target="#b76">[Hoc+01]</ref>. While it is required that the gradients can flow efficiently through the neural network along back-propagation, the vanishing gradients cause the deepest layers of the network to not receive enough gradient information to be efficiently trained. The vanishing gradients are ultimately blamed on the classical activation functions (e.g. sigmoid), with saturating regions where the gradient is vanishingly small (the derivative of the activation function is close to 0). Stacking many layers and activation functions thus makes gradients quickly converging to 0 as they back-propagate. More recent activation functions, like the ReLU <ref type="bibr" target="#b56">[GBB11]</ref> somewhat mitigate this issue; however, as quite some RELU neurons are saturated in each layer, a non-negligible fraction of the gradient information is lost at each step.</p><p>Deep Hierarchical LVM are also susceptible to this problem, as introducing a hierarchy of latent variables implies that the gradient will need to flow though more neural networks (one per edge in the Bayesian Network defining the model). This can lead the latent variables which are farthest to the observed ones in the graph to not train well, if at all [Sø +16], and as such the resulting model cannot exploit its capacity to the fullest.</p><p>A common mitigation for this problem in the Deep Learning literature is the use of residual networks <ref type="bibr" target="#b70">[He+16]</ref>. These constructs rework the structure of neural network in such a way that several paths lead to each neurons, and can ensure that at least one of these paths only consists in affine transformations, ensuring meaningful gradient always reaches all parameters in the neural network. Residual networks can in general be an answer to this issue for Deep Hierarchical LVM as well, though some care needs to be taken when incorporating them due to the stochastic nature of the training, which can cause stability issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Stability problems</head><p>The ELBO training objective is computed based on two expectations: one over the examples in the dataset, and another over the latent variables, sampled from the inference model q φ . The first expectation is approximated using mini-batches, leading to training via stochastic gradient descent <ref type="bibr" target="#b105">[Lec+98b;</ref><ref type="bibr" target="#b77">Hof+13]</ref>. The second expectation is generally approximated by Monte-Carlo: q φ is sampled a few times and the ELBO is computed on the basis of this average. Though often the expectation is approximated by a single sample with the assumption that the noise will average out across the many training iterations.</p><p>This however significantly increases the noise of the gradient estimation during the training, making in general VAE almost impossible to train with plain stochastic gradient descent without diverging. Adaptive optimizers like Adam <ref type="bibr" target="#b90">[KB17]</ref> are generally used<ref type="foot" target="#foot_22">foot_22</ref> for their momentum properties, which reduce the noise in parameter updates.</p><p>The use of Hierarchical Deep LVMs pose the additional difficulties that, for internal latent variables, both q φ and p θ are generated by the output of a neural network each. Due to the stochasticity of the optimization process, it can happen that at some point a minibatch is evaluated for which predicted distributions are quite far from each other at some variable z i , causing the probability ratio p θ (z i |... )</p><formula xml:id="formula_68">q φ (z i |... )</formula><p>in the ELBO to be extremely small. This in turns causes a large spike in the ELBO value for that minibatch, causing very large gradients to correct for it, excessively disrupting the internal state of the optimizer and causing the training process to diverge. This is mostly a problem of training dynamics: due to the large number of parameters in artificial neural networks, even a small update to each (as enforced by Adam) can still have a dramatic effect on the output of the network at the next iteration. The more hierarchical variables in the model, the more likely that at least one of them, when sampled, produces a value in an unlikely region of the space, creating a cascade of unusual values entering the subsequent networks, entailing a spike of the loss and generating extreme gradients.</p><p>This instability could be mitigated by considering a sufficient number of samples drawn after q φ and taking their average to better approximate the expectation; but this approach is hardly affordable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Alternative training formulations</head><p>The stability issue can also be handled by adjusting the training procedure and the ELBO optimization. Two approaches investigated in the literature include considering an inference model structure tightly connected to that of the generative model, and sequentially learning the latent variables. Both approaches have mainly considered unary tree-structures, as illustrated in Figure <ref type="figure">4</ref>.2, factoring as:</p><formula xml:id="formula_69">p θ (x, z1, . . . z K ) = p θ (x|z K )p θ (z K |z K-1 ) . . . p θ (z 2 |z 1 ) (4.2)</formula><p>Here, the hierarchy of latent variables mostly aims at a more powerful representation: with numerous latent variables stacked on top of each other, even if each</p><formula xml:id="formula_70">Z 1 Z 2 Z 3 Z 4 X Figure 4</formula><p>.2: Hierarchical graphical model whose 4 latent variables are structured as a unary tree. variable has simple neural networks encoding them, complex marginal distributions can be reached for the last one z K .</p><formula xml:id="formula_71">Z 1 Z 2 Z 3 Z 4 X (a) Inference model of LadderVAE. Z 1 Z 2 Z 3 Z 4 X (b) Output of forward-NaMI.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coupling the inference and generative models Introduced by [Sø +16], the</head><p>LadderVAE builds an inference model with same topological ordering as the generative model (thus similar to reverse-NaMI). It relies on a Gaussian parametrization of the latent variables: each layer z i of the generative model is modeled by a neural network with output µ p,i</p><formula xml:id="formula_72">(z i-1 ), σ 2 p,i (z i-1 ). Finally, p θ (z i |z i-1 ) = N (µ p,i (z i-1 ), σ 2 p,i (z i-1 )</formula><p>). The specificity of the LadderVAE lies in the definition of its inference model. first, a deterministic neural network takes the data x as input and produces parameters μq,i (x), σ2 q,i (x) for all latent variables as once, and then the actual q distribution is defined by combining these parameters with the associated parameters from p to build q φ (z i |x, z i-1 ) = N (µ q,i , σ 2 q,i ):</p><formula xml:id="formula_73">σ 2 q,i = 1 σ -2 p,i + σ-2 q,i and µ i,q = µ p,i σ -2 p,i + μq,i σ-2 q,i σ -2 p,i + σ-2 q,i (4.3)</formula><p>The above coupling of q φ and p θ defines the inference model as an iterative refinement of the prediction of the generative model, using information extracted from the target value x, with the variance predictions as mixture weights. This formulation avoids a major source of instability as it ensures that σ q,i ≤ σ p,i . Quite the contrary, when σ q,i &gt;&gt; σ p,i in a regular VAE, thethis incurs a high Kullback-Leibler divergence, strongly penalizing the model and generating large gradients. LadderVAE is by construction immune to this risk of instability.</p><p>Note that in the LadderVAE all latent predictions from the inference model directly depend on x (as opposed to e.g. NaMI where each variable depends on its direct neighbor variables, both cases are compared on Figure <ref type="figure">4</ref>.3), enabling the information to flow through the model more efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequential training of latent variables</head><p>The Two Stage VAE <ref type="bibr" target="#b47">[DW19]</ref> addresses the following issue. When training a Gaussian non-hierarchical VAE, the marginal latent distribution of the inference model q φ (z) = Ex∈D q φ (z|x), also referred to as aggregated posterior in the literature, does not in general correctly match the generative latent distribution p θ (z). This mismatch causes the generation of unrealistic samples: when z is sampled from p θ in an improbable region after q φ , the generative neural network has not been trained in such regions and it fails to generate a realistic sample.</p><p>The authors argue that this failure happens when the data is concentrated in a low-dimensional manifold of the data space <ref type="bibr" target="#b47">[DW19]</ref>. This property, known as the Manifold Hypothesis, is discussed further in Section 6.1. Accordingly, the VAE needs to find said manifold, an ill-defined problem (except in the large sample limit). In this situation, the VAE can optimize its ELBO well without necessarily converging to an aggregated posterior that accurately matches the latent distribution p θ (z).</p><p>Even though, the aggregated posterior q φ (z) still covers most of the latent space Z, not being restricted to a low-dimensional manifold. The Two Stage VAE precisely exploits this q φ (z) and trains a second VAE, using another latent variable u to approximate q φ (z). The eventual model is a Hierarchical LVM p θ (x, z, u) = p θ (x|z)p θ (z|u)p(u). One can think of the first stage as "smoothing" the dataset in view of the second stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Key design considerations</head><p>Hierarchical models can still be trained in a stable way using gradient descent on the standard ELBO, provided that some care is taken of the neural network architecture, their initialization, and the training dynamics.</p><p>Neural Network architecture To allow the gradient to flow across the whole architecture and efficiently train the model, the use of residual structures is necessary. Specifically, for every neural network involved in either the inference or the generative models, there must exists one linear path from the input to the output neurons (involving no non-linear activation function). This direct path help ensuring the flow of the gradient information up to the deepest parts of the model.</p><p>The information flow towards the deepest part of the model can also be improved by augmenting the NaMI-produced graph for the inference model, adding additional edges from the observed variables to the latent ones, much like the LadderVAE does. The increased cost of these additional edges can be mitigated by implementing partial weight-sharing between the neural networks working on these inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model initialization</head><p>The initialization of the various neural networks interacting during the training of a Hierarchical Deep LVM can have a dramatic impact on its training stability. A random initialization might result in generating poorly aligned samples from p θ and q φ , yielding a poor initial ELBO and (very) large gradients, as discussed in Section 4.2.2.</p><p>An option is to initialize each neural network in such a way that it yields a constant output, not depending on its inputs. This is achieved by setting to 0 the weight matrix of the last layer, with a constant bias adjusted to yield a sensible initial value depending on the considered distribution. For example, if the network is to predict a Gaussian distribution, it could be initialized to always rpedict a mean of 0 and a variance of 1. This way the rest of the network will still compute random features of the input, allowing the gradient computation to pick up correlations and initiate the training. This targeted initialization of the last layer is part of the Fixup Initialization scheme <ref type="bibr" target="#b181">[ZDM18]</ref>.</p><p>The same initialization strategy also applies on the inference model, albeit with a different rationale. Having q φ predict random distributions right from the beginning imposes an initial organization of the latent space of abstract variables<ref type="foot" target="#foot_23">foot_23</ref> . If this organization is suboptimal (which is likely the case) the network can nevertheless be stuck with it, as it can form a local minimum of the training objective. Initializing q φ to have constant predictions equal to that of p θ avoids this, as no organization is imposed. The natural stochasiticity of the gradient estimation via Monte-Carlo is enough to break the symmetry of this initial configuration and allow training.</p><p>Finally, when using complex residual networks, one must preserve the initial variance (similarly to mainstream neural networks <ref type="bibr" target="#b105">[Lec+98b]</ref>). Hierarchical Deep LVM are particularly sensitive to an initialization that increases the variance, as this effect can cascade through the latent variables hierarchy. The use of standard initializations within residual networks however tends to increase the output variance, due to the multiple paths. An empirically efficient alternative is the Fixup Initialization <ref type="bibr" target="#b181">[ZDM18]</ref>, which is designed to compensate this variance increase<ref type="foot" target="#foot_24">foot_24</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise reduction</head><p>The noise in the estimation of the gradient through the reparameterization trick can be further reduced by using a Path Derivative estimator <ref type="bibr" target="#b156">[RWD17]</ref>. Using the reparameterization trick, a latent variable z sampled from q φ is written as a function of some standard noise , the parameters of the inference network φ, and the input x: z( , φ, x). Then, the gradient estimate produced by the reparameterization trick decomposes as:</p><formula xml:id="formula_74">∇ φ E z∼q φ log p θ (x, z) q φ (z|x) = E z∼q φ       ∇ z log p θ (x, z) q φ (z|x) • ∇ φ z path derivative -∇ φ log q φ (z|x)       (4.4)</formula><p>The last term of this equation, ∇ φ log q φ (z|x) has a null expectation:</p><formula xml:id="formula_75">E z∼q φ ∇ φ log q φ (z|x) = z q φ (z|x) ∇ φ q φ (z|x) q φ (z|x) dz = z ∇ φ q φ (z|x)dz = ∇ φ z q φ (z|x)dz = 0</formula><p>(4.5) However, this term introduces variance in the gradient estimation, which tends to drown the useful signal during the latter stages of the training. It can however be removed from the gradient estimation using a stop-gradient instruction in the computation graph of the model (which is supported by most deep learning frameworks). A detailed discussing about when this estimator can be preferable to the simple reparameterization trick, and how to do it, is presented in <ref type="bibr" target="#b156">[RWD17]</ref>.</p><p>Training dynamics In some cases, the stability can be improved by using two different optimizers for the inference model q φ and the generative model p θ . In particular, choosing an optimizer with more inertia and a smaller stepsize for p θ permits q φ to converge quicker; this ensures that a tighter ELBO is used to compute the training gradients for p θ . A slow-moving p θ also prevents it from getting suddenly too far from the prediction of q φ and generating huge gradients, as discussed in Section 4.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Graph Structure Learning</head><p>A question is whether same methods can be applied to learn the structure of Bayesian Networks (Section 1.3.3) and that of Hierarchical Deep LVM. This question however raises two difficulties: besides the general issue of learning the structure of an LVM, comes the additional complexity of structure choice in deep learning.</p><p>Two works related to learning Hierarchical Deep LVMs will be discussed (the litterature on the topic being scarce and recent): Graph-VAE <ref type="bibr" target="#b71">[He+18]</ref> and LT-VAE <ref type="bibr" target="#b108">[Li+19]</ref>. Both approaches center on learning an internal structure of Gaussian latent variables z i , which are then all given as input to the final stage of the generative model p θ (x|z 1 , . . . z k ).</p><p>Graph-VAE This approach considers a multivariate latent variable z = (z 1 , z 2 , . . . , z K ) and factors its latent distribution such that the set of parents of each z j is a subset of {z i , i &lt; j}. For each pair (z i , z j ) with i &lt; j, a binary variable c i,j models whether an edge from i to j should exist or not, defining a conditional generative model on the vector c:</p><formula xml:id="formula_76">p θ (x, z|c) = p θ (x|z) j p θ (z j |z i s.t. c i,j = 1) (4.6)</formula><p>In practice, the neural network structure is fixed and the conditioning on c is achieved by multiplying z i by c i,j before feeding it as input to the neural network handling z j . The inference model q φ is defined using the same graphical structure and conditioning, but giving x as input to each distribution:</p><formula xml:id="formula_77">q φ (z|x, c) = j q φ (z j |x, z i s.t. c i,j = 1) (4.7)</formula><p>For each c, the above formula defines an ELBO training of p θ (x|c), where c fully encodes the graphical latent structure to be learned. c itself is learned by defining a distribution p µ (x) as a product of Bernoulli distribution parameterized by a vector µ of their means: p µ (c i,j ) = B(µ i,j ). The final training objective is then defined by taking the expectation of the c-conditioned ELBO over p µ (c), and estimating said expectation via Gumbel-Softmax parametrization to learn µ via gradient descent along θ and φ: Although the resulting loss is not a lower-bound per se, the authors report that the approach works well in practice and that p µ reliably converges to be a constant distribution, meaning the model does settle for a single latent structure.</p><formula xml:id="formula_78">L = E c∼pµ   E z∼q φ (z|x,c) log p θ (x, z|c) q φ (z|x, c)   (4.8) Y 1 Y 2 Y 3 Z 4 Z 3 Z 2 Z 1 X Figure 4</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latent Tree VAE (LTVAE)</head><p>This model learns the structure of the latent variables, as illustrated in Figure <ref type="figure">4</ref>.4. The number of latent dimensions is still fixed in advance; the z i are partitioned into clusters, multivariate variables noted Z 1 , . . . , Z B , where B is not fixed in advance. Discrete latent variables Y 1 , . . . Y are learned too: these Y j are tree-structured, and each Z i variable is linked to a single Y j as its parent. The learning procedure concerns: the number of Y j , their organization as a tree, the number of Z i , the dimensionality of each, and which Y j governs a Z i .</p><p>The inference model q φ (z|x) is a diagonal multivariate distribution over the whole joint variable z, defining an elaborate latent distribution pθ(z). While p θ (x|z) and q φ (z|x) are learned like in a mainstream VAE, the latent distribution p θ (z) is learned via an EM-like algorithm, optimizing its parameters and computing the gradient ∇ z log p θ (z) by message passing. The latent structure itself is also continuously optimized during the training search, modifying the graph via graph operators (adding a Y i , splitting a Z j into two new variables, changing the parent of a Z j , ...) and evaluating the quality of a structure via the Bayesian Information Criterion (BIC) (Section 1.3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Summary</head><p>This chapter describes the Hierarchical Deep LVMs framework, and presents the Natural Minimal I-map (NaMI) algorithm to construct an inference model for any Bayesian network, that captures all relevant dependencies while remaining as sparse as possible.</p><p>These approaches face similar challenges as deep networks (regarding the training stability and the flow of information through the model during training), still exacerbated by the intrinsically stochastic nature of the ELBO training criterion. In order to mitigate these issues, an option is to couple more tightly the structures of the inference and the generative model. The NaMI graph can be augmented by adding direct edges from the observed variables to latent ones, improving information flow at the expense of the computational cost. Mainstream architectures require specific care in the design of the neural networks and their initialization.</p><p>Regarding the learning of the Bayesian Network graph, some encouraging preliminary results have been presented in the literature <ref type="bibr" target="#b71">[He+18;</ref><ref type="bibr" target="#b108">Li+19]</ref>. This chapter discusses the state of the art related to observation models. While latent variables can be arbitrarily modeled following the desired properties (as will be discussed in Part III), the modeling of observed variables is directly linked to their probabilistic interpretation, defining the observation model. The observation model can be best designed from the known internal structure of the data (sound, images, text...) as in Machine Learning in general, via pre-processing (e.g., normalization of numerical values, embedding of semantic values or manual feature construction), or based on the structure of the data (e.g. convolutional networks for image processing <ref type="bibr" target="#b101">[LB98]</ref> or long short-term memory (LSTM) structures for sequential data <ref type="bibr" target="#b80">[HS97]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II</head><p>Section 5.1 presents perceptual distances, which adjust a Gaussian observation model w.r.t. a specific distance function. Section 5.2 is centered on the use of auto-regressive observation models, which decompose multi-dimensional examples as a sequence of conditionally-produced values. These very expressive models are notably applied to represent temporal or spatial structures (such as sound or images). Then, Section 5.3 focuses on an extremely powerful class of observation models built upon normalizing flows: RealNVP. Finally, Section 5.4 discusses the posterior collapse phenomenon, a not infrequent pitfall related to the use of very expressive observation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Perceptual distances for images</head><p>The Gaussian observation model is in general an intuitive choice: it represents the fact that the value x was measured with some (known or not) uncertainty. If the measurement apparatus that produced the dataset has a known precision, this can be reflected in the model by specifying a Gaussian observation model with an appropriate fixed variance, reflecting the fact that making predictions that are more precise than the experimental apparatus is meaningless.</p><p>When applied to images, this interpretation is not always satisfying. A diagonal Gaussian distribution would make sense by representing the intrinsic noise of the photographic captor. This noise is however extremely small, implying a variance so small that the observation model is then essentially deterministic, defeating the purpose of integrating data structure into the model.</p><p>Work has been done to address this problem by trying to use the observation model to represent semantic uncertainty in the image data, by differentiating information that is semantically relevant from what could be called semantic noise. This is achieved by considering different distance measures in image-space than the euclidean distance induced by the pixel-wise Gaussian distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Gaussian observation and choice of distance</head><p>The normal distribution can be specified to explicit its dependency with regards to the underlying metric. Let X denote the instance space, with a distance function on this space d : X × X → R + . A normal-like distribution of parameters x ∈ X and σ 2 &gt; 0 is defined as:</p><formula xml:id="formula_79">N d (x|x, σ 2 ) ∝ exp - 1 2σ 2 d(x, x) 2 (5.1)</formula><p>The usual isotropic normal distribution is then recovered for d(x, y) = x -y 2 . This formulation is appealing for the VAE, especially when viewed as an autoencoder. The reconstruction term (Equation 3.3) then boils down to the expectation of the squared distance d 2 between the input datapoint x and the value predicted by the decoder neural network x. The key issues are to define the appropriate distance measure, and the scale parameter σ 2 .</p><p>Along this line, an appropriate distance is one making a real picture far from any image filled with noise, while making close two similar real images. The pixel-based Euclidean distance, d(x, x) 2 = i (x i -xi ) 2 does not satisfy these requirements, as illustrated on Figure <ref type="figure">5</ref>.1.</p><p>The question thus becomes to find perceptual distances, reflecting the human perception of similarities and dissimilarities between images. Such similarity measures have been explored over the last decades, notably for content-addressed search in image databases [NG06; Bed+16], but most are inadequate to support the optimization and training of deep networks, not being differentiable.</p><p>Note that the use of an arbitrary distance function raises another issue, that of directly sampling the distribution N d . Actually, most models based on such N d take the output x of the decoder NN in lieu of generated sample. While this approximation makes sense for σ 2 &lt;&lt; 1, it might be abused in practice, entailing most undesirable effects. We shall come back to this important issue in Section 6.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">NN-based perceptual distances</head><p>Perceptual distances often rely on the use of neural networks (thus defining an implicit differentiable distance function). Formally, a NN is used to embed the images onto a vector feature space; the Euclidean distance in this feature space is used as perceptual distance, under the assumption that the feature space induces a more meaningful Euclidean distance than the pixel space. The question thus becomes finding an appropriate feature space as well as a tractable way to compute it. Quite a few approaches reuse some intermediate representation learned by a neural network trained to achieve image recognition. Along this line, DeepSIM <ref type="bibr" target="#b35">[DB16]</ref> uses an internal layer of the classifier AlexNet <ref type="bibr" target="#b97">[KSH12]</ref>, trained for image classification on the ImageNet <ref type="bibr" target="#b36">[Den+09]</ref> dataset. The Euclidean distance computed in this internal feature space is combined with the Euclidean distance in pixel space and an adversarial feedback based on Generative Adversarial Networks (GANs)<ref type="foot" target="#foot_25">foot_25</ref> [Goo+14; RMC16] to produce a hybrid training criterion, mixing the perceptual distance and the discriminant information, eventually yielding more realistic generated images.</p><p>Similarly, <ref type="bibr" target="#b78">[Hou+17]</ref> use the distance defined from a VGGNet classifier [SZ15] also trained on ImageNet; they consider the Gaussian distribution built upon this distance to train a generative model on the CelebA faces dataset <ref type="bibr" target="#b109">[Liu+15]</ref>, by using a combination of several internal deep and shallow layers of the classifier network. The intuition is that, although the classifier has not been trained on the same data, both datasets are natural images; therefore the same feature space should be relevant to both. Moreover, using a classifier trained on a more general dataset than the generative model can also reduce overfitting.</p><p>Another approach is that of VAEGAN <ref type="bibr" target="#b99">[Lar+16]</ref>, that uses the latent representation of an adversarial discriminator (trained to discriminate the generated samples from the initial data). By construction, the discriminator aims to distinguish real images from generated ones, thus expectedly creating a feature space where the Euclidean distance would be relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Autoregressive observation models</head><p>Rather than building further on the Gaussian observation model, another very general approach for handling handling multi-dimensional variables consists in splitting them into a list of scalar variables, with a chained distribution structure:</p><formula xml:id="formula_80">p θ (x|z) = i p θ (x i |z, x 0 , . . . , x i-1 ) (5.2)</formula><p>Such models, referred to as autoregressive models, can be extremely expressive. Actually, many such models were developed with no latent variables: the autoregressive component p θ (x i |x 0 , . . . , x i-1 ) can be powerful enough to represent a complex distribution, and it can be trained directly using explicit maximum likelihood. Such models are especially well suited to data with a temporal or spatial structure, such as sound, images or language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Recurrent Neural Networks for sequential data</head><p>Auto-regressive observation models can be most simply implemented using recurrent neural networks such as LSTMs <ref type="bibr" target="#b80">[HS97]</ref>. The latent variable z is used to define the initial state h 0 of the LSTM decoder, that yields eventually x as illustrated in Figure <ref type="figure">5</ref>.2. In this approach [FA15; Bow+15], the associated inference network similarly relies on an LSTM. Another approach uses a recurrent structure for the latent variables themselves, akin a Hidden Markov Model (illustrated on Figure <ref type="figure">5</ref>.3(a)). Introducing a sequence of latent variables can drastically improve the expressiveness of the model, accurately reflecting the sequential nature of the data. In practice, Deep LVMs built on recurrent architectures often use a combination of latent and deterministic nodes, such as the Variational Recurrent Neural Network (VRNN) <ref type="bibr" target="#b28">[Chu+15]</ref> illustrated in Figure <ref type="figure">5</ref>.3(b), that has been used for speech modeling. Even more complex structures have been proposed, such as the Stochastic Recurrent Neural Network (SRNN) <ref type="bibr" target="#b53">[Fra+16]</ref> that uses a hierarchy of two sequences of latent variables linked to the sequence of observations. </p><formula xml:id="formula_81">z h 1 h 2 x 1 x 2 . . . (a) Generative model x K-1 x K h K-1 . . . h K z (b) Inference model</formula><formula xml:id="formula_82">z 1 z 2 z 3 x 1 x 2 x 3 . . . (a) Hidden Markov Model h 0 h 1 h 2 . . . z 1 z 2 . . . x 1 x 2 . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">PixelRNN and PixelCNN for image generation</head><p>When considering an autoregressive factorization for image generation, one naturally considers each channel of each pixel of the image as different variables. Along this line, PixelRNN model <ref type="bibr" target="#b127">[OKK16]</ref> fully embraces the discrete nature of computer images by modeling the variable of each channel as a 256-values discrete variable, parameterized using a softmax output. With no latent variables, this model can be trained directly to maximize the data likelihood.</p><p>In its simplest mode PixelRNN generates the image row by row (denoted Row-LSTM). A more powerful approach, BiLSTM, implements a recurrent structure w.r.t. both dimensions of the image, ensuring a better coherence of the generated image. The third variant, PixelCNN, has proved the most popular one, where the generation of a given pixel x i depends only on its neighbor pixels, following the receptive field of a convolutional layer. The whole neural network thus is structured using convolutional neural networks (as opposed to recurrent ones, with significant improvement of the runtime performances at the cost of some expressiveness). Both variants are shown in Figure <ref type="figure">5</ref>.4. PixelCNN is acknowledged to be a powerful and expressive architecture. It has been used as decoder within an auto-encoder <ref type="bibr" target="#b129">[Oor+16a]</ref>, and combined with a Deep LVM to yield the PixelVAE <ref type="bibr" target="#b65">[Gul+16]</ref>. Further improvements notably replace the 256-way softmax output with a mixture of discretized logistic distribution<ref type="foot" target="#foot_26">foot_26</ref> , drastically reducing the output dimension of the network while retaining sufficient expressiveness in PixelCNN++ <ref type="bibr" target="#b159">[Sal+17]</ref>. Later, PixelSNAIL <ref type="bibr" target="#b26">[Che+18b]</ref> was proposed, improving the receptive field of the autoregressive process to better handle long-term dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">WaveNet for audio generation</head><p>Audio data models lend themselves to a natural sequential factorization along the time steps. Accordingly, Wavenet <ref type="bibr" target="#b130">[Oor+16b]</ref> was designed following the principles of PixelRNN. It similarly handles the prediction of the audio waveform x t as that of a categorical variable, where the continuous signal value is binned into intervals (the width of which follows a logarithmic scale). The major novelty in Wavenet lies in the internal structure of the recurrent network based on dilated convolutions.</p><p>Recurrent neural networks are known to struggle with long-term dependencies, and while e.g. LSTM <ref type="bibr" target="#b80">[HS97]</ref> mitigates this issue, it remains insufficient for raw audio -usually recorded from 16 kHz up to 44 kHz, or even higher. Tens of thousands of variables for each second of audio is more than any standard recurrent network can hope to remember. Wavenet thus introduces an internal structure specifically designed to handle long-term dependencies using several layers of dilated convolutions, each layer effectively doubling the receptive field of the output with regard to the previously generated values (Figure <ref type="figure">5</ref>.5). In its initial version Wavenet was rather slow, generating samples x t one at a time. To alleviate this shortcoming, <ref type="bibr" target="#b131">[Oor+18]</ref> introduces the Parallel Wavenet. This neural structure similar to Wavenet uses a Normalizing Flow, transforming a sequence of latent values sampled from a fixed distribution t ∼ p( ) into a sequence of observations x t ∼ p(x t | 1 . . . t ). The benefit of this structure is that x t no longer depends on the values of the previous timesteps x 0 , . . . , x t-1 , allowing each value to be sampled in parallel in a much faster way.</p><p>However, as discussed in Section 2.3.3, Normalizing Flows are trained by minimizing their Kullback Leibler divergence to an energy model (as opposed to, by maximum likelihood). Accordingly, the Parallel Wavenet is trained using a regular Wavenet as its target energy model. The complete training is thus achieved in two steps: first a regular Wavenet is trained on the dataset, then the Parallel Wavenet is trained using Wavenet as a teacher, akin a Network Distillation scheme <ref type="bibr" target="#b82">[HVD15]</ref>.</p><p>Wavenet is extensively used for speech synthesis, conditioning the synthesis on a phonetic encoding of the sentences to generate, with such a quality that Wavenet was used to voice the Google assistant when it was deployed in Oct. 2017<ref type="foot" target="#foot_27">foot_27</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">RealNVP and flows-based observation models</head><p>Normalizing Flows (Section 2.3.3), being very expressive and able to approximate almost any well-behaved distribution, are a very powerful option for building observation models. They however need to be adapted to learn a distribution from a dataset (as opposed to an energy function).</p><p>The adaptation is straightforward: instead of defining the transformation as x = f θ ( ), it is reversed as = f θ (x). The density equation then becomes:</p><formula xml:id="formula_83">log p θ (x) -log |∇ x f | = log π( ) (5.3)</formula><p>This formulation supports a maximum likelihood training from the dataset:</p><formula xml:id="formula_84">log p θ (D) = x∈D log p θ (x) = x∈D log |∇ x f | + log π(f θ (x)) (5.4)</formula><p>However, this only formulation is limited as p θ (x) cannot be efficiently sampled unless f -1 θ can be easily computed. This limitation was initially addressed by the use of real-valued non-volume preserving (realNVP) transformations <ref type="bibr" target="#b44">[DSB17]</ref>, both invertible and suitable for use in Normalizing Flows.</p><p>The general idea of realNVP is to split the input and output multi-dimensional variables in two: x = (x 1 , x 2 ) and = ( 1 , 2 ), and consider the following transformation f θ , called an affine coupling (where * is an element-wise multiplication):</p><formula xml:id="formula_85">f θ : 1 = x 1 2 = x 2 * s θ (x 1 ) + t θ (x 1 ) (5.5)</formula><p>As the transformation is conditioned by x 1 , which is fixed, it can be easily inverted (where ÷ is an element-wise division):</p><formula xml:id="formula_86">f -1 θ : x 1 = 1 x 2 = ( 2 -t θ ( 1 )) ÷ s θ ( 1 ) (5.6)</formula><p>Although this transformation is simple in itself, stacking several instances of it (with different parameters), and alternating the role of the two halves of the variables by permuting them 4 yield powerful representations. In particular for the application to images, <ref type="bibr" target="#b44">[DSB17]</ref> propose to split the pixels of the image in two groups along a checkerboard pattern; both halves thus cover the whole image, allowing for coherent transformations. The t θ and s θ functions are then learned using convolutional neural networks.</p><p>Further improvements and variations of realNVP have been proposed: Glow <ref type="bibr" target="#b91">[KD18]</ref> replaces the permutation step by an invertible 1 × 1 convolution, of which permutations are a special case. Flow++ <ref type="bibr" target="#b75">[Ho+19]</ref> introduces a more complex class of coupling layers, and proposes a new method to address dequantization<ref type="foot" target="#foot_29">foot_29</ref> based on the ELBO and using another Normalizing Flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">The Posterior Collapse Phenomenon</head><p>Autoregressive and realNVP-based models, initially introduced as standalone generative models, are mostly used as such. They both have conditional variants, and can be used as observation models within a Deep LVM; along this line PixelVAE <ref type="bibr" target="#b65">[Gul+16]</ref> combines VAE with a PixelCNN decoder. However, in general ELBO training of these models proves difficult due to a phenomenon known as Posterior Collapse (PC).</p><p>The PC occurs when the Deep LVM involves a very powerful observation model, that would be capable of approximating well the dataset while entirely ignoring the value of the latent variables (Figure <ref type="figure">5</ref>.6). Along this line, the inference model q φ receives almost no feedback from the data while the ELBO draws it to match the latent distribution p θ (z), and it collapses to this distribution: ∀x : q φ (z|x) = p θ (z). The model thus reaches a good optimization of the ELBO while completely ignoring the latent variables <ref type="bibr" target="#b24">[Che+17]</ref>, which generally goes against the intended goal of introducing such variables in the first place.</p><p>It is currently believed that the posterior collapse occurs due to the training dynamics of the model [He+19; Luc+19]. In the early training stages the inference model q φ poorly approximates the real posterior distribution p θ (z|x) associated to these complex observation models, and the inferred z is thus irrelevant to improve the prediction p θ (x|z). The poor quality of this approximation is blamed on the insufficient optimization of the inference model, making it lag behind the observation model <ref type="bibr" target="#b72">[He+19]</ref>.</p><p>Several approaches have been developed to mitigate the PC effect. [Luc+19] consider an annealing process on the ELBO, setting a weight α on the term D KL (q φ (z|x) p θ (z)), initialized at 0 and gradually increased to 1, then recovering the original ELBO. Therefore the observation model can freely use the z variable in the early training stage, as the inference model is then allowed to deviate a lot from the latent distribution p θ (z). The increase of α then slowly drives the latent variable z back to p θ (z), while the observation model has already learned to use it, and follows the movement. <ref type="bibr" target="#b141">[Raz+19]</ref> introduces the δ-VAE, where the distribution classes for q φ (z|x) and p θ (z) are chosen in such a way that their KL-divergence is lower-bounded by some hyper-parameter δ &gt; 0, preventing the total collapse of the inference model. Likewise, this makes it free for the observation model to somehow use the latent variable and opening the door for more. Finally, <ref type="bibr" target="#b2">[Ale+18]</ref> modifies the ELBO training objective by reformulating it as a constrained optimization problem and then generalizing it to design a new training objective that forces the model to use the latent variable.</p><p>The most effective results obtained by combining Deep LVMs with powerful observation models rely on the use of discrete latent variables. An example thereof is PixelVAE++ <ref type="bibr" target="#b157">[Sad+19]</ref>, that improves PixelVAE taking inspiration from Pixel-CNN++, replacing the latent space with a discrete variable, and learning the latent distribution p θ (z) as an RBM, mimicking DVAE <ref type="bibr" target="#b148">[Rol17]</ref>. The Vector-Quantized VAE (VQ-VAE) <ref type="bibr" target="#b133">[OVK17]</ref> and its refinement VQ-VAE-2 [ROV19] significantly modify the model formulation by learning a set of latent embeddings and a discrete distribution over them, effectively handling the inference model q φ (z|x) as a mixture of point mass distribution (a mixture of Diracs). This makes it impossible to interpret the learning criterion as a lower bound of the data likelihood. Nevertheless, VQ-VAE reaches very competitive performance in the context of generation of realistic high-definition images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Summary</head><p>This chapter focuses on the probabilistic interpretation of observed variables. This interpretation (and the associated probabilistic model choice) defines the lens through which the LVM can interact with the data, thus conditioning the success of the training.</p><p>Several approaches have been designed to account for data properties or structures: Perceptual distances are meant to emulate the human-perceived similarity between images. Autoregressive models (e.g. Wavenet or PixelRNN/CNN) factor the model as a succession of conditional distributions, yielding very expressive models for discrete sound or image data. Inspired from autoregressive flows, RealNVP builds an expressive class of observation models enabling to generate high-dimensional examples.</p><p>In counterpart for these gains in expressivity, the above approaches are highly susceptible to posterior collapse, ignoring the latent variables and learning the data distribution from the only observation model. Several adjustments have been proposed to avoid this issue [Luc+19; Raz+19; Ale+18].</p><p>Overall, these expressive observation models tend to weaken the link between the latent variables and the observed data. Specifically, the latent representation can then be less easily exploited in order to analyze the data: expressive observation models can induce, and compensate for, a poorly informative latent representation. This chapter presents and discusses the relationship between the model and the data in relation with the so-called Manifold Hypothesis [Rif+11; BWS15; FMN16; CCR21], considering that the data lie near a manifold. Ideally, an optimal latent representation would define a mapping from some (low-dimensional) space onto the data manifold, that is, provide a parametric map of this manifold.</p><p>The question thus becomes when and how can an LVM appropriately characterize the data manifold. This chapter presents the first main contribution of this thesis: a case study under the assumptions of a large sample limit and an infinitely expressive latent representation, extending a former article <ref type="bibr" target="#b16">[BS20b]</ref>.</p><p>The subject of information flow throughout the a VAE and its relation to the learning process has been studied thoroughly. One notable angle of analysis is the interpretation the latent space as a noisy communication channel between the encoder and decoder in the light of Information Theory [BK18; RV18; ZSE18; Raz+19; Zhe+19; DSL20]. An other lies on linking the VAE to Principal Component Analysis (PCA) <ref type="bibr" target="#b34">[Dai+18;</ref><ref type="bibr" target="#b113">Luc+19]</ref>. This chapter and the next one provide a complementary analysis focusing on the geometrical interpretation of the training objective in light of the Manifold Hypothesis, and the impact of the observation model on the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The Manifold Hypothesis</head><p>Most datasets are endowed with an internal structure, that is implicitly characterized as not every element in the considered embedding space X is a valid sample: a random matrix of pixels does not correspond to a photorealistic image, a random image does not represent a person in general, a random sequence of numbers does not encode a voice waveform, etc. (On the other hand, if any sample in a high-dimensional space were a valid one, then in general, the available data resources would be insufficient to support learning).</p><p>The structure of the real data samples in a high dimensional space, referred to as Manifold Hypothesis (MH), is formulated as follows:</p><p>The considered dataset in a high-dimensional space is actually concentrated around a low-dimensional manifold embedded in this space.</p><p>Note that the dataset is assumed to concentrate near a low-dimensional manifold, as opposed to, be contained in the manifold. The latter assumption would be unrealistic, due to the data noise. The MH thus actually assumes that there exists a low-dimensional representation of the dataset with no significant loss of information; it does not assume that the data exactly lie in some "true" manifold of the embedding space.</p><p>The MH is generally assumed in the domain of computer vision: the region of natural images is continuous and connected<ref type="foot" target="#foot_30">foot_30</ref> while most pixel matrices are "visibly" not natural images. The same applies for audio data. The MH can have an adverse impact on some learning algorithms, such as Generative Adversarial Networks: the fact that the data lie in a restricted region of the embedding space can hinder or prevent the training of the model <ref type="bibr" target="#b0">[AB17]</ref>.</p><p>If such an appropriate manifold were known, then any datapoint could be decomposed in two parts: a location on the manifold, plus some small deviation from the manifold. Along this line the semantically useful information would be said location on the manifold, while the deviation would represent a small noise. This decomposition, akin to Manifold Learning <ref type="bibr" target="#b20">[Cay05]</ref>, motivates the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Quasi-deterministic observation models</head><p>Latent Variable Models can be understood with respect to the MH. The learned distribution over observed variables, p θ (x), can be viewed as a mixture of the observation model, indexed by the latent variables z: p θ (x) = z p θ (x|z)p θ (z)dz. Along this line, the LVM training aims to pave the data manifold with instances of its observation model (Figure <ref type="figure">6</ref>.1).</p><p>If all considered observation models are low-variance distributions, then the learned observation model p θ (x|z) itself establishes a mapping from the z space to the data manifold, the transformation z → x being almost deterministic (in the low variance case). In order for the learned observation model to characterize the data manifold, the latent variables z must contain all relevant information for characterizing a given example within the whole dataset; the latent representation could then support other downstream tasks<ref type="foot" target="#foot_31">foot_31</ref> . Let us define the notion of quasi-deterministic observation model as an observation model where the generative process of x given z is a deterministic procedure f θ augmented with some noise θ : x = f θ (z) + θ . Thus p θ (x|z) can be formulated in terms of p ,θ ( |z), the density of the noise model:</p><formula xml:id="formula_87">p θ (x|z) = p ,θ ( = x -f θ (z)|z) (6.1)</formula><p>Though the noise can in principle depend on z (inducing heteroscedastic models), the idea is that after training, the learned noise model will have a small variance such that the deterministic mapping x = f θ (z) offers a decent alternative to actually sampling p θ (x|z).</p><p>In the following two examples of quasi-deterministic observation models are analyzed. The simplest one (diagonal Gaussian observation) has limitations that may force the model to fail to differentiate the manifold from the noise. The second illustrates how these limitations can be overcome without leaving the quasideterministic context, by building a hierarchical observation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">The Gaussian observation and its limitations</head><p>When considering Gaussian observation models, the observed variable x involves a mean noted f θ (z) and a covariance matrix. The low variance of the noise model holds iff this covariance matrix have small eigenvalues compared to the overall variance of the considered dataset.</p><p>In practice, three options have been considered in the literature. A first option considers an isotropic covariance matrix σ 2 I with a constant σ. This option is retained in many papers, notably in computer vision where the VAE is mostly viewed as a regularized auto-encoder 3 [Hou+17; Dor+17; Hua+18; GSS20; Gho+20], trained from the squared error reconstruction loss (x, x) = x -x 2 . This loss is equivalent to a Gaussian observation model with a fixed isotropic variance 4 σ 2 = 1/2. However, a variance of 1/2 might seem unreasonably large (when considering the image data as a vector whose coordinates are in [0; 1]), preventing f θ (z) from being a good approximation for p θ (x|z). As will be shown in Section 6.3, such a high σ can be considered the main cause for the blurriness long observed in VAE-generated images.</p><p>It can be noted that in this context, changing the fixed observation variance σ 2 is equivalent to applying a factor in front of the KL part of the loss, as done by β-VAE 5 <ref type="bibr" target="#b73">[Hig+17]</ref>. Empirically, it is observed that increasing the value of β improves the disentanglement of the VAE latent space; in counterpart, the images generated from the decoder (x = f θ (z)) are increasingly blurry, which is coherent with it introducing an observation noise that is too large relative to the data characteristics. A detailed comparison between β-VAE and quasi-deterministic observation models in terms of training dynamics is given in Appendix 7.A.</p><p>Other usual options consists in considering an isotropic covariance matrix whose variance is learned as a global parameter of the model <ref type="bibr" target="#b154">[RV18]</ref>, or as a diagonal covariance matrix, whose components are the output of the decoder neural network alongside the mean [KW14; MF18]. As will be shown in Chapter 7, learning the variance of the observation model has a positive impact on the dynamics of the learning process, compared to considering a fixed variance, even if adjusted using preliminary experiments.</p><p>The limitation of all above options is twofold: firstly, they lack the expressiveness of a full-rank covariance matrix; secondly, they assume an uncorrelated noise between the dimensions of x. If the data structure involves some correlated noise, the above models, being unable to model it directly, might settle for a smaller variance than appropriate. Hence, a part of the noise would eventually be encoded in the latent space alongside the actual information, as illustrated by Figure <ref type="figure">6</ref>.2. On the other hand, the option of considering (learning) a full-rank covariance matrix is impractical, especially so in high-dimensional domains like computer vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Hierarchical quasi-deterministic observations</head><p>The use of quasi-deterministic observation models can however be combined with taking advantage of the structure of the data: elaborate models can be defined using an adequate LVM structure. While the properties of high dimensional data are counter-intuitive in many cases, the manifold assumption can be invoked to enforce the sought properties or behaviors, even while sticking to the quasi-deterministic framework. 4 The negative log-likelihood of a Gaussian distribution of mean x and of variance σ 2 = 1/2 reads:</p><p>-</p><formula xml:id="formula_88">log p(x|x, σ 2 ) = 1 2σ 2 x -x 2 -D log σ = x -x 2 + D 2 log 2</formula><p>The constant term D 2 log 2 does not affect the optimization process. 5 In the isotropic Gaussian observation, the variance σ 2 acts as a global multiplicative parameter in front of the squared error. This makes it possible to interpret it as a hyperparameter reweighting the reconstruction and KL parts of the ELBO. By introducing the parameter β = σ 2 , the formulation becomes equivalent to that studied in the β-VAE: Such an adequate LVM structure is that of Laplacian Pyramid representations, reflecting the multi-scale structure of images and explored e.g. in LapCVAE <ref type="bibr" target="#b42">[Dor+17]</ref>. The article introduces several modifications to the VAE; in the following we focus on the use of intermediate observed variables, which can be considered independently of the other modifications.</p><formula xml:id="formula_89">L β-VAE = βDKL q φ (z|x) p θ (z) + E z∼q φ x -f θ (z) 2 (6.2)</formula><p>The core idea consist in generating the image along a sequence of resolution steps. First a small image x 0 is generated, then this image is upscaled, and the model generates a update δx 1 that is added to the upscaled version to make a larger image with more details: x 1 = upscale(x 0 ) + δx 1 . The process is iterated until the sought size is reached, generally with an upscaling of a factor 2 in each step. The sequence of generated images x 0 , x 1 , . . . is thus defined by (z denoting the set of latent variables):</p><formula xml:id="formula_90">       x 0 ∼ p(x 0 |z) δx i+1 ∼ p(δx i+1 |x i , z) x i+1 = upscale(x i ) + δx i+1 (6.3)</formula><p>This is illustrated by Figure <ref type="figure">6</ref>.3: each observed variable x i+1 depends on the previous one x i and some subset of the latent variable.</p><p>Along this setting, for each full image noted x N , a sequence of x i (observed variables generated by downscaling x N ) is used in the training procedure. The process, decomposing the data into multiple scales (as appropriate for images), guides the model along this structure.</p><p>Finally a hierarchical quasi-deterministic observation model thus builds x i at </p><formula xml:id="formula_91">x i = upscale(x i-1 ) + f i,θ (x i-1 , z) + i,θ (x i-1 , z) (6.4)</formula><p>Both the prediction f i,θ and noise i,θ functions take as arguments the previous image, x i-1 and some subset of the latent variables. This hierarchical observation model can be combined with any latent structure as appropriate for the application domain and goals. LapCVAE for example introduces a hierarchy of latent variables z 1 , z 2 , . . . depending on the observed variables, and conditioning them as depicted in Figure <ref type="figure">6</ref>.4.</p><formula xml:id="formula_92">z 0 z 1 z 2 z 3 x 0 x 1 x 2 x 3</formula><p>Figure <ref type="figure">6</ref>.4: LapCVAE. The graphical model illustrates the dependencies among the observed x i and latent z i variables. The dependency of z i on z i-1 is achieved through concatenation: each latent variable contains the concatenation of all previous ones, plus new dimensions inferred from the two previous generated images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Noise Variance and data resolution</head><p>A first contribution of the presented manuscript is to analyze how the structure of the observation model governs the possibilities of the inference model even under the assumption of a large sample limit and infinite capacity (representation power) of the inference model. This contribution is analyzed in view of the Manifold Hypothesis. A primary remark is that the variance σ of the observation model noise governs the resolution and degree of approximation of the data by the model: the training criterion involves the likelihood of the dataset w.r.t. the model at hand, where the noise amplitude is σ. Accordingly, any data pattern that would be made indistinguishable by this noise amplitude, is lost, for the same reasons as discussed in relation with the Posterior Collapse phenomenon (Section 5.4). In the β-VAE case, increasing β amounts to increasing the variance of the noise, which in turn prevents the learned model from grasping the fine-grained patterns of the data. Eventually, such a high variance results both in defining a blurry model, and reducing the amount of information captured by the latent variable, making it in turn more amenable to disentanglement 6 . The proposed interpretation is backed upon a theoretical result (section 6.3.1). Experiments on synthetic datasets situated on a 1D manifold illustrate the interplay among the model variance (fixed or learned) and the quality of the learned model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Modeling an hypersphere</head><p>The impact of the observation model is examined under three assumptions:</p><p>1. The inference model used to train the VAE is assumed to be exact: q φ (z|x) = p θ (z|x) for all x. Therefore the ELBO is tight, and its maximization boils down to maximizing the likelihood Ex∈D log p θ (x).</p><p>2. The predictor function f θ of the observation model is sought in a hypothesis space with infinite capacity (encoded by a neural network with arbitrary expressiveness).</p><p>3. The optimization process is assumed to reach the exact optimum of the criterion; the dataset is assumed to be an infinite uniform sample on the target manifold.</p><p>Therefore, the VAE only depends on the observation model, a Gaussian observation model with an isotropic covariance matrix σ 2 I, for some fixed value of σ and whose mean is predicted by a neural network f θ .</p><p>Let us further assume that the sought manifold is a hypersphere of radius R of center 0, in dimension D (in R D ).</p><p>Then:</p><p>Theorem 6.1. Under the previously described assumptions, if σ ≥ R √ D-1 , then the global optimum is reached when f θ is a constant function at 0.</p><p>In other words, if the variance σ 2 is too large, the designed VAE will learn nothing of the dataset, even though it has infinite capacity. The proof of this theorem, detailed in Appendix 6.A, consists in analytically characterizing the optimal distribution p θ (x); this characterization is made possible under the considered assumptions. Let µ be the mean of the observation model and output of the predictor neural network f θ . It is shown that, when optimal, the distribution of µ is uniform over an hypersphere of radius r ≥ 0, where r is given by maximizing the following quantity:</p><formula xml:id="formula_93">(r) = e -r 2 2σ 2 π θ=0 exp Rr σ 2 cos θ sin D-2 (θ)dθ (6.5) When σ ≥ R √ D-1</formula><p>, reaches its maximum for r = 0, which concludes the proof of Theorem 6.1.</p><p>The behavior of is illustrated in Figure <ref type="figure">6</ref>.5 (left, for D = 2; right, for D = 10), plotting (r) in the 2D plane given by R/σ and r/σ, with the curve of optimal r depicted in black. It is seen that the optimal r remains 0 until R/σ grows larger than respectively √ 2 and √ 10. The actual threshold is larger than the one given in Theorem 6.1 ( √ D rather than √ D -1). After the threshold, r/σ quickly grows with R/σ, and converges asymptotically to r = R. As σ shrinks to 0, r converges to R. same size, and can afford less precise latent encoding. As a result, it can more easily follow the tendency for disentanglement that a factorized inference model suggests (3.4). In view of the Manifold Hypothesis, Theorem 6.1 establishes that a Gaussian VAE with fixed variance σ 2 is blind to data structures whose radius of curvature is smaller than<ref type="foot" target="#foot_34">foot_34</ref> σ √ D -1. In other words, the VAE is doomed to miss such "details" of the data distribution if their scale is too small compared to its (fixed) variance; the VAE then yields an overly smooth manifold.</p><p>According to this result, the fixed variance of the VAE model σ sets a lower-bound on the smoothness of the manifold the VAE can learn. More precisely, σ defines a trade-off between the noise (missed) and the information (stored in the latent representation): too large, and the fine-grained patterns will be missed; too small and the noise will be stored in the latent representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Experimental study of manifold approximation</head><p>This claim is experimentally supported on a synthetic 2D dataset Figure <ref type="figure">6</ref>.6. A 1D sinusoidal manifold is defined in R 2 , and the synthetic dataset is generated from this manifold with a isotropic Gaussian noise, the amplitude of which varies along the manifold (heteroscedastic distribution).</p><p>A powerful VAE is generated from this dataset along a large sample limit process (10.000 new samples are generated in each epoch) with a Gaussian observation model of various σ values, and an "infinitely powerful" generative model<ref type="foot" target="#foot_35">foot_35</ref> .</p><p>On this synthetic dataset, the relation between the fixed σ and the curvature of the learned manifold can be summarized as follows: For a large σ value, the model yields a smoothed version of the manifold; for very small σ values, the noise is interpreted as part of the manifold, increasing the dimensionality of the latent space. This relation between the approximating manifold and the scale parameter of the observation model and the thresholding effect similar to a phase transition has also been experimentally observed by <ref type="bibr" target="#b154">[RV18]</ref>.</p><p>The precision of the observation model, governing the manifold approximation, also has a dramatic impact on the generative model. The two manifolds x = f θ (z) respectively obtained by reconstruction (z ∼ q φ , Figure <ref type="figure">6</ref>.6) and generation (z ∼ p θ , Figure <ref type="figure">6</ref>.7) differ depending on σ: Both manifolds are very similar when σ is adequate or too large. Quite the contrary, when σ is too small, the latent variable z seemingly fails to adequately capture the manifold, resulting in a poor coverage of the latent distribution p θ (z) by the aggregated inference model q φ (z). This eventually causes the generative process to yield poorly realistic samples.</p><p>It must be emphasized that this failure when σ is small is related to the training dynamics; we shall return to this issue in Chapter 7.</p><p>These remarks establish that, when using a quasi-deterministic observation model, the choice of the noise variance σ is a crucial design point. When considering a model with a fixed isotropic covariance, σ acts as regularization weight, balancing the KL-part of the ELBO (D KL (q φ (z|x) p θ (z))) and the reconstruction term ( Ez∼q φ log p θ (x|z)), as classically done in practice in the VAE literature [Hou+17;   Lar+16; Hig+17; Hua+18; GSS20].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Summary</head><p>The observation model aims at a probabilistic mapping between the space of latent variables and the observed data space. Under the manifold assumption, one might consider instead a quasi-deterministic observation model, involving a deterministic mapping onto the data manifold with an additional small noise. Some examples of this approach, ranging from the Gaussian case to LapCVAE, are described.</p><p>Our claim is that the variance of this added noise governs the identification of the data manifold; as theoretically and experimentally shown (Theorem 6.1, Section 6.3.2), manifold regions with a high curvature compared to the noise variance are smoothed and the details are lost. At the other extreme, a too small noise variance leads the model to encode the data noise, increasing the effective dimension of the learned manifold.</p><p>The key question thus becomes to identify the noise variance: i) based on prior knowledge (e.g. related to known measurement uncertainties); ii) tuned as a model hyper-parameter; iii) or learned as yet another model parameter. The learning dynamics differs widely depending on the chosen option, as will be shown in Chapter 7. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.A Proof of Theorem 6.1</head><p>Proof of Theorem 6.1. Under the assumptions stated in Section 6.3.1, the aim is to characterize p θ (x) = z p θ (x|z)p θ (z)dz at the optimum. The Gaussian observation model is defined by:</p><formula xml:id="formula_94">p θ (x|z) = 1 (2πσ) D/2 exp - 1 2σ 2 x -f θ (z) 2 (6.6)</formula><p>The prediction function f θ can be discarded (e.g. through a change of variable µ = f θ (z)); only the associated distribution p θ (µ) needs to be considered:</p><formula xml:id="formula_95">p θ (x) = 1 (2πσ) D/2 µ exp - 1 2σ 2 x -µ 2 p θ (µ)dµ (6.7)</formula><p>The considered dataset has a spherical symmetry around the origin; the observation model also is isotropic. Therefore at its optimum the distribution p θ (µ) must also have this spherical symmetry, i.e. it only depends on the norm of µ. After normalization, the sought probability distribution thus has the following form:</p><formula xml:id="formula_96">p θ (µ) = q( µ ) A D-1 µ D-1 (6.8)</formula><p>with A D-1 the area of the unit D -1 hypersphere, and q a normalized probability measure ( r q(r)dr = 1).</p><p>Considering the likelihood of the dataset (and dropping constant terms related to q), it comes:</p><formula xml:id="formula_97">L = E x∈D log p θ (x) = x =R log µ q( µ ) µ D-1 exp - 1 2σ 2 x -µ 2 dµ dx + . . . (6.9)</formula><p>Let r be the norm of µ and θ be the angle between x and µ. In spherical coordinates, the exponential can be reformulated as x -µ 2 = R 2 + r 2 -2Rr cos θ. The inner integral on µ depends only on R and θ. The integration on the other D -2 dimensions yields a multiplicative constant that can be moved out of the logarithm. After this rewriting, the contents of the logarithm no longer depends on x, making the outer integral trivial as well.</p><formula xml:id="formula_98">L = A D-1 log +∞ r=0 q(r) π θ=0 exp - r 2 -2Rr cos θ 2σ 2 sin D-2 (θ)dθdr + . . . (6.10)</formula><p>The term in the logarithm is the expectation over q of some function of r, it is thus maximized when q is a Dirac measure at the maximum value of that function. Thus at the optimum, p θ (µ) is the uniform distribution over a hypersphere of center 0. Only its radius r remains to be determined. Maximizing L is equivalent to maximizing the contents of the logarithm: The derivative of yields:</p><formula xml:id="formula_99">d dr = e -r 2 2σ 2 π θ=0 R cos θ -r σ 2 exp Rr σ 2 cos θ sin D-2 (θ)dθ (6.12)</formula><p>Using integration by parts on the R cos θ term, it comes:</p><formula xml:id="formula_100">π 0 R cos θ σ 2 exp Rr σ 2 cos θ sin D-2 (θ)dθ = R (D -1)σ 2 exp Rr σ 2 cos θ sin D-1 (θ) π 0 =0 + π 0 R 2 r (D -1)σ 4 exp Rr σ 2 cos θ sin D (θ)dθ</formula><p>Finally yielding:</p><formula xml:id="formula_101">d dr = r σ 2 e -r 2 2σ 2 π θ=0 R 2 sin 2 θ (D -1)σ 2 -1 exp Rr σ 2 cos θ sin D-2 (θ)dθ (6.13)</formula><p>In particular, if</p><formula xml:id="formula_102">R 2</formula><p>(D-1)σ 2 ≤ 1, the derivative of as a function of r is always negative, implying that it reaches its maximum for r = 0. This means that p θ (µ) is a Dirac-measure at µ = 0, and therefore the predictive function f θ is the constant function 0. This chapter continues the analysis presented in the previous chapter and extending <ref type="bibr" target="#b16">[BS20b]</ref>, showing that in the quasi-deterministic case the variance of the observation model governs the scale of the data patterns that can be modelled.</p><p>The question investigated here concerns how to learn this variance Section 7.1 and its impact on the training dynamics 7.3. Only Gaussian observation models are considered in the chapter for the sake of clarity; the analysis however is general in the sense that it does not rely on the specific structure of the Gaussian model but rather on its quasi-deterministic properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Observation variance fitting</head><p>As said (Section 6.3), an observation model with a too high noise variance prevents the model from capturing fine-grained details of the data. Quite the contrary, a too low variance causes the encoding the "natural" data noise into latent variables.</p><p>Unless this variance is supplied from prior knowledge, it must thus be learned from the data (and even when it is known beforehand learning it is still beneficial, Section 7.3). Two approaches are found in the literature:</p><p>• Considering an isotropic observation model N (f θ (z), σ) where σ is optimized along training [RV18] (Section 7.1.1);</p><p>• Considering an isotropic N (f θ (z), σ(z)Id) or non-isotropic N (f θ (z), D(z)) with D a diagonal matrix, and the scalar or vector noise variance σ(z) being learned by the neural net [KW14; MF18] (section 7.1.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1">Learning a global noise variance σ</head><p>In the case where the sought variance σ 2 is constant over the observation space X ⊂ R D , then its optimization can be done analytically. Let q φ (z|x) denote the inference model, f θ the decoder neural network, with D the dimensionality of the observation space. In this case, σ is only involved in the reconstruction part of the ELBO:</p><formula xml:id="formula_103">E x∈D E z∼q φ (z|x) log p θ (x|z) = -E x∈D E z∼q φ (z|x) x -f θ (z) 2 2σ 2 + D log σ (7.1)</formula><p>Let e 2 = Ex∈D Ez∼q φ (z|x) x -f θ (z) 2 be the average squared reconstruction error. The optimal value σ is thus reached as:</p><formula xml:id="formula_104">σ 2 = arg min σ 2 e 2 2σ 2 + D log σ (7.2)</formula><p>Simple calculations then give:</p><formula xml:id="formula_105">σ 2 = e 2 D (7.3)</formula><p>The optimal variance thus is directly set to the average reconstruction error per coordinate. This result generalizes to non-isotropic observation models, where the noise is defined after a diagonal matrix ∆(σ 1 , . . . , σ D ): variance σ i on the ith coordinate is the average squared reconstruction error of the model on this coordinate 1 .</p><p>Algorithmically, σ can be computed from the average reconstruction error incurred in the current epoch, and updated for the next epoch. This is proposed with good success in the recent article <ref type="bibr" target="#b142">[RDL21]</ref>. In practice however (as said in Section 6.2.1), most articles using a Gaussian observation model consider σ a fixed hyperparameter. Another option is to learn σ by gradient descent like any other parameter, and have it converging to its optimal value. Expectedly, σ gradually decreases along training, as the reconstruction quality improves. This approach appears empirically equivalent to computing the optimal σ at every batch (Figure <ref type="figure">7</ref>.4). The stability and dynamical implications of this process are discussed in Section 7.2 and Section 7.3.</p><p>A third alternative is formulated by the Generalized ELBO with Constrained Optimization (GECO) algorithm <ref type="bibr" target="#b154">[RV18]</ref>, where the search for a VAE proceeds by minimizing the KL divergence in the latent part of the ELBO under the constraint that the average squared reconstruction error be smaller than some prescribed value. This approach is formulated in terms of β-VAE <ref type="bibr" target="#b73">[Hig+17]</ref>, which is in the Gaussian case equivalent to changing the observation variance, as discussed in Section 6.2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Learning a local noise variance σ(z)</head><p>Most interestingly, the seminal paper on VAE <ref type="bibr" target="#b98">[KW14]</ref> advocated the learning of the noise variance as an output of the decoder NNthough this architecture is 1 Full-rank covariance matrix for the observation model is also analytically solvable and leads to Σ = E (x -f θ (z))(x -f θ (z)) T , however such models are generally impractical in high-dimensional data spaces as they require large matrix inversions. also rarely considered in practice. Formally, the decoder neural network yields two vectors of size K, respectively the mean f θ (z) and the (diagonal) variance σ<ref type="foot" target="#foot_36">foot_36</ref> θ (z) of the model. As said, the case of a full covariance matrix has been considered for small input dimensions only.</p><p>The model is trained by gradient descent to maximize the Gaussian log-probability:</p><formula xml:id="formula_106">log p θ (x|z) = - i (x i -f θ (z) i ) 2 2σ 2 θ (z) i -log σ θ (z) i (7.4)</formula><p>This formulation makes it possible to learn different noise amplitudes in different regions of the input space, either reflecting the heteroscedastic noise of the data (as in the artificial example in Chapter 6, Figure <ref type="figure">6</ref>.6(a)), or reflecting the uncertainty of the model to account for the data in the region. In the latter case, the large variance reflects the fact that the model does not know how to handle this sample.</p><p>This gain in expressiveness however comes at a cost in training stability. Depending on the architecture of the underlying neural network and the optimizer, the values of the observation model might vary in a large range, or take extreme values. In such cases the 1/σ 2 θ (z) factor occasionally becomes huge 2 , severely hindering the training process. To avoid this, the parameterization of the neural network should ensure that σ 2 θ (z) be initialized to a reasonably large value, and evolve slowly enough, avoiding abrupt changes from one iteration to the next. We shall return to the impacts of the training dynamics in Section 7.2 and Section 7.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.3">Empirical study</head><p>Considering the artificial dataset introduced in the previous chapter, this section presents an empirical comparison of both options of learning a global or local variance (Figure <ref type="figure">7</ref>.1). The model with a globally optimized value for σ is doomed to find a trade-off, with too low a variance in the high noise regions, and too large a variance elsewhere (Figure <ref type="figure">7</ref>.1(c)). On the contrary, the model where σ(z) is a learned function of z manages to perfectly fit the noise from the dataset (Figure <ref type="figure">7</ref>.1(d)): the generated samples (in green) display the same dispersion as the original dataset (in blue). The goodness of fit is also visible from the ELBO improvement: the model with learned function σ(z) yields 1.62 ± 0.08 while the model with learned global σ only reaches 1.26 ± 0.09.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">The risk of deterministic collapse</head><p>Both schemeslearning the variance either directly or as a function of the latent variableconverge toward setting variance σ 2 to the (possibly dimension-wise) reconstruction error x -f θ (z) 2 . In the former case, σ 2 converges toward the average reconstruction error; in the latter case, σ 2 (z) converges toward the local reconstruction error.</p><p>When considering a quasi-deterministic observation model however, there is a risk of deterministic collapse: if the VAE yields a perfect reconstruction (i.e. f θ (z) = x everywhere), then the optimal value for σ is 0 (Equation <ref type="formula">7</ref>.3), and the ELBO goes to +∞. Note that such a perfect reconstruction entails a high cost in terms of D KL (q φ (z|x) p θ (z)), since the inference model q φ (z|x) is bound to be deterministic as well, making the KL-divergence infinite too<ref type="foot" target="#foot_37">foot_37</ref> . The risk of collapse is explained as follows. In the deterministic limit, both ELBO terms are proportional to the dimensionality of their respective space (data or latent). Typically for a Gaussian VAE, the reconstruction loss is the sum of the squared reconstruction error, and a log-variance term N log σ x . If the reconstruction error is very small, the loss is dominated by the second term, which is proportional to the dimensionality of the input space. The latent KL similarly involves a term which is bounded in the deterministic limit, plus a term of the formi log σ z,i , with i ranging among the latent coordinates. This latter term is proportional to the number of dimensions where σ i is significantly smaller than 1 (the variance of p(z)). In the deterministic limit, the variances go to 0 and the full behavior of the ELBO is dominated by term N log σ xi log σ z,i .</p><p>As a result of this limiting behavior, if the number of effectively used dimensions in the latent space is smaller than N , then the ELBO tends to +∞ as all variances converge to 0, resulting in a model converging to a deterministic auto-encoder while optimizing its objective. This argument is not specific to the Gaussian case, but relies on the fact as q φ (z|x) and p θ (x|z) converge to deterministic distributions, Ez∼q φ log p θ (x|z) grows to +∞ faster than D KL (q φ (z|x) p(x)), which is generally the case if the model manages to compress the dataset at least a little. This risk of collapse, as identified by [RV18; MF18], follows from the fact that training a continuous probabilistic model on a finite dataset is not a well-posed problem, as its optimal solution is a mixture of point masses over the examples. Indeed the ELBO is higher-bounded by the negative entropy of the target distribution. However when considering a continuous observation model, this entropy needs to be computed as a differential entropy. When viewed as a continuous distribution, the entropy of a Dirac is -∞, meaning that the differential entropy of any finite dataset is -∞ as well. This results in an optimization problem where the ELBO is not higher-bounded by a finite value, making it ill-defined and entailing the deterministic collapse phenomenon. This risk has however to the best of our knowledge remained theoretical: the optimizer dynamics and the limitations of the neural network structure generally prevent the model from reliably reaching a perfect reconstruction, preventing in turn a deterministic collapse. However the model is still driven to decrease the observation variance as much as possible to increase its ELBO, as long as its capacity allows it.</p><p>As was analyzed in Section 6.3.2, the variance the model settles on determines the resolution at which it observes the dataset and the amount of detail that is learned in the latent space. It effectively defines the limit between signal and noise, and on a finite dataset the model is driven to consider as much information as possible as signal, as long as it can be compressed at least a little. This is in general counterproductive: as long as the model is expressive enough, it'll be able to learn and compress any noise on a finite dataset <ref type="bibr" target="#b182">[Zha+17]</ref>. In such a dynamic, part of the random noise in the dataset would be interpreted as small but significant signal and stored in the latent space. This could be interpreted as some form of overfitting.</p><p>In some situations, knowledge about the dataset allows to know in advance a lower-bound for any reasonable value of this observation variance: the uncertainty of the measurement apparatus that produced the data could be known, or smaller details are deemed irrelevant for the task at hand (for example, details that are invisible to the human eye can be irrelevant in a task of image generation). In such cases it seems natural to ensure that the model will not converge to a variance that is smaller than this lower bound, to avoid putting unnecessary pressure on the latent encoding.</p><p>We propose here two simple methods to achieve that. The first method is to parameterize the learning process of the variance such that it cannot decrease below it<ref type="foot" target="#foot_38">foot_38</ref> , effectively making this part of the optimization space unreachable for the model. The second method is to augment each training batch with a Gaussian noise with variance equal to said lower-bound. This noise will not be compressible by the model (as it is a real, infinite noise), preventing it from storing it in the latent space. That added noise can also have a regularization behavior on the inference model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">The dynamics of variance learning as an annealing process</head><p>Chapter 6 illustrates the dramatic impact of the observation variance on the approximation of the data manifold, governing the latent representation. This impact is investigated in more depth, focusing on the case where the variance is learned. A lesion study is conducted, by comparing the observation modelwhere the scalar σ converges toward σ = 0.043 -with the eventual observation model obtained when setting σ to this same value. Unexpectedly, the latter model (fixing σ = 0.043) fails to correctly characterize the data manifold, as illustrated in Figure <ref type="figure">7</ref>.2.</p><p>The fact that the variance is learned is conjectured to significantly modify the learning dynamics. More specifically, our tentative interpretation is as follows: initializing σ to a large value and letting the training process learn it plays a regularization role comparable to an annealing process, akin KL-annealing <ref type="bibr" target="#b113">[Luc+19]</ref>.  Formally, starting with a large σ causes the model to first learn a most simple representation of the data, as discussed in Section 6.3.2. This simplistic representation is very easy to efficiently compress into the latent space, and the model promptly learns an efficient representation. This representation allows the reconstruction quality to be decent enough to afford decreasing σ; the smaller σ in turn enables the model to be aware of smaller details, that are gradually accounted for in the latent representation.</p><p>In contrast, freezing σ to a small value puts a large initial weight on the reconstruction part of the ELBO (the 1/σ 2 term dominates), making the model minimizing its reconstruction loss at all cost. The optimization, thus entirely driven by local reconstruction quality, fails to establish a global coherent structure on the latent space. As a result, the model remains stuck in a local minima with a poorly organized latent representation.</p><p>This interpretation is further assessed by comparing the loss trajectories (Figure <ref type="figure">7</ref>.3). The training dynamics significantly differ in both cases of learned versus fixed σ, as follows: when σ is learned, the data information is gradually accounted for in the latent space, causing the latent loss (Equation 3.3) to gradually increase while the reconstruction loss gradually decreases, resulting in a gradual reduction of the negative ELBO. On the opposite, the model with fixed σ = 0.043 suffers a very high reconstruction loss from the start; it quickly reduces it and quickly converges, hardly improving its loss past the first 5 epochs. Note that the gradual dynamics of the losses when σ is learned strongly correlates with the evolution of the value of σ itself, as illustrated on Figure <ref type="figure">7</ref>.4.</p><p>As said, this gradual decrease of σ, viewed as an annealing process, seems to benefit to the shaping of the latent space of a quasi-deterministic observation model. By gradually increasing the amount of detail available to the model, it allows an incremental refinement of the latent representation, which in turn allows the model to converge to a more efficient latent space. The simplest way to achieve this annealing is by having σ be initialized to a large value (of the order of the total variance of the training data), and letting the model learn its value gradually, as discussed in How the final value of the ELBO depends on the fixed value of σ versus learned σ is illustrated on Figure <ref type="figure">7</ref>.5. 50 independent runs with fixed σ log-uniformly drawn in interval [0.01; 1] have been done. The eventual optimal ELBO shows a bell curve w.r.t. σ, reaching its optimum for σ ≈ .1 (in blue, Figure <ref type="figure">7</ref>.5). Likewise, 10 runs have been launched to optimize the ELBO with a global learned σ, showing that: i) the variance of the eventual ELBO value is very low (all runs converge toward very close optimal σ); this optimal σ value (.043) is significantly lower than the optimal value for the runs with fixed σ (in red, on Fig. Figure <ref type="figure">7</ref>.5). Last, 10 runs have been launched with σ learned as a function of the latent variable z, and for each run, the range of these optimal σ is depicted as a segment (in green on Fig. Figure <ref type="figure">7</ref>.5). To reflect the prediction of multiple different σ values by these last models, the cumulative distribution of these prediction for one such model is presented in Figure <ref type="figure">7</ref>.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Summary and perspectives</head><p>This chapter presents two results concerning the variance of the observation model in the quasi-deterministic case.</p><p>Firstly, for a given predictor function f θ (z) and inference model q φ , the optimal value of the variance (w.r.t. the ELBO optimization) is the average squared error of the VAE reconstruction<ref type="foot" target="#foot_39">foot_39</ref> . The associated risk of deterministic collapse is analyzed. While this risk is hardly met in practice, it might lead to retain a variance lower than would be appropriate. Two heuristics counter-acting this effect are discussed.</p><p>Secondly, a proof of concept is presented, suggesting that learning the variance might have beneficial effects beyond finding the appropriate value. Most interestingly, enabling the VAE to learn the variance allows the model to gradually build and  compress the latent representation, increasing the amount of detail stored in the latent space, until reaching the point where all remaining information would be more expensive to store in the latent space than the gain provided in terms of reconstruction quality. Overall, this learning dynamics is viewed as an annealing process, adequately separating the noise from the information to the extent permitted by the model capacity.</p><p>A perspective for further study thus consists in inspecting how the latent space forms its structure, and how it manages (or fails) to reflect the topological structure of the dataset. Our contribution, showing the impact of the training dynamics, suggests to investigate the adaptive balancing of the reconstruction and the compression efforts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.A Observation tempering and link with β-VAE</head><p>Chapter 6 detailed the equivalence between setting a fixed variance to a Gaussian observation model and the introduction of a weighting factor between the "reconstruction" and "latent" parts of the ELBO. While this equivalence is no longer true when the variance is a learned parameter<ref type="foot" target="#foot_40">foot_40</ref> , in essence the comparison is still applicable, this section will explicit how.</p><p>The β-VAE <ref type="bibr" target="#b73">[Hig+17]</ref> can be compared to defining the global generative model as:</p><formula xml:id="formula_107">p θ (x, z) ∝ p θ (x|z) 1/β p θ (z) (7.5)</formula><p>By analogy with the tempered posteriors of Bayesian inference, we will refer to this as observation tempering. It is important to note that this observation tempering is not the same as the β-VAE, as the later does not take into account the normalization factor of the modified observation model (which depends on z, θ and β). This is a situation similar to the one analyzed by <ref type="bibr" target="#b103">[LC19]</ref>. After studying the impact of observation tempering, we will explicit how it can be compared to the proper β-VAE.</p><p>Tempering the observation model with β &gt; 1 makes it blurrier, converging to a uniform distribution in the limit β → ∞. It is to be expected that the analysis of Section 6.3 will overall still apply here. As β increases, the model becomes more and more blind to fine details and highly-curved regions of the data manifold. On the opposite, tempering the observation model with β &lt; 1 makes it sharper than it normally is, with all the opposite effects as illustrated on Figure <ref type="figure">7</ref>.7. If the observation model is allowed to learn some scale parameter, it is to be expected that it will converge to a different value of it, compensating the tempering to some extend<ref type="foot" target="#foot_41">foot_41</ref> .</p><p>The relation of β-VAE to observation tempering is that the former does not take into account the renormalization. Let pβ represent the tempered version of some base distribution p. It is defined by the following identity in log-probabilities, including the normalization term:</p><formula xml:id="formula_108">log pβ (x) = 1 β log p(x) -log p(x) 1/β dx (7.6)</formula><p>Now, when considering the gradient of the distribution relative to some value λ (which can be either a model parameter or the value of another variable of the model), the normalization factor gives rise to a non-zero gradient term: Isolating the gradient as computed by β-VAE:</p><formula xml:id="formula_109">∇ λ log pβ (x) = 1 β   ∇ λ log p(x) -E x∼p β ∇ λ log p(x)   (7.7)</formula><formula xml:id="formula_110">1 β ∇ λ log p(x) β-VAE gradient = ∇ λ log pβ (x) tempered observation gradient + 1 β E x∼p β ∇ λ log p(x) (7.8)</formula><p>The gradient guiding β-VAE can thus be seen as an approximation of the gradient guiding the tempered observation with an additional term. The analysis of this term will explicit the relation between the two formulations.</p><p>The second term of Equation <ref type="formula">7</ref>.8 is very similar to a known identity<ref type="foot" target="#foot_42">foot_42</ref> , which is recovered when β = 1:</p><formula xml:id="formula_111">E x∼p ∇ λ log p(x) = 0 (7.9)</formula><p>As β is changed from 1, the gradients in the expectation are reweighted relative to each other, changing the result. In particular, when β &gt; 1, the tempered distribution pβ is more spread-out than the original distribution p. This affects the expectation such that gradient terms in low-probability regions are over-represented, while gradient terms in high-probability regions are under-represented. With each point-wise gradient directing the distribution towards increasing the probability at this point, they thus combine into a global gradient that tends to increase the spread of the distribution further. A symmetric reasoning can be done when β &lt; 1, in which case pβ is more concentrated than p, and the resulting gradient drives the distribution overall towards being even more concentrated.</p><p>Finally, Equation 7.8 can be read as follows: the gradient guiding the training in β-VAE is similar to the gradient guiding a tempered observation with the same β, with an additional term that accentuates the effect of β (spreading the distribution when β &gt; 1 and concentrating it when β &lt; 1). This second terms thus prevents the model from effectively compensating the tempering of the observation model by learning different parameters.</p><p>As an illustrative example, consider a single-dimensional Gaussian observation of learned variance σ 2 . In this case, the additional term can be computed analytically:</p><formula xml:id="formula_112">1 β ∇ λ log p(x) = ∇ λ log pβ (x) + β -1 β ∇ λ log σ (7.10)</formula><p>In this case, the β-VAE formulation drives the model towards increasing the chosen σ 2 if β &gt; 1, compared to the usual Gaussian observation<ref type="foot" target="#foot_43">foot_43</ref> . The general interpretation thus holds overall: the β-VAE alters the convergence of the observation model in the training dynamics. When β &gt; 1, it forces the model to use a smoother observation model than the natural ELBO would converge to, with the consequences explored in Section 6.3. In particular, the higher the β, the more the model is blind to details of the data manifold. This results in less information encoded in the latent variables, and blurrier reconstructions and generations in the context of images. All of this is in accordance with the empirical results observed by <ref type="bibr" target="#b73">[Hig+17]</ref>. While the previous chapters focus on the design of deep LVMs, aimed to reflect the data via the observation model, this chapter focuses on the design of Deep LVMs and their latent structure, to enforce model properties guided by either epistemic considerations about the data, or the intended use of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Properties of latent structures</head><p>After describing how such properties have been enforced in the literature, either by integrating a deep LVM into a larger model (Section 8.1 &amp; 8.2), or by carefully designing its latent structure (combining probabilistic and deterministic variables, Section 8.3), this chapter describes our contribution related to anomaly detection in the context of the Compact Muon Solenoid (CMS) experiment at CERN <ref type="bibr" target="#b139">[Pol+19]</ref>. A conditional deep LVM is there used to detect and distinguish two different kinds of anomalies, by leveraging its latent structure (Section 8.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Generative classifiers for robustness</head><p>This section focuses on the use of generative models for classification.</p><p>The dominant classification approach is discriminative, that is, the ML model is trained to directly approximate P (Y |X = x), the conditional distribution of the class label Y given the description x of an example (Figure <ref type="figure">8</ref>.1(a)). This approach faces a major challenge: the quality of the learned approximation for a given example x dramatically depends on how close this example is to the training dataset, with little means to evaluate the quality of said approximation a priori <ref type="bibr" target="#b168">[Sno+19;</ref><ref type="bibr" target="#b125">Nal+19b]</ref>. The actual classification is then achieved by selecting the y value making x most likely. On this two-node model, this amounts to applying Bayes' Theorem: p(y|x) ∝ p(x|y)p(y) using the conditional generative model and a prior p(y) on the class labels. Under the assumption of independence of X features, this yields the well known Naive Bayes classifier, delivering in practice surprisingly good results (despite this assumption to generally be unrealistic) <ref type="bibr" target="#b43">[DP97;</ref><ref type="bibr" target="#b83">HY01]</ref>. The general Bayes principle can also be applied to more complex generative models including latent variables. For instance, in <ref type="bibr" target="#b161">[Sch+18]</ref> one VAE per class is trained, and then a tight ELBO estimation of log p(x|y) is computed at test time.</p><p>The generative approach is significantly more computationally expensive than the discriminative one, as it requires the computation of a conditional query on a graphical model. Its main merit is its robustness property. The prediction of a generative classifier combines a prior (where the prior p(y) can be simply estimated from the class frequencies in the training data) p(y) and the generative likelihood for each class p(x|y). Its behavior can thus be thought of in terms of mixture models, making it less prone to overfitting than discriminative classifiers. Indeed, examples far from the training set are expected to yield low generative probabilities p(x|y) for all classes, resulting in a final prediction somewhat close to the prior. Furthermore, this setting makes room for evaluating the probability of the sample p(x), that can be used to estimate how close this example is to the training dataset. This makes it possible to discard examples with a very low probability, enabling the classifier to abstain instead of reporting a low confidence classification.</p><p>These two properties of resistance to overfitting and identification of untypical examples have been experimentally and thoroughly explored in <ref type="bibr" target="#b102">[LBS19]</ref>. This article compares several structures of generative and discriminative classifiers against state of the art adversarial attacks. The effectiveness of different methods to detect such adversarial attacks are also compared. Their conclusions are that generative classifiers are indeed less prone to making confident but wrong predictions, and that even when they do, the evaluation of p(x) is a robust way to detect out-of-distribution examples.</p><p>This last issue, the detection of out-of-distribution examples, is still debated in the state of the art. The simplest method of detecting out-of-distribution samples, thresholding p(x), has been empirically shown to be unreliable in high-dimensional data spaces: out-of-distribution samples can have a higher probability assigned by the model than actual samples from the training dataset. Indeed the curse of dimensionality makes the probability density a poor indicator of whether a given sample does lie in the typical set of a distribution. This phenomenon and its implications are notably analyzed by [Nal+19b; CJA19; Nal+19a]. We shall return to this point in Section 8.4. How to use generative classifiers for detecting out-of-distribution samples has been further examined within the Linear Discriminant Analysis (LDA) framework: by introducing a Gaussian assumption on the form of the generative models p(x|y), the application of Bayes' Theorem is reframed as finding the class that minimizes a distance in a feature space previously learned by a discriminative classifier, improving the prediction robustness <ref type="bibr" target="#b106">[Lee+18]</ref>. Notably the introduction of a learned covariance matrix for the Gaussian model allows to geometrically reshape the latent space, improving the quality of the used distance function. In this framework, <ref type="bibr" target="#b135">[PDZ18]</ref> further proposes to directly learn the feature space in which LDA is performed, rather than rely on a previously trained one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Semi-supervised learning with VAEs</head><p>This section focuses on the combined used of labeled and unlabed data, to support a more robust classification approach.</p><p>Semi-supervised learning (SSL) encompasses diverse algorithms, able to harness a (supposedly large) unlabeled dataset to improve the predictive capacity of a model trained on a smaller labeled dataset. SSL relies on the assumption that unlabeled data yield meaningful information about the domain structure, such as the presence of natural clusters, which can be used for the prediction task. Many such methods consist in implicitly labeling the unlabeled samples, for example by propagating labels from the labeled ones using geometrical properties.</p><p>The so-called Generative semi-supervised model (M2) procedure, proposed in <ref type="bibr" target="#b95">[Kin+14]</ref>, consists in jointly training a classifier and the inference model of a Deep LVM, that is itself trained on both the labeled and unlabeled dataset.</p><p>Consider the 3-node LVM represented in Figure <ref type="figure">8</ref>.2(a), where the X node represents the data, Y its label, and Z an abstract latent variable. This model, factored as p θ (x, y, z) = p θ (x|z, y)p θ (y)p θ (z), is trained simultaneously on labeled and unlabeled data using two different inference models.</p><p>On labeled dataset D, the model is trained using Y and X as observed variables, combined with an inference model q φ (z|x, y), represented as Figure <ref type="figure">8</ref>.2(b). Applying the ELBO on this model yields the following training objective:</p><formula xml:id="formula_113">L labeled = (x,y)∈D   log p θ (y) + E z∼q φ (z|x,y) log p θ (x|z, y)p θ (z) q φ (z|x, y)   (8.1)</formula><p>The above loss, decoupling p θ (y) from the rest of the generative model, makes it to reflect the probabilities of the different classes in the dataset. Independently, the other two parts of the model p θ (x|z, y) and p θ (z) are trained jointly as a conditional VAE to reflect the distribution of X given Y .</p><p>When considering the unlabeled dataset U, the inference model is augmented with a component q φ (y|x) predicting y, yielding the model presented in Figure <ref type="figure">8</ref>.2(c). The associated ELBO training objective is thus:</p><formula xml:id="formula_114">L unlabeled = x∈U E y∼q φ (y|x)   log p θ (y) q φ (y|x) + E z∼q φ (z|x,y) log p θ (x|z, y)p θ (z) q φ (z|x, y)   (8.2)</formula><p>Note that the expectation over Y cannot be evaluated using the reparametrization trick as Y is a discrete variable. It is thus computed exactly, evaluating the ELBO of the conditional generative model for each possible value of the label Y , and weighting these values according to q φ (y|x).</p><p>Lastly, the q φ (y|x) part of the inference model acts as a probabilistic classifier. This most interesting part, trained (after Equation <ref type="formula">8</ref>.2) to approximate<ref type="foot" target="#foot_44">foot_44</ref> p θ (y|x), can be seen as a generative classifier based on the Deep LVM p θ . The whole approach thus builds a generative model consistent with both the labeled dataset D and the unlabeled dataset U, by maximizing the joint objective L labeled + L unlabeled , and delivers q φ (y|x), a good approximation of the generative classifier defined by this model.</p><p>Moreover, one can also directly train q φ (y|x) as a regular classifier on the labeled dataset <ref type="bibr" target="#b95">[Kin+14]</ref>, introducing a third term in the overall loss with hyperparameter weight α, and considering the full training objective L labeled + L unlabeled + α L classifier .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Combining probabilistic and deterministic latent variables</head><p>This section is interested in the modeling of structured data, focusing on the particular case of temporal data and the identification of the underlying dynamics of the considered system. The claim is that such models are more effectively identified by combining probabilistic and deterministic variables.</p><p>As will be shown in this section, a finer control of the latent representation can be obtained through introducing deterministic variables in the graphical model. Such variables play a very different role compared to the probabilistic ones: they do not appear in any density distribution and they only affect the training objective indirectly, by guiding the information flow through the model, as illustrated by the Deep Variational Bayes Filter <ref type="bibr" target="#b89">[Kar+17]</ref>.</p><formula xml:id="formula_115">z t+1 z t z t+2 u t x t+1</formula><p>(a) Generative model The model, aimed to learn the behavior of a controlled dynamical system, is trained from a sequence (x t , u t ), with x t the observed state of (resp. u t the control applied on) the system at time step t. For instance, x t might stand for the location of the considered vehicle, and u t for the amplitude of acceleration and steering angle. A natural modeling approach is to introduce a sequence of latent variables z t akin a hidden Markov model (Figure <ref type="figure">8</ref>.3). However, <ref type="bibr" target="#b89">[Kar+17]</ref> notes that this model structure puts the stress on accurately reconstructing x t from z t (in the auto-encoding step of ELBO training); but empirically, it fails to accurately capturing the desired dynamics of the z t sequence.</p><formula xml:id="formula_116">z t+1 z t z t+2 u t x t+1 (b) Inference model</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.1">Failure of the fully probabilistic approach</head><p>The overall approach, as depicted in Figure <ref type="figure">8</ref>.3, assumes the Markovian property of the z t sequence: z t is supposed to yield all necessary information for predicting x t , as well as, together with u t , predicting z t+1 . While <ref type="bibr" target="#b89">[Kar+17]</ref> report that this is not the case, they offer no tentative interpretation for this failure. This failure is unexpected as one might think that minimizing the gap between the prediction of the inference and generative models corresponds to an optimal ELBO.</p><p>Let us suggest a tentative interpretation for this failure, based on analyzing the training dynamics along the same lines as in Section 7.3.</p><p>In the early training stage, the optimization process is generally mostly driven by the reconstruction term of the loss (as discussed in Section 7.3), that drives p θ (x t |z t ) and q φ (z t |x t , z t+1 , u t , u t+1 ) along an auto-encoding scheme. This causes the model to store into z t all information needed to reconstruct x t on a per-timestep basis. In a further stage, when the reconstruction loss is decent enough, the reconstruction term of the loss no longer dominates, and the optimization process should ideally proceed to compress the latent representation, taking advantage of the Markov relation between the z t variables.</p><p>However, at this stage, z t is unlikely to contain the necessary information for predicting z t+1 , as it has mostly been optimized for predicting x t . If the system involves some latent information required for (short or long term) prediction, that is not required for instant prediction (of x t ), then p θ does not have access to this relevant information, preventing the prediction of z t+1 given z t and u t . In essence, the model is stuck in a local minimum where it misses the temporal relation between the variables. In the exemple of the vehicle dynamics, x t contains the location of the vehicle; but in order to predict its dynamics, one needs z t to encode both its location and its momentum. If the latter information is missing, one cannot predict z t+1 from z t .</p><formula xml:id="formula_117">z t+1 z t z t+2 u t β t x t+1 (a) Generative model z t+1 z t u t β t x t+1 (b) Inference model</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.2">Deep Variational Bayes Filter</head><p>The above issue can be avoided by modifying the structure of the generative model, and making the latent variables z t deterministic, as proposed by <ref type="bibr" target="#b89">[Kar+17]</ref>, with</p><formula xml:id="formula_118">z t+1 = f (t) θ (z t , u t , β t )</formula><p>where β t is a latent variable accounting for the stochasticity of the overall dynamics (Figure <ref type="figure">8</ref>.4). The variable z t+1 is the only input of the decoder p θ (x t+1 |z t+1 ), thus to achieve good prediction of x t+1 during training, z t+1 must contain all the necessary information. In turn, z t+1 being a deterministic variable, the inference model q φ does not directly predicts its value, the information pressure thus flows up to the parents of z t+1 : the triplet (z t , u t , β t ) must contain the necessary information to predict z t+1 (and thus x t+1 ).</p><p>Note that this new formalization radically changes the training dynamics: the z t now being deterministic variables, the ELBO no longer penalizes storing information into them (as opposed to β t ). The training objective thus enables storing as much information in z t as needed to predict z t+1 , ensuring a good modeling of the system dynamics 2 . The good experimental results confirm the merits of the approach, combining probabilistic and deterministic latent variables: within this formalization, <ref type="bibr" target="#b89">[Kar+17]</ref> accurately model the dynamics of simple physical systems, such as a pendulum or a ball bouncing in a box, and can predict dynamics of the system on timelines significantly longer than the length of training sequences. However to the best of our knowledge, evaluation of this approach on more complex problems 2 To enforce the interpretability of the latent representation, <ref type="bibr" target="#b89">[Kar+17]</ref> further requires f (t) θ to be a mixture of linear functions of zt, ut and βt. Formally, the matrices encoding these linear functions are globally learned as function of t, and the mixture parameters are learned functions of (zt, ut) (but not directly of t).</p><p>remains to be done: <ref type="bibr" target="#b89">[Kar+17]</ref> heavily rely on the fact that the dynamical equation of their test systems can be represented linearly in the latent space.</p><p>This experiment illustrates how a change of the latent structure in the generative model can have a dramatic impact on what can be learned. Using deterministic variables as the backbone of the recurrent structure rather than a Markovian construct allows the gradient information to flow much more efficiently through the model, thus avoiding local optima where the temporal relation is not learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Typed anomaly detection</head><p>As discussed in Section 8.1, LVMs can to some extent be used to detect out-ofdistribution samples. I applied this property to achieve anomaly detection in the domain of particle physics, in collaboration with Adrian Alan Pol <ref type="bibr" target="#b139">[Pol+19]</ref>. The context of application is the Compact Muon Solenoid (CMS), a large detector on the Large Hadron Collider (LHC) at CERN, tasked with detecting particles from high-energy physics experiments. The CMS notably took part in the confirmation of existence of the Higgs Boson.</p><p>The CMS trigger system aims to prune the raw data stream from the particle detectors to manageable amounts by filtering out non-interesting events. It is made of a number of rules that can be evaluated online and triggered depending on the content of the events; it governs whether these events will be retained for further analysis. The experiment produces around 40 million events per second, which is much too large an amount of data for exhaustive processing. A first level of fast hardware-implemented filters (named L1 triggers) reduces this to 100 thousand events per second. Then a second level of software triggers (named High level trigger (HLT)) further reduces this to 1000 events per second. Each HLT processes the events selected by a pre-defined subset of L1 triggers, making a hierarchical relation between L1 and HLT.</p><p>The CMS system is hierarchical, with a second layer of (more complex) trigger rules exploiting the events of the first (simpler) ones.</p><p>The applicative goal is to detect anomalies in the measurement data streams to identify hardware or software failures in the CMS trigger system. Failures can expectedly be detected by observing unusual rates of acceptance in the triggers <ref type="bibr" target="#b140">[Pol20]</ref>.</p><p>This anomaly detection task has two specific features: i) two kinds of anomalies need to be distinguished; ii) the anomalous status of a datapoint is context-dependent.</p><p>These features can be efficiently accounted for in a specific deep LVM, as will be detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.1">The two kinds of anomalies</head><p>In the following, each datapoint is a vector of numerical values. In the context of the CMS data, each of these values correspond to the trigger rate of a single filter during a physical experiment. As the triggers are related by a hierarchical relation, depending on where the fault occurs (at the level of a L1 trigger, or at the level of a HLT) the final vector of trigger rates is affected differently.</p><p>The first kind of anomaly, referred to as type A anomaly, manifests itself as a large change of value in a single feature of the vector. The second kind of anomaly, referred to as type B anomaly, manifests itself as a small but correlated change over a group of features. Both types of anomaly can be emulated in an LVM in a natural way, via perturbing different variables in the generative process. A type A anomaly corresponds to a perturbation of a single observed variable, while the generative process is untouched as a whole. A type B anomaly can be thought of as perturbing a single latent variable, with cascading consequences, leading to a host of small correlated changes at the observation level. In relation to the CMS data, Type A anomalies are anomalies related to a fault in a single HLT, while Type B anomalies are linked to a fault at the L1 level, cascading over to all HLT feeding on this particular L1 trigger.</p><p>More formally, the behavior of the LVM on anomalous observations differs depending on the kind of anomaly.</p><p>Type A anomalies are generally errors that cannot be modeled by the generative model, as they do not fit the generative process of the training data at all. It is thus expected that the auto-encoding process would fail to account for these anomalies.</p><p>As a result, the reconstruction term of the ELBO, Ez∼q φ log p θ (x|z), would have a value much lower than for regular data.</p><p>On the other hand, type B anomalies would somewhat align with the generative process and the inference model might reflect type B anomalies through slightly modifying the latent variable values according to the existing generative process (p θ (x|z)). In this case, the reconstruction term of the ELBO would have a usual amplitude, but the inferred values for the latent variables would cause a very low probability for the latent term Ez∼q φ log p θ (z).</p><p>In a nutshell, the general intuition is that when evaluating the ELBO on an anomalous datapoint, at least one of the variables of the model will take an unexpected value. Depending on which variable does, one can identify the kind of anomaly presented to the LVM. Furthermore the (usual) dimensionality reduction from X to Z alleviates the curse of dimensionality encountered when assessing whether the variable is out-of-distribution.</p><p>In <ref type="bibr" target="#b139">[Pol+19]</ref> we focus on a model with a single latent variable Z and a single observed variable X; both are multi-dimensional Gaussian variables whose dimensions depend on the problem considered. The definition of what counts as a Type B anomaly amounts to putting a threshold on the value of the latent KL divergence, D KL (q φ (z|x) p θ (z)), while Type A anomalies are found by comparing the real feature vector x to the one predicted by the observation model µ θ (z), and rescaled by the predicted standard deviations σ θ (z). This amounts to computing the max norm of the difference vector (i running on the dimensions of the space):</p><formula xml:id="formula_119">max i |x i -µ θ (z) i | σ θ (z) i (8.3)</formula><p>That criterion is triggered if a feature of the vector x deviates from the predicted value µ θ (z) significantly more than the predicted standard deviation σ θ (z), allowing e.g. to characterize 3-sigma deviations (being reminded that type A anomalies intervene on a single coordinate of the observations). Limitations. The potential limitation of the approach is twofoldalthough these limitations were not experimentally encountered in <ref type="bibr" target="#b139">[Pol+19]</ref>. The first limitation (regarding the detection of type B anomalies) lies in assessing whether the KL term is unusually high (log p θ (z) unusually low). As discussed in Section 8.1, the use of the log-likelihood is not always a good indicator, especially in high-dimensional spaces [Nal+19b; CJA19; Nal+19a]. However, the fact that one considers here the latent Z as opposed to the observed X alleviates this issue.</p><p>The second limitation is when, even though the ELBO presents an abnormally low value, the gap is equally spread among several variables, making it impossible to precisely identify the faulty variable. This situation might arise in a hierarchical generative process where several nodes take a slightly unusual value, and their combined effects lead to a very unexpected end result. The question of whether these cases should be treated as anomalies or not is generally problem-dependent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.2">Conditional anomaly detection</head><p>In order to detect malfunctioning sensors at the CERN, another constraint needs to be considered: the question of whether a datapoint is an anomaly or not depends on some external factors, K, e.g. reflecting the nature of the ongoing LHC experiments. Depending on the current experiment, we have some expectations about the behavior of the trigger system.</p><p>Accordingly, the data distribution should be learned as p θ (x|k), prompting for the use of a conditional deep LVM (Figure <ref type="figure">8</ref>.5).</p><p>This conditional formulation plays a crucial role in the use of this model for anomaly detection. As discussed in Section 8.4.1, K should rather be viewed as a deterministic variable, available to both generative and inference models. This ensures the model uses Z to only encode the relevant information not already contained in K. This role of Z is enforced by the KL term of the ELBO, that drives q φ (z|x, k) (and thus p θ (z|x, k) as well, Section 3.4) to be as close as possible to the fixed latent distribution p(z).</p><p>The KL information pressure is such that Z is as parcimonious as possible, thus avoids duplicating any information already contained in K, 3 as long as the decoder 3 The value of the latent KL loss of a VAE can be interpreted as the amount of information the decoder has to specify to distinguish the particular sample at hand in the whole generative latent distributionp θ (z). ELBO training thus drives the model to build a latent representation which allows this using as little information as possible. It follows from this that any information provided to the model via the K variable but still encoded in Z by the inference model will cause an ELBO penalty compared to the optimal model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.3">Empirical validation</head><p>This method for anomaly detection was empirically validated on both toy examples (a synthetic dataset, MNIST, and Fashion-MNIST) as well as the proprietary data from the CMS experiment <ref type="bibr" target="#b139">[Pol+19]</ref>, confirming the above considerations as follows.</p><p>The Conditional VAE is referred in the figures as CVAE.</p><p>In the context of the MNIST and Fashion-MNIST datasets, the notion of conditional anomaly is intuitively defined as an image that does not look like its class, either due to a labeling error, or because the image is fundamentally borderline (for example, a very deformed digit, which can be hard to classify). It is observed that the conditional VAE (CVAE, in Figure <ref type="figure">8</ref>.6) does detect such examples as type B anomalies, and that this classification strongly correlates with the uncertainty of a classifier trained on the same dataset: anomalous datapoints are the most difficult ones to classify. In particular, one observes that the conditional part of the VAE significantly improves the anomaly detection, further backing the claim that it is easier for the model to decide whether an image is weird-looking when knowing its alleged class.</p><p>The tests on the synthetic and CMS data allow one to assess the behavior of the model of type A and type B anomalies compartively to the ground truth (Figure <ref type="figure">8</ref>.7). The synthetic data used 100-dimensional X values, generated from a 5-dimensional K external factor. In the case of the CMS data, X is composed of the trigger rates of 24 HLT, while K is composed of the trigger rates of the 4 L1 triggers that feed them.</p><p>It is observed that type A anomalies are very easy to detect (being of large amplitude in both datasets), while type B anomalies are more challenging. However, the conditional VAE significantly outperforms the vanilla VAE, illustrating the positive impact of using K and letting the latent variable Z focus on the anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Summary</head><p>This chapter focuses on the design of latent structures in order to achieve different goals: supervised and semi-supervised learning; structure-based learning; and anomay detection.</p><p>Classification can be achieved by the use of conditional generative models in the context of generative classification, producing models that are more resilient to adversarial attacks and out-of-distribution samples, by avoiding unreasonably confident predictions, making it easier to detect anomalous examples and abstaining from classifying them. The integration of the conditional generative model in a larger structure <ref type="bibr" target="#b95">[Kin+14]</ref> allows to expand this construct to semi-supervised learning, and train a discriminative classifier using the generative one as a teacher. This approach also nicely illustrates how multiple datasets with different observed variables can be used to jointly train a single model.</p><p>Regarding data structures, the introduction of deterministic latent variables in the LVM <ref type="bibr" target="#b89">[Kar+17]</ref> can significantly impact the training dynamics of the model, and allow finer control over the flow of information through the variables. In particular, sequential models can more efficiently learn temporal dependencies through a backbone of deterministic variables, rather than probabilistic ones for which the training dynamics can easily get stuck in local minima.</p><p>Finally, formulating the question of anomaly detection in the context of generative graphical models enables to finely distinguish among different types of anomalies. In the presented contribution <ref type="bibr" target="#b139">[Pol+19]</ref>, we show that the generative model (via the inference model) can be structured so as to distinguish several parts in the data producing system, here enabling to identify faulty behavior from two different systems in the CMS experiment at CERN. The ability of deep LVMs to represent data using low-dimensional variables also seems to make them more robust to the curse of dimensionality. This chapter describes our second main scientific contribution, the Compositional Variational Autoencoder (CompVAE), first presented in <ref type="bibr" target="#b15">[BS20a]</ref>. This contribution originates from the context of smart energy policy design and infrastructure dimensioning. More precisely, the goal is to generate the electrical consumption curves aggregating the consumption of a few dozen households, based on little metadata information about these individual households, under various usage scenarii. The difference, compared to other approaches related with residential consumption forecasting [Cia+13; Ort+14; Zha+18], is that the latter aim to precise short or midterm forecasting built on probabilistic models of electrical consumption of individual appliances.</p><p>The considered goal was formulated and addressed at a general level: define compositional models, trained from and able to generate whole instances, involving a varying number of entities. In other words, the point is to define a programmable probabilistic simulator, trained from aggregated instances. The presented approach, tackling the compositional generative goal, faces three challenges: Firstly, the number of households is not fixed in advance, and the model needs to potentially accommodate a large number (a few hundred) of households based on their metadata. Secondly, the aggregated consumption should be invariant w.r.t. permutation of the 115 households.</p><p>Thirdly, the aggregated model should account for the fact that the individual curves are not independent: they are all conditioned by same global factors, e.g. weather or holidays.</p><p>These requirements are addressed using a generative model conditioned by a multi-set<ref type="foot" target="#foot_45">foot_45</ref> , hence the name Compositional Variational Auto-Encoder. This approach is more generally designed to enable generating instances of some "whole" based on a multi-set description of its parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">A latent space supporting composition</head><p>A main specific requirement of the tackled problem is to control the generated output based on a multi-set, denoted { i }. As detailed in Section 5.2.1, quite a few Latent Variable Models can handle sequential data [FA15; Bow+15; Chu+15; Fra+16; OKK16; Oor+16b]. The goal here is to ensure that the eventual generated output does not depend on the arbitrary order on the i elements, that is, achieving a permutation-invariant representation: the behavior of the model is not affected by a permutation is applied on its inputs. Encoding such invariances in the structure of the model and the architecture of the neural networks has a significant positive effect on the training and model quality <ref type="bibr" target="#b152">[RSP17b;</ref><ref type="bibr" target="#b14">BPC19]</ref>. In CompVAE, this invariance property is sought using a 2-level representation, as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.1">Definition of the latent structure</head><p>Let C denote the set of external factors (e.g. weather or holidays) generally conditioning all simultaneous consumption curves.</p><p>Besides the source of variations represented by C, each i-th part of the whole has some additional internal variation on the top of its description via i . In the case of electrical consumption for instance, i might be the type of electrical contract of the i-th household; this type of contract does not entirely characterize the behavior of a household.<ref type="foot" target="#foot_46">foot_46</ref> This remark leads to associate each i-th part with a continuous latent variable W i , aimed to capture this internal variation. Along this line, the model learns an associated distribution p θ (w i | i ).</p><p>Secondly, as said, the different parts involved in the whole depend on some global factor C. For electrical consumption, the instanciation of C might represent an external event that jointly affects the consumption of all households (a match on the TV). For image generation, C might indicate the general light and light orientation conditions. For music generation it could capture the synchronization of the different instruments. This lack of independence is modelled by introducing another latent variable Z, depending on C (the global factors) and possibly the {W i } as well: p θ (z|c, {w i }).</p><p>Eventually, the output X is generated by combining Z and the {W i } in a last step, p θ (x|z, {w i }), yielding the following factored distribution:</p><formula xml:id="formula_120">p θ (x, z, {w i }|c, { i }) = p θ (x|z, {w i }) p θ (z|c, {w i }) i p θ (w i | i ) (9.1)</formula><p>The next step is to describe how X and Z depend on the multi-set {W i }. The use of recurrent neural networks is not appropriate: they impose an arbitrary ordering of the elements, and pose several optimization challenges when considering a large number of elements. For this reason CompVAE takes inspiration from the encoder-aggregator-decoder structure that has been used in previous work dealing with set-structured data [ES17; Esl+18; Gar+18; Lee+19] and introduces a specific deterministic latent variable W that aggregates the {W i }, and conditions X and Z with W (Figure <ref type="figure">9</ref>.1): The aggregation function Ψ must apply on any number of inputs, be invariant with regard to their order, and capture the multiplicity of a same element in the multi-set.</p><formula xml:id="formula_121">w = Ψ(w 1 , w 2 , . . . w K ) (9.2) X Z W Ψ C W 1 1 W 2 2 W K K . . . . . .</formula><p>The straigtforward approach, used in CompVAE, is to consider their sum:</p><formula xml:id="formula_122">w = i w i</formula><p>The investigation of other aggregators is left for further work. This aggregation of the individual w i has important implications on the inference model, and the choice of an additive aggregation is in large part driven by the fact that there are efficient and simple ways to control for the sum of a set of random variables (more in Section 9.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.2">Handling the variable number of parts in neural architecture</head><p>A key issue in CompVAE is to account for the fact that the generated whole X must reflect the number K of pats involved in the composition. Two main situations are considered, depending on whether the general amplitude of X is proportional to K (e.g. in the case of the consumption curves) or not (e.g. in images, each pixel varies in the same range, and the number of pixels remain the same, whatever the number of objects in the scene).</p><p>Since the 2010s, many neural networks are based on activation functions akin the ReLU <ref type="bibr" target="#b56">[GBB11]</ref>, with value linear in their input unless they are saturated. In this case, when the amplitude of the input is doubled, the overall amplitude of the output is approximately doubled as well. Accordingly, when using such networks for modeling p θ in CompVAE, the amplitude of Z and X is proportional to that of W , and thus to K, the number of parts.<ref type="foot" target="#foot_47">foot_47</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Inference model over multi-sets</head><p>Symmetrically, the design of the CompVAE inference model poses the inverse problem of that of the generative model: the information contained in the variable X needs to be split into the different {W i } variables. This inference model naturally factors as:</p><formula xml:id="formula_123">q φ (z, {w i }|x, c, { i }) = q φ (z|c, x)q φ ({w i }|x, c, z, { i }) (9.</formula><p>3)</p><p>The question is how to implement q φ ({w i }|x, c, z, { i }).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.1">The recurrent network approach</head><p>Our first attempt to build the inference model relied on factorizing further the q φ distribution by introducing an arbitrary ordering of the elements, as follows:</p><formula xml:id="formula_124">q φ ({w i }|x, c, z, { i }) = i q φ (w i |x, c, z, i , {w &lt;i })<label>(9.4)</label></formula><p>Such a factorization can easily be implemented using a recurrent neural network: at each step, the network is given a triplet (x, c, i ) as input and predicts a distribution on w i as output, the dependency on {w &lt;i } being handled by the recurrent state of the network. This approach however does not scale well to large numbers of elements (due to long-term dependencies problems with RNNs, as discussed in Section 5.2.3). We also observed that, even with a small number of elements, the information does not in practice split equally between the different w i ; quite the contrary it is observed that the w i s are almost insignificant for i ≥ 3. While the RNN achieves a good reconstruction, the model thus fails to capture the link between w i and i , resulting in a very poor generative quality.</p><p>Our second attempt, aimed to mitigate the above loss of signal issue, was to explicit the recurrent state of the model. In the former attempt the recurrent state does not directly depend on the sampled value of each variable w i , blurring the dependency on {w &lt;i }. The second attempt thus made it explicit that the relevant recurrent state is the sum of the previously extracted w i , hopefully enabling the extraction of w i . The sought distribution thus reads:</p><formula xml:id="formula_125">q φ ({w i }|x, c, z, { i }) = i q φ   w i x, c, z, i , j&lt;i w j   (9.5)</formula><p>The above extraction procedure behaves like a hand-rolled RNN: an accumulator variable, initialized to 0, holds the partial sum j&lt;i w j ; then at each step this accumulator is given as input to the neural network, in addition to x, c, z and i , and its output is the probabilistic prediction for w i , from which a value is sampled and added to the accumulator, as illustrated by Figure <ref type="figure">9</ref>.2.</p><p>This second attempt however faced the same issue as the first one, most of the information being captured by the first few variables. Another, non-recurrent approach was thus considered.</p><formula xml:id="formula_126">0 j&lt;2 W j j&lt;3 W j j&lt;4 W j W 1 W 2 W 3 1 2 3</formula><p>Figure 9.2: Graphical representation of the recurrent inference model with explicit recurrent state. The dependency of each w i node on (x, c, z) is omitted for clarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.2">Correlated Gaussian prediction</head><p>The failure of the inference model to adequately split the information between the different W i variables is blamed on the choice to process them sequentially, rather than as a whole. Therefore, we opted for designing an inference model that directly predicts a joint distribution over the set {W i }.</p><p>In order to ensure an accurate reconstruction of X, the key issues are to identify W and Z; the W i s are only directly involved in the KL term of the ELBO.</p><p>For each (vectorial) W i in the latent space, its coordinates are assumed to be independent; for simplicity, W i will be considered as a scalar in the remainder (its prediction actually proceeds coordinate-wise). The simplest model considers a diagonal Gaussian distribution over the vector (w 1 , w 2 , . . . , w K ), where the neural network predicts a mean and variance pair (µ i , σ 2 i ) for each w i . We modify the diagonal covariance matrix to allow the model to control for the variance of the sum of these variables: the motivation is to enforce a small variance on the prediction of the value w while enabling a larger variance on the prediction of each w i , to allow a tighter ELBO.</p><p>The motivation for this requirement (enabling a high variance for each individual W i while enforcing a low variance on W through correlating the W i s) is the following. On the one hand the low variance on the prediction of W is required for a good reconstruction of X by the model. On the other hand, the inference model should not be required to identify the individual contributions of the parts. Alleviating the need for individual predictions allows one to increase the entropy of the inference prediction (thus improving the ELBO), and avoids the need for the neural network to break the symmetry between similar parts, a far from trivial task.</p><p>To control the variance of W , a new parameter 0 ≤ ρ i ≤ 1 for i = 1 to K is introduced, informally defining how much W i varies conditionally to W ; ρ i &gt; 0 enforces a negative correlation between W i and W , as formalized in Equation 9.6.</p><p>Let i and µ i + σ i i be samples respectively drawn after N (0; 1) and N (µ i ; σ 2 i )). The ρ i parameter is used in the sampling procedure of w i , as:</p><formula xml:id="formula_127">w i = µ i + σ i i -ρ i j σ j j (9.6)</formula><p>The above sampling procedure defines a multivariate normal distribution of all W i s, such that the variance of W = i W i is controlled by the ρ i parameters with:</p><formula xml:id="formula_128">V ar (W i ) = (1 -ρ i ) 2 σ 2 i + j =i ρ 2 j σ 2 j (9.7) V ar W = 1 - i ρ i 2 i σ 2 i (9.8)</formula><p>thus, the variance of W i can be high while the variance of W is low. In the case where i ρ i = 1, the variance of W is 0, making its prediction deterministic. In the particular case where ρ i = 1/N , with N the number of parts in the whole, then one has as desired the variance of W set to 0, while the variance of each</p><formula xml:id="formula_129">W i is (1 -2 N )σ 2 i + 1 N j σ 2 j</formula><p>, which can still be relatively large. The density of the w i distribution reads, with |Σ| the determinant of the covariance matrix of the w i :</p><formula xml:id="formula_130">log q φ ({w i }|{µ i }, {σ i }, {ρ i }) = - 1 2 i 2 i - 1 2 log |Σ| - K 2 log 2π (9.9)</formula><p>This determinant can be computed analytically (with detailed derivation in Appendix 9.A):</p><formula xml:id="formula_131">1 2 log |Σ| = log 1 - i ρ i + i log σ i (9.10)</formula><p>A non-admissible case is when i ρ i = 1, where the variance of W is zero and the determinant of the covariance matrix Σ is 0. This case is avoided by choosing an appropriate parameterization, e.g. by setting ρ i as the softmax of some ν i in the real space:</p><formula xml:id="formula_132">ρ i = e ν i 1 + j e ν j (9.11)</formula><p>ensuring that both the sum of the ρ i is less than 1 and ρ i is in interval (0, 1). This parameterization also interestingly supports the closed form computation of the KL-divergence between q φ ({w i }|z, x, c, { i }) and p θ ({w i }|{ i }) (detailed in Appendix 9.B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.3">Using graph neural networks</head><p>The neural network defining q φ ({w i }|z, x, c, { i }) thus yields three values µ i , σ i and ν i for each coordinate of W i . The chosen architecture, easily scaling up with the dimension size of the latent W space, is that of graph neural networks (GraphNN) [Sca+09; Gil+17; Wu+21].</p><p>In GraphNN, each layer of the network is structured according to a same graph (Figure <ref type="figure">9</ref>.3): each node in a layer receives as input its previous state and the output of its neighbor nodes computed in the former layer; the same activation function is used in each node for a given layer. Formally, letting L denote the layer index, with h L i the state of node i at layer L, and f L the function encoded by the neural network on the L-th GraphNN layer, then:</p><formula xml:id="formula_133">h L+1 i = f L h L i , {h L j } j∈N i (9.12)</formula><p>for N i the set of neighbor node of the i-th node.</p><p>Layer i -1 Layer i Layer i + 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 9.3:</head><p>A GraphNN: within each layer, the neurons (circles) are connected using a same graph (black lines). The value of each i-th neuron is computed from the values of the i-th neuron and its neighbors in the previous layer. For readability, the computation graph is only shown for the red and green neurons.</p><p>In order for the function definition to be independent of the number of neighbors, the function f L is implemented as taking the sum (or average) of some projection of the state at the neighbors via a function Φ L :</p><formula xml:id="formula_134">h L+1 i = f L   h L i , j∈N i Φ L (h L j )   (9.13)</formula><p>where f L and Φ L are implemented and learned as standard neural networks. In CompVAE, the GraphNN is built on a fully connected layer graph<ref type="foot" target="#foot_48">foot_48</ref> . It gradually exploits and refines individual parts and whole information (respectively, the { i } element metadata, the state of the other variables, and the global (x, z, c))), as illustrated by Figure Figure <ref type="figure">9</ref>.4. Note that the global (x, z, c) is pre-processed by</p><formula xml:id="formula_135">{ i } i NN {h 1 i } i G f1, Φ1 {h 2 i } i G f2, Φ2 {h 3 i } i G f3, Φ3 {h 4 i } i h NN x z c NN {σ i } i {µ i } i {ν i } i Figure 9</formula><p>.4: Graphical representation of the GraphNN used in the inference model of CompVAE with 3 GraphNN layers(G). Each "NN" rectangle represents a neural network independent of the graphical structure. When applied to a set of variables {. . . } i , these neural networks are applied independently on each element to produce a the output set of variables.</p><p>another neural network into a latent value h, which is provided as input to both f L and Φ L in each layer of the GraphNN:</p><formula xml:id="formula_136">h L+1 i = f L   h L i , h, j∈N i Φ L (h L j , g)  </formula><p>(9.14)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Empirical results</head><p>The proposed CompVAE architecture is validated on two artificial problems and the real-world problem motivating the design of the approach, the generation of electrical consumption curves. Preliminary results on both artificial problems in <ref type="bibr" target="#b15">[BS20a]</ref>; the validation real-world data has been completed since and is also provided here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3.1">1D artificial problem</head><p>In the first artificial problem, a part is a sine curve; the whole is made of the nonlinear sum of these curves. In this problem, the output amplitude is proportional to the number K of parts, and each part affects all coordinates of the whole. Each part (sine curve) is defined by its frequency, amplitude and phase. The associated meta-data consists of the single frequency i (and thus is known when generating the curves); the amplitude a i and phase κ i are meant to be captured by the latent variables w i . The whole curve is obtained by applying a tanh function on the sum of the K curves, inducing a saturating behavior controlled by a hyper-parameter λ. The whole curve is then sampled according to some time resolution T to produce a vector of values:</p><formula xml:id="formula_137">x[t] = K tanh λ K K i=0 a i cos 2π i T t + κ i (9.15)</formula><p>The observation model thus is defined as a diagonal Gaussian observation on the vector x[t], for t = 0 to T .</p><p>The frequency i of each sine curve is randomly sampled in the finite set {1, 2, . . . 10}; amplitude a i is sampled from a normal distribution N (1, 0.3); phase κ i is sampled from a normal distribution N (0, π/2). Two global curves generated from the same four sine curves are depicted in Figure <ref type="figure">9</ref>.5, in order to compare the curve obtained by the tanh of the sum and that of the sum of the tanh. The point of this artificial problem is to investigate the case where the whole does not boil down to the sum of the parts. tanh of sum sum of tanh The overall curve (Figure <ref type="figure">9</ref>.6, right) is generated from the partial sums: from top to bottom, one sees the overall curve generated from w 1 alone, then w 1 + w 2 , then w 1 + w 2 + w 3 , forming a coherent composition of the different individual parts.</p><p>The model used in this problem is built using a 10-layers residual network for the generative model and 3 GraphNN layers combined with 6 residual layers for the inference network. It takes approximately 10 hours to train using a GTX1080 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3.2">2D artificial problem</head><p>The second artificial problem is concerned with the generation of an image (the whole) combining parts described as color anchors. Formally, a part (color anchor) is defined from its location, color, and intensity. The associated meta-data i consists of both the color varying in {white, black, red, green, blue} and the location of the anchor point encoded as a 2D vector in [0; 1] 2 ; the intensity of the anchor point is left to be captured by w i . Each part induces a color gradient on the blank canvas. The whole is an image alike a Voronoi diagram (Figure <ref type="figure">9</ref>.7) where the color in each pixel is set to a weighted combination of the anchor colors, weighted by the distance of the pixel to the anchor and the intensity thereof. This 2D problem presents two additional difficulties compared to the former 1D problem. Firstly, the whole output (the image) is of constant amplitude and does not depend on the number K of parts; pixel values lie in the [0; 1] interval whatever K is. Secondly, each part only has a local impact on the whole.</p><p>The first issue implies that the generative model needs to include a saturating mechanism. Two approaches have been considered, based on the combination function ψ and the observation model.</p><p>The aggregation function Ψ (Equation 9.2) is modified by applying, on the additive aggregation of the W i s, the following saturating activation function: and finally,</p><formula xml:id="formula_138">x → χ(x) = x 1 + γ|x| (9.16)</formula><formula xml:id="formula_139">W = χ i W i (9.17)</formula><p>The coefficient γ is learned as a global parameter, and initialized to 1.0. This activation function has a saturating behavior similar to that of tanh but is slower to saturate (Figure <ref type="figure">9</ref>.8), preventing gradient vanishing in the early learning stages, when w still has a large variance.</p><p>Additionally, the observation model is built using the discretized logistic model [Sal+17] (Section 5.2.2). This model generally behaves as a quasi-deterministic observation model (Section 6.2), but it is built on the discrete domain of pixels (that is, {0, 1, 2, . . . , 255}). It thus acts as a second saturating layer, enforcing by design  the fact that every generated pixel belongs to the proper domain.</p><p>The second difficulty is that each part (anchor) only locally affects the whole image locally. The learning process thus must manage to identify which part of the whole image is associated with an i part; the training information is more sparse. In contrast, in the 1D problem, every i part had an impact on all coordinates of the whole curve. This sparsity of the training signal overall results in a significantly longer training process. Typically, the last thing the model learns is the link between the location of the parts and their effect on the whole image, as shown on Figure <ref type="figure">9</ref>.9.</p><p>The whole process is illustrated on Figure <ref type="figure">9</ref>.10, displaying the whole image generated from an increasing number of the individual color anchors. As in the 1D problem, all individual w i s are sampled from the generative model p θ (w i | i ) and the overall image (Figure <ref type="figure">9</ref>.10, right) is generated from the partial sums: from top to bottom, one sees the overall image generated from w 1 alone, then w 1 + w 2 , then w 1 + w 2 + w 3 , forming a coherent composition of the different individual parts.</p><p>The model used for this experiment is a 20-layer residual network for the generative model, and uses 5 GraphNN layers with 10 additional residual layers for the inference model. Its full training took 2 days on a GTX1080 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3.3">Electrical curves composition</head><p>The applicative motivation of CompVAE is concerned with smart energy control policies, and more specifically the dimensioning of infrastructures along diverse usage scenarii. In the context of the NEXT contract (ADEME funding, coordinator Artelys), our industrial partner needs to assess the consumption peak of sets of households under different energy demand settings (weather, electric car). More abstractly, the question is to generate energy consumption curves corresponding to a set of customers (households or factories), where each customer is associated with its contract metadata.</p><p>Our input data consists of anonymized consumption curves from around 500 households, covering a span of 5 years for the longest. The consumption is measured bi-hourly, resulting in 48 values per day. Examples of the consumption curve of a single household over a week are displayed in Figure <ref type="figure">9</ref>.11. These curves illustrate the erratic behavior of household-level consumption in general: the baseline is very low, with spikes of consumption when persons are active, turning lights on and using electrical appliances. Note that the aggregated curves of circa 100 households show a much smoother behavior than individual curves (Figure <ref type="figure">9</ref>.12). As expected, the aggregation of independent random variables is smoother than the individual variables. Note however that the behavior of different households (the random variables) are independent only to some extent: they are correlated as the households face the same weather and external temperature, the same holiday periods, the same matches on the TV.</p><p>However, the comparatively smoother behavior of aggregated households motivates the presented approach: training a generative modeling to directly produce aggregated curves, associated with the multi-set of entity (household) descriptions.</p><p>The metadata available for each entity (household) is composed of the type of power contract (categorical variable), the power subscribed (numerical variable), and possibly the group of off-peak hours<ref type="foot" target="#foot_49">foot_49</ref> (also described with a categorical variable). These three values thus compose the i label associated with household i. The objective is to build a model that can generate aggregate consumption curves of circa 50-150 households. In addition, the hourly measure of temperature is given as a global metadata C.</p><p>CompVAE uses a specific observation model p θ (x, w, z) here, reflecting the multiscale structure of aggregated electrical curves (Figure <ref type="figure">9</ref>.12): a strongly regular baseline with a daily regularity, decorated with a fast varying component. This structure leads to the use of a hierarchical observation model as presented in Section 6.2.2. Formally, curve X is decomposed into two observed variables X1 and X2, where X2 is the full-resolution curve, and X1 is a smoothed version, sub-sampled by a factor of 2. The model then decomposes as p θ (x2|x1, w, z)p θ (x1| w, z). As in the Laplacian pyramid structure, X2 is predicted as a correction to an upscaled version of X1. The neural network structure itself is built using 1D convolutional and residual networks: the generator model is composed of 14 residual layers, while the inference model has 5 GraphNN layers, associated with 7 residual layers. The total training time is of approximately 1 day using a GTX1080 gpu.     The training procedure uses aggregated curves that are generated on the fly for each minibatch, uniformly selecting a week and a set of households in the set of 500 households and (at most) 250 weeks. One can thus consider that the training data is virtually infinite<ref type="foot" target="#foot_50">foot_50</ref> , which significantly helps avoiding overfitting.</p><p>The behavior of the trained model is presented in Figure <ref type="figure">9</ref>.13. In particular, Figure <ref type="figure">9</ref>.13(a) and Figure <ref type="figure">9</ref>.13(b) illustrate the reconstruction quality reached by CompVAE on these data: X2 is near-perfect given the real X1, and X1 itself captures well the shape of the curve, with most of the uncertainty being on the exact height of the peaks and lows. Figure <ref type="figure">9</ref>.13(c) illustrates what would be a "full reconstruction" from the latent values: Z and {W i } are given from the inference model, but X1 is sampled from p θ (x1| w, z) before being given to p θ (x2|x1, w, z), the later being represented on the plot. The resulting prediction, while still fitting the overall shape of the curve, now displays small but significant deviations from it. While the error between the reconstructed curves and the real ones is of 3.8kW (±1.5kW ) and 4.9kW (±1.6kW ) per household<ref type="foot" target="#foot_51">foot_51</ref> for individual X1 and X2 reconstructions, it reaches around 13.9kW (±5.3kW ) per household for the "full reconstruction". This illustrates how the uncertainty is shared between the two variables X1 and X2 by the hierarchical observation model.</p><p>In generative mode, Figure <ref type="figure">9</ref>.13(d) displays 5 curves produced by CompVAE upon receiving the same { i } 100-element multiset. All generated curves have same general shape and amplitude as the original one: the average distance between the original curve and a generated one is 20kW (±11kW ) per household (using the same metadata), to be compared with 92kW (±73kW ) when the individual curves are independent, that is, the same distance as between two independent real curves. This result confirms that CompVAE correctly identifies the dependency between the metadata and the curve.</p><p>The quality of the generated curves is evaluated and compared to real data according to three domain-specific metrics, related to the goal of balancing the electrical network. The first metric is the peak consumption: the maximum value reached by the curve during the week. A too high peak value can trigger some security mechanisms on the grid. A second metric is the peak sustained consumption for a given duration: for example the maximum value that is reached for at least 8h in total during the whole week. Sustained high consumption can also adversely affect the network, e.g. by causing overheating in some parts. A third metric is the flexibility of the curve, a technical indicator defined as the L1 distance between the curve and the constant curve of same average consumption over the week. At the grid level, consumption and production must always be balanced; in this respect, the easiest case is that of constant consumption curves. The flexibility thus measures how far the curve is from a constant curve with the same total energy consumed, using the earth-mover's (or energy-mover's) distance.</p><p>The overall distribution (averaged over the number of households, household metadata and temperature profiles) of these three metrics are compared in Figure <ref type="figure">9</ref>.14. The provided histograms are computed from 100,000 real aggregated curves and 100,000 curves generated by CompVAE. One observes a small but noticeable bias in CompVAE, that generates curves with slightly higher peaks and a slightly higher flexibility in average, as shown in Fig. <ref type="figure">9</ref>.14. Following the discussion in Chapter 7, a tentative interpretation might be that, as the generative model did not fully capture the structure of the curves, it provisionned the intrinsic variability of the curves through random noise; this noise might explain the wider range of the curve values, increasing the top-1 value (peak) and its variance (flexibility).</p><p>The impact of providing the temperature as global metadata C is assessed through a lesion study, comparing the latent part of the losses for a model trained with and without this metadata, as summarized in Table <ref type="table">9</ref>.1. These values can be interpreted as the amount of data the encoder needs to store in the latent variables in addition to the one already provided by the latent model p θ (z, {w i }|{ i }). CompVAE trained without the temperature information converges to storing on average 12 bits in the set of {w i } as a whole, and 25 bits in z, so 37 bits total. This is already quite a small value compared to the size of the data (X is a vector of 336 values), illustrating how  Table <ref type="table">9</ref>.1: Lesion study, impact of providing the weather temperature as input to CompVAE: Amount of information stored by the model in the latent variables, as interpreted from the loss values.</p><p>X can indeed be well predicted from the set { i }. However, the model trained with the temperature input as C converges to around 8 bits in the set of {w i } and 18 bits in z, for a total of 26 bits. The addition of the temperature input thus allows the model to reduce by around 30% the amount of information the inference model needs to provide on top of the trained model to accurately reconstruct the curve, illustrating the expected link between weather and electrical consumption (being reminded that electrical heating is quite common in France). It is interesting to note that even though the temperature is only injected at the level of the Z variable in the model, its usage enables to reduce the amount of information stored both in Z and in the {W i }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4">Summary and perspectives</head><p>Our second main contribution, CompVAE is a Deep LVM with a specific latent structure aimed to enforce additive semantics in latent space. This structure makes CompVAE able to accurately learn and exploit a generative model conditioned on a multi-set of variables, addressing the applicative need of generating aggegated electrical consumption curves for a neighborhood given the set of households it contains. Its empirical validation on synthetic and real-world problems demonstrates its generality and its potential<ref type="foot" target="#foot_52">foot_52</ref> . The CompVAE structure involves clearly separated observation and latent models as generally advocated throughout the manuscript. A perspective for further study is thus to combine CompVAE with more sophisticated observation models (e.g. Wavenet or PixelCNN), and extend compositional generation to high-dimensional complex data.</p><p>Another perspective concerns the aggregation function Ψ used to combine the {W i } variables in CompVAE. All considered models rely on the sum (or a variation thereof); the rationale is to allow the inference model to infer the {W i }s while controlling for their sum, using a multivariate Gaussian distribution. Other aggregation functions could be considered, e.g. an element-wise max, or a learned combination function built on invariant neural networks <ref type="bibr" target="#b151">[RSP17a;</ref><ref type="bibr" target="#b14">BPC19]</ref>. How to adjust the inference model to capture the behavior of these aggregation functions opens the path for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9.A Determinant of the covariance matrix</head><p>The sampling procedure is defined by:</p><formula xml:id="formula_140">w i = µ i + σ i i -ρ i j σ j j (9.18)</formula><p>Let D be the diagonal matrix (σ 1 , σ 2 , . . . , σ K ), 1 be the column vector (1, 1, . . . , 1), and w, ρ, and µ be the column vectors defined by the {w i }, {ρ i } { i } and {µ i } respectively. The sampling procedure can be reformulated using these as:</p><formula xml:id="formula_141">w = µ + D -ρ(1 T D ) = µ + (I -ρ1 T )D (9.19)</formula><p>The covariance matrix is thus given as a product of four matrices:</p><formula xml:id="formula_142">Σ = (I -ρ1 T )DD(I -ρ1 T ) T (9.20)</formula><p>The determinant of D is i σ i , remains the determinant of (I -ρ1 T ) to compute. This can be done using the matrix determinant lemma 9 :</p><formula xml:id="formula_143">|I -ρ1 T | = 1 -1 T ρ = 1 - i ρ i (9.22)</formula><p>Finally the determinant is given as:</p><formula xml:id="formula_144">|Σ| = 1 - i ρ i 2 i σ 2 i (9.23)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9.B Computing the KL divergence on {W i }</head><p>In the context of the CompVAE model, p θ ({w i }|{ i }) factorizes as a product i p θ (w i | i ), each term of this product being a normal distribution.</p><p>The KL divergence thus decomposes as (conditioning variables are ommited for brevity):</p><formula xml:id="formula_145">D KL (q φ ({w i }| . . . ) p θ ({w i }| . . . )) = -H(q φ ({w i }| . . . )) - i E w i ∼q φ log p θ (w i | . . . ) (9.24)</formula><p>The entropy of the q φ distribution is easily known from its covariance matrix:</p><formula xml:id="formula_146">H(q φ ({w i }| . . . )) = K 2 + K 2 log 2π + 1 2 log |Σ| (9.25) = K 2 + K 2 log 2π + log 1 - i ρ i + i log σ i (9.26)</formula><p>9 For any invertible square matrix A and vectors u and v:</p><formula xml:id="formula_147">|A + uv T | = (1 + v T A -1 u)|A| (9.21)</formula><p>Chapter 9. Compositional VAE: structure-enforced properties</p><p>To compute the second half of the KL, let m i be the mean of p θ (w i | i ), and s 2 i be its variance. The log-density is thus expressed as:</p><formula xml:id="formula_148">log p θ (w i | i ) = - (w i -m i ) 2 2s 2 i -log s i - 1 2 log 2π (9.27)</formula><p>The expectation is then computed using the sampling definition of w i , and by averaging over the standard normal variables 1 , . . . , K :</p><formula xml:id="formula_149">E w i ∼q φ log p θ (w i | . . . ) = - 1 2s 2 i E 1 ,..., K   µ i + σ i i -ρ i j σ j j -m i   2 -log s i - 1 2 log 2π = - 1 2s 2 i   (µ i -m i ) 2 + (1 -ρ i ) 2 σ 2 i + ρ 2 i j =i σ 2 j   -log s i - 1 2 log 2π = - 1 2s 2 i   (µ i -m i ) 2 + (1 -2ρ i )σ 2 i + ρ 2 i j σ 2 j   -log s i - 1 2 log 2π</formula><p>Putting all terms together, the final result is similar to the usual divergence between two diagonal normal distribution, with a few additional terms involving the ρ i parameters:  This chapter presents the third main contribution of the manuscript, concerned with the control of the generative process. Many related works [Mat+16; RMC16; Lar+16; Che+18a; Moy+18; Mat+19b] are based on the explicit interpretation and control of the latent variables. Another approach is proposed here, where the latent distribution is altered using an explicit loss on the observed variables, as this second formulation is more in line with some problems. A first version of the approach, named Boltzmann Tuning of Generative Models (BTGM), was presented in <ref type="bibr" target="#b17">[BS21]</ref>. This chapter describes an extended version of BTGM.</p><formula xml:id="formula_150">D KL (. . . ) = i (µ i -m i ) 2 + (1 -2ρ i )σ 2 i + ρ 2 i j σ 2 j 2s 2 i + log s i σ i -log 1 - i ρ i - K 2 (9.</formula><p>Considering a given, already trained generative model p(x), and an external criterion f : X → R, the goal is to refine the model and define a new model p(x) that maximizes Ex∼p f (x) while remaining as close to p as possible. This goal, akin model fine-tuning, is formalized as a tractable optimization problem, and a sound procedure is proposed to tackle it.</p><p>This problem is also motivated by an application from the smart energy control domain, and specifically the estimation of the consumption peak. More formally, in the same context as in the previous chapter, the goal is to generate extreme though realistic electrical consumption curves; these curves will be used to evaluate the behavior of the electrical grid in specific scenarii and the associated risk attached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>135</head><p>BTGM proposes a general answer to the above problem. At an abstract level, the point is to bias the generative model toward the region of extreme values w.r.t. the considered external criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1">Boltzmann distributions and Pareto exploration</head><p>A most appropriate framework to express constraints in a probabilistic setting is the celebrated Principle of Maximum-Entropy (MaxEnt), originated from statistical physics <ref type="bibr" target="#b86">[Jay57]</ref> and now widely used in Machine Learning. In Bayesian terms, this principle concerns the appropriate choice of a prior distribution, as being the one with largest entropy among the admissible distributions (complying with the constraints).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1.1">Principle of maximum (relative) entropy</head><p>Most considered constraints either restrict the support of the distribution, or require the expectation of some function over the distribution take a given value:</p><formula xml:id="formula_151">E f = C.</formula><p>In both cases, the MaxEnt principle can be formulated as a constrained optimization problem:</p><formula xml:id="formula_152">arg max p H(p) s.t. ∀i : E x∼p f i (x) = C i (10.1)</formula><p>This constrained optimization problem is solved by using Lagrange multipliers <ref type="bibr" target="#b86">[Jay57]</ref>, yielding a solution of the form (complete derivation in Appendix 10.A):</p><formula xml:id="formula_153">p(x) = 1 Z exp i λ i f i (x) (10.2)</formula><p>where the values of the Lagrange multipliers λ i depend on constant C i s, and the normalization constant Z also is a function of the Lagrange multipliers. Interestingly though unsurprisingly, energy-based models (Section 1.1.2) take the same functional form. Both approaches take inspiration from statistical physics: In both cases, the principle of maximum entropy of the distribution over the physical states of the studied system, subject to the expectation of the total energy taking a known value <ref type="bibr" target="#b86">[Jay57]</ref>, yields the Boltzmann distribution (where the inverse temperature plays the role of the Lagrange multiplier).</p><p>The principle of maximum entropy has been further generalized by <ref type="bibr" target="#b19">[Cat07]</ref>, combined with Bayes rule to define the principle of maximum relative entropy. This latter principle states that, given a prior distribution p(x), the refinement of p subject to a set of constraints of the form E f = C is properly formulated through minimizing the KL-divergence of the sought distribution p and p (or relative entropy of p):</p><formula xml:id="formula_154">arg min p D KL (p p) s.t. ∀i : E x∼p f i (x) = C i (10.3)</formula><p>This new problem can be solved in the same way as MaxEnt, and yields a similar solution:</p><formula xml:id="formula_155">p(x) = p(x) Z exp i λ i f i (x) (10.4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1.2">Exploration of the Pareto front</head><p>This formulation interestingly allows for exchanging the roles of the optimization objective and the constraints, up to a reparameterization of the Lagrange multipliers.</p><p>In short, optimizing the (relative) entropy under the constraint that the expectation of a function f is fixed to a constant value, is equivalent to maximizing E f under the constraint of a given value for the (relative) entropy<ref type="foot" target="#foot_53">foot_53</ref> . More generally, the Lagrange multipliers can be interpreted as a parameterization of the Pareto front corresponding to the multi-objective optimization of the various f i criteria and the (relative) entropy. This Pareto front, describing the possible trade-offs between the considered objectives, can be explored via varying the λ i s. This exploration is illustrated on a simple case with a single criterion f (x). Let pλ be the distribution defined as:</p><formula xml:id="formula_156">pλ (x) = p(x) Z(λ) e λf (x) (10.5)</formula><p>Then, the local behavior of the criteria seen as functions of λ can be expressed using statistical quantities evaluated over pλ , as follows:</p><formula xml:id="formula_157">d dλ D KL (p λ p) = λV ar pλ f (10.6) d dλ E pλ f = V ar pλ f (10.7)</formula><p>In particular, when restricted to λ &gt; 0, both D KL (p λ p) and Ep λ f are monotonic functions of λ. The λ &lt; 0 case is symmetrically handled (by minimizing f instead of maximizing it). This confirms that exploring the different values of λ reliably explores the Pareto front balancing these two objectives. Similar identities hold for second derivatives (with proofs in Appendix 10.B):</p><formula xml:id="formula_158">d 2 dλ 2 D KL (p λ p) = V ar pλ f + λ E pλ   f -E pλ f   3 (10.8) d 2 dλ E pλ f = E pλ   f -E pλ f   3 (10.9)</formula><p>From the above equations, it follows that if the first, second, and third moments of f under pλ can be empirically estimated (assuming that one can sample the instance space according to pλ ), these estimates can be used to efficiently explore the said Pareto front.<ref type="foot" target="#foot_54">foot_54</ref> .</p><p>The sought approximation of pλ can be found using variational inference (presented in Section 2.3); it reads: This optimization problem can be solved within the variational inference framework, depending on the considered f and p. This optimization can be combined with a second-order method to efficiently find the value of λ corresponding to a given target value of D KL (p λ p) or Ep λ f . The approach is described in Algorithm 10. dλ 2 Ep λ f using Equation 10.9 by Monte-Carlo λ ← Second order update to bring Ep λ f towards F until convergence of λ return pλ In both algorithms, the computational cost is dominated by the optimization of Equation <ref type="formula">10</ref>.11. The Monte-Carlo estimation of the objective value and its two derivatives with a large number of samples is comparatively inexpensive; hence the estimation error comes from the error on pλ itself (not from the Monte-Carlo estimation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2">The Boltzmann tuning of Generative Models</head><p>The above general principles aimed to finding pλ from p can be adapted in the deep LVM framework, defining our third contribution, the Boltzmann Tuning of Generative Models (BTGM). This algorithm (Algorithm 10.1 &amp; 10.2) involves an inner loop (finding pλ for a given value of λ and an outer loop, adjusting the value of λ complying with the constraint w.r.t. the current p λ , until convergence of λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2.1">Generalizing to multiple variables</head><p>When transposing the optimization problem from Equation <ref type="formula">10</ref>.1 to a LVM, a first issue regards the definition of the relevant variables, and specifically which variables should be marginalized before computing the KL-divergence between pλ and p.</p><p>Let us consider the case of distribution p(x, z) with X the observed variable and Z an abstract latent variable. The quantity of interest clearly is the distribution p(x) over the observed variable. One would thus like to minimize D KL (p λ (x) p(x)) (as opposed to, D KL (p λ (x, z) p(x, z)), that is in general different). However, the optimization of D KL (p λ (x, z) p(x, z)) is straightforward to estimate from the LVM, while D KL (p λ (x) p(x)) is much more expensive, as it requires marginalizing out the latent variable Z. The question thus becomes of comparing both optimization problems (marginalized and non marginalized) and estimate the cost of the non-marginalized approximation.</p><p>Formally, the KL-divergence can be decomposed as:</p><formula xml:id="formula_159">D KL pλ (x, z) p(x, z) = D KL pλ (x) p(x) + E x∼p λ D KL pλ (z|x) p(z|x) (10.12)</formula><p>The non marginalized KL-divergence thus is a higher-bound of the marginalized one. Accordingly, minimizing the non-marginalized KL-divergence also brings the marginalized down, but the tightness of the bound is unknown and there is no guarantee regarding the difference between both optimal solutions. In the marginalized optimization problem, the model can flexibly reorganize the latent space as it does not constrain in any way the distribution of the latent variable Z. Quite the contrary, the non-marginalized optimization problem directly takes into account the latent space: it forces both p λ (z) to remain similar to p(z) and p λ (x|z) to remain similar to p(x|z).</p><p>The lack of flexibility of the latter optimization problem is however not necessarily a drawback, and might actually be beneficial to the BTGM implementation. In most cases, distribution p is obtained as the (imperfect) result of a training process. Searching for pλ while drastically modifying the latent structure of p thus amounts to training from scratch a new model distilling p. On the one hand, this optimization is very costly; on the other hand, it can amplify the errors in p.</p><p>The alternative is to only learn a new latent distribution pλ (z), while keeping the "decoder" part of the model p(x|z) frozen, where pλ is obtained as: pλ (x, z) = p(x|z)p λ (z) (10.13)</p><p>The characteristics of the data, what makes p "realistic", are essentially captured in p(x|z), where the latent variable Z only dictates the data region to be sampled from. The only modification of the Z distribution thus ensures that the tuned model pλ remains within the domain of realistic data (as sampled by p), and focuses on the appropriate subdomain according to criterion f . Furthermore, the KL-divergence simplifies when focusing on the only Z distribution optimization:</p><formula xml:id="formula_160">D KL pλ (x, z) p(x, z) = D KL pλ (z) p(z) + E z∼p λ D KL p(x|z) p(x|z) =0 (10.14)</formula><p>Overall, conducting the optimization on the two variable model p(x, z) with criterion f (x) is equivalent to conducting the optimization on the single-variable model p(z) with criterion f (z) = Ex∼p(x|z) f (x).<ref type="foot" target="#foot_55">foot_55</ref> This reduction enables to exploit models with a deterministic "decoder", such as GANs. It is however still necessary to evaluate the tightness of the upper bound (Equation 10.12).</p><p>Note that even though pλ (x|z) = p(x|z), this does not imply in general that pλ (z|x) ≈ p(z|x). After Bayes theorem, pλ (z|x)</p><formula xml:id="formula_161">p(z|x) = pλ (z) pλ (x) p(x) p(z) (10.15)</formula><p>In order to enforce the tightness of the upper bound (Equation <ref type="formula">10</ref>.12), that is, ensure Ex∼p λ D KL (p λ (z|x) p(z|x)) be close to 0, then the ratio needs to be most of the time close to 1 when (x, z) ∼ pλ :</p><formula xml:id="formula_162">∀(x, z) ∼ pλ : pλ (z) pλ (x) ≈ p(z) p(x) (10.16)</formula><p>In the case where x is a quasi-deterministic and invertible function of z, the change of probability from p to pλ can be mostly controlled by the change of probability of z. In the VAE case, the use of a quasi-deterministic observation model (Section 6.2) falls in the above category; the mapping from z to x can be made quasi-invertible by using a restricted probabilistic inference model. <ref type="foot" target="#foot_56">4</ref>In the GAN case, on the one hand they do provide a deterministic mapping; on the other hand, there is a-priori no guarantees for this mapping to be invertible; hence, the use of a GAN as base p model might result in a larger gap between D KL (p λ (x, z) p(x, z)) and D KL (p λ (x) p(x)). Likewise, complex observation models such as PixelCNN (Section 5.2.2) neither provide quasi-determinism nor are quasi-invertible, and thus they are a priori poor candidates as base models for BTGM.</p><p>When considering a multi-variable deep LVM (with more than two variables), the same methodology can be followed, selecting only some variables X i s of the model to be tuned while the total KL-divergence reads as a sum of KL-divergences over these variables (taking the KL expectation w.r.t. their parent variables noted π(X i )):</p><formula xml:id="formula_163">D KL pλ p = i E π(X i ) D KL pλ (x i |π(X i )) p(x i |π(X i ))</formula><p>(10.17) Does approximating the KL-divergence over observed variables by the full KLdivergence over all variables entail a performance loss? The answer thus depends on whether the observed variables depend on the rest of the model in a quasideterministic and quasi-invertible way. In the positive case, the tightness of the upper bound is good after Equation <ref type="formula">10</ref>.12 (the second term in right hand side is small); otherwise there is no guarantee.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2.2">Using normalizing flows</head><p>A key issue is to define a good search space for pλ . For simplicity, let us focus on the single-variable case; the multi-variable case is handled in the same way. While any variational inference method can be used in principle, the choice of flows-based methods (Section 2.3.3) appear to be appropriate: even though pλ can be a very complex distribution, its support is bound to be within the support of p for the sake of the realism of the generated samples.</p><p>Using normalizing flows (Section 2.3.3) to transform samples from p into samples of another distribution p is thus a natural approach. It provides a significant flexibility, while the values of p can still be computed in closed form. Letting g denote the learned flow, x a sample from p and x = g(x), the generated sample from p, then it comes: p In practice, to ensure a proper coverage of the space and a good exploration of the modes of pλ , the flow model is initialized close to the identity function, ensuring that the training samples cover the whole support of p from the start.</p><formula xml:id="formula_164">(x) = p(x)|J(g)(x)| -1 (10.</formula><p>As said, the approach involves an inner optimization loop (finding p λ ) and an outer loop (adjusting λ). Using a flow-based approximation in the frame of Algorithm 10.1 or Algorithm 10.2 enables a warm-start heuristics in the inner loop: re-using the approximation of g from outer iteration t -1 to warm-start g at iteration t. As long as the estimated value of λ increases along the outer loop of optimization, the new target distribution becomes more concentrated around its modes, making the previous one a decent initialization. If λ decreases this strategy is however more risky: one or more modes of the distribution may become eligible, not necessarily covered by the previous approximation. In that case, the safe solution consists in initializing g to identity, or to a previous approximation trained with a lower λ value.</p><p>The experiments presented in Section 10.3 rely on this warm-start procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2.3">Comparing and selecting the f criterion</head><p>A key step in the setup of BTGM is the choice of the criterion f to be maximized. Informally, the expert's requirements can be represented in many different ways, and same solutions should be found when using f or hof for any monotonous scalar function h. The difficulty of the underlying optimization problem however varies depending on which h is chosen. Let us examine how BTGM behaves depending on f . Note that the Pareto front defined by the family pλ when λ ranges in R is unaffected when f is composed with any affine h (h(x) = ax + b, with a &gt; 0). Varying constant b amounts to changing the normalization constant Z(λ), and varying coefficient a amounts to changing λ, leaving the Pareto front unchanged. An affine normalization of f is based on this remark: in the remainder, it is assumed with no loss of generality that the expectation of f under the base distribution p is 0, and its variance is 1.</p><p>A given f (after the affine normalization) is assessed from the expected difficulty of learning a good approximation of pλ with f . Intuitively, if pλ involves sharp and intricate boundaries, the task is more difficult. Letting g denote the transformation from p to pλ , then the determinant |J(g)| of its Jacobian matrix gives a quantitative estimate of how much g needs to warp its working space to transform samples from p into samples from pλ . The variations of this determinant across the space thus provide a good indicator of the complexity of this transformation.</p><p>More formally, the complexity of g at its best (corresponding to an optimal pλ ) can be computed from its theoretical value given by Equation <ref type="formula">10</ref>.5. The gradient of the logarithm of its determinant is given as:</p><formula xml:id="formula_165">∇ x log |J(g)| -1 = ∇ x log pλ (x) p(x) = λ∇ x f (x) (10.20)</formula><p>The difficulty of learning pλ for a criterion f is thus given a priori by considering the distribution of the gradient of f under the base distribution p. Therefore, two criteria f 1 and f 2 can be compared based on the histograms of their normalized gradients: ∇ x f (x) / V ar p (f ), as will be illustrated in Section 10.3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3">Case studies</head><p>This section illustrates the use of BTGM on three case studies: In the first one, the criterion f is an externally-trained classifier, and the goal is to bias a generative model to oversample the selected class(es), allowing one to finely control the strength of the bias. In the second one, BTGM is applied in the context of smart energy policies, continuing the application described in Section 9.3.3; the initial goal is to produce curves and facilitate the estimation of the peak consumption; more generally, one want to produce extreme-but-realistic consumption curves according to some metrics. The third case study investigates how to use BTGM to combine an overly general generative model (as trained by a VAE) with a discriminator network (as used in GANs) to yield a more realistic distribution sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3.1">Case 1: Conditioning a distribution</head><p>Given a generative model p(x), BTGM is applied to create a conditioned version of it. Let us assume for instance that some classifier c(y|x) is provided, then we might use it to condition a posteriori the generative model and e.g., approximate p(x|y) for a chosen class y.</p><p>In order to do so, one might consider two criteria, commonly associated to probabilistic classifiers: f (x) = c(y|x) and f (x) = log c(y|x). From an analytical point of view, the second criterion (log-probability of the class) seems to be more appropriate, yielding the theoretical distribution (after Equation 10. Criterion f (x) = c(y|x) does not yield such a principled theoretical solution. However, as discussed in Section 10.2.3, another issue is whether one or the other criterion induces a tractable optimization problem. This question is experimentally investigated as follows. We trained a classifier on the MNIST dataset; the distributions of ∇ x c(y|x) and ∇ x log c(y|x) for each of the 10 classes are computed, using a trained VAE as base distribution p. The histograms, estimated from 10.000 samples, are presented as Figure <ref type="figure">10</ref>.1. In the latter case (f (x) = c(y|x)), Figure <ref type="figure">10</ref>.1 (left) shows a large bar at 0 (for large regions of the space, the gradient norm is close to 0), and values up to 100 are observed (the histogram is truncated for readability). The optimization landscape defined by f (x) = c(y|x) thus expectedly involves large plateaus (regions where the gradient norm is close to 0) separated by large cliffs (regions where the gradient norm is very high). While this landscape reflects the behavior of a sharp classifier, it is expected to define a hard optimization problem for the normalizing flow, as it requires the learned transformation to widely vary at the boundaries among classes (following Equation 10.20). On the opposite, the former case (f (x) = logc(y|x)) involves few plateaus (regions with gradients close to 0) and no abrupt transitions (the gradient norm remains less than 15), suggesting a much smoother optimization landscape consisting of hills and valleys.</p><p>The above remarks are empirically confirmed by building pλ for various values of λ. As could have been expected, the empirical curves do not perfectly match the theoretical curves. However, the gap is significantly lower when using f = log(c(y|x)) <ref type="foot" target="#foot_57">5</ref> . More specifically, for low λ values, pλ tends to remain close to p; as λ increases, it quickly overshoots the theoretical D KL . This behavior is consistent with an optimization landscape composed of plateaus and abrupt cliffs: for low λ the landscape is mostly flat, and the few small cliffs are missed, and when λ increases only the high plateaus are kept and the rest of the distribution support is suddenly discarded.</p><p>In contrast, the evolution of the distribution for f (x) = log(c(y|x)) is smoother and more gradual, closer to the theoretical values, thus confirming the expectations based on the regularity of its gradient norm.</p><p>The generated samples are illustrated on Figure <ref type="figure">10</ref>.4 using f (x) = log c(y = 4|x).</p><p>From top to bottom, the λ value increases; each row displays a set of samples from pλ . As λ increases, the prevalence of the digit 4 increases in the generated samples, and non-4 digits are mostly chosen in the class 9, that most look alike 4. For λ ≥ 1, only 4 samples are generated; for λ = 1.25, the distribution focuses on the most unambiguous 4 samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3.2">Case 2: Extreme values of a distribution</head><p>The motivating application used in CompVAE (Chapter 9) is also considered for BTGM. <ref type="foot" target="#foot_58">6</ref> The presented results are based on a regular VAE trained on electrical curves, aggregating 10 households. The rationale for considering a small number of households is to enforce the variability of the generated curves, and produce examples that are visually compelling. The same model, trained on larger aggregations, produces "extreme" curves that are less easily interpretable due to the lower global variance of the dataset.</p><p>BTGM is applied on a pre-trained VAE by learning a normalizing flow in its latent space, as described in Section 10.2.1 and Section 10.2.2. The generation of electrical consumption curves considers the same objective functions as presented in Section 9.3.3: the peak value, the flexibility, and the sustained maximum value over 8 hours, characterized as follows (where x = (x 1 , x 2 , . . . x T ) denotes the generated curve):</p><formula xml:id="formula_166">f peak (x) = max i (x i ) (10.24) (a)</formula><p>Ep λ f as a function of λ using c(y|x). (b) Ep λ f as a function of λ using log c(y|x).     </p><formula xml:id="formula_167">f sustained (x; k) = top-k i (x i ) (10.25) f flexibility (x) = i x i - 1 T j x j (10.26)</formula><p>In order to generate visually extreme cases, the target value for D KL is fixed tolog(0.001) ≈ 6.91, corresponding to the top 0.1% curves w.r.t. the chosen criterion. In all cases the process converged in less than 10 updates of λ, following Algorithm 10.1. The resulting tuned distributions are shown in Figure <ref type="figure">10</ref>.5, on which the respective impact of each criterion is clearly visible. The maximization of f peak (Figure <ref type="figure">10</ref>.5(b)) selects curves that are slightly above average, but with very high short peaks (even going beyond 30kW). In contrast, maximizing f sustained does not produce as high peaks, but selects curves with higher average value, as desired. Finally, maximizing f flexibility selects curves with high variance, with periods of both very high and very low consumption. In all cases, the generated curves still have the general characteristic of real curves (such as the daily pattern) and do present significant variety, in concordance with BTGM objective of remaining as close to the base generative model as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3.3">Case 3: Fine-tuning a generative model</head><p>Another usage of BTGM aims to fine-tuning generative models to improve their generation quality. As discussed in Section 3.2, deep LVMs such as VAEs tend to learn overly general distributions due to the limited capacity of their inference models and their maximum likelihood training <ref type="bibr" target="#b0">[AB17]</ref>. Given such a model, BTGM  proceeds to refine its latent distribution and better stick to realistic samples using an adversarial mechanism a posteriori <ref type="bibr" target="#b62">[Goo+14]</ref>.</p><p>A standard GAN classifier (referred to as discriminator) discriminates among generated samples (drawn after a generative model p G ) and a real dataset p D . When trained to optimality, the discriminator thus provides an approximation of p D (x) p G (x)+p D (x) . The pre-sigmoid output of the discriminator is thus itself an approximation 7 of log p D (x) p G (x) , making it an interesting candidate for a BTGM f criterion. Using p G as base distribution, the optimized distribution produced by BTGM reads:</p><formula xml:id="formula_168">pλ (x) ∝ p G (x) 1-λ p D (x) λ (10.27)</formula><p>Distribution pλ gets closer to the data distribution p D as λ increases, with theoretically pλ = p D for λ = 1. In practice it is unlikely to fully recover p D , but one might expect to decently tighten an overly general distribution p G . Note that the use of a GAN discriminator within BTGM enables to decouple the training of the modules: the discriminator is trained while p G is frozen, and BTGM is then launched to learn pλ with both p G and the discriminator frozen: this mechanism avoids the concurrent adversarial training of the modules, sidestepping the notorious stability issues of the GANs [AB17].</p><p>7 Let y denote the pre-sigmoid activation of the discriminator, then sigmoid(y) ≈ p D (x) p G (x)+p D (x) . Solving for y yields y ≈ p D (x) p G (x) .  A proof of concept for this a posteriori adversarial refinement of an overly general distribution is provided on the MNIST dataset. p G is trained as a Gaussian VAE; f is a classifier trained to distinguish p G from the dataset, with 99% accuracy. BTGM is applied on the VAE latent space (Section 10.2.1), and the results are presented in Figure <ref type="figure">10</ref>.6. An ideal solution is obtained for Ep λ f ≈ 0, i.e. on average, the classifier cannot distinguish between pλ and p D . As expected, BTGM does not manage to reach this ideal solution and the optimization saturates for λ ≤ 0.5, failing to tighten the model further. The D KL value reached at this point is ≈ 4, hinting at a concentration of the model around the 2% most realistic images according to the classifier 8 .</p><p>The reason for failing to improve further pλ likely lies in the shape of the 8 The reasoning is as follows. Considering some base distribution p, and another distribution q which is proportional to p, with support is restricted to some subset S of the support of p, then one has DKL(q p) = -log p(S), where p(S) represents the total probability mass of the set S according to p. Inversely, if pλ restricts its supportwhile remaining proportional to p on this support (which is untrue in general), then the mass of its support can be estimated from the value of the KL-divergence.  This tentative interpretation is confirmed by plotting the histogram of the gradient norm (Figure <ref type="figure">10</ref>.7): while most gradients are well-behaved, around 1% of them take very high values, up to a norm of 230. This optimization landscape likely contains some very high cliffs, that the normalizing flow fails to capture. This optimization landscape suggests that the discriminator manages to tightly characterize the support of the real data distribution p D , leading to sharp boundaries between the classes. As the support of p D is known to be contained within that of p G (as VAEs always cover the whole dataset), this suggests the generative model p G is too spread out, making the discriminator task too easy. Empirically, BTGM fails to bring the expectation of log p D p G higher than -5, meaning the region is still largely classified as belonging to p G . It is also likely that the Gaussian observation model of the VAE further introduces some noise over which BTGM does not have control (as it only operates in the latent space) but which is exploited by the discriminator. This last point underlines the fundamental assumption made in Section 10.2.1: that p G (x|z) reflects the true distribution. In the case of a Gaussian observation model, this assumption contradicts the analysis presented in Chapter 6 and Chapter 7, showing that there will always be some residual noise that a discriminator could capture. A perspective to mitigate this drawback would be to train the discriminator on a version of the dataset on which a similar noise has been introduced, in the spirit of <ref type="bibr" target="#b158">[Saj+18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.4">Summary and perspectives</head><p>The Boltzmann Tuning for Generative Models (BTGM) presented in this chapter constitutes the third contribution of this thesis. Built on Deep LVMs and the celebrated Maximum Entropy Principle, BTGM makes it possible to selectively revise some parts of a Deep LVM based on an external differentiable criterion f operating on a subset of variables. The presented framework focuses on adjusting the distribution of the latent (Z) variable of a VAE based on a criterion f operating on its observed (X) variable; in the general case, the distribution and criterion can equally handle observed or latent variables.</p><p>BTGM can naturally be interpreted in probabilistic terms, e.g. recovering a conditional generative model when criterion f is based on a discriminative classifier. On our motivating application in the domain of electrical consumption curves, it gracefully modifies the original distribution according to the criterion, preserving the realism and general behavior of real electric curves when the base distribution is "sufficiently" appropriate.</p><p>A third case study, concerned with the adversarial refinement of a distribution, illustrates the main limitation of the approach, as follows. BTGM freezes some parts of the LVM distribution and modifies the others. But even when training extremely powerful normalizing flows to achieve the modifications, BTGM cannot compensate for deficiencies present in frozen parts of the model. This remark opens a perspective for further research. As retraining the whole distribution (not freezing any part of it) is expensive, the question is whether and how marginal modifications on some parts of the model can be achieved, avoiding both the rigidity of freezing them and the computational cost of learning them fully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10.A Derivation of the MaxEnt solution</head><p>The constrained optimization problem of Equation 10.1 is restated here: This expression must be 0 for any perturbation δ p, meaning the term between brackets must be 0 for every value of x. This means in turn: log p(x) = η -1 + i λ i f i (x) (10.31) And then: p(x) = e η-1 e i λ i f i (x) (10.32)</p><p>The value of η is determined by the constraint that p must be a normalized probability distribution. Defining Z as: Z = 1 e η-1 = x e i λ i f i (x) dx (10.33)</p><p>We finally get: p(x) = 1 Z e i λ i f i (x) (10.34)</p><p>The value of the remaining Lagrange multipliers (λ i ) i must now be determined according to the other constraints: Ep f i = C i . (that does depend on λ) in Equation <ref type="formula">10</ref>.37 yields the second derivative: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10.B Proofs of the derivative formulas</head><formula xml:id="formula_169">d 2 dλ 2 E pλ f = d dλ E pλ   f -E pλ f   2 = E pλ   f   f -E pλ f   2 -2   f -E pλ f   d dλ E pλ f    -   E pλ f      E pλ   f -E pλ f   2    = E pλ   f -E pλ f   3 -2 E pλ   f -E pλ f   =0 d</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and Perspectives</head><p>Deep latent variable models (LVM) are at the forefront of the state of the art in generative models, offering both a flexible model space and a principled training methodology, relying on the Evidence Lower Bound (ELBO) criterion to maximize the data likelihood. The analysis presented in the manuscript is conducted in the perspective of the structure design, including the associated inference models, and their impacts. This perspective is contrasted with a number of works at the state of the art, e.g. [BGS16; Hig+17; Ale+18; RV18; Raz+19], that proceed with augmenting the ELBO with ad hoc regularization terms, or with altering the training process, in order to shape the deep LVM and enforce the desired properties.</p><p>Quite the contrary, our claim is that the structure design can convey a number of targeted properties in a principled yet efficient way, operating at both static and dynamic levels.</p><p>On the static level, mainly two topics have been investigated: the relationship to the data, and the latent structure and symmetries. Regarding the relationship with the data, Chapter 5 emphasizes that the observation model, the probabilistic structure defined on the observed variables of the LVM, disentangles the notions of signal and noise. The signal is encoded into the latent variables; the noise is modeled through the observed variables. At one extreme, (too) powerful autoregressive observation models yield the posterior collapse phenomenon, where the LVM essentially models the whole data information based on noise only. A particular case is when observed variables are noisy deterministic functions of the latent variables. In this case, referred to as quasi-deterministic observation models and discussed in Chapter 6, a rich representation of the data structure can still be obtained, e.g. using a hierarchy of variables to capture multi-scale representations <ref type="bibr" target="#b42">[Dor+17]</ref>. In this context, our first contribution shows theoretically and empirically that such observation models are governed by the scale of their noise. This hyper-parameter actually governs the trade-off between the latent compression and the reconstruction terms of the ELBO. In particular, we show on a proof of concept that an overestimated noise hyper-parameter can prevent from identifying the data manifold, even in the large sample limit (Theorem 6.1).</p><p>Our second contribution is to show how the latent structure organization can be leveraged to enforce sophisticated generative properties, with a motivating application in the domain of smart energy policies. Specifically, the CompVAE model (Chapter 9) uses a hierarchy of latent variables to deliver a programmable generative model, conditioned on a multiset of elements. By using one latent variable per conditioning element and aggregating them through a permutation-invariant function, the permutation symmetries of the input multi-set are seamlessly enforced in the model structure. On top of the aggregation, the structure involves a global latent variable that captures the factors of variation shared by all entitites (in the application domain where the entities are households, and the programmable generative model delivers the aggregated consumption curves of the households, the latter latent variable reflects e.g. the weather). The empirical validation of the approach in the context of the NEXT contract (funded by the French Energy Agency, ADEME) successfully showed the merits and efficiency of the approach.</p><p>On the dynamic level, mainly three topics have been of interest: the relationship between the structure and the optimization trajectory; the a posteriori refinement of the probabilistic model; and thirdly (Chapter 3) the regularization role of the inference model, guiding convergence toward an easy to approximate posterior distribution, as analyzed through the lens of posterior regularization <ref type="bibr" target="#b54">[Gan+10;</ref><ref type="bibr" target="#b164">Shu+18]</ref>.</p><p>Regarding the relationship with the optimization trajectory, the learning of the observation noise variance has been studied in Chapter 7. The main result is to show that the impact goes much deeper than only finding the appropriate value of the variance parameter. Specifically, starting with a high noise enables the model to first learn a very smooth approximation of the data manifold, discarding much of the data information. This approximation allows an efficient latent representation to be found; this latent representation is iteratively refined as the noise variance is decreased, enabling the model to gradually capture finer-grained details from the data. Overall, the optimization trajectory yields a much better (quasi) optimum through this interplay between both terms of latent compression and reconstruction loss, akin an annealing procedure. The improvement is equally manifest in terms of the eventual ELBO value and the quality of the generated samples. The impact of this optimization trajectory can be understood in the perspective of Bayesian deep learning <ref type="bibr" target="#b118">[MAV17]</ref>, stating that a final (sparse) solution can best be found by first considering an unconstrained space (with no sparsity constraint) and only thereafter gradually increasing the sparsity pressure. In our case, the complexity of the learning task gradually and automatically increases as the observation variance decreases, the reduction of variance being itself driven by the progress of the reconstruction loss; the whole model can thus be seen as self-regularized.</p><p>Regarding the a posteriori refinement of a probabilistic model, our last contribution is the Boltzmann Tuning of Generative Models (BTGM) (Chapter 10). Formally, the BTGM framework establishes that a trained deep LVM can be "surgically" altered using Variational Inference principles according to an external criterion (operating on observed variables) through modifying only some specific parts of the learned latent representation. This approach can be applied to a posteriori condition a trained model or explore the extreme regions of a distribution, while controlling precisely which factors -or causes -are allowed to be modified, and to which extent. As a result, while not directly linked to model design, BTGM can exploit a pre-existing latent structure for directed tuning. The experimental validation on the same motivating application of CompVAE indeed shows that the BTGM approach constitutes an efficient alternative to rejection sampling in order to explore the extreme regions of the distribution. In summary, out motto is that encoding model properties through the LVM structure design is when possible an efficient way to achieve robust models which are amenable to being explainable and transparent. The guiding thread of the presented research is that an LVM can be well characterized from both static and dynamic perspectives from its only structure design, while preserving the probabilistic interpretation of the ELBO criterion. This approach provides a complementary perspective on model design to the introduction of additional objectives or regularization terms within the training loss [BGS16; Hig+17; Ale+18; RV18; Raz+19]. This motto thus raises the question of how to encode domain-or problemdependent objectives through the LVM design. This question is at the core of the main research perspectives opened by the presented work.</p><p>A first perspective is to build a bridge between deep LVMs and causal models, and more specifically to uncover and exploit the causal structure of the real datagenerating process to guide the design of the LVM structure. On the one hand the idea is simple and clear: it is generally believed that the true underlying causal structure of the data is among the simplest ones accounting for the data everything else being equal [PJS17; PM18]; the true causal structure thus should yield an easier to train model and deliver a better generalization overall. This claim needs however to be taken with a grain of salt. Firstly, finding the true causal structure is not a simpler problem than building a good generative model. Secondly, the true causal structure is not necessarily aligned with the requirements of the expected usage of the model; it might also make the training procedure harder than it needs to be.</p><p>A counter-example backing this remark is again provided by the motivating application of CompVAE. In the context of the generative model of aggregated electrical curves, there exist root causes governing each and every household consumption (e.g. the weather, the holidays, a match on the TV). These root causes operate besides the individual causes attached to each household (e.g. the electrical appliances, the type of contract of the household). In a relevant causal model the outcome thus is defined as the aggregation of all household curves, where each household curve is governed together by the root and the individual causes.</p><p>The CompVAE model however first models the aggregation of the households (in an abstract latent space); and the external factors are introduced on top of the aggregation to produce the global aggregated curve. In other words, the root causes appear after the individual causes in the hierarchy. This structure is motivated as external factors affect individual households in a coherent way, and because the targeted outcome is the global behavior only. For this reason, CompVAE does not need to represent the root causes per se, through some associated latent variable; instead, it directly encodes the effect of those root causes onto the aggregated curve. This architecture comes with two main advantages. Firstly, it results in a significantly simpler computational graph, facilitating its training and contributing to the stability of the solution. Secondly, this architecture allows the latent representation to efficiently disentangle the impact of external factors from the individual factors of each household, supporting an efficient ensemblist manipulation of the household descriptions.</p><p>In summary, the LVM architecture can usefully take inspiration from the causal underlying structure of the phenomenon under study, with two caveats. On the one hand, uncovering the causal structure is a problem per se; on the other hand, the true causal structure needs be revisited in the perspective of the usage and learning of the LVM.</p><p>Another, longer-term, perspective of research lies in extending BTGM to tackle inverse problems. Formally, given the objective function and a trained LVM architecture, one might want to determine the minimal amount of change required to meet one's objectives in terms of system response. BTGM presently relies on the assumption of an accurate differentiable generative model. A first line of research concerns the extension of the approach to handle binary or categorical variables; a second line of research consists of investigating the impact of model misspecifications.</p><p>Formally, BTGM presently proceeds by perturbing the distribution of observed or latent variables. But the sought perturbations can also be thought of in terms of interventions on observed or latent variables, and/or on the mechanisms linking the observed to latent variables. Along this line, the extended BTGM could go much beyond counter-factual reasoning, and actually tackle planning (what changes are most effective to reach a given effect). Overall, this extension would help to identify minimal interventions on a system to reach desired behavior. In an applicative perspective, this approach paves the way toward optimal design and control (how to best control the system in order to get a given response).</p><p>When applied on a causal model (as opposed to a generative model), this BTGM extension might help identifying the (observed) variables that should best be controlled, and guide the design efforts. When applied to control latent variables, this could allow to identify which parts of the model need to be refined the most, and/or pinpoint the deficiencies of the model, and how to repair it by introducing more epistemic knowledge.</p><p>A shorter-term research perspective opened by the presented work is related to the quasi-deterministic observation models, as the presented analysis of the relationship between the model and the training data calls for further refinement. Theorem 6.1 provides an intuitive understanding of the smoothing effect of the observation noise on highly curved manifolds. A most interesting extension of this analytical result aims to predict how those manifolds are smoothed depending on the precision. Similarly, the precise analysis of non-isotropic noise (e.g. like in Laplacian Pyramid observations <ref type="bibr" target="#b42">[Dor+17]</ref> on images) might yield new lessons about very structured and high-dimensional data. Lastly, while the theoretical and empirical results have been established under the large-sample limit assumption, it remains to see how the data shortage might interact with the data precision. Title: Deep Latent Variable Models: from properties to structures Keywords: Generative Models, Deep Learning, Latent Variable Models, Bayesian Networks Abstract: Deep Latent Variable Models are generative models combining Bayesian Networks and deep learning, illustrated by the renowned Variational Autoencoder. This thesis focuses on their structure, understood as the combination of 3 aspects: the Bayesian Network graph, the choice of probability distribution families for the variables, and the neural architecture. We show that and how several aspects and properties of those models can be understood and controlled through this structure, without altering the training objective constructed from the Evidence Lower Bound.</p><p>The first contribution concerns the impact of the observation model -the probabilistic modeling of the observed variables -on the training process: how it determines the demarcation between signal and noise and its impact on training dynamic when its scale parameter is learned rather than fixed. It then behaves similarly to a simulated annealing pro-cess.</p><p>The second contribution, CompVAE, is centered on the hierarchical structure of latent variables: a generative model conditioned by a multi-set of elements to be combined in the final generation. Com-pVAE demonstrates how global properties -ensemblist manipulations in this case -can be achieved by solely structural design. The model is furthermore empirically validated on real data to generate electrical consumption curves.</p><p>The third contribution, Boltzmann Tuning of Generative Models (BTGM), is a framework for adjusting trained generative models according to an externally provided criterion while finding the minimal required adjustments. This is done while finely controlling which latent variables are adjusted and how the are. We empirically demonstrate how BTGM can be used to specialize a trained model or to explore the extreme parts of a generative distribution.</p><p>Université Paris-Saclay Espace Technologique / Immeuble Discovery Route de l'Orme aux Merisiers RD 128 / 91190 Saint-Aubin, France</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 . 1 :</head><label>11</label><figDesc>Figure 1.1: In this example graphical model (a), the observation of the value of a variable can split the graph into independent subgraphs (b): the pairs of variables (A, B) and (D, E) are independent of each other given the value of variable C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc>Figure 1.2:Example of a Bayesian Network modeling the possible causes of why the grass outside may be wet (W ). The two direct considered causes are the rain (R) and the sprinkler (S). The rain is more likely to occur when the sky is cloudy (C), while the sprinkler is more likely to be used when the sky is clear and the air is hot (H). While the graph may appear cyclic, it is not when you consider the orientation of the edges. For example you cannot loop back to S by only following the arrows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 . 3 :</head><label>13</label><figDesc>Figure 1.3: Example of a Markov Random Field.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 . 4 :</head><label>14</label><figDesc>Figure 1.4: Examples for graphical representation of a Boltzmann Machine (a) and a Restricted Boltzmann Machine (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 . 5 :</head><label>15</label><figDesc>Figure 1.5: Representation of a Markov Chain as a Bayesian Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 . 1 :</head><label>21</label><figDesc>Figure 2.1: Graphical representation of Latent Dirichlet Allocation, the rectangles, referred to as plates, represent variables that are repeated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>2 , as illustrated by Figure 2.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 . 2 :</head><label>22</label><figDesc>Figure 2.2: Representation of a 2D Gaussian distribution (left) compared to a mixture of 5 Gaussian distributions (right). While the single Gaussian has a simple elliptic shape, Gaussian mixtures can express much more complex distirbutions.</figDesc><graphic coords="38,101.04,401.89,194.29,127.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 . 1 :</head><label>31</label><figDesc>Figure 3.1: Illustration of the generative behavior of a Gaussian VAE: each latent value z (left) is mapped to a Gaussian distribution in the data space p θ (x|z) (middle). The mixture of these individual Gaussian distributions makes the complete generative distribution p θ (x) (right).</figDesc><graphic coords="49,138.55,99.21,317.22,211.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 . 4 :</head><label>34</label><figDesc>Figure 3.4: Discrete VAE: Graphical representation of: (a) the generative model; and (b) the inference model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 . 1 :</head><label>41</label><figDesc>Figure 4.1: Example of a generative model graph (a), the associated inference model generated by forward-NaMI (b), and the one generated by reverse-NaMI (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 4 . 3 :</head><label>43</label><figDesc>Figure 4.3: Comparison of the inference model used by Ladder-VAE and the on that NaMI would produce for this generative model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Figure 5.1: Pixel-based Euclidean distance on images: the distance between the noisy and clean versions of image A is the same as the distance between image A and image B.</figDesc><graphic coords="72,115.09,105.19,118.96,118.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 . 2 :</head><label>52</label><figDesc>Figure 5.2: Recursive structures: (a) a recurrent neural network is used to represent an observation model from a single latent variable; (b) the associated inference model. Diamond-shaped nodes represent deterministic latent variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 5 . 3 :</head><label>53</label><figDesc>Figure 5.3: Comparison of a Hidden markov Model (a) and a more complex latent structure as proposed by the VRNN [Chu+15] (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 5 . 4 :</head><label>54</label><figDesc>Figure 5.4: The 3 variants of PixelRNN. Top layer is the output, bottom layer is the input. Figure from [OKK16].</figDesc><graphic coords="74,138.55,506.23,317.21,153.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 5 . 5 :</head><label>55</label><figDesc>Figure 5.5: Representation of the dilated convolutions used in Wavenet. Each input is the concatenation of the output at previous time step and some conditioning for this time step. Figure from [Oor+16b].</figDesc><graphic coords="75,98.90,407.91,396.51,137.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Figure 5.6: Illustration of posterior collapse. In the Gaussian VAE (5.6(a)) each latent value Z is mapped to a different distribution in the data space X, the mixture of all of them making the actual generative distribution p θ (x) (black outline). When posterior collapse occurs (5.6(b)), all latent values are mapped to the same distribution in the data space and the observation model represents the generative distribution by itself: ∀z : p θ (x|z) = p θ (x).</figDesc><graphic coords="78,105.01,99.21,190.33,194.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Manifold Hypothesis . . . . . . . . . . . . . . . . . . . . . . . 73 6.2 Quasi-deterministic observation models . . . . . . . . . . . . . . . 74 6.2.1 The Gaussian observation and its limitations . . . . . . . 75 6.2.2 Hierarchical quasi-deterministic observations . . . . . . . . 76 6.3 Noise Variance and data resolution . . . . . . . . . . . . . . . . . 78 6.3.1 Modeling an hypersphere . . . . . . . . . . . . . . . . . . 79 6.3.2 Experimental study of manifold approximation . . . . . . 80 6.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 6.A Proof of Theorem 6.1 . . . . . . . . . . . . . . . . . . . . . . . . . 84</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 6 . 1 :</head><label>61</label><figDesc>Figure 6.1: Example of approximate paving of a manifold (blue line) with observation models (red circles). Each circle representing for example a small-variance Gaussian distribution.</figDesc><graphic coords="82,118.73,99.21,356.86,176.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>( a )</head><label>a</label><figDesc>Figure 6.2: Illustration of the inappropriately small variance imposed by a diagonal observation model. (a) The cluster of points can efficiently be fitted by a single full-rank normal distribution. (b) It requires a mixture of smaller variance normal distributions if these are constrained to be diagonal. The second observation model requires additional information to be captured in the latent variables, compared to the first one.</figDesc><graphic coords="84,101.04,99.21,194.30,192.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>x 0 x 1 x 2 x 3 Figure 6 . 3 :</head><label>363</label><figDesc>Figure 6.3: Illustration of a multiscale observation model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 6 . 5 :</head><label>65</label><figDesc>Figure 6.5: Contourplot of (Equation 6.5) in the 2D plane given by r/σ and R/σ. Left: D = 2. Right: D = 10. The background color indicates the value of the criterion (increasing from blue to yellow on a logarithmic scale). Black curve indicates the optimum of (r). The threshold value √ D is indicated as a black dot on the horizontal axis.</figDesc><graphic coords="87,101.04,99.21,194.29,191.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 6 . 6 :</head><label>66</label><figDesc>Figure 6.6: Impact of the observation model variance σ 2 on the learned manifold (output of the predictive neural network x = f θ (z), with z ∼ q φ ). (a): The original manifold involves several regions, with a varying curvature, and a varying noise. Original points are in blue, learned manifold in orange. (b-c): Large values of σ result in a smoothed approximation of the manifold, where highly-curved regions have been lost. (d): A well calibrated σ adequately separates the manifold structure from its noise. (e-f) Too small σ values force the model to encode the noise into the latent variable as well; the dimension of the learned manifold increases from 1 to 2.</figDesc><graphic coords="88,98.90,388.16,194.30,125.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 6 . 7 :</head><label>67</label><figDesc>Figure 6.7: Impact of the observation model variance σ 2 on the generative process. (a): the original data (in blue). The output of the predictive model (x = f θ (z) with z ∼ p θ (z)) is in orange and the generated samples (x = x + θ ) are in green. (b-c):When σ is too large, the generated manifold (orange) matches with the reconstructed one (Figure6.6), and the added θ noise ensures complete coverage of the dataset (note the change of axes scale). (e-f): When σ is too small, the generated manifold is actually quite different from the reconstructed one, suggesting that the latent representation fails to adequately capture the real manifold: z ∼ p θ (z) often generates unrealistic samples.</figDesc><graphic coords="90,98.90,432.80,194.30,130.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>θ sin D-2 (θ)dθ (6.11)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head></head><label></label><figDesc>Observation variance fitting . . . . . . . . . . . . . . . . . . . . . 87 7.1.1 Learning a global noise variance σ . . . . . . . . . . . . . 88 7.1.2 Learning a local noise variance σ(z) . . . . . . . . . . . . 88 7.1.3 Empirical study . . . . . . . . . . . . . . . . . . . . . . . . 89 7.2 The risk of deterministic collapse . . . . . . . . . . . . . . . . . . 89 7.3 The dynamics of variance learning as an annealing process . . . . 92 7.4 Summary and perspectives . . . . . . . . . . . . . . . . . . . . . . 94 7.A Observation tempering and link with β-VAE . . . . . . . . . . . . 97</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>( a )Figure 7 . 1 :</head><label>a71</label><figDesc>Figure 7.1: Results of training the VAE from Section 6.3.2 with σ either learned as a global value or as an output of the decoder. In blue is the original data, in orange the predictions x = f θ (z), and in green actual samples from p θ . While both models learn the same approximating manifold (a, b), the second one manages to better fit the heterogeneous noise of the dataset in generation (d) than the first one (c).</figDesc><graphic coords="97,101.04,244.19,194.30,125.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>( a )Figure 7 . 2 :</head><label>a72</label><figDesc>Figure 7.2: Comparing VAE with trained and fixed variance on the artificial problem (Section 6.3.2). (a): Reconstruction of initial samples with learned σ. (b): Reconstruction of initial samples with σ = .043. (c): Generated samples with learned σ. (d): Generated samples with σ = .043. Original samples are in blue; Predictions without observation noise are in orange; Generated samples are in green. While the model with a learned σ correctly characterizes the dataset, the model with a fixed σ value fails to separate the noise from the underlying manifold (the noise is encoded in the latent space, as seen on (b), resulting in a terrible generation performance as shown in (d).</figDesc><graphic coords="99,101.04,244.19,194.30,125.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>( a )</head><label>a</label><figDesc>Losses for learned global σ. (b) Losses for fixed σ = 0.043.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 7 . 3 :</head><label>73</label><figDesc>Figure 7.3: Trajectories of the reconstruction loss (orange), latent KL loss (blue) and negative ELBO (green) for the model with learned global σ (Fig. 7.3(a)) and fixed σ = 0.043 (Fig. 7.3(b)). The first model has a very gradual learning trajectory, while the second starts with a high reconstruction loss and converges very quickly toward a local optimum.</figDesc><graphic coords="100,101.04,99.21,194.30,130.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 7 . 4 :</head><label>74</label><figDesc>Figure 7.4: Evolution of the learned value for σ during the training procedure. Blue:σ is learned through SGD. Orange: σ is fixed to its optimal value (Equation7.3) at each minibatch. Both schemes are empirically equivalent.</figDesc><graphic coords="101,158.38,99.21,277.57,185.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 7 . 5 :</head><label>75</label><figDesc>Figure 7.5: Representation of the ELBO value reached by the model as a function of the observation model variance σ 2 . Each dot corresponds to one training instance.In blue are models whose variance was fixed at the beginning of the training. In red, models where the variance is learned as a global parameter, the reported variance being the final learned value. In green are represented models where the variance is part of the output of the decoder (and thus depends on the latent variable); each is represented by an horizontal line over the range of values produced by the model.</figDesc><graphic coords="102,98.90,111.30,396.51,261.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>Figure 7 . 6 :</head><label>76</label><figDesc>Figure 7.6: Cumulative distribution of the predicted σ(z) across the generative distribution p(z) (horizontal axis is in logarithmic scale). A large portion of the [0.01; 0.08] interval is used by the model, reflecting its learning of the heterogeneous noise in the dataset.</figDesc><graphic coords="102,178.20,506.26,237.91,167.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_34"><head>Figure 7 . 7 :</head><label>77</label><figDesc>Figure 7.7: Illustration of the effect of tempering on a distribution. The base distribution (blue) is significantly broadened when tempered with a large β (orange, β = 5), and concentrated when tempered with a small β (green, β = 1/5).</figDesc><graphic coords="105,138.55,99.21,317.21,213.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_35"><head></head><label></label><figDesc>Generative classifiers for robustness . . . . . . . . . . . . . . . . . 103 8.2 Semi-supervised learning with VAEs . . . . . . . . . . . . . . . . . 105 8.3 Combining probabilistic and deterministic latent variables . . . . 106 8.3.1 Failure of the fully probabilistic approach . . . . . . . . . 107 8.3.2 Deep Variational Bayes Filter . . . . . . . . . . . . . . . . 108 8.4 Typed anomaly detection . . . . . . . . . . . . . . . . . . . . . . . 109 8.4.1 The two kinds of anomalies . . . . . . . . . . . . . . . . . 109 8.4.2 Conditional anomaly detection . . . . . . . . . . . . . . . 111 8.4.3 Empirical validation . . . . . . . . . . . . . . . . . . . . . 112 8.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_36"><head>Figure 8 . 1 :</head><label>81</label><figDesc>Figure 8.1: Graphical representation of a discriminative classifier (a) and a generative one (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_37"><head>Figure 8 . 2 :</head><label>82</label><figDesc>Figure 8.2:The generative semi-supervised model combines a generative and an inference model<ref type="bibr" target="#b95">[Kin+14]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_38"><head>Figure 8 . 3 :</head><label>83</label><figDesc>Figure 8.3: Intuitive generative and inference models for sequence modeling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_39"><head>Figure 8 . 4 :</head><label>84</label><figDesc>Figure 8.4: Generative and inference models for the Deep Variational Bayes Filter. Diamond-shaped nodes represent deterministic variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_40"><head>Figure 8 . 5 :</head><label>85</label><figDesc>Figure 8.5: Generative and inference models associated with the conditional VAE presented in [Pol+19].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_41"><head>Figure 8 . 7 :</head><label>87</label><figDesc>Figure 8.7: Anomaly detection: ROC curves for the synthetic test dataset (left) and the CMS trigger rates dataset (right). The represented variance corresponds to 5 independent runs. The anomaly score for type B reports the average D KL of z. For CMS trigger case with low false-positive rate (fall-out), VAE slightly outperforms CVAE but remains within the training variance. On type A anomalies, VAE and CVAE have very similar performances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_42"><head></head><label></label><figDesc>latent space supporting composition . . . . . . . . . . . . . . . 116 9.1.1 Definition of the latent structure . . . . . . . . . . . . . . 116 9.1.2 Handling the variable number of parts in neural architecture117 9.2 Inference model over multi-sets . . . . . . . . . . . . . . . . . . . . 118 9.2.1 The recurrent network approach . . . . . . . . . . . . . . 118 9.2.2 Correlated Gaussian prediction . . . . . . . . . . . . . . . 119 9.2.3 Using graph neural networks . . . . . . . . . . . . . . . . 121 9.3 Empirical results . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 9.3.1 1D artificial problem . . . . . . . . . . . . . . . . . . . . . 122 9.3.2 2D artificial problem . . . . . . . . . . . . . . . . . . . . . 123 9.3.3 Electrical curves composition . . . . . . . . . . . . . . . . 127 9.4 Summary and perspectives . . . . . . . . . . . . . . . . . . . . . . 132 9.A Determinant of the covariance matrix . . . . . . . . . . . . . . . . 133 9.B Computing the KL divergence on {W i } . . . . . . . . . . . . . . . 133</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_43"><head>Figure 9 . 1 :</head><label>91</label><figDesc>Figure 9.1: Representation of the CompVAE generative model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_44"><head>Figure 9 . 5 :</head><label>95</label><figDesc>Figure 9.5: Non-linear part-to-whole aggregation (purple) compared to the sum of non-linear perturbations of the parts (green). Both curves involve a non-linear transform factor λ = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_45"><head>Figure 9 . 6 :</head><label>96</label><figDesc>Figure 9.6: The compositional CompVAE generative model on the 1D artificial problem: On each row is displayed a part (left) and the whole (right) made of this part and all above parts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_46"><head>Figure 9 . 7 :Figure 9 . 8 :</head><label>9798</label><figDesc>Figure 9.7: Examples of training images for the color gradient composition problem.</figDesc><graphic coords="132,178.20,99.21,237.92,198.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_47"><head>Figure 9 . 9 :</head><label>99</label><figDesc>Figure 9.9: CompVAE on the 2D problem, composition of color anchors. Leftmost: the ground truth image. Left to right, generated output at epoch {0, 1, 2, 3, 4 5} ×100, 000. The right colors are identified around epoch 200.000; the right locations are identified much later, around epoch 500,000.</figDesc><graphic coords="133,98.90,219.96,396.55,215.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_48"><head>Figure 9 . 10 :</head><label>910</label><figDesc>Figure 9.10: The compositional CompVAE generative model on the 2D artificial problem: On each row is displayed a part (column 1), the ground truth whole made of this part and all above parts (column 2) and generated images (columns 3 to 9) generated from this part and all above parts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_49"><head>( a )</head><label>a</label><figDesc>Consumption curve of a household. (b) Consumption curve of a household. (c) Consumption curve of a household. (d) Consumption curve of a household.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_50"><head>Figure 9 . 11 :</head><label>911</label><figDesc>Figure 9.11: Examples of consumption curves of single households. Horizontal axis is labeled in days, starting at Monday morning and ending at Sunday evening. Vertical axis is labeled in Watts.</figDesc><graphic coords="135,98.90,237.63,198.26,101.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_51"><head>( a )</head><label>a</label><figDesc>Consumption curve of 100 household. (b) Consumption curve of 100 household. (c) Consumption curve of 100 household. (d) Consumption curve of 100 household.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_52"><head>Figure 9 . 12 :</head><label>912</label><figDesc>Figure 9.12: Examples of aggregated consumption curves of a hundred random households. Horizontal axis is labeled in days, starting at Monday morning and ending at Sunday evening. Vertical axis is labeled in Watts.</figDesc><graphic coords="135,98.90,564.74,198.26,99.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_53"><head>Figure 9 . 13 :</head><label>913</label><figDesc>Figure 9.13: CompVAE performance on electrical consumption curves. The reconstructions (a,b,c) show the target curve in red, and the Gaussian model prediction by its mean (purple) and standard deviation (light blue). (a) shows the reconstructed X1, (b) the reconstructed X2 given the real X1, and (c) the reconstructed X2 given the reconstructed X1. (d) shows 5 generated curves from the same set of { i } metadata.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_54"><head>Figure 9 . 14 :</head><label>914</label><figDesc>Figure 9.14: Histograms of the overall distribution of generated curves (orange) and the dataset (blue) according to 3 domain-specific metrics: the peak value, the flexibility, and the maximum-value sustained over 8 hours (top-8h).</figDesc><graphic coords="138,158.38,494.36,277.56,186.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_55"><head></head><label></label><figDesc>{W i } i loss (bits) Z loss (bits) Total latent loss (bits)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_56"><head></head><label></label><figDesc>Fine-tuning a generative model . . . . . . . . . . 146 10.4 Summary and perspectives . . . . . . . . . . . . . . . . . . . . . . 150 10.A Derivation of the MaxEnt solution . . . . . . . . . . . . . . . . . . 151 10.B Proofs of the derivative formulas . . . . . . . . . . . . . . . . . . . 151 10.C Monte-Carlo Prediction of Ep λ f and D KL (p λ p) . . . . . . . . . 154</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_57"><head></head><label></label><figDesc>pλ with its formal definition (Equation 10.5) and dropping the constant terms: pλ = arg max p H(p) + E x∼p λf (x) + log p(x) (10.11)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_58"><head></head><label></label><figDesc>18) with |J(g)(x)| the determinant of the Jacobian matrix of g in x. The optimization problem defined in Equation 10.11 then is rewritten as an optimization on g: arg max g E x∼p λf (g(x)) + log p(g(x)) + log |J(g)(x)| (10.19)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_59"><head></head><label></label><figDesc>5): pλ ∝ p(x) c(y|x) λ (10.21) If classifier c accurately approximates p(y|x), then setting λ = 1 gives pλ ≈ p(x|y) after Bayes theorem. Depending on the value of λ, one might control the strength of the bias, from a slight oversampling of class y (λ &lt; 1) to a strong preference for examples unambiguously classified into class y (λ &gt; 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_60"><head>Figure 10 . 1 :</head><label>101</label><figDesc>Figure 10.1: Comparing criterion f (x) = c(y|x) (in blue) and f (x) = log c(y|x) (in orange) on MNIST: binned distribution of their gradient norms. The distribution tails are truncated for the sake of visualization.</figDesc><graphic coords="150,98.90,338.54,396.52,163.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_61"><head></head><label></label><figDesc>Figure 10.2 reports D KL (p λ p) versus Ep λ f , comparing the empirical value (in orange) and the theoretical value (in blue) for both f = c(y|x) (Figure 10.2, left) and f = logc(y|x) (Figure 10.2, right). The theoretical values are numerically computed by sampling p and using the following formulas (derivations detailed in Appendix 10.C): E pλ f = Ep f e λf Ep e λf (10.22) D KL (p λ p) = Ep f e λf Ep e λf -log E p e λf (10.23)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_62"><head>(</head><label></label><figDesc>c) D KL (p λ p) as a function of λ using c(y|x). (d) D KL (p λ p) as a function of λ using log c(y|x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_63"><head>Figure 10 . 2 :</head><label>102</label><figDesc>Figure 10.2: Comparing the theoretical (in blue) and empirical (in orange) values of the criteria. Left: f (x) = c(y|x). Right: f (x) = log c(y|x).</figDesc><graphic coords="152,98.90,512.88,190.33,149.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_64"><head>( a )</head><label>a</label><figDesc>Ep λ f as a function of D KL (p λ p) using c(y|x).(b) Ep λ f as a function of D KL (p λ p) using log c(y|x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_65"><head>Figure 10 . 3 :</head><label>103</label><figDesc>Figure 10.3: Representation of the theoretical (blue lines) and empirical (orange dots) Pareto front between both criteria, depending on the choice of f , using either f (x) = c(y|x) (left) or f (x) = log c(y|x) (right).</figDesc><graphic coords="152,305.09,514.40,190.33,148.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_66"><head>Figure 10 . 4 :</head><label>104</label><figDesc>Figure 10.4: Samples generated from pλ biasing a generative model trained on MNIST towards the class 4( using f (x) = log c(y = 4|x)). The top to bottom rows respectively correspond to λ = {0.0, 0.25, 0.5, 0.75, 1.0, 1.25}. In each row are presented samples from pλ : pλ = p for λ = 0 (top row) and the bottom row corresponds to the theoretical conditional model (λ = 1).</figDesc><graphic coords="153,158.38,99.21,277.57,206.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_67"><head>( a )</head><label>a</label><figDesc>Real curves. (b) Maximizing f peak . (c) Maximizing f sustained . (d) Maximizing f flexibility .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_68"><head>Figure 10 . 5 :</head><label>105</label><figDesc>Figure 10.5: Generation of electrical consumption curves: original curves (in blue), curves generated from the base distribution (in green) and from the biased distribution (in red). (a): Original curves. (b): Curves biased toward high consumption peak. (c): Curves biased toward sustained consumption (over 8 hours, thus biased toward the top 16 highest consumption. (d) Curves biased toward high flexibility. In each case, 5 curves are sampled and superposed to illustrate the variety of the generation.</figDesc><graphic coords="154,98.90,220.54,190.32,102.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_69"><head>( a )</head><label>a</label><figDesc>E pλ f (y axis) vs λ (x axis). (b) D KL (p λ p) (y axis) vs λ (x axis). (c) E pλ f (y axis) vs D KL (p λ p) (x axis).(d) Generated samples, with the strength λ of the bias increasing from top to bottom rows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_70"><head>Figure 10 . 6 :</head><label>106</label><figDesc>Figure 10.6: Adversarial refinement of p G (VAE trained on MNIST) based on an adversarial discriminator f , comparison of theoretical (in blue) and empirical results (in orange). 10.6(a), 10.6(b): Evolution of E pλ f and D KL (p λ p) with λ. 10.6(c): Pareto front of both objectives. 10.6(d): top to bottom rows respectively correspond to λ in {0.0, 0.125, 0.250, 0.375, 0.5, 0.625, 0.750}; on each row are samples generated from pλ , showing a mode dropping phenomenon (see text).</figDesc><graphic coords="155,120.74,243.81,158.61,122.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_71"><head>Figure 10 . 7 :</head><label>107</label><figDesc>Figure 10.7: Distribution of the norm of the gradient of the objective f (preactivation output of the discriminator) wrt to the latent variable. The histogram is truncated at a norm of 20 for clarity, but around 1% of the gradients have a norm circa 230.</figDesc><graphic coords="156,98.90,99.21,396.52,199.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_72"><head></head><label></label><figDesc>Figure 10.6(b) shows the optimization plateau at the same value of λ for which the curve for D KL steepens, hinting at a point where the optimization landscape contains large plateaus and high cliffs, as in Section 10.3.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_73"><head></head><label></label><figDesc>) s.t. ∀i : E x∼p f i (x) = C i (10.28)In order to solve it, we use consider the Lagrange multiplier method, defining the Lagrangian as: )f i (x)dx -C i i-th constraint (10.29) Then, solving for p and the Lagrange multipliers η and (λ i ) i implies requiring that we are at a saddle point of the Lagrangian L for all of these variables. For p, this means that, for any small perturbation p → pδ p the first-order change of the Lagrangian must be δL = 0. Injecting this into the definition and only keeping first-order terms in δ p yields: δL = X log p(x) + 1 -ηi λ i f i (x) δ p(x)dx (10.30)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_74"><head>From 2 =</head><label>2</label><figDesc>In order to derive the formulas for the derivatives, let us first derive two intermediate results (assuming a single criterion f and Lagrange multiplier λ):Lemma 10.1. The derivative d dλ log Z(λ) reads:d dλ log Z(λ) = E pλ f (10.35) Proof. As Z(λ) = x p(x)e λf (x) dx by definition, it follows: Let h : X → R be a function (possibly depending on λ as well as x).The derivative of its expectation on pλ wrt λ reads:x h(x)p(x)e λf (x) dx = 1 Z(λ) x h(x)f (x) + ∂h ∂λ (x) p(x)e λf (x) dx -1 Z(λ) 2dZ dλ x h(x)p(x)e λf (x) dx Lemma 10.1 and Lemma 10.2, we can derive the first and second derivatives of Ep λ f : Lemma 10.3. The first and second derivatives of Ep λ f wrt λ read: Replacing h with f in Equation 10.37, and noting that f does not depend on λ, yields the first derivative: V ar pλ f (10.40) Noting that V ar pλ f = Ep λ f -Ep λ f 2 and replacing h with f -Ep λ f 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_75"><head></head><label></label><figDesc>first and second derivatives of D KL (p λ p): Lemma 10.4. The first and second derivatives of D KL (p λ p) wrt λ read: d dλ D KL (p λ p) = λV ar pλ f and d 2dλ 2 D KL (p λ p) = V ar pλ f + λ E By definition:D KL (p λ p) = E + λV ar pλ [f ] -E pλ [f ]= λV ar pλ f (10.44) and:d dλ D KL (p λ p) = V ar pλ f + λ d dλ V ar pλ f = V ar pλ f + λ E -Carlo Prediction of E pλ f and D KL (p λ p)Following the theoretical definition of pλ (Equation10.5): pλ (x) = p(x) Z(λ) e λf (x) (10.46) One can express Z(λ) as: Z(λ) = x p(x)e λf (x) dx = E p e λf (10.47) From this, interpreting the integrals as expectations over p yield the expected results: p(x)e λf (x) Z(λ) dx = x p(x)f (x)e λf (x) dx x p(x)e λf (x) dx = Ep f e λf Ep e λf (10.48) Similarly, re-injecting the definition of pλ into the KL yields: D KL (p λ p) = E using the previous results: D KL (p λ p) = Ep f e λf Ep e λf -log E p e λf (10.52)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_76"><head>Titre:</head><label></label><figDesc>Modèles à Variables Latentes Profonds : des propriétés aux structures Mots clés : Modèles Génératifs, Apprentissage Profond, Modèles à Variables Latentes, Réseaux Bayésiens Résumé : Les Modèles à Variables Latentes Profonds sont des modèles génératifs combinant les Réseaux Bayésiens avec l'apprentissage profond, illustrés par le célèbre Auto-encodeur Variationnel. Cette thèse se focalise sur leur structure, entendue comme la combinaison de 3 aspects : le graphe du Réseau Bayésien, le choix des familles probabilistes des variables, et l'architecture des réseaux de neurones. Nous démontrons que de nombreux aspects et propriétés de ces modèles peuvent être compris et contrôlés par cette structure, sans altérer l'objectif d'entraînement construit sur l'Evidence Lower Bound. La première contribution concerne l'impact du modèle d'observation -la modélisation probabiliste des variables observées -sur le processus d'entraînement : comment il détermine la séparation entre signal et bruit, ainsi que son impact sur la dynamique de l'entraînement lorsque son paramètre d'échelle est appris plustôt que fixé, où il agit alors comme un processus de recuit simulé. La seconde contribution, CompVAE, est cen-trée sur la structure hiérarchique des variables latentes : un modèle génératif conditionné par un multi-ensemble d'élements à combiner dans la génération finale. CompVAE démontre comment des propriétés globales -des manipulations ensemblistes dans ce cas -peuvent être atteintes par la seule conception structurale. Ce modèle est de plus validé empiriquement sur des données réelles, pour la génération de courbes de consommation électrique. La troisième contribution, Boltzmann Tuning of Generative Models (BTGM), est un cadre permettant d'ajuster un modèle génératif pré-entraîné selon un critère extérieur, en trouvant les ajustements minimaux nécessaire. Ceci est fait tout en contrôlant finement quelles variables latentes sont ajustées, et comment elles le sont. Nous démontrons empiriquement comment BTGM peut être utilisé pour spécialiser un modèle déjà entraîné, ou pour explorer les parties extrêmes d'une distribution générée.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="54,138.55,99.21,317.22,208.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Chapter 3 Deep Latent Variable Models Contents</head><label></label><figDesc>Discrete latent variables . . . . . . . . . . . . . . . . . . . . . . . . 47 3.4 Impact of the Inference Model . . . . . . . . . . . . . . . . . . . . 49 3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50</figDesc><table><row><cell>3.1 The Variational Auto-Encoder . . . . . . . . . . . . . . . . . . . . 41</cell></row><row><cell>3.1.1 Amortized Inference . . . . . . . . . . . . . . . . . . . . . 41</cell></row><row><cell>3.1.2 The Reparametrization Trick . . . . . . . . . . . . . . . . 42</cell></row><row><cell>3.1.3 Link with Auto-Encoders . . . . . . . . . . . . . . . . . . 43</cell></row><row><cell>3.2 Advanced latent models . . . . . . . . . . . . . . . . . . . . . . . . 44</cell></row><row><cell>3.2.1 Powerful encoders and complex latent spaces . . . . . . . 44</cell></row><row><cell>3.2.2 Learned latent distributions . . . . . . . . . . . . . . . . . 46</cell></row><row><cell>3.3 Latent Variable Models took a new turn with the rise of Deep Learning, yielding</cell></row><row><cell>the famed Deep Latent Variable Models. Note that "deep" refers to the use of deep</cell></row><row><cell>artificial networks to implement and learn the functions underlying the graphical</cell></row><row><cell>model, and not to the topology of the graph. The most typical example of these</cell></row><row><cell>Deep LVMs is the Variational Auto-Encoder.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Chapter 4 Hierarchical Deep LVMs Contents 4</head><label></label><figDesc>.1 The ELBO with hierarchical latent variables . . . . . . . . . . . . 51 4.2 Optimization of hierarchical structures . . . . . . . . . . . . . . . 53 This chapter extends the Variational Auto-Encoder framework and the ELBO learning criterion, to the general case of Hierarchical Deep LVMs, where several latent and/or observed variables are structured into a Deep LVM.</figDesc><table /><note><p>4.2.1 Gradient flow . . . . . . . . . . . . . . . . . . . . . . . . . 53 4.2.2 Stability problems . . . . . . . . . . . . . . . . . . . . . . 54 4.2.3 Alternative training formulations . . . . . . . . . . . . . . 54 4.2.4 Key design considerations . . . . . . . . . . . . . . . . . . 56 4.3 Graph Structure Learning . . . . . . . . . . . . . . . . . . . . . . 58 4.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>.4: Example of a latent structure that could be learned by LTVAE. At the end of the training, if several Z i variables are attached to the same Y j (like Z 3 and Z 4 here), they can be fused into a single variable.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Observation models Chapters 5 Probabilistic interpretation of observed variables 6 The Manifold Hypothesis and Quasi-Deterministic Observations 7 Dynamics of Variance Learning Chapter 5 Probabilistic interpretation of observed variables Contents</head><label></label><figDesc></figDesc><table /><note><p>5.1 Perceptual distances for images . . . . . . . . . . . . . . . . . . . 63 5.1.1 Gaussian observation and choice of distance . . . . . . . . 64 5.1.2 NN-based perceptual distances . . . . . . . . . . . . . . . 65 5.2 Autoregressive observation models . . . . . . . . . . . . . . . . . . 66 5.2.1 Recurrent Neural Networks for sequential data . . . . . . 66 5.2.2 PixelRNN and PixelCNN for image generation . . . . . . 67 5.2.3 WaveNet for audio generation . . . . . . . . . . . . . . . . 68 5.3 RealNVP and flows-based observation models . . . . . . . . . . . 69 5.4 The Posterior Collapse Phenomenon . . . . . . . . . . . . . . . . . 70 5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Reported ROC area under curve (AUC) for MNIST (left) Fashion-MNIST (right) datasets and different anomaly detection algorithms as a function of varying anomaly threshold t based on LeNet-5 [Lec+98a] model classification log loss.Overall classifier accuracy is 98.95% and 89.62% for MNIST and Fashion-MNIST respectively. The curves stay relatively flat due to high performance of the classifier: most of the test samples have log loss smaller than 0.01. The variance is computed over 5 independent runs.</figDesc><table><row><cell>AUC</cell><cell>0.8</cell><cell></cell><cell></cell><cell>AUC</cell><cell>0.7</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.4 0.3</cell><cell>CVAE's ⅅKL VAE's ⅅKL μSVM Isolation Forest</cell><cell></cell><cell></cell><cell>0.4 0.3</cell><cell>CVAE's ⅅKL VAE's ⅅKL μSVM Isolation Forest</cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6 Anomaly Treshold [Log Loss] 0.8 1.0</cell><cell>0.0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6 Anomaly Treshold [Log Loss] 0.8 1.0</cell></row><row><cell cols="3">Figure 8.6:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>neural network implementing p θ (x|z, k) can appropriately mix Z and K into the final prediction X. As above, Z being concise makes it less susceptible to dimensionality issues.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>28) Exploration of the Pareto front . . . . . . . . . . . . . . . 137 10.2 The Boltzmann tuning of Generative Models . . . . . . . . . . . . 138 10.2.1 Generalizing to multiple variables . . . . . . . . . . . . . . 139 10.2.2 Using normalizing flows . . . . . . . . . . . . . . . . . . . 141 10.2.3 Comparing and selecting the f criterion . . . . . . . . . . 141 10.3 Case studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142</figDesc><table><row><cell>Chapter Latent manipulation from 10 Boltzmann principles</cell></row><row><cell>Contents</cell></row><row><cell>10.1 Boltzmann distributions and Pareto exploration . . . . . . . . . . 136</cell></row><row><cell>10.1.1 Principle of maximum (relative) entropy . . . . . . . . . . 136</cell></row><row><cell>10.1.2 10.3.1 Case 1: Conditioning a distribution . . . . . . . . . . . . . 142</cell></row><row><cell>10.3.2 Case 2: Extreme values of a distribution . . . . . . . . . . 144</cell></row><row><cell>10.3.3 Case 3:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Maximizing Ep λ f subject to D KL (p λ p) D ← Target value for D KL (p λ p) λ ← 0 repeat pλ ← arg max p H(p) + Ex∼p λf (x) + log p(x)(Equation 10.11) Estimate D KL (p λ p) by Monte-Carlo Estimate d dλ D KL (p λ p) using Equation 10.6 by Monte-Carlo Estimate d 2 dλ 2 D KL (p λ p) using Equation 10.8 by Monte-Carlo λ ← Second order update to bring D KL (p λ p) towards D until convergence of λ return pλ Minimizing D KL (p λ p) subject to Ep</figDesc><table><row><cell>1</cell></row><row><cell>and Algorithm 10.2.</cell></row><row><cell>Algorithm 10.1 Algorithm 10.2</cell></row></table><note><p>λ f F ← Target value for Ep λ f λ ← 0 repeat pλ ← arg max p H(p) + Ex∼p λf (x) + log p(x) (Equation 10.11) Estimate Ep λ f by Monte-Carlo Estimate d dλ Ep λ f using Equation 10.7 by Monte-Carlo Estimate d 2</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Contract NEXT, funded by ADEME, French Agence de la Transition Ecologique.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>A notable example is the representation of a statistical link between illnesses and their symptoms.In such case, one can introduce one variable per illness and per symptom.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>This is the case if either the distribution is positive (no configuration has a probability of 0) or the graph is chordal (all cycle of size greater than</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>has an internal edge connecting two of its nodes, forming smaller cycles as well).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>Indeed, any Bayesian Network can be converted into a Markov Networks by using the conditional probabilities associated to each node as a clique potential. On the other hand, not all Markov Networks can be converted into a Bayesian Network over the same set of variables.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>Another usage is that of counterfactual reasoning (what if not) [PJS17; PM18]. This is outside of the scope of the presented research.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_6"><p>This inference problem bears mathematical similarities with that of constraints programming<ref type="bibr" target="#b155">[RVW06]</ref>, but we focus here on inference queries on probabilistic graphs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>While log p(z|x) = log p(z, x) -log p(x), note that the later term is a constant, and thus does not affect the optimization process.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_8"><p>We can for example think of the micro-states in statistical physics, or the actual number of contaminated persons (as opposed to the number of reported cases) in an epidemiological model.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_9"><p>In particular, Gaussian functions being universal approximators<ref type="bibr" target="#b123">[MS96]</ref>, a Gaussian mixture with a sufficiently large number of component would be able to represent any reasonable distribution.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_10"><p>For example, any distribution with a known cumulative distribution function F can be expressed this way: let z by a uniform variable over [0; 1] and x deterministically derived from it: x = F -1 (z). p(z) is a simple uniform distribution and p(x|z) is a simple constant distribution, yet the marginal p(x) is the distribution defined by F , which can be arbitrarily complex.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_11"><p>The Bayesian posterior over the parameters of a non-identifiable model does not converge to a point measure in the large sample limit, while it does converge for an identifiable model.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_12"><p>The choice of the KL-divergence as an optimization objective is in part driven by the fact that it makes the optimization problem rather easy to manipulate and does not require the distribution p to be sampled nor normalized.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_13"><p>If each qi is a single-mode distribution, then the complete q will have a single mode as well. But even if the qi can be multi-modal, this forces the modes of each dimension to be independent, which is unlikely to match the real structure of p(z|x), causing the inference model to still choose a single mode and fit it.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_14"><p>While the source of this high variance is not theoretically established, to our best knowledge, it intuitively reflects the fact that this estimator does not use any differential information from g, only its values.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_15"><p>In negative-curvature spaces distances tend to grow quickly in a non-intuitive way. While the perimeter of a circle in an euclidean space grows linearly with its radius, in a negative-curvature space it will grow quicker. This means that the amount of space at a given maximal distance from the origin is higher in negative-curved spaces, allowing to arrange more datapoints equidistant from each other than would be in an euclidean one. This property is successfully exploited to represent geometrically hierarchically-structured data.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_16"><p>In order to separate two very close latent values, the neural network (the represented function) must allow for abrupt variations in their vicinity. Depending on the optimization algorithm and neural architectures, this might be hardly doable or unstable.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_17"><p>Unfortunately, the log-trick yields poor estimates of the gradient in this context.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_18"><p>Letting k be sampled from a categorical distribution with K values, its one-hot encoding is the K-dimensional vector with all coordinates set to 0 except for the k-th, set to 1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_19"><p>This properties relies on the specific choice of p(ζi|zi) made in DVAE, and the re-use of that same distribution in q φ .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_20"><p>Unless powerful inference models, e.g. Normalizing Flows or MCMC-based, are considered.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_21"><p>A topological ordering is the definition of an ordering relation of the graph compatible with its topological structure, meaning that if node B is a descendant of node A, then the ordering must have A B. A topological ordering for a given DAG is not necessarily unique.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_22"><p>It is classic to use Adam with lower momentum parameters than the standard, such as (β1, β2) = (0.5, 0.9) rather than (0.9, 0.999), the later being often unstable when used with VAEs.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_23"><p>This argument also applies to pθ for latent variable which have parents: if p θ (zi|π(Zi)) is randomly initialized this gives a very opinionated shape to the associated latent space.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_24"><p>The variance of the random initialization is reduced by taking into account the number of different paths reaching a certain point of the network. This ensures that at initialization, the network as a whole preserves the input variance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_25"><p>The main mechanism of GANs is the use of a so-called "discriminator network": a binary classifier aims to distinguish images from the real dataset from the ones produced by the generative model. The generative model is then trained by reversing the discriminator gradient, in order to fool the discriminator.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_26"><p>The discretized logistic, a distribution similar to the Normal distribution, is likewise parameterized by a location and a scale parameter. A main difference lies in its distribution support, set to an integer interval as opposed to R. The interested reader is refferred to<ref type="bibr" target="#b159">[Sal+17]</ref> for a more comprehensive presentation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_27"><p>https://deepmind.com/blog/article/wavenet-launches-google-assistant</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_28"><p>Permutations of the components of x are invertible operations whose Jacobian determinant is 1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_29"><p>The dequantization problem arises when training continuous probabilistic models (such as realNVP) on data that have been discretized (such as images whose pixel values are in [|1; 255|]). In that case, the target distribution actually lives in a discrete grid-like subspace of the data space, making it a collection of point masses. Such a distribution, beyond the reach of most continuous models, may cause the training to diverge. Dequantization is the process of adding a small continuous noise to the discretized data to make it continuous again.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_30"><p>There is a very natural and intuitive way to continuously transform a photograph into another: making both of them part of the same filmed video that goes from one point of view to the other.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_31"><p>Such task include for example using the VAE as a dimensionality-reduction algorithm, comparable to a non-linear PCA<ref type="bibr" target="#b113">[Luc+19]</ref>. Part III further expands on design of the latent structure of the LVM to extract sought information or enforce desirable properties.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_32"><p>It is actually difficult to measure precisely how widespread it is used: a large fraction of articles about VAEs do not explicit their observation models.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_33"><p>All structure being fixed, the model needs to pack less information into a latent space of the</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_34"><p>Note that Figure6.5 suggests the cutoff is actually at σ √ D.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_35"><p>Using a Resnet-based architecture with a 10 dimensional latent variable z.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_36"><p>As σ(z) must be strictly positive, it is usually sought as the softplus of an expression, and goes to 0 as this expression goes to -∞.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_37"><p>For q φ (z|x) a deterministic Dirac distribution, its KL to a non-tereministic prior is -∞.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_38"><p>For example, noting σmin the lower-bound, the predicted σ can be passed to a threshold function such as σ → max(σ, σmin) or σ → σmin + sof tplus(σ).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_39"><p>More precisely, the global average if σ is globally optimized by gradient descent; the local average in the image of the latent region if σ is learned as a function of z.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_40"><p>For example, the Gaussian observation includes an additive log σ term to the loss, breaking the equivalence.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_41"><p>The tempered observation model is in general not in the same distribution family as the original model, as a result it cannot be expected that the model would exactly compensate it. Notable exceptions are exponential family distributions (such as categorical, Gaussian or Beta for example), for which the tempering operation does preserve the class, and amounts to a simple reparametrization which learning can in principle compensate. It will however still affect training dynamics.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_42"><p>Previously proved in Equation 4.5.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_43"><p>pβ (x) is just a reparametrization σ 2 → βσ 2 for which the learning process can compensate exactly.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_44"><p>Optimizing the ELBO drives q φ (z|x, y)q φ (y|x) to be a good approximation of p θ (z, y|x), which in turns implies that q φ (y|x) is trained to be a good approximation of p θ (y|x).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_45"><p>A multi-set differs from a standard mathematical set as it can contain multiple copies of some elements.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_46"><p>Likewise, when generating an image based on the involved entities, i might specify that the i-th entity s a chair; still there are many instances of chair.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_47"><p>If such a proportionality is not desirable, the structure of the neural networks needs to be adjusted accordingly, for example by introducing (at least) one layer of saturating activation functions like the sigmoid or the hyperpolic tangent, as done in section 9.3.2.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_48"><p>Even with a fully-connected graph, the computational cost remains reasonable thanks to the chosen structure: ΦL needs only be computed once, and the sum on all neighbors can be efficiently computed by first computing the sum on all nodes, and then subtracting the value from the current node from that total sum. The complete process thus remains linear in the number of elements of the composition, not quadratic.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_49"><p>The electricity provider proposes electrical contracts where the electricity is cheaper during some time range (usually during the night), as an incentive to shift part of the consumption (such as water heaters or washing machines) during off-peak hours.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_50"><p>As the number of ways to randomly choose between 50 and 150 elements from a set of 500 or magnitude comparable to 10 130</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_51"><p>The error is computed as the sum of absolute error across time, divided by the number of households in the composition, so that values associated with different number of households can still be compared.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_52"><p>Though a slight bias, interpreted as the amplification of the entity interdependencies, is observed on the electrical curves case study.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_53"><p>Both associated Lagrangians (see details in Appendix 10.A) are very similar, the only difference being whether the Lagrange multiplier λ applies on f or of the KL-divergence. As a result, they yield the same solution, up to a reparameterization of λ into 1/λ.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_54"><p>In the case where more than one fi criterion is considered, the approach can be extended to characterize in closed form the gradient of the criteria w.r.t. the (λi)i vector, as well as their Hessian matrix.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_55"><p>The criterion f under pλ reads E(x,z)∼ pλ f (x). Under the assumption pλ (x, z) = p(x|z)p λ (z), this can be decomposed as Ez∼p λ Ex∼p(x|z) f (x). The latter is expressed as the expectation of the alternative criterion f (z) = Ex∼p(x|z) f (x) under pλ (z), effectively moving the decoder part of the model into the optimization criterion.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_56"><p>If the inference model is limited to be single mode, e.g. Gaussian, then the generative model p θ (x, z) is driven to learn a latent representation compatible with this inference model: such that p θ (z|x) has a single mode as well (Section 3.4), therefore x is a quasi-invertible function of z.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_57"><p>When using the classification probability, the maximum gap between the predicted and reached values for the KL-divergence is 0.58, while it is of only 0.17 when using the log-probability (the values of f are not comparable as they are on different scales).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_58"><p>The full integration of CompVAE and BTGM is not achieved at time of writing.</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remerciements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Towards Principled Methods for Training Generative Adversarial Networks</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.04862</idno>
		<idno>arXiv: 1701.04862</idno>
		<imprint>
			<date type="published" when="2017-01-17">Jan. 17, 2017</date>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page">44</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Automatic Control</title>
		<imprint>
			<date type="published" when="1974-12">Dec. 1974</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fixing a Broken ELBO</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rif</forename><forename type="middle">A</forename><surname>Saurous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page">155</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Synthesizing Robust Adversarial Examples</title>
		<author>
			<persName><forename type="first">Anish</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Model Selection and Inference: A Practical Information-Theoretic Approach</title>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">P</forename><surname>Burnham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Anderson ; Kenneth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Burnham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Springer</publisher>
			<biblScope unit="page">24</biblScope>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Practical Use of the Information-Theoretic Approach</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Endowing a Content-Based Medical Image Retrieval System with Perceptual Similarity Using Ensemble Strategy</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Vinicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naves</forename><surname>Bedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Davi</forename><surname>Pereira Dos Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcelo</forename><surname>Ponciano-Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paulo</forename><surname>Mazzoncini De Azevedo-Marques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Imaging</title>
		<idno type="ISSN">1618-727</idno>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2016-02-01">Feb. 1, 2016</date>
		</imprint>
	</monogr>
	<note>André Ponce de León Ferreira de Carvalho, and Caetano Traina</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sylvester Normalizing Flows for Variational Inference</title>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonard</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><surname>Hasenclever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jakub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05649</idno>
	</analytic>
	<monogr>
		<title level="m">UAI 2018</title>
		<imprint>
			<date type="published" when="2019-02-20">Feb. 20, 2019</date>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Representations of knowledge in complex systems</title>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">U</forename><surname>Je Besag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Grenander</surname></persName>
		</author>
		<author>
			<persName><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Variational Bayesian EM Algorithm for Incomplete Data : with Application to Scoring Graphical Model Structures</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics</title>
		<imprint>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="2002-07-25">July 25, 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Variational Bayesian learning of directed graphical models with hidden variables</title>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Publisher: International Society for Bayesian Analysis</title>
		<imprint>
			<date type="published" when="2006-12">Dec. 2006</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Importance Weighted Autoencoders</title>
		<author>
			<persName><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<idno>arXiv: 1509.00519</idno>
		<imprint>
			<date type="published" when="2016-07">Nov. 7, 2016</date>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Approximating Posterior Distributions in Belief Networks Using Mixtures</title>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 10</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kearns</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Solla</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bounded Information Rate Variational Autoencoders</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Braithwaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.07306</idno>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2018-07-25">2018. July 25, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Generating Sentences from a Continuous Space</title>
		<author>
			<persName><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-11-19">Nov. 19, 2015</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">66</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Stochastic Deep Networks</title>
		<author>
			<persName><forename type="first">Gwendoline</forename><surname>De Bie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Peyré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019-05-24">May 24, 2019</date>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page">116</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">From Abstract Items to Latent Spaces to Observed Data and Back: Compositional Variational Auto-Encoder</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michèle</forename><surname>Sebag ; Ulf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Brefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Fromont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arno</forename><surname>Hotho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marloes</forename><surname>Knobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Céline</forename><surname>Maathuis</surname></persName>
		</author>
		<author>
			<persName><surname>Robardet</surname></persName>
		</author>
		<idno>978-3-030-46150-8</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page" from="274" to="289" />
		</imprint>
	</monogr>
	<note>cit. on pp. 8, 115</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Variational Auto-Encoder: not all failures are equal</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michèle</forename><surname>Sebag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.01972</idno>
		<idno>arXiv: 2003.01972</idno>
		<imprint>
			<date type="published" when="2020-04">Mar. 4, 2020</date>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
	<note>cs, eess, stat</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Boltzmann Tuning of Generative Models</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michele</forename><surname>Sebag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.05252</idno>
		<idno>arXiv: 2104.05252</idno>
		<imprint>
			<date type="published" when="2021-04-12">Apr. 12, 2021</date>
			<biblScope unit="page" from="8" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Why Deep Learning Works: A Manifold Disentanglement Perspective</title>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Brahma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dapeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyuan</forename><surname>She</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2015-12-16">Dec. 16, 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Information and Entropy</title>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Caticha</surname></persName>
		</author>
		<idno type="arXiv">issn:0094243X.arXiv:0710.1068</idno>
	</analytic>
	<monogr>
		<title level="m">AIP Conference Proceedings</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">954</biblScope>
			<biblScope unit="page">136</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Algorithms for manifold learning</title>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Cayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Univ. of California at San Diego Tech. Rep</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">74</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Variational Autoencoder with Learned Latent Structure</title>
		<author>
			<persName><forename type="first">Marissa</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Canal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Rozell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics. International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2021-03-18">Mar. 18, 2021</date>
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hamiltonian Variational Auto-Encoder</title>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Anthony L Caterini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dino</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Sejdinovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Bayesian method for the induction of probabilistic networks from data</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><surname>Herskovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="1992">1992</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Variational Lossy Autoencoder</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02731</idno>
		<imprint>
			<date type="published" when="2017-04">Mar. 4, 2017</date>
			<biblScope unit="page">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Isolating Sources of Disentanglement in Variational Autoencoders</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">PixelSNAIL: An Improved Autoregressive Generative Model</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">I</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">68</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Large-Sample Learning of Bayesian Networks is NP-Hard</title>
		<author>
			<persName><forename type="first">David</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chickering</forename></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<idno type="ISSN">1533-7928</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2004-10">Oct 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Recurrent Latent Variable Model for Sequential Data</title>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2980" to="2988" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Fuzzy Logic tool for household electrical consumption modeling</title>
		<author>
			<persName><forename type="first">Lucio</forename><surname>Ciabattoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Grisostomi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianluca</forename><surname>Ippoliti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sauro</forename><surname>Longhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IECON 2013 -39th Annual Conference of the IEEE Industrial Electronics Society. IECON 2013 -39th Annual Conference of the IEEE Industrial Electronics Society</title>
		<imprint>
			<date type="published" when="2013-11">Nov. 2013</date>
			<biblScope unit="page">115</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient Structure Learning of Bayesian Networks using Constraints</title>
		<author>
			<persName><forename type="first">P</forename><surname>Cassio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>De Campos</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<idno type="ISSN">1533-7928</idno>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">WAIC, but Why? Generative Ensembles for Robust Anomaly Detection</title>
		<author>
			<persName><forename type="first">Hyunsun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.01392</idno>
		<idno>arXiv: 1810.01392</idno>
		<imprint>
			<date type="published" when="2019-05-23">May 23, 2019</date>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page">105</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Reinterpreting Importance-Weighted Autoencoders</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Cremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quaid</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.02916</idno>
		<idno>arXiv: 1704.02916</idno>
		<imprint>
			<date type="published" when="2017-08-14">Aug. 14, 2017</date>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. AISec &apos;17</title>
		<meeting>the 10th ACM Workshop on Artificial Intelligence and Security. AISec &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017-11-03">Nov. 3, 2017</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Connections with Robust PCA and the Role of Emergent Sparsity in Variational Autoencoder Models</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Aston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wipf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<idno type="ISSN">1533-7928</idno>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generating Images with Perceptual Similarity Metrics based on Deep Networks</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">D D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition. 2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009-06">June 2009</date>
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Nat</forename><surname>Dilokthanakul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">A M</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugh</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Salimbeni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murray</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName><surname>Shanahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02648</idno>
		<idno>arXiv: 1611.02648</idno>
		<imprint>
			<date type="published" when="2017-01-13">Jan. 13, 2017</date>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">NICE: Non-linear Independent Components Estimation</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<idno>arXiv: 1410.8516</idno>
		<imprint>
			<date type="published" when="2015-04-10">Apr. 10, 2015</date>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Maximum Likelihood from Incomplete Data via the EM Algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<idno type="ISSN">0035-9246</idno>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="1977">1977</date>
			<publisher>Royal Statistical Society, Wiley</publisher>
		</imprint>
	</monogr>
	<note>Publisher</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Messagepassing algorithms for compressed sensing</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arian</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Montanari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2009-11-10">Nov. 10, 2009</date>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Document Hashing with Mixture-Prior Generative Models</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinliang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). EMNLP-IJCNLP 2019</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">Nov. 2019</date>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Laplacian Pyramid of Conditional Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Garoe</forename><surname>Dorta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lourdes</forename><surname>Agapito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivor</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName><surname>Simpson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th European Conference on Visual Media Production</title>
		<meeting>the 14th European Conference on Visual Media Production<address><addrLine>London, United Kingdom</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017-12-11">2017. 2017. Dec. 11, 2017</date>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page">155</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">On the Optimality of the Simple Bayesian Classifier under Zero-One Loss</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<idno type="ISSN">1573-0565</idno>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">104</biblScope>
			<date type="published" when="1997-11-01">Nov. 1, 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Density estimation using Real NVP</title>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<imprint>
			<date type="published" when="2017-02-27">Feb. 27, 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Constraining Variational Inference with Geometric Jensen-Shannon Divergence</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Deasy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikola</forename><surname>Simidjievski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lió</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Neural Spline Flows</title>
		<author>
			<persName><forename type="first">Conor</forename><surname>Durkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artur</forename><surname>Bekasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>D{\textbackslash}textquotesingle Alché-Buc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Diagnosing and Enhancing VAE Models</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Wipf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05789</idno>
		<imprint>
			<date type="published" when="2019-10-30">Oct. 30, 2019</date>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page">55</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Towards a Neural Statistician</title>
		<author>
			<persName><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02185</idno>
		<imprint>
			<date type="published" when="2017-03-20">Mar. 20, 2017</date>
			<biblScope unit="page">117</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Neural Scene Representation and Rendering</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frederic</forename><surname>Besse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><forename type="middle">S</forename><surname>Morcos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avraham</forename><surname>Ruderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">P</forename><surname>Reichert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theophane</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chloe</forename><surname>Hillier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page">117</biblScope>
			<date type="published" when="2018-06-15">June 15, 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Variational Recurrent Auto-Encoders</title>
		<author>
			<persName><forename type="first">Otto</forename><surname>Fabius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joost</forename><forename type="middle">R</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6581[cs,stat]</idno>
		<idno>arXiv: 1412.6581</idno>
		<imprint>
			<date type="published" when="2015-06-15">June 15, 2015</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">66</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Reparameterizing Distributions on Lie Groups</title>
		<author>
			<persName><forename type="first">Luca</forename><surname>Falorsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pim</forename><surname>De Haan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><forename type="middle">R</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Forré</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02958</idno>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<biblScope unit="page">46</biblScope>
			<date type="published" when="2019-03-07">2019. Mar. 7, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Testing the manifold hypothesis</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Fefferman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjoy</forename><surname>Mitter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hariharan</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Mathematical Society</title>
		<idno type="ISSN">0894-0347</idno>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Sequential Neural Models with Stochastic Layers</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Sø Ren Kaae Sø Nderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ole</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">D</forename><surname>Winther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">66</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Posterior Regularization for Structured Latent Variable Models</title>
		<author>
			<persName><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Jo\&amp;\#227</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Graça</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Gillenwater</surname></persName>
		</author>
		<author>
			<persName><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<idno type="ISSN">1533-7928</idno>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">49</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Murray</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ali Eslami</surname></persName>
		</author>
		<idno>PMLR</idno>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">117</biblScope>
		</imprint>
	</monogr>
	<note>Conditional Neural Processes</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep Sparse Rectifier Neural Networks</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics. the Fourteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011-06-14">June 14, 2011</date>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">53</biblScope>
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Amortized Inference in Probabilistic Reasoning</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images</title>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="1984-11">Nov. 1984</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
	<note>IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI-6</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Nonparametric variational inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Coference on International Conference on Machine Learning. ICML&apos;12</title>
		<meeting>the 29th International Coference on International Conference on Machine Learning. ICML&apos;12<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2012-06-26">June 26, 2012</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">From Variational to Deterministic Autoencoders</title>
		<author>
			<persName><forename type="first">Partha</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Vergari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12436</idno>
		<imprint>
			<date type="published" when="2020-05-29">May 29, 2020</date>
			<biblScope unit="page">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Neural Message Passing for Quantum Chemistry</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017-07-17">July 17, 2017</date>
			<biblScope unit="page">121</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Generative Adversarial Nets</title>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
	<note>cit. on pp. 7, 65, 147</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Explaining and Harnessing Adversarial Examples</title>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<idno>arXiv: 1412.6572</idno>
		<imprint>
			<date type="published" when="2015-03-20">Mar. 20, 2015</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">PatchVAE: Learning Local Latent Codes for Recognition</title>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03623</idno>
		<idno>arXiv: 2004.03623</idno>
		<imprint>
			<date type="published" when="2020-07">Apr. 7, 2020</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">PixelVAE: A Latent Variable Model for Natural Images</title>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kundan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrien</forename><forename type="middle">Ali</forename><surname>Taiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05013</idno>
		<idno>arXiv: 1611.05013</idno>
		<imprint>
			<date type="published" when="2016-11-15">Nov. 15, 2016</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">67</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Boosting Variational Inference</title>
		<author>
			<persName><forename type="first">Fangjian</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamara</forename><surname>Broderick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05559</idno>
		<idno>arXiv: 1611.05559</idno>
		<imprint>
			<date type="published" when="2017-03-01">Mar. 1, 2017</date>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Variational Autoencoder With Optimizing Gaussian Mixture Model Priors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Access</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Alternating Back-Propagation for Generator Network</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><forename type="middle">Nian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence. Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017-02">Feb. 2017</date>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Monte Carlo sampling methods using Markov chains and their applications</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Hastings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<idno type="ISSN">0006-3444</idno>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="1970-04-01">Apr. 1, 1970</date>
		</imprint>
	</monogr>
	<note>Publisher: Oxford Academic</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">53</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Variational Autoencoders with Jointly Optimized Latent Dependency Structure</title>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Lehrmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2019. 2018</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">58</biblScope>
		</imprint>
	</monogr>
	<note>cit</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Lagging Inference Networks and Posterior Collapse in Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Junxian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Spokoyny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.05534</idno>
		<imprint>
			<date type="published" when="2019-01-28">Jan. 28, 2019</date>
			<biblScope unit="page">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</title>
		<author>
			<persName><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loïc</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">155</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">An evaluation of the diagnostic accuracy of Pathfinder</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">E</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bharat</forename><forename type="middle">N</forename><surname>Nathwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Biomedical Research</title>
		<idno type="ISSN">0010-4809</idno>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="1992-02-01">Feb. 1, 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019-05-24">May 24, 2019</date>
			<biblScope unit="page">70</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Gradient flow in recurrent nets: the difficulty of learning long-term dependencies</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A Field Guide to Dynamical Recurrent Neural Networks</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kremer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Kolen</surname></persName>
		</editor>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">53</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Stochastic variational inference</title>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<idno type="ISSN">1532-4435</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2013-05-01">May 1, 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Deep Feature Consistent Variational Autoencoder</title>
		<author>
			<persName><forename type="first">Xianxu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linlin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoping</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision (WACV). 2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2017-03">2017. Mar. 2017</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Reducing the Dimensionality of Data with Neural Networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<idno type="ISSN">0036-8075</idno>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2006-07-28">July 28, 2006</date>
		</imprint>
		<respStmt>
			<orgName>American Association for the Advancement of Science Section</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<idno type="ISSN">0899-7667</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">63</biblScope>
			<date type="published" when="1997-11-01">Nov. 1, 1997</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Publisher</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis</title>
		<author>
			<persName><forename type="first">Huaibo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Distilling the Knowledge in a Neural Network</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<idno>arXiv: 1503.02531</idno>
		<imprint>
			<date type="published" when="2015-09">Mar. 9, 2015</date>
			<biblScope unit="page">69</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Idiot&apos;s Bayes-Not So Stupid After All?</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Hand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keming</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Statistical Review</title>
		<idno type="ISSN">1751-5823</idno>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">104</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Adversarial Examples Are Not Bugs, They Are Features</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Logan</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">104</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Learning Bayesian Network Structure using LP Relaxations</title>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics. the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010-03-31">Mar. 31, 2010</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Information Theory and Statistical Mechanics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Jaynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">136</biblScope>
			<date type="published" when="1957-05-15">May 15, 1957</date>
			<publisher>American Physical Society</publisher>
		</imprint>
	</monogr>
	<note>Publisher</note>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<idno>arXiv: 1611.01144</idno>
		<imprint>
			<date type="published" when="2017-05">Aug. 5, 2017</date>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">An algebra of bayesian belief universes for knowledge-based systems</title>
		<author>
			<persName><forename type="first">Finn</forename><surname>Verner Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristian</forename><forename type="middle">G</forename><surname>Olesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stig</forename><surname>Kjaer Andersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Networks</title>
		<idno type="ISSN">1097-0037</idno>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data</title>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Karl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Soelch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Van Der Smagt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06432</idno>
		<imprint>
			<date type="published" when="2017-03-03">Mar. 3, 2017</date>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="106" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2017-01-29">Jan. 29, 2017</date>
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><surname>Garnett</surname></persName>
		</author>
		<title level="m">Glow: Generative Flow with Invertible 1x1 Convolutions</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">70</biblScope>
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems 31</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models: Principles and Techniques -Adaptive Computation and Machine Learning</title>
		<author>
			<persName><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nir</forename><surname>Friedman</surname></persName>
		</author>
		<idno>978-0-262-01319-2</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>The MIT Press</publisher>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Adversarial examples in the physical world</title>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.02533</idno>
		<idno>arXiv: 1607.02533</idno>
		<imprint>
			<date type="published" when="2017-02-10">Feb. 10, 2017</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Semi-Amortized Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Semi-supervised Learning with Deep Generative Models</title>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Durk P Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27</title>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Improving Variational Inference with Inverse Autoregressive Flow</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafal</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04934</idno>
		<idno>arXiv: 1606.04934</idno>
		<imprint>
			<date type="published" when="2017-01-30">Jan. 30, 2017</date>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114[cs,stat]</idno>
		<idno>arXiv: 1312.6114</idno>
		<imprint>
			<date type="published" when="2014-05-01">May 1, 2014</date>
			<biblScope unit="volume">41</biblScope>
		</imprint>
	</monogr>
	<note>cit. on pp. 7, 8, 34</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName><forename type="first">Anders</forename><surname>Boesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lindbo</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Søren</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016-06-11">June 11, 2016</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Classification using discriminative restricted Boltzmann machines</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning. ICML &apos;08</title>
		<meeting>the 25th international conference on Machine learning. ICML &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2008-07-05">July 5, 2008</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Convolutional networks for images, speech, and time series</title>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>978-0-262-51102-5</idno>
	</analytic>
	<monogr>
		<title level="m">The handbook of brain theory and neural networks</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998-10-01">Oct. 1, 1998</date>
			<biblScope unit="page">63</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Are Generative Classifiers More Robust to Adversarial Attacks?</title>
		<author>
			<persName><forename type="first">Yingzhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Bradshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019-05-24">May 24, 2019</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">The continuous Bernoulli: fixing a pervasive error in variational autoencoders</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Loaiza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-</forename><surname>Ganem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>D{\textbackslash}textquotesingle Alché-Buc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">97</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Name: Proceedings of the IEEE</title>
		<imprint>
			<date type="published" when="1998-11">Nov. 1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page">112</biblScope>
		</imprint>
	</monogr>
	<note>cit</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Efficient backprop</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<idno>978-3-540-65311-0</idno>
	</analytic>
	<monogr>
		<title level="m">Lecture notes in computer science</title>
		<imprint>
			<date type="published" when="1996">1996. 1998</date>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
	<note>Neural networks : tricks of the trade</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks</title>
		<author>
			<persName><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">105</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Set Transformer: A Framework for Attention-Based Permutation-Invariant Neural Networks</title>
		<author>
			<persName><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoonho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungtaek</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Kosiorek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seungjin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019-05-24">May 24, 2019</date>
			<biblScope unit="page">117</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title level="m" type="main">Learning Latent Superstructures in Variational Autoencoders for Deep Multidimensional Clustering</title>
		<author>
			<persName><forename type="first">Xiaopeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhourong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nevin</forename><forename type="middle">L</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05206</idno>
		<imprint>
			<date type="published" when="2019-02-22">Feb. 22, 2019</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">58</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Deep Learning Face Attributes in the Wild</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gunnar</forename><surname>Raetsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019-05-24">May 24, 2019</date>
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Direct Optimization through \textbackslash arg \textbackslash max for Discrete Variational Auto-Encoder</title>
		<author>
			<persName><forename type="first">Guy</forename><surname>Lorberbom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreea</forename><surname>Gane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamir</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>D{\textbackslash}textquotesingle Alché-Buc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<idno type="ISSN">0035-9246</idno>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
	<note>Publisher: [Royal Statistical Society, Wiley</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Understanding Posterior Collapse in Generative Latent Variable Models</title>
		<author>
			<persName><forename type="first">James</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Baker Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DGS@ICLR</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="70" to="72" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Multiplicative Normalizing Flows for Variational Bayesian Neural Networks</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017-07-17">July 17, 2017</date>
			<biblScope unit="page">36</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Disentangling factors of variation in deep representation using adversarial training</title>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Michael F Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Sprechmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">D D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">135</biblScope>
			<date type="published" when="2016">2016</date>
			<publisher>Curran Associates, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Continuous Hierarchical Representations with Poincaré Variational Auto-Encoders</title>
		<author>
			<persName><forename type="first">Emile</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charline</forename><forename type="middle">Le</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>D{\textbackslash}textquotesingle Alché-Buc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Disentangling Disentanglement in Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Emile</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Siddharth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019-05-24">May 24, 2019</date>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Variational Dropout Sparsifies Deep Neural Networks</title>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arsenii</forename><surname>Ashukha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Vetrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017-07-17">July 17, 2017</date>
			<biblScope unit="page">156</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Equation of State Calculations by Fast Computing Machines</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arianna</forename><forename type="middle">W</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marshall</forename><forename type="middle">N</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augusta</forename><forename type="middle">H</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<idno type="ISSN">0021-9606</idno>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="1953-06-01">June 1, 1953</date>
			<publisher>American Institute of Physics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Leveraging the Exact Likelihood of Deep Latent Variable Models</title>
		<author>
			<persName><forename type="first">Pierre-Alexandre</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jes</forename><surname>Frellsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page">91</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Variational boosting: iteratively refining posterior approximations</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">J</forename><surname>Foti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06">Aug. 6, 2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
	<note>ICML&apos;17</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Invariant Representations without Adversarial Training</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Moyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Brekelmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aram</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Ver Steeg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">135</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">On approximate approximations using Gaussian kernels</title>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Maz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">'</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Gunther</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMA Journal of Numerical Analysis</title>
		<idno type="ISSN">0272- 4979</idno>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="1996-01-01">Jan. 1, 1996</date>
		</imprint>
	</monogr>
	<note>Publisher: Oxford Academic</note>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akihiro</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02994</idno>
		<idno>arXiv: 1906.02994</idno>
		<imprint>
			<date type="published" when="2019-10-16">Oct. 16, 2019</date>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page">105</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Do Deep Generative Models Know What They Don&apos;t Know?</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">T</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akihiro</forename><surname>Matsukawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilan</forename><surname>Görür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Image retrieval and perceptual similarity</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">R</forename><surname>Gegenfurtner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Applied Perception</title>
		<idno type="ISSN">1544-3558</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2006-01-01">Jan. 1, 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Pixel Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016-06-11">June 11, 2016</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">67</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Gaussian Variational Approximation With a Factor Covariance Structure</title>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">J</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Nott</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1080/10618600.2017.1390472</idno>
		<ptr target="https://doi.org/10.1080/10618600.2017.1390472" />
	</analytic>
	<monogr>
		<title level="m">Publisher: Taylor &amp; Francis _eprint</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Lasse Espeholt, koray kavukcuoglu koray, Oriol Vinyals, and Alex Graves</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">D D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">67</biblScope>
		</imprint>
	</monogr>
	<note>Conditional Image Generation with PixelCNN Decoders</note>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title level="m" type="main">WaveNet: A Generative Model for Raw Audio</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<idno>arXiv: 1609.03499</idno>
		<imprint>
			<date type="published" when="2016">Sept. 19, 2016</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">68</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Parallel WaveNet: Fast High-Fidelity Speech Synthesis</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Driessche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Cobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Stimberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Casagrande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Grewe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seb</forename><surname>Noury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Walters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Belov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">68</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Stochastic model for electrical loads in Mediterranean residential buildings: Validation and applications</title>
		<author>
			<persName><forename type="first">Joana</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Guarino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaume</forename><surname>Salom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Corchero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Cellura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Energy and Buildings</title>
		<idno type="ISSN">0378-7788</idno>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="2014">Sept. 1, 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Neural Discrete Representation Learning</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">71</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">Learning Latent Space Energy-Based Prior Model</title>
		<author>
			<persName><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying Nian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Max-Mahalanobis Linear Discriminant Analysis Networks</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">105</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Reverend bayes on inference engines: a distributed hierarchical approach</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second AAAI Conference on Artificial Intelligence. AAAI&apos;82</title>
		<meeting>the Second AAAI Conference on Artificial Intelligence. AAAI&apos;82<address><addrLine>Pittsburgh, Pennsylvania</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1982-08-18">Aug. 18, 1982</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Elements of Causal Inference : Foundations and Learning Algorithms</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno>978-0-262-03731-0</idno>
	</analytic>
	<monogr>
		<title level="m">Journal Abbreviation: Foundations and Learning Algorithms</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title level="m" type="main">The book of why: the new science of cause and effect. Basic books</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note>cit</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Anomaly Detection With Conditional Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Pol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gianluca</forename><surname>Cerminara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cécile</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maurizio</forename><surname>Pierini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMLA 2019 -18th IEEE International Conference on Machine Learning and Applications</title>
		<imprint>
			<date type="published" when="2019-12-16">Dec. 16, 2019</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="109" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title level="m" type="main">Machine Learning Anomaly Detection Applications to Compact Muon Solenoid Data Quality Monitoring</title>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Alan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pol</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020-06-08">June 8, 2020</date>
			<biblScope unit="page">109</biblScope>
		</imprint>
		<respStmt>
			<orgName>Université Paris-Saclay</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title level="m" type="main">Preventing Posterior Collapse with delta-VAEs</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aäron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.03416</idno>
		<imprint>
			<date type="published" when="2019-01-10">Jan. 10, 2019</date>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="71" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Simple and Effective VAE Training with Calibrated Decoders</title>
		<author>
			<persName><forename type="first">Kostas</forename><surname>Oleh Rybkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Daniilidis</surname></persName>
		</author>
		<author>
			<persName><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021-07-01">July 1, 2021</date>
			<biblScope unit="page">88</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Black Box Variational Inference</title>
		<author>
			<persName><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Section: Machine Learning</title>
		<imprint>
			<date type="published" when="2014-02">Apr. 2, 2014</date>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<author>
			<persName><forename type="first">Salah</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Manifold Tangent Classifier</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Variational Inference with Normalizing Flows</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015-06-01">June 1, 2015</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title level="m" type="main">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<idno>arXiv: 1511.06434</idno>
		<imprint>
			<date type="published" when="2016-07">Jan. 7, 2016</date>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Stochastic Backpropagation and Approximate Inference in Deep Generative Models</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014-01-27">Jan. 27, 2014</date>
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
	<note>Section: Machine Learning. cit. on pp. 7, 8, 34, 41</note>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title level="m" type="main">Discrete Variational Autoencoders</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rolfe</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02200</idno>
		<idno>arXiv: 1609.02200</idno>
		<imprint>
			<date type="published" when="2017-04-21">Apr. 21, 2017</date>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Generating Diverse High-Fidelity Images with VQ-VAE-2</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>D{\textbackslash}textquotesingle Alché-Buc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">71</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Optimal scaling of discrete approximations to Langevin diffusions</title>
		<author>
			<persName><forename type="first">O</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><forename type="middle">S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<idno type="ISSN">1467-9868</idno>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title level="m" type="main">Deep Learning with Sets and Point Clouds</title>
		<author>
			<persName><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barnabas</forename><surname>Poczos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04500</idno>
		<idno>arXiv: 1611.04500</idno>
		<imprint>
			<date type="published" when="2017-02-23">Feb. 23, 2017</date>
			<biblScope unit="page">132</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Equivariance Through Parameter-Sharing</title>
		<author>
			<persName><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barnabás</forename><surname>Póczos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017-07-17">July 17, 2017</date>
			<biblScope unit="page">116</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">Exponential convergence of Langevin distributions and their discrete approximations</title>
		<author>
			<persName><forename type="first">O</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">L</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><surname>Tweedie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Publisher: Bernoulli Society for Mathematical Statistics and Probability</title>
		<imprint>
			<date type="published" when="1996-12">Dec. 1996</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b154">
	<monogr>
		<title level="m" type="main">Taming VAEs</title>
		<author>
			<persName><forename type="first">Danilo</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rezende</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Viola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00597</idno>
		<idno>arXiv: 1810.00597</idno>
		<imprint>
			<date type="published" when="2018-10-01">Oct. 1, 2018</date>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b155">
	<monogr>
		<title level="m" type="main">Handbook of constraint programming</title>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Van Beek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toby</forename><surname>Walsh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Elsevier</publisher>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">Sticking the Landing: Simple, Lower-Variance Gradient Estimators for Variational Inference</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">57</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b157">
	<monogr>
		<title level="m" type="main">PixelVAE++: Improved PixelVAE with Discrete Prior</title>
		<author>
			<persName><forename type="first">Hossein</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Vinci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Buffoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">H</forename><surname>Amin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09948</idno>
		<idno>arXiv: 1908.09948</idno>
		<imprint>
			<date type="published" when="2019-08-26">Aug. 26, 2019</date>
			<biblScope unit="page">71</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">Tempered Adversarial Networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giambattista</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Parascandolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Mehrjou</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">149</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page">68</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">The Graph Neural Network Model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Neural Networks</title>
		<imprint>
			<date type="published" when="2009-01">Jan. 2009</date>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">121</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b161">
	<monogr>
		<title level="m" type="main">Towards the first adversarially robust neural network model on MNIST</title>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Schott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09190</idno>
		<imprint>
			<date type="published" when="2018">Sept. 20, 2018</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">Estimating the Dimension of a Model</title>
		<author>
			<persName><forename type="first">Gideon</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<idno type="ISSN">0090-5364</idno>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="1978-03">Mar. 1978</date>
			<publisher>Publisher: Institute of Mathematical Statistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Binary join trees for computing marginals in the Shenoy-Shafer architecture</title>
		<author>
			<persName><forename type="first">P</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Journal of Approximate Reasoning. Uncertainty in AI (UAI&apos;96) Conference</title>
		<imprint>
			<date type="published" when="1997-08-01">Aug. 1, 1997</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Amortized Inference Regularization</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung</forename><forename type="middle">H</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mykel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Kochenderfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Mean Field Theory for Sigmoid Belief Networks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<idno type="ISSN">1076-9757</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="1996-03-01">Mar. 1, 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b166">
	<analytic>
		<title level="a" type="main">A simple approach for finding the globally optimal Bayesian network structure</title>
		<author>
			<persName><forename type="first">Tomi</forename><surname>Silander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petri</forename><surname>Myllymäki</surname></persName>
		</author>
		<idno>978-0-9749039-2-7</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence. UAI&apos;06</title>
		<meeting>the Twenty-Second Conference on Uncertainty in Artificial Intelligence. UAI&apos;06<address><addrLine>Arlington, Virginia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2006-07-13">July 13, 2006</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b167">
	<analytic>
		<title level="a" type="main">Restricted Boltzmann machines for collaborative filtering</title>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning. ICML &apos;07</title>
		<meeting>the 24th international conference on Machine learning. ICML &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2007-06-20">June 20, 2007</date>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b168">
	<analytic>
		<title level="a" type="main">Sø +16] Casper Kaae Sø nderby, Tapani Raiko, Lars Maalø e, Sø ren Kaae Sø nderby, and Ole Winther</title>
		<author>
			<persName><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaniv</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sebastian Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">H</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>D{\textbackslash}textquotesingle Alché-Buc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016">2019. 2016</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">53</biblScope>
		</imprint>
	</monogr>
	<note>Ladder Variational Autoencoders</note>
</biblStruct>

<biblStruct xml:id="b169">
	<analytic>
		<title level="a" type="main">Learning Stochastic Inverses</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Stuhlmüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b170">
	<monogr>
		<title level="m" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556[cs]</idno>
		<idno>arXiv: 1409.1556</idno>
		<imprint>
			<date type="published" when="2015-04-10">Apr. 10, 2015</date>
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b171">
	<analytic>
		<title level="a" type="main">VAE with a VampPrior</title>
		<author>
			<persName><forename type="first">Jakub</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics. International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2018-03-31">Mar. 31, 2018</date>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b172">
	<analytic>
		<title level="a" type="main">DVAE++: Discrete Variational Autoencoders with Overlapping Transformations</title>
		<author>
			<persName><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Macready</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbing</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Khoshaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07-03">July 3, 2018</date>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
	<note>Section: Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b173">
	<analytic>
		<title level="a" type="main">DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors</title>
		<author>
			<persName><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Macready</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b174">
	<analytic>
		<title level="a" type="main">Model selection and psychological theory: A discussion of the differences between the Akaike information criterion (AIC) and the Bayesian information criterion (BIC)</title>
		<author>
			<persName><forename type="first">I</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><surname>Vrieze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Place: US Publisher: American Psychological Association</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Print</note>
</biblStruct>

<biblStruct xml:id="b175">
	<analytic>
		<title level="a" type="main">Faithful Inversion of Generative Models for Effective Amortized Inference</title>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Golinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rob</forename><surname>Zinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Siddharth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">52</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b176">
	<analytic>
		<title level="a" type="main">Correctness of Local Probability Propagation in Graphical Models with Loops</title>
		<author>
			<persName><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<idno type="ISSN">0899-7667</idno>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2000-01-01">Jan. 1, 2000</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Publisher</note>
</biblStruct>

<biblStruct xml:id="b177">
	<analytic>
		<title level="a" type="main">A Comprehensive Survey on Graph Neural Networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2021-01">Jan. 2021</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">121</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b178">
	<analytic>
		<title level="a" type="main">Variance reduction properties of the reparameterization trick</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matias</forename><surname>Quiroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">A</forename><surname>Sisson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics. The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019-04-11">Apr. 11, 2019</date>
			<biblScope unit="page">43</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b179">
	<monogr>
		<title level="m" type="main">Exponential Tilting of Generative Models: Improving Sample Quality by Training and Sampling from Latent Energy</title>
		<author>
			<persName><forename type="first">Zhisheng</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yali</forename><surname>Amit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08100</idno>
		<idno>arXiv: 2006.08100</idno>
		<imprint>
			<date type="published" when="2020-06-14">June 14, 2020</date>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b180">
	<analytic>
		<title level="a" type="main">Can the strengths of AIC and BIC be shared? A conflict between model indentification and regression estimation</title>
		<author>
			<persName><forename type="first">Yuhong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<idno type="ISSN">0006-3444</idno>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2005-12-01">Dec. 1, 2005</date>
		</imprint>
	</monogr>
	<note>Publisher: Oxford Academic</note>
</biblStruct>

<biblStruct xml:id="b181">
	<analytic>
		<title level="a" type="main">Fixup Initialization: Residual Learning Without Normalization</title>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations. Sept</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">57</biblScope>
		</imprint>
	</monogr>
	<note>cit</note>
</biblStruct>

<biblStruct xml:id="b182">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<imprint>
			<date type="published" when="2017-02-26">Feb. 26, 2017</date>
			<biblScope unit="page">91</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b183">
	<analytic>
		<title level="a" type="main">Forecasting Residential Energy Consumption: Single Household Perspective</title>
		<author>
			<persName><forename type="first">Monica</forename><surname>Xiaoou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miriam</forename><forename type="middle">A M</forename><surname>Grolinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Capretz</surname></persName>
		</author>
		<author>
			<persName><surname>Seewald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th IEEE International Conference on Machine Learning and Applications (ICMLA). 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)</title>
		<imprint>
			<date type="published" when="2018-12">2018. Dec. 2018</date>
			<biblScope unit="page">115</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b184">
	<analytic>
		<title level="a" type="main">Understanding VAEs in Fisher-Shannon Plane</title>
		<author>
			<persName><forename type="first">Huangjie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangchao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">01 July 17, 2019</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b185">
	<analytic>
		<title level="a" type="main">A simple approach to Bayesian network computations</title>
		<author>
			<persName><forename type="first">Nevin</forename><surname>Lianwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Tenth Canadian Conference on Artificial Intelligence</title>
		<meeting>of the Tenth Canadian Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b186">
	<monogr>
		<title level="m" type="main">The Information Autoencoding Family: A Lagrangian Perspective on Latent Variable Generative Models</title>
		<author>
			<persName><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.06514</idno>
		<ptr target="http://arxiv.org/abs/1806.06514" />
		<imprint>
			<date type="published" when="2018-07-07">July 7, 2018. 2021</date>
			<biblScope unit="page">73</biblScope>
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
