<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active semi-supervised expectation maximization learning for lung cancer detection from Computerized Tomography (CT) images with minimally label training data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Phuong</roleName><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName><surname>Chapman</surname></persName>
						</author>
						<author>
							<persName><surname>David</surname></persName>
						</author>
						<author>
							<persName><roleName>Sumeet, Morris, Michael, Yesha</roleName><forename type="first">Yelena</forename><forename type="middle">Phuong</forename><surname>Menon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sumeet</forename><surname>Chapman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Menon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yelena</forename><surname>Morris</surname></persName>
						</author>
						<author>
							<persName><surname>Yesha</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Phuong</forename><surname>Nguyen</surname></persName>
							<email>phuong3@umbc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science and Electrical Engineering</orgName>
								<orgName type="institution">University Of Maryland Baltimore County</orgName>
								<address>
									<addrLine>1000 Hilltop Circle</addrLine>
									<postCode>21250</postCode>
									<settlement>Baltimore</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Chapman</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science and Electrical Engineering</orgName>
								<orgName type="institution">University Of Maryland Baltimore County</orgName>
								<address>
									<addrLine>1000 Hilltop Circle</addrLine>
									<postCode>21250</postCode>
									<settlement>Baltimore</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sumeet</forename><surname>Menon</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science and Electrical Engineering</orgName>
								<orgName type="institution">University Of Maryland Baltimore County</orgName>
								<address>
									<addrLine>1000 Hilltop Circle</addrLine>
									<postCode>21250</postCode>
									<settlement>Baltimore</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Morris</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Diagnostic Radiology, Nuclear Medicine, and Internal Medicine</orgName>
								<orgName type="department" key="dep2">Mercy Medical Center</orgName>
								<address>
									<addrLine>345 St. Paul Place</addrLine>
									<postCode>21202</postCode>
									<settlement>Baltimore</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yelena</forename><surname>Yesha</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science and Electrical Engineering</orgName>
								<orgName type="institution">University Of Maryland Baltimore County</orgName>
								<address>
									<addrLine>1000 Hilltop Circle</addrLine>
									<postCode>21250</postCode>
									<settlement>Baltimore</settlement>
									<region>MD</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">SPIE Medical Imaging</orgName>
								<address>
									<postCode>2020</postCode>
									<settlement>Houston</settlement>
									<region>Texas</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Active semi-supervised expectation maximization learning for lung cancer detection from Computerized Tomography (CT) images with minimally label training data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1117/12.2549655</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Lung Cancer screening</term>
					<term>Active Learning</term>
					<term>Semi-Supervised Learning</term>
					<term>CT</term>
					<term>Label Acquiring</term>
					<term>Computer-Aided Diagnosis</term>
					<term>Expectation Maximization</term>
					<term>Artificial Intelligence</term>
					<term>Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Active semi-supervised expectation maximization learning for lung cancer detection from Computerized Tomography (CT) images with minimally label training data,"</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Deep learning using Convolutional Neural Networks (CNNs) has greatly improved the performance of Computer Aided Diagnosis (CAD) algorithms for cancer screening in recent years <ref type="bibr">[1 , 2 , 3 , 4 , 5 , 6 , 7]</ref>. However, a disadvantage of many deep learning classification techniques including many CNNs is that these algorithms are fully supervised and therefore require very large datasets with manual annotation by expert radiologists in order achieve high accuracy. Typically these fully annotated datasets are on the order of thousands of images, whereas clinical Picture Archiving and Communication Systems (PACS) even at a community hospital contains millions of unlabeled or weakly labeled Radiology examinations. As such, a major challenge in applying deep learning based CAD clinically is to be able to make use of larger unlabeled radiology imaging datasets and to combine these datasets with smaller highly annotated datasets.</p><p>Methods to reduce the amount of manual annotation necessary while maintaining or improving accuracy are an important contribution because manual annotation for medical imagery is time consuming, costly, and requires expert labelers with a high level of expertise in radiology.</p><p>Accurate Chest CT annotation for lung cancer screening requires a board certified diagnostic radiologist (4 years of medical school, 1 year of internship, and 4 years of diagnostic radiology residency), ideally with additional experience or subspecialization in Thoracic Radiology or Oncologic Radiology (1-2 years additional fellowship or clinical experience). Furthermore, challenging tasks such as nodule segmentation and malignancy assessment require additional annotation that is beyond the routine clinical standard of care and therefore is not readily available. The misclassification rate for CNNs has been empirically estimated to decay exponentially as data volumes increase <ref type="bibr" target="#b7">[8]</ref>. Therefore, the absence of large annotated datasets are currently a limiting factor in the clinical application of deep learning for radiology. Active learning and Semi-supervised learning algorithms have the potential to enable deep learning based CAD to further improve performance by making use of large clinical image volumes collected by institutions thereby greatly reducing the necessary labeling burden.</p><p>In this study we investigate a novel learning model that combines Active learning with Semi-supervised learning in order to reduce the amount of annotation necessary to create a CNN based CAD algorithm for Chest CT cancer screening examinations. Lung cancer screening was recently identified as contributing to the largest year-over-year decline in cancer deaths ever recorded. <ref type="bibr" target="#b8">[9]</ref> We demonstrate that an Active Semi-Supervised Expectation Maximization (ASEM) algorithm is a viable approach for training deep CNN based CAD algorithms using CT exams. This work builds upon our recent work demonstrating that a Semi-supervised EM (SEM) algorithm was able to improve cross-validated Lung Cancer screening accuracy as compared to a fully-fully-supervised technique <ref type="bibr" target="#b9">[10]</ref>. We expand on this algorithm by incorporating Active learning in combination with Expectation-Maximization (EM) in order to further improve cross-validated screening accuracy. The active learning component allows the algorithm to interactively suggest images to radiologists that need to be labeled, and the semi-supervised learning using EM allows the algorithm to incorporate a larger unlabeled training image dataset along with a smaller labeled dataset. The suggested images from the the large unlabeled pool are selected by a validating classification uncertainty method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Recently, <ref type="bibr" target="#b6">[7]</ref> presented an artificial intelligence (AI) system which can potentially outperform human experts in breast cancer prediction. To evaluate its effectiveness in the clinical setting, they have curated a large characteristic dataset from the UK and large enhanced dataset from the USA and have manifested complete reduction of 5.7% (USA) and 1.2% (UK) in false positive rate and 9.4% (USA) and 2.7% (UK) in false negative rate. Expectation Maximization (EM) is an influential generative meta-algorithm for latent variable training and has been employed for semi-supervised learning <ref type="bibr" target="#b10">[11]</ref>. Generative algorithms model the probability distribution of unlabeled imagery as a function of model and labeled imagery <ref type="bibr">[12 , 13]</ref>. Although EM assumes an underlying generative model, recent work in combining EM with discriminative CNN architectures have been shown to be successful in practice, likely due to the non-linearity of CNNs. EM is applied to improve semantic segmentation of general imagery using CNNs <ref type="bibr" target="#b13">[14]</ref>. The method achieves 73.9% accuracy with a small number of pixel-level annotated images which is almost competitive with the fully-supervised model's accuracy of 79%.</p><p>Active learning or "optimal experimental design" in statistics is part of the machine learning field, where the learner selectively asks (or queries) experts for more ground truth labels in order to achieve its desirable outcome (e.g model's accuracy or better learning with less samples). As such, Active learning methods choose the most informative unlabeled samples for annotation by a human radiologist. The selection process requires the learning algorithm to provide a query strategy to select unlabeled data points that are most likely to improve the model accuracy if labeled. By using uncertainty sampling <ref type="bibr" target="#b14">[15]</ref>, the way to select is by picking the least certain label and requiring experts to annotate. Recently, active learning has been to overcome data scarcity issues with current models by incrementally choosing the most revealing unlabeled samples, querying their labels and putting them to the labeled data set <ref type="bibr" target="#b15">[16]</ref>.</p><p>The Monte Carlo dropout method is used to estimate the level of uncertainty in the active learning process or look ahead technique to select samples <ref type="bibr" target="#b16">[17]</ref>. Better uncertainty estimation is obtained using ensemble models <ref type="bibr" target="#b17">[18]</ref>. Previous work combined the approach proposed by <ref type="bibr" target="#b16">[17]</ref> and data augmentation (generate new training samples from a latent variable, discriminate between real and fake samples) for classification learning tasks <ref type="bibr" target="#b18">[19]</ref>.</p><p>Active learning alone has been applied for characterization of endothelial cells in human tumors <ref type="bibr" target="#b19">[20]</ref> and predicting positive p53 cancer rescue regions by using the most informative information method <ref type="bibr" target="#b20">[21]</ref>. There is a recent active learning framework that is presented by <ref type="bibr" target="#b21">[22]</ref> for skin lesion analysis which is cost-effective by selecting and employing much fewer labeled samples while the network still attains state-of-the-art performance. Their active learning method tends to enhance the annotation coherence. The authors have selected their samples to be highly supportive and have used dataset of the ISIC 2017 Skin lesion Classification challenge and attained state-of-the-art performance by using 50% of the data for the first task and 40% of the data for the second task of skin lesion classification. Previous work in <ref type="bibr" target="#b22">[23]</ref> developed a model that recognizes anomalies within plain-text-based reports which could then be utilized further as a method to create labels for models depending on CT scans thereby aiming to decrease human efforts in labeling CT scans. A systematic approach named NoduleX was proposed by <ref type="bibr" target="#b23">[24]</ref> which uses a deep learning CNN as well as a radiomics approach for prediction of lung nodule malignancy using CT images of the LIDC dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">METHODOLOGY</head><p>The ASEM method combines both Semi-supervised and Active learning to improve the accuracy of the model prediction with as few known labels as possible. Active learning techniques require an Oracle step in which the algorithm asks for more ground truth from the unlabeled data during the ASEM process. Figure <ref type="figure">1</ref> shows an overview of our proposed learning model. We first train an initial model using a subset of the training data which is fully labeled. Subsequently, the ASEM model alternates between Semi-supervised Expectation and Maximization steps as well as Active learning Oracle , and Active Retraining steps. Each ASEM iteration requires retraining the model in the Maximization and Active Retraining steps with improved estimates of the latent variables either due to Expectation, or due to the Oracle. The computational burden of retraining the model for each ASEM iteration however is greatly reduced by re-using the weights from the previous ASEM iteration rather than retraining from a random seed (see table <ref type="table" target="#tab_3">4</ref> for the runtime performance of our ASEM-CAD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 Overview of proposed model for lung cancer detection</head><p>The ASEM algorithm is an alternating local maximization-maximization algorithm in which we attempt to perform a maximum likelihood estimate of our model and expected experimental design in the presence of latent θ ξ variables and given the ability to actively label a finite number of observations . Our goal is to show that the Z y maximum likelihood of the model is improving after each Active Learning step and after each EM step.</p><p>A theoretical detail is that EM steps attempt to maximize likelihood whereas Active learning minimizes cross entropy. These have equivalent global optima under the assumption of statistical independence and have approximately equivalent optima in practical machine learning applications as follows,</p><formula xml:id="formula_0">(1) (X ) log( p(X | θ)) og(p(X|θ)) -∑ i p i i ≈ -l</formula><p>The Expectation and Maximization steps maximize likelihood of the model under all possible values of the latent variable space <ref type="bibr" target="#b10">[11]</ref>. The likelihood of a latent variable is given by the integral of the joint probability density over all possible values of the latent variable Z .</p><p>(2) (θ; ) p(X|θ) (X, Z|θ)dZ L X = = ∫ p EM attempts to solve the above integral by alternating between Expectation and Maximization steps. Expectation is in which we calculate the expected value of the latent variables given the t th iteration of the model . In the θ t context of a deep learning framework, the expected value of can be computed by classifying label E Z|X,Θ t probabilities of the unlabeled imagery using the t th iteration of the model coefficients .</p><formula xml:id="formula_1">θ t (3) (θ|θ ) [log L(θ; , )] Q t = E Z|X,θ T X Z</formula><p>The Maximization step is to compute the maximum likelihood model given our current expected value of the θ t+1 latent variables . This can be accomplished by retraining the deep learning model using the expected value of the Z image labels at the t th iteration.</p><formula xml:id="formula_2">(4) rgmax Q(θ|θ ) θ t+1 = a θ t</formula><p>Our active learning process is designed to select data points for an expert human to label during the EM iteration training. In this way we make selective incremental improvements to data label quality. The active learning steps optimize the expected posterior cross entropy of the model given an alternate experimental design with the ξ addition of a labeled sample . We cannot measure the posterior cross entropy directly because we must select a y i sample before acquiring it's true label via Oracle. As such the expected posterior cross entropy is as follows</p><formula xml:id="formula_3">(5) (ξ) og(p(X|θ, , )) dy U = -∫ l y i ξ i</formula><p>This quantity can be rewritten using Bayes rule for bayesian experimental design as follows,</p><formula xml:id="formula_4">(6) (ξ) og(p(y |θ, , ) dy U = -∫ l i X ξ p(X|θ,ξ) p(y |θ,ξ) i i</formula><p>This integral would be expensive to compute as it would require retraining the algorithm for every possible sample choice and every possible sample label prior to choosing the appropriate sample. However, we can make an approximation that a single sample does not change the model prediction of most samples more than a small amount at a time, but rather the predicted sample inself has the greatest local contribution to y i posterior cross entropy.</p><p>Under this assumption the change in posterior cross entropy is approximately equal the the normalized classification entropy over all possible K labels as follows, ( <ref type="formula">7</ref>)</p><formula xml:id="formula_5">U (ξ) (y ) (y ) log(p(y )) Δ ≈ I norm i = -1 log(K) ∑ K k=1 p ik ik</formula><p>We can perform a small number of Active Learning steps in a batch rather than performing a single active learning step. In this case, our expected utility becomes the normalized classification entropy of all of the selected samples in the batch as follows,</p><formula xml:id="formula_6">(8) vg(I (Y )) (y)) a norm = 1 Y | | ∑ y∈Y I norm</formula><p>As such the ASEM algorithm alternates between steps 3, 4, and 8 in order to improve the maximum likelihood estimate and reduce classification cross entropy in the presence of latent variables while optimizing Bayesian experimental design. An important point is that algorithm, as a maximization-maximization meta-algorithm does not guarantee convergence to a global optimum, but rather will achieve a local optimal experimental design as well as a local optimal estimate of latent variables for semi-supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">DATA AND EXPERIMENTAL DESIGN</head><p>We analyze the performance of the active semi-supervised EM (ASEM) model using 3 lung cancer screening datasets: Kaggle, NLST, and LIDC-IDRI. The Kaggle Data Science bowl (2017) (Kaggle17) is a benchmark dataset for Computer Aided Diagnosis (CAD) algorithms for Non-Small Cell Lung Cancer (NSCLC) cancer screening using Low Dose Computed Tomography (LDCT) scans. Each volumetric scan contains varying number of Chest CT image slices, and each slice is the standard resolution of 512x512 pixels. We experiment with the Kaggle17 dataset, which consists of a total of 1375 patients. These scans are labeled as 1 for cancerous (i.e. diagnosed with lung cancer within one year of the scan) and 0 for non-cancerous. NLST was a landmark 2011 study that proved that high risk individuals (60+ yrs old, and heavy smokers) who receive periodic LDCT lung cancer screening exams have greater life expectancy and lower mortality than if these individuals were to receive periodic chest x-ray screenings. We used 4075 LDCT scans from the NLST dataset, and each scan was labeled as 1 if the patient was diagnosed with cancer or 0 if the patient was not diagnosed with cancer. Of these 4075 scans, 639 patients were diagnosed with lung cancer.</p><p>The LIDC-IDRI Dataset <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> is a publicly available dataset that consists of diagnostic and lung cancer screening thoracic computed tomography (CT) scans with marked-up annotated lesions. This dataset is a web-accessible international resource initiated by the National Cancer Institute (NCI), and then further developed by the Foundation for the National Institutes of Health (FNIH) and going along with the Food and Drug Administration (FDA). LIDC is used for the purpose of research towards development, training and assessing of computer-aided diagnostic (CAD) methods for detecting and diagnosing lung cancer in its early stages. This dataset is created in collaboration with seven academic centers and eight medical imaging companies that have 1018 CT cases where it has thoracic CT scans associated with an XML file. The LIDC study has annotations that are provided by four experienced Thoracic Radiologists who reviewed each of the 1018 CT cases in the LIDC/IDRI cohort and marked lesions into 3 categories based on the nodule size. Nodules &gt; or = 3mm have a greater probability of being malignant than nodules &lt;3mm and non-nodule &gt; or = 3mm. The malignancy rating is given from 1-5 depending on the size and features of the nodule.</p><p>The following section presents how we build and evaluate our ASEM model for Computer Aided Diagnosis, called ASEM-CAD for lung cancer detection using the above 3 datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Pre-processing</head><p>In Both Kaggle and NLST datasets, each patient CT scans have varied slice numbers. For each patient, we create standard 3D volume data as input for the model by resizing the 512x512 image pixels of multiple DICOM slices into a standard 50x50x20 voxel resolution. The third dimension is reduced to 20 by chunking slices into 20 chunks then average. Thus, the input 3D volume for each patient has 50x50x20 dimensions, each associated with a label: either 1 (cancer) or 0 (non-cancer). Kaggle has 1357 patients with 356 cancer cases. Cancer cases represent 26% of the Kaggle dataset and non-cancer cases represent 74%. For NLST, after preprocessing we have 2538 cases, 397 cancers and 2141 non-cancer.</p><p>The third dataset, LIDC, has 1010 CT scans, with each slice having 512x512 pixels. We crop 4253 nodules which cover the size of nodules according to annotations that are provided by the four experienced radiologists. Their annotations are given in the form of nodule Region Of Interest and their Z-positions. Thus we crop the the 32x32x16 dimension nodules using the spatial coordinate centered at the annotated location of the CT scans. For assigning the labels of the nodule, we use rating scores provided by board certified radiologists with levels 1 and 2 as a non-cancer nodule (benign), level 4 and 5 as cancer nodule (malignant). The score level 1 meaning highly benign, 2 as moderately benign (non-cancer), 4 as moderately suspicious to be malignant and 5 as highly likely to be malignant (cancer). Nodules labeled by a radiologist as having an intermediate malignancy (rating 3) are not considered for classification in this paper. In summary, we have 4253 nodules, each has 32x32x16 dimensions and an associated label 1 (cancer) and 0 (non-cancer). There are 1653 cancerous nodules. 2600 nodules belong to benign cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Neural Architecture and Training Procedures</head><p>The ASEM-CAD neural architecture has six CNN layer blocks. Each has Convolutional 3D layers, LeakyRelu, BatchNormalization, MaxPooling3D, DropOut with 32, 32, 64, 64, 64, 64 feature maps. The Convolutional 3D uses a 3x3x3 filter. Then follow by Dense, BatchNormalization, DropOut layer with 256 features. The last layer has Dense 1024 and 2 classes. For the LIDC dataset, we use a simpler CNN architecture with layer block 1, 2, 3, 4, 7 and 8. The CNN feature maps are 8, 8, 16, 16 for LIDC experiments. For all experiments, data is splitting as 80% of input dataset is used for ASEM to train and evaluate the model. The remaining 20% of dataset is used for testing.</p><p>The ASEM training procedure is as follows: the initial model is fully trained with 50% of all labels until convergence using category Cross-entropy loss. The ASEM-CAD is trained using RMSprop optimizer with a learningRate of 0.0001. The Initial model is fully trained using 500 epochs. Then each ASEM meta-iteration (EM iteration) is trained with 10 epochs. The ASEM model is trained in batches of 32 samples. The Initial model is saved.</p><p>Then EM iterations can load the initial model's parameters and start the Active EM training. The Active component selects 10 samples and asks an Oracle for the label during an ASEM iteration. The number of ASEM' Active EM iterations is set to 5. In addition, we apply Label Smoothing, BatchNormalization, and Early Termination techniques for training our ASEM-CAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS</head><p>In this section, we present our experimental findings of the performance of the ASEM algorithm in comparison to fully supervised learning as well as in comparison to the SEM algorithm. We calculate Receiver Operating Curves (ROC), and present accuracy, Area Under Curve (AUC), sensitivity, specificity, and precision as evaluation metrics. We evaluate the ASEM-CAD using the Kaggle17, NLST, and LIDC datasets and compare with fully supervised training as well as Semi-Supervised EM. We compare the following methods, Supervised 1 : Using only 50% of these labeled datasets; Supervised 2 : Using 100% labeled dataset; SEM-CAD : Start with 50% labeled data initially then using full dataset for EM iterations. ASEM-CAD 1 : Active semi-supervised with 50% labels and additional labels with Max. Classification Entropy; ASEM-CAD 2 : Active semi-supervised with 50% labels, add additional labels with above Avg Classification Entropy.</p><p>Most lung cancer datasets including Kaggle17, NLST, and LIDC have an unbalanced number of cancer vs non cancer cases with a greater number of non-cancerous cases relative to cancerous cases. Yet in clinical practice, it is necessary to bias the final threshold of any cancer screening test such as to over-predict false positives in order to reduce the probability of predicting false negatives. In order to provide a more complete picture, ROCs are calculated by varying the prediction threshold between 0 to 1 and plotting sensitivity against 1 -specificity if all predictions above the varied threshold are classified as cancerous. AUC varies from 0 to 1 (higher is better), and is defined as the integral of sensitivity with respect to 1-specificity over the domain of the ROC curve. Tables <ref type="table" target="#tab_0">1,</ref><ref type="table" target="#tab_1">2</ref>, and 3 calculate an inflection point along this ROC curve and present sensitivity , specificity, and precision . Table <ref type="table" target="#tab_0">1</ref> shows the performance of the ASEM-CAD algorithm over the Kaggle17 dataset, Table <ref type="table" target="#tab_1">2</ref> shows the performance over the NLST dataset, and Table <ref type="table" target="#tab_2">3</ref> shows the performance over the LIDC-IDRI dataset. At the inflection point, Specificity and Precision were higher although Sensitivity was slightly lower as compared to fully-supervised learning model using 100% labels (table <ref type="table" target="#tab_0">1</ref>). It also showed in table 1 that ASEM-CAD1 outperforms the SEM-CAD in similar metrics.Noticeably, ASEM-CAD1 performed much better by 7.9%, 13%, 15%, 6%, and 23% in all metrics respectively in its order in table 1 over our ASEM-CAD2. ROC curves comparing Supervised 2, SEM-CAD, and ASEM-CAD1 are shown in Figure <ref type="figure">2</ref>.</p><p>Figure <ref type="figure">2</ref> ROC analysis of the Kaggle dataset a) left Supervised 2 (100% labels) b) middle semi-supervised SEM-CAD (50% labels). c) right our ASEM-CAD1 , Active Semi-Supervised (50% labels, add labels with Max. Classification Entropy). Note: this ROC curve is reported per run not on average of multiple runs presented in table <ref type="table" target="#tab_0">1</ref>.</p><p>Table <ref type="table" target="#tab_1">2</ref> shows a similar ROC analysis of ASEM-CAD1 against supervised and semi-supervised techniques. We see that the ASEM-CAD1 algorithm achieves AUC of 0.88 which is comparable and slightly greater than Supervised 2 which achieves AUC of 0.87. Supervised 2 has the benefit of using all of the labeled data, whereas ASEM-CAD1 uses only using slightly more than half of the labeled data. Figure <ref type="figure" target="#fig_0">3</ref> shows the ROC curves comparing ASEM-CAD2 versus Supervised 2, we see that ASEM-CAD2 exhibits comparable performance characteristics to Supervised 2 in addition to achieving similar AUC.  <ref type="table" target="#tab_2">3</ref> compares the performance of ASEM versus supervised and semi-supervised methods for nodule malignancy estimation using the LIDC-IDRI dataset.</p><p>We see that ASEM-CAD1 achieves AUC of 0.81 which is very comparable performance to Supervised 2 (AUC 0.82), by using only slightly more than 50% of the data labels, as opposed to 100% of the data labels. For this dataset ASEM-CAD1 and ASEM-CAD2 achieved comparable AUC performance and these algorithms outperformed SEM-CAD. At the inflection point ASEM-CAD1 achieves slightly greater sensitivity but slightly lower specificity than Supervised 2. We compare the ROC curves for Supervised 2 vs ASEM-CAD1 in Figure <ref type="figure" target="#fig_1">4</ref>, and we find that these curves have similar accuracy performance characteristics.   Also notable is that the ASEM algorithm, despite iteratively retraining of the CNN models more than 10 times, adds less than 50% additional overhead to the overall training time. Table <ref type="table" target="#tab_3">4</ref> shows the wall-time runtimes of the ASEM-CAD algorithm for training using a customized built computer with AMD 1885 MHz 32 cores, 658 GB, 3 NVIDIA GeForce RTX, each GPU has 11 GB memory. The reason that the runtime is manageable (30%-50% increase) as opposed to a factor 10x or more is because we save and reuse the CNN weights after each iteration as opposed to retraining the CNN from random weights. As a maximization-maximization procedure, each ASEM iteration can be thought of as a local hillclimb in order to further improve the maximum likelihood estimate of the model parameters. Thus, the weights from the previous ASEM step a good initial guess to the weights of the subsequent ASEM step, thereby reducing the number of epochs necessary (and thus total walltime) for the ASEM Iterations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>ASEM-CAD is a new CNN based CAD model which combines both semi-supervised and active learning to detect lung cancerous nodules and lung cancer cases using CT scans, while reducing the number of labeled scans necessary to train the neural architecture. ASEM-CAD has been evaluated using three public chest CT datasets for lung-cancer screening: Kaggle17, NLST, LIDC. Our experiments showed ASEM-CAD can detect lung cancer with high AUC performance comparable to that of fully supervised learning, but with only slightly more than 50% of the training labels. The ASEM-CAD1 vs Supervised2 AUC performances were: NLST (0.88 vs 0.87), Kaggle17 (0.94 vs 0.92), and LIDC-IDRI: (0.81 vs 0.82) . The Active learning component asks for additional ground truth of unlabeled data which has a high level of classification uncertainty (high entropy) during the EM training process. This selection process results in better performance as compared to purely Semi-Supervised learning as well (SEM-CAD).</p><p>In conclusion, we have demonstrated that ASEM-CAD is able to detect suspicious lung nodules with comparable accuracy as using a fully supervised algorithm but with far fewer labeled images. ASEM-CAD may help to provide medical imaging researchers and commercial vendors with a more practical approach to train more powerful artificial intelligence based virtual radiology assistants (vRA) to augment radiologists interpreting oncologic imaging in the setting of lung cancer screening and perhaps other diagnostic radiology examinations more generally.</p><p>In the future, we expect that Semi-Supervised and Active learning will play an increasingly larger role in the development of Deep CAD algorithms as these techniques will make it possible to learn from large clinical PACS datasets while reducing the need for manual annotation by radiologists.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3</head><label>3</label><figDesc>Figure 3 ROC analysis of the NLST dataset a) left fully-supervised(100% labels). b) Right ASEM-CAD2 Active Semi-supervised (50% labels), add labels with above Average Classification Entropy.</figDesc><graphic coords="11,81.75,181.50,225.75,186.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4</head><label>4</label><figDesc>Figure 4 ROC analysis of the LIDC dataset a) left fully-supervised (100% labels)-Supervised2. b) Right Active Semi-supervised (50% labels, add label with Maximization Classification Entropy) ASEM-CAD1.</figDesc><graphic coords="12,87.00,80.25,214.50,153.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="5,73.50,453.75,468.00,179.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>ASEM performance over the Kaggle17 dataset</figDesc><table><row><cell>Experiments</cell><cell>Number of Samples</cell><cell cols="2">Test_ACC AUC</cell><cell>Sensitivity</cell><cell cols="2">Specificity Precision</cell></row><row><cell>Supervised 1</cell><cell>50% labels only</cell><cell>0.87</cell><cell>0.85</cell><cell>0.69</cell><cell>0.94</cell><cell>0.79</cell></row><row><cell>Supervised 2</cell><cell>100% labels</cell><cell>0.92</cell><cell>0.92</cell><cell>0.81</cell><cell>0.95</cell><cell>0.85</cell></row><row><cell>SEM-CAD</cell><cell>50% label initially</cell><cell>0.91</cell><cell>0.92</cell><cell>0.88</cell><cell>0.92</cell><cell>0.76</cell></row><row><cell></cell><cell>50%, add labels with Max.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ASEM-CAD1</cell><cell>Classification Entropy</cell><cell>0.92</cell><cell>0.94</cell><cell>0.78</cell><cell>0.96</cell><cell>0.88</cell></row><row><cell></cell><cell>50%, add labels with above</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ASEM-CAD2</cell><cell cols="2">Avg Classification Entropy 0.85</cell><cell>0.81</cell><cell>0.66</cell><cell>0.9</cell><cell>0.67</cell></row><row><cell cols="7">Over the Kaggle17 dataset, ASEM-CAD1 outperformed Supervised 2 algorithms in AUC (0.94 vs 0.92), this is</cell></row><row><cell cols="5">notable because Supervised 2 has the benefit of using 100% of the training labels.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>ASEM paerformance over the NLST dataset.</figDesc><table><row><cell>Experiments</cell><cell>Number of Samples</cell><cell>Test_AC</cell><cell>AUC</cell><cell cols="2">Sensitivity Specificity</cell><cell>Precision</cell></row><row><cell></cell><cell></cell><cell>C</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Supervised 1</cell><cell>50% labels only</cell><cell>0.92</cell><cell>0.87</cell><cell>0.65</cell><cell>0.97</cell><cell>0.75</cell></row><row><cell>Supervised 2</cell><cell>100% labels</cell><cell>0.94</cell><cell>0.87</cell><cell>0.72</cell><cell>0.97</cell><cell>0.90</cell></row><row><cell>SEM-CAD</cell><cell>50% label initially</cell><cell>0.90</cell><cell>0.89</cell><cell>0.77</cell><cell>0.92</cell><cell>0.67</cell></row><row><cell>ASEM-CAD1</cell><cell>50%, add labels with Max.</cell><cell>0.93</cell><cell>0.88</cell><cell>0.56</cell><cell>0.99</cell><cell>0.94</cell></row><row><cell></cell><cell>classification entropy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ASEM-CAD2</cell><cell>50%, add labels with above</cell><cell>0.92</cell><cell>0.86</cell><cell>0.63</cell><cell>0.99</cell><cell>0.91</cell></row><row><cell></cell><cell>Avg classification entropy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>ASEM performance over the LIDC-IDRI dataset.</figDesc><table><row><cell>Experiments</cell><cell>Number of Samples</cell><cell>Test_ACC</cell><cell>AUC</cell><cell cols="3">Sensitivity Specificity Precision</cell></row><row><cell>Supervised 1</cell><cell>50% labels only</cell><cell>0.67</cell><cell>0.82</cell><cell>0.91</cell><cell>0.52</cell><cell>0.54</cell></row><row><cell>Supervised 2</cell><cell>100% labels</cell><cell>0.74</cell><cell>0.82</cell><cell>0.78</cell><cell>0.72</cell><cell>0.64</cell></row><row><cell>SEM-CAD</cell><cell>50% label initially</cell><cell>0.71</cell><cell>0.81</cell><cell>0.82</cell><cell>0.64</cell><cell>0.59</cell></row><row><cell>ASEM-CAD1</cell><cell>50%, add labels with Max.</cell><cell>0.73</cell><cell>0.81</cell><cell>0.79</cell><cell>0.70</cell><cell>0.62</cell></row><row><cell></cell><cell>classification entropy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ASEM-CAD2</cell><cell>50%, add labels with above</cell><cell>0.73</cell><cell>0.80</cell><cell>0.82</cell><cell>0.67</cell><cell>0.60</cell></row><row><cell></cell><cell>avg classification entropy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Training wall time of the ASEM-CAD algorithm</figDesc><table><row><cell>Dataset</cell><cell>Number of</cell><cell></cell><cell cols="2">Total runtime in Minutes</cell><cell></cell></row><row><cell></cell><cell>Images</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Initial Model</cell><cell>ASEM Iterations</cell><cell>Total Time</cell><cell>Percent Increase</cell></row><row><cell>Kaggle</cell><cell>1357</cell><cell>26</cell><cell>8</cell><cell>34</cell><cell>31 %</cell></row><row><cell>NLST</cell><cell>2538</cell><cell>47</cell><cell>15</cell><cell>62</cell><cell>32 %</cell></row><row><cell>LIDC</cell><cell>4253</cell><cell>8</cell><cell>4</cell><cell>12</cell><cell>50 %</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proc. of SPIE Vol. 11314 113142E-2 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Proc. of SPIE Vol. 11314 113142E-3 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Proc. of SPIE Vol. 11314 113142E-4 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>Proc. of SPIE Vol. 11314 113142E-5 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_4"><p>Proc. of SPIE Vol. 11314 113142E-6 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_5"><p>Proc. of SPIE Vol. 11314 113142E-7 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_6"><p>Proc. of SPIE Vol. 11314 113142E-8 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_7"><p>Proc. of SPIE Vol. 11314 113142E-9 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_8"><p>Proc. of SPIE Vol. 11314 113142E-10 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_9"><p>Proc. of SPIE Vol. 11314 113142E-11 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_10"><p>Proc. of SPIE Vol. 11314 113142E-12 Downloaded From: https://www.spiedigitallibrary.org/conference-proceedings-of-spie on 09 Apr 2020 Terms of Use: https://www.spiedigitallibrary.org/terms-of-use</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGEMENTS</head><p>This work was sponsored by <rs type="institution">NSF IUCRC University of Maryland Baltimore County: Center for Accelerated Real Time Analytics (CARTA)</rs>, <ref type="url" target="https://carta.umbc.edu/">https://carta.umbc.edu/</ref> . We would like to thank <rs type="person">Jayalakshmi Mangalagiri</rs> for helping in preparing this manuscript. Additional thanks to <rs type="person">Kushal Mehta</rs>, <rs type="person">Arshita Jain</rs>, and <rs type="person">Ankita Viresh Rathod</rs> for pre-processing the LIDC dataset. Special thanks to <rs type="person">Eliot Siegel</rs> for his contributions to our research related to CAD algorithms for cancer screening.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on deep learning in medical image analysis</title>
		<author>
			<persName><forename type="first">Geert</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thijs</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehteshami</forename><surname>Babak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnaud</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adiyoso</forename><surname>Arindra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Setio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohsen</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeroen</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awm</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bram</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><forename type="middle">I</forename><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer</title>
		<author>
			<persName><forename type="first">Babak</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitko</forename><surname>Ehteshami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">Johannes</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bram</forename><surname>Van Diest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nico</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geert</forename><surname>Karssemeijer</surname></persName>
		</author>
		<author>
			<persName><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Awm</forename><surname>Jeroen</surname></persName>
		</author>
		<author>
			<persName><surname>Van Der Laak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2199" to="2210" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deep learning for identifying metastatic breast cancer</title>
		<author>
			<persName><forename type="first">Dayong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rishab</forename><surname>Gargeya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Humayun</forename><surname>Irshad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">H</forename><surname>Beck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05718</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computer-aided classification of lung nodules on computed tomography images via deep learning technique</title>
		<author>
			<persName><forename type="first">Kai</forename><forename type="middle">-</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Che-Hao</forename><surname>Lung</surname></persName>
		</author>
		<author>
			<persName><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chusnul</forename><surname>Shintami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Huang</forename><surname>Hidayati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu-Jen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OncoTargets and therapy</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks</title>
		<author>
			<persName><forename type="first">Paras</forename><surname>Lakhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baskaran</forename><surname>Sundaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">284</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="574" to="582" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A 3D Probabilistic Deep Learning System for Detection and Diagnosis of Lung Cancer Using Low-Dose CT Scans</title>
		<author>
			<persName><surname>Ozdemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">L</forename><surname>Onur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><surname>Berlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.03233</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">International evaluation of an AI system for breast cancer screening</title>
		<author>
			<persName><forename type="first">Scott</forename><surname>Mckinney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varun</forename><surname>Sieniek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natasha</forename><surname>Godwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hutan</forename><surname>Antropova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Ashrafian</surname></persName>
		</author>
		<author>
			<persName><surname>Back</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">577</biblScope>
			<biblScope unit="issue">7788</biblScope>
			<biblScope unit="page" from="89" to="94" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?</title>
		<author>
			<persName><forename type="first">Junghwan</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyewook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garry</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Synho</forename><surname>Do</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06348</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cancer statistics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jemal</surname></persName>
		</author>
		<idno type="DOI">10.3322/caac.21590</idno>
	</analytic>
	<monogr>
		<title level="j">CA A Cancer J Clin</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="7" to="30" />
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep Expectation-Maximization for Semi-Supervised Lung Cancer Screening</title>
		<author>
			<persName><forename type="first">S</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yesha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Saboury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGKDD 2019</title>
		<meeting>ACM SIGKDD 2019<address><addrLine>Anchorage, Alaska</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">Arthur</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><surname>Jerry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison Department of Computer Sciences</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The relative value of labeled and unlabeled samples in pattern recognition with an unknown mixing parameter</title>
		<author>
			<persName><forename type="first">Vittorio</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2102" to="2117" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation</title>
		<author>
			<persName><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1742" to="1750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Selective sampling for nearest neighbor classifiers</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Rusakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="152" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient active learning for image classification and segmentation using a sample selection and conditional generative adversarial network</title>
		<author>
			<persName><forename type="first">Dwarikanath</forename><surname>Mahapatra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behzad</forename><surname>Bozorgtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Philippe</forename><surname>Thiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mauricio</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="580" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep bayesian active learning with image data</title>
		<author>
			<persName><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riashat</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1183" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The power of ensembles for active learning in image classification</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">H</forename><surname>Beluch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Nürnberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">M</forename><surname>Köhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="9368" to="9377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bayesian generative active deep learning</title>
		<author>
			<persName><forename type="first">Toan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thanh-Toan</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.11643</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An active learning approach for rapid characterization of endothelial cells in human tumors</title>
		<author>
			<persName><forename type="first">Raghav</forename><forename type="middle">K</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vinay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><forename type="middle">D</forename><surname>Somasundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianliang</forename><surname>Griffith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drew</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><surname>Samoyedny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">See</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Predicting positive p53 cancer rescue regions using Most Informative Positive (MIP) active learning</title>
		<author>
			<persName><forename type="first">Samuel</forename><forename type="middle">A</forename><surname>Danziger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberta</forename><surname>Baronio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lydia</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linda</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kirsty</forename><surname>Salmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Wesley</forename><surname>Hatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">H</forename><surname>Lathrop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An Active Learning Approach for Reducing Annotation Cost in Skin Lesion Analysis</title>
		<author>
			<persName><forename type="first">Xueying</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Machine Learning in Medical Imaging</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="628" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Combining deep learning methods and human knowledge to identify abnormalities in computed tomography (CT) reports</title>
		<author>
			<persName><forename type="first">Matias</forename><surname>Benitez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vignesh</forename><surname>Selvakumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Phelan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maciej</forename><surname>Mazurowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">Y</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">D</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Henao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Aided Diagnosis</title>
		<imprint>
			<biblScope unit="volume">10950</biblScope>
			<biblScope unit="page">109500</biblScope>
			<date type="published" when="2019">2019. 2019</date>
			<publisher>International Society for Optics and Photonics</publisher>
		</imprint>
	</monogr>
	<note>In Medical Imaging</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Highly accurate model for prediction of lung nodule malignancy with CT scans</title>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">L</forename><surname>Causey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shiqian</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><forename type="middle">A</forename><surname>Qualls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">G</forename><surname>Politte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><surname>Prior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuzhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuzhen</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Lung Image Database Consortium (LIDC) data collection process for nodule detection and annotation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Mcnitt-Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Armato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Laderach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academic radiology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1464" to="1474" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on CT scans</title>
		<author>
			<persName><forename type="first">Iii</forename><surname>Armato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bidaut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mcnitt-Gray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Kazerooni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical physics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="915" to="931" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
