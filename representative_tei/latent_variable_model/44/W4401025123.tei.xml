<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms</title>
				<funder ref="#_mPKnFpQ #_6Rb6SGs #_vzVvMez">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder ref="#_KpmaJfr">
					<orgName type="full">National Institute of General Medical Sciences of National Institutes of Health</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-08-23">23 Aug 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Aneesh</forename><surname>Komanduri</surname></persName>
							<email>akomandu@uark.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Arkansas</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yongkai</forename><surname>Wu</surname></persName>
							<email>yongkaw@clemson.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Clemson University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Feng</forename><surname>Chen</surname></persName>
							<email>feng.chen@utdallas.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Texas at Dallas</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xintao</forename><surname>Wu</surname></persName>
							<email>xintaowu@uark.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Arkansas</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-08-23">23 Aug 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2306.01213v4[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using nonlinear learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior learned from auxiliary labels and the latent causal structure. We theoretically show the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demonstrate that our framework induces highly disentangled causal factors, improves interventional robustness, and is compatible with counterfactual generation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Disentangled representation learning aims to learn meaningful and compact representations that capture semantic aspects of data by structurally disentangling the factors of variation <ref type="bibr" target="#b0">[Bengio et al., 2013]</ref>. Such representations have been shown to offer useful properties such as better interpretability, robustness to distribution shifts, efficient out-of-distribution sampling, and fairness <ref type="bibr">[Locatello et al., 2019]</ref>. However, disentangled representation learning typically assumes that the underlying factors are independent, which is unrealistic in practice. The factors generating the data can contain correlations or even causal relationships that are disregarded when factors are assumed to be independent. Further, a generative model learning from an independent prior assumes that all combinations of the latent factors are equally likely to appear in the training data. Thus, disentangling the factors would yield a sub-optimal likelihood since the assumed support could be well outside the support of the training data. Recently, there has been a growing interest in bridging causality <ref type="bibr" target="#b9">[Pearl, 2009]</ref> and representation learning <ref type="bibr" target="#b0">[Bengio et al., 2013]</ref>. The goal of causal representation learning (CRL) is to map unstructured low-level data to high-level abstract causal variables of interest <ref type="bibr" target="#b10">[Scholkopf et al., 2021]</ref>. The key assumption is that high-dimensional observations are generated from a set of underlying low-dimensional causally related factors of variation. Causal representations have been shown to be useful for tasks involving reasoning and planning. Causal representations also adhere to the principle of independent causal mechanisms (ICM) <ref type="bibr">[Parascandolo et al., 2018]</ref>, which states that the mechanisms that generate each causal variable are independent such that a change in one mechanism does not affect another <ref type="bibr">[SchÃ¶lkopf and von KÃ¼gelgen, 2022;</ref><ref type="bibr" target="#b9">Peters et al., 2017]</ref>. Learning a generative model that captures the causal structure among latent factors can be crucial for reasoning about the world under manipulation. For example, a pendulum, light source, and shadow, as seen in Figure <ref type="figure" target="#fig_0">1</ref>, may be causally related but are separate entities in the world that can be independently manipulated. Particularly, manipulating the pendulum's angle will affect the shadow's position and length. These hypothetical scenarios could be counterfactually generated from a causal model.</p><p>Ensuring that causal representations are disentangled is useful for the causal controllable generation to generate counterfactual instances unseen during training. Such instances could be utilized as augmented data for robust learning in downstream tasks. The notion of disentanglement may be trivial when the factors are independent but becomes difficult to achieve when there are correlations or causal relationships among factors in the observed data. For highly correlated factors, it can be difficult to separate the factors of variation from their latent codes <ref type="bibr" target="#b11">[TrÃ¤uble et al., 2021]</ref>. Recently, it was shown that it is impossible to learn a disentangled representation in an unsupervised manner without some form of inductive bias <ref type="bibr">[Locatello et al., 2019]</ref>. Recent work proved that models with an independent prior are unidentifiable <ref type="bibr" target="#b10">[Shen et al., 2022]</ref>. Further, most existing disentanglement methods fail to disentangle factors when correlations exist in the data <ref type="bibr" target="#b11">[TrÃ¤uble et al., 2021]</ref>. However, results from large-scale empirical studies <ref type="bibr" target="#b8">[Locatello et al., 2020]</ref> have indicated that supervision in the form of auxiliary labels or contrastive data can effectively disentangle correlated or causal factors.</p><p>Related Work. Our work builds upon the ideas presented in iVAE <ref type="bibr">[Khemakhem et al., 2020]</ref> and causal variants <ref type="bibr" target="#b12">[Yang et al., 2021;</ref><ref type="bibr">Komanduri et al., 2022]</ref> and extends them to consider a principled view of causal disentanglement in the label supervised setting. DIVA <ref type="bibr" target="#b4">[Ilse et al., 2020]</ref> and CC-VAE <ref type="bibr" target="#b4">[Joy et al., 2021]</ref> are special case implementations of the iVAE framework. <ref type="bibr" target="#b12">Yang et al. [2021]</ref> proposed Causal-VAE, which uses a causal masking layer and is limited to linear SCMs. <ref type="bibr">Komanduri et al. [2022]</ref> extended this to a nonlinear setting and proposed a causal prior. Both works proposed simplistic models to learn causal mechanisms under the strictly additive noise assumption and do not, from an empirical or theoretical perspective, focus on disentanglement. <ref type="bibr" target="#b10">Shen et al. [2022]</ref> proposed learning causal representations supervised by a GAN loss. There has also been work focusing on learning causal representations from paired counterfactual data <ref type="bibr">[Brehmer et al., 2022]</ref>, temporal data <ref type="bibr" target="#b8">[Lippe et al., 2023]</ref>, in self-supervised learning <ref type="bibr">[von KÃ¼gelgen et al., 2021]</ref>, and when interventional data is available <ref type="bibr" target="#b0">[Ahuja et al., 2023]</ref>. Unlike many previous works in label-supervised VAEbased CRL, we consider general nonlinear SCMs instead of restricting to additive noise models, propose a causal prior to causally factorize the latent space, and achieve disentanglement of causal mechanisms, as summarized in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions.</head><p>(1) We propose ICM-VAE, a framework for causal representation learning under label supervision, where causal variables are derived from nonlinear flow-based diffeomorphic causal mechanisms. (2) Based on the ICM principle, we propose the notion of causal disentanglement for causal models from the perspective of mechanisms and design a causal disentanglement prior to causally factorize the learned distribution over causal variables. (3) Using the structure from our causal disentanglement prior, we theoretically show identifiability of the learned causal factors up to permutation and elementwise reparameterization. (4) We experimentally validate our method and show that our model can almost perfectly disentangle the causal factors, improve interventional robustness, and generate consistent counterfactuals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General SCM Compatible</head><p>Causal Prior </p><formula xml:id="formula_0">Causal Mechanism Disentanglement iVAE âœ— âœ— âœ— CausalVAE âœ— âœ— âœ— SCM-VAE âœ— âœ“ âœ— ICM-VAE (Ours) âœ“ âœ“ âœ“</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>Let X âŠ‚ R d denote the support of the observed data x generated from a set of causally related ground-truth factors.</p><p>The observations are assumed to be explained by some latent causal factors of variation z with domain Z âŠ‚ R n , where n â‰ª d. z represents a set of causal factors while z i represents a single causal factor. We assume x can be decomposed as x = g(z) + Î¾ where Î¾ âˆ¼ N (0, Ïƒ 2 I) are mutually independent Gaussian noise terms for reconstruction. Let g : Z â†’ X be the decoder (or mixing function). Each factor z i contains semantically meaningful information about the observation.</p><p>In the traditional VAE <ref type="bibr" target="#b5">[Kingma and Welling, 2013]</ref>, we assume the observed data is generated by the latent generative model with the structure p Î¸ (x, z) = p Î¸ (x|z)p Î¸ (z) where Î¸ are the true but unknown parameters. We aim to learn the joint distribution p(x, z) to estimate the marginal density and a posterior p(z|x) to describe the underlying factors of variation given a prior p(z) over the latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Identifiability</head><p>The goal of learning a useful representation that recovers the true underlying data-generating factors is closely tied to the problem of blind source separation (BSS) and independent component analysis (ICA) <ref type="bibr" target="#b2">[Hyvarinen et al., 2018;</ref><ref type="bibr" target="#b1">Comon, 1994;</ref><ref type="bibr" target="#b3">HyvÃ¤rinen and Pajunen, 1999]</ref>. Provably showing that a learning algorithm achieves this goal up to tolerable ambiguities under certain conditions is formalized as the identifiability of a model. In this section, we use the notion of âˆ¼-equivalence <ref type="bibr">[Khemakhem et al., 2020]</ref> to formulate the notion of identifiability. Definition 1 (âˆ¼-identifiability). Let âˆ¼ be an equivalence relation on Î¸. The generative model is âˆ¼-identifiable if</p><formula xml:id="formula_1">p Î¸ (x) = p Î¸ (x) =â‡’ Î¸ âˆ¼ Î¸ (1)</formula><p>If two different choices of model parameter Î¸ and Î¸ lead to the same marginal density p Î¸ (x), then they must be equal and this implies that p Î¸ (x, z) = p Î¸ (x, z), p Î¸ (z) = p Î¸ (z), and p Î¸ (z|x) = p Î¸ (z|x). However, recent work showed that it is impossible to achieve marginal density equivalence p Î¸ (x) = p Î¸ (x) with an unconditional prior p Î¸ (z) <ref type="bibr">[Khemakhem et al., 2020]</ref>. Since the VAE is unidentifiable without some form of additional restriction on the function class of the mixing function or auxiliary information, the identifiable VAE (iVAE) was proposed to utilize auxiliary information in the form of a conditionally factorial prior for identifiability guarantees <ref type="bibr">[Khemakhem et al., 2020]</ref>. In iVAE, each factor z i is assumed to have a univariate exponential family distribution (due to their universal approximation capabilities) given the conditioning variable u, where a function Î» determines the natural parameters of the distribution. The general PDF of the conditional distribution is defined as follows:</p><formula xml:id="formula_2">p T,Î» (z|u) = i h i (z i ) exp k j=1 T i,j (z i )Î» i,j (u) -Ïˆ i (u) (2)</formula><p>where h i (z i ) is the base measure, T i : Z â†’ R k and T i = (T i,1 , . . . , T i,k ) are the sufficient statistics, Î» i (u) = (Î» i,1 (u), . . . , Î» i,k (u)) are the corresponding natural parameters, k is the dimension of each sufficient statistic, and the remaining term Ïˆ i (u) acts as a normalizing constant. A prior conditioned on auxiliary information u can guarantee that the joint densities p Î¸ (x, z) = p Î¸ (x, z) are equivalent up to some equivalence class. The following two definitions describe the conditions necessary to achieve the identifiability of a learned model up to linear transformation and block permutation indeterminacies, respectively. Definition 2 <ref type="bibr">([Khemakhem et al., 2020]</ref>). Let âˆ¼ be an equivalence relation on Î¸, X = g(Z), and X = Ä(Z). We say that Î¸ and Î¸ are linearly-equivalent if and only if there exists an invertible matrix A âˆˆ R nkÃ—nk and vectors b, c âˆˆ R nk such that âˆ€x âˆˆ X :</p><formula xml:id="formula_3">1. T(g -1 (x)) = A T(Ä -1 (x)) + b, âˆ€x âˆˆ X 2. A T Î»(u) + c = Î»(u)</formula><p>We denote this equivalence as Î¸ âˆ¼ A Î¸.</p><p>Definition 3 <ref type="bibr">([Khemakhem et al., 2020]</ref>). We say Î¸ and Î¸ are permutation-equivalent, denoted Î¸ âˆ¼ P Î¸, if and only if P is permutation matrix that has block-permutation structure respecting T. That is, there exist n invertible k Ã— k matrices A 1 , . . . , A n and an n-permutation Ï€ such that for all z âˆˆ R nk , P áº‘ = [z Ï€(1) A T 1 , z Ï€(2) A T 2 , . . . , z Ï€(n) A T n ] T . Linear equivalence indicates the true representation is a linear transformation of the learned representation and only guarantees the learned representation captures the true representation. In general, linear-equivalent identifiability does not guarantee that the factors of variation are disentangled since the linear transformation can mix up the variables (i.e. one component of g -1 corresponds to multiple components of Ä-1 ). Permutation equivalence implies that the i-th factor z i of one representation corresponds to a unique factor in another representation, given the permutation Ï€. To truly disentangle factors of variation, we must ensure that each coordinate of the learned representation is equal to the scaled and shifted coordinate of the ground truth up to some permutation. To this end, we define the notion of disentanglement as permutation equivalence <ref type="bibr" target="#b6">[Lachapelle et al., 2022]</ref> as follows. Definition 4 (Permutation Disentanglement). Given some ground-truth model, a learned model Î¸ is said to be disentangled if Î¸ and Î¸ are permutation-equivalent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Structural Causal Model</head><p>Henceforth, we assume z is described by a structural causal model (SCM) <ref type="bibr" target="#b9">[Pearl, 2009]</ref>, which is formally defined by a tuple M = âŸ¨Z, E, F âŸ©, where Z is the domain of the set of n endogenous causal variables z = {z 1 , . . . , z n }, E is the domain of the set of n exogenous noise variables Ïµ = {Ïµ 1 , . . . , Ïµ n }, which is learned as an intermediate latent variable, and F = {f 1 , . . . , f n } is a collection of n independent causal mechanisms of the form</p><formula xml:id="formula_4">z i = f i (Ïµ i , z pa i ) (3)</formula><p>where âˆ€i, f i : Based on the intuition that causal models are described by mechanisms, we define a new notion of disentanglement that takes into account conditional distributions of causal variables under the Markov factorization. The new causal conditional equivalence preserves information about the independent causal mechanisms (ICM), which is a unique formulation for a causal model and important for performing correct interventions. The following two definitions describe the conditions necessary to satisfy causal mechanism equivalence. Definition 5 (Causal Mechanism Permutation Equivalence). Let âˆ¼ be an equivalence relation between Î¸ and Î¸, X = g(Z), and X = Ä(Z). If the factors z are causally related, we say that Î¸ is causal mechanism permutation equivalent to Î¸ iff:</p><formula xml:id="formula_5">E i Ã— jâˆˆpa i Z j â†’ Z i are</formula><p>1. There exists a permutation matrix P such that I = P â€¢ J where I and J are indices of z and áº‘, respectively. 2. Given an equivalence pair (i, j), i.e., P ij Ì¸ = 0, from this permutation matrix, one has T i (z i |z pa i ) = D ij Tj (z j |z pa j ), âˆ€z i âˆˆ Z i , âˆ€áº‘ j âˆˆ Z j , where D ij is a scaling coefficient. 3. For all i, j âˆˆ {1, . . . , n}, we have the mechanism equivalence Î» i (z pa i , u) = D ij Î»j (z pa j , u), where D is a diagonal scaling matrix.</p><p>Definition 6 (Causal Disentanglement). Given some groundtruth model Î¸, a learned model Î¸ is said to be causally disentangled if Î¸ and Î¸ are causal mechanism permutationequivalent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Framework</head><p>We design a framework to achieve causal disentanglement.</p><p>We propose ICM-VAE, a VAE-based framework based on the independent causal mechanisms (ICM) principle that achieves disentanglement of causal mechanisms. Figure <ref type="figure" target="#fig_1">2</ref> shows the overall architecture of our proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Structural Causal Flow</head><p>Rather than assuming the limiting linear causal graphical model (CGM), as done in <ref type="bibr">CausalVAE [Yang et al., 2021]</ref>, we consider causal mechanisms to be complex nonlinear functions. Diverging from the strictly additive noise model assumption, we propose to parameterize causal mechanisms with a more general diffeomorphic<ref type="foot" target="#foot_0">foot_0</ref> function. Flow-based models <ref type="bibr">[Papamakarios et al., 2021]</ref> are often quite expressive in low-dimensional settings, which makes them desirable for learning complex distributions due to efficient and exact evaluation of densities. We parameterize the causal mechanisms with a conditional flow, which we refer to as the latent structural causal flow (SCF), that learns to map the independent noise distribution to a distribution over causal variables. This module is inspired by the causal autoregressive flow <ref type="bibr">[Khemakhem et al., 2021]</ref>. This type of model is more realistic and general to better capture the complex distribution over the latent causal variables compared to simple linear mappings and leads to counterfactual identifiability <ref type="bibr" target="#b8">[Nasr-Esfahany et al., 2023]</ref>. The SCF, denoted as f RF , is the reduced form (RF) of a nonlinear SCM function that conceptually maps noise variables Ïµ to causal variables z as follows</p><formula xml:id="formula_6">z = f RF (Ïµ)<label>(4)</label></formula><p>where f RF : E â†’ Z is derived from the recursive substitution of causal mechanisms f i in topological order of the causal graph as follows</p><formula xml:id="formula_7">z i = f i (Ïµ i ; z pa i ), âˆ€i âˆˆ {1, . . . , n}<label>(5)</label></formula><p>realized as a function of the noise term and parent variables.</p><p>The noise encoding Ïµ i is exactly the SCM noise variable corresponding to the causal variable z i . Similar to several prior works <ref type="bibr" target="#b10">[Shen et al., 2022;</ref><ref type="bibr" target="#b7">Liang et al., 2023]</ref>, we assume that the latent causal graph is known in the form of a binary adjacency matrix to focus on formulating the problem of causal disentanglement. To implement a diffeomorphic function f RF , we use flow-based models to parameterize the causal mechanisms. Specifically, this flow is implemented as an affine-form autoregressive flow, where we derive each causal variable one at a time in topological order such that each variable is dependent only on a subset of previously derived variables (i.e. parents). Thus, the change of variables can be computed quite easily for exact and efficient likelihood estimation. In general, one can parameterize causal mechanisms using any nonlinear diffeomorphic function, as long as it takes into account the topological ordering. Let's take the pendulum example in Figure <ref type="figure" target="#fig_0">1</ref> to illustrate. The causal structure is z 1 â†’ z 3 , z 4 and z 2 â†’ z 3 , z 4 . Then, the SCF would be f</p><formula xml:id="formula_8">RF : (Ïµ 1 , Ïµ 2 , Ïµ 3 , Ïµ 4 ) â†’ (z 1 = f 1 (Ïµ 1 ), z 2 = f 2 (Ïµ 2 ), z 3 = f 3 (Ïµ 3 , z 1 , z 2 ), z 4 = f 4 (Ïµ 4 , z 1 , z 2 )), where z i = f RF i (Ïµ i ; Ïµ pa i ) = f i (Ïµ i ; z pa i )</formula><p>and each f i is a diffeomorphic transformation of the form</p><formula xml:id="formula_9">z i = f i (Ïµ i ; z pa i ) = exp(a i ) â€¢ Ïµ i + b i (6)</formula><p>where a i = r 1 (z pa i ) and b i = r 2 (z pa i ) are the slope and offset parameters of the affine transformation, respectively, learned via neural networks r 1 and r 2 that capture information about the causal parents. Since the Jacobian of the function will be triangular by construction and the slope parameter is learned for each variable, the slope is equivalent to the diagonal elements of the Jacobian matrix as follows</p><formula xml:id="formula_10">log i âˆ‚Ïµ i âˆ‚z i = i log âˆ‚f RF i (Ïµ i ; Ïµ pa i ) âˆ‚Ïµ i -1 = i a i (7)</formula><p>where Ïµ pa i denotes the noise terms associated with the parents of causal variable z i . The structural causal flow can easily be generalized to multivariate scenarios by masking groups of latent codes corresponding to each causal variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Generative Model</head><p>To achieve an identifiable model, we leverage auxiliary information as a weak supervision signal <ref type="bibr">[Khemakhem et al., 2020]</ref>. Let u âˆˆ R n be the auxiliary observed labels corresponding to the causally related ground-truth factors with support U âŠ‚ R n . We assume that the decoder g is diffeomorphic onto its image. Several prior works <ref type="bibr" target="#b8">[Locatello et al., 2020;</ref><ref type="bibr">Khemakhem et al., 2020;</ref><ref type="bibr" target="#b6">Lachapelle et al., 2022]</ref> assume that the nonlinear mixing function mapping Z to X is a diffeomorphism. Consider the pendulum system from Figure 1 consisting of a light source, a pendulum, and a shadow. Given only the image, it is completely certain that we can identify where each object appears in the image. So, we find it reasonable to assume a diffeomorphic mixing function g for our exploration. Let Î¸ = (g, T, Î», G z ) be the parameters of the conditional generative model defined as follows</p><formula xml:id="formula_11">p Î¸ (x, Ïµ, z|u) = p Î¸ (x|Ïµ, z)p Î¸ (Ïµ, z|u)<label>(8)</label></formula><p>where</p><formula xml:id="formula_12">p Î¸ (x|Ïµ, z) = p Î¸ (x|z) = p Î¾ (x -g(z))<label>(9</label></formula><p>) If we assume that the distribution over the noise Î¾ is Gaussian with infinitesimal variance, we can model non-noisy observations as a special case of Eq. ( <ref type="formula" target="#formula_12">9</ref>). The prior distribution in the generative model is given by</p><formula xml:id="formula_13">p Î¸ (Ïµ, z|u) = p(Ïµ)p Î¸ (z|u)<label>(10)</label></formula><p>where we choose p(Ïµ) as a standard Gaussian base distribution and p(z|u) is assumed to be conditionally factorial. However, the conditional prior in Eq. ( <ref type="formula">2</ref>) cannot properly capture causal mechanisms for causally related factors. We next define a causally factorized prior suitable to achieve causal disentanglement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoder</head><p>Decoder </p><formula xml:id="formula_14">âˆ¼ Reconstruction Data âˆ¼ Noise Prior ğœ– ! ğœ– " ğœ– # ğœ– $ ğ‘§ ! ğ‘§ " ğ‘§ # ğ‘§ $ ğ‘“ ! ğœ– ! ğ‘“ " ğœ– " ğ‘“ # ğœ– # ; ğ‘§ ğ©ğš ! ğ‘“ &amp; ğœ– &amp; ; ğ‘§ ğ©ğš " ğ‘§ $ ğ‘§ # ğ‘¢ ! ğ‘¢ # ğ‘¢ $ ğ‘¢ " ğ‘ ! (ğ‘§ " |ğ‘¢ " ) $ ğ‘ % (ğ‘§ &amp; |ğ‘§ ğ’‘ğ’‚ # , ğ‘¢ &amp; ) )*! &amp;*$ Causal Disentanglement Prior ğ‘ ! (ğ‘§ $ |ğ‘¢ $ ) ğ‘ ! (ğ‘§ % |ğ‘§ ğ©ğš ! , ğ‘¢ % ) ğ‘ ! (ğ‘§ ( |ğ‘§ ğ©ğš " , ğ‘¢ ( ) ğ‘§ " ğ‘§ ! Causal Mechanism Factorization Causal Representation Noise Encoding Structural Causal Flow ğ‘§ = ğ‘“ !" ğœ–</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Causal Disentanglement Prior</head><p>We aim to use a structured prior and perform conditioning in the latent space, similar to previous work on nonlinear <ref type="bibr">ICA [Khemakhem et al., 2020]</ref>, to enforce z to be a disentangled causal representation. However, for a model incorporating causal structure, the form of the conditional prior in Eq. ( <ref type="formula">2</ref>) needs to be modified and generalized to causally factorized distributions. To enforce the disentanglement of z, we parameterize the prior distribution to learn a mapping from u to z. That is, since the goal of causal disentanglement is to map each latent/mechanism to exactly one corresponding ground-truth factor/mechanism, we can explicitly incorporate this into the prior. Using u as our observational labels, we parameterize the factorized causal conditionals with a conditional flow between u and z to establish a bijective relationship. The goal is for the distribution over the causal variables to tend towards the learned prior. The prior over z is defined as follows</p><formula xml:id="formula_15">p Î¸ (z|u) = n i=1 p Î¸ (z i |z pa i , u i ) = n i=1 p(u i ) âˆ‚Î» i (u i ; z pa i ) âˆ‚u i -1 (11) p Î¸ (z i |z pa i , u i ) = h i (z i ) exp(T i (z i |z pa i )Î» i (G z i âŠ™ z, u i ) -Ïˆ i (z, u))<label>(12)</label></formula><p>where Î» i (G z i âŠ™ z, u i ) is the estimated parameter vector of the prior obtained via mechanism Î» i , G z i is the ith column of the adjacency matrix of the causal graph of z, h i (z) is the base measure, and T i (z) = (z, z 2 ) is the sufficient statistic. The prior induces a causal factorization of z with causal conditionals p Î¸ (z i |z pa i , u i ), where u i is introduced as a weak supervision signal for identifiability. Eq. ( <ref type="formula">11</ref>) is reminiscent of temporal priors that define a distribution over a latent variable conditioned on the variable at a previous time step <ref type="bibr" target="#b8">[Lippe et al., 2023]</ref>. In our case, we view the causal factors as derived autoregressively. With a slight abuse of notation, we define Î»(z, u) to be the concatenation of all Î» i (G z i âŠ™ z, u i ). The function Î»(z, u) outputs the natural parameter vector for the causally factorized distribution. We further require Î» : Z Ã— U â†’ Z to be a bijective map between u and learned representation z to encourage disentanglement of the causal mechanisms. In practice, we choose p(u) from a locationscale family such as Gaussian. The learned mechanism Î» i is defined as the following diffeomorphic map:</p><formula xml:id="formula_16">Î» i (u i ; z pa i ) = exp(c i ) â€¢ u i + d i<label>(13)</label></formula><p>where c i = s 1 (z pa i ) and d i = s 2 (z pa i ) are the slope and offset parameters of the flow, respectively, learned via neural networks. To obtain a causally factorized conditional prior over z, we map the base distribution p(u), which is known beforehand, to a distribution over z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Learning Objective</head><p>Putting all the components together, ICM-VAE consists of a stochastic encoder q Ï• (Ïµ, z|x, u), a decoder p Î¸ (x|Ïµ, z), and diffeomorphic causal transformations f i (â€¢; Ïµ). All components are learnable and implemented as neural networks. Formally, we aim to optimize the following variational lower bound:</p><formula xml:id="formula_17">log p Î¸ (x, u) â‰¥ E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ) + log p Î¸ (x|z) -Î²{log q Ï• (Ïµ|x, u) + log q Ï• (z|x, u) -log p(Ïµ) -log p Î¸ (z|u)} (<label>14</label></formula><formula xml:id="formula_18">)</formula><p>where Î² is the latent bottleneck parameter. We train the model by minimizing the negative of the ELBO loss and learn to map low-level pixel data to noise variables and map the noise variable distribution to a distribution over the causal variables. For a detailed derivation of the ELBO, refer to Appendix A.3. Causal structure learning could be heuristically incorporated jointly with the learning objective by enforcing acyclicity and sparsity of the causal graph. However, most causal discovery methods, such as GraN-DAG <ref type="bibr" target="#b6">[Lachapelle et al., 2020]</ref>, require restricting parametric assumptions on the causal model (i.e., additive noise), to be practically applied. For an extended discussion on incorporating causal discovery and challenges, refer to Appendix C. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Identifiability Analysis</head><p>We design our framework to satisfy the conditions necessary to achieve causal mechanism equivalence and causally disentangle the factors of variation. The causally factorized prior in Eq. ( <ref type="formula">11</ref>) induces disentanglement of causal mechanisms. Theorem 1 extends the identifiability theorem from iVAE <ref type="bibr">[Khemakhem et al., 2020]</ref> to show causal mechanism equivalence identifiability when we have a causal model. We note that causal mechanism disentanglement implies the disentanglement of causal factors.</p><p>Theorem 1 (Identifiability of ICM-VAE). Suppose that we observe data sampled from a generative model defined according to ( <ref type="formula" target="#formula_11">8</ref>)-( <ref type="formula" target="#formula_15">12</ref>) with two sets of model parameters Î¸ = (g, T, Î», G z ) and Î¸ = (Ä, T, Î», Äœz ). Suppose the following assumptions hold 1. The set {x âˆˆ X |Ï• Î¾ (x) = 0} has measure zero, where Ï• Î¾ is the characteristic function of the density p Î¾ defined in Eq. ( <ref type="formula" target="#formula_12">9</ref>).</p><p>2. The decoder g is diffeomorphic onto its image.</p><p>3. The sufficient statistics T i are diffeomorphic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">[Sufficient Variability]</head><p>There exists nk+1 distinct points u 0 , . . . , u nk such that the matrix</p><formula xml:id="formula_19">L = (Î»(z pa (1) , u (1) ) -Î»(z (0) , u (0) ), . . . , Î»(z pa (nk) , u (nk) ) -Î»(z (0) , u (0) ))<label>(15)</label></formula><p>of size nk Ã— nk is invertible, the ground-truth function Î» is affected sufficiently strongly by each individual label u i and previously derived variables z pa i , and âˆ€i,</p><formula xml:id="formula_20">Î» i (z pa i , u i ) Ì¸ = 0.</formula><p>Then Î¸ and Î¸ are causal mechanism permutation-equivalent, and the model Î¸ is causally disentangled.</p><p>For the proof of Theorem 1, refer to Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Evaluation</head><p>In this section, we empirically evaluate the effectiveness of ICM-VAE. We consider a setting where the causal variables can be multi-dimensional and fix the dimension of Evaluation Metrics. The DCI metric <ref type="bibr">[Eastwood and Williams, 2018]</ref> quantifies the degree to which ground-truth factors and learned latents are in one-to-one correspondence.</p><p>We compute the DCI disentanglement (D) and completeness (C) scores, which are based on a feature importance matrix quantifying the degree to which each latent code is important for predicting each ground truth causal factor. The informativeness (I) score is the prediction error in the latent factors predicting the ground-truth generative factors and is constant (I = 0) throughout all datasets and models, so we omit it for brevity. We train models with 3 random seeds and select the median DCI score to report. We note that DCI is highly correlated with other disentanglement metrics, such as MCC, with strong connections to identifiability <ref type="bibr">[Eastwood et al., 2023]</ref>.</p><p>To evaluate how changes in the generative factors affect the latent factors, we compute the interventional robustness score (IRS) <ref type="bibr" target="#b11">[Suter et al., 2019]</ref>, which is similar to an R 2 value. Implementation. For the Pendulum (6K training and 1K testing) and Flow (6K training and 2K testing) datasets, we linearly increase the Î² parameter throughout training from 0 to 1. We train for 9 â€¢ 10 3 steps using a batch size of 64.</p><p>We use a Gaussian encoder and decoder with mean and variance computed by fully connected neural networks. For the CausalCircuit dataset (35K training and 10K testing), we linearly increase Î² from 0 to 0.05. We train for 3.5 â€¢ 10 4 steps using a batch size of 100. We use a convolutional neural network architecture with 6 layers and ReLU activation followed by a fully connected layer to estimate the mean and variance.</p><p>The noise level for the variance of the Gaussian distribution of the conditional prior is controlled by Ïƒ 2 âˆˆ {0.01, 0.00001}.</p><p>The structural causal flow and Î» are implemented as affine form autoregressive flows with the slope and offset computed by fully connected 3-layer neural networks with 100 unit hidden layers and ReLU activation. We set the learning rate to 0.001 for all experiments. We set the dimension of each causal variable to 4 for all datasets. Our code is available at <ref type="url" target="https://github.com/Akomand/ICM-VAE">https://github.com/Akomand/ICM-VAE</ref>.</p><p>Baselines. We compare the performance of our approach, in terms of disentanglement and interventional robustness, with four baseline models: ing on the robot arm factor and propagating causal effects. We observe that the red light also turns on as the robot arm interacts with the blue or green lights. On the other hand, when the arm interacts with the red light, only the red light turns on and the other lights remain off. We observe a similar phenomenon in the Pendulum and Water Flow systems in Figure <ref type="figure" target="#fig_2">3</ref>, which shows the result of intervening on causal factors and propagating effects. Intervening on the pendulum angle or light position has causal effects on the shadow. However, interventions on the shadow factors do not change the parent factors. For the counterfactual generation procedure, results from intervening on other causal factors, and iVAE latent traversals, refer to Appendix B.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We propose ICM-VAE, a framework for causal representation learning under label supervision. We model causal mechanisms as flow-based transformations from noise to causal variables. We extend the idea of disentanglement to causal models and propose the notion of causal mechanism disentanglement. To this end, we design a causal disentanglement prior to causally factorize the distribution over causal variables. We theoretically show permutation-equivalent identifiability of the learned factors. Experimental results show that ICM-VAE almost perfectly disentangles the causal factors, improves interventional robustness, and generates consistent counterfactuals. Future work will incorporate causal discovery and disentanglement given partially observed labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices A Theory</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Restatement and Proof of Theorem 1</head><p>The following definitions and lemmas describe properties of exponential family sufficient statistics and the implication of causal mechanism permutation equivalence, which are used in our proof of Theorem 1. Definition 7 (Minimal Sufficient Statistic <ref type="bibr" target="#b6">[Lachapelle et al., 2022]</ref>). Given a parameterized distribution in the exponential family, we say its sufficient statistic T i is minimal when there exists no v Ì¸ = 0 such that v T T i (z) is constant for all z âˆˆ Z. Definition 8 (Permutation-Scaling Matrix <ref type="bibr" target="#b6">[Lachapelle et al., 2022]</ref>). A matrix is permutation-scaling if every row or column contains exactly one non-zero element. Lemma 1 ( <ref type="bibr" target="#b6">[Lachapelle et al., 2022]</ref>). A sufficient statistic T : Z â†’ R k is minimal if and only if there exist z (0) , . . . , z (k) belonging to the support of Z such that the following kdimensional vectors are linearly independent:</p><formula xml:id="formula_21">T(z (1) ) -T(z (0) ), . . . , T(z (k) ) -T(z (0) )<label>(16)</label></formula><p>Definition 9. A conditional sufficient statistic T(z|y) : Z Ã— Y â†’ R k describes the sufficient statistics of the conditional distribution of z induced as a result of conditioning on variable y. Definition 10. For all i, j âˆˆ {1, . . . , n}, if T i (z i |z pa i ) and Ti (z j |z pa j ) are causal permutation-equivalent, then z i and z j are permutation-equivalent.</p><p>We adapt the theory from <ref type="bibr" target="#b6">[Lachapelle et al., 2022]</ref> and <ref type="bibr">[Khemakhem et al., 2020]</ref> and propose the following theorem for identifiability. Theorem 1 (Identifiability of ICM-VAE). Suppose that we observe data sampled from a generative model defined according to ( <ref type="formula" target="#formula_11">8</ref>)-( <ref type="formula" target="#formula_15">12</ref>) with two sets of model parameters Î¸ = (g, T, Î», G z ) and Î¸ = (Ä, T, Î», Äœz ). Suppose the following assumptions hold 1. The set {x âˆˆ X |Ï• Î¾ (x) = 0} has measure zero, where Ï• Î¾ is the characteristic function of the density p Î¾ defined in Eq. ( <ref type="formula" target="#formula_12">9</ref>). 2. The decoder g is diffeomorphic onto its image. 3. The sufficient statistics T i are diffeomorphic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">[Sufficient Variability]</head><p>There exists nk+1 distinct points u 0 , . . . , u nk such that the matrix</p><formula xml:id="formula_22">L = (Î»(z pa (1) , u (1) ) -Î»(z (0) , u (0) ), . . . , Î»(z pa (nk) , u (nk) ) -Î»(z (0) , u (0) )) (17)</formula><p>of size nk Ã— nk is invertible, the ground-truth function Î» is affected sufficiently strongly by each individual label u i and previously derived variables z pa i , and âˆ€i,</p><formula xml:id="formula_23">Î» i (z pa i , u i ) Ì¸ = 0.</formula><p>Then Î¸ and Î¸ are causal mechanism permutation-equivalent, and the model Î¸ is causally disentangled.</p><p>Proof Intuition. The general idea of the proof is as follows. First, we use assumption 1 to show that the observed data distribution with noise is equivalent to the noiseless distribution. Then, using assumptions 2-4, we show the existence of an invertible linear transformation (in terms of the full-rank matrix L) between the learned and true causal factors, transforming both the sufficient statistic and mechanism Î». Finally, by utilizing the causal graph (either fixed or learned), we show that the linear transformation must have a permutation and scaling structure and leads to causal mechanism equivalence due to the structure of the conditional sufficient statistics and causal mechanisms Î». Thus, we show that the model is identifiable up to permutation and elementwise reparameterization.</p><p>Proof. To show that the set of parameters Î¸ is identifiable up to permutation, we break down the proof into five main steps.</p><p>Step 1 (Equality of Denoised Distributions). Firstly, we show that we can transform the equality of observed data distributions into a statement about the equality of noiseless distributions. Suppose we have two sets of parameters Î¸ and Î¸ such that their marginal distributions are equivalent as follows:</p><formula xml:id="formula_24">p Î¸ (x|u) = p Î¸ (x|u)<label>(18)</label></formula><p>for all pairs (x, u). Let g -1 = s â€¢ a -1 be the encoding of causal factors z, where a -1 is the encoding of the noise variables Ïµ. Then, we have the following</p><formula xml:id="formula_25">Z p T,Î» (z|u)p g (x|z) dz = Z p T, Î»(z|u)p Ä (x|z) dz (19) Z p T,Î» (z|u)p Î¾ (x -g(z)) dz = Z p T, Î»(z|u)p Î¾ (x -Ä(x)) dz (20) X p T,Î» (g -1 (x)|u) det J g -1 (x)p Î¾ (x -x) dx = X p T, Î»(Ä -1 (x)|u) det J Ä-1 (x)p Î¾ (x -x) dx (21) R d p T,Î»,g,u (x)p Î¾ (x -x) dx = R d p T, Î»,Ä,Ã» (x)p Î¾ (x -x) dx (22) (p T,Î»,g,u * p Î¾ )(x) = (p T, Î»,Ä,Ã» * p Î¾ )(x) (23) F[p T,Î»,g,u ](w)Ï• Î¾ (w) = F[p T, Î»,Ä,Ã» ](w)Ï• Î¾ (w) (24) F[p T,Î»,g,u ](w) = F[p T, Î»,Ä,Ã» ](w) (25) p T,Î»,g,u = p T, Î»,Ä,Ã»<label>(26)</label></formula><p>where F is the Fourier transform. Eq. ( <ref type="formula">24</ref>) and Eq. ( <ref type="formula" target="#formula_25">26</ref>) use the fact that the Fourier transform is invertible and Eq. ( <ref type="formula">25</ref>) is an application of the fact that the Fourier transform of a convolution is the product of their Fourier transforms. Thus, we have shown that if the distributions with added noise are the same, then the noise-free distributions must also be the same over all possible values (x, u) within the support.</p><p>Step 2 (Linear relationship). Define v = Ä-1 â€¢ g : Z â†’ áº. By replacing Eq. ( <ref type="formula" target="#formula_25">26</ref>) with the exponential form of the conditional prior from Eq. ( <ref type="formula">11</ref>), we obtain the following:</p><formula xml:id="formula_26">p T,Î» (z|u) = p T, Î»(z|u) (27) p T,Î» (g -1 (x)|u) det J g -1 (x) = p T, Î»(Ä -1 (x)|u) det J Ä-1 (x)<label>(28)</label></formula><formula xml:id="formula_27">n i=1 h i (g -1 i (x)) exp k j=1 T i,j (g -1 i (x)|g -1 pa i (x))Î» i,j (z pa i , u i ) -Ïˆ i (z pa i , u i ) det J g -1 (x) = n i=1 h i (Ä -1 i (x)) exp k j=1 Ti,j (Ä -1 i (x)|g -1 pa i (x)) Î»i,j (v(z pa i ), u i ) -Ïˆi (z pa i , u i ) det J Ä-1 (x)<label>(29)</label></formula><p>Taking the logarithm of both sides of Eq. ( <ref type="formula" target="#formula_27">29</ref>) yields the following</p><formula xml:id="formula_28">log det J g -1 (x) + n i=1 log h i (g -1 i (x)) + k j=1 T i,j (g -1 i (x)|g -1 pa i (x))Î» i,j (z pa i , u) -Ïˆ i (z pa i , u i ) = log det J Ä-1 (x) + n i=1 log Ä¥i (Ä -1 i (x)) + k j=1 Ti,j (Ä -1 i (x)|g -1 pa i (x)) Î»i,j (v(z pa i ), u) -Ïˆi (z pa i , u i )<label>(30)</label></formula><p>Let u 0 , . . . , u nk be the points provided by assumption 4 and define âˆ†Î»(z pa , u) = Î»(z pa , u) -Î»(z 0 , u 0 ). The notation z pa indicates that each causal variable in z is derived from its parents. We substitute each of the u â„“ in the above equation to obtain nk + 1 distinct equations. Using u 0 as a pivot, we subtract the first equation for u 0 from the remaining nk equations to obtain âˆ€â„“ âˆˆ 1, . . . , nk,</p><formula xml:id="formula_29">T(g -1 (x)) T âˆ†Î»(z pa â„“ , u â„“ ) - i Ïˆ i (z pa â„“ , u â„“ ) -Ïˆ i (z 0 , u 0 ) = T(Ä -1 (x)) T âˆ† Î»(v(z pa â„“ ), u â„“ ) - i Ïˆi (z pa â„“ , u â„“ ) -Ïˆi (z 0 , u 0 ) (31)</formula><p>Now, let L be the full-rank matrix described in the sufficient variability assumption (assumption 4), and L the matrix defined with respect to Î». Note that L is not guaranteed to be full-rank. Regrouping all normalizing constants Ïˆ into a term b â„“ = d(z pa â„“ , z 0 , u â„“ , u 0 ) and letting b be the vector of all b â„“ for all â„“ âˆˆ {1, . . . , nk}, we obtain the following:</p><formula xml:id="formula_30">L T T(g -1 (x)) = LT T(Ä -1 (x)) + b (<label>32</label></formula><formula xml:id="formula_31">)</formula><p>Since L is assumed to be invertible, we can multiply by the inverse of L T on both sides to obtain the following</p><formula xml:id="formula_32">T(g -1 (x)) = A T(Ä -1 (x)) + c<label>(33)</label></formula><p>where A = (L T ) -1 L and c = (L T ) -1 b.</p><p>Step 3 (Invertibility of A). We show that A is an invertible matrix. By Lemma 1, we have that the minimality of sufficient statistic T i implies that the following set of vectors is linearly independent:</p><formula xml:id="formula_33">T i (z (1) i ) -T i (z (0) i ), . . . , T i (z (k) i ) -T i (z (0) i )<label>(34)</label></formula><p>Define</p><formula xml:id="formula_34">z (0) = [z (0) 1 , . . . , z (0) n ] T âˆˆ R n<label>(35</label></formula><p>) For all i âˆˆ {1, . . . , n} and p âˆˆ {1, . . . , k}, define the vectors</p><formula xml:id="formula_35">z (p,i) = [z (0) 1 , . . . , z (0) i-1 , z (p) i , z (0) i+1 . . . , z (0)</formula><p>n ] T âˆˆ R n (36) Now, for 1 â‰¤ p â‰¤ k and i âˆˆ {1, . . . , n}, we consider the following difference</p><formula xml:id="formula_36">T(z (p,i) ) -T(z (0) ) = A[ T(z (p,i) ) -T(z (0) )]<label>(37)</label></formula><p>where the LHS is a vector filled with zeros except for the block corresponding to T i (z</p><formula xml:id="formula_37">(p,i) i ) -T(z<label>(0)</label></formula><p>i ). Define</p><formula xml:id="formula_38">âˆ†T (i) = [T(z (1,i) ) -T(z (0) ) . . . T(z (k,i) ) -T(z (0) )]<label>(38)</label></formula><p>and</p><formula xml:id="formula_39">âˆ† T(i) = [ T(z (1,i) ) -T(z (0) ) . . . T(z (k,i) ) -T(z (0) )]<label>(39)</label></formula><p>Then, we have that the columns of both these are linearly independent and all rows are filled with zeros except the block of rows {(i -1)k + 1, . . . , ik}. So, writing Eq. ( <ref type="formula" target="#formula_36">37</ref>) in matrix form and grouping all components, we have the following</p><formula xml:id="formula_40">[âˆ†T (1) , . . . , âˆ†T (n) ] = A[âˆ† T(1) , . . . , âˆ† T(n) ]<label>(40)</label></formula><p>Thus, we have a block diagonal matrix of size nk Ã—nk. Since each block is invertible, [âˆ†T (1) , . . . , âˆ†T (n) ] must be invertible. This implies that A must be invertible. Thus, Eq. ( <ref type="formula" target="#formula_32">33</ref>) and the invertibility of A imply that Î¸ âˆ¼ A Î¸. Step 4 (Linear relationship of natural parameters). In addition to showing the linear relationship between the sufficient statistic, we also show the linear relationship linking Î» and Î». Define v = Ä-1 â€¢ g : Z â†’ áº. That is, there exists a diffeomorphism between the learned and ground-truth factors. We rewrite Eq. ( <ref type="formula" target="#formula_28">30</ref>) as follows:</p><formula xml:id="formula_41">T(g -1 (x)) T Î»(z pa , u) = T(Ä -1 (x)) T Î»(v(z pa ), u) + Îº(z pa , u) + Î³(z)<label>(41)</label></formula><p>where we combine all terms depending only on z into Î³ and those depending only on u into Îº. Now, we can rewrite the above as follows using the linear relationship between sufficient statistics:</p><formula xml:id="formula_42">T(Ä -1 (x)) T A T Î»(z pa , u) + c T Î»(z pa , u) = T(Ä -1 (x)) T Î»(v(z pa ), u) + Îº(z pa , u) + Î³(z)<label>(42)</label></formula><formula xml:id="formula_43">T(Ä -1 (x)) T A T Î»(z pa , u) = T(Ä -1 (x)) T Î»(v(z pa ), u) + Îº(z pa , u) + Î³(z)<label>(43)</label></formula><p>where Îº absorbs all u-dependent terms. We can simplify this equality to the following:</p><formula xml:id="formula_44">T(Ä -1 (x)) T (A T Î»(z pa , u) -Î»(v(z pa ), u)) = Îº(z pa , u) + Î³(z)<label>(44)</label></formula><formula xml:id="formula_45">T(Ä -1 (x)) T (A T Î»(z pa , u) -Î»(v(z pa ), u)) = Îº(z pa , u) + Î³(Ä -1 (x))<label>(45)</label></formula><p>Taking the finite difference between distinct values z and z yields</p><formula xml:id="formula_46">[T(z) -T(z)] T (A T Î»(z pa , u) -Î»(v(z pa ), u)) = Î³(Ä -1 (x)) -Î³(Ä -1 (x))<label>(46)</label></formula><p>Now, we can construct an invertible matrix [âˆ†T (1) . . . âˆ†T (n) ] such that</p><formula xml:id="formula_47">[âˆ†T (1) . . . âˆ†T (n) ] T (A T Î»(z pa , u) -Î»(v(z pa ), u)) = [âˆ†Î³ (1) . . . âˆ†Î³ (n) ]<label>(47)</label></formula><p>Due to this invertibility, we can simplify the above to obtain</p><formula xml:id="formula_48">A T Î»(z pa , u) + Î³ = Î»(v(z pa ), u)<label>(48)</label></formula><p>where</p><formula xml:id="formula_49">Î³ = -[âˆ†T (1) . . . âˆ†T (n) ] -T [âˆ†Î³ (1) . . . âˆ†Î³ (n) ]<label>(49)</label></formula><p>We can rewrite this as follows to yield the equivalence of Î» and Î» A T Î»(z pa , u) + Î³ = Î»(v(z pa ), u) (50)</p><p>Step 5 (Permutation Equivalence). To show that A is a permutation-scaling matrix, we have to show that any two columns cannot have nonzero entries on the same row.</p><p>â€¢ If G z is fixed, we are done since the trivial permutation always holds. Since the decoder is assumed to be diffeomorphic, there is a point-wise nonlinearity between each corresponding factor of the representation. Thus, a bijective mapping establishes a component-wise reparameterization (scaling) and trivial permutation.</p><p>â€¢ If G z is learned, then for a learned sparse graph Äœz if the following holds</p><formula xml:id="formula_50">Ï€( Äœz ) = G z (51)</formula><p>then we still achieve permutation equivalence by permuting the causal graph.</p><p>We conclude that A must be a causal permutation-scaling matrix. Since Î» captures the causal dependencies between factors of z, we have that the following must be true</p><formula xml:id="formula_51">T i (z i |z pa i ) = A ij Tj (z j |z pa j )<label>(52)</label></formula><p>Thus, T, T and Î», Î» must be causal mechanism permutationequivalent, respectively, and z is causally disentangled. Therefore, z is disentangled, and we have that Î¸ âˆ¼ P Î¸, where P = A is a permutation-scaling matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Traditional disentanglement cannot guarantee independent causal mechanisms equivalence</head><p>In this section, we provide a counterexample to show that the traditional notion of disentanglement cannot capture the equivalence of causal mechanisms. For example, consider the running example of the Pendulum system. We have four causal factors that are causally related. Let z denote the true factors of variation and áº‘ denote the learned factors, where each z i and áº‘i correspond to the same causal variable. For the sake of simplicity, consider the example in Figure <ref type="figure" target="#fig_5">5</ref>.</p><p>Observe that the causal mechanisms learned are different than the true causal mechanisms. We have the following equivalent marginal distribution for true and learned factors:</p><formula xml:id="formula_52">p(z) = p(z 1 )p(z 2 )p(z 3 |z 1 , z 2 )p(z 4 |z 1 , z 2 ) â‰ˆ p(áº‘ 1 )p(áº‘ 2 )p(áº‘ 3 |áº‘ 1 , áº‘2 )p(áº‘ 4 |áº‘ 1 , áº‘2 ) = p(áº‘)</formula><p>However, traditional disentanglement does not imply equivalence of all individual causal mechanisms of true and learned factors. In the above example, the true SCM consists of different mechanisms than the learned SCM, but both yield the same marginal distribution. This example violates the causal mechanism permutation equivalence and causal disentanglement but satisfies traditional disentanglement. We claim that learning a model that achieves equivalence of causal mechanisms from the perspective of the ICM principle better captures disentanglement in the causal setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Derivation of ICM-VAE ELBO</head><p>We aim to push the variational posterior distribution q Ï• (Ïµ, z|x, u) to the true joint posterior distribution p Î¸ (Ïµ, z|x, u). Formally, the goal is to minimize the KL divergence as follows:</p><p>D(q Ï• (Ïµ, z|x, u), p Î¸ (Ïµ, z|x, u))</p><formula xml:id="formula_53">= q Ï• (Ïµ, z|x, u) log q Ï• (Ïµ, z|x, u) p Î¸ (Ïµ, z|x, u) dÏµ dz<label>(53)</label></formula><p>= q Ï• (Ïµ, z|x, u) log q Ï• (Ïµ, z|x, u)p Î¸ (x, u) p Î¸ (Ïµ, z, u, x) dÏµ dz (54) = q Ï• (Ïµ, z|x, u) log p Î¸ (x, u)</p><p>+ log q Ï• (Ïµ, z|x, u) p Î¸ (Ïµ, z, u, x) dÏµ dz</p><formula xml:id="formula_54">(55) = q Ï• (Ïµ, z|x, u) log p Î¸ (x, u) + q Ï• (Ïµ, z|x, u) log q Ï• (Ïµ, z|x, u) p Î¸ (Ïµ, z, u, x) dÏµ dz<label>(56)</label></formula><p>= log p Î¸ (x, u)</p><formula xml:id="formula_55">+ q Ï• (Ïµ, z|x, u) log q Ï• (Ïµ, z|x, u) p Î¸ (Ïµ, z, u, x) dÏµ dz<label>(57)</label></formula><p>= log p Î¸ (x, u)</p><formula xml:id="formula_56">+ q Ï• (Ïµ, z|x, u) log q Ï• (Ïµ, z|x, u) p Î¸ (x|Ïµ, z, u)p Î¸ (Ïµ, z, u) dÏµ dz<label>(58)</label></formula><p>= log p Î¸ (x, u) + E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log q Ï• (Ïµ, z|x, u) p Î¸ (Ïµ, z, u)</p><formula xml:id="formula_57">-log p Î¸ (x|Ïµ, z, u)<label>(59)</label></formula><p>= log p Î¸ (x, u) + D(q Ï• (Ïµ, z|x, u)||p Î¸ (Ïµ, z|u))</p><formula xml:id="formula_58">-E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z, u)<label>(60)</label></formula><p>So, we have the following:</p><formula xml:id="formula_59">D(q Ï• (Ïµ, z|x, u)||p Î¸ (Ïµ, z|x, u)) = log p Î¸ (x, u) + D(q Ï• (Ïµ, z|x, u)||p Î¸ (Ïµ, z|u)) -E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z, u)<label>(61)</label></formula><p>Rearranging, we can simply the objective to the following:</p><formula xml:id="formula_60">log p Î¸ (x, u) -D(q Ï• (Ïµ, z|x, u)||p Î¸ (Ïµ, z|x, u)) = E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z, u) -D(q Ï• (Ïµ, z|x, u)||p Î¸ (Ïµ, z|u))<label>(62)</label></formula><p>This implies that</p><formula xml:id="formula_61">log p Î¸ (x, u) -D(q Ï• (Ïµ, z|x, u)||p Î¸ (Ïµ, z|x, u)) â‰¤ log p Î¸ (x, u)<label>(63)</label></formula><p>Putting everything together yields the following evidence lower bound (ELBO)</p><formula xml:id="formula_62">log p Î¸ (x, u) Evidence â‰¥ Likelihood E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z, u) - KL Term D(q Ï• (Ïµ, z|x, u)||p Î¸ (Ïµ, z, u))<label>(64)</label></formula><p>Now, since Ïµ and z are related by a diffeomorphism, we can simplify the objective as follows.</p><p>log p Î¸ (x, u) â‰¥E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z, u)</p><formula xml:id="formula_63">-D(q Ï• (Ïµ|x, u)||p Î¸ (Ïµ)) -D(q Ï• (z|x, u)||p Î¸ (z|u))<label>(65)</label></formula><p>obtained by the following derivation log p Î¸ (x, u) â‰¥ E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z, u)</p><p>-E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log q Ï• (Ïµ, z|x, u) p Î¸ (Ïµ, z)</p><formula xml:id="formula_64">(66) = E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z, u) -log q Ï• (Ïµ, z|x, u) p Î¸ (Ïµ, z)<label>(67)</label></formula><p>= E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ, z) -log q Ï• (Ïµ, z|x, u)</p><formula xml:id="formula_65">+ log p Î¸ (Ïµ, z)<label>(68)</label></formula><p>= E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ) + log p Î¸ (x|z)</p><p>-log q Ï• (Ïµ, z|x, u) + log p Î¸ (Ïµ) + log p Î¸ (z|u)</p><formula xml:id="formula_66">(69) = E Ïµ,zâˆ¼q Ï• (Ïµ,z|x,u) log p Î¸ (x|Ïµ) + log p Î¸ (x|z)</formula><p>-log q Ï• (Ïµ|x, u) -log q Ï• (z|x, u) Causal Circuit. The Causal Circuit dataset is a new dataset created by <ref type="bibr">[Brehmer et al., 2022]</ref> to explore research in causal representation learning. The dataset consists of 512 Ã— 512 Ã— 3 resolution images generated by 4 ground-truth latent causal variables: robot arm position, red light intensity, green light intensity, and blue light intensity. The images show a robot arm interacting with a system of buttons and lights. The data is rendered using an open-source physics engine. The original dataset consists of pairs of images before and after an intervention has taken place. For this work, we only utilize observational data of either the before or after system. The data is generated according to the following process:</p><formula xml:id="formula_67">+ log p Î¸ (Ïµ) + log p Î¸ (z|u)<label>(70)</label></formula><formula xml:id="formula_68">v R = 0.2 + 0.6 * clip(u 2 + u 3 + b R , 0, 1) v G = 0.2 + 0.6 * b G v B = 0.2 + 0.6 * b B u 4 âˆ¼ Beta(5v R , 5 * (1 -v R )) u 3 âˆ¼ Beta(5v G , 5 * (1 -v G )) u 2 âˆ¼ Beta(5v B , 5 * (1 -v B )) u 1 âˆ¼ U (0, 1)</formula><p>where b R , b G , and b B are the pressed state of buttons that depends on how far the button is touched from the center, u 1 is the robot arm position, and u 2 , u 3 , and u 4 are the intensities of the blue, green, and red lights, respectively. The causal graph is shown in Figure <ref type="figure">6c</ref>. From this generative process, we selectively choose only images for which the causal graph is satisfied (the robot arm's position and the downstream effects). For example, the robot arm appearing over the green button, green button lit up, and red button lit up is consistent with the assumption that the robot arm position causes changes in which buttons light up according to the causal graph. The filtered dataset consists of roughly 35K training samples and 10K testing samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Counterfactual Generation</head><p>Following <ref type="bibr" target="#b9">[Pearl, 2009]</ref>, the process for obtaining counterfactual predictions consists of three steps 1. Abduction: given an observation x, we infer the distribution over the latent variable Ïµ via Ïµ = a -1 (x). In the context of ICM-VAE, we have that z = g -1 (x) = f RF (Ïµ).</p><p>2. Action: substitute the values of z with values based on the counterfactual query z zj â†Î± 3. Prediction: using the modified model and the value of z, compute (decode to) the value of x, the consequence of the counterfactual.</p><p>We clarify that, unlike the abduction step from traditional counterfactual inference, in our counterfactual generation procedure, we first derive noise terms from the observed high dimensional data and derive the causal factors from the noise terms. This effectively implies we obtain the original noise terms associated with the latent causal factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Additional Experimental Results</head><p>We include additional counterfactual images generated using ICM-VAE on other causal variables from the CausalCircuit dataset in Figure <ref type="figure">7</ref>. Observe that we can manipulate z 2 in an isolated fashion to change the brightness of the blue light and the brightness of the red light after computing causal effects. When intervening on z 3 , we see a change in the green light and a change in the brightness of the red light. Finally, after intervening on z 4 , we see a change in the brightness of the red light, but not its causal parents, which is consistent with the intervention. Further, we include iVAE-generated images after latent traversals on causal variables for the CausalCircuit dataset (Figure <ref type="figure">8</ref>) and the Pendulum/Water Flow datasets (Figure <ref type="figure">9</ref>). We can see that iVAE is not able to disentangle the causal factors and not capable of generating counterfactual images according to the assumed causal model since iVAE is an acausal method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Extension to Discrete-valued Factors</head><p>In this work, we focus on formulating ideas in causal disentanglement and representation learning and use synthetic datasets with continuous-valued variables for evaluation. However, an extension of our framework to datasets with discrete-valued variables (such as <ref type="bibr">CelebA [Liu et al., 2015]</ref>) would take the form of parameterizing causal mechanisms using discrete flows <ref type="bibr" target="#b11">[Tran et al., 2019]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Baselines</head><p>We compare ICM-VAE with four baselines: two acausal and two causal.</p><p>Î²-VAE <ref type="bibr">[Higgins et al., 2017]</ref> is an unsupervised disentanglement method that aims to promote disentanglement in the latent space by encouraging the latent representation to be more factorized. However, Î²-VAE is unable to effectively disentangle the factors of variation to a high degree, which is consistent with the claim from <ref type="bibr">[Locatello et al., 2019]</ref> that unsupervised disentanglement is not possible without additional inductive biases.</p><p>iVAE <ref type="bibr">[Khemakhem et al., 2020]</ref> unifies nonlinear ICA and the VAE to develop a framework for learning identifiable representations using auxiliary information in the form of a conditionally factorial prior. However, the framework of iVAE assumes independent factors of variation, which is often an impractical assumption. Due to this assumption, iVAE is unable to disentangle causally related factors.</p><p>CausalVAE <ref type="bibr" target="#b12">[Yang et al., 2021]</ref> and SCM-VAE <ref type="bibr">[Komanduri et al., 2022]</ref> extended the iVAE framework for causally related factors of variation. CausalVAE utilizes a prior that still assumes mutual independence of the factors of variation. Further, CausalVAE assumes a simple linear SCM, which is unrealistic in practice. SCM-VAE builds on this work and consists of a post-nonlinear additive noise SCM and a labelspecific causal prior. However, the causal prior proposed still does not induce a causal factorization of latent factors. Thus, CausalVAE and SCM-VAE are also unable to properly disentangle the causal factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Compute</head><p>We run our experiments on an Ubuntu 20.04 workstation with eight NVIDIA Tesla V100-SXM2 GPUs with 32GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Discussion on Causal Discovery</head><p>Similar to <ref type="bibr" target="#b10">[Shen et al., 2022;</ref><ref type="bibr" target="#b7">Liang et al., 2023]</ref>, in this work, we assume the latent causal structure is known to theoretically formulate the idea of causal mechanism disentanglement. In principle, our theory works just the same for a discovered causal graph as long as it is recovered up to some permutation of the true graph. This can be formalized as a graph isomorphism between the learned and ground-truth causal graphs <ref type="bibr">[Brehmer et al., 2022]</ref>. Incorporating causal discovery methods, such as NOTEARS <ref type="bibr" target="#b12">[Zheng et al., 2018]</ref> or GraN-DAG <ref type="bibr" target="#b6">[Lachapelle et al., 2020]</ref>, could be integrated heuristically in the form of adding a penalty to terms in the VAE loss objective to enforce sparsity and acyclicity as follows L total = L ICM -V AE + H(A) + âˆ¥Aâˆ¥ 0 (71)</p><p>where H(A) = tr[(I + Î±A âŠ™ A)] n -n = 0 is the acyclicity constraint and âˆ¥ â€¢ âˆ¥ 0 enforces the sparsity of the DAG. We can alternatively use the âˆ¥ â€¢ âˆ¥ 1 for sparsity to ensure a differentiable objective. Similar to <ref type="bibr" target="#b12">[Zheng et al., 2018]</ref>, we can utilize the augmented Lagrangian to optimize the joint loss objective. However, since we use flow-based models to parameterize causal mechanisms, the topological ordering of the causal graph is important. Since our focus in this work is not causal discovery, we assume knowledge of the causal graph from domain knowledge. We assume a flexible diffeomorphic general nonlinear structural causal model. Most causal discovery methods require restricting assumptions, such as linear (or post-nonlinear) additive noise models, to be practically applied. In this work, we motivate the need for more sophisticated causal discovery methods for generalized SCMs that may not necessarily assume some parametric form. A promising candidate is Jacobian-based causal discovery <ref type="bibr">[Reizinger et al., 2023]</ref>, which leverages the structure of nonlinear ICA methods and the Jacobian of causal mechanisms to facilitate causal discovery. Additionally, other causal discovery algorithms could be used heuristically with a variety of different assumptions <ref type="bibr">[Vowels et al., 2021;</ref><ref type="bibr" target="#b1">Glymour et al., 2019]</ref>. We look to explore this direction in future work. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: We learn causal models representing images as latent causal variables z. The bottom shows the effect of intervening on the latent code corresponding to the pendulum's angle, propagating effects, and generating a counterfactual image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Architecture of ICM-VAE Framework, which contains two main components: (i) Structural Causal Flow (SCF), and (ii) Causal Disentanglement Prior. The blue color represents prior components and the orange represents the learning process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Pendulum (left) and Flow (right) counterfactual images after intervening on causal factors, individually, and propagating effects.</figDesc><graphic coords="6,54.40,54.12,208.41,140.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>each causal variable, which has also been explored in previous work<ref type="bibr" target="#b12">[Yang et al., 2021;</ref><ref type="bibr" target="#b8">Lippe et al., 2023]</ref>. This assumption enables the representation to learn more informative and specific latent codes to describe the factors of variation (i.e. x-position, y-position, etc.). We run experiments on datasets with continuous factors, but discrete flows<ref type="bibr" target="#b11">[Tran et al., 2019]</ref> can be used for discrete factors. Our results suggest a component-wise correspondence between the learned and true causal factors.Datasets. We show the performance of our framework on three datasets, each consisting of four real-valued causal variables. The Pendulum dataset<ref type="bibr" target="#b12">[Yang et al., 2021]</ref> consists of causal variables with causal graph (pendulum angle â†’ shadow length, shadow position) and (light position â†’ shadow length, shadow position). The Flow dataset<ref type="bibr" target="#b12">[Yang et al., 2021]</ref> consists of variables with causal graph (ball size â†’ water height), (hole position â†’ water flow), and (water height â†’ water flow). We also show experiments on a more complex 3D dataset of a robot arm interacting with colored buttons called CausalCircuit[Brehmer et al., 2022], which consists of variables with causal graph (robot arm â†’ blue light intensity, green light intensity, and red light intensity), (blue light intensity â†’ red light intensity), and (green light intensity â†’ red light intensity).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: CausalCircuit counterfactual images by intervening on robot arm to turn on a colored light, which can causally affect other lights.</figDesc><graphic coords="7,426.03,61.35,65.81,72.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Counterexample to traditional disentanglement</figDesc><graphic coords="12,345.17,133.49,151.58,67.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 6: Causal Graphs of Datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :Figure 8 :Figure 9 :</head><label>789</label><figDesc>Figure 7: ICM-VAE counterfactuals generated after intervening on blue light (top), green light (middle), and red light (bottom), respectively.</figDesc><graphic coords="16,145.91,176.36,321.43,59.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Causal and acausal framework compatibilities in labelsupervised setting</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Causal Disentanglement of ICM-VAE and baselines</figDesc><table><row><cell>Causal Disentanglement. Our experiments show that</cell></row><row><cell>learning diffeomorphic causal mechanisms, rather than lin-</cell></row><row><cell>ear SCM, and incorporating the causal structure to learn a</cell></row><row><cell>bijective Î» to estimate the parameters of the causally factor-</cell></row><row><cell>ized distribution significantly improves the disentanglement</cell></row><row><cell>and interventional robustness of learned causal factors com-</cell></row><row><cell>pared with baselines, as shown in Table 2. Consistent with</cell></row><row><cell>our intuition, iVAE fails to disentangle the causal factors. The</cell></row><row><cell>results indicate that ICM-VAE disentangles the causal factors</cell></row><row><cell>and mechanisms almost perfectly. A high DCI disentangle-</cell></row><row><cell>ment score indicates a permutation matrix mapping the latent</cell></row><row><cell>factors to ground-truth generative factors in an ideal one-to-</cell></row><row><cell>one mapping [Eastwood et al., 2023]. Further, our model</cell></row><row><cell>improves the interventional robustness of the representation,</cell></row><row><cell>where interventions on ground-truth factors map to interven-</cell></row><row><cell>tions on the corresponding learned factors.</cell></row></table><note><p><p><p><p>Î²-VAE [Higgins et al., 2017] (unsupervised and acausal), iVAE [Khemakhem et al., 2020] (acausal), CausalVAE [Yang et al., 2021] (causal), and SCM-VAE [Komanduri et al., 2022] (causal). The causal baselines propose relatively simplistic models that do not necessarily guarantee the disentanglement of causal factors.</p>Counterfactual Generation. We show counterfactual generated results of intervening on learned latent factors. Figure</p>4</p>shows the CausalCircuit system and the result of interven-</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>A diffeomorphism is a differentiable bijection with a differentiable inverse.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work is supported in part by <rs type="funder">National Science Foundation</rs> under awards <rs type="grantNumber">1910284</rs>, <rs type="grantNumber">1946391</rs> and <rs type="grantNumber">2147375</rs>, the <rs type="funder">National Institute of General Medical Sciences of National Institutes of Health</rs> under award <rs type="grantNumber">P20GM139768</rs>, and the <rs type="institution">Arkansas Integrative Metabolic Research Center at University of Arkansas</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_mPKnFpQ">
					<idno type="grant-number">1910284</idno>
				</org>
				<org type="funding" xml:id="_6Rb6SGs">
					<idno type="grant-number">1946391</idno>
				</org>
				<org type="funding" xml:id="_vzVvMez">
					<idno type="grant-number">2147375</idno>
				</org>
				<org type="funding" xml:id="_KpmaJfr">
					<idno type="grant-number">P20GM139768</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName><surname>Ahuja</surname></persName>
			<affiliation>
				<orgName type="collaboration">Taco Cohen</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pascal</forename><surname>Courville</surname></persName>
		</editor>
		<editor>
			<persName><surname>Vincent</surname></persName>
		</editor>
		<meeting>the 40th International Conference on Machine Learning<address><addrLine>Pim De Haan, Phillip Lippe</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2023. 2023. 2013. 2013. 2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cian Eastwood and Christopher K. I. Williams. A framework for the quantitative evaluation of disentangled representations</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Comon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Comon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><surname>Glymour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<editor>
			<persName><surname>Eastwood</surname></persName>
		</editor>
		<meeting><address><addrLine>Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994. 1994. 2018. 2018. 2023. 2019. 2019. 2017. 2017</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="287" to="314" />
		</imprint>
	</monogr>
	<note>International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><surname>Hyvarinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08651</idno>
		<title level="m">Nonlinear ica using auxiliary variables and generalized contrastive learning</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nonlinear independent component analysis: Existence and uniqueness results</title>
		<author>
			<persName><forename type="first">Pajunen</forename><surname>HyvÃ¤rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="429" to="439" />
			<date type="published" when="1999">1999. 1999</date>
		</imprint>
	</monogr>
	<note>Aapo HyvÃ¤rinen and Petteri Pajunen</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoencoders and nonlinear ica: A unifying framework</title>
		<author>
			<persName><forename type="first">Ilse</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Twenty Third International Conference on Artificial Intelligence and Statistics<address><addrLine>Ricardo</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020. 2021. 2021. 2020</date>
		</imprint>
	</monogr>
	<note>International Conference on Learning Representations. Khemakhem et al., 2021] Ilyes Khemakhem</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scm-vae: Learning identifiable causal representations via structural knowledge</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Leech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling ; Aneesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongkai</forename><surname>Komanduri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 24th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>The 24th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<publisher>Kingma and Welling</publisher>
			<date type="published" when="2013">2021. 2013. 2013</date>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>IEEE International Conference on Big Data (Big Data)</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ICA</title>
		<author>
			<persName><surname>Lachapelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020. 2020. 2022. 2022</date>
		</imprint>
	</monogr>
	<note>First Conference on Causal Learning and Reasoning</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Causal component analysis</title>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Arash Nasr-Esfahany, Mohammad Alizadeh, and Devavrat Shah. Counterfactual identifiability of bijective causal models</title>
		<author>
			<persName><surname>Lippe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Niki Kilbertus</addrLine></address></meeting>
		<imprint>
			<publisher>Giambattista Parascandolo</publisher>
			<date type="published" when="2015">2023. 2023. 2015. 2015. 2019. 2019. 2020. 2023. 2023. 2021. 2018</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
	<note>Proceedings of the 35th International Conference on Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Elements of Causal Inference: Foundations and Learning Algorithms</title>
		<author>
			<persName><forename type="first">;</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<editor>
			<persName><forename type="first">Yash</forename><surname>Reizinger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Matthias</forename><surname>Sharma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernhard</forename><surname>Bethge</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ferenc</forename><surname>SchÃ¶lkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wieland</forename><surname>HuszÃ¡r</surname></persName>
		</editor>
		<editor>
			<persName><surname>Brendel</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2009">2009. 2009. 2017. 2017. 2023</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
	<note>Jacobian-based causal discovery with nonlinear ICA</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Weakly supervised disentangled generative causal representation learning</title>
		<author>
			<persName><surname>Scholkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.00607</idno>
	</analytic>
	<monogr>
		<title level="m">From statistical to causal learning</title>
		<imprint>
			<date type="published" when="2021-05">2021. May 2021. 2022. 2022. 2022</date>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="1" to="55" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Toward Causal Representation Learning</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robustly disentangled causal mechanisms: Validating deep representations for interventional robustness</title>
		<author>
			<persName><surname>Suter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.02582</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">Yash</forename><surname>KÃ¼gelgen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Luigi</forename><surname>Sharma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wieland</forename><surname>Gresele</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernhard</forename><surname>Brendel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michel</forename><surname>SchÃ¶lkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesco</forename><surname>Besserve</surname></persName>
		</editor>
		<editor>
			<persName><surname>Locatello</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Necati Cihan Camgoz</publisher>
			<date type="published" when="2019">2019. 2019. 2019. 2019. 2021. 2021. 2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Advances in Neural Information Processing Systems. Vowels et al., 2021. and Richard Bowden. D&apos;ya like dags? a survey on structure learning and causal discovery</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Causalvae: Disentangled representation learning via neural structural causal models</title>
		<author>
			<persName><forename type="first">Yang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018">2021. 2021. 2018</date>
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
