<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SAG-VAE: End-to-end Joint Inference of Data Representations and Feature Relations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-07-22">22 Jul 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">A</forename><surname>Preprint</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chen</forename><surname>Wang</surname></persName>
							<email>chen.wang.cs@rutgers.edu</email>
						</author>
						<author>
							<persName><forename type="first">Chengyuan</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vladimir</forename><surname>Ivanov</surname></persName>
							<email>vladimir.ivanov@rutgers.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University -New Brunswick Piscataway</orgName>
								<address>
									<postCode>08854</postCode>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University -New Brunswick Piscataway</orgName>
								<address>
									<postCode>08854</postCode>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Rutgers University Piscataway</orgName>
								<address>
									<postCode>08854</postCode>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SAG-VAE: End-to-end Joint Inference of Data Representations and Feature Relations</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-07-22">22 Jul 2020</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1911.11984v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ability to capture relations within data can provide the much needed inductive bias for robust and interpretable Machine Learning algorithms. Variational Autoencoder (VAE) is a promising candidate for such purpose thanks to their power in data representation inference, but its vanilla form and common variations cannot process feature relations. In this paper, inspired by recent advances in relational learning with graph neural networks, we propose the Self-Attention Graph Variational AutoEncoder (SAG-VAE) model which can simultaneously learn feature relations and data representations in an end-to-end manner. The SAG-VAE is trained by jointly inferring the posterior distribution of two types of latent variables, which respectively represent the data and the feature relations. The feature relations are represented as a graph structure, and the presence of each edge is determined by a Gumbel-Softmax distribution. The generative model is accordingly parameterized by a graph neural network with a special attention mechanism we introduced in the paper. Therefore, the SAG-VAE model can generate via graph convolution and be trained via backpropagation. Experiments based on graphs show that SAG-VAE is capable of approximately retrieving edges and links between vertices based entirely on feature observations. Furthermore, experiments on image data illustrate that the learned feature relations can provide the SAG-VAE robustness against perturbations in image reconstruction and sampling. The learned feature relations as graph adjacency matrices are observed to be structured, which provides intuitive interpretability of the models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In practice, data often comes with complex relations between features which are not explicitly visible, and extracting this structural information has been a crucial, yet challenging, task in the field of Machine Learning. Recently, renewed interest in relational and structure learning has been largely driven by the development of new end-to-end Neural Network and Deep Learning frameworks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>, with multiple promising results reported. This renewed drive in relational structure inference using Neural Networks can be partially attributed to current efforts to overcome the limited generalization capabilities of Deep Learning <ref type="bibr" target="#b3">[4]</ref>. More importantly, learning the relational structure with Neural Network models has several inherent advantages: strong and efficient parameterization ability of Deep Learning can Several experiments are carried out with multiple data sets of different kinds to test the performances. We observe in the experiments that SAG-VAE can learn organized latent structures for homogeneous image data, and the interpretation can match the nature of the certain type of image. Also, for graph data with known connections, SAG-VAE can retrieve a significant portion of the connections based entirely on feature observations. Based on these performances, we argue that SAG-VAE can serve as a general relational structure learning method from data. Furthermore, since SAG-VAE is a general framework compatible with most Variational Autoencoders, it is straightforward to combine advanced VAEs with SAG-VAE to create more powerful models.</p><p>The rest of the paper is arranged as follows: Section 2 conducts a literature review regarding methods related to the paper; Section 3 introduces the background and discuss the proposed SAG-VAE; Experimental results are shown in section 4, and the implications are discussed; And finally, section 5 gives a general conclusion of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early interest in learning latent feature relations and structures partly stems from questions over causality in different domains <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. Before the era of machine learning, methods in this field substantially relied on domain knowledge and statistical scores <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, and most of them work only on small-scale problems. The recent advancements in machine learning prompted the development of large-scale and trainable models on learning feature relations <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. However, most of the aforementioned methods are domain-specified and are usually not compatible with general-purpose data. Thus, these models are not quantitatively evaluated or compared in this paper.</p><p>Feature relational learning in Neural Networks can trace its history from sequential models. Recurrent Neural Network (RNN) and its variants like LSTM <ref type="bibr" target="#b19">[20]</ref> are the early examples of relational learning methods, although their aspect of 'feature relation' has been overwhelmed by their success in sequential modeling. After the emerge of Deep Learning, researchers in the domain of Natural Language Processing first built 'neural relational' models to exploit the relations between features <ref type="bibr" target="#b20">[21]</ref>. Recently, a variety of notable methods on neural relational learning, such as AIR <ref type="bibr" target="#b21">[22]</ref>, (N-)REM <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b2">3]</ref> and JK network <ref type="bibr" target="#b1">[2]</ref>, have achieved state-of-the-art performances by adopting explicit modeling of certain relations. However, although the models discussed above are powerful, most of them assume a known relational structure given by the data or experts, which means they do not have the ability in extracting feature relations.</p><p>More recently, the idea of leveraging graph neural networks to learn feature relations has grasped considerable interests <ref type="bibr" target="#b3">[4]</ref>. The graph neural network model was originally developed in the early 2000s <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b7">8]</ref>, and it has been intensively improved by a series of research efforts <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>. And finally, <ref type="bibr" target="#b8">[9]</ref> proposed the well-renowned Graph Convolutional Network (GCN) model which established the framework of modern graph neural networks. Graph neural networks are increasingly popular in the exploration and exploitation of feature relations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b28">29]</ref>, and there are several methods in this domain similar to the proposed SAG-VAE. For instance, <ref type="bibr" target="#b5">[6]</ref> embeds a graph neural network into the framework of Variational Autoencoders to learn the latent structure for dynamic models, and <ref type="bibr" target="#b29">[30]</ref> designs an iterative refining algorithm to extract the graph structure. Furthermore, <ref type="bibr" target="#b30">[31]</ref> proposed the Variational Graph Autoencoder (VGAE) that can reconstruct graph edges from feature observations and limited number of given edges. The VGAE model provides a strong baseline to evaluate graph edge retrieval. Apart from the graph neural networks, this paper is also closely related to Variational Autoencoders (VAEs) <ref type="bibr" target="#b10">[11]</ref> and the Gumbel-Softmax distribution <ref type="bibr" target="#b12">[13]</ref>. Among the numerous variations of the VAEs, <ref type="bibr" target="#b31">[32]</ref> devises an auto-encoding inference structure composed by a Graph Convolutional Network-based encoder and an inner product-based decoder, which can accomplish tasks similar to the SAG-VAE. Furthermore, <ref type="bibr" target="#b32">[33]</ref> elaborated on the idea to use VAEs to learn explicit graph structure. Gumbel-softmax was introduced by <ref type="bibr" target="#b12">[13]</ref> to provide a 'nearly-discrete' distribution compatible with reparametrization and backpropagation. Based on this technique, we can compute gradients for each edge, which is considered impossible with the categorical distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Graph Convolution Networks</head><p>We first introduce Graph Convolutional Networks following the framework of <ref type="bibr" target="#b8">[9]</ref>. A graph is denoted as G = (V , E), where V is the set of vertices and E is the set of edges. The vertices and their features are denoted by a n × d matrix, where n = |V | and d is number of features. A graph adjacency matrix A of size n × n is adopted to indicate the edge connections, and Â = A + I is used to introduce relevance for each vertex itself. A feed-forward layer is characterized by the following equation:</p><formula xml:id="formula_0">H (l+1) = f W (H (l) , A) = σ( D-1 2 Â D-1 2 H (l) W (l) ) = σ( ÃH (l) W (l) )<label>(1)</label></formula><p>where D is the diagonal matrix with Ds,s = t Âs,t , and</p><formula xml:id="formula_1">Ã = D-1 2 (A + I) D-1 2</formula><p>is the normalized adjacency matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Variational Autoencoders</head><p>Variational Autoencoders (VAEs) have been witnessed to be one of the most efficient approaches to infer latent representations of the data <ref type="bibr" target="#b10">[11]</ref>. Following the standard notation, we use p(•) to denote the real distribution and q(•) for the variational distribution. Therefore, the inference model q(Z|X) and the generative model p(X|Z) as:</p><formula xml:id="formula_2">q(Z|X) = m i=1 q φ (z i |x i ) p(X|Z) = m i=1 p θ (x i |z i ) (2)</formula><p>Where m stands for the amount of data. And under the Gaussian prior used in the original paper <ref type="bibr" target="#b10">[11]</ref>, the inference network will be:</p><formula xml:id="formula_3">q φ (z i |x i ) = N (z i |µ φ(xi) , diag(σ 2 φ(xi) ))<label>(3)</label></formula><p>and the optimization objective was given as the format of Evidence Lower Bound (ELBO):</p><formula xml:id="formula_4">log p(X) ≥ -L(θ, φ) =E Z∼q φ (Z|X) [log p θ (X|Z)] -D KL (q φ (Z|X)||p(Z))<label>(4)</label></formula><p>For conjugate priors like Gaussian, the KL-divergence can be computed analytically to avoid the noise in Monte-Carlo simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Gumbel-Softmax Distribution</head><p>To introduce feature relations as a graph structure, the most straightforward approach is to represent each edge connection as a Bernoulli random variable. Alas, there is no properly-defined gradients for discrete distributions like Bernoulli. Hence, to train the model in a backpropagation fashion, we must have some alternatives to the truly discrete distribution. Thanks to recent advances in Bayesian Deep Learning, we are able to utilize Gumbel-Softmax distribution <ref type="bibr" target="#b12">[13]</ref> to simulate Bernoulli/categorical distributions. A simplex-valued random variable a from a Gumbel-Softmax distribution is a k-length vector characterized by the follows:</p><formula xml:id="formula_5">a 1:k = exp((log(α k ) + G k )/τ ) K k=1 exp((log(α k ) + G k )/τ ) 1:k (5)</formula><p>where α k is proportional to the Bernoulli/categorical probability and G k is a noise from the Gumbel distribution.</p><p>The subscript 1 : k indicates a softmax vector, and τ is the temperature variable that control the 'sharpness' of the distribution. A higher τ will make the distribution closer to a uniform one, and a lower τ will lead to a more discrete-like distribution.</p><p>Notice that the above equation is not a density function: the density function for the Gumbel-Softmax distribution is complex, and we usually do not use it in practice. What is of our interest is that we can design neural networks to learn log(α k ) for each class (in the case of graph edge connection, the number of classes is 2 since we want to approximate Bernoulli), and although the output of the neural network is not necessarily valid distributions, we can apply the reparametrization trick and the transformation of equation 5 to get simplex-valued vectors. In this way, the neural network to learn log(α k ) (encoding network) can be trained by backpropagation since the gradients of equation 5 is well-defined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inference of SAG-VAE</head><p>Based on the above strategy, we introduce another latent variable A, which represents the distribution of the adjacency matrix of the graph. We only consider undirected graph in this paper, so the distribution an be factorized into p(A) = n s=1 n t=s+1 p(A s,t ). Following the doctrine of variational inference, we use the Gumbel-Softmax distribution to approximate the probability for each edge:</p><formula xml:id="formula_6">q φ (A s,t |X) = Gumbel-Softmax(φ 1 (A s,t |X))<label>(6)</label></formula><p>Notice that in equation 6 there is no index on X, which means the learned adjacency matrix is a shared structure (amortized inference) and should be averaging over the input. In practice, one can apply Gumbel-Softmax to each φ 1 (A s,s |X i ), and averaging over the probability:</p><formula xml:id="formula_7">q φ (A s,t |X) = 1 m m i=1 Gumbel-Softmax(φ 1 (A s,t |X i ))<label>(7)</label></formula><p>as this will make the estimation of the KL-divergence part more robust. We will discuss more on this issue further in the later paragraphs. Taking back the original Z variable, the joint posterior is p(Z, A|X). Figure <ref type="figure" target="#fig_0">1</ref> illustrates the difference between the vanilla VAE and the SAG-VAE. Observing from the graphical model of SAG-VAE, since A and Z are considered not PREPRINT d-separated, they are not necessarily independent given X. Nevertheless, to simplify computation, we perform the conditional independence approximation on the variational distributions:</p><formula xml:id="formula_8">p(Z, A|X) ≈ q φ1 (Z|X)q φ2 (A|X)<label>(8)</label></formula><p>Crucially, equation 8 allows the posterior distributions to be separated, and therefore avoids noisy and expensive Monte-Carlo simulation of the joint KL-divergence. With the similar derivation developed in <ref type="bibr" target="#b10">[11]</ref>, one can get the new ELBO of our model:</p><formula xml:id="formula_9">log p(X) ≥ -L(θ, φ 1 , φ 2 ) = E Z∼q φ 1 (Z|X),A∼q φ 2 (A|X) [log p θ (X|Z, A)] -D KL [q φ1 (Z|X)||p(Z)] -D KL [q φ2 (A|X)||p(A)]<label>(9)</label></formula><p>The posterior distribution of Z is characterized by a learned Gaussian distribution, and the prior p(Z) is standard Gaussian. We omit more complicated priors developed recently since our focus is not on powerful data representation. The posterior distribution of A is ccharacterized by the learned Gumbel-Softmax distribution, and the prior of A is a Bernoulli distribution with one-hot, uniform or specified values.</p><p>For SAG-VAE, we need the dimension of the hidden representation to be equal to the number of dimension (one can see the reason in section 3.3). Therefore, we propose two types of implementations. The first one is to apply a set of hidden distributions for each data point, as it is usually applied in ordinary VAEs; and the second one is to learn a distribution for each dimension. Noticeably, the latter scheme will lead to high-quality reconstruction results, albeit with the cost that the model becomes more vulnerable to noise/perturbations and sampling from the SAG-VAE becomes difficult. Nevertheless, the advantages of robustness and noise-resistance of SAG-VAE are more obvious with the second implementation.</p><p>Another issue to notice is the computation of the KL-divergence term D KL [q φ2 (A|X)||p(A)]. Notice that for the SAG-VAE with data point-wise representation, with the implementation based on equation 7, the KL divergence will become:</p><formula xml:id="formula_10">1 m m i=1 n 2 -n j=1 D KL (q φ2 (A j={s,t} |X i )||p(A j={s,t} ))</formula><p>This function is not properly normalized as the summation depends on n but there is no such parameter on the denominator. For the per-dimension version of SAG-VAE, although we do have an additional 1 n factor, this KLdivergence term can still be way too dominating as the summation is of O(n 2 ) terms. Thus, inspired by the idea in <ref type="bibr" target="#b33">[34]</ref>, we use a β A = 1 n 2 -n to normalize the KL-divergence term (β A D KL [q φ2 (A|X)||p(A)]) and improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Self-attention Graph Generative Network</head><p>The generative network of SAG-VAE is composed by a novel Self-attention Graph Neural Network model design in this paper. We can denote this in a short-handed notation:</p><formula xml:id="formula_11">p θ (X i |Z i , A) = SA-GNN θ (Z i , A)<label>(10)</label></formula><p>The Self-attention Graph Network follows the framework of <ref type="bibr" target="#b8">[9]</ref> for information aggregation. On the top of that, one significant difference is the introduction of the self-attention layer. The approach is similar to the mechanism in Selfattention GANs <ref type="bibr" target="#b34">[35]</ref>, but instead of performing global attention regardless of geometric information, the self-attention layer in our model is based on the neighbouring nodes. The reason for adopting such a paradigm in this model is that the node features and edge connections are learned instead of given. And if a global unconditional attention is performed, the errors on the initialization stage will be augmented.</p><p>Suppose feature H (l) is the output of the previous layer has the shape [n × d (l) ], where n and d (l) represent the number of dimensions (vertices) and graph features, respectively. Now for node i and any other node j ∈ N i (neighboring vertices), the relevance value e i,j is computed as follows:</p><formula xml:id="formula_12">e i,j = (H (l) i W l )(H (l) j W r ) T<label>(11)</label></formula><p>where W l and W r are the [d (l) × d] convolution matrices to transform the d-dimension features to d-dim attention features. Finally, having taken into consideration the graph edge connections as geometric information, we perform the PREPRINT softmax operation on the neighboring nodes of i (including itself). Formally, the attention value will be computed as:</p><formula xml:id="formula_13">α i,j = exp(e i,j ) j∈Ni∪{i} exp(e i,j ) , ∀j ∈ N i ∪ {i}<label>(12)</label></formula><p>In practice, the above operation can be done before normalization in parallel by multiplying the relevance information computed by equation 11 with the adjacency matrix. This attention mechanism is similar to Graph Attention Network (GAT) <ref type="bibr" target="#b30">[31]</ref>, with one main difference being that in GAT the relevance features are aggregated and multiplied by a learnable vector, while in SA-GNN the relevance features are directly processed by dot products. After computing α i,j for each pair and obtaining the matrix α, the attention result can be directly computed by matrix multiplication in the same manner of <ref type="bibr" target="#b34">[35]</ref>:</p><formula xml:id="formula_14">H(l) = [α(H (l) W g )]W f (<label>13</label></formula><formula xml:id="formula_15">)</formula><p>where</p><formula xml:id="formula_16">W g and W f are the [d (l) × d] and [ d × d (l)</formula><p>] transformation matrices, respectively. The main purpose of using the two matrix is to reduce computational cost.</p><p>To introduce more flexibility, we considered incorporating edge weights into the attention mechanism. The weights can be computed by the encoding matrix with a share structure of q φ2 (A) network. Formally, this can be expressed as:</p><formula xml:id="formula_17">V = φ2 (X)<label>(14)</label></formula><p>where φ2 (•) indicates a network shares the structure with φ 2 (•) except the last layer. Meanwhile, the main diagonal of V will be set to 1. Therefore, equation 12 can be revised into:</p><formula xml:id="formula_18">α i,j = exp(e i,j )V i,j j∈Ni∪{i} exp(e i,j )V i,j , ∀j ∈ N i ∪ {i}<label>(15)</label></formula><p>And in a similar idea to <ref type="bibr" target="#b34">[35]</ref>, the attention-based feature will be multiplied by a λ coeffcient originally set as 0 and added to the features updated by the rules in vanilla GCN:</p><formula xml:id="formula_19">H (l+1) = (λ H(l) + ÃH (l) )W (l)<label>(16)</label></formula><p>where W (l) is the convolution weights of the l-th layer. Based on the above equation, the network will first focus on learning the graph geometry (edges), and then using the attention mechanism to improve the generation quality.</p><p>One potential issue of training VAEs is the so-called 'posterior collapse', i.e., the posterior distribution becomes irrelevant from data when the decoder (generative model) is powerful. Graph neural networks are powerful models, so to make sure the posterior distributions are properly trained, we introduced the idea in <ref type="bibr" target="#b35">[36]</ref> to enforce correlation between the generated graph adjacency matrix and the output of each layer. Specifically, we use skip connection to interpolate the latent representation of data with the self-attention-processed information at each layer. This can be denoted as:</p><formula xml:id="formula_20">H (l+1) = σ(λ H(l) + ÃH (l) )W (l) + ÃH (1) Ŵ (l)<label>(17)</label></formula><p>where σ(•) is the non-linear activation, H (1) is the latent representation of the data (directly from Z), and</p><formula xml:id="formula_21">Ŵ (l)</formula><p>is the convolutional weight between the latent representation and the current layer. For the last layer, we apply activation after amalgamating the information:</p><formula xml:id="formula_22">H (L) = σ (λ H(L-1) + ÃH (L-1) )W (L) + ÃH (1) Ŵ (L)<label>(18)</label></formula><p>to keep the properties produced by certain activation (e.g. Sigmoid will produce results in [0, 1]). Finally, it is important to note that in the VAE framework, the latent variable Z does not naturally fit in the GCN framework where each node is treated as a feature vector. Thus, for the data point-wise distribution version of SAG-VAE, one needs to first transform the dimension into n with a fully-connected layer, and then add one dimension to get a [m × n × 1] tensor. In contrast, for the SAG-VAE with dimension-wise distributions, one can directly sample a [m × n × d] to operate on GCNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we demonstrate the performances of SAG-VAE on various tasks. Intuitively, by learning the graphstructured feature relations, SAG-VAE will have two advantages over ordinary VAEs and their existing variations: interpretable relations and insights between features and robustness against perturbations. To validate the correctness of the learned feature relations, one can apply SAG-VAE to the task of retrieving graph edges based on node feature observations. On the other hand, for the robustness of the SAG-VAE model, one can test the performance on tasks such as reconstruction with noise/mask and sampling with perturbations.</p><p>For the most of the experiments, the SAG-VAE models are implemented with dimension-wise distributions. The setup is picked for it the advantage of SAG-VAE is more significant with it. The data point-wise distribution counterpart of the SAG-VAE is also straightforward to implement, although the parameters are more difficult to tune.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Graph Connection Retrieval</head><p>We apply two types of feature observations based on graph data. For the first type, the features are generated by a 2-layer Graph Neural Network (GCN in <ref type="bibr" target="#b8">[9]</ref>) by propagating information between neighboring nodes; And for the second type, we pick graph data with given feature observations and randomly drop out rows and add Gaussian noises to obtain a collection of noisy data. Notice this task of retrieving graph edge from feature observations is considered as an interesting problem in the area of machine learning. To facilitate the training process, for the SAG-VAE model used for graph connection retrieval, we apply an 'informative' prior that adopts the edge density as the prior of Bernoulli distribution. This is a realistic assumption and the type of information is likely available for real-life problems. Thus, it does not affect the fairness of performance comparisons.</p><p>Results of experiments on two types of graph data illustrate that SAG-VAE can correctly retrieve a significant portion of links (satisfactory recall) while avoid generating overly redundant connections (satisfactory precision). For the first type of data, SAG-VAE can effectively generalize the reconstruction to an unseen pattern of positions. Also, by sampling from the hidden distributions, new patterns of positions can be observed. For the second type of data, SAG-VAE can outperform major existing methods. In addition, the inference of hidden representation is a unique advantage comparing to existing methods.</p><p>To show the performance advantages of SAG-VAE, the performances of SAG-VAE are compared with pairwise product and Variational Graph Autoencoder (VGAE) <ref type="bibr" target="#b31">[32]</ref>. The number of models for comparison is in small scale since there is only limited number of methods capable of inferring links based entirely on feature observations. The most naive model (pairwise product) is to directly compute the dot product between any pair of vertices, and use Sigmoid to produce the probability for a link to exist. This simple method serves as the baseline in the experiments of <ref type="bibr" target="#b31">[32]</ref>, although the features in the original experiments were calculated by DeepWalk <ref type="bibr" target="#b36">[37]</ref>. More advanced baselines are based on VGAE, which use part of the graph to learn representation and generalize the generation to the overall graph. The direct comparison between VGAE and SAG-VAE is to remove all edge connections and feed the graph data to VGAE with only 'self-loops' on each node. To further validate the superiority of SAG-VAE, we also demonstrate the performance of VGAE with 10% of edges preserved in the training input, and show that SAG-VAE can outperform VGAE even under this biased setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Karate Synthetic Data</head><p>We adopt Zachary's karate club graph to generate the first type of feature observations. In the implementation, each type of node (labeled in the original dataset) is parametrized by an individual Gaussian distribution, and 5 different weights are adopted to generate graphs with 5 patterns. During the training phase, only the first 4 types of graphs are provided to the network, and the final pattern is used to test if the trained SAG-VAE is able to generalize the prediction.</p><p>Figure <ref type="figure" target="#fig_2">2</ref> illustrates the reconstruction of 3 patterns of node positions based on the SAG-VAE with an individual Gaussian distribution on each dimension. From the figure, it can be observed that the SAG-VAE model can approximately correctly reconstruct the node positions, and while the patterns of links are not exactly the same as the original, the overall geometries are similar in terms of edge distributions. In addition, for the unseen pattern (the rightmost column), the model successfully infers the position and the key links of the graph.</p><p>Figure <ref type="figure" target="#fig_3">3</ref> shows the sampling results with both data point-and dimension-wise representation of SAG-VAE. From the figures, it can be observed that both versions of SAG-VAE can generate Karate data information in an organized manner. Sampling from the SAG-VAE with data-wise latent code can further restrict the patterns of the graph, while sampling from its dimension-wise counterpart appears to get a more organized distribution on the node level with different types of nodes better segmented.</p><p>Table <ref type="table" target="#tab_0">1</ref> illustrates the comparison of performance between different methods on the Karate-generated data. From the table it can be observed that SAG-VAE with both data-wise and dimension-wise implementations can outperform methods of comparisons. It is noticeable that for this graph generation task, adding 10% ground-truth links does not help significantly improve the F 1 score of VGAE. In contrast, simply applying pairwise product will lead to a better performance in this case.   Table <ref type="table" target="#tab_1">2</ref> illustrates the comparison of performance (F 1 scores) between different models on three benchmark graph data sets: Graph Protein <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>, Coil-rag <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref> and Enzymes <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b41">42]</ref>. All the 3 types of data come with rich node feature representation, and we obtain the training and testing data by selecting one sub-graph from the data and apply the second type of data generation (with random noise and row dropout). The extracted graph are of size 64, 6 and 18, respectively. Comparing to the Karate data used above, the graphs adopted here are significantly sparser</p><p>From Table <ref type="table" target="#tab_1">2</ref>, it can be observed that SAG-VAE can outperform methods adopted for comparison, especially for the VGAE-based results. For VGAE, the performance is poor for all datasets and adding back 10% links does not help remedy the situation. On the other hand, simply applying pairwise product yields in quite competitive performances. One possible reason behind this observation is that since the node features are highly noisy, it is very difficult for the VAE architecture to learn meaningful embedding of the nodes; on the other hand, since the feature representations are originally rich, pairwise product can capture sufficient information, and therefore leads to an unexpected good  As it is stated before, we expect SAG-VAE to have a more robust performance against perturbations because of the learned correlations between features can lead to a noise-resisting inductive bias. In this section, we test the robustness of SAG-VAE on two image datasets: MNIST and Fashion MNIST. The performances are evaluated based on 3 tasks: masked/corrupted reconstruction, noisy reconstruction, and noisy sampling. Intuitively, for the reconstruction tasks, if the reconstructed images from SAG-VAE are of higher qualities than those from plain VAE, the robustness of SAG-VAE will be corroborated. Moreover, the noisy sampling task will directly perturb some of the hidden representations, and the inductive bias in SAG-VAE will be able to overcome it. Finally, the plots of the adjacency matrices will show how well the model learned the structured relationships between features. While we may not have any metric to measure it, we can observe if the learned relations are structured and if they are consistent with the characteristics of the images.</p><p>In these experiments, we only implemented SAG-VAE with dimension-wise distributions. This type of model can produce reconstruction with higher qualities, but it is more vulnerable to perturbation. Therefore, testing with this type of implementation can better illustrate the advantages of SAG-VAE. A drawback of the dimension-wise distribution in sampling is that it makes the data representation harder to obtain, as there is no immediate low-dimension latent codes. Hence, to conduct the sampling process, we model the mean and variance of each pixel for data with different labels. We use Gaussian distribution:</p><formula xml:id="formula_23">µ ∼ N (µ µ , σ µ ) σ ∼ N (µ σ , σ σ )</formula><p>to approximately model the manifold and distributions of each dimensions. Notice that unlike graph data, for images, using dimension-wise distribution will bring high image variance. Therefore, it is not recommended to use this strategy in practice. We apply this paradigm here mainly for the purpose to illustrate the robustness of the SAG-VAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Noisy and Masked Reconstruction</head><p>Both MNIST and Fashion MNIST images are in the shape of 28 × 28. For the Fashion MNIST, to better leverage a common structure, we remove the image classes that are not shirt-like or pans-like since their geometries are significantly different from the rest of the dataset. To artificially introduce adversarial perturbation on images, two types of noises are applied: uniform noise and block-masking (corruption). For uniform noise-based perturbation, 200 pixels (150 for Fashion MNIST) are randomly selected and replaced with a number generated from uniform distribution U (0, 1). For masked-based perturbation, a block of 6 × 6 is added at random position on each image, thus a small portion of the digit or object in the image is unseen.</p><p>We firstly test SAG-VAE on MNIST data with perturbations. 10 reconstructed images with corresponding perturbed and original images are randomly selected and presented in figure <ref type="figure" target="#fig_4">4</ref> and figure <ref type="figure" target="#fig_5">5</ref>. On the same image, the performance of PREPRINT vanilla VAE is also illustrated. The vanilla VAE is implemented with fully connected layer for each dimension, which is equivalent to SAG-VAE with the adjacency matrix (links) to be zero for all but the main diagonal.  As one can observe, images reconstructed by vanilla VAE falsely learned the patterns of noise and blocks, as there is no inductive bias against such situation. On the other hand, for both tasks, SAG-VAE outperforms VAE significantly in terms of reconstruction quality. For the noisy perturbation, one can merely observe visible noise from the reconstruction result of SAG-VAE. And for the masked perturbation, although the reconstruction quality is not as strong, it can still be observed that the edges of blocks are smoothed and mask sizes are reduced adequately. Notice that the performance of SAG-VAE on the task with uniform noise is close to denoising autoencoder <ref type="bibr" target="#b42">[43]</ref>, yet we did not introduce any explicit denoising measure. The de-noising characteristics is introduced almost entirely by the inductive bias from the learned feature relations.</p><p>We further test the same tasks on Fashion MNIST, and the performances can be shown in figures 7 and 8. Again, we can observe from the figures that SAG-VAE significantly outperforms VAE when perturbation exists in the input data. It is noticeable that in Fashion MNIST reconstruction, SAG-VAE appears to be more resistant to block-masking, although the robustness against uniform noise is much more significant, similar to its performances on the MNIST dataset.</p><p>Figure <ref type="figure" target="#fig_6">6</ref> shows the loss (l 2 distance) between reconstructed images and the original and the noise-corrupted images respectively for the SAG-VAE on the Fashion MNIST data. The legends are removed in the interest of the clarity of plotting. It can be observed that the gap between reconstructed and original images declines aligned with training loss, while the loss between reconstructed images and noise images declines ends up with landing at a plateau on a high level. This indicates that the robustness of SAG-VAE will defy itself from learning the perturbation as information. Limited by the space, we did not include the figure for the training losses of vanilla VAE. In our experiments, we observe that for vanilla VAE, the reconstruction loss between the noisy image will continue to decrease while the loss between the real image will increase, indicating that plain VAE falsely fits the perturbation as information.</p><p>Finally, figure <ref type="figure" target="#fig_10">9</ref> shows the learned feature relations as adjacency matrices for both MNIST and Fashion MNIST. It can be observed that while it is not very straightforward to interpret the reason for each connection to exist, the graph PREPRINT structure is properly organized, and it can be reasonably argues that the robustness against perturbation comes from this organized structure.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Noisy Sampling</head><p>Following the method discussed in section 4.2, we fit the latent distribution of different MNIST digits/classes with the means and variances of each pixel. For each digit/class, we only pick one image to avoid the high image variance from the dimension-wise modeling. After getting the µ and σ for each digit, we sample 10 hidden representation z for each of the digits/classes, and randomly replace 200 dimensions with random noise before sending them to the decoder to generate images. Figure <ref type="figure" target="#fig_11">10</ref> illustrates the performance comparison between the SAG-VAE and the vanilla VAE on the above task.  From the figure, it can be observed that although both methods can preserve the general manifold of each digit, the SAG-VAE model outperforms vanilla VAE in terms of avoiding 'noise over digits', i.e., loss of the grain-like pattern. This can be explained by the graph convolution mechanism of the SAG-VAE, which can 'fill' the noise-corrupted pixel through exchanging information with connected pixels. And with a higher quality of image coherence, we can argue that the SAG-VAE model is shown to be more robust against noise perturbations during sampling. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose Self-Attention Graph Variaional AutoEncoder (SAG-VAE) based on recent advances on Variational Autoencoders and Graph Neural Networks. This novel model can jointly infer data representations and relations between features, which provides strong explainable results for the input datasets. In addition, by introducing the learned relations as inductive biases, the model demonstrates strong robustness against perturbations. Besides, a novel Self-Attention Graph Neural Network (SA-GNN) is proposed in the paper.</p><p>To conclude, this paper makes the following major contributions: firstly, it proposes a novel VAE-based framework which can jointly infer representations and feature relations in an end-to-end manner; secondly, it presents a novel Self-attention-based Graph Neural Network, which leverages the power of self-attention mechanism to improve the performance; and finally, it demonstrates advantageous performances on multiple experiments, which can be of great utility in practice.</p><p>In the future, the authors intend to extend the model to more advanced posterior approximation techniques (e.g. IWAE) and more flexible priors (e.g. normalized flow). Testing the performances of the model on more complicated datasets is another direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The model structure and graphical model of SAG-VAE.</figDesc><graphic coords="4,142.20,413.68,327.59,252.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>PREPRINT</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: SAG-VAE reconstruction of the position and link information of Zachary's karate club data. Top: Ground Truth; Middle: Position Reconstruction; Bottom: Position and Link Reconstruction. Notice that the pattern of the right-most column is not seen by SAG-VAE during the training phase.</figDesc><graphic coords="8,118.80,72.00,374.28,155.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Karate position sampling from SAG-VAE with two different implementations</figDesc><graphic coords="8,142.20,277.23,327.58,262.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Reconstruction comparison on noisy MNIST. Top: Noisy images; 2nd row: VAE Reconstruction; 3rd row: SAG-VAE Reconstruction; Bottom: Original images.</figDesc><graphic coords="10,130.50,108.23,351.00,134.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Reconstruction comparison on masked MNIST. Top: Masked images; 2nd row: VAE Reconstruction; 3rd row: SAG-VAE Reconstruction; Bottom: Original images.</figDesc><graphic coords="10,130.50,290.83,351.00,134.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Training Loss and Reconstruction Loss of Fashion MNIST.</figDesc><graphic coords="11,130.50,107.66,351.00,131.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Reconstruction comparison on noisy Fashion MNIST. Top: Noisy images; 2nd row: VAE Reconstruction; 3rd row: SAG-VAE Reconstruction; Bottom: Original images.</figDesc><graphic coords="11,142.20,281.49,327.60,125.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Reconstruction comparison on masked Fashion MNIST. Top: Masked images; 2nd row: VAE Reconstruction; 3rd row: SAG-VAE Reconstruction; Bottom: Original images.</figDesc><graphic coords="11,142.20,459.46,327.60,125.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>PREPRINT</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Adjacency Matrix Generated from MNIST and Fashion MNIST.</figDesc><graphic coords="12,142.20,72.00,327.60,146.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Noisy Sampling on MNIST images.</figDesc><graphic coords="12,142.20,329.90,327.61,165.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance comparison between SAG-VAE and other methods on Karate-generated data. The curse of noisy feature is resolved by applying SAG-VAE: with the merits of the joint inference of data representation and feature relations, the model can overcome the problem of noise under the VAE framework and lead to overall superior performances.</figDesc><table><row><cell>Method</cell><cell cols="3">Precision Recall F 1 score</cell></row><row><cell>Pairwise Product</cell><cell>0.139</cell><cell>0.985</cell><cell>0.243</cell></row><row><cell>VGAE (no input edge)</cell><cell>0.142</cell><cell>0.524</cell><cell>0.223</cell></row><row><cell>VGAE (10 % link)</cell><cell>0.150</cell><cell>0.539</cell><cell>0.234</cell></row><row><cell>SAG-VAE (data-wise)</cell><cell>0.616</cell><cell>0.558</cell><cell>0.586</cell></row><row><cell>SAG-VAE (dimension-wise)</cell><cell>0.558</cell><cell>0.611</cell><cell>0.583</cell></row><row><cell>performance.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison (F1 score only) between SAG-VAE and other methods on graph data with given node features.</figDesc><table><row><cell>Method</cell><cell cols="3">Protein Colirag Enzymes</cell></row><row><cell>Pairwise Product</cell><cell>0.367</cell><cell>0.714</cell><cell>0.410</cell></row><row><cell>VGAE (no input edge)</cell><cell>0.276</cell><cell>0.620</cell><cell>0.315</cell></row><row><cell>VGAE (10 % link)</cell><cell>0.283</cell><cell>0.643</cell><cell>0.319</cell></row><row><cell>SAG-VAE (dimension-wise)</cell><cell>0.385</cell><cell>0.800</cell><cell>0.423</cell></row><row><cell>4.2 Image Data: Robust Reconstruction and Sampling</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomohiro</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Ichi Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Relational neural expectation maximization: Unsupervised discovery of objects and their interactions</title>
		<author>
			<persName><forename type="first">Sjoerd</forename><surname>Van Steenkiste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Relational inductive biases, deep learning, and graph networks</title>
		<author>
			<persName><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Peter W Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causal effect inference with deep latent-variable models</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6446" to="6456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural relational inference for interacting systems</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph networks as learnable physics engines for inference and control</title>
		<author>
			<persName><forename type="first">Alvaro</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Merel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ah</forename><surname>Chung Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Investigating causal relations by econometric models and cross-spectral methods</title>
		<author>
			<persName><forename type="first">Clive Wj</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="424" to="438" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Causal reasoning in medicine: analysis of a protocol</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Kuipers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerome</forename><forename type="middle">P</forename><surname>Kassirer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="363" to="385" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Identification of synaptic interactions</title>
		<author>
			<persName><forename type="first">Hugh</forename><forename type="middle">L</forename><surname>David R Brillinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">P</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName><surname>Segundo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological cybernetics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="213" to="228" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Collective dynamics of &apos;small-world&apos;networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">H</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="issue">6684</biblScope>
			<biblScope unit="page">440</biblScope>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bayesian latent structure discovery from multi-neuron recordings</title>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Scott Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">W</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><surname>Pillow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2002" to="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glomo: unsupervised learning of transferable relational graphs</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="8950" to="8961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attend, infer, repeat: Fast scene understanding with generative models</title>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Sm Ali Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Theophane</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Szepesvari</surname></persName>
		</author>
		<author>
			<persName><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3225" to="3233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural expectation maximization</title>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sjoerd</forename><surname>Van Steenkiste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6691" to="6701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Supervised neural networks for the classification of structures</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sperduti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonina</forename><surname>Starita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="714" to="735" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 2005 IEEE International Joint Conference on Neural Networks</title>
		<meeting>2005 IEEE International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Nervenet: Learning structured policy with graph neural networks</title>
		<author>
			<persName><forename type="first">Tingwu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graphite: Iterative generative modeling of graphs</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Variational graph auto-encoders</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adversarially regularized graph autoencoder for graph embedding</title>
		<author>
			<persName><forename type="first">Ruiqi</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Generated loss and augmented training of mnist vae</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Chou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10937</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Self-attention generative adversarial networks</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Avoiding latent variable collapse with generative skip models</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Adji B Dieng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soon</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><surname>Schönauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Svn Vishwanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans-Peter</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Distinguishing enzyme structures from non-enzymes without alignments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Dobson</surname></persName>
		</author>
		<author>
			<persName><surname>Doig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of molecular biology</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="771" to="783" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Iam graph database repository for graph based pattern recognition and machine learning</title>
		<author>
			<persName><forename type="first">Kaspar</forename><surname>Riesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horst</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="287" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Columbia object image library</title>
		<author>
			<persName><surname>Sameer A Nene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Shree K Nayar</surname></persName>
		</author>
		<author>
			<persName><surname>Murase</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
	<note>coil-20</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">the enzyme database: updates and major new developments</title>
		<author>
			<persName><forename type="first">Ida</forename><surname>Schomburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antje</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Ebeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marion</forename><surname>Gremse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Heldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Huhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dietmar</forename><surname>Schomburg</surname></persName>
		</author>
		<author>
			<persName><surname>Brenda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>suppl 1):D431-D433</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
