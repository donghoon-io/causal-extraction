<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predictive learning as a network mechanism for extracting low-dimensional latent space representations</title>
				<funder ref="#_ptqThAX">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_DF88bwn">
					<orgName type="full">FRQNT</orgName>
				</funder>
				<funder>
					<orgName type="full">Greg Wayne (DeepMind, UK)</orgName>
				</funder>
				<funder ref="#_77YNG3E">
					<orgName type="full">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Stefano</forename><surname>Recanatesi</surname></persName>
							<email>stefanor@uw.edu</email>
							<idno type="ORCID">0000-0002-3576-9261</idno>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Neuroscience and Swartz Center for Theoretical Neuroscience</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><surname>Farrell</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Applied Mathematics</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guillaume</forename><surname>Lajoie</surname></persName>
							<idno type="ORCID">0000-0003-2730-7291</idno>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics and Statistics</orgName>
								<orgName type="institution">Université de Montréal</orgName>
								<address>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Mila-Quebec Artificial Intelligence Institute</orgName>
								<address>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sophie</forename><surname>Deneve</surname></persName>
							<affiliation key="aff4">
								<orgName type="laboratory">Group for Neural Theory</orgName>
								<orgName type="institution">Ecole Normal Superieur</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mattia</forename><surname>Rigotti</surname></persName>
							<idno type="ORCID">0000-0001-6466-2810</idno>
							<affiliation key="aff5">
								<orgName type="institution">IBM Research AI</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Shea-Brown</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Neuroscience and Swartz Center for Theoretical Neuroscience</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Applied Mathematics</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="institution">Allen Institute for Brain Science</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predictive learning as a network mechanism for extracting low-dimensional latent space representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1038/s41467-021-21696-1</idno>
					<note type="submission">Received: 12 July 2019; Accepted: 22 January 2021;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Artificial neural networks have recently achieved many successes in solving sequential processing and planning tasks. Their success is often ascribed to the emergence of the task's low-dimensional latent structure in the network activityi.e., in the learned neural representations. Here, we investigate the hypothesis that a means for generating representations with easily accessed low-dimensional latent structure, possibly reflecting an underlying semantic organization, is through learning to predict observations about the world. Specifically, we ask whether and when network mechanisms for sensory prediction coincide with those for extracting the underlying latent variables. Using a recurrent neural network model trained to predict a sequence of observations we show that network dynamics exhibit lowdimensional but nonlinearly transformed representations of sensory inputs that map the latent structure of the sensory environment. We quantify these results using nonlinear measures of intrinsic dimensionality and linear decodability of latent variables, and provide mathematical arguments for why such useful predictive representations emerge. We focus throughout on how our results can aid the analysis and interpretation of experimental data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N</head><p>eural network representations are often described as encoding latent information from a corpus of data <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> . Similarly, the brain forms representations to help it overcome a formidable challenge: to organize episodes, tasks, and behavior according to a priori unkown latent variables underlying the experienced sensory information. In this paper, motivated by the literature suggesting that these efficient representations are instrumental for the brain's ability to solve a variety of tasks <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref> , we ask: How does such an organization of information emerge?</p><p>In the context of artificial neural networks, two related bodies of work have shown that this can occur due to the process of prediction-giving rise to predictive representations. First, neural networks are able to extract latent semantic characteristics from linguistic corpora when trained to predict the context in which a given word appears <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> . The resulting neural representations of words (known as word embeddings) have emergent geometric properties that reflect the semantic meaning of the words they represent <ref type="bibr" target="#b14">15</ref> . Second, models learning to encode for future sensory information give rise to internal representations that encode task-related maps useful for goaldirected behavior <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> .</p><p>As predictive mechanisms have been conjectured to be implemented across distinct neural circuits <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref> , characterizing predictive representations can then shed light on where and how the brain exploits such mechanisms to organize sensory information. Our goal is to build theoretical and data-analytic tools that explain why a predictive learning process leads to lowdimensional maps of the latent structure of the underlying tasks -and what the general features of such maps in neural recordings might be. This links predictive learning in neural networks with existing mechanisms of extracting latent structure <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> and low-dimensional representations from data <ref type="bibr" target="#b24">25</ref> .</p><p>We begin with an introductory example of how predictive learning enables the extraction of latent variables characterizing the regularity of transitions among a set of discrete "states", each of which generates a different observation about the world. Then we focus on a model where observations are generated from continuous latent variables embedded in a low-dimensional manifold. We focus on the special case of spatial exploration, in which the latent variables are the position and orientation of an agent in the spatial environment, and the observations are highdimensional sensory inputs specific to a given position and orientation. The predictive learning task we study is to predict future observations. Our central question is whether a recurrent neural network (RNN) trained on this predictive learning task will extract representations of the underlying low-dimensional latent variables.</p><p>We develop analytical tools to reveal the low-dimensional structure of representations created by predictive learning. Crucial to this is the distinction between linear <ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref> and nonlinear dimensionality <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32</ref> , which allows us to uncover what we call latent space signal transfer, wherein latent variables become increasingly linearly decodable from the top principal components of the neural representation as learning progresses. Latent space signal transfer is accompanied by clear trends in the linear and nonlinear dimensionality of the underlying representation manifold, and potentially gives rise to the the formation of neurons with localized activations on the nonlinear manifold, manifold cells <ref type="bibr" target="#b32">33</ref> . Importantly, while each of these phenomena could separately find its origin in a mechanism different from predictive learning, they altogether provide a strong measurable feature of predictive learning that expect further testing in both neural and machine-learning experiments. We conclude by extending our framework to the analysis of both neural data and a second task-arm-reaching movements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Predictive learning and latent representations: a simple example. In predictive learning a neural network learns to minimize the errors between its output at the present time and a stream of future observations. This is a predictive framework in the temporal domain, where the prediction is along the time axis <ref type="bibr" target="#b19">20</ref> . At each time t an agent observes the state of a system o t and takes an action a t out of a set of possible actions. The agent is prompted to learn that, given (o t , a t ), it will next observe o t+1 .</p><p>We begin by illustrating our core idea-that predictive learning leads neural networks to represent the latent spaces underlying their inputs-in a simple setting. We study the task shown in Fig. <ref type="figure" target="#fig_0">1a</ref>, where the state of the system is in one of N s = 25 states. To each state is associated a unique set of five random cards that the agent observes whenever it is in that state. The states are organized on a two-dimensional lattice-the latent space. Observations have no dependence on the lattice structure, as they are randomly assigned to each state with statistics that are completely independent from one state to the next. On the other hand, actions are defined on the lattice: at each time t the agent either randomly moves to one out of the four neighboring states by selecting the corresponding action or remains in the same state. Movements, when they occur are thus along the four cardinal directions N, S, W, E used to indicate the corresponding action. Meanwhile, 0 denotes the action corresponding to no movement, for a total of N a = 5 possible actions.</p><p>The agent solves this predictive task when, prompted with a pair (o t , a t ), it correctly predicts the upcoming observation o t+1 . A priori, this task does not require the agent to extract information about the underlying lattice structure of the state space. Indeed the agent could solve the task with at least two possible strategies:</p><p>(1) by associating with each observation (set of cards) the next observation via a collection of N s × N a distinct relationships (o t , a t ) ↦ o t+1 (combinatorial solution), or (2) via a simple set of relationships that exploit the underlying lattice structure of the state space. In this second scenario the agent would uncover the lattice structure while using it to map actions to predictions. This solution thus presupposes an internal representation of the latent space and we refer to it as predictive representation solution. The critical difference between the combinatorial and predictive representation solutions is that the latter extracts a representation of the latent space while the former doesnot, cfr. Fig. <ref type="figure" target="#fig_0">1b</ref>.</p><p>We train a simple two-layer network on this card-game task: to predict the future observation given inputs of the current observation and action, Fig. <ref type="figure" target="#fig_0">1c</ref>. We focus on the first layer that receives the joint input of actions and observations. In this example observations are encoded with a one-hot representation, formally turning the problem into a classification task. Upon learning, by means of Stochastic Gradient Descent (SGD), the network develops an internal representation in the hidden layer for each of the 125 input pairs (o t , a t ).</p><p>Visualizing these internal representations in the space of principal components of neural activations, the underlying latent structure of the state space appears (Fig. <ref type="figure" target="#fig_0">1d</ref>.) This lattice-like structure is a joint representation of observations and actions. This representation emerges over the course of learning: initially, the representation of each observation-action pair (o t , a t ) does not reflect the underlying latent space, see Fig. <ref type="figure" target="#fig_0">1d</ref>. The development of the latent space representation can be clearly visualized across stages of the learning process (see Fig. <ref type="figure" target="#fig_0">S1</ref>).</p><p>Additionally, if we remove the actions from the input to the network but still training it to perform prediction, the network still learns a representation that partially reflects the latent space, Fig. <ref type="figure" target="#fig_0">1e</ref>, though this time it is distorted (cf. Fig. <ref type="figure" target="#fig_1">S2</ref>).</p><p>Below, we will demonstrate this phenomenon in other more complex settings, but we first pause to build intuition for why it occurs within neural networks. We start by noticing that upon learning the five actions a ∈ {N, S, W, E, θ} are mapped to a fixed vector w a , which is added to the state representation w s every time the corresponding action is selected:</p><formula xml:id="formula_0">x s;a ¼ tanhðw s þ w a þ bÞ ;<label>ð1Þ</label></formula><p>where b is a learned bias parameter. Specifically, consider the representation x in the network for predicting a state s 0 located immediately above (to the N) of the state s, in two scenarios. In the first, s 0 is arrived at from s, after the action a = N. This gives the representation</p><formula xml:id="formula_1">x s;N ¼ tanhðw s þ w N þ bÞ<label>ð2Þ</label></formula><p>In the second, s 0 is arrived at from s 0 , after the null action:</p><formula xml:id="formula_2">x s 0 ;0 ¼ tanhðw 0 þ w 0 þ bÞ<label>ð3Þ</label></formula><p>Both of these activations must be read out to return the same prediction: s 0 . While this could occur in principle if the readout operation learned to collapse different representations to the same readout, the network learns a simpler solution in which the representations (Eq. ( <ref type="formula" target="#formula_1">2</ref>)) and (Eq. ( <ref type="formula" target="#formula_2">3</ref>)) are equal (cf. <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35</ref> ), so that x s 0 ;0 ¼ x s;N implies:</p><formula xml:id="formula_3">w s 0 À w s ¼ w N À w 0<label>ð4Þ</label></formula><p>for any pair of states s; s 0 linked by the action a = N. This implies that (up to the hyperbolic tangent non-linearity), the representation of the states is acted upon by the action in a translational invariant way in the direction of the action w N -w 0 . This is true for any of the actions N, S, W, E, and for any starting state s. Thus, the representation inherits an approximate translation invariance-the characteristic property of a lattice structure. This invariance confers a geometrical structure upon the learned neural representation that reflects the latent space. This phenomenon directly generalizes to lattices of higher dimension, as shown in Fig. <ref type="figure" target="#fig_0">1f</ref>. We note that this analysis holds precisely when the learning process enforces representations of the same decoded state to be nearly identical-which occurs in all of our simulations and is predicted by other numerical and theoretical studies <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35</ref> -and holds approximately when it tends to cluster these together. By contrast, in a general combinatorial solution of Eq. ( <ref type="formula" target="#formula_3">4</ref>) each observation action pair could be linked to the upcoming state independently, x s;N ≠x s 0 ;0 .</p><p>We can apply related ideas to begin to understand more challenging case in which the prediction task is performed without knowledge of the action, so that only observations are passed as input to the network. As we showed in figure (Fig. <ref type="figure" target="#fig_0">1e</ref>) above, in this case the internal representation still partially reflects the latent space. This is not because the set of observations as a whole carries any information about the latent space, but because the effect of the actions-to bind nearby states together-is reflected in the statistics of the sequence of observations. Thus, through making predictions about future observations, the network still learns to bind states that occur nearby in time together, extracting the latent space (cf. Suppl. Mat. Sec. 2.4).</p><p>We next generalize the predictive learning framework to two different, more complex benchmark tasks of neuroscientific interest: spatial exploration and arm-reaching movements.</p><p>Predictive learning extracts latent space representations in a spatial exploration task. We focus on predictive learning in a spatial exploration task in order to generalize the previous example to show how predictive learning extracts the lowdimensional latent structure from a high-dimensional sensory stream (Fig. <ref type="figure" target="#fig_1">2a</ref>) and to introduce novel metrics, which quantify such process.</p><p>In the spatial exploration task an agent traverses a square open arena. Traversing the environment, the actions taken determine a trajectory in three spaces: the latent space, which defines the agent's (or animal's) state in the environment, the observation space of the agent's sensory experience, and the neural activation space of its neural representation. We introduce the task defining these three spaces.</p><p>The latent space, similarly to the card-game example, is the set of spatial coordinates that identifies the agent's state, (x, y, θ), The diagram highlights the layer studied here, although the network has a two layers, where the second layer serves as a decoder. d The network's neural representation: activity in the hidden layer plotted vs. principal components PCs 1 and 2 of hidden layer activity. For each observation-action pair (o t , a t ), the corresponding activation is colored by the position of the state that the network predicts: x-coordinate (left plot, before and after learning) and y-coordinate (right plot). e Same as panel d in the absence of the action as a input to the network. f Same as panel d for a three-dimensional latent space.</p><p>where x and y are position and θ is its direction. The observation space is defined in terms of the agent's ability to sense the surrounding environment. To model this we consider the case where the agent senses both visual and distal information from the environment's walls-the agent is equipped with sensors that span a 90 o visual cone centered on its current direction θ reporting distance and color of the environment's wall along their directions, Fig. <ref type="figure" target="#fig_1">2b</ref>. The environment the agent navigates is a discrete grid of 64 × 64 locations. Each wall tile, one at each wall location, is first colored randomly and then a narrow spatial autocorrelation is applied, see Fig. <ref type="figure" target="#fig_1">2b</ref>. The number of sensors N s is chosen so that observations across sensors are independent N s = 5.</p><p>We consider the case where the agent's actions are correlated in time but do not depend on the observations-random exploration. At each step the agent's direction θ is updated by a small random angle dθ drawn from a Gaussian distribution centered at zero and with a variance of 30 o . The agent then moves to the discrete grid location most aligned with the updated direction θ + dθ (unless it is occupied by a wall; cfr. Methods for details). Actions are performed by the agent with respect to its allocentric framework, so that there are nine possible choices: for each location there are eight neighboring ones plus the possibility of remaining in the same location. While the agent moves in the environment it collects a stream of observations.</p><p>In predictive learning, the agent learns to predict the upcoming sensory observation, Fig. <ref type="figure" target="#fig_1">2c</ref>. It achieves this by minimizing the difference between its prediction y t at time t and the upcoming observation o t+1 : C = ∑ t ||y to t+1 || 2 , Fig. <ref type="figure" target="#fig_1">2d</ref>. We refer to the activations of the units of the trained RNN as its internal predictive representation. The RNN can be thought as a model of the agent's brain area carrying out the task. As the agent learns to predict the next observation, its representation is influenced both by the observation space (since the task is defined purely in terms of observations) and by the latent space (since the actions are defined on it); a priori, it is not obvious which space's influence will be stronger. In this example, we used a more general recurrent network rather than the simplest-possible feedforward setup in the first example of Fig. <ref type="figure" target="#fig_0">1</ref>; this allows information from the stream of sensory observations to be integrated over time, a feature especially important in more challenging settings when instantaneous sensory information may be only partially informative of the current state.</p><p>A first indication that, by the end of learning, neurons encode the latent space is given by the fact that individual neurons develop spatial tuning Fig. <ref type="figure" target="#fig_1">2e</ref>. The neural representation has extracted information about the latent space from the observations, without any explicit prompt to do so. In the Suppl. Mat. (Figs. S7-S12), we show how this phenomenon is robust to alterations of the sensory observations and network architecture.</p><p>However, when the same network learns, based on the same input sequence, to reproduce the current observation (autoencoding framework corresponding to a cost C = ∑ t ||y to t || 2 ) rather than predict the upcoming one, individual neurons do not appear to develop spatial tuning, Fig. <ref type="figure" target="#fig_1">2f</ref> and Suppl. Mat. (Figs. <ref type="figure" target="#fig_0">S10-11</ref>).</p><p>Metrics for predictive learning and latent representations. How -and to what extent-does the neural population as a whole represent the latent space? This question demands quantitative answers. To this end we develop novel methods for analyzing neural representation manifolds, and three metrics that capture the dynamical and geometrical properties of the representation manifold. These are predictive error, latent signal transfer and dimensionality gain. While the first of these is specific to predictive frameworks, the other two could be interpreted as general metrics to quantify the process of extraction of a low-dimensional latent space from data. Below we illustrate these metrics in the context of the spatial exploration task (cf. Figs. S3-5 for a detailed analysis and more examples of such metrics). Predictive error. The network's task is to predict future observations. Owing to correlations in the sensory input itself from one timestep to the next, to verify that the network is actually making predictions we first ask whether the network's output is most similar to the upcoming observation rather than current or previous ones <ref type="bibr" target="#b35">36</ref> . This can be captured by the absolute difference between the current output of the network and the stream of observations at any time, which we refer to as predictive error. If this is skewed towards the upcoming observation (see Fig. <ref type="figure" target="#fig_2">3a</ref> blue line), it suggests that the network predicts elements of upcoming observations. This measure relies on knowledge of the network's output and of the stream of observations. An allied measure of this effect relies on the ability to decode past vs. future latent states from the current neural representation. If the decoding error is skewed for future (vs. past) latent states, this also suggests that the network predicts future states. Figure <ref type="figure" target="#fig_2">3b</ref> shows that this is the case for the spatial exploration network: it codes for future latent variables as well as current and past ones, with the axis of symmetry for decoding the spatial coordinates x, y located close to the future value Δt = 1 (cf. Fig. <ref type="figure" target="#fig_2">S13</ref> for a comparison with neural data). Similarly the axis of symmetry for the angle θ is located closer to Δt = 1, although in this case the analysis is confounded by the fact that actions carry partial information regarding θ.</p><p>Latent signal transfer. We next introduce a feature of predictive learning that tracks how the neural representation reflects the latent space over the course of learning. This quantifies the phenomenon visible by eye in the introductory example of Fig. <ref type="figure" target="#fig_0">1d</ref>. To define the latent signal transfer metric, at each stage of learning we compute the average of the canonical correlation (CC) coefficients between the representation projected into its PCs, and latent space variables x, y, θ. The blue line in Fig. <ref type="figure" target="#fig_2">3c</ref> shows the average of the CC coefficients between the representation in PCs 1 to 3 and the position x, y of the agent in latent space. When the average CC coefficient is 1, all the signal regarding x, y has been transferred onto PCs 1 to 3 in a linear fashion. A similar interpretation holds for the other curves: in sum, they track the formation of explicit representations of latent variables that are accessible via linear decoding .</p><p>Figure <ref type="figure" target="#fig_2">3c</ref> shows that, between epoch 50 and 150, most of the information regarding the latent space moves onto the first few PC modes of the neural representation. The same analysis can be carried out with respect to observation space variables. This is shown in Fig. <ref type="figure" target="#fig_2">3d</ref>, where the decreasing trend indicates that the observation space signal flows out of the first few PC components as learning progresses. Altogether Fig. <ref type="figure" target="#fig_2">3c,</ref><ref type="figure">d</ref> show that the representation, as interpreted through PC components, encodes more information about the latent space as opposed to the observation space as learning progresses (blue and red lines).</p><p>Dimensionality gain. Finally, motivated by the fact that the latent spaces of interest are lower-dimensional, we introduce metrics that allow us to quantify the extent to which the learned neural representations have a similar dimension.</p><p>We begin by noting that the latent signal transfer analysis (Fig. <ref type="figure" target="#fig_2">3c,</ref><ref type="figure">d</ref>) suggests that predictive learning might have formed a low-D neural representation. However, when we measure the dimensionality of the neural representation with a linear dimensionality metric, the participation ratio (PR), we observe that dimensionality actually increases over the course of learning Fig. <ref type="figure" target="#fig_2">3e</ref>. Instead, measuring the dimensionality of the neural representaion with nonlinear techniques sensitive to the local curvature of the representation manifold-yielding the intrinsic dimensionality (ID)-shows that the dimensionality rather than increasing at most decreases through learning.</p><p>This dichotomy can be interpreted by means of two different demands that shape network representations. On one hand, the representation is prompted to encode high-dimensional observations; on the other, it extracts the regularity of a low-dimensional latent space. While the high dimensionality of the observations is a global property, referring to the collection of many observations, the regularity of the latent space is induced on a local scale, as neural representations relate to their possible neighbors via the action. These demands lead the linear dimensionality PR, measuring a global property of the representation manifold, and the nonlinear dimensionality ID, measuring more local properties, to have opposite trends. This interpretation is supported by further experiments and the next example we study, that arm-reaching movements, in which the network is prompted to predict a lower-dimensional observation signal. To encapsulate this phenomenon we suggest the metric of dimensionality gain (DG), which is the ratio between the linear global dimensionality and the nonlinear local dimensionality of the representation manifold. Higher values of DG thus capture the network's ability to extract a low-dimensional representation of a high-dimensional stream of observations. In the example of Fig. <ref type="figure" target="#fig_2">3e</ref>, f, DG ≈ 3.5 upon learning.</p><p>The role of prediction in extracting latent representations. To show how the three metrics just described characterize predictive learning, we compare representations learned in the same networks but without the demand for prediction (as in Fig. <ref type="figure" target="#fig_1">2f</ref>). In Fig. <ref type="figure">4</ref> we show how predictive error, latent signal transfer and dimensionality properties of the network differ in these two cases. The comparison is carried out by training 50 different networks of smaller size (100 neurons) on either the predictive task or a non-predictive version in which the network outputs observations received on the current timestep. In sum, comparing each of the metrics introduced above for the predictive vs. non-protective cases shows that, while predictive learning extracts a lowdimensional manifold encoding for the latent variables, nonpredictive learning in these networks does not.</p><p>One point here bears further discussion. While Fig. <ref type="figure">4e</ref> shows that ID is lower in the predictive vs. non-predictive case, this may seem surprising because there are grounds to expect that ID would be equal in these cases. These grounds are that the observations are produced as a map from a low-dimensional latent space in both cases, so that if the network directly encodes them, it should admit a similar low-dimensional parametrization and hence similar ID in both cases as well. The resolution comes from the fact that ID, despite being a local measure, is based on statistical properties of points sampled from a manifold (cf. "Methods"). So if the manifold appears higher dimensional, despite having a parametrization, which is low-dimensional, then ID would point to a higher dimension. In other terms ID is sensitive to the manifold's smoothness and can be taken as a measure of it for manifolds parameterized by a fixed number of variables. This problem is known in the literature as multiscaling and different ID measures are more or less robust to it <ref type="bibr" target="#b30">31</ref> .</p><p>Finally we note that, in Suppl. Mat. Figs. S7-12, we describe a series of 12 other control networks that show how results on the role of prediction are robust against a number of factors such as noise. These results show that predictive models outperform nonpredictive models in the encoding of latent variables, at least when such encoding is probed by means of linear measures (cf. Fig. <ref type="figure">S7</ref>).</p><p>Visualizing the structure of learned neural population manifolds: signal transfer and neural manifold cells. The metrics just introduced capture properties of the neural representation at the population level via useful numbers that can be plotted over the course of learning. Here, we pause to visualize the underlying population representations in two complementary ways.</p><p>The first visualization is directly related to the metric of latent space signal transfer. In Fig. <ref type="figure" target="#fig_3">5a</ref> the neural representation projected into the space of its first three PCs, colored according to each of the three latent variables x, y, and θ. Each point in these plots corresponds to the neural representation at a specific moment in time, and the color of the point is determined by the position or orientation of the agent in the latent environment at that moment. This shows visually that, after learning, the agent's location x, y is systematically encoded in the first three PCs, while PCs four and five encode the agent's orientation θ, Fig. <ref type="figure" target="#fig_3">5b</ref>. This corresponds to the high values of latent space signal transfer seen at the end of learning in Fig. <ref type="figure" target="#fig_2">3c</ref>. We next turn to visualize whether the observation variables are similarly encoded in the network representation. Figure <ref type="figure" target="#fig_3">5c</ref> shows that, while the first three PCs do encode distance, they do not appear to encode the sensoraveraged color in any of the three RGB (red, green, blue) channels. Intriguingly, this is a consequence of learning: average color information is encoded in the first PCs in the beginning of learning as suggested by the signal transfer measure (cfr. Fig. <ref type="figure" target="#fig_2">3c</ref>), but less in the end of it. Taken together, the visualizations in Fig. <ref type="figure" target="#fig_3">5a,</ref><ref type="figure">b</ref> support the conclusion from the signal transfer metrics that the network allocates most of its internal variability to the encoding of latent variables.</p><p>These visualizations of population level neural coding, as well as plots of single neuron tuning as in Fig. <ref type="figure" target="#fig_1">2e</ref>, require foreign knowledge of the latent space variables. However, in many settings, neither the values or nature of these variables maybe known in advance. How can we proceed in these cases? We now introduce a second strategy for visualizing neural activity, via an emerging concept that we refer to as neural manifold cells <ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37</ref> .</p><p>Figure <ref type="figure" target="#fig_3">5d</ref> shows the activity of the same 100 neurons in Fig. <ref type="figure" target="#fig_1">2e</ref> averaged over "locations" in the space spanned by the first two PCs of the neural population activity itself. This shows tuning of individual neurons, but not with respect to motor, stimulus, or environmental variables as is typically studied-but rather with respect to population level neural activity. The approach reveals a similarity between the well known phenomenon of place cells tuned to a location in the environment and neural manifold cells tuned to a "location" on the principal components of their neural population manifold (we make this relationship made more explicit in the context of hippocampal data in Fig. <ref type="figure" target="#fig_2">S13</ref>). Overall, this shows that receptive fields localized not just in the latent, but also in the principle component, spaces can arise naturally through predictive learning.</p><p>Predictive learning extracts latent representations of armreaching movements. While the spatial exploration task studied above is a useful proving ground, given the clear role played by latent spatial variables, we wished to illustrate the broader scope of the effects of predictive learning. Thus, we next apply this framework to a different task, that of predicting arm-reaching movements. We model arm movements as a dynamical system with forward and inverse kinematics according to the mitrovic model <ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39</ref> . In this model, movements in the 2d sagittal plane of the upper right limb are modeled as a function of six muscles, Fig. <ref type="figure" target="#fig_4">6a</ref>. The muscles control, by means of dynamical equations, two angles: the angle in between the upperarm and the line of the shoulders, and the angle in between the forearm and upperarm. The position of the elbow and wrist is then a nonlinear trigonometric function of these angles and of the lengths of the upperarm and forearm.</p><p>We cast this system into predictive learning by generating randomly correlated binary input pulses, which signal the contraction of one of the six muscles through the forward kinematics equations, resulting in exploratory movements of the arm.</p><p>We train the predictive recurrent network to predict future (x,y) locations of both the elbow and the wrist given their current locations and the input to the six muscles. This replicates the spatial exploration task description in terms of observations and actions, where observations are in this case thought to be the current locations of the elbow and wrist with respect to the shoulder Fig. <ref type="figure" target="#fig_4">6b</ref> and actions are muscular contraction signals.</p><p>Upon learning, the network successfully predicts future observations and extracts in its neural representation the values of the underlying latent variables that ultimately regulate the movements: the two angles, see Fig. <ref type="figure" target="#fig_4">6c,</ref><ref type="figure">e</ref>. Owing to the low dimensionality of the observations compared with the spatial exploration task, and the fact that they are partially colinear with the latent variables, latent space signal transfer increases over the course of learning as before, but observation space signal transfer does not decay.</p><p>For the same reason, the linear dimensionality (PR), as it increases through learning, achieves a lower final value. The latent variable extraction is accompanied by the localization of neural activations on the neural population manifold and on the latent space as shown in Fig. <ref type="figure" target="#fig_4">6f</ref>, g replicating the results shown for the spatial exploration task. Furthermore, we analyzed neural recordings in the primary motor cortex <ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41</ref> during a motor task, as an example of how our analysis of representations of armreaching movements could inform future data analyses and experiments, cf. Fig. <ref type="figure" target="#fig_0">S14</ref>.</p><p>Network mechanisms that create low-D representations through prediction. In our introductory example of the cardgame, we gave some mathematical reasoning for how simple Fig. <ref type="figure">4</ref> Comparison between predictive and non-predictive learning. We train 50 networks of 100 neurons in each of the predictive and non-predictive conditions and equalize the learning axis between the two to highlight the trends of the different measures. a Predictive error. The position of the predictive error symmetry axis plotted throughout learning for the predictive and non-predictive network ensembles. The symmetry axis position is the one that minimizes a L2 norm between the predictive error curve (cf. Fig. <ref type="figure" target="#fig_2">3a</ref>) and its reflection through the symmetry axis. b Latent signal transfer analysis. A canonical correlation analysis is performed between the latent space and the top PCs of the neural representation at every epoch, and the average of the two canonical correlations (for coordinates x and y) is shown. c Observation signal transfer analysis. The canonical correlation analysis, same as panel b, is performed between the top PCs of the observations and the top PCs of the network's representation. d Linear dimensionality (PR) throughout learning. e Non-linear dimensionality (ID) throughout learning. f Dimensionality gain (DG) throughout learning.</p><p>feedforward networks trained to predict their future inputs (observations) can extract the structure of the latent space underlying those observations. Here, we formalize this idea and extend it to recurrent networks, as used for the more general spatial and motor exploration settings studied above. Here, the RNN is governed by the equations:</p><formula xml:id="formula_4">r t ¼ g Wr tÀ1 þ W o o t þ W a a t À Á y t ¼ g W out r t À Á<label>ð5Þ</label></formula><p>where W, W o , W a , W out are the weight matrices and y is the output exploited to minimize the predictive cost C pred ¼ P t jy t À o tþ1 j 2 . Following the same logic as for the card-game task, we consider two independent network updates, denoted by A and B respectively, which lead up to the same observation o t+1 , read out from identical representations r A t ¼ r B t . Again, up to nonlinear corrections, this gives the condition:</p><formula xml:id="formula_5">r A tÀ1 À r B tÀ1 ¼ W À1 W o ðo A t À o B t Þ þ W a ða A t À a B t Þ À Á<label>ð6Þ</label></formula><p>which is an analogous to Eq. ( <ref type="formula" target="#formula_3">4</ref>). From here, we consider two different scenarios.</p><p>In the first, the action term dominates. This gives an identical case to the one already analyzed in the introductory section Eq. ( <ref type="formula" target="#formula_3">4</ref>): the action acts on the neural representation in a translationally invariant way. As before, this results in representations corresponding to different observations being translated with respect to one another similarly to how the action translates among them in the underlying latent space. For the spatial exploration task this corresponds to the product of a two-dimensional lattice and a circle (angle); for the arm-reaching task this corresponds to the product of two angles.</p><p>In the second scenario, the observation term dominates. Observations at the current time define a set of possible observations at the next timestep, those related to the current observation via one of the possible actions from the current point in the latent space. Extending the reasoning above suggests that representations r A and r B of latent states A and B should be similar according to the overlap in this set of possible nexttimestep observations. This again suggests that the structure of latent space will be inherited by representations, as it is only states that are related by one action that can map to the same nexttimestep observation. This is indeed what we find: Fig. <ref type="figure" target="#fig_0">1e</ref> and Figs. S7-10 (case without actions) show how the latent space emerges in neural representations in predictive networks even in the absence of action inputs. However, the Supplemental Sec. S1.2 does show that these representations carry latent information in a less regular way when actions are not provided to the networks.</p><p>Taken together, these results show that the network's representation is shaped by the latent space by means of learning to predict future inputs. This connects to novel approached that have recently led to important progress in the theory of deep learning <ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref> by applying group theory to analyze neural networks <ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46</ref> . Through this emerging perspective predictive networks, when prompted with the current observation of the state of a system (o) can be analyzed as if they were asked to output the transformed observation upon applying the action of a group element g a : o ↦ g a (o). In our setup we use the generators of the group instead of all possible group elements. As the network ). The activity of each neuron (one per quadrant) is averaged as the population activity is in a specific "location'' on the neural manifold in the space spanned by PCs 1 and 2.</p><p>learns to apply group actions g a to its representation, it transforms, through its layers, the given observation o into a neural representation onto which the action acts as a group element.</p><p>At this stage the network's representation inherits the geometry of what is called the group's representation. For example, in the spatial exploration example, the states in which the agent can be found are defined by the Special Euclidean group of rotations and translations in two dimensions SE (2). In our framework the actions of the agent correspond to the group generators for translations-reflecting minimal translational movements of the agent (the angle, corresponding to the rotation degree, is not directly provided). Thus, the action passed to the network is formally the one relative to the translation subgroup, and it is provided in vectorial form. As these group generators act as vectorial translations on the neural representations, a definite geometry is inherited by the network representation: the translation subgroup of SE( <ref type="formula" target="#formula_1">2</ref>) is encoded as a two-dimensional lattice <ref type="bibr" target="#b46">47</ref> . This is a more general way to arrive at the conclusions of the direct calculations taken above.</p><p>The analysis above shows how the structure of the latent space shapes the structure of neural representations. This structure can be clearly visualized in many of the plots presented above. Moreover, it is reflected in the metrics we introduce in at least two ways. First, we expect that states being represented in a transitionally invariant way will lead to the ability to decode states from neural representations; how this plays out for the principal components of neural activity that are used for plotting neural activity above and for the metric of latent space signal transfer is described using results from the linear algebra of Toeplitz matrices in Supplemental Secs. S2.1-2.3. Second, states being represented in a transitionally invariant way leads to an approximate parameterization of neural activity via terms of the latent space, corresponding to the lower values of intrinsic dimensionality also measured above.</p><p>By contrast, as an autoencoder does not compute the action of a group element on its input, is not generally expected to build a representation with structure induced by that group. Nonetheless a group theoretic approach to autoencoders still enables insights into why autoencoders develop activations reminiscent of receptive fields <ref type="bibr" target="#b47">48</ref> . In the Suppl. Mat. Sec. 2.5 we provide further considerations on the locality of receptive fields mainly inspired by ref. <ref type="bibr" target="#b36">37</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>How the brain extracts information about the latent structures of the external world, given only its sensory observations, is a longstanding question. Here, we show that the computation of predicting future inputs can contribute to this process, giving rise to to low-dimensional neural representation of the underlying latent spaces in artificial neural networks. We demonstrate this phenomenon in a sequence of gradually more complex simulations and by providing basic mathematical arguments that indicate its generality.</p><p>What features of neural responses, or representations, characterize predictive learning? When the observations to be predicted arise from an environment with an underlying lowdimensional latent structure, e.g., in the case of spatial exploration or arm-reaching movements, our work suggests several distinct features. First, the predictive error shows that neural representations are biased towards encoding upcoming observations or latent variables. Second the latent structure underlying the observations is transferred onto the representation progressively through learning (Latent Signal Transfer, cf. Fig. <ref type="figure" target="#fig_3">5</ref>). Finally, the dimensionality of the set of neural responses will likely appear high when assessed with standard linear measures, such as participation ratio <ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29</ref> . However, when assessed through nonlinear metrics sensitive to the dimensionality of curved manifolds, the dimensionality will be lower, in the ideal case tending to the number of independent latent variables.</p><p>This last feature is the result of neural responses being strongly tuned to the variables, which parameterize the neural representation manifold (cfr. Fig. <ref type="figure" target="#fig_3">5d</ref>). An established example of such strong coding is the locality of neural receptive fields in latent space (e.g., place fields). Here, we observe an allied phenomenon, that of manifold cells with local receptive fields on the manifold of population-wide neural responses. This is a feature that can be explored in artificial network studies of complex data, or in experimental settings (cf. proof-of-concept data analysis in Suppl. Mat. Fig. <ref type="figure" target="#fig_2">S13</ref>) where the underlying latent variables do not need to be known in advance. This feature connects to recent work on understanding neuronal representations through the lens of dimensionality <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b48">49</ref> . Overall, these features provide a quantitative framework to compare representations across conditions that can be applied both in machine learning (e.g., to compare learning schemes and overall mechanisms of extracting latent signals from data) and in brain circuits (e.g., to compare coding in distinct brain areas).</p><p>Our findings should not be taken as a theory of a specific area rather as a formulation of a general connection between predictive coding and the extraction of latent information from sensory data. For example, our model falls short in explaining mechanistically key elements of spatial maps individuated in hippocampal recordings, such as the emergence of place cells and their relation to direction or grid cells. However, it does suggest that predictive learning is a mechanism that enables the binding of sensory information beyond spatial exploration and towards the more general notion of semantically related episodes. While traditionally distinct theories of hippocampus involve declarative memory <ref type="bibr" target="#b49">50</ref> ) and spatial exploration <ref type="bibr" target="#b50">51</ref> , considerable effort has been devoted to reconciling these apparently contrasting views <ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref> . In particular, Eichenbaum <ref type="bibr" target="#b53">54</ref> proposed that the hippocampus supports a semantic relational network that organizes related episodes to subserve sequential planning <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b55">56</ref> . Here, we posit that prediction-with its ability to extract latent information-may serve as such a mechanism to generate semantic relational networks. In particular, we speculate that relevant semantic relations are encoded by neural representations of low intrinsic dimensionality, which are constructed by predictive learning to reflect the relevant latent variables in a task. Our results substantiate and build on the importance of allied frameworks in constructing such relational networks <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b56">57</ref> . Overall the predictive learning framework provides a potential alternative of generating hippocampal representations, which differs from both attractor <ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59</ref> and path-integration models <ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b60">61</ref> , while maintaining elements of both these models. Discerning the underlying differences and similarities will require careful future investigations.</p><p>From an algorithmic and computational perspective, our proposal is motivated by the recent success of predictive models in machine-learning tasks that require vector representations reflecting semantic relationships in the data. Information retrieval and computational linguistics have benefited enormously from the geometric properties of word embeddings learned by predictive models <ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b61">62</ref> . Furthermore, prediction over observations has been used as an auxiliary task in reinforcement learning to acquire representations favoring goal-directed learning <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref> . Alongside these studies there are other emerging frameworks that are related to the predictive learning networks we analyze: contrastive predictive coding <ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b63">64</ref> , information theoretic approaches <ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b65">66</ref> and world models <ref type="bibr" target="#b66">67</ref> . Furthermore, our contribution shall also be seen in light of computational models studying neurons with optic flow selectivity <ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b68">69</ref> .</p><p>Predictive learning is a general framework that goes beyond the examples analyzed here, and future work can expand in other directions (text, visual processing, behavioral tasks, etc.) that may open new theoretical advances and new implications for learning and generalization. It will also be exciting to adapt and test these ideas for the analysis of large-scale population recordings of in vivo neural data-ideally longitudinally, so that the evolution of learned neural representations can be tracked with metrics such as the emergence of a low-D neural representation manifold, predictive error, latent signal transfer and dimensionality gain. A very interesting possibility is that this might uncover the presence of latent variables in tasks where they were previously unsuspected or unidentified. Our techniques require no advance knowledge of the latent variables. The consequence is that both the number and identity of latent variables can be discovered by analysis of a learned neural response manifold, as studied in other settings <ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref> .</p><p>Furthermore, it will be important to develop a formal connection between predictive learning mechanisms <ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74</ref> and reinforcement learning (RL) paradigms <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b74">75</ref> in both model-free and model-based schemes <ref type="bibr" target="#b75">[76]</ref><ref type="bibr" target="#b76">[77]</ref><ref type="bibr" target="#b77">[78]</ref> . This has the potential to build a general framework that could uncover predictive learning behavior in both animals and humans. One step here would be to extend existing RL paradigms to scenarios where making predictions is important even in the absence of rewards <ref type="bibr" target="#b78">[79]</ref><ref type="bibr" target="#b79">[80]</ref><ref type="bibr" target="#b80">[81]</ref><ref type="bibr" target="#b81">[82]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Card-game network. We generate a two-dimensional 5 x 5 grid of states, which is the latent space. To each state, we randomly assign a random set of five cards from a deck of 40, sampled with no repetition. This serves as an example of observations associated to states, which are fully random, independent, and of arbitrary complexity. In particular the dimensionality of the observation is not tied to the dimensionality of the latent space. We generate 10 6 state transitions following the five actions as defined in the main text. Upon generating such sequence of states we train a feedforward network to predict upcoming obeservations given current ones. The network is a two-layer network with 100 neurons in both layers, the first with sigmoidal transfer function and the second with hyperbolic tangent followed by a binary cross-entropy cost function. Both actions and observations have a one-hot encoding. All weights are initialized with random normal matrices. Training is performed on 80% of the sequence and validated on the remaining 20% utilizing a RMSprop optimizer (parameters: learning constant = 0.0001, α = 0.95, ϵ regularizer = 1 ⋅ 10 -7 ). The learning rate was reduced of a factor 0.5 if the validation loss did not decrease for eight consecutive epochs (reducing on plateau scheme). Training was stopped after 25 epochs with no improvement in the validation loss (min delta of variation 5e-5). The neural network used for Fig. <ref type="figure" target="#fig_1">2e</ref> is identical to the one just described, except that the output is read out at the second layer (the hyperbolic tangent layer) with mean-squared error. This is to account for the fact that the prediction, when actions are not passed to the network, is probabilistic towards neighboring states. All simulations were performed in Keras.</p><p>Neural network model for the spatial exploration task. We study a recurrent neural network (RNN) that generates predictive neural representations during the exploration of partially observable environments. RNNs are suited to processing sequence-to-sequence tasks <ref type="bibr" target="#b82">83</ref> and the state of a recurrent network is a function of the history of previous inputs and can thus be exploited to learn contextually appropriate responses to a new given input <ref type="bibr" target="#b83">[84]</ref><ref type="bibr" target="#b84">[85]</ref><ref type="bibr" target="#b85">[86]</ref> .</p><p>Figure <ref type="figure" target="#fig_1">2c</ref> illustrates the RNN model: at a given time t the RNN receives as input an observation vector o ! and a vector representation of the action a ! . The internal state r ! t of the network is updated and used to generate the network's output through the following set of equations:</p><formula xml:id="formula_6">r t ¼ g Wr tÀ1 þ W o o t þ W a a t ð Þ y t ¼ g W out r t ð Þ<label>ð7Þ</label></formula><p>The RNN is trained to predict the observation at the next timestep by minimizing the first cost function, or alternatively to autoencode its input, via the predictive and non-predictive cost functions, respectively:</p><formula xml:id="formula_7">C pred ¼ 1 T P TÀ1 t¼0 jjo tþ1 À y t jj 2 ; C nonÀpred ¼ 1 T P TÀ1 t¼0 jjo t À y t jj 2 :<label>ð8Þ</label></formula><p>Networks were trained by minimizing the cost function in Eq. ( <ref type="formula" target="#formula_7">8</ref>) via backpropagation through time <ref type="bibr" target="#b86">87</ref> . While RNNs are known to be difficult to train in many cases <ref type="bibr" target="#b87">88</ref> , a simple vanilla RNN model with hyperbolic tangent activation function was able to learn our task, Fig. <ref type="figure" target="#fig_1">2d</ref>.</p><p>The connectivity matrix of the recurrent network was initialized to the identity <ref type="bibr" target="#b88">89,</ref><ref type="bibr" target="#b89">90</ref> , while input and output connectivity matrices were initialized to be random matrices. Individual weights were sampled from a normal distribution with mean zero and standard deviation 0.02. The network had 500 recurrent units (with the exception noted below), while the input and output size depended on the task as defined by the environment. Each epoch of training corresponded to T = 10 6 time steps.</p><p>All other training details were the same as reported for the card-game example. For the simulations of Fig. <ref type="figure" target="#fig_3">5</ref>, we trained 100 networks of 100 neurons: 50 networks in the predictive case and 50 networks in the non-predictive case (cf. Eq. ( <ref type="formula" target="#formula_7">8</ref>) with equal instantiation of the rest of parameters.</p><p>Description of the spatial environment. modeled the spatial exploration task in two dimensions. We simulated the exploration of the agent in a square maze tessellated by a grid of evenly spaced cells (64 × 64 = 4096 locations). At every time t the agent was in a given location in the maze and headed in a direction φ ∈ [0, 2π). The agent executed a random walk in the maze, which was simulated as follows. At every step in the simulation an action was selected by updating the direction variable θ stochastically with dθ (i.i.d. sampled from a Gaussian distribution with variance σ 2 theta ¼ 0:5 rad ). The agent then attempted a move to the cell, among the eight adjacent ones, that was best aligned to θ. The move occurred unless the target cell was occupied by a wall, in which case the agent remained in the current position but updated its angle with an increment twice the size of a regular one: σ 2 theta ¼ 1:0 rad . To ensure coherence between updates in the direction θ and the cell towards which the agent just moved, we required each update in dθ to be towards the direction of the agent's last movement d a so that dθ ⋅ (θd a ) would always be positive, where d a assumed one of 8 values depending on the action taken by the agent.</p><p>The chosen action was encoded in a one-hot vector that indexed the movement. The actions were discrete choices a t ∈[0. . 8] correlating with the head direction but distinct from it. This was indeed a continuous variable θ t ∈ [0, 2π). Moreover, knowledge of the action didn't provide direct information about the agent's direction and observation; in other words, there was no direct correspondance between the action taken and the observation collected as for each location and action there were many possible directions the agent could point towards and consequently as many possible observations.</p><p>As the agent explored the environment it collected, through a set of N s = 5 sensors, observations of the distance and color of the walls along five different directions equally spaced in a 90 degree visual cone centered at φ. Thus it recorded, for each sensor, four variables at every timestep: the distance from the wall and the RGB components of the color of the wall. This information was represented by a vector o t of size 5 × 4 = 20. Such a vector, together with the action represented as a one-hot representation, was fed as input into the network and used for the training procedure. The walls were initially colored so that each tile corresponding to a wall carried a random color (i.e., three uniformly randomly generated numbers in the interval [0,1]). A Gaussian filter of variance two tiles was then used, for each color channel, to make the color representations smooth. Figure <ref type="figure" target="#fig_1">2b</ref> shows an example of such an environment.</p><p>Predictive error. The predictive error is a direct generalization of Eq. ( <ref type="formula" target="#formula_7">8</ref>) as a function of a time lag variable:</p><formula xml:id="formula_8">C pred ðlagÞ ¼ 1 T X TÀ1 t¼0</formula><p>jjo tþlag À y t jj 2 ; ð9Þ so that it is possible to verify that the output of the network y is most similar, on average, to the upcoming observation rather than the current observation.</p><p>Latent signal transfer. The latent signal transfer measure was obtained by performing a canonical correlation analysis (CCA) between two spaces: the top 3 PC components of the network's representation and other variables as specified in the text, e.g., latent variables (x,y). CCA extracts the directions of maximal correlation between the two spaces returning a set of canonical correlations. Latent signal transfer is then taken to be the average of these canonical correlations, which are as many as the minimum between the ranks of the two spaces.</p><p>Nonlinear dimensionality: intrinsic dimensionality. While research on estimating intrinsic dimensionality (ID) is advancing, there is still no single decisive algorithm to do so; rather, we adopt the recommended practice of computing and reporting several (here, five) different estimates of ID based on distinct ideas <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32</ref> .</p><p>The set of techniques we use include: MiND ML <ref type="bibr" target="#b90">91</ref> , MLE <ref type="bibr" target="#b91">92</ref> , DancoFit <ref type="bibr" target="#b92">93</ref> , CorrDim <ref type="bibr" target="#b93">94</ref> , and GMST <ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b95">96</ref> . These techniques follow the selection criteria illustrated in ref. <ref type="bibr" target="#b30">31</ref> , emphasizing the ability to handle high-dimensional data (in our case hundreds of dimensions) and being robust, efficient, and reliable; we refer the reader to ref. <ref type="bibr" target="#b24">25</ref> for a useful comparison. We implement these techniques using the code from the the authors available online <ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b92">93</ref> , "out of the box" without modifying hyperparameters.</p><p>A simple intuition regarding for some of the selected techniques builds on the notion of correlation dimension, which derives from the following idea. Consider a manifold M of dimensionality d embedded in IR N and a set of points uniformly sampled from the manifold. For each point build a ball of radius r (denoted as B r ), then the number of points within B r (denoted as #B r ) can be analyzed as a function of r and be found to scale as #B r ~rd at least for small r. This scaling can be exploited to estimate d.</p><p>Description of arm-reaching movements model. To model arm-reaching movements we used a kinematic model of the arm muscles <ref type="bibr" target="#b96">97,</ref><ref type="bibr" target="#b97">98</ref> . The arm kinematics were modeled in the transverse plane by analyzing the effect of six muscles on the arm dynamics, cf. Fig. <ref type="figure" target="#fig_4">6a</ref>. The activation signals for the muscles were used as actions in our model. For each of the six muscles, we used a pulsed binary signal where at each instant in time the pulse can be turned on or off. These activation signals are filtered and passed to the equations of inverse kinematics of the muscles, which regulate muscular contraction. Such muscle dynamics drives the arm dynamics according to the Mitrovic model <ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b98">99,</ref><ref type="bibr" target="#b99">100</ref> . All the details regarding the implementations of this model can be found on the Github repository we adopted for the simulations <ref type="url" target="https://github.com/jeremiedecock/pyarm">https://github.com/ jeremiedecock/pyarm</ref> and in the code we provide. The most relevant feature of this model for our study is the fact that the six-dimensional muscle activity drives nonlinear dynamics in the two-dimensional latent space described by the two angles α, β in Fig. <ref type="figure" target="#fig_4">6a</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig.1Predictive network solving a card-game task. a Description of the latent space underlying the task. b Illustration of the task and information flow diagram: the neural representation receives state observations and actions and extracts the latent space structure by means of predicting upcoming observations. c Diagram of the network's structure. The diagram highlights the layer studied here, although the network has a two layers, where the second layer serves as a decoder. d The network's neural representation: activity in the hidden layer plotted vs. principal components PCs 1 and 2 of hidden layer activity. For each observation-action pair (o t , a t ), the corresponding activation is colored by the position of the state that the network predicts: x-coordinate (left plot, before and after learning) and y-coordinate (right plot). e Same as panel d in the absence of the action as a input to the network. f Same as panel d for a three-dimensional latent space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Predictive network solving an exploration task. a Information flow diagram of the task: an agent explores a two-dimensional environment (latent space) through actions and receives observations regarding it. The network's task is to predict the next sensory observation. By learning to do so it recovers information regarding the underlying hidden latent space. b Illustration of the agent with sensors in the square environment where the walls have been colored (cfr. Methods). The sensors span a 90 o degree angle and register the color and distance of the wall along their respective directions. c Diagram of the predictive recurrent neural network: the network receives actions and observations as inputs and is trained to output the upcoming sensory observation. d Cost during training for the network (cf. Methods). e Average activity of 100 neurons (each of the 100 neurons average activity is showed in one of the small 100 quadrants) against the x, y coordinates of the environment, showing place-related activity. f Same as panel e for a RNN trained to autoencode its input observations.</figDesc><graphic coords="4,110.56,60.50,410.44,209.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc>Fig.3Learning the predictive representation. a Predictive error (L 2 norm) in blue between the network's output and the observation as a function of the lag (Delta t). In red average L 2 norm between the observation at time 0 and at a lag Delta t. b Linear decoding of latent variables. RMS measure of the linear decoding of (x, y, θ) at time Delta t from the neural representation at time 0. The dotted line highlights the axis of symmetry of the curves. c Signal transfer analysis: Canonical Correlation Analysis between PCs of the neural representation and the latent space. The lines correspond to the average of the canonical correlations between the highlighted variables. d Same as panel c but for the observation space. e Participation ratio of the representation during learning. f Intrinsic dimensionality (ID) of the representation during learning. Five different intrinsic dimensionality estimators are used (cfr. Methods).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5</head><label>5</label><figDesc>Fig.5Features of the learned predictive representation. a 100,000 points of the neural network representation, corresponding to an equal number of steps for the agent's exploration, are shown projected into the space spanned by PCs 1 to 3 of the learned representation, and colored, respectively, according to x, y latent variables (cfr. Fig.1afor color code) and θ. b Same as panel b but for PCs 4 and 5. c Same as panel a but colored with respect to the mean distance or color activations of the agent's sensors. In this specific example, the first five PC components explain, respectively, 13.7%, 11.4%, 10.2%, 5.5%, 5.4% of the total neural variance. d Manifold cell activations: average activity of 100 neurons on the manifold (here displayed for the first PCs 1 and 2.). The activity of each neuron (one per quadrant) is averaged as the population activity is in a specific "location'' on the neural manifold in the space spanned by PCs 1 and 2.</figDesc><graphic coords="8,72.88,71.78,462.76,259.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 Predictive representations of arm-reaching movements. Plane transverse to the dynamic of arm-reaching movements. The muscle model is shown and the two latent angular variables α and β. b Recurrent network model. c Predictive error upon training. The symmetry axis is around lag +1 indicating that the network is carrying out the prediction correctly. Latent signal transfer and observation signal transfer. e Dimensionality trends learning both linear and nonlinear (ID) dimensionality f Top: principal components space (PCs 1-2) colored by the average angles α, β for each location. Bottom: average activity of neurons in space by the top 2 PCs. Each subplot represents the average activity of a neurons. Neurons are ranked according to their average firing rates. The most active neuron is in the left the second in the first column second row and so on for all the neurons. g Average of neurons in latent space β. Each corresponds the neuron in panel f.</figDesc><graphic coords="9,100.42,252.92,234.76,112.12" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>NATURE COMMUNICATIONS | (2021) 12:1417 | https://doi.org/10.1038/s41467-021-21696-1 | www.nature.com/naturecommunications</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>Reporting summary. Further information on research design is available in the Nature Research Reporting Summary linked to this article.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements E.S.B. is supported by <rs type="funder">NSF</rs> Grant <rs type="grantNumber">1514743</rs>, wishes to thank the <rs type="institution">Allen Institute for Brain Science founders, Paul</rs> and <rs type="person">Jody Allen</rs>, for their vision, encouragement, and support. G.L. is supported by an <rs type="funder">NSERC</rs> <rs type="grantName">Discovery Grant</rs> (<rs type="grantNumber">RGPIN-2018-04821</rs>) and the <rs type="funder">FRQNT</rs> <rs type="programName">Young Investigator Startup Program</rs> (2019NC253251). Part of this work was conducted during an internship at IBM Research. The authors would like to acknowledge the numerous colleagues who have helped generate the ideas of the paper. In particular, we thank <rs type="person">Luca Mazzucato</rs> (<rs type="affiliation">University of Oregon, USA</rs>), <rs type="person">Kameron Decker Harris</rs> (<rs type="affiliation">University of Washington, USA</rs>), <rs type="person">Stefan Mihalas</rs> (<rs type="affiliation">Allen Institute for Brain Science, USA</rs>), <rs type="funder">Greg Wayne (DeepMind, UK)</rs>, and <rs type="person">Alon Rubin</rs> (<rs type="affiliation">Weizmann Institute, Israel</rs>), <rs type="person">Cengiz Pehlevan</rs> (<rs type="affiliation">Harvard University</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ptqThAX">
					<idno type="grant-number">1514743</idno>
				</org>
				<org type="funding" xml:id="_77YNG3E">
					<idno type="grant-number">RGPIN-2018-04821</idno>
					<orgName type="grant-name">Discovery Grant</orgName>
				</org>
				<org type="funding" xml:id="_DF88bwn">
					<orgName type="program" subtype="full">Young Investigator Startup Program</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p>All data generated through the simulations generated is made available from the corresponding author upon reasonable request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability</head><p>All code is made available from the corresponding author upon reasonable request.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p>S.R.: conceptualization, formal analysis, software, validation, visualization, writing. M.F.: conceptualization, formal analysis, review and editing. G.L.: conceptualization, formal analysis, review and editing. S.D.: conceptualization, formal analysis, review and editing. M.R.: conceptualization, project administration, supervision, writing, review and editing. E.S.B.: conceptualization, project administration, supervision, writing, review and editing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary information</head><p>The online version contains supplementary material available at <ref type="url" target="https://doi.org/10.1038/s41467-021-21696-1">https://doi.org/10.1038/s41467-021-21696-1</ref>.</p><p>Correspondence and requests for materials should be addressed to S.R.</p><p>Peer review information Nature Communications thanks Florian Raudies and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.</p><p>Reprints and permission information is available at <ref type="url" target="http://www.nature.com/reprints">http://www.nature.com/reprints</ref> Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Language and Speech Processing</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A.-H</forename><surname>Dediu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Martín-Vide</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Mitkov</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Truthe</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust timing and motor patterns by taming chaos in recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Laje</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Buonomano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="925" to="933" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hybrid computing using a neural network with dynamic external memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">538</biblScope>
			<biblScope unit="page">471</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Saeedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1606.02396" />
		<title level="m">Deep successor reinforcement learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neurocomputational dynamics of sequence learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Konovalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page">1282</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Vector-based navigation using grid-like representations in artificial agents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Banino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">557</biblScope>
			<biblScope unit="page" from="429" to="433" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unsupervised predictive memory in a goal-directed agent</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1803.10760" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Task representations in neural networks trained to perform many cognitive tasks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Joglekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="297" to="306" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1301.3781" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Rand-walk: a latent variable model approach to word embeddings</title>
		<author>
			<persName><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Risteski</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1502.03520arxiv" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving generalization for temporal difference learning: the successor representation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="613" to="624" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Stachenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2528" to="2536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Predictive representations can link model-based reinforcement learning to model-free mechanisms</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Russek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computat. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">1005768</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Predictive coding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdiscip. Rev.: Cognit. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="580" to="593" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A review of predictive coding algorithms</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Spratling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Cogn</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="92" to="97" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Computational account of spontaneous activity as a signature of predictive coding</title>
		<author>
			<persName><forename type="first">V</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Denève</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computat. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">1005355</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Build, compute, critique, repeat: data analysis with latent variable models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Rev. Stat. Appl</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="203" to="232" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning deep generative models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Rev. Stat. Appl</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="361" to="385" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A review of dynamic network models with latent variables</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Surv</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dimensionality reduction: a comparative</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Postma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Den Herik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="66" to="71" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">in The Dynamic Brain: an Exploration of Neuronal Variability and Its Functional Significance</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>OUP</publisher>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The importance of mixed selectivity in complex cognitive tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">497</biblScope>
			<biblScope unit="page">585</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stimuli reduce the dimensionality of cortical activity</title>
		<author>
			<persName><forename type="first">L</forename><surname>Mazzucato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fontanini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Camera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Syst. Neurosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimal degrees of synaptic connectivity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Litwin-Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Axel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1153" to="1164" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A theory of multineuronal dimensionality, dynamics and measurement</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.1101/214262page</idno>
		<ptr target="https://doi.org/10.1101/214262page" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Intrinsic dimension estimation: advances and open problems</title>
		<author>
			<persName><forename type="first">F</forename><surname>Camastra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Staiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sci</title>
		<imprint>
			<biblScope unit="volume">328</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intrinsic dimension estimation: relevant techniques and a benchmark framework</title>
		<author>
			<persName><forename type="first">P</forename><surname>Campadelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Casiraghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ceruti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Probl. Eng</title>
		<imprint>
			<biblScope unit="page">759567</biblScope>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Probing variability in a cognitive map using manifold inference from neural dynamics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lewallen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aronov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nevers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Tank</surname></persName>
		</author>
		<idno type="DOI">10.1101/418939</idno>
		<ptr target="https://doi.org/10.1101/418939" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Recurrent neural networks learn robust representations by dynamically balancing compression and expansion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Recanatesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Shea-Brown</surname></persName>
		</author>
		<idno type="DOI">10.1101/564476</idno>
		<ptr target="https://doi.org/10.1101/564476" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Dimensionality compression and expansion in deep neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Recanatesi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1906.00443" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Predictive information in a sensory population</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Marre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="6908" to="6913" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Manifold-tiling localized receptive fields are optimal in similarity-preserving neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tepper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pehlevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Genkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chklovskii</surname></persName>
		</author>
		<idno type="DOI">10.1101/338947</idno>
		<ptr target="https://doi.org/10.1101/338947" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at bioRxiv</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A computational model of limb impedance control based on principles of internal model uncertainty</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Osu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kawato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1360</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Stochastic Optimal Control with Learned Dynamics Models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mitrovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Edinburgh Research Archive</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Linear-nonlineartime-warp-poisson models of neural activity</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Lawlor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Perich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Kording</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Neurosci</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Extracellular Neural Recordings from Macaque Primary and Dorsal Premotor Motor Cortex during A Sequential Reaching Task</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Perich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Lawlor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Kording</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Miller</surname></persName>
		</author>
		<ptr target="CNRS.org" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">On the generalization of equivariance and convolution in neural networks to the action of compact groups</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2747" to="2755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">A general theory of equivariant cnns on homogeneous spaces</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1811.02017" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Theoretical aspects of group equivariant neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Esteves</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2004.05154" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Equivariance through parametersharing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2892" to="2901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Keriven</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="7092" to="7101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Aspects of Harmonic Analysis and Representation Theory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gallier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Quaintance</surname></persName>
		</author>
		<ptr target="https://www.seas.upenn.edu/~jean/nc-harmonic.pdf" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Why does Deep Learning work?-A perspective from Group Theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1412.6621" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Sparse synaptic connectivity is required for decorrelation and pattern separation in feedforward networks</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Cayco-Gajic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clopath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1116</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Preserved learning and retention of patternanalyzing skill in amnesia: dissociation of knowing how and knowing that</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page" from="207" to="210" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</title>
		<author>
			<persName><forename type="first">J</forename><surname>O'keefe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dostrovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="171" to="175" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Memory, navigation and theta rhythm in the hippocampal-entorhinal system</title>
		<author>
			<persName><forename type="first">G</forename><surname>Buzsáki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Moser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="130" to="138" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Mnemonic networks in the hippocampal formation: from spatial maps to temporal and conceptual codes</title>
		<author>
			<persName><forename type="first">B</forename><surname>Milivojevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Doeller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="page">1231</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Can we reconcile the declarative memory and spatial navigation views on hippocampal function?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Eichenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="764" to="770" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Memory and space: towards an understanding of the cognitive map</title>
		<author>
			<persName><forename type="first">D</forename><surname>Schiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13904" to="13911" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Kanitscheider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fiete</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="4529" to="4538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The hippocampus as a predictive map</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Stachenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1643" to="1653" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Attractor neural network models of spatial maps in hippocampus</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tsodyks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="481" to="489" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An attractor network in the hippocampus: theory and neurophysiology</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Rolls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learn. Memory</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="714" to="731" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Path integration and the neural basis of the &apos;cognitive map&apos;</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Mcnaughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="663" to="678" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Origin and role of path integration in the cognitive representations of the hippocampus: computational insights into open questions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Savelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Knierim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Biol</title>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="page">188912</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1807.03748" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Data-efficient image recognition with contrastive predictive coding</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Hénaff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4182" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Buchwalter</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1906.00910" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Selfie: self-supervised pretraining for image embedding</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1906.02940" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Learning to predict without looking ahead: world models without forward prediction</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1910.13038" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Computational modelling of optic flow selectivity in MSTd neurons</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Beardsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Vaina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network (Bristol, England)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="467" to="493" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="485" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Unsupervised learning of image manifolds by semidefinite programming</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="77" to="90" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Predictive coding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P N</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdiscipl. Rev. Cognit. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="580" to="593" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">The brain as an efficient and robust adaptive learner</title>
		<author>
			<persName><forename type="first">S</forename><surname>Denève</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bourdoukan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="969" to="977" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Reinforcement learning and episodic memory in humans and animals: an integrative framework</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="101" to="128" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Predictive representations can link model-based reinforcement learning to model-free mechanisms</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Russek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">1005768</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The successor representation in human reinforcement learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Momennejad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Human Behav</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="680" to="692" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Hippocampal contributions to model-based planning and spatial memory</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">M</forename><surname>Vikbladh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="683" to="693" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Temporal difference models and reward-related learning in the human brain</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Critchley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="329" to="337" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Modulating the use of multiple memory systems in value-based decisions with contextual novelty</title>
		<author>
			<persName><forename type="first">K</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Semmler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cognit. Neurosci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1455" to="1467" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">What are memories for? the hippocampus bridges past experience with future decisions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Biderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bakkour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shohamy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2020.04.004</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2020.04.004" />
	</analytic>
	<monogr>
		<title level="j">Trend. Cognit. Sci</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Learning representations that support extrapolation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dulberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Frankland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="10136" to="10146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Internal representation of task rules by recurrent dynamics: the importance of the diversity of neural responses</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B D</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao-Jing &amp;</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fusi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Computat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Attractor concretion as a mechanism for the formation of context representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B D</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Salzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fusi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="833" to="847" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">A critical review of recurrent neural networks for sequence learning</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1506.00019" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Capacity and trainability in recurrent neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1611.09913" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Minimum neighbor distance estimators of intrinsic dimension</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lombardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ceruti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Casiraghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Campadelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 European Conference on Machine Learning and Knowledge Discovery in Databases-Volume Part II, ECML PKDD&apos;11</title>
		<meeting>the 2011 European Conference on Machine Learning and Knowledge Discovery in Databases-Volume Part II, ECML PKDD&apos;11</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="374" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="777" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title level="m" type="main">DANCo: dimensionality from angle and norm concentration</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ceruti</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1206.3881" />
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Measuring the strangeness of strange attractors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Grassberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Procaccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="189" to="208" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>De Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">Manifold learning with geodesic minimal spanning trees</title>
		<author>
			<persName><forename type="first">J</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hero</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/cs/0307038" />
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="report_type">Preprint at</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Learning cost-efficient control policies with XCSF: generalization capabilities and further improvement</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Decock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rigoux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sigaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th annual conference on Genetic and evolutionary computation</title>
		<meeting>the 13th annual conference on Genetic and evolutionary computation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1235" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">XCSF with tile coding in discontinuous actionvalue landscapes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Lanzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Loiacono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Intell</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="117" to="132" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Adaptive optimal control for redundantly actuated arms</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Simulation of Adaptive Behavior</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="93" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vijayakumar</surname></persName>
		</author>
		<title level="m">From Motor Learning to Interaction Learning in Robots</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="65" to="84" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
