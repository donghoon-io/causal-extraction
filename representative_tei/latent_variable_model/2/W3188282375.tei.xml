<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A note on identification constraints and information criteria in Bayesian latent variable models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2021-08-05">5 August 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Graves</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Edgar</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
						</author>
						<title level="a" type="main">A note on identification constraints and information criteria in Bayesian latent variable models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-08-05">5 August 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3758/s13428-021-01649-8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian SEM</term>
					<term>Structural equation models</term>
					<term>Model comparison</term>
					<term>Identification</term>
					<term>blavaan</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is well known that, in traditional SEM applications, a scale must be set for each latent variable: typically, either the latent variance or a factor loading is fixed to one. While this has no impact on the fit metrics in ML estimation, it can potentially lead to varying Bayesian model comparison metrics due to the use of different prior distributions under each parameterization. This is a problem, because a researcher could artificially improve one's preferred model simply by changing the identification constraint. Using a single-factor CFA as motivation for study, we first show that Bayesian model comparison metrics can systematically change depending on constraints used. We then study principled methods for setting the scale of the latent variable that stabilize the model comparison metrics. These methods involve (i) the placement of priors on ratios of factor loadings, as opposed to individual loadings; and (ii) use of effect coding. We illustrate the methods via simulation and application.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Bayesian psychometric models have gained popularity due to their accessibility, their application to small data sets, and their ability to handle complex models that would prove difficult to estimate using maximum likelihood methods (e.g., <ref type="bibr" target="#b1">Fox, 2010;</ref><ref type="bibr" target="#b8">Kaplan, 2014;</ref><ref type="bibr" target="#b12">Lee, 2007;</ref><ref type="bibr" target="#b13">Lee &amp; Song, 2004;</ref><ref type="bibr" target="#b14">Levy &amp; Mislevy, 2016;</ref><ref type="bibr" target="#b19">Muthén &amp; Asparouhov, 2012;</ref><ref type="bibr" target="#b29">Rupp, Dey, &amp; Zumbo, 2004;</ref><ref type="bibr" target="#b32">Song &amp; Lee, 2012;</ref><ref type="bibr" target="#b35">van de Schoot, Winter, Ryan, Zondervan-Zwijnenburg, &amp; Depaoli, 2017)</ref>.</p><p>These models generally involve latent variables representing person traits or attributes, requiring a constraint to be placed on the latent variable scale in order to identify other model parameters. This is typically done in one of two ways. The first constrains a single-factor loading per latent variable to a constant, usually 1. This is sometimes called the fixed marker method or unit loading identification (ULI; <ref type="bibr" target="#b10">Kline, 2015)</ref>. The second constrains the latent variance to be a constant, which is again usually 1. This is known Benjamin Graves blgpp5@mail.missouri.edu 1 Department of Psychological Sciences, University of <ref type="bibr">Missouri,</ref><ref type="bibr">210 McAlester Hall,</ref><ref type="bibr">320 S 6th Street,</ref><ref type="bibr">Columbia,</ref><ref type="bibr">MO 65211,</ref><ref type="bibr">USA</ref> as the fixed factor method or unit variance identification (UVI). Further detail on traditional factor model identification appears in <ref type="bibr" target="#b6">Jöreskog (1969)</ref> and <ref type="bibr" target="#b7">Jöreskog (1979)</ref> and in <ref type="bibr">Peeters (2012a)</ref> and <ref type="bibr">Peeters (2012b)</ref>.</p><p>When using traditional estimation methods for SEM, including maximum likelihood and least squares estimation, the specific identification constraint typically does not influence model fit or model comparison metrics (though see, e.g., <ref type="bibr">Klößner and Klopp 1995;</ref><ref type="bibr" target="#b21">O'Brien &amp; Reilly, 1995;</ref><ref type="bibr">Steiger, 2002, for exceptions)</ref>. This is not necessarily true for Bayesian models. For Bayesian models, the prior distributions often differ across identification constraints, which can in turn influence the fit metrics. For example, fixing the first factor loading to one may lead to a betterfitting model, as compared to fixing the second factor loading to one. Further, if priors are centered around zero, they suggest that free loadings are likely to be smaller than the loading that is fixed to one. Unlike in the frequentist setting, this change in priors across identification methods implies that the models are distinct from each other even though they have the same structure. This is potentially problematic because it provides a route by which researchers can artificially improve or worsen a particular model's metrics. For example, one can imagine a hypothetical situation where a researcher's preferred model is not selected as best by an information criterion (for example, by DIC). The researcher may then change the identification constraint, find that their preferred model is selected, and report results under the new identification constraints. This issue is unique to Bayesian latent variable models and, to our knowledge, has not received attention in previous literature.</p><p>The purpose of this paper is to study how model identification constraints influence Bayesian model comparison criteria. We consider the popular Bayesian metrics of DIC <ref type="bibr" target="#b33">(Spiegelhalter, Best, Carlin, &amp; van der Linde, 2002)</ref>, WAIC <ref type="bibr" target="#b39">(Watanabe, 2010)</ref>, and the Pareto-smoothed leave-one-out cross-validation metric (LOOIC; e.g., <ref type="bibr" target="#b37">Vehtari, Gelman, &amp; Gabry, 2017)</ref> that is implemented in the loo package for R <ref type="bibr" target="#b36">(Vehtari et al., 2020)</ref>. These metrics are defined as</p><formula xml:id="formula_0">DIC = -2 log L( θ|Y ) +2 log L( θ|Y ) -log L( θ|Y ) (1) WAIC = -2 n i=1 log 1 S S s=1 f (y i |ϑ s ) +2 n i=1 var s (log f (y i |ϑ)) (2) LOOIC = -2 n i=1 log S s=1 w s i f (y i |ϑ s ) S s=1 w s i (<label>3</label></formula><formula xml:id="formula_1">)</formula><p>where θ is a vector of posterior parameter means, L( θ|Y ) is the likelihood at those means, S is the number of posterior draws, f (y i |ϑ s ) is the density of observation i w.r.t. sampled parameters at iteration s, and the w s i are importance sampling weights. We use a likelihood that is marginal over the latent variables in the model; see <ref type="bibr" target="#b17">Merkle, Furr, and Rabe-Hesketh (2019)</ref> for further detail on this issue.</p><p>In the sections below, we first illustrate the fact that the information criteria mentioned above can exhibit different values, depending on the identification constraint used. In essence, different identification constraints can lead to different prior distributions, which in turn lead to different Bayesian models. We then explore the issue in more detail via simulation and describe alternative identification constraints that can help resolve the issue. Finally, we describe an application and discuss general implications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Illustration</head><p>We first illustrate the problem in the context of Bayesian CFA. We use a subset of the <ref type="bibr" target="#b5">Holzinger and Swineford (1939)</ref> data available in the MBESS package <ref type="bibr" target="#b9">(Kelley, 2018)</ref>, focusing on the three spatial ability tests. We fit a onefactor model (see Fig. <ref type="figure">1</ref>) with four different identification Fig. <ref type="figure">1</ref> General path diagram used to fit the example models and generate simulation data constraints: ULI on each of the three loadings as well as UVI. Under traditional estimation methods, these four models exhibit exactly the same model fit metrics (χ 2 statistics, AICs, BICs, RMSEAs, etc). Thus, if we find that the models systematically differ on Bayesian model comparison metrics, it is notable because it means that a model could be artificially improved or worsened by choice of identification constraint. Note that we are not comparing the four models in order to select the model with the "best" identification constraint; we are instead illustrating that the four models differ in the values of their information criteria.</p><p>We estimated the one-factor model via three MCMC chains, with chain lengths being automatically determined by the <ref type="bibr" target="#b27">Raftery and Lewis (1995)</ref> procedure that is implemented in R package runjags <ref type="bibr" target="#b0">(Denwood, 2016)</ref>. After burning in and sampling the model for a pre-specified length, the procedure determines the number of additional samples necessary to estimate each parameter's 2.5th quantile to an accuracy of .005 with probability .95. Models were estimated and summarized via blavaan <ref type="bibr" target="#b18">(Merkle &amp; Rosseel, 2018)</ref>, which provides an interface between lavaan model specification <ref type="bibr" target="#b28">(Rosseel, 2012)</ref> and the JAGS software for MCMC <ref type="bibr" target="#b24">(Plummer &amp; et al. 2003)</ref>. Factor loading priors were set to normal with mean 0 and standard deviation of 10, and the latent precision prior was Gamma(1, .5). Under the UVI constraints, it is possible for the sampled factor loadings to flip signs from positive to negative and back again. To address this issue, a sign constraint was placed on a single loading per factor, as discussed by <ref type="bibr">Peeters (2012b)</ref>. This is generally preferable to half-normal or log-normal priors on all loadings, because those priors do not allow for reverse-coded variables or for loadings whose posterior distribution is symmetric around 0. Other priors were taken to be blavaan defaults, which are intended to be weakly informative. Manifest variable intercepts (ν) were set to a Normal with a mean of 0 and standard deviation of 32 and latent variable intercepts (α) are set to be a Normal with a mean of 0 and standard deviation of 10.</p><p>Results are shown in Table <ref type="table" target="#tab_0">1</ref>. Choice of identification constraint is presented in the first column, followed by the values of the marginal log-likelihood (LogL), WAIC, DIC, and LOOIC. We see up to six-point differences in the values of these metrics, depending on the identification constraint employed. It is apparent that the fit metrics can differ depending on how the model is identified. If we were to explicitly compute uncertainty in these metrics, then these differences may not be large (and see the General Discussion for further remarks here). However, uncertainty is not commonly considered here (at least, in Bayesian SEM), and the differing value would not be expected by researchers who have a background in frequentist SEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation</head><p>The above results were obtained with a single data set and could therefore be due to noise. This section expands the illustration, to examine the generality of the results. While we focus on Bayesian information criteria, the results have implications for other types of fit metrics. The simulation compared a one-factor model with the latent variance fixed to 1 (UVI model) to a one-factor model with the first loading fixed to 1 (ULI model), and it specifically focused on how the identification constraint influences the information criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Data were generated via the model from the illustration section, with parameter values fixed to the ML estimates from the original <ref type="bibr" target="#b5">Holzinger and Swineford (1939)</ref> data. The observed variables x 1 ("Visual"), x 2 ("Cubes"), and x 3 ("Lozenges") have variances of <ref type="bibr">26.77, 13.01, 30.93, factor loadings of 4.92, 2.96, and 5.96, and intercepts of 29.32, 24.70, 14.84</ref>, respectively, with the latent variance being fixed to 1. To examine systematic differences in model comparison metrics, we fit two models to each simulated data set: one with the first factor loading fixed to one and the other with the latent variance fixed to 1 (as in the previous section). These models' metrics would not differ under traditional ML estimation methods. We used two sets of priors that varied in informativeness. The less-informative set of priors used the default settings in blavaan in which the factor loading prior (λ) was set to be Normal(0, 10), where the mean is 0 and standard deviation is 10. The latent variable precision (ψ -1 ) was set to a Gamma(1, .5), which has a mean of 2 and standard deviation of 2. The more informative set of priors involved Normal(0, 1) distributions on factor loadings and a Gamma(.5, 2) distribution on the latent precision. This gamma distribution has a mean of 0.25 and standard deviation of 0.354. Figure <ref type="figure" target="#fig_0">2</ref> shows the distributions of the priors and reference points for ML parameter estimates. We also manipulated sample size, generating data sets with 500 and 1000 observations.</p><p>Each possible combination of priors and sample sizes was considered, leading to a total of eight possible conditions (2 loading priors × 2 latent precision priors × 2 sample sizes). For each simulation condition, we generated 500 data sets, estimated the UVI and ULI models via MCMC, and recorded the model assessment metrics. Primary metrics of interest were each model's DIC, WAIC, LOOIC, and marginal log-likelihood (LogL). For each metric, we also recorded model preference by computing the proportion of time the UVI model had a better value than the corresponding ULI model. If the fit metrics are the same across identification constraints, then this proportion should be close to .5. Values above .5 suggest the UVI model is preferred, while values below .5 suggest the ULI model is preferred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Primary results are shown in Fig. <ref type="figure" target="#fig_1">3</ref>, which are split by sample size. The priors used are on the x-axis, model preference (proportion of replications favoring UVI) is on the y-axis, and the bars represent the various fit metrics. In the figures, we can see that there is a systematic preference for one model identification method over the other, depending on the prior specification used and on the sample size. When uninformative priors are used for the factor loadings (Normal(0, 10)), the UVI method was preferred across all of the fit metrics. Use of informative priors for the factor loadings (Normal(0, 1)) changed model preference to favor the ULI method across all fit metrics. The lack of appearance of bars in the figure is due to an overwhelming preference for the ULI models, where nearly 100% of the replications were favoring this identification method. Changes in the latent variance prior had little effect on model preference, but preference values did get closer to .5 when sample size was increased from 500 to 1000. This is because the influence of the prior weakens as sample size increases. Of the fit metrics, marginal LogL preferred one Mean differences between the fit measures were also calculated for each simulation condition. The results are presented in Table <ref type="table" target="#tab_1">2</ref>. The conditions that showed the least preference also had the smallest mean differences, and these differences decreased as sample size was increased. The LogL exhibited smaller mean differences than the other metrics, which can be explained by the fact that the other metrics involve the LogL multiplied by -2.  The first three columns contain the sample sizes and prior specifications for each of the conditions. The last four columns present the average difference in fit metric values when subtracting the ULI model from the UVI model. Negative values suggest a preference for the UVI method</p><p>The informative Normal(0,1) prior on loadings also led to increased differences in metrics and favoring of the ULI model, whereas the UVI model was favored under the noninformative priors.</p><p>The results observed here can be explained by the extent to which the priors agree with the likelihood. To illustrate this, the asymptotic maximum likelihood estimates for our models (from lavaan) appear in Table <ref type="table" target="#tab_2">3</ref>. These estimates come from a simulated data set of 30,000 observations in order to approximate a "practically infinite" number of observations. The rows show which identification method is used for the model, either UVI or ULI, and the columns show the maximum likelihood estimates for the factor loadings and latent variance. In this example, it is worth noting that changing the constrained parameter changes the values of the parameter estimates, but the relationships between the factor loadings are preserved (i.e., λ 2 &lt; λ 1 &lt; λ 3 ). This table shows that the estimated loadings under UVI are inconsistent with our informative prior distribution (Normal(0,1)), which explains why the UVI model was not preferred under that prior distribution.</p><p>To further illustrate the influence of the priors on factor loadings, we fit another model with UVI constraints to the The table above shows parameter estimates for models identified using traditional ULI and UVI methods and maximum likelihood estimations. The first column shows which parameter was set to 1, while the other columns show parameter estimates and standard errors original dataset. This model was similar to the illustration, except that the factor loading priors were normal with mean 4.5 and standard deviation of 1. These priors are informative and also do a good job of capturing the maximum likelihood estimates. Information criteria values for this model can be found in Table <ref type="table" target="#tab_3">4</ref> and can be compared to those in Table <ref type="table" target="#tab_0">1</ref>. We see that, by all three information criteria, this model now appears better than all the previous models from Table <ref type="table" target="#tab_0">1</ref>.</p><p>In sum, we have observed that identification constraints can lead to differing information criteria, with the differences being explained by the prior specification and sample size. This means that a Bayesian model's metrics can potentially be improved by changing the identification constraint, something that has no impact under other estimation methods and that is often ignored in Bayesian SEM estimation. While we are unaware of researchers actually doing this, awareness of the issue is worthwhile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative methods for setting the scale</head><p>The previous sections have illustrated the fact that Bayesian model comparison metrics can change depending on how a researcher sets the scale of the latent variables. In this section, we describe two methods for setting the scales of latent variables such that the issue is reduced or removed. The first method places priors on ratios of factor loadings, so that the specific loading fixed to 1 has less influence on </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ratio method</head><p>Our first method involves maintaining the same identification constraint (e.g., fixing a single parameter to one), with prior distributions being placed on ratios of factor loadings instead of on individual factor loadings. In particular, <ref type="bibr" target="#b20">Newsom (2015)</ref> describes the relationship between loadings estimated under the ULI method to loadings estimated under the UVI method. Multiplying a factor loading by the square root of the variance parameter under UVI yields the estimate of the loading under ULI. Conversely, the estimated factor loading under ULI is the ratio of the same loading and the referent indicator value under UVI. With these sorts of results, we can place priors on the ratios of loadings instead of the individual loadings, and then extract loadings from the ratios, depending on the identification method used.</p><p>Referring to the one-factor, three-indicator model from Fig. <ref type="figure">1</ref>, we can use prior distributions similar to below, regardless of whether ULI or UVI is employed:</p><formula xml:id="formula_2">1 ψ ∼ Gamma(1, .5) (4) r 1 = λ 1 λ 2 ∼ N(0, 10) (5) r 2 = λ 1 λ 3 ∼ N(0, 10). (<label>6</label></formula><formula xml:id="formula_3">)</formula><p>The ratios r 1 and r 2 have priors centered at 0, instead of 1, to allow for the possibility that the individual loadings are negative as well as positive. If we expected all loadings to be positive, then a prior mean of 1 would be sensible.</p><p>We can now obtain parameter estimates under either ULI or UVI using the above ratios. For example, say that we fix λ 1 to one. The remaining factor loadings are:</p><formula xml:id="formula_4">λ 1 = 1 ( 7 ) λ 2 = 1 r 1 (8) λ 3 = 1 r 2 . (<label>9</label></formula><formula xml:id="formula_5">)</formula><p>Alternatively, if we fix the latent variance to one, the factor loadings can be obtained as:</p><formula xml:id="formula_6">λ 1 = ψ (10) λ 2 = √ ψ r 1 (11) λ 3 = √ ψ r 2 , (<label>12</label></formula><formula xml:id="formula_7">)</formula><p>where λ 1 is fixed to √ ψ so that the model-implied variance of the first indicator is the same as it would be if λ 1 had been fixed to one. This implies that λ 1 can only take positive values, which can be overly restrictive for a factor loading. However, such a sign constraint is necessary for the model to achieve global parameter identification under Bayesian estimation with UVI <ref type="bibr">(Peeters, 2012b)</ref>, so it serves a specific purpose here.</p><p>To study these ratio prior distributions, we conducted another simulation similar to the previous simulation, except using the ratio priors described above. We estimated four models with unique identification constraints: a model with each factor loading separately fixed to 1, and a fourth model with the latent variance fixed to 1. Model preferences were, once again, calculated by comparing the metrics of the UVI model to each of the ULI models. The simulation used the same set of priors specified above and sample sizes of 500 and 1000. Within each condition, we carried out 500 replications.</p><p>Model preference values for comparing each of the ULI models to the UVI model are found in Fig. <ref type="figure" target="#fig_2">4</ref>. Overall, as compared to initial simulations, models were not preferred as strongly as they were in the earlier simulations. For each of the combinations of priors and sample sizes, model preferences using DIC, WAIC, and LOOIC tended to approach .5 and were closest to exhibiting no preference at the largest sample size of 1000. Model preference values varied slightly depending on which factor loading was fixed to 1, but were generally similar across choice of fixed loading.</p><p>As can be seen, placing priors on ratios of parameters can help to reduce differences in information criteria, so that choice of identification constraint matters less in practice. However, this is not a full solution because, at sample sizes smaller than 500 (e.g., 100), the models with priors on ratios of loadings did not reliably converge for us. Perhaps a more reliable MCMC algorithm could be developed, but we did not pursue it here. Additionally, priors on ratios of factor loadings are not widely implemented in any software packages (they are not straightforward to implement), and the ratios can make it difficult for applied researchers to set informative priors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect coding method</head><p>Instead of placing priors on functions (ratios) of parameters, we can place identification constraints on functions of parameters so that no individual parameter is singled out as the fixed parameter. The <ref type="bibr" target="#b15">Little, Slegers, and Card (2006)</ref> effect coding method is well suited to this task. Under this method, the latent variable mean is estimated, and the model is identified via </p><formula xml:id="formula_8">I i=1 λ i I = 1<label>(13)</label></formula><formula xml:id="formula_9">I i=1 ν i = 0, (<label>14</label></formula><formula xml:id="formula_10">)</formula><p>where I is the number of unique indicators for a latent variable and the ν i are the indicator intercepts (see Fig. <ref type="figure">1</ref>). These equations state that factor loadings are constrained to average 1, and the intercepts become deviations from the grand mean of observed variables (the latent mean becomes the grand mean of observed variables). Referring specifically to Fig. <ref type="figure">1</ref>, we can use the constraints λ 1 = 3λ 2λ 3 and ν 1 = 0ν 2ν 3 . A similar strategy has been considered in Bayesian item response modeling (e.g., <ref type="bibr" target="#b2">Fox &amp; Glas, 2001)</ref>, where the sum of difficulties is restricted to equal 0 and the product (as opposed to sum) of discriminations is restricted to equal 1. Under effect coding, there are no arbitrary decisions about which parameter should be fixed to one. Thus, if a researcher were to consistently use effect coding, there are no issues with model comparison metrics systematically differing by choice of constraint. And implementation is straightforward, because packages lavaan and blavaan both allow the user to specify effect coding as the scaling option for latent variables, with default prior distributions being the same as they would be otherwise (with users being encouraged to set their own prior distributions).</p><p>However, effect coding may be unintuitive in situations where an observed variable is influenced by multiple latent variables (i.e., in a model with cross-loadings) and is not the ideal identification method here. In the case of crossloadings, we can still specify the constraints from the previous paragraph separately for each latent variable. But now an observed variable can be involved in the constraints associated with multiple latent variables, making the parameter interpretation cloudy. For example, an observed variable's intercept could be constrained to sum to 0 with other intercepts associated with one latent variable, and that same intercept could be separately constrained to sum to 0 with other intercepts associated with a second latent variable. This potentially leads to indirect dependencies between observed variable intercepts that were specified to be conditionally independent; see <ref type="bibr" target="#b15">Little et al. (2006)</ref> for some further discussion of this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example</head><p>To illustrate the identification methods' applications, we return to the <ref type="bibr" target="#b5">Holzinger and Swineford (1939)</ref> data used in our original illustration. For the ratio priors, we estimate both the UVI and three ULI models, with the ULI models corresponding to each loading being fixed to 1. We also estimate the same model under effect coding, with the <ref type="bibr" target="#b27">Raftery and Lewis (1995)</ref> automatic convergence method being used to determine the length of the chains (with three chains being used). Because the data set used for the illustration and example contains only 73 observations, we used informative prior distributions to aid in convergence. We used Normal(1,1) priors on ratios of loadings, and we used Gamma(.3, .5) priors on precisions (ψ -1 and θ -1 ).</p><p>Fit metrics for all models are presented in Table <ref type="table" target="#tab_4">5</ref>. The rows of the table denote how the model was identified and where the "1" was placed. The first three rows use ULI in conjunction with placing priors on ratios of factor loadings, the fourth row uses UVI with priors on ratios of factor loadings, and the last row uses effect coding for identification. Looking down each column, fit metric values still exhibit variability, though not as much as in the earlier illustration. Fixing the "Cubes" factor loading to 1 produces Identification method is presented in the first column, followed by each of the selected metrics larger fit metrics than the other constraints, likely because this is the smallest loading (see Table <ref type="table" target="#tab_2">3</ref>) and the ratio prior disagrees more here, as compared to models where other loadings are fixed to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General discussion</head><p>In this paper, we highlighted the fact that model identification constraints can influence Bayesian model comparison metrics in ways that would not be observed under frequentist modeling. This is potentially a problem because model identification constraints are often chosen arbitrarily, which can lead to a Bayesian model's metrics becoming artificially better or worse depending on choice of constraint. This could be viewed as an extra "researcher degree of freedom" <ref type="bibr" target="#b30">(Simmons, Nelson, &amp; Simonsohn, 2011)</ref> when conducting applied analyses: if a researcher's preferred Bayesian model does not look the best under one identification constraint, the researcher could potentially choose an alternative identification constraint to influence the results. We considered two solutions to the issue. The first involved identifying the model in the usual way (with a loading or latent variance fixed to 1), with priors being placed on ratios of factor loadings instead of individual loadings. While this solution is general, it might be difficult to conceptualize informative priors under this approach, the approach is not generally implemented in any software of which we are aware, and MCMC convergence is not optimal at small sample sizes. The second solution involved effect coding, which avoids the need to arbitrarily fix a single parameter to one. We generally recommend the use of effect coding where applicable in Bayesian SEM, both because the parameter interpretations are intuitive and because effect coding can be easily handled in software such as blavaan. However, effect coding becomes cumbersome in models with cross-loadings. Additionally, in any application, a researcher could potentially choose between effect coding, priors on ratios of loadings, or traditional priors and model parameterizations, reporting only the model that has the "best" values as compared to other candidate models. So awareness of the issues discussed here is important, paired with sensitivity analyses. Some other methods related to parameter identification should be mentioned here. The first is the parameter expansion approach of <ref type="bibr" target="#b4">Ghosh and Dunson (2009)</ref>. Under this approach, we sample from an overparameterized model where the scale of the latent variable is not set. We then impose an identification constraint as a post-processing step, leading to posterior chains that have converged. While we would set prior distributions for all parameters of the overparameterized model, the implications for the priors of the post-processed, inferential parameters may still depend on the identification constraint chosen. The second approach involves building priors around the constrained parameters, as described by <ref type="bibr" target="#b14">Levy and Mislevy (2016)</ref>. For example, if we fix a factor loading to 1 for identification, the priors for the other loadings could have a mean of 1 instead of 0, stating that the other loadings are equally likely to be larger or smaller than the constrained loading. We may still encounter problems in situations where a single loading is considerably larger than the others. If we fix that large loading to one, then our priors centered at 1 may still lead to worse information criteria values, as compared to a model where we fix a different loading to one.</p><p>Recently, new Bayesian metrics of absolute fit, including BCFI, BTLI, and BRMSEA, have been studied by <ref type="bibr" target="#b3">Garnier-Villarreal and Jorgensen (2019)</ref> and are implemented in blavaan. They are designed to approximate the traditional model fit indices, and they can also be expected to vary by choice of identification constraint because they generally involve the log-likelihood (which was examined in this paper). Thus, in addition to model comparison, the issues described here could influence a researcher's assessment of absolute fit: researchers could, e.g., improve a model's BRMSEA value by changing the identification constraint. Further research may be worthwhile here, especially in the context of the rules of thumb associated with these indices.</p><p>We also note that the identification/prior issues considered in this paper may become unimportant if one is willing to explicitly consider the uncertainty associated with model selection criteria. <ref type="bibr" target="#b38">Vehtari, Simpson, Yao, and</ref><ref type="bibr">Gelman (2019), McElreath (2015)</ref>, and others discuss the use of standard errors associated with WAIC and related metrics, pointing out that it is often inappropriate to select a single model when the differences between information criteria are small relative to the standard errors of the differences. <ref type="bibr" target="#b25">Preacher and Merkle (2012)</ref> considered related issues in the context of maximum likelihood SEM, focusing heavily on BIC. As applied to the current problem, the differences in information criteria across identification constraints will usually be small relative to the posterior uncertainty in the criteria. This implies that, if we consider posterior uncertainty, then the priors and identification constraints examined in this paper will often lead to similar inferences. However, these uncertainty estimates can be influenced by similar model predictions, misspecified models with outliers, and small sample sizes, and the uncertainty calculations are not as simple as computing the variance of posterior samples <ref type="bibr" target="#b31">(Sivula, Magnusson, &amp; Vehtari, 2020)</ref>. Thus, uncertainty estimates for Bayesian information criteria are not always available in popular software, leading many SEM researchers to use point estimates of information criteria to select a single model from a set of candidates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2</head><label>2</label><figDesc>Fig.2Distributions of priors used for simulation. The points on the graphs show the parameter estimates from<ref type="bibr" target="#b5">Holzinger and Swineford (1939)</ref> for the factor loadings and latent variance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Model preference values for the simulation with a sample size of 500 in the top graph and 1000 in the bottom. Values closer to 1 suggest the UVI model is preferred, values closer to 0 suggest the ULI model is preferred, and values around .5 suggest no model preference</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc>Fig.4Model preference comparing each ULI model to the UVI model using ratio identification method. The headings on each graph show which factor loading was set to 1 for ULI</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Fit metrics under various choices of model identification constraints</figDesc><table><row><cell></cell><cell>LogL</cell><cell>DIC</cell><cell>WAIC</cell><cell>LOOIC</cell></row><row><cell>UVI</cell><cell>-687.68</cell><cell>1396.69</cell><cell>1397.87</cell><cell>1398.06</cell></row><row><cell>ULI: Visual</cell><cell>-693.39</cell><cell>1393.70</cell><cell>1401.89</cell><cell>1402.14</cell></row><row><cell>ULI: Cubes</cell><cell>-693.34</cell><cell>1394.95</cell><cell>1403.63</cell><cell>1403.72</cell></row><row><cell>ULI: Lozenges</cell><cell>-691.59</cell><cell>1395.03</cell><cell>1400.81</cell><cell>1401.04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Simulation mean differences</figDesc><table><row><cell>Size</cell><cell>Lambda</cell><cell>iPsi</cell><cell>LogL</cell><cell>DIC</cell><cell>WAIC</cell><cell>LOOIC</cell></row><row><cell>500</cell><cell>N(0,10)</cell><cell>Gamma(1,.5)</cell><cell>-0.08</cell><cell>-0.13</cell><cell>-0.20</cell><cell>-0.20</cell></row><row><cell>1000</cell><cell>N(0,10)</cell><cell>Gamma(1,.5)</cell><cell>-0.04</cell><cell>-0.06</cell><cell>-0.09</cell><cell>-0.09</cell></row><row><cell>500</cell><cell>N(0,1)</cell><cell>Gamma(1,.5)</cell><cell>1.12</cell><cell>2.07</cell><cell>2.08</cell><cell>2.08</cell></row><row><cell>1000</cell><cell>N(0,1)</cell><cell>Gamma(1,.5)</cell><cell>0.61</cell><cell>1.11</cell><cell>1.11</cell><cell>1.11</cell></row><row><cell>500</cell><cell>N(0,10)</cell><cell>Gamma(.5,2)</cell><cell>-0.06</cell><cell>-0.06</cell><cell>-0.12</cell><cell>-0.12</cell></row><row><cell>1000</cell><cell>N(0,10)</cell><cell>Gamma(.5,2)</cell><cell>-0.03</cell><cell>-0.03</cell><cell>-0.06</cell><cell>-0.06</cell></row><row><cell>500</cell><cell>N(0,1)</cell><cell>Gamma(.5,2)</cell><cell>1.16</cell><cell>2.17</cell><cell>2.18</cell><cell>2.18</cell></row><row><cell>1000</cell><cell>N(0,1)</cell><cell>Gamma(.5,2)</cell><cell>0.62</cell><cell>1.15</cell><cell>1.16</cell><cell>1.16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Asymptotic marginal maximum likelihood parameter estimates</figDesc><table><row><cell cols="2">Fixed Parameter Psi</cell><cell cols="2">Lambda1 Lambda2 Lambda3</cell></row><row><cell>UVI: Latent</cell><cell>1 (0)</cell><cell cols="2">4.91 (0.05) 2.96 (0.03) 6 (0.05)</cell></row><row><cell>Variance</cell><cell></cell><cell></cell></row><row><cell>ULI: Visual</cell><cell cols="2">24.13 (0.45) 1 (0)</cell><cell>0.6 (0.01) 1.22 (0.02)</cell></row><row><cell>ULI: Cubes</cell><cell cols="3">8.77 (0.17) 1.66 (0.02) 1 (0)</cell><cell>2.02 (0.03)</cell></row><row><cell cols="4">ULI: Lozenges 35.96 (0.64) 0.82 (0.01) 0.49 (0.01) 1 (0)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Fit metric values for model with mean shifted, informative priors</figDesc><table><row><cell>Value</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>Fit metric values when applying the ratio identification and effect coding to the example spatial ability data</figDesc><table><row><cell></cell><cell>LogL</cell><cell>DIC</cell><cell>WAIC</cell><cell>LOOIC</cell></row><row><cell>ULI: Visual</cell><cell>-687.82</cell><cell>1394.11</cell><cell>1395.45</cell><cell>1395.61</cell></row><row><cell>ULI: Cubes</cell><cell>-687.95</cell><cell>1395.96</cell><cell>1396.83</cell><cell>1397.01</cell></row><row><cell>ULI: Lozenges</cell><cell>-687.84</cell><cell>1393.53</cell><cell>1394.84</cell><cell>1395.00</cell></row><row><cell>UVI: Latent Variance</cell><cell>-687.73</cell><cell>1394.39</cell><cell>1395.59</cell><cell>1395.76</cell></row><row><cell>Effect Coding</cell><cell>-687.77</cell><cell>1393.94</cell><cell>1395.05</cell><cell>1395.20</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Behav Res (2022) 54:795-804</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">runjags: An R package providing interface utilities, model templates, parallel computing methods and additional distributions for MCMC models in JAGS</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Denwood</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v071.i09</idno>
		<ptr target="https://doi.org/10.18637/jss.v071.i09" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Fox</surname></persName>
		</author>
		<title level="m">Bayesian item response modeling: Theory and applications</title>
		<meeting><address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bayesian estimation of a multilevel IRT model using Gibbs sampling</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A W</forename><surname>Glas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="271" to="288" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adapting fit indices for Bayesian structural equation modeling: Comparison to maximum likelihood</title>
		<author>
			<persName><forename type="first">M</forename><surname>Garnier-Villarreal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Jorgensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Default prior distributions and efficient posterior computation in Bayesian factor analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="306" to="320" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A study in factor analysis: The stability of a bi-factor solution</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Holzinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Swineford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1939">1939</date>
		</imprint>
	</monogr>
	<note>Supplementary Educational Monographs</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A general approach to confirmatory maximum likelihood factor analysis</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Author&apos;s addendum</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in factor analysis and structural equation models</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Magidson</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Abt Books</publisher>
			<date type="published" when="1979">1979</date>
			<biblScope unit="page" from="40" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Bayesian statistics for the social sciences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>The Guildford Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">MBESS: The MBESS R Package</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kelley</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=MBESS" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Computer software manual. R package version 4.4.3</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Principles and practice of structural equation modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Kline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Guilford Publications</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Explaining constraint interaction: How to interpret estimated model parameters under alternative scaling methods</title>
		<author>
			<persName><forename type="first">S</forename><surname>Klößner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Klopp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="155" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Structural equation modeling: A Bayesian approach</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Wiley</publisher>
			<pubPlace>Chichester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evaluation of the Bayesian and maximum likelihood approaches in analyzing structural equation models with small sample sizes</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="653" to="686" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bayesian psychometric modeling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mislevy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>Boca Raton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A nonarbitrary method of identifying and scaling latent variables in SEM and MACS models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Slegers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Card</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15328007sem1301_3</idno>
		<ptr target="https://doi.org/10.1207/s" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="72" />
			<date type="published" when="2006">2006. 15328007sem1301 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Statistical rethinking: A Bayesian course with examples in R and Stan</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mcelreath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<pubPlace>Boca Raton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bayesian comparison of latent variable models: Conditional versus marginal likelihoods</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Furr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rabe-Hesketh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="802" to="829" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">blavaan: Bayesian structural equation models via parameter expansion</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v085.i04</idno>
		<ptr target="https://doi.org/10.18637/jss.v085.i04" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian structural equation modeling: a more flexible representation of substantive theory</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">313</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Newsom</surname></persName>
		</author>
		<title level="m">Longitudinal structural equation modeling: a comprehensive introduction</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Equality in constraints and metricsetting measurement models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Bayesian exploratory and confirmatory factor analysis: Perspectives on constrained-model selection (Unpublished doctoral dissertation)</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F W</forename><surname>Peeters</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<pubPlace>Utrecht University</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rotational uniqueness conditions under oblique factor correlation metric</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F W</forename><surname>Peeters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="288" to="292" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Plummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international workshop on distributed statistical computing</title>
		<meeting>the 3rd international workshop on distributed statistical computing</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">124</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The problem of model selection uncertainty in structural equation modeling</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Preacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0026804</idno>
		<ptr target="https://doi.org/10.1037/a0026804" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing</title>
		<author>
			<orgName type="collaboration">R Core Team</orgName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
	<note>Computer software manual</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The number of iterations, convergence diagnostics and generic metropolis algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Raftery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">lavaan: An R package for structural equation modeling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<ptr target="http://www.jstatsoft.org/v48/i02/" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">To Bayes or not to Bayes, from whether to when: Applications of Bayesian methodology to modeling</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Zumbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="424" to="451" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797611417632</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1359" to="1366" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Uncertainty in Bayesian leave-one-out cross-validation based model comparison</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sivula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.10296</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Basic and advanced Bayesian structural equation modeling: With applications in the medical and behavioral sciences</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Wiley</publisher>
			<pubPlace>Chichester</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bayesian measures of model complexity and fit</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Linde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="583" to="639" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">When constraints interact: a caution about reference variables, identification constraints, and scale dependencies in structural equation modeling</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Steiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A systematic review of Bayesian articles in psychology: The last 25 years</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zondervan-Zwijnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="217" to="239" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Bürkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Paananen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<ptr target="https://mc-stan.org/loo/" />
		<title level="m">Efficient leave-one-out cross-validation and WAIC for Bayesian models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>R package version 2.4.1</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1413" to="1432" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Limitations of &quot;limitations of Bayesian leave-one-out cross-validation for model selection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Brain &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="27" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3571" to="3594" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">ggplot2: Elegant graphics for data analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<ptr target="http://ggplot2.org" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
