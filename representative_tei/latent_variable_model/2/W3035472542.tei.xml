<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dialogue State Induction Using Neural Latent Variable Models</title>
				<funder>
					<orgName type="full">Westlake University</orgName>
				</funder>
				<funder ref="#_N9NGCDa">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qingkai</forename><surname>Min</surname></persName>
							<email>minqingkai@westlake.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="institution">Westlake University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Institute of Advanced Technology</orgName>
								<orgName type="department" key="dep2">Westlake Institute for Advanced Study 3 Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Libo</forename><surname>Qin</surname></persName>
							<email>lbqin@ir.hit.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Zhiyang</forename><surname>Teng</surname></persName>
							<email>tengzhiyang@westlake.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="institution">Westlake University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Institute of Advanced Technology</orgName>
								<orgName type="department" key="dep2">Westlake Institute for Advanced Study 3 Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
							<email>xiaoliu@bit.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<email>zhangyue@westlake.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Engineering</orgName>
								<orgName type="institution">Westlake University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Institute of Advanced Technology</orgName>
								<orgName type="department" key="dep2">Westlake Institute for Advanced Study 3 Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Dialogue State Induction Using Neural Latent Variable Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dialogue state modules are a useful component in a task-oriented dialogue system. Traditional methods find dialogue states by manually labeling training corpora, upon which neural models are trained. However, the labeling process can be costly, slow, error-prone, and more importantly, cannot cover the vast range of domains in real-world dialogues for customer service. We propose the task of dialogue state induction, building two neural latent variable models that mine dialogue states automatically from unlabeled customer service dialogue records. Results show that the models can effectively find meaningful dialogue states. In addition, equipped with induced dialogue states, a state-ofthe-art dialogue system gives better performance compared with not using a dialogue state module.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dialogue state modules are a central component to a taskoriented dialogue system <ref type="bibr" target="#b8">[Wen et al., 2017;</ref><ref type="bibr">Lei et al., 2018]</ref>. Given a user utterance and existing dialogue history, a dialogue system typically extracts dialogue states, according to which a system response is generated. An example is shown in Figure <ref type="figure" target="#fig_0">1</ref>, given two turns of a dialogue, the first user utterance is "I want an expensive restaurant that serves Turkish food.", and the dialogue states consist of the slot-value pairs inform(price=expensive, food=Turkish). As the dialogue proceeds, the dialogue state is updated at each turn. After tow dialogue turns, the dialogue state becomes inform(price=expensive, food=Turkish); request(area), where inform represents the search constraints expressed by user and request represents the search target that the user is asking for. In this example, the user intention is to reserve a restaurant. The business domain is restaurant customer service. The dialogue state represents what the user is looking for at the current turn of the conversation.</p><p>Prior work has mostly followed a manual labeling-traintest paradigm, which begins with the design of annotation guidelines, followed by the collection and manual labeling of training corpora, before training a model.  et <ref type="bibr">al., 2010]</ref>. One limitation for supervised learning is that the manual labeling process can be slow and costly given a certain domain of customer service. Available datasets are labeled on a few popular domains such as restaurant, taxi, train and hotel <ref type="bibr" target="#b10">[Williams et al., 2014;</ref><ref type="bibr" target="#b0">Budzianowski et al., 2018;</ref><ref type="bibr" target="#b7">Rastogi et al., 2019]</ref>. However, in practice, the number of customer service domains ranges far beyond hundreds (e.g. telecommunication customer service, banking, household maintenance, police, e-commercial customer service, etc), which makes it infeasible to manually label corpora for every domain. In addition, it has been shown that the ratio of annotation errors can be as high as 30% and even 40% for the DST task (i.e., the MultiWOZ datasets) <ref type="bibr" target="#b2">[Eric et al., 2019;</ref><ref type="bibr">Zhang et al., 2019]</ref>.</p><p>To address this issue, it can be useful to automatically induce dialogue states from raw dialogues. We assume that there is a large set of dialogue records of many different domains, but without manual labeling of dialogue states. Such data are relatively easy to obtain, for example from customer service call records from different businesses. Consequently, we propose the task of dialogue state induction (DSI), which is to automatically induce slot-value pairs from raw dialogue data and can be better used for downstream dialogue tasks such as database query, act prediction and response generation. The difference between DSI and DST is illustrated in Figure <ref type="figure" target="#fig_0">1</ref>. Similar to DST models, DSI outputs dialogue states in slot-value pairs such as inform(price=expensive), where price represents a slot, and expensive represents a value. For requestable slots such as request(area), request is regarded as the slot and area is regarded as the value.</p><p>During training, DST relies on both a dialogue record and manual labeling of slot-value pairs on the dialogues. In contrast, our task does not rely on manual labeling and can generate slot-value pairs over raw dialogues automatically.</p><p>We introduce two neural latent variable models for DSI by treating the whole state and each slot as latent variables, from which values observed in dialogue data are generated. The goal is to induce slots according to those frequently cooccurring values and the dialogue contexts. In particular, each value (i.e., phrase in raw text) is represented by using both a sparse one-hot representation and a dense contextualized embedding representation. Both models are generative probabilistic models, which generate a value by first generating a latent dialogue state vector, and then generating a slot. The difference between the two models is the modeling of service domains. We observe that different service domains may contain slots with similar contexts or values. For example, both taxi and bus domains can have the same slot to location. In order not to mix their structures from a large dialogue record, our second model further considers the service domain explicitly by taking the dialogue state as a Mixture-of-Gaussians. We refer to the basic model DSI-base and the advanced model DSI-GM.</p><p>Experiments over the MultiWOZ <ref type="bibr" target="#b0">[Budzianowski et al., 2018]</ref> and the SGD <ref type="bibr" target="#b7">[Rastogi et al., 2019]</ref> datasets show that both DSI models can effectively induce dialogue states compared with a random select strategy. In addition, the Gaussian mixture model gives significantly better results compared with the basic model. Finally, we apply DSI to a recently proposed dialogue system <ref type="bibr">[Chen et al., 2019]</ref>, by replacing the dialogue state module with our DSI-GM model. Results show that adding induced dialogue states gives significantly better results in both dialogue act prediction and response BLEU compared with a dialogue system without considering dialogue states. In particular, the BLEU score using the DSI-GM model outputs is better by 2.1% compared with not using dialogue states, and lower by 0.8% compared with using manual labeling dialogue states. This shows that by inducing dialogue states, improved dialogue systems can be obtained. To our knowledge, we are the first to automatically induce dialogue states in the form of slot-value pairs using a neural latent variable model. Our models can serve as baselines for further research. We release our code at <ref type="url" target="https://github.com/taolusi/dialogue-state-induction">https://github.com/taolusi/dialogue-state-induction</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The role of DST and DSI in task-oriented dialogue systems. Task-oriented dialogue systems are complex, traditionally involving a pipeline of multiple steps, including automatic speech recognition (ASR) <ref type="bibr" target="#b8">[Wen et al., 2017]</ref>, spoken language understanding (SLU) <ref type="bibr" target="#b7">[Qin et al., 2019]</ref>, dialogue state tracking (DST) <ref type="bibr" target="#b12">[Zhong et al., 2018]</ref>, policy learning and natural language generation (NLG) <ref type="bibr">[Chen et al., 2019]</ref>. SLU consistes of two main sub-tasks, namely intent detection, which is to identify the user intent such as hotel booking, and slot tagging, which is to identify relevant semantic slots in a user utterance, such as price and stars. Dialogue state tracking aims to identify user goals at every turn of the dialogue, such as inform(price=moderate, stars=4); request(phone), which makes the core component in a task-oriented dialogue system. Policy learning aims to learn the system action based on the current state. Natural language generation transforms the system action into natural language.</p><p>Recently, some work on task-oriented dialogue systems takes an overall end-to-end method, by encoding the user utterance and dialogue history, and then generating a response directly using a seq2seq model variant, without explicitly maintaining dialogue states <ref type="bibr" target="#b1">[Eric and Manning, 2017;</ref><ref type="bibr" target="#b7">Qin et al., 2020]</ref>. Compared to such work, we show that automatically inducing dialogue states can improve dialogue performance, which is consistent with observations of DST research <ref type="bibr">[Lei et al., 2018;</ref><ref type="bibr" target="#b9">Wen et al., 2018]</ref>. <ref type="bibr" target="#b8">Wen et al. [2017]</ref> pioneered this line of work by proposing a typical modularly connected end-to-end trainable task-oriented dialogue system directly based on text without considering the speech recognition noise and thus ignored the component of SLU to obtain the dialogue state.</p><p>DST vs SLU. In a traditional pipeline, DST operates on SLU output to update the dialogue state dealing with noise from ASR and SLU. In particular, SLU can give an N-Best list of semantic representations based on the N-Best list of sentences from ASR. DST handles all these uncertainties, e.g. error propagation, to update the dialogue state. However, the recent datasets are collected based on text without taking noisy speech inputs into consideration, which has made the task of slot tagging in SLU and the task of DST rather separately investigated. The correlation between recent slot tagging work and DST work can be subtle, and there is little discussion in the literature about their fundamental differences. In practice, widely used datasets for SLU include ATIS <ref type="bibr" target="#b2">[Hemphill et al., 1990]</ref>, while for DST include Multi-WoZ <ref type="bibr" target="#b0">[Budzianowski et al., 2018]</ref>. For latter datasets, there is not labeling of the SLU task. Recently, DST research has taken end-to-end methods, without considering SLU as a preprocessing step. Compared with SLU, our work is more in line with current neural DST work, with DSI being a direct alternative to DST in zero-shot training scenarios.</p><p>DSI vs robust DST. Existing work on DST integrates dialogue states by manually labeling more or less. Compared to these methods, our method has exactly the same setting as end-to-end DST, which is more cost-effective. Traditional supervised models for dialogue state tracking regard the task Utterance 1: I would like a guesthouse rather than a star hotel. <ref type="bibr" target="#b0">[Chen et al, 2013;</ref><ref type="bibr" target="#b7">Shi et al, 2018]</ref>: hotel_type=guesthouse, hotel_type=star hotel DSI (representation of user intent): inform(hotel_type=guesthouse) Utterance 2: I want a flight from Chicago to Dallas. <ref type="bibr" target="#b0">[Chen et al, 2013;</ref><ref type="bibr" target="#b7">Shi et al, 2018]</ref>: city=Chicago, city=Dallas DSI (more fine-grained): inform(depature_city=Chicago, destination_city=Dallas) as a multi-class classification problem <ref type="bibr" target="#b6">[Mrkšić et al., 2015]</ref>. Given a user utterance and existing dialogue history, a model predicts the corresponding value (or None) of each slot. However, such methods cannot predict the existence of unknown slot values. Consequently, recent work begins to investigate value generation from scratch <ref type="bibr">[Ren et al., 2019]</ref>. Such methods reduce the decoding complexity by avoiding the enumeration of all possible slots and values. However, the models still rely on supervised data for training. Our method employs the same decoding efficiency, yet additionally does not require labeled corpora.</p><p>DSI is also related to domain adaptations of DST in handling unknown data. Supervised methods consider multidomain settings by parameter sharing <ref type="bibr">[Wu et al., 2019a]</ref>. Such methods cannot deal with unknown domains, which are dominant in practice. Some work considers zero-shot learning, transferring knowledge from known domains to unknown domains without labels <ref type="bibr" target="#b7">[Rastogi et al., 2019]</ref>. One constraint of such methods is that they rely on domain similarity for transfer, and therefore cannot be applied to general domains. In addition, they rely on schema-level slot descriptions for capturing domain correlation, which requires manual labeling and for which the quality is difficult to control. In contrast, our method can be directly used to induce dialogue states from arbitrary dialogue records.</p><p>Induction methods. The closest in spirit of our work, Chen et al.</p><p>[2013] used the FrameNet-style frame-semantic parsers to induce slots from a user utterance; Shi et al. <ref type="bibr">[2018]</ref> proposed a framework auto-dialabel to cluster noun words into slots. Compared with their work, our work is different in two main aspects. First, the problems that we solve are different, which can be seen in Figure 2. In particular, given the utterance "I would like a guesthouse rather than a star hotel.", the user intent is to book a hotel, the slots include hotel type=guesthouse and hotel type=star hotel, and the dialogue state is inform(hotel type=guesthouse). Given the sentence "I want a flight from Chicago to Dallas", the user intent is to book a flight, the slots include city=Chicago and city=Dallas, and the dialogue state is inform(departure city=Chicago, destination city=Dallas). From the two examples we can see that DSI not only reflects the user goals but also is more specific to the current dialogue state, while their methods are more general to the semantics. Our task is directly useful for subsequent policy learning and response generation tasks. Second, we consider a deep neural model with hidden variables and contextualized embeddings, which also adapts better to the multi-domain scenario.</p><p>3 Task Definition: Dialogue State Induction Given a set of customer service records without annotation (e.g. user intent and dialogue states or other manual labeling), the task is to automatically discover information that the user is looking for at each turn. We call this automatic discovery process dialogue state induction (DSI). In particular, at each turn, the current user utterance and dialogue history can be used as input, and the output is a set of slot-value pairs, namely, the dialogue state. Turn-level vs joint-level dialogue state. By definition, a dialogue state should reflect the user goal from the beginning of the dialogue until the current turn. We call this a joint-level dialogue state. In practice, DST research has also investigated the extraction of local user goal at each dialogue turn, which we call a turn-level state. Our models produce dialogue state for each dialogue turn, where the input is the current user utterance and its preceding system utterance, and the output is a set of slot-value pairs. For multi-turn dialogues, the current dialogue state should reflect the whole dialogue history, as problem definition specifies. Following <ref type="bibr" target="#b12">Zhong et al. [2018]</ref>, we handle this issue by simply using the union of slot-value pairs in each history dialogue turn for representing the current dialogue state. When there are multiple values for one slot, we use the latest value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>We build two incrementally more complex neural latent variable models for DSI. The models induce dialogue state over a dialogue turn according to a generate process from slots to candidate values, where candidate values are represented by both one-hot vectors and contextualized embedding vectors. The two types of representations are complementary to each other, with the latter also containing features from a global context. In particular, the current user utterance and its preceding system utterance are concatenated (in their chronical order, with the latter before the former) and fed as input to a pre-trained ELMo model to obtain the contextualized word embedding vector<ref type="foot" target="#foot_1">foot_1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Values</head><p>Both methods are generative models that induce slot-value pairs over candidate values over a dialogue dataset. We follow Goel et al. <ref type="bibr">[2019]</ref> and extract possible values from local conversation contexts before assigning them to slots. We take a different method to this end. In particular, we use the model of <ref type="bibr" target="#b0">Cui and Zhang [2019]</ref> to extract POS tags and the Stanford CoreNLP toolkit to extract named entities and coreferences. A set of rules are used to extract candidate values given the POS and entity patterns including filtering stopwords, repeated candidates and non-representative entity mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model 1: DSI-base</head><p>Our first model is shown in Figure <ref type="figure" target="#fig_2">3</ref> (as represented by both a one-hot vector and a contextualized dense vector) from a structured slot frame, distributed according to a hidden vector variable z. This framework follows the variational dense embedding method of <ref type="bibr" target="#b4">Kingma and Welling [2014]</ref>. In particular, z is treated as a Gaussian vector, with the mean and variance factors themselves being decided according to the observed values. As a result, its training follows a variational auto-encoder scheme. Given a corpus of user turns T , for each turn t ∈ T , there is a set of candidate values C t . We first sample a latent state vector z from a global Gaussian distribution. Then a neural network f s (z; θ) takes z as input to encode slot distribution logits, sampling a discrete slot assignment vector s corresponding to each candidate c ∈ C t in turn t. Last, for each candidate, we sample a one-hot vector oh from a categorical distribution parameterized by the output of a neural network f oh (s; α), as well as a contextualized word embedding vector ce from a multivariable Gaussian distribution parameterized by the output of a neural network f ce (s; β).</p><p>In particular, for the latent state z, the Gaussian distribution is parameterized by a mean vector µ and a diagonal covariance matrix σ 2 . Suppose that there are S slots. The categorical slot distribution for each candidate c is parameterized by a probability vector γ ∈ R S . For each slot s, the Gaussian distribution for the contextualized embedding ce is parameterized by a mean vector µ s ∈ R n and a diagonal vector of covariance matrix σ s ∈ R n , where n represents the dimension of ce. Further, the categorical distribution for the one-hot vector oh is parameterized by a probability vector λ s ∈ R V , where V is the candidate value vocabulary size. All the parameters are obtained through neural networks.</p><p>The generative process is shown in Algorithm 1. Accordingly, the joint probability for a turn t can be factorized as:</p><formula xml:id="formula_0">p(t) = p(z) c∈Ct p(s|z)p(oh|s)p(ce|s)<label>(1)</label></formula><p>where the probability terms are defined as: µ and σ 2 are the parameters of a Gaussian prior distribution. γ, λ s , µ s and σ 2 s are calculated as:</p><formula xml:id="formula_1">p(z) = N z|µ, σ 2 (2) p(s|z) = Cat(s|γ) (3) p(oh|s) = Cat(oh|λ s ) (4) p(ce|s) = N ce|µ s , σ 2 s (5)</formula><formula xml:id="formula_2">γ = softmax(W γ z + b γ ) (6) λ s = softmax(W λ s + b λ ) (7) µ s = BN(W µ s + b µ ) (8) σ s = BN(W σ s + b σ ) (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model 2: DSI-GM</head><p>A limitation of DSI-base is that sampling a latent state vector z from a global Gaussian distribution does not sufficiently model the fact that different domains may have different distributions. For those slots that appear in different domains (for example, slot name appear both in domain restaurant and hotel with similar utterance contexts), it can be difficult for DSI-base to distinguish them correctly. We apply a Gaussian Mixture Model (GMM) in DSI-base by assuming the state vector is generated from a Mixture-of-Gaussians, in which each Gaussian represents a domain. This is inspired by Variational Deep Embedding (VaDE) <ref type="bibr" target="#b3">[Jiang et al., 2017]</ref>, which combines VAE and GMM for a clustering task. Specifically, suppose that there are K domains. As shown in Figure <ref type="figure" target="#fig_2">3</ref>(b), we first sample a domain d from a categorical distribution parameterized by π ∈ R K , where π d is the prior probability for domain d and K d=1 π d = 1. The latent state vector z is sampled from a Gaussian distribution with parameters of a mean vector µ d and a covariance vector σ d corresponding to the chosen domain d. The latent state vector is then used for sampling a slot vector for each candidate in a turn, in the same way as DSI-base. According to the generative process shown in Algorithm 2, the joint probability for a user turn t is</p><formula xml:id="formula_3">p(t) = p(d)p(z|d) c∈Ct p(s|z)p(oh|s)p(ce|s), (<label>10</label></formula><formula xml:id="formula_4">)</formula><p>where the additional probabilities are defined as:</p><formula xml:id="formula_5">p(d) = Cat(d|π) (11) p(z|d) = N z|µ d , σ 2 d (12)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Inference</head><p>Given the generative process of DSI-GM, following <ref type="bibr">Liu et al. [2019a]</ref>, we collapse the discrete slot latent variable s and rewrite the joint log-likelihood as:</p><formula xml:id="formula_6">log p(t) = log z d p(d)p(z|d) c∈Ct p(oh|z)p(ce|z)dz ≥ E q(z,d|t) [log p(t, z, d) q(z, d|t) ] = L ELBO (t)<label>(13)</label></formula><p>where L ELBO is the evidence lower bound (ELBO). Since direct optimization and inference for Equation 13 is intractable. We follow previous work <ref type="bibr" target="#b4">[Kingma and Welling, 2014;</ref><ref type="bibr" target="#b3">Jiang et al., 2017]</ref> and use a variational posterior distribution q(z, d|t) to approximate the true posterior distribution p(z, d|t). By assuming a mean field distribution <ref type="bibr" target="#b11">[Xing et al., 2003]</ref>, q(z, d|t) can be factorized as q(z|t)q(d|t). The posterior q(z|t) can be modeled using a multivariate Gaussian distribution, with the mean vector µ d and the variance vector σ d obtained through a neural network as shown in Figure <ref type="figure" target="#fig_3">4</ref>. q(d|t) is calculated as follows:</p><formula xml:id="formula_7">p(d|t) = p(d|z) ≡ p(d)p(z|d) K d =1 p(d )p(z|d )<label>(14)</label></formula><p>Using the reparameterization trick <ref type="bibr" target="#b4">[Kingma and Welling, 2014]</ref>, the ELBO can be decomposed into a reconstruction term and a regularization term, respectively:</p><formula xml:id="formula_8">L ELBO (t) = E q(z,d|t) [log p(t|z)] -D KL (q(z, d|t)||p(z, d))</formula><p>(15) where D KL (q(z, d|t)||p(z, d)) is the KL divergence between the Mixture-of-Gaussians prior p(z, d) and variational posterior q(z, d|t).</p><p>After training, the domain and slot assignment for each candidate c can be obtained by Equation <ref type="formula" target="#formula_7">14</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DSI-Based Response Generation</head><p>We apply the DSI models on the task of downstream response generation, following the pipeline system which was first proposed by Wen et al.</p><p>[2017] and then decomposed into two components by Chen et al. <ref type="bibr">[2019]</ref>. As shown in Figure <ref type="figure" target="#fig_4">5</ref>, the top component consists of the dialogue state module and database operation module, while the bottom component contains the dialogue act prediction module and response generation module. For the bottom component, we directly take the recently proposed HDSA model <ref type="bibr">[Chen et al., 2019]</ref> to test our induced dialogue states.</p><p>For the top component, we investigate three different settings of the dialogue state module: (i) empty dialogue states under the condition that no annotation is available (grey oval), (ii) dialogue states induced by our mixture model (green oval), (iii) dialogue states obtained by manual labeling (golden oval). In the last two settings, the dialogue states are regarded as input for subsequent modules, while in the first setting, no state information is given, which corresponds to end-to-end models [Eric and <ref type="bibr" target="#b1">Manning, 2017;</ref><ref type="bibr">Wu et al., 2019b]</ref> for dialogue system. The first setting is used to test the effectiveness of our model, while the third setting can be regarded as the oracle upper bound of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We evaluate our proposed DSI task and its effectiveness on the downstream tasks using the MultiWOZ 2.1 <ref type="bibr" target="#b2">[Eric et al., 2019]</ref> dataset, which fixes some noisy state annotations in the MultiWOZ 2.0 <ref type="bibr" target="#b0">[Budzianowski et al., 2018]</ref> dataset. Mul-tiWOZ2.1 contains 10,438 multi-turn dialogues and we follow the same partition as <ref type="bibr">Wu et al. [2019a]</ref>. To justify the generalization of the proposed model, we also use a recently proposed SGD <ref type="bibr" target="#b7">[Rastogi et al., 2019]</ref> dataset, which contains 16,142 multi-turn dialogues and is the largest existing conversational corpus. We use the same train/validation split sets as Rastogi et al. <ref type="bibr">[2019]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Settings</head><p>For the DSI models, the Adam optimizer is used to maximize the ELBO of Equation <ref type="formula">15</ref>. All the models are trained over the training set, where hyper-parameters are tuned on the development set, before being finally used on the test set. Since no manual labels are available, we follow <ref type="bibr">Liu et al. [2019a]</ref> and select the hyper-parameters which fit the best ELBO score on the dev set as shown in Table <ref type="table" target="#tab_3">2</ref>. For the downstream HDSA model, we directly take the original hyper-parameters. Since our datasets are manually labeled with domains and slots (restaurant-name), we can name the induced slots after the gold-standard slots that have the maximum value match.</p><p>In addition, in the datasets, each slot is labeled with a service domain, and thus we obtain a domain output also.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation Metrics</head><p>DSI For each turn, DSI-base and DSI-GM induce several or no slot-value pairs based on the current user utterance and its preceding system utterance. We compare the DSI outputs with the slots that have non-empty assignments in the ground truth dialogue states for the current user turn. We consider the following two metrics<ref type="foot" target="#foot_3">foot_3</ref> : 1. State Matching (Precision, Recall and F1-score in Table 1): Similar to previous work <ref type="bibr">[Liu et al., 2019a]</ref>, we use state matching to evaluate the overlapping of induced states and the ground truth. 2. Goal Accuracy (Accuracy in Table <ref type="table" target="#tab_2">1</ref>): We adopt this standard metric from DST <ref type="bibr">[Wu et al., 2019a;</ref><ref type="bibr" target="#b12">Zhong et al., 2018]</ref>. The predicted dialogue states for a turn is considered as true only when all the user search goal constraints are correctly and exactly identified. We evaluate both metrics in both the turn level and the joint level (Table <ref type="table" target="#tab_2">1</ref>). The joint level metrics are more strict in jointly considering the output of all turns. Response generation Following Chen et al. <ref type="bibr">[2019]</ref>, the dialogue act prediction results are evaluated in terms of Precision, Recall and F1-score. Delexicalized-BLEU and Entity F1 are used to evaluate response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSI Performance</head><p>The DSI results are shown in Table <ref type="table" target="#tab_2">1</ref>. We have four main observations:</p><p>• Both DSI models show great advantages over a random select strategy, which randomly assigns a reference slot for each candidate. This shows the strength of our neural generative models with hidden variables. • DSI-GM outperforms DSI-base on both the turn level and joint level metrics, which demonstrates the effectiveness of the GMM model, which finds an appropriate domain first before sampling a latent state representation. We attribute this to the fact that the dialogue states can be more effectively regarded as a hierarchical structure (i.e., domain-slot-value) and hence first detecting a domain and then a slot under this domain can help alleviate the difficulty of distinguishing the appropriate slot in a large mixture of similar slot values. • The joint goal accuracy is significantly lower compared with the other metrics, which shows that the metric can be overly strict in our unsupervised setting. This is a consistent observation of recent work on cross-lingual dialogue state tracking <ref type="bibr">[Liu et al., 2019b]</ref>, which shows that the joint goal accuracy of a cross-lingual DST model can be as low as 11% on accuracy even with crosslingual contextualized embeddings. Furthermore, the joint goal F1-score can reach 44.8% on MultiWOZ dataset, which shows that our model can achieve promising performance without any labeled training data. • The results among all metrics on the SGD dataset are lower than those on the MultiWOZ2.1 dataset. We attribute it to this reason that the SGD dataset is more difficult than the MultiWOZ dataset because it contains more types of domains and slots (16 domains and 214 slots as compared with 7 domains and 24 slots in MultiWOZ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DAP and Response Generation</head><p>The dialogue act prediction (DAP) and response generation results are shown in Table 3. Compared to not using dialogue states, the outputs of DSI-GM allows a subsequent model <ref type="bibr">[Chen et al., 2019]</ref> to improve the F1-score of dialogue act prediction by 2.1%, and further improve the BLEU and entity F1 for a system output utterance by 2.1% and 1.9%, respectively. This shows that maintaining dialogue states can be useful in neural dialogue systems, as consistent with observations from DST research <ref type="bibr">[Lei et al., 2018;</ref><ref type="bibr" target="#b9">Wen et al., 2018]</ref>. The results demonstrate that DSI is a useful task in dialogue systems research and our baseline models are effective. In Table <ref type="table" target="#tab_4">3</ref>, the gap between DSI-GM and manual labeling indicates further rooms for improvement on the dialogue model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">DSI-GM vs. DSI-base</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain Accuracy</head><p>We measure the fraction of user turns for which the domains are correctly induced for all candidates. Figure <ref type="figure">6</ref> shows the comparison between the DSI-base model and the DSI-GM model. We can see that the DSI-GM outperforms the DSI-base on each domain, which demonstrates that explicitly modeling the domain distribution is effective across all domains. In addition, to better intuitively know how much better the domain representation can be modeled through DSI-GM, we visualize the learned state representations of DSI-base and DSI-GM only with its domain label. In particular, we use t-SNE to reduce the dimensionality of the latent representation z and plot the whole test set in Figure <ref type="figure">7</ref>. Compared with DSI-base, whose latent state representations are mixed in the domain level, DSI-GM shows its superiority in representing different domains, as representations are clustering in a more orderly way. This further demonstrates the effectiveness of GMM applied in our task.</p><p>Case Study Figure <ref type="figure">8</ref> shows a case on the dialogue states induced by DSI-base and DSI-GM. In this case, both the attraction and restaurant domains consist of a name slot, which shares similar contexts such as "Can i get the address for". This can make their contextualized features similar although the two name slots should be treated as two distinct types. DSI-base generates an incorrect domain attraction while DSI-GM induces the correct domain restaurant. We attribute it to  the fact that the DSI-GM model captures domain information by explicitly modeling the multi-domain distribution through a Mixture-of-Gaussians instead of a global Gaussian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Error Analysis</head><p>We present the accuracies on each domain between DSI-base and DSI-GM. The results are shown in Table <ref type="table" target="#tab_5">4</ref>. Both DSIbase and DSI-GM give the lowest accuracy on the hotel domain and a relatively higher accuracy on the attraction domain. To further understand the reason, we calculate the statistics of slots on the hotel and attraction domains, which are shown in Figure <ref type="figure" target="#fig_6">9</ref>. It can be seen that the numbers of dominant slot types of the two domains are 10 and 3, respectively, correctly recognizing which can give strong overall accuracies. In both domains, these slots are distributed evenly. This indicates that the number of distinct slots is a key factor to the difficulty level for our DSI models, which is intuitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We proposed a novel task of dialogue state induction, which is to automatically identify dialogue state slots and values over a large set of dialogue records. Compared with existing research, our task is practically more useful for handling the large variety of services available in the industry, which disallows scalable manual labeling of dialogue states. We further built two neural generative models with latent variables. Results on standard DST datasets show that the models can effectively induce meaningful dialogue states from raw dialogue data, and further improve the results of a dialogue system compared to without using dialogue states. Our methods can serve as baselines for further research on the task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison between DSI and traditional DST. The strikethrough font is used to represent the resources not needed by DSI. The dialogue state is accumulated as the dialogue proceeds. Turns are separated by dashed lines. Dialogues and external ontology are separated by black lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison between DSI and previous induction methods for SLU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of DSI models. (T -# of user turns; C -# of candidates per turn. d and s are discrete latent variables, z is a continuous latent variable. oh and ce are observed data.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An encoder network is used to maximize the ELBO of DSI-base and DSI-GM. "LT" denotes linear transformation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: DSI-based dialogue response generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 6: Domain accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Slots distributions on hotel and attraction domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The supervised learning task is called Dialogue State Tracking (DST) [Young</figDesc><table><row><cell>User: I want an expensive restaurant</cell><cell>User: I want an expensive restaurant</cell></row><row><cell>that serves Turkish food.</cell><cell>that serves Turkish food.</cell></row><row><cell>Manual labeling:</cell><cell>Manual labeling:</cell></row><row><cell>inform(price=expensive,</cell><cell>inform(price=expensive,</cell></row><row><cell>food=Turkish)</cell><cell>food=Turkish)</cell></row><row><cell>System: Anatolia serves Turkish food.</cell><cell>System: Anatolia serves Turkish food.</cell></row><row><cell>User: What is the area?</cell><cell>User: What is the area?</cell></row><row><cell>Manual labeling:</cell><cell>Manual labeling:</cell></row><row><cell>inform(price=expensive,</cell><cell>inform(price=expensive,</cell></row><row><cell>food=Turkish); request(area)</cell><cell>food=Turkish); request(area)</cell></row><row><cell>Ontology(optional):</cell><cell>Ontology(optional):</cell></row><row><cell>price: [cheap, expensive, moderate, ...]</cell><cell>price: [cheap, expensive, moderate, ...]</cell></row><row><cell>food: [Turkish, Italian, polish, ...]</cell><cell>food: [Turkish, Italian, polish, ...]</cell></row><row><cell>area: [south, north, center, ...]</cell><cell>area: [south, north, center, ...]</cell></row><row><cell>Turn 1:</cell><cell>Turn 1:</cell></row><row><cell>inform(price=expensive,</cell><cell>inform(price=expensive,</cell></row><row><cell>food=Turkish)</cell><cell>food=Turkish)</cell></row><row><cell>Turn 2:</cell><cell>Turn 2:</cell></row><row><cell>inform(price=expensive,</cell><cell>inform(price=expensive,</cell></row><row><cell>food=Turkish); request(area)</cell><cell>food=Turkish); request(area)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Overall results of DSI.</figDesc><table><row><cell>MultiWOZ 2.1</cell></row><row><cell>Models</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Hyper-parameters settings.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Empirical results on MultiWOZ dialogue act prediction and response generation.</figDesc><table><row><cell>Dialogue State</cell><cell cols="3">Dialog Act Prediction</cell><cell cols="2">Delexicalized</cell></row><row><cell></cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell cols="2">BLEU Entity F1</cell></row><row><cell>None</cell><cell>71.0</cell><cell>67.4</cell><cell>69.1</cell><cell>18.7</cell><cell>54.6</cell></row><row><cell>DSI-GM</cell><cell>72.0</cell><cell>70.5</cell><cell>71.2</cell><cell>20.8</cell><cell>56.5</cell></row><row><cell>Manual labeling</cell><cell>75.6</cell><cell>73.0</cell><cell>74.2</cell><cell>21.6</cell><cell>61.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Turn goal accuracy per domain.</figDesc><table><row><cell></cell><cell cols="4">attraction hotel restaurant taxi train</cell></row><row><cell>DSI-base</cell><cell>27.9</cell><cell>21.7</cell><cell>26.1</cell><cell>30.7 26.0</cell></row><row><cell>DSI-GM</cell><cell>40.3</cell><cell>31.4</cell><cell>35.6</cell><cell>39.9 36.8</cell></row><row><cell cols="2">hotel (13 slot types)</cell><cell></cell><cell cols="2">attraction (9 slot types)</cell></row><row><cell>book stay,</cell><cell>pricerange,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>277</cell><cell>257</cell><cell></cell><cell>name, 280</cell><cell></cell></row><row><cell></cell><cell cols="2">book day,</cell><cell></cell><cell></cell></row><row><cell>name, 325</cell><cell cols="2">253</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>area, 273</cell></row><row><cell>others, 4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">book people,</cell><cell></cell><cell></cell></row><row><cell>parking, 171</cell><cell></cell><cell>246</cell><cell></cell><cell></cell></row><row><cell>internet, 183</cell><cell>type, 239</cell><cell></cell><cell></cell><cell></cell></row><row><cell>stars, 200</cell><cell>area , 220</cell><cell></cell><cell>type, 337</cell><cell>others, 14</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>In practice, we use the ELMo pre-trained model with the output size of</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="256" xml:id="foot_2"><p>We also tried BERT, whose performance is almost the same as ELMo. However, BERT is much slower and more resourceintensive for training.Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>A fuzzy matching mechanism is used to compare induced values with the ground truth.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank the anonymous reviewers for their detailed and constructive comments. The first three authors contributed equally. <rs type="person">Yue Zhang</rs> is the corresponding author. We would like to acknowledge funding support from <rs type="funder">National Natural Science Foundation of China</rs> under Grant No.<rs type="grantNumber">61976180</rs> and the <rs type="funder">Westlake University</rs> and <rs type="institution">Bright Dream Joint Institute for Intelligent Robotics</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_N9NGCDa">
					<idno type="grant-number">61976180</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised induction and filling of semantic slots for spoken dialogue systems using frame-semantic parsing</title>
		<author>
			<persName><surname>Budzianowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASRU Workshop</title>
		<imprint>
			<publisher>Cui and Zhang</publisher>
			<date type="published" when="2013">2018. 2018. 2013. 2013. 2019. 2019. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A copy-augmented sequence-to-sequence architecture gives good performance on task-oriented dialogue</title>
		<author>
			<persName><forename type="first">Eric</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Manning</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Mihail</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiwoz 2.1: Multi-domain dialogue state corrections and state tracking baselines. arXiv</title>
		<author>
			<persName><forename type="first">Eric</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="1990">2019. 2019. 2019. 2019. 1990. 1990</date>
		</imprint>
	</monogr>
	<note>HLT</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Variational deep embedding: An unsupervised and generative approach to clustering</title>
		<author>
			<persName><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures</title>
		<author>
			<persName><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Welling ; Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014">2014. 2014. 2018. 2018. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Attention-informed mixed-language training for zero-shot cross-lingual taskoriented dialogue systems</title>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A stack-propagation framework with token-level intent detection for spoken language understanding</title>
		<author>
			<persName><surname>Mrkšić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015">2015. 2015. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset</title>
		<author>
			<persName><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<editor>
			<persName><surname>Shi</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2020. 2020. 2019. 2019. 2019. 2019. 2018. 2018</date>
		</imprint>
	</monogr>
	<note>EMNLP</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A networkbased end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName><forename type="first">Wen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sequence-to-sequence learning for task-oriented dialogue with dialogue state representation</title>
		<author>
			<persName><forename type="first">Wen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The dialog state tracking challenge series</title>
		<author>
			<persName><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<publisher>AI Magazine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The hidden information state model: A practical framework for pomdp-based spoken dialogue management</title>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<publisher>Richard Socher, and Caiming Xiong</publisher>
			<date type="published" when="2003">2019. 2019. 2019. 2019. 2003. 2003. 2010. 2010. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>A generalized mean field algorithm for variational inference in exponential families. Find or classify? dual strategy for slot-value predictions on multi-domain dialog state tracking. arXiv</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Global-locally self-attentive encoder for dialogue state tracking</title>
		<author>
			<persName><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<editor>
			<persName><forename type="first">Caiming</forename><surname>Zhong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Richard</forename><surname>Xiong</surname></persName>
		</editor>
		<editor>
			<persName><surname>Socher</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
