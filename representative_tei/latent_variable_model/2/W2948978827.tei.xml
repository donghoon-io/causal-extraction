<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Foundations and Trends R in Machine Learning An Introduction to Variational Autoencoders</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-12-11">11 Dec 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
							<email>mwelling@qti.qualcomm.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Universiteit van Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName><surname>Google</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Universiteit van Amsterdam</orgName>
								<address>
									<region>Qualcomm</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Foundations and Trends R in Machine Learning An Introduction to Variational Autoencoders</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-11">11 Dec 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1561/XXXXXXXXX</idno>
					<idno type="arXiv">arXiv:1906.02691v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction 1.Motivation</head><p>One major division in machine learning is generative versus discriminative modeling. While in discriminative modeling one aims to learn a predictor given the observations, in generative modeling one aims to solve the more general problem of learning a joint distribution over all the variables. A generative model simulates how the data is generated in the real world. "Modeling" is understood in almost every science as unveiling this generating process by hypothesizing theories and testing these theories through observations. For instance, when meteorologists model the weather they use highly complex partial differential equations to express the underlying physics of the weather. Or when an astronomer models the formation of galaxies s/he encodes in his/her equations of motion the physical laws under which stellar bodies interact. The same is true for biologists, chemists, economists and so on. Modeling in the sciences is in fact almost always generative modeling.</p><p>There are many reasons why generative modeling is attractive. First, we can express physical laws and constraints into the generative process while details that we don't know or care about, i.e. nuisance variables, are treated as noise. The resulting models are usually highly intuitive and interpretable and by testing them against observations we can confirm or reject our theories about how the world works.</p><p>Another reason for trying to understand the generative process of data is that it naturally expresses causal relations of the world. Causal relations have the great advantage that they generalize much better to new situations than mere correlations. For instance, once we understand the generative process of an earthquake, we can use that knowledge both in California and in Chile.</p><p>To turn a generative model into a discriminator, we need to use Bayes rule. For instance, we have a generative model for an earthquake of type A and another for type B, then seeing which of the two describes the data best we can compute a probability for whether earthquake A or B happened. Applying Bayes rule is however often computationally expensive.</p><p>In discriminative methods we directly learn a map in the same direction as we intend to make future predictions in. This is in the opposite direction than the generative model. For instance, one can argue that an image is generated in the world by first identifying the object, then generating the object in 3D and then projecting it onto an pixel grid. A discriminative model takes these pixel values directly as input and maps them to the labels. While generative models can learn efficiently from data, they also tend to make stronger assumptions on the data than their purely discriminative counterparts, often leading to higher asymptotic bias <ref type="bibr" target="#b0">(Banerjee, 2007)</ref> when the model is wrong. For this reason, if the model is wrong (and it almost always is to some degree!), if one is solely interested in learning to discriminate, and one is in a regime with a sufficiently large amount of data, then purely discriminative models typically will lead to fewer errors in discriminative tasks. Nevertheless, depending on how much data is around, it may pay off to study the data generating process as a way to guide the training of the discriminator, such as a classifier. For instance, one may have few labeled examples and many more unlabeled examples. In this semisupervised learning setting, one can use the generative model of the data to improve classification <ref type="bibr">(Kingma et al., 2014;</ref><ref type="bibr">Sønderby et al., 2016a)</ref>.</p><p>Generative modeling can be useful more generally. One can think of it as an auxiliary task. For instance, predicting the immediate future may help us build useful abstractions of the world that can be used for multiple prediction tasks downstream. This quest for disentangled, semantically meaningful, statistically independent and causal factors of variation in data is generally known as unsupervised representation learning, and the variational autoencoder (VAE) has been extensively employed for that purpose. Alternatively, one may view this as an implicit form of regularization: by forcing the representations to be meaningful for data generation, we bias the inverse of that process, which maps from input to representation, into a certain mould. The auxiliary task of predicting the world is used to better understand the world at an abstract level and thus to better make downstream predictions.</p><p>The VAE can be viewed as two coupled, but independently parameterized models: the encoder or recognition model, and the decoder or generative model. These two models support each other. The recognition model delivers to the generative model an approximation to its posterior over latent random variables, which it needs to update its parameters inside an iteration of "expectation maximization" learning. Reversely, the generative model is a scaffolding of sorts for the recognition model to learn meaningful representations of the data, including possibly class-labels. The recognition model is the approximate inverse of the generative model according to Bayes rule.</p><p>One advantage of the VAE framework, relative to ordinary Variational Inference (VI), is that the recognition model (also called inference model) is now a (stochastic) function of the input variables. This in contrast to VI where each data-case has a separate variational distribution, which is inefficient for large data-sets. The recognition model uses one set of parameters to model the relation between input and latent variables and as such is called "amortized inference". This recognition model can be arbitrary complex but is still reasonably fast because by construction it can be done using a single feedforward pass from input to latent variables. However the price we pay is that this sampling induces sampling noise in the gradients required for learning. Perhaps the greatest contribution of the VAE framework is the realization that we can counteract this variance by using what is now known as the "reparameterization trick", a simple procedure to reorganize our gradient computation that reduces variance in the gradients.</p><p>The VAE is inspired by the Helmholtz Machine <ref type="bibr" target="#b16">(Dayan et al., 1995)</ref> which was perhaps the first model that employed a recognition model. However, its wake-sleep algorithm was inefficient and didn't optimize a single objective. The VAE learning rules instead follow from a single approximation to the maximum likelihood objective.</p><p>VAEs marry graphical models and deep learning. The generative model is a Bayesian network of the form p(x|z)p(z), or, if there are multiple stochastic latent layers, a hierarchy such as p(x|z L )p(z L |z L-1 ) ...p(z 1 |z 0 ). Similarly, the recognition model is also a conditional Bayesian network of the form q(z|x) or as a hierarchy, such as q(z 0 |z 1 )...q(z L |X). But inside each conditional may hide a complex (deep) neural network, e.g. z|x ∼ f (x, ), with f a neural network mapping and a noise random variable. Its learning algorithm is a mix of classical (amortized, variational) expectation maximization but through the reparameterization trick ends up backpropagating through the many layers of the deep neural networks embedded inside of it.</p><p>Since its inception, the VAE framework has been extended in many directions, e.g. to dynamical models <ref type="bibr" target="#b60">(Johnson et al., 2016)</ref>, models with attention <ref type="bibr" target="#b40">(Gregor et al., 2015)</ref>, models with multiple levels of stochastic latent variables <ref type="bibr" target="#b65">(Kingma et al., 2016)</ref>, and many more. It has proven itself as a fertile framework to build new models in. More recently, another generative modeling paradigm has gained significant attention: the generative adversarial network (GAN) <ref type="bibr" target="#b37">(Goodfellow et al., 2014)</ref>. VAEs and GANs seem to have complementary properties: while GANs can generate images of high subjective perceptual quality, they tend to lack full support over the data <ref type="bibr" target="#b42">(Grover et al., 2018)</ref>, as opposed to likelihood-based generative models. VAEs, like other likelihood-based models, generate more dispersed samples, but are better density models in terms of the likelihood criterion. As such many hybrid models have been proposed to try to represent the best of both worlds <ref type="bibr" target="#b23">(Dumoulin et al., 2017;</ref><ref type="bibr" target="#b42">Grover et al., 2018;</ref><ref type="bibr" target="#b110">Rosca et al., 2018)</ref>.</p><p>As a community we seem to have embraced the fact that generative models and unsupervised learning play an important role in building intelligent machines. We hope that the VAE provides a useful piece of that puzzle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Aim</head><p>The framework of variational autoencoders (VAEs) <ref type="bibr">(Kingma and Welling, 2014;</ref><ref type="bibr" target="#b106">Rezende et al., 2014)</ref> provides a principled method for jointly learning deep latent-variable models and corresponding inference models using stochastic gradient descent. The framework has a wide array of applications from generative modeling, semi-supervised learning to representation learning.</p><p>This work is meant as an expanded version of our earlier work <ref type="bibr">(Kingma and Welling, 2014)</ref>, allowing us to explain the topic in finer detail and to discuss a selection of important follow-up work. This is not aimed to be a comprehensive review of all related work. We assume that the reader has basic knowledge of algebra, calculus and probability theory.</p><p>In this chapter we discuss background material: probabilistic models, directed graphical models, the marriage of directed graphical models with neural networks, learning in fully observed models and deep latentvariable models (DLVMs). In chapter 2 we explain the basics of VAEs. In chapter 3 we explain advanced inference techniques, followed by an explanation of advanced generative models in chapter 4. Please refer to section A.1 for more information on mathematical notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Probabilistic Models and Variational Inference</head><p>In the field of machine learning, we are often interested in learning probabilistic models of various natural and artificial phenomena from data. Probabilistic models are mathematical descriptions of such phenomena. They are useful for understanding such phenomena, for prediction of unknowns in the future, and for various forms of assisted or automated decision making. As such, probabilistic models formalize the notion of knowledge and skill, and are central constructs in the field of machine learning and AI.</p><p>As probabilistic models contain unknowns and the data rarely paints a complete picture of the unknowns, we typically need to assume some level of uncertainty over aspects of the model. The degree and nature of this uncertainty is specified in terms of (conditional) probability dis-tributions. Models may consist of both continuous-valued variables and discrete-valued variables. The, in some sense, most complete forms of probabilistic models specify all correlations and higher-order dependencies between the variables in the model, in the form of a joint probability distribution over those variables.</p><p>Let's use x as the vector representing the set of all observed variables whose joint distribution we would like to model. Note that for notational simplicity and to avoid clutter, we use lower case bold (e.g. x) to denote the underlying set of observed random variables, i.e. flattened and concatenated such that the set is represented as a single vector. See section A.1 for more on notation.</p><p>We assume the observed variable x is a random sample from an unknown underlying process, whose true (probability) distribution p * (x) is unknown. We attempt to approximate this underlying process with a chosen model p θ (x), with parameters θ:</p><formula xml:id="formula_0">x ∼ p θ (x) (1.1)</formula><p>Learning is, most commonly, the process of searching for a value of the parameters θ such that the probability distribution function given by the model, p θ (x), approximates the true distribution of the data, denoted by p * (x), such that for any observed x:</p><formula xml:id="formula_1">p θ (x) ≈ p * (x) (1.2)</formula><p>Naturally, we wish p θ (x) to be sufficiently flexible to be able to adapt to the data, such that we have a chance of obtaining a sufficiently accurate model. At the same time, we wish to be able to incorporate knowledge about the distribution of data into the model that is known a priori.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.1">Conditional Models</head><p>Often, such as in case of classification or regression problems, we are not interested in learning an unconditional model p θ (x), but a conditional model p θ (y|x) that approximates the underlying conditional distribution p * (y|x): a distribution over the values of variable y, conditioned on the value of an observed variable x. In this case, x is often called the input of the model. Like in the unconditional case, a model p θ (y|x) is chosen, and optimized to be close to the unknown underlying distribution, such that for any x and y:</p><formula xml:id="formula_2">p θ (y|x) ≈ p * (y|x) (1.3)</formula><p>A relatively common and simple example of conditional modeling is image classification, where x is an image, and y is the image's class, as labeled by a human, which we wish to predict. In this case, p θ (y|x) is typically chosen to be a categorical distribution, whose parameters are computed from x.</p><p>Conditional models become more difficult to learn when the predicted variables are very high-dimensional, such as images, video or sound. One example is the reverse of the image classification problem: prediction of a distribution over images, conditioned on the class label. Another example with both high-dimensional input, and highdimensional output, is time series prediction, such as text or video prediction.</p><p>To avoid notational clutter we will often assume unconditional modeling, but one should always keep in mind that the methods introduced in this work are, in almost all cases, equally applicable to conditional models. The data on which the model is conditioned, can be treated as inputs to the model, similar to the parameters of the model, with the obvious difference that one doesn't optimize over their value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Parameterizing Conditional Distributions with Neural Networks</head><p>Differentiable feed-forward neural networks, from here just called neural networks, are a particularly flexible and computationally scalable type of function approximator. Learning of models based on neural networks with multiple 'hidden' layers of artificial neurons is often referred to as deep learning <ref type="bibr" target="#b36">(Goodfellow et al., 2016;</ref><ref type="bibr" target="#b78">LeCun et al., 2015)</ref>. A particularly interesting application is probabilistic models, i.e. the use of neural networks for probability density functions (PDFs) or probability mass functions (PMFs) in probabilistic models. Probabilistic models based on neural networks are computationally scalable since they allow for stochastic gradient-based optimization which, as we will explain, allows scaling to large models and large datasets. We will denote a deep neural network as a vector function: NeuralNet(.).</p><p>At the time of writing, deep learning has been shown to work well for a large variety of classification and regression problems, as summarized in <ref type="bibr" target="#b78">(LeCun et al., 2015;</ref><ref type="bibr" target="#b36">Goodfellow et al., 2016)</ref>. In case of neuralnetwork based image classification <ref type="bibr" target="#b79">LeCun et al., 1998</ref>, for example, neural networks parameterize a categorical distribution p θ (y|x) over a class label y, conditioned on an image x. p = NeuralNet(x)</p><p>(1.4)</p><formula xml:id="formula_3">p θ (y|x) = Categorical(y; p) (1.5)</formula><p>where the last operation of NeuralNet(.) is typically a softmax() function such that i p i = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Directed Graphical Models and Neural Networks</head><p>We work with directed probabilistic models, also called directed probabilistic graphical models (PGMs), or Bayesian networks. Directed graphical models are a type of probabilistic models where all the variables are topologically organized into a directed acyclic graph. The joint distribution over the variables of such models factorizes as a product of prior and conditional distributions:</p><formula xml:id="formula_4">p θ (x 1 , ..., x M ) = M j=1 p θ (x j |P a(x j )) (1.6)</formula><p>where P a(x j ) is the set of parent variables of node j in the directed graph.</p><p>For non-root-nodes, we condition on the parents. For root nodes, the set of parents is the empty set, such that the distribution is unconditional.</p><p>Traditionally, each conditional probability distribution p θ (x j |P a(x j )) is parameterized as a lookup table or a linear model <ref type="bibr" target="#b71">(Koller and Friedman, 2009)</ref>. As we explained above, a more flexible way to parameterize such conditional distributions is with neural networks. In this case, neural networks take as input the parents of a variable in a directed graph, and produce the distributional parameters η over that variable:</p><formula xml:id="formula_5">η = NeuralNet(P a(x)) (1.7) p θ (x|P a(x)) = p θ (x|η) (1.8)</formula><p>We will now discuss how to learn the parameters of such models, if all the variables are observed in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6">Learning in Fully Observed Models with Neural Nets</head><p>If all variables in the directed graphical model are observed in the data, then we can compute and differentiate the log-probability of the data under the model, leading to relatively straightforward optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6.1">Dataset</head><p>We often collect a dataset D consisting of N ≥ 1 datapoints:</p><formula xml:id="formula_6">D = {x (1) , x (2) , ..., x (N ) } ≡ {x (i) } N i=1 ≡ x (1:N ) (1.9)</formula><p>The datapoints are assumed to be independent samples from an unchanging underlying distribution. In other words, the dataset is assumed to consist of distinct, independent measurements from the same (unchanging) system. In this case, the observations D = {x (i) } N i=1 are said to be i.i.d., for independently and identically distributed. Under the i.i.d. assumption, the probability of the datapoints given the parameters factorizes as a product of individual datapoint probabilities. The log-probability assigned to the data by the model is therefore given by:</p><formula xml:id="formula_7">log p θ (D) = x∈D log p θ (x)</formula><p>(1.10)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6.2">Maximum Likelihood and Minibatch SGD</head><p>The most common criterion for probabilistic models is maximum loglikelihood (ML). As we will explain, maximization of the log-likelihood criterion is equivalent to minimization of a Kullback Leibler divergence between the data and model distributions.</p><p>Under the ML criterion, we attempt to find the parameters θ that maximize the sum, or equivalently the average, of the log-probabilities assigned to the data by the model. With i.i.d. dataset D of size N D , the maximum likelihood objective is to maximize the log-probability given by equation (1.10).</p><p>Using calculus' chain rule and automatic differentiation tools, we can efficiently compute gradients of this objective, i.e. the first derivatives of the objective w.r.t. its parameters θ. We can use such gradients to iteratively hill-climb to a local optimum of the ML objective. If we compute such gradients using all datapoints, ∇ θ log p θ (D), then this is known as batch gradient descent. Computation of this derivative is, however, an expensive operation for large dataset size N D , since it scales linearly with N D .</p><p>A more efficient method for optimization is stochastic gradient descent (SGD) (section A.3), which uses randomly drawn minibatches of data M ⊂ D of size N M . With such minibatches we can form an unbiased estimator of the ML criterion:</p><p>1</p><formula xml:id="formula_8">N D log p θ (D) 1 N M log p θ (M) = 1 N M x∈M log p θ (x) (1.11)</formula><p>The symbol means that one of the two sides is an unbiased estimator of the other side. So one side (in this case the right-hand side) is a random variable due to some noise source, and the two sides are equal when averaged over the noise distribution. The noise source, in this case, is the randomly drawn minibatch of data M. The unbiased estimator log p θ (M) is differentiable, yielding the unbiased stochastic gradients:</p><formula xml:id="formula_9">1 N D ∇ θ log p θ (D) 1 N M ∇ θ log p θ (M) = 1 N M x∈M ∇ θ log p θ (x)</formula><p>(1.12)</p><p>These gradients can be plugged into stochastic gradient-based optimizers; see section A.3 for further discussion. In a nutshell, we can optimize the objective function by repeatedly taking small steps in the direction of the stochastic gradient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6.3">Bayesian inference</head><p>From a Bayesian perspective, we can improve upon ML through maximum a posteriori (MAP) estimation (section section A.2.1), or, going even further, inference of a full approximate posterior distribution over the parameters (see section A.1.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.7">Learning and Inference in Deep Latent Variable Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.7.1">Latent Variables</head><p>We can extend fully-observed directed models, discussed in the previous section, into directed models with latent variables. Latent variables are variables that are part of the model, but which we don't observe, and are therefore not part of the dataset. We typically use z to denote such latent variables. In case of unconditional modeling of observed variable x, the directed graphical model would then represent a joint distribution p θ (x, z) over both the observed variables x and the latent variables z.</p><p>The marginal distribution over the observed variables p θ (x), is given by:</p><formula xml:id="formula_10">p θ (x) = p θ (x, z) dz (1.13)</formula><p>This is also called the (single datapoint) marginal likelihood or the model evidence, when taken as a function of θ. Such an implicit distribution over x can be quite flexible. If z is discrete and p θ (x|z) is a Gaussian distribution, then p θ (x) is a mixtureof-Gaussians distribution. For continuous z, p θ (x) can be seen as an infinite mixture, which are potentially more powerful than discrete mixtures. Such marginal distributions are also called compound probability distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.7.2">Deep Latent Variable Models</head><p>We use the term deep latent variable model (DLVM) to denote a latent variable model p θ (x, z) whose distributions are parameterized by neural networks. Such a model can be conditioned on some context, like p θ (x, z|y). One important advantage of DLVMs, is that even when each factor (prior or conditional distribution) in the directed model is relatively simple (such as conditional Gaussian), the marginal distribution p θ (x) can be very complex, i.e. contain almost arbitrary dependen-cies. This expressivity makes deep latent-variable models attractive for approximating complicated underlying distributions p * (x).</p><p>Perhaps the simplest, and most common, DLVM is one that is specified as factorization with the following structure:</p><formula xml:id="formula_11">p θ (x, z) = p θ (z)p θ (x|z) (1.14)</formula><p>where p θ (z) and/or p θ (x|z) are specified. The distribution p(z) is often called the prior distribution over z, since it is not conditioned on any observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.7.3">Example DLVM for multivariate Bernoulli data</head><p>A simple example DLVM, used in <ref type="bibr">(Kingma and Welling, 2014)</ref> for binary data x, is with a spherical Gaussian latent space, and a factorized Bernoulli observation model:</p><formula xml:id="formula_12">p(z) = N (z; 0, I) (1.15) p = DecoderNeuralNet θ (z) (1.16) log p(x|z) = D j=1 log p(x j |z) = D j=1</formula><p>log Bernoulli(x j ; p j ) (1.17)</p><formula xml:id="formula_13">= D j=1 x j log p j + (1 -x j ) log(1 -p j ) (1.18)</formula><p>where ∀p j ∈ p : 0 ≤ p j ≤ 1 (e.g. implemented through a sigmoid nonlinearity as the last layer of the DecoderNeuralNet θ (.)), where D is the dimensionality of x, and Bernoulli(.; p) is the probability mass function (PMF) of the Bernoulli distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.8">Intractabilities</head><p>The main difficulty of maximum likelihood learning in DLVMs is that the marginal probability of data under the model is typically intractable. This is due to the integral in equation (1.13) for computing the marginal likelihood (or model evidence), p θ (x) = p θ (x, z) dz, not having an analytic solution or efficient estimator. Due to this intractability, we cannot differentiate it w.r.t. its parameters and optimize it, as we can with fully observed models. The intractability of p θ (x), is related to the intractability of the posterior distribution p θ <ref type="bibr">(z|x)</ref>. Note that the joint distribution p θ (x, z) is efficient to compute, and that the densities are related through the basic identity:</p><formula xml:id="formula_14">p θ (z|x) = p θ (x, z) p θ (x) (1.19)</formula><p>Since p θ (x, z) is tractable to compute, a tractable marginal likelihood p θ (x) leads to a tractable posterior p θ (z|x), and vice versa. Both are intractable in DLVMs.</p><p>Approximate inference techniques (see also section A.2) allow us to approximate the posterior p θ (z|x) and the marginal likelihood p θ (x) in DLVMs. Traditional inference methods are relatively expensive. Such methods, for example, often require a per-datapoint optimization loop, or yield bad posterior approximations. We would like to avoid such expensive procedures.</p><p>Likewise, the posterior over the parameters of (directed models parameterized with) neural networks, p(θ|D), is generally intractable to compute exactly, and requires approximate inference techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variational Autoencoders</head><p>In this chapter we explain the basics of variational autoencoders (VAEs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Encoder or Approximate Posterior</head><p>In the previous chapter, we introduced deep latent-variable models (DLVMs), and the problem of estimating the log-likelihood and posterior distributions in such models. The framework of variational autoencoders (VAEs) provides a computationally efficient way for optimizing DLVMs jointly with a corresponding inference model using SGD.</p><p>To turn the DLVM's intractable posterior inference and learning problems into tractable problems, we introduce a parametric inference model q φ (z|x). This model is also called an encoder or recognition model. With φ we indicate the parameters of this inference model, also called the variational parameters. We optimize the variational parameters φ such that:</p><formula xml:id="formula_15">q φ (z|x) ≈ p θ (z|x) (2.1)</formula><p>As we will explain, this approximation to the posterior help us optimize the marginal likelihood.</p><p>Like a DLVM, the inference model can be (almost) any directed graphical model:</p><formula xml:id="formula_16">q φ (z|x) = q φ (z 1 , ..., z M |x) = M j=1 q φ (z j |P a(z j ), x) (2.2)</formula><p>where P a(z j ) is the set of parent variables of variable z j in the directed graph. And also similar to a DLVM, the distribution q φ (z|x) can be parameterized using deep neural networks. In this case, the variational parameters φ include the weights and biases of the neural network. For example:</p><formula xml:id="formula_17">(µ, log σ) = EncoderNeuralNet φ (x) (2.3) q φ (z|x) = N (z; µ, diag(σ)) (2.4)</formula><p>Typically, we use a single encoder neural network to perform posterior inference over all of the datapoints in our dataset. This can be contrasted to more traditional variational inference methods where the variational parameters are not shared, but instead separately and iteratively optimized per datapoint. The strategy used in VAEs of sharing variational parameters across datapoints is also called amortized variational inference <ref type="bibr" target="#b32">(Gershman and Goodman, 2014)</ref>. With amortized inference we can avoid a per-datapoint optimization loop, and leverage the efficiency of SGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evidence Lower Bound (ELBO)</head><p>The optimization objective of the variational autoencoder, like in other variational methods, is the evidence lower bound, abbreviated as ELBO.</p><p>An alternative term for this objective is variational lower bound. Typically, the ELBO is derived through Jensen's inequality. Here we will use an alternative derivation that avoids Jensen's inequality, providing greater insight about its tightness.</p><p>For any choice of inference model q φ (z|x), including the choice of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>x-space z-space</head><p>Encoder: q φ (z|x) Decoder: pθ(x|z)</p><p>Prior distribution: pθ(z)</p><formula xml:id="formula_18">Dataset: D Figure 2</formula><p>.1: A VAE learns stochastic mappings between an observed x-space, whose empirical distribution qD(x) is typically complicated, and a latent z-space, whose distribution can be relatively simple (such as spherical, as in this figure). The generative model learns a joint distribution p θ (x, z) that is often (but not always) factorized as p θ (x, z) = p θ (z)p θ (x|z), with a prior distribution over latent space p θ (z), and a stochastic decoder p θ (x|z). The stochastic encoder q φ (z|x), also called inference model, approximates the true but intractable posterior p θ (z|x) of the generative model.</p><p>variational parameters φ, we have:</p><formula xml:id="formula_19">log p θ (x) = E q φ (z|x) [log p θ (x)] (2.5) = E q φ (z|x) log p θ (x, z) p θ (z|x) (2.6) = E q φ (z|x) log p θ (x, z) q φ (z|x) q φ (z|x) p θ (z|x) (2.7) = E q φ (z|x) log p θ (x, z) q φ (z|x) =L θ,φ (x) (ELBO) + E q φ (z|x) log q φ (z|x) p θ (z|x) =D KL (q φ (z|x)||p θ (z|x))</formula><p>(2.8)</p><p>The second term in eq. (2.8) is the Kullback-Leibler (KL) divergence between q φ (z|x) and p θ (z|x), which is non-negative:</p><formula xml:id="formula_20">D KL (q φ (z|x)||p θ (z|x)) ≥ 0 (2.9)</formula><p>and zero if, and only if, q φ (z|x) equals the true posterior distribution. The first term in eq. (2.8) is the variational lower bound, also called the evidence lower bound (ELBO):</p><formula xml:id="formula_21">L θ,φ (x) = E q φ (z|x) [log p θ (x, z) -log q φ (z|x)]</formula><p>(2.10)</p><p>Due to the non-negativity of the KL divergence, the ELBO is a lower bound on the log-likelihood of the data.</p><formula xml:id="formula_22">L θ,φ (x) = log p θ (x) -D KL (q φ (z|x)||p θ (z|x)) (2.11) ≤ log p θ (x) (2.12)</formula><p>So, interestingly, the KL divergence D KL (q φ (z|x)||p θ (z|x)) determines two 'distances':</p><p>1. By definition, the KL divergence of the approximate posterior from the true posterior;</p><p>2. The gap between the ELBO L θ,φ (x) and the marginal likelihood log p θ (x); this is also called the tightness of the bound. The better q φ (z|x) approximates the true (posterior) distribution p θ (z|x), in terms of the KL divergence, the smaller the gap. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Two for One</head><p>By looking at equation 2.11, it can be understood that maximization of the ELBO L θ,φ (x) w.r.t. the parameters θ and φ, will concurrently optimize the two things we care about:</p><p>1. It will approximately maximize the marginal likelihood p θ (x).</p><p>This means that our generative model will become better.</p><p>2. It will minimize the KL divergence of the approximation q φ (z|x) from the true posterior p θ (z|x), so q φ (z|x) becomes better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Stochastic Gradient-Based Optimization of the ELBO</head><p>An important property of the ELBO, is that it allows joint optimization w.r.t. all parameters (φ and θ) using stochastic gradient descent (SGD).</p><p>We can start out with random initial values of φ and θ, and stochastically optimize their values until convergence. Given a dataset with i.i.d. data, the ELBO objective is the sum (or average) of individual-datapoint ELBO's:</p><formula xml:id="formula_23">L θ,φ (D) = x∈D L θ,φ (x) (2.13)</formula><p>The individual-datapoint ELBO, and its gradient ∇ θ,φ L θ,φ (x) is, in general, intractable. However, good unbiased estimators ∇θ,φ L θ,φ (x) exist, as we will show, such that we can still perform minibatch SGD.</p><p>Unbiased gradients of the ELBO w.r.t. the generative model parameters θ are simple to obtain:</p><formula xml:id="formula_24">∇ θ L θ,φ (x) = ∇ θ E q φ (z|x) [log p θ (x, z) -log q φ (z|x)] (2.14) = E q φ (z|x) [∇ θ (log p θ (x, z) -log q φ (z|x))] (2.15) ∇ θ (log p θ (x, z) -log q φ (z|x)) (2.16) = ∇ θ (log p θ (x, z)) (2.17)</formula><p>The last line (eq. ( <ref type="formula" target="#formula_38">2</ref>.17)) is a simple Monte Carlo estimator of the second line (eq. (2.15)), where z in the last two lines (eq. ( <ref type="formula" target="#formula_38">2</ref>.16) and eq. ( <ref type="formula" target="#formula_38">2</ref>.17)) is a random sample from q φ (z|x). Unbiased gradients w.r.t. the variational parameters φ are more difficult to obtain, since the ELBO's expectation is taken w.r.t. the distribution q φ (z|x), which is a function of φ. I.e., in general:</p><formula xml:id="formula_25">∇ φ L θ,φ (x) = ∇ φ E q φ (z|x) [log p θ (x, z) -log q φ (z|x)] (2.18) = E q φ (z|x) [∇ φ (log p θ (x, z) -log q φ (z|x))] (2.19)</formula><p>In the case of continuous latent variables, we can use a reparameterization trick for computing unbiased estimates of ∇ θ,φ L θ,φ (x), as we will now discuss. This stochastic estimate allows us to optimize the ELBO using SGD; see algorithm 1. See section 2.9.1 for a discussion of variational methods for discrete latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Reparameterization Trick</head><p>For continuous latent variables and a differentiable encoder and generative model, the ELBO can be straightforwardly differentiated w.r.t. both φ and θ through a change of variables, also called the reparameterization trick <ref type="bibr">(Kingma and</ref><ref type="bibr">Welling, 2014 and</ref><ref type="bibr" target="#b106">Rezende et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Change of variables</head><p>First, we express the random variable z ∼ q φ (z|x) as some differentiable (and invertible) transformation of another random variable , given z and φ:</p><formula xml:id="formula_26">z = g( , φ, x) (2.20)</formula><p>where the distribution of random variable is independent of x or φ.</p><p>Algorithm 1: Stochastic optimization of the ELBO. Since noise originates from both the minibatch sampling and sampling of p( ), this is a doubly stochastic optimization procedure. We also refer to this procedure as the Auto-Encoding Variational Bayes (AEVB) algorithm. Data:</p><formula xml:id="formula_27">D: Dataset q φ (z|x): Inference model p θ (x, z): Generative model Result: θ, φ: Learned parameters (θ, φ) ← Initialize parameters while SGD not converged do M ∼ D (Random minibatch of data) ∼ p( ) (</formula><p>Random noise for every datapoint in M) Compute Lθ,φ (M, ) and its gradients ∇ θ,φ Lθ,φ (M, ) Update θ and φ using SGD optimizer end</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.2">Gradient of expectation under change of variable</head><p>Given such a change of variable, expectations can be rewritten in terms of ,</p><formula xml:id="formula_28">E q φ (z|x) [f (z)] = E p( ) [f (z)]</formula><p>(2.21)</p><p>where z = g( , φ, x). and the expectation and gradient operators become commutative, and we can form a simple Monte Carlo estimator:</p><formula xml:id="formula_29">∇ φ E q φ (z|x) [f (z)] = ∇ φ E p( ) [f (z)] (2.22) = E p( ) [∇ φ f (z)] (2.23) ∇ φ f (z) (2.24)</formula><p>where in the last line, z = g(φ, x, ) with random noise sample ∼ p( ). See figure 2.3 for an illustration and further clarification, and figure 3.2 for an illustration of the resulting posteriors for a 2D toy problem. The variational parameters φ affect the objective f through the random variable z ∼ q φ (z|x). We wish to compute gradients ∇ φ f to optimize the objective with SGD. In the original form (left), we cannot differentiate f w.r.t. φ, because we cannot directly backpropagate gradients through the random variable z. We can 'externalize' the randomness in z by re-parameterizing the variable as a deterministic and differentiable function of φ, x, and a newly introduced random variable . This allows us to 'backprop through z', and compute gradients ∇ φ f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Gradient of ELBO</head><p>Under the reparameterization, we can replace an expectation w.r.t. q φ (z|x) with one w.r.t. p( ). The ELBO can be rewritten as:</p><formula xml:id="formula_30">L θ,φ (x) = E q φ (z|x) [log p θ (x, z) -log q φ (z|x)] (2.25) = E p( ) [log p θ (x, z) -log q φ (z|x)] (2.26)</formula><p>where z = g( , φ, x).</p><p>As a result we can form a simple Monte Carlo estimator Lθ,φ (x) of the individual-datapoint ELBO where we use a single noise sample from p( ):</p><formula xml:id="formula_31">∼ p( ) (2.27) z = g(φ, x, ) (2.28) Lθ,φ (x) = log p θ (x, z) -log q φ (z|x) (2.29)</formula><p>This series of operations can be expressed as a symbolic graph in software like TensorFlow, and effortlessly differentiated w.r.t. the parameters θ and φ. The resulting gradient ∇ φ Lθ,φ (x) is used to optimize the ELBO using minibatch SGD. See algorithm 1. This algorithm was originally referred to as the Auto-Encoding Variational Bayes (AEVB) algorithm by <ref type="bibr">Kingma and Welling, 2014</ref>. More generally, the reparameterized ELBO estimator was referred to as the Stochastic Gradient Variational Bayes (SGVB) estimator. This estimator can also be used to estimate a posterior over the model parameters, as explained in the appendix of <ref type="bibr">(Kingma and Welling, 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unbiasedness</head><p>This gradient is an unbiased estimator of the exact single-datapoint ELBO gradient; when averaged over noise ∼ p( ), this gradient equals the single-datapoint ELBO gradient:</p><formula xml:id="formula_32">E p( ) ∇ θ,φ Lθ,φ (x; ) = E p( ) [∇ θ,φ (log p θ (x, z) -log q φ (z|x))] (2.30) = ∇ θ,φ (E p( ) [log p θ (x, z) -log q φ (z|x)]) (2.31) = ∇ θ,φ L θ,φ (x)</formula><p>(2.32)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.4">Computation of log q φ (z|x)</head><p>Computation of the (estimator of) the ELBO requires computation of the density log q φ (z|x), given a value of x, and given a value of z or equivalently . This log-density is a simple computation, as long as we choose the right transformation g().</p><p>Note that we typically know the density p( ), since this is the density of the chosen noise distribution. As long as g(.) is an invertible function, the densities of and z are related as:</p><formula xml:id="formula_33">log q φ (z|x) = log p( ) -log d φ (x, ) (2.33)</formula><p>where the second term is the log of the absolute value of the determinant of the Jacobian matrix (∂z/∂ ):</p><formula xml:id="formula_34">log d φ (x, ) = log det ∂z ∂ (2.34)</formula><p>We call this the log-determinant of the transformation from to z. We use the notation log d φ (x, ) to make explicit that this log-determinant, similar to g(), is a function of x, and φ. The Jacobian matrix contains all first derivatives of the transformation from to z:</p><formula xml:id="formula_35">∂z ∂ = ∂(z 1 , ..., z k ) ∂( 1 , ..., k ) =     ∂z 1 ∂ 1 • • • ∂z 1 ∂ k . . . . . . . . . ∂z k ∂ 1 • • • ∂z k ∂ k     (2.35)</formula><p>As we will show, we can build very flexible transformations g() for which log d φ (x, ) is simple to compute, resulting in highly flexible inference models q φ (z|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Factorized Gaussian posteriors</head><p>A common choice is a simple factorized Gaussian encoder</p><formula xml:id="formula_36">q φ (z|x) = N (z; µ, diag(σ 2 )): (µ, log σ) = EncoderNeuralNet φ (x) (2.36) q φ (z|x) = i q φ (z i |x) = i N (z i ; µ i , σ 2 i ) (2.37)</formula><p>where N (z i ; µ i , σ 2 i ) is the PDF of the univariate Gaussian distribution. After reparameterization, we can write:</p><formula xml:id="formula_37">∼ N (0, I) (2.38) (µ, log σ) = EncoderNeuralNet φ (x) (2.39) z = µ + σ (2.40)</formula><p>where is the element-wise product. The Jacobian of the transformation from to z is:</p><formula xml:id="formula_38">∂z ∂ = diag(σ),<label>(2.41)</label></formula><p>i.e. a diagonal matrix with the elements of σ on the diagonal. The determinant of a diagonal (or more generally, triangular) matrix is the product of its diagonal terms. The log determinant of the Jacobian is therefore:</p><formula xml:id="formula_39">log d φ (x, ) = log det ∂z ∂ = i log σ i (2.42)</formula><p>and the posterior density is:</p><formula xml:id="formula_40">log q φ (z|x) = log p( ) -log d φ (x, ) (2.43) = i log N ( i ; 0, 1) -log σ i (2.44)</formula><p>when z = g( , φ, x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Full-covariance Gaussian posterior</head><p>The factorized Gaussian posterior can be extended to a Gaussian with full covariance:</p><formula xml:id="formula_41">q φ (z|x) = N (z; µ, Σ) (2.45)</formula><p>A reparameterization of this distribution is given by:</p><formula xml:id="formula_42">∼ N (0, I) (2.46) z = µ + L (2.47)</formula><p>where L is a lower (or upper) triangular matrix, with non-zero entries on the diagonal. The off-diagonal elements define the correlations (covariances) of the elements in z.</p><p>The reason for this parameterization of the full-covariance Gaussian, is that the Jacobian determinant is remarkably simple. The Jacobian in this case is trivial: ∂z ∂ = L. Note that the determinant of a triangular matrix is the product of its diagonal elements. Therefore, in this parameterization:</p><formula xml:id="formula_43">log | det( ∂z ∂ )| = i log |L ii | (2.48)</formula><p>And the log-density of the posterior is:</p><formula xml:id="formula_44">log q φ (z|x) = log p( ) - i log |L ii | (2.49)</formula><p>This parameterization corresponds to the Cholesky decomposition Σ = LL T of the covariance of z:</p><formula xml:id="formula_45">Σ = E (z -E [z|])(z -E [z|]) T (2.50) = E L (L ) T = LE T L T (2.51) = LL T (2.52)</formula><p>Note that E T = I since ∼ N (0, I). One way to build a matrix L with the desired properties, namely triangularity and non-zero diagonal entries, is by constructing it as follows:</p><formula xml:id="formula_46">(µ, log σ, L ) ← EncoderNeuralNet φ (x) (2.53) L ← L mask L + diag(σ) (2.54)</formula><p>and then proceeding with z = µ + L as described above. L mask is a masking matrix with zeros on and above the diagonal, and ones below the diagonal. Note that due to the masking L, the Jacobian matrix (∂z/∂ ) is triangular with the values of σ on the diagonal. The log-determinant is therefore identical to the factorized Gaussian case:</p><formula xml:id="formula_47">log det ∂z ∂ = i log σ i (2.55)</formula><p>More generally, we can replace z = L + µ with a chain of (differentiable and nonlinear) transformations; as long as the Jacobian of each step in the chain is triangular with non-zero diagonal entries, the log determinant remains simple. This principle is used by inverse autoregressive flow (IAF) as explored by <ref type="bibr" target="#b65">Kingma et al., 2016 and</ref>  L: unbiased estimate of the single-datapoint ELBO L θ,φ (x)</p><formula xml:id="formula_48">(µ, log σ, L ) ← EncoderNeuralNet φ (x) L ← L mask L + diag(σ) ∼ N (0, I) z ← L + µ Llogqz ← -i ( 1 2 ( 2 i + log(2π) + log σ i )) i = q φ (z|x) Llogpz ← -i ( 1 2 (z 2 i + log(2π))) = p θ (z) p ← DecoderNeuralNet θ (z) Llogpx ← i (x i log p i + (1 -x i ) log(1 -p i )) = p θ (x|z) L = Llogpx + Llogpz -Llogqz</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Estimation of the Marginal Likelihood</head><p>After training a VAE, we can estimate the probability of data under the model using an importance sampling technique, as originally proposed by <ref type="bibr" target="#b106">Rezende et al., 2014.</ref> The marginal likelhood of a datapoint can be written as:</p><formula xml:id="formula_49">log p θ (x) = log E q φ (z|x) [p θ (x, z)/q φ (z|x)]</formula><p>(2.56)</p><p>Taking random samples from q φ (z|x), a Monte Carlo estimator of this is:</p><formula xml:id="formula_50">log p θ (x) ≈ log 1 L L l=1 p θ (x, z (l) )/q φ (z (l) |x) (2.57)</formula><p>where each z (l) ∼ q φ (z|x) is a random sample from the inference model. By making L large, the approximation becomes a better estimate of the marginal likelihood, and in fact since this is a Monte Carlo estimator, for L → ∞ this converges to the actual marginal likelihood. Notice that when setting L = 1, this equals the ELBO estimator of the VAE. We can also use the estimator of eq. (2.57) as our objective function; this is the objective used in importance weighted autoencoders <ref type="bibr" target="#b11">(Burda et al., 2015)</ref> (IWAE). In that paper, it was also shown that the objective has increasing tightness for increasing value of L. It was later shown by <ref type="bibr" target="#b15">Cremer et al., 2017</ref> that the IWAE objective can be re-interpreted as an ELBO objective with a particular inference model. The downside of these approaches for optimizing a tighter bound, is that importance weighted estimates have notoriously bad scaling properties to high-dimensional latent spaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Marginal Likelihood and ELBO as KL Divergences</head><p>One way to improve the potential tightness of the ELBO, is increasing the flexibility of the generative model. This can be understood through a connection between the ELBO and the KL divergence.</p><p>With i.i.d. dataset D of size N D , the maximum likelihood criterion is:</p><formula xml:id="formula_51">log p θ (D) = 1 N D x∈D log p θ (x) (2.58) = E q D (x) [log p θ (x)] (2.59)</formula><p>where q D (x) is the empirical (data) distribution, which is a mixture distribution:</p><formula xml:id="formula_52">q D (x) = 1 N N i=1 q (i) D (x) (2.60)</formula><p>where each component q (i) D (x) typically corresponds to a Dirac delta distribution centered at value x (i) in case of continuous data, or a discrete distribution with all probability mass concentrated at value x (i)  in case of discrete data. The Kullback Leibler (KL) divergence between the data and model distributions, can be rewritten as the negative log-likelihood, plus a constant:</p><formula xml:id="formula_53">D KL (q D (x)||p θ (x)) = -E q D (x) [log p θ (x)] + E q D (x) [log q D (x)] (2.61) = -log p θ (D) + constant (2.62)</formula><p>where constant = -H(q D (x)). So minimization of the KL divergence above is equivalent to maximization of the data log-likelihood log p θ <ref type="bibr">(D)</ref>.</p><p>Taking the combination of the empirical data distribution q D (x) and the inference model, we get a joint distribution over data x and latent variables z: q D,φ (x, z) = q D (x)q(z|x).</p><p>The KL divergence of q D,φ (x, z) from p θ (x, z) can be written as the negative ELBO, plus a constant:</p><formula xml:id="formula_54">D KL (q D,φ (x, z)||p θ (x, z)) (2.63) = -E q D (x) E q φ (z|x) [log p θ (x, z) -log q φ (z|x)] -log q D (x) (2.64) = -L θ,φ (D) + constant (2.65)</formula><p>where constant = -H(q D (x)). So maximization of the ELBO, is equivalent to the minimization of this KL divergence D KL (q D,φ (x, z)||p θ (x, z)).</p><p>The relationship between the ML and ELBO objectives can be summa-rized in the following simple equation:</p><formula xml:id="formula_55">D KL (q D,φ (x, z)||p θ (x, z)) (2.66) = D KL (q D (x)||p θ (x)) + E q D (x) [D KL (q D,φ (z|x)||p θ (z|x))]</formula><p>(2.67)</p><formula xml:id="formula_56">≥ D KL (q D (x)||p θ (x)) (2.68)</formula><p>One additional perspective is that the ELBO can be viewed as a maximum likelihood objective in an augmented space. For some fixed choice of encoder q φ (z|x), we can view the joint distribution p θ (x, z) as an augmented empirical distribution over the original data x and (stochastic) auxiliary features z associated with each datapoint. The model p θ (x, z) then defines a joint model over the original data, and the auxiliary features. See figure 2.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Challenges</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.1">Optimization issues</head><p>In our work, consistent with findings in <ref type="bibr" target="#b9">(Bowman et al., 2015)</ref> and <ref type="bibr">(Sønderby et al., 2016a)</ref>, we found that stochastic optimization with the unmodified lower bound objective can gets stuck in an undesirable stable equilibrium. At the start of training, the likelihood term log p(x|z) is relatively weak, such that an initially attractive state is where q(z|x) ≈ p(z), resulting in a stable equilibrium from which it is difficult to escape. The solution proposed in <ref type="bibr" target="#b9">(Bowman et al., 2015)</ref> and <ref type="bibr">(Sønderby et al., 2016a)</ref> is to use an optimization schedule where the weights of the latent cost D KL (q(z|x)||p(z)) is slowly annealed from 0 to 1 over many epochs.</p><p>An alternative proposed in <ref type="bibr" target="#b65">(Kingma et al., 2016)</ref> is the method of free bits: a modification of the ELBO objective, that ensures that on average, a certain minimum number of bits of information are encoded per latent variable, or per group of latent variables.</p><p>The latent dimensions are divided into the K groups. We then use the following minibatch objective, which ensures that using less than λ nats of information per subset j (on average per minibatch M) is not The maximum likelihood (ML) objective can be viewed as the minimization of DKL(q D,φ (x)||p θ (x)), while the ELBO objective can be viewed as the minimization of DKL(q D,φ (x, z)||p θ (x, z)), which upper bounds DKL(q D,φ (x)||p θ (x)).</p><p>If a perfect fit is not possible, then p θ (x, z) will typically end up with higher variance than q D,φ (x, z), because of the direction of the KL divergence.</p><p>advantageous:</p><formula xml:id="formula_57">L λ = E x∼M E q(z|x) [log p(x|z)] (2.69) - K j=1 maximum(λ, E x∼M [D KL (q(z j |x)||p(z j ))] (2.70)</formula><p>Since increasing the latent information is generally advantageous for the first (unaffected) term of the objective (often called the negative reconstruction error), this results in E x∼M [D KL (q(z j |x)||p(z j ))] ≥ λ for all j, in practice. In <ref type="bibr" target="#b65">Kingma et al., 2016</ref> it was found that the method worked well for a fairly wide range of values (λ ∈ [0.125, 0.25, 0.5, 1, 2]), resulting in significant improvement in the resulting log-likelihood on a benchmark result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.2">Blurriness of generative model</head><p>In section 2.7 we saw that optimizing the ELBO is equivalent to minimizing D KL (q D,φ (x, z)||p θ (x, z)). If a perfect fit between q D,φ (x, z) and p θ (x, z) is not possible, then the variance of p θ (x, z) and p θ (x) will end up larger than the variance q D,φ (x, z) and the data q D,φ (x). This is due to the direction of the KL divergence; if there are values of (x, z) which are likely under q D,φ but not under p θ , the term E q D,φ (x,z) [log p θ (x, z)] will go to infinity. However, the reverse is not true: the generative model is only slightly penalized when putting probability mass on values of (x, z) with no support under q D,φ .</p><p>Issues with 'blurriness' can thus can be countered by choosing a sufficiently flexible inference model, and/or a sufficiently flexible generative model. In the next two chapters we will discuss techniques for constructing flexible inference models and flexible generative models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.9">Related prior and concurrent work</head><p>Here we briefly discuss relevant literature prior to and concurrent with the work in <ref type="bibr">(Kingma and Welling, 2014)</ref>.</p><p>The wake-sleep algorithm <ref type="bibr" target="#b50">(Hinton et al., 1995)</ref> is another on-line learning method, applicable to the same general class of continuous latent variable models. Like our method, the wake-sleep algorithm employs a recognition model that approximates the true posterior. A drawback of the wake-sleep algorithm is that it requires a concurrent optimization of two objective functions, which together do not correspond to optimization of (a bound of) the marginal likelihood. An advantage of wake-sleep is that it also applies to models with discrete latent variables. Wake-Sleep has the same computational complexity as AEVB per datapoint.</p><p>Variational inference has a long history in the field of machine learning. We refer to <ref type="bibr" target="#b132">(Wainwright and Jordan, 2008)</ref> for a comprehensive overview and synthesis of ideas around variational inference for exponential family graphical models. Among other connections, <ref type="bibr" target="#b132">(Wainwright and Jordan, 2008)</ref> shows how various inference algorithms (such as expectation propagation, sum-product, max-product and many others) can be understood as exact or approximate forms of variational inference.</p><p>Stochastic variational inference <ref type="bibr" target="#b52">Hoffman et al., 2013</ref> has received increasing interest. <ref type="bibr" target="#b5">Blei et al., 2012</ref> introduced a control variate schemes to reduce the variance of the score function gradient estimator, and applied the estimator to exponential family approximations of the posterior. In <ref type="bibr" target="#b102">(Ranganath et al., 2014</ref>) some general methods, e.g. a control variate scheme, were introduced for reducing the variance of the original gradient estimator. In <ref type="bibr" target="#b118">(Salimans and Knowles, 2013)</ref>, a similar reparameterization as in this work was used in an efficient version of a stochastic variational inference algorithm for learning the natural parameters of exponential-family approximating distributions.</p><p>In Graves, 2011 a similar estimator of the gradient is introduced; however the estimator of the variance is not an unbiased estimator w.r.t. the ELBO gradient.</p><p>The VAE training algorithm exposes a connection between directed probabilistic models (trained with a variational objective) and autoencoders. A connection between linear autoencoders and a certain class of generative linear-Gaussian models has long been known. In <ref type="bibr" target="#b111">(Roweis, 1998)</ref> it was shown that PCA corresponds to the maximum-likelihood (ML) solution of a special case of the linear-Gaussian model with a prior p(z) = N (0, I) and a conditional distribution p(x|z) = N (x; Wz, I), specifically the case with infinitesimally small . In this limiting case, the posterior over the latent variables p(z|x) is a Dirac delta distribution: p(z|x) = δ(z -W x) where W = (W T W) -1 W T , i.e., given W and x there is no uncertainty about latent variable z. <ref type="bibr" target="#b111">Roweis, 1998</ref> then introduces an EM-type approach to learning W. Much earlier work <ref type="bibr" target="#b8">(Bourlard and Kamp, 1988)</ref> showed that optimization of linear autoencoders retrieves the principal components of data, from which it follows that learning linear autoencoders correspond to a specific method for learning the above case of linear-Gaussian probabilistic model of the data. However, this approach using linear autoencoders is limited to linear-Gaussian models, while our approach applies to a much broader class of continuous latent variable models.</p><p>When using neural networks for both the inference model and the generative model, the combination forms a type of autoencoder <ref type="bibr" target="#b36">(Goodfellow et al., 2016)</ref> with a specific regularization term:</p><formula xml:id="formula_58">Lθ,φ (x; ) = log p θ (x|z)</formula><p>Negative reconstruction error</p><formula xml:id="formula_59">+ log p θ (z) -log q φ (z|x)</formula><p>Regularization terms</p><p>(2.71)</p><p>In an analysis of plain autoencoders <ref type="bibr" target="#b131">(Vincent et al., 2010)</ref> it was shown that the training criterion of unregularized autoencoders corresponds to maximization of a lower bound (see the infomax principle <ref type="bibr" target="#b82">(Linsker, 1989</ref>)) of the mutual information between input X and latent representation Z. Maximizing (w.r.t. parameters) of the mutual information is equivalent to maximizing the conditional entropy, which is lower bounded by the expected log-likelihood of the data under the autoencoding model <ref type="bibr" target="#b131">(Vincent et al., 2010)</ref>, i.e. the negative reconstruction error. However, it is well known that this reconstruction criterion is in itself not sufficient for learning useful representations <ref type="bibr" target="#b2">(Bengio et al., 2013)</ref>. Regularization techniques have been proposed to make autoencoders learn useful representations, such as denoising, contractive and sparse autoencoder variants <ref type="bibr" target="#b2">(Bengio et al., 2013)</ref>. The VAE objective contains a regularization term dictated by the variational bound, lacking the usual nuisance regularization hyper-parameter required to learn useful representations. Related are also encoder-decoder architectures such as the predictive sparse decomposition (PSD) <ref type="bibr" target="#b63">(Kavukcuoglu et al., 2008)</ref>, from which we drew some inspiration. Also relevant are the recently introduced Generative Stochastic Networks <ref type="bibr" target="#b3">(Bengio et al., 2014)</ref> where noisy autoencoders learn the transition operator of a Markov chain that samples from the data distribution. In <ref type="bibr" target="#b115">(Salakhutdinov and Larochelle, 2010)</ref> a recognition model was employed for efficient learning with Deep Boltzmann Machines. These methods are targeted at either unnormalized models (i.e. undirected models like Boltzmann machines) or limited to sparse coding models, in contrast to our proposed algorithm for learning a general class of directed probabilistic models.</p><p>The proposed DARN method <ref type="bibr" target="#b41">(Gregor et al., 2014)</ref>, also learns a directed probabilistic model using an autoencoding structure, however their method applies to binary latent variables. In concurrent work, <ref type="bibr" target="#b106">Rezende et al., 2014</ref> also make the connection between autoencoders, directed probabilistic models and stochastic variational inference using the reparameterization trick we describe in <ref type="bibr">(Kingma and Welling, 2014)</ref>. Their work was developed independently of ours and provides an additional perspective on the VAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.9.1">Score function estimator</head><p>An alternative unbiased stochastic gradient estimator of the ELBO is the score function estimator <ref type="bibr" target="#b70">(Kleijnen and Rubinstein, 1996)</ref>:</p><formula xml:id="formula_60">∇ φ E q φ (z|x) [f (z)] = E q φ (z|x) [f (z)∇ φ log q φ (z|x)]</formula><p>(2.72)</p><formula xml:id="formula_61">f (z)∇ φ log q φ (z|x) (2.73)</formula><p>where z ∼ q φ (z|x). This is also known as the likelihood ratio estimator <ref type="bibr" target="#b34">(Glynn, 1990;</ref><ref type="bibr" target="#b29">Fu, 2006)</ref> and the REINFORCE gradient estimator <ref type="bibr" target="#b135">(Williams, 1992)</ref>. The method has been successfully used in various methods like neural variational inference <ref type="bibr" target="#b91">(Mnih and Gregor, 2014)</ref>, black-box variational inference <ref type="bibr" target="#b102">(Ranganath et al., 2014)</ref>, automated variational inference <ref type="bibr" target="#b136">(Wingate and Weber, 2013)</ref>, and variational stochastic search <ref type="bibr" target="#b98">(Paisley et al., 2012)</ref>, often in combination with various novel control variate techniques <ref type="bibr" target="#b33">(Glasserman, 2013)</ref> for variance reduction. An advantage of the likelihood ratio estimator is its applicability to discrete latent variables.</p><p>We do not directly compare to these techniques, since we concern ourselves with continuous latent variables, in which case we have (computationally cheap) access to gradient information ∇ z log p θ (x, z), courtesy of the backpropagation algorithm. The score function estimator solely uses the scalar-valued log p θ (x, z), ignoring the gradient information about the function log p θ (x, z), generally leading to much higher variance. This has been experimentally confirmed by e.g. <ref type="bibr" target="#b73">(Kucukelbir et al., 2017)</ref>, which finds that a sophisticated score function estimator requires two orders of magnitude more samples to arrive at the same variance as a reparameterization based estimator.</p><p>The difference in efficiency of our proposed reparameterization-based gradient estimator, compared to score function estimators, can intuitively be understood as removing an information bottleneck during the computation of gradients of the ELBO w.r.t. φ from current parameters θ: in the latter case, this computation is bottlenecked by the scalar value log p θ (x, z), while in the former case it is bottlenecked by the much wider vector ∇ z log p θ (x, z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Beyond Gaussian Posteriors</head><p>In this chapter we discuss techniques for improving the flexibility of the inference model q φ (z|x). Increasing the flexibility and accuracy of the inference model wel generally improve the tightness of the variational bound (ELBO), bringing it closer the true marginal likelihood objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Requirements for Computational Tractability</head><p>Requirements for the inference model, in order to be able to efficiently optimize the ELBO, are that it is (1) computationally efficient to compute and differentiate its probability density q φ (z|x), and (2) computationally efficient to sample from, since both these operations need to be performed for each datapoint in a minibatch at every iteration of optimization. If z is high-dimensional and we want to make efficient use of parallel computational resources like GPUs, then parallelizability of these operations across dimensions of z is a large factor towards efficiency. This requirement restricts the class of approximate posteriors q(z|x) that are practical to use. In practice this often leads to the use of simple Gaussian posteriors. However, as explained, we also need the density q(z|x) to be sufficiently flexible to match the true posterior p(z|x), in order to arrive at a tight bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Improving the Flexibility of Inference Models</head><p>Here we will review two general techniques for improving the flexibility of approximate posteriors in the context of gradient-based variational inference: auxiliary latent variables, and normalizing flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Auxiliary Latent Variables</head><p>One method for improving the flexibility of inference models, is through the introduction of auxiliary latent variables, as explored by <ref type="bibr" target="#b117">Salimans et al., 2015</ref><ref type="bibr" target="#b103">, (Ranganath et al., 2016)</ref> and <ref type="bibr" target="#b86">Maaløe et al., 2016.</ref> The methods work by augmenting both the inference model and the generative model with a continuous auxiliary variable, here denoted with u.</p><p>The inference model defines a distribution over both u and and z, which can, for example, factorize as:</p><formula xml:id="formula_62">q φ (u, z|x) = q φ (u|x)q φ (z|u, x) (3.1)</formula><p>This inference model augmented with u, implicitly defines a potentially powerful implicit marginal distribution:</p><formula xml:id="formula_63">q φ (z|x) = q φ (u, z|x) du (3.2)</formula><p>Likewise, we introduce an additional distribution in the generative model: such that our generative model is now over the joint distribution p θ (x, z, u). This can, for example, factorize as:</p><formula xml:id="formula_64">p θ (x, z, u) = p θ (u|x, z)p θ (x, z) (3.3)</formula><p>The ELBO objective with auxiliary variables, given empirical distribution q D (x), is then (again) equivalent to minimization of a KL divergence:</p><formula xml:id="formula_65">E q D (x) E q φ (u,z|x) [log p θ (x, z, u) -log q φ (u, z|x)] (3.4) = D KL (q D,φ (x, z, u)||p θ (x, z, u) (3.5)</formula><p>Recall that maximization of the original ELBO objective, without auxiliary variables, is equivalent to minimization of D KL (q D,φ (x, z)|| p θ (x, z)), and that maximization of the expected marginal likelihood is equivalent to minimization of D KL (q D,φ (x)||p θ (x)).</p><p>We can gain additional understanding into the relationship between the objectives, through the following equation:</p><formula xml:id="formula_66">D KL (q D,φ (x, z, u)||p θ (x, z, u)) (3.6) (= ELBO loss with auxiliary variables) = D KL (q D,φ (x, z)||p θ (x, z)) + E q D (x,z) [D KL (q D,φ (u|x, z)||p θ (u|x, z))] ≥ D KL (q D,φ (x, z)||p θ (x, z)) (3.7) (= original ELBO objective)) = D KL (q D (x)||p θ (x)) + E q D (x) [D KL (q D,φ (z|x)||p θ (z|x))] (3.8) ≥ D KL (q D (x)||p θ (x)) (3.9) (= Marginal log-likelihood objective)</formula><p>From this equation it can be seen that in principle, the ELBO gets worse by augmenting the VAE with an auxiliary variable u:</p><formula xml:id="formula_67">D KL (q D,φ (x, z, u)||p θ (x, z, u)) ≥ D KL (q D,φ (x, z)||p θ (x, z))</formula><p>But because we now have access to a much more flexible class of inference distributions, q φ (z|x), the original ELBO objective D KL (q D,φ (x, z)|| p θ (x, z)) can improve, potentially outweighing the additional cost of</p><formula xml:id="formula_68">E q D (x,z) [D KL (q D,φ (u|x, z)||p θ (u|x, z))].</formula><p>In <ref type="bibr" target="#b117">(Salimans et al., 2015)</ref>, <ref type="bibr" target="#b103">(Ranganath et al., 2016)</ref> and <ref type="bibr" target="#b86">(Maaløe et al., 2016)</ref> it was shown that auxiliary variables can indeed lead to significant improvements in models.</p><p>The introduction of auxiliary latent variables in the graph, are a special case of VAEs with multiple layers of latent variables, which are discussed in chapter 4. In our experiment with CIFAR-10, we make use of multiple layers of stochastic variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Normalizing Flows</head><p>An alternative approach towards flexible approximate posteriors is Normalizing Flow (NF), introduced by <ref type="bibr" target="#b108">(Rezende and Mohamed, 2015)</ref> in the context of stochastic gradient variational inference. In normalizing flows, we build flexible posterior distributions through an iterative procedure. The general idea is to start off with an initial random variable with a relatively simple distribution with a known (and computationally cheap) probability density function, and then apply a chain of invertible parameterized transformations f t , such that the last iterate z T has a more flexible distribution<ref type="foot" target="#foot_0">foot_0</ref> :</p><formula xml:id="formula_69">0 ∼ p( ) (3.10) for t = 1...T : (3.11) t = f t ( t-1 , x) (3.12) z = T (3.13)</formula><p>The Jacobian of the transformation factorizes:</p><formula xml:id="formula_70">dz d 0 = T t=1 d t d t-1 (3.14)</formula><p>So its determinant also factorizes as well:</p><formula xml:id="formula_71">log det dz d 0 = T t=1 log det d t d t-1 (3.15)</formula><p>As long as the Jacobian determinant of each of the transformations f t can be computed, we can still compute the probability density function of the last iterate:</p><formula xml:id="formula_72">log q φ (z|x) = log p( 0 ) - T t=1 log det d t d t-1 (3.16)</formula><p>Rezende and Mohamed, 2015 experimented with a transformation of the form:</p><formula xml:id="formula_73">f t ( t-1 ) = t-1 + uh(w T t-1 + b) (3.17)</formula><p>where u and w are vectors, w T is w transposed, b is a scalar and h(.) is a nonlinearity, such that uh(w T z t-1 + b) can be interpreted as a MLP with a bottleneck hidden layer with a single unit. This flow does not scale well to a high-dimensional latent space: since information goes through the single bottleneck, a long chain of transformations is required to capture high-dimensional dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Inverse Autoregressive Transformations</head><p>In order to find a type of normalizing flow that scales well to a highdimensional space, <ref type="bibr" target="#b65">Kingma et al., 2016</ref> consider Gaussian versions of autoregressive autoencoders such as MADE <ref type="bibr" target="#b31">(Germain et al., 2015)</ref> and the <ref type="bibr">PixelCNN (Van Oord et al., 2016)</ref>. Let y be a variable modeled by such a model, with some chosen ordering on its elements y = {y i } D i=1 . We will use [µ(y), σ(y)] to denote the function of the vector y, to the vectors µ and σ. Due to the autoregressive structure, the Jacobian matrix is triangular with zeros on the diagonal: ∂[µ i , σ i ]/∂y j = [0, 0] for j ≥ i. The elements [µ i (y 1:i-1 ), σ i (y 1:i-1 )] are the predicted mean and standard deviation of the i-th element of y, which are functions of only the previous elements in y.</p><p>Sampling from such a model is a sequential transformation from a noise vector ∼ N (0, I) to the corresponding vector y: y 0 = µ 0 +σ 0 0 , and for i &gt; 0, y i = µ i (y 1:i-1 ) + σ i (y 1:i-1 ) • i . The computation involved in this transformation is clearly proportional to the dimensionality D. Since variational inference requires sampling from the posterior, such models are not interesting for direct use in such applications. However, the inverse transformation is interesting for normalizing flows. As long as we have σ i &gt; 0 for all i, the sampling transformation above is a one-to-one transformation, and can be inverted:</p><formula xml:id="formula_74">i = y i -µ i (y 1:i-1 ) σ i (y 1:i-1 ) (3.18)</formula><p>Kingma et al., 2016 make two key observations, important for normalizing flows. The first is that this inverse transformation can be parallelized, since (in case of autoregressive autoencoders) computations of the individual elements i do not depend on each other. The vectorized transformation is: = (yµ(y))/σ(y) <ref type="bibr">(3.19)</ref> where the subtraction and division are element-wise.</p><p>The second key observation, is that this inverse autoregressive operation has a simple Jacobian determinant. Note that due to the autoregressive structure, ∂[µ i , σ i ]/∂y j = [0, 0] for j ≥ i. As a result, the transformation has a lower triangular Jacobian (∂ i /∂y j = 0 for j &gt; i), with a simple diagonal: ∂ i /∂y i = 1 σ i . The determinant of a lower triangular matrix equals the product of the diagonal terms. As a result, the log-determinant of the Jacobian of the transformation is remarkably simple and straightforward to compute:</p><formula xml:id="formula_75">log det d dy = D i=1 -log σ i (y) (3.20)</formula><p>The combination of model flexibility, parallelizability across dimensions, and simple log-determinant, makes this transformation interesting for use as a normalizing flow over high-dimensional latent space.</p><p>For the following section we will use a slightly different, but equivalently flexible, transformation of the type: We let an initial encoder neural network output µ 0 and σ 0 , in addition to an extra output h, which serves as an additional input to each subsequent step in the flow. The chain is initialized with a factorized Gaussian q φ (z 0 |x) = N (µ 0 , diag(σ 0 ) 2 ):</p><formula xml:id="formula_76">0 ∼ N (0, I) (3.23) (µ 0 , log σ 0 , h) = EncoderNeuralNet(x; θ) (3.24) z 0 = µ 0 + σ 0 0 (3.25)</formula><p>Algorithm 3: Pseudo-code of an approximate posterior with Inverse Autoregressive Flow (IAF). Input: EncoderNN(x; θ) is an encoder neural network, with additional output h. Input: AutoregressiveNN(z; h, t, θ) is a neural network that is autoregressive over z, with additional inputs h and t. Input: T signifies the number of steps of flow. Data:</p><p>x: a datapoint, and optionally other conditioning information θ: neural network parameters Result:</p><p>z: a random sample from q(z|x), the approximate posterior distribution l: the scalar value of log q(z|x), evaluated at sample 'z'</p><formula xml:id="formula_77">[µ, σ, h] ← EncoderNN(x; θ) ∼ N (0, I) z ← σ + µ l ← -i (log σ i + 1 2 2 i + 1 2 log(2π)) for t ← 1 to T do [m, s] ← AutoregressiveNN(z; h, t, θ) σ ← (1 + exp(-s)) -1 z ← σ z + (1 -σ) m l ← l -i (log σ i ) end</formula><p>IAF then consists of a chain of T of the following transformations: the final iterate is:</p><formula xml:id="formula_78">(µ t , σ t ) = AutoregressiveNeuralNet t ( t-1 , h; θ) (3.26) t = µ t + σ t t-1 (3.</formula><formula xml:id="formula_79">z ≡ T (3.28) log q(z|x) = - D i=1 1 2 2 i + 1 2 log(2π) + T t=0 log σ t,i (3.29)</formula><p>The flexibility of the distribution of the final iterate T , and its ability to closely fit to the true posterior, increases with the expressivity of the autoregressive models and the depth of the chain. See figure <ref type="figure">3</ref>.1 for an illustration of the computation.</p><p>A numerically stable version, inspired by the LSTM-type update, is where we let the autoregressive network output (m t , s t ), two uncon-  strained real-valued vectors, and compute t as:</p><formula xml:id="formula_80">(m t , s t ) = AutoregressiveNeuralNet t ( t-1 , h; θ) (3.30) σ t = sigmoid(s t ) (3.31) t = σ t t-1 + (1 -σ t ) m t (3.32)</formula><p>This version is shown in algorithm 3. Note that this is just a particular version of the update of eq. (3.27), so the simple computation of the final log-density of eq. (3.29) still applies. It was found beneficial for results to parameterize or initialize the parameters of each AutoregressiveNeuralNet t such that its outputs s t are, before optimization, sufficiently positive, such as close to +1 or +2. This leads to an initial behavior that updates only slightly with each step of IAF. Such a parameterization is known as a 'forget gate bias' in LSTMs, as investigated by <ref type="bibr" target="#b61">Jozefowicz et al., 2015.</ref> It is straightforward to see that a special case of IAF with one step, and a linear autoregressive model, is the fully Gaussian posterior discussed earlier. This transforms a Gaussian variable with diagonal covariance, to one with linear dependencies, i.e. a Gaussian distribution with full covariance.</p><p>Autoregressive neural networks form a rich family of nonlinear transformations for IAF. For non-convolutional models, the family of masked autoregressive network introduced in <ref type="bibr" target="#b31">(Germain et al., 2015)</ref> was used as the autoregressive neural networks. For CIFAR-10 experiments, which benefits more from scaling to high dimensional latent space, the family of convolutional autoregressive autoencoders introduced by <ref type="bibr">(Van Oord et al., 2016;</ref><ref type="bibr" target="#b129">Van den Oord et al., 2016)</ref> was used.</p><p>It was found that results improved when reversing the ordering of the variables after each step in the IAF chain. This is a volume-preserving transformation, so the simple form of eq. (3.29) remains unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Related work</head><p>As we explained, inverse autoregressive flow (IAF) is a member of the family of normalizing flows, first discussed in <ref type="bibr" target="#b108">(Rezende and Mohamed, 2015)</ref> in the context of stochastic variational inference. In <ref type="bibr" target="#b108">(Rezende and Mohamed, 2015)</ref> two specific types of flows are introduced: planar flow (eq. (3.17)) and radial flow. These flows are shown to be effective to problems with a relatively low-dimensional latent space. It is not clear, however, how to scale such flows to much higher-dimensional latent spaces, such as latent spaces of generative models of larger images, and how planar and radial flows can leverage the topology of latent space, as is possible with IAF. Volume-conserving neural architectures were first presented in in <ref type="bibr" target="#b17">(Deco and Brauer, 1995)</ref>, as a form of nonlinear independent component analysis.</p><p>Another type of normalizing flow, introduced by (Dinh et al., 2014) (NICE), uses similar transformations as IAF. In contrast with IAF, NICE was directly applied to the observed variables in a generative model. NICE is type of transformations that updates only half of the variables z 1:D/2 per step, adding a vector f (z D/2+1:D ) which is a neural network based function of the remaining latent variables z D/2+1:D . Such large blocks have the advantage of computationally cheap inverse transformation, and the disadvantage of typically requiring longer chains. In experiments, <ref type="bibr" target="#b108">(Rezende and Mohamed, 2015)</ref> found that this type of transformation is generally less powerful than other types of normalizing flow, in experiments with a low-dimensional latent space. Concurrently to our work, NICE was extended to high-dimensional spaces in <ref type="bibr" target="#b21">(Dinh et al., 2016)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(Real NVP).</head><p>A potentially powerful transformation is the Hamiltonian flow used in Hamiltonian Variational Inference <ref type="bibr" target="#b117">(Salimans et al., 2015)</ref>. Here, a transformation is generated by simulating the flow of a Hamiltonian system consisting of the latent variables z, and a set of auxiliary momentum variables. This type of transformation has the additional benefit that it is guided by the exact posterior distribution, and that it leaves this distribution invariant for small step sizes. Such a transformation could thus take us arbitrarily close to the exact posterior distribution if we can apply it a sufficient number of times. In practice, however, Hamiltonian Variational Inference is very demanding computationally. Also, it requires an auxiliary variational bound to account for the auxiliary variables, which can impede progress if the bound is not sufficiently tight.</p><p>An alternative method for increasing the flexibility of variational inference is the introduction of auxiliary latent variables <ref type="bibr" target="#b117">(Salimans et al., 2015;</ref><ref type="bibr" target="#b103">Ranganath et al., 2016;</ref><ref type="bibr" target="#b128">Tran et al., 2015)</ref>, discussed in 3.2.1, and corresponding auxiliary inference models. Latent variable models with multiple layers of stochastic variables, such as the one used in our experiments, are often equivalent to such auxiliary-variable methods. We combine deep latent variable models with IAF in our experiments, benefiting from both techniques.</p><p>In the previous chapter we explain advanced strategies for improving inference models. In this chapter, we review strategies for learning deeper generative models, such as inference and learning with multiple latent variables or observed variables, and techniques for improving the flexibility of the generative models p θ (x, z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Inference and Learning with Multiple Latent Variables</head><p>The generative model p θ (x, z), and corresponding inference model q φ (z|x) can be parameterized as any directed graph. Both x and z can be composed of multiple variables with some topological ordering. It may not be immediately obvious how to optimize such models in the VAE framework; it is, however, quite straightforward, as we will now explain.</p><p>Let z = {z 1 , ..., z K }, and q φ (z|x) = q φ (z 1 , ..., z K |x) where the subscript corresponds with the topological ordering of each variable. Given a datapoint x, computation of the ELBO estimator consists of two steps:</p><p>1. Sampling z ∼ q φ (z|x). In case of multiple latent variables, this means ancestral sampling the latent variables one by one, in topological ordering defined by the inference model's directed graph. In pseudo-code, the ancestral sampling step looks like:</p><p>for i = 1...K : (4.1)</p><formula xml:id="formula_81">z i ∼ q φ (z i |P a(z i )) (4.2)</formula><p>where P a(z i ) are the parents of variable z i in the inference model, which may include x. In reparameterized (and differentiable) form, this is:</p><formula xml:id="formula_82">for i = 1...K : (4.3) i ∼ p( i ) (4.4) z i = g i ( i , P a(z i ), φ) (4.5)</formula><p>2. Evaluating the scalar value (log p θ (x, z) -log q φ (z|x)) at the resulting sample z and datapoint x. This scalar is the unbiased stochastic estimate lower bound on log p θ (x). It is also differentiable and optimizable with SGD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Choice of ordering</head><p>It should be noted that the choice of latent variables' topological ordering for the inference model can be different from the choice of ordering for the generative model. Since the inference model has the data as root node, while the generative model has the data as leaf node, one (in some sense) logical choice would be to let the topological ordering of the latent variables in the inference model be the reverse of the ordering in the generative model.</p><p>In multiple works <ref type="bibr" target="#b116">(Salimans, 2016;</ref><ref type="bibr">Sønderby et al., 2016a;</ref><ref type="bibr" target="#b65">Kingma et al., 2016)</ref> it has been shown that it can be advantageous to let the generative model and inference model share the topological ordering of latent variables. The two choices of ordering are illustrated in figure 4.1. One advantage of shared ordering, as explained in these works, is that this allows us to easily share parameters between the inference and generative models, leading to faster learning and better solutions.  To see why this might be a good idea, note that the true posterior over the latent variables, is a function of the prior:</p><formula xml:id="formula_83">p θ (z|x) ∝ p θ (z)p θ (x|z) (4.6)</formula><p>Likewise, the posterior of a latent variable given its parents (in the generative model), is:</p><formula xml:id="formula_84">p θ (z i |x, P a(z i )) ∝ p θ (z i |P a(z i ))p θ (x|z i , P a(z i )) (4.7)</formula><p>Optimization of the generative model changes both p θ (z i |P a(z i )) and p θ (x|z i , P a(z i )). By coupling the inference model q φ (z i |x, P a(z i )) and prior p θ (z i |P a(z i )), changes in p θ (z i |P a(z i )) can be directly reflected in changes in q φ (z i |P a(z i )). This coupling is especially straightforward when p θ (z i |P a(z i )) is Gaussian distributed. The inference model can be directly specified as the product of this Gaussian distribution, with a learned quadratic pseudo-likelihood term:</p><formula xml:id="formula_85">q φ (z i |P a(z i ), x) = p θ (z i |P a(z i )) l(z i ; x, P a(z i ))/Z,</formula><p>where Z is tractable to compute. This idea is explored by <ref type="bibr" target="#b116">(Salimans, 2016)</ref> and <ref type="bibr">(Sønderby et al., 2016a)</ref>. In principle this idea could be extended to a more general class of conjugate priors, but no work on this is known at the time of writing.</p><p>A less constraining variant, explored by <ref type="bibr" target="#b65">(Kingma et al., 2016)</ref>, is to simply let the neural network that parameterizes q φ (z i |P a(z i ), x) be partially specified by a part of the neural network that parameterizes p θ (z i |P a(z i )). In general, we can let the two distributions share parameters. This allows for more complicated posteriors, like normalizing flows or IAF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Alternative methods for increasing expressivity</head><p>Typically, especially with large data sets, we wish to choose an expressive class of directed models, such that it can feasibly approximate the true distribution. Popular strategies for specifying expressive models are:</p><p>• Introduction of latent variables into the directed models, and optimization through (amortized) variational inference, as explained in this work.</p><p>• Full autoregression: factorization of distributions into univariate (one-dimensional) conditionals, or at least very low-dimensional conditionals (section 4.3).</p><p>• Specification of distributions through invertible transformations with tractable Jacobian determinant (section 4.4).</p><p>Synthesis from fully autoregressive models models is relatively slow, since the length of computation for synthesis from such models is linear in the dimensionality of the data. The length of computation of the log-likelihood of fully autoregressive models does not necesarilly scale with the dimensionality of the data. In this respect, introduction of latent variables for improving expressivity is especially interesting when x is very high-dimensional. It is relatively straightforward and computationally attractive, due to parallelizability, to specify directed models over high-dimensional variables where each conditional factorizes into independent distributions. For example, if we let p θ (x j |P a(x j )) = k p θ (x j,k |P a(x j )), where each factor is a univariate Gaussian whose means and variance are nonlinear functions (specified by a neural network) of the parents P a(x j ), then computations for both synthesis and evaluation of log-likelihood can be fully parallelized across dimensions k. See <ref type="bibr" target="#b65">(Kingma et al., 2016)</ref> for experiments demonstrating a 100x improvement in speed of synthesis.</p><p>The best models to date, in terms of attained log-likelihood on test data, employ a combination of the three approaches listed above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Autoregressive Models</head><p>A powerful strategy for modeling high-dimensional data is to divide up the high-dimensional observed variables into small constituents (often single dimensional parts, or otherwise just parts with a small number of dimensions), impose a certain ordering, and to model their dependencies as a directed graphical model. The resulting directed graphical model breaks up the joint distribution into a product of a factors:</p><formula xml:id="formula_86">p θ (x) = p θ (x 1 , ..., x D ) = p θ (x 1 ) T j=2 p θ (x j |P a(x j )) (4.8)</formula><p>where D is the dimensionality of the data. This is known as an autoregressive (AR) model. In case of neural network based autoregressive models, we let the conditional distributions be parameterized with a neural network:</p><formula xml:id="formula_87">p θ (x j |x &lt;j ) = p θ (x j |NeuralNet j θ (P a(x j ))) (4.9)</formula><p>In case of continuous data, autoregressive models can be interpreted as a special case of a more general approach: learning an invertible transformation from the data to a simpler, known distribution such as 4.4. Invertible transformations with tractable Jacobian determinant 53 a Gaussian or Uniform distribution; this approach with invertible transformations is discussed in section 4.4. The techniques of autoregressive models and invertible transformations can be naturally combined with variational autoencoders, and at the time of writing, the best systems use a combination <ref type="bibr" target="#b108">Rezende and Mohamed, 2015;</ref><ref type="bibr" target="#b65">Kingma et al., 2016;</ref><ref type="bibr" target="#b44">Gulrajani et al., 2017</ref>.</p><p>A disadvantage of autoregressive models, compared to latent-variable models, is that ancestral sampling from autoregressive models is a sequential operation computation of O(D) length, i.e. proportional to the dimensionality of the data. Autoregressive models also require choosing a specific ordering of input elements (equation (4.8)). When no single natural one-dimensional ordering exists, like in two-dimensional images, this leads to a model with a somewhat awkward inductive bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Invertible transformations with tractable Jacobian determinant</head><p>In case of continuous data, autoregressive models can be interpreted as a special case of a more general approach: learning an invertible transformation with tractable Jacobian determinant (also called normalizing flow) from the data to a simpler, known distribution such as a Gaussian or Uniform distribution. If we use neural networks for such invertible mappings, this is a powerful and flexible approach towards probabilistic modeling of continuous data and nonlinear independent component analysis <ref type="bibr" target="#b17">(Deco and Brauer, 1995)</ref>.</p><p>Such normalizing flows iteratively update a variable, which is constrained to be of the same dimensionality as the data, to a target distribution. This constraint on the dimensionality of intermediate states of the mapping can make such transformations more challenging to optimize than methods without such constraint. An obvious advantage, on the other hand, is that the likelihood and its gradient are tractable. In <ref type="bibr" target="#b20">(Dinh et al., 2014;</ref><ref type="bibr" target="#b21">Dinh et al., 2016)</ref>, particularly interesting flows (NICE and Real NVP) were introduced, with equal computational cost and depth in both directions, making it both relatively cheap to optimize and to sample from such models. At the time of writing, no such model has yet been demonstrated to lead to the similar performance as purely autoregressive or VAE-based models in terms of data log-likelihood, but this remains an active area of research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Follow-Up Work</head><p>Some important applications and motivations for deep generative models and variational autoencoders are:</p><p>• Representation learning: learning better representations of the data. Some uses of this are:</p><p>-Data-efficient learning, such as semi-supervised learning -Visualisation of data as low-dimensional manifolds</p><p>• Artificial creativity: plausible interpolation between data and extrapolation from data.</p><p>Here we will now highlight some concrete applications to representation learning and artificial creativity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Representation Learning</head><p>In the case of supervised learning, we typically aim to learn a conditional distribution: to predict the distribution over the possible values of a variable, given the value of some another variable. One such problem is that of image classification: given an image, the prediction of a distribution over the possible class labels. Through the yearly ImageNet competion <ref type="bibr" target="#b114">(Russakovsky et al., 2015)</ref>, it has become clear that deep convolutional neural networks <ref type="bibr" target="#b79">(LeCun et al., 1998;</ref><ref type="bibr" target="#b36">Goodfellow et al., 2016)</ref> (CNNs), given a large amount of labeled images, are extraordinarily good at solving the image classification task. Modern versions of CNNs based on residual networks, which is a variant of LSTM-type neural networks <ref type="bibr" target="#b51">(Hochreiter and Schmidhuber, 1997)</ref>, now arguably achieves human-level classification accuracy on this task <ref type="bibr" target="#b45">(He et al., 2015;</ref><ref type="bibr" target="#b46">He et al., 2016)</ref>.</p><p>When the number of labeled examples is low, solutions found with purely supervised approaches tend to exhibit poor generalization to new data. In such cases, generative models can be employed as an effective type of regularization. One particular strategy, presented in <ref type="bibr">Kingma et al., 2014, is</ref> to optimize the classification model jointly with a variational autoencoder over the input variables, sharing parameters between the two. The variational autoencoder, in this case, provides an auxiliary objective, improving the data efficiency of the classification solution. Through sharing of statistical strength between modeling problems, this can greatly improve upon the supervised classification error. Techniques based on VAEs are now among state of the art for semisupervised classification <ref type="bibr" target="#b86">(Maaløe et al., 2016)</ref>, with on average under 1% classification error in the MNIST classification problem, when trained with only 10 labeled images per class, i.e. when more than 99.8% of the labels in the training set were removed. In concurrent work <ref type="bibr" target="#b105">(Rezende et al., 2016a)</ref>, it was shown that VAE-based semi-supervised learning can even do well when only a single sample per class is presented.</p><p>A standard supervised approach, GoogLeNet <ref type="bibr" target="#b124">(Szegedy et al., 2015)</ref>, which normally achieves near state-of-the-art performance on the Ima-geNet validation set, achieves only around 5% top-1 classification accuracy when trained with only 1% of the labeled images, as shown by <ref type="bibr" target="#b101">Pu et al., 2016.</ref> In contrast, they show that a semi-supervised approach with VAEs achieves around 45% classification accuracy on the same task, when modeling the labels jointly with the labeled and unlabeled input images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Understanding of data, and artificial creativity</head><p>Generative models with latent spaces allow us to transform the data into a simpler latent space, explore it in that space, and understand it better. A related branch of applications of deep generative models is the synthesis of plausible pseudo-data with certain desirable properties, sometimes coined as artificial creativity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chemical Design</head><p>One example of a recent scientific application of artificial creativity, is shown in <ref type="bibr" target="#b35">Gómez-Bombarelli et al., 2018.</ref> In this paper, a fairly straightforward VAE is trained on hundreds of thousands of existing chemical structures. The resulting continuous representation (latent space) is subsequently used to perform gradient-based optimization </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural Language Synthesis</head><p>A similar approach was used to generating natural-language sentences from a continuous space by <ref type="bibr" target="#b9">Bowman et al., 2015.</ref> In this paper, it is shown how a VAE can be successfully trained on text. The model is shown to succesfully interpolate between sentences, and for imputation of missing words. See figure 4.3.  <ref type="bibr" target="#b9">(Bowman et al., 2015)</ref>. The intermediate sentences are grammatically correct, and the topic and syntactic structure are typically locally consistent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Astronomy</head><p>In <ref type="bibr" target="#b104">(Ravanbakhsh et al., 2017)</ref>, VAEs are applied to simulate observations of distant galaxies. This helps with the calibration of systems that need to indirectly detect the shearing of observations of distant galaxies, caused by weak gravitational lensing in the presence of dark matter between earth and those galaxies. Since the lensing effects are so weak, such systems need to be calibrated with ground-truth images with a known amount of shearing. Since real data is still limited, the proposed solution is to use deep generative models for synthesis of pseudo-data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image (Re-)Synthesis</head><p>A popular application is image (re)synthesis. One can optimize a VAE to form a generative model over images. One can synthesize images from the generative model, but the inference model (or encoder) also allows one to encode real images into a latent space. One can modify the encoding in this latent space, then decode the image back into the observed space. Relatively simple transformations in the observed space, such as linear transformations, often translate into semantically meaningful modifications of the original image. One example, as demonstrated by White, 2016, is the modification of images in latent space along a "smile vector" in order to make them more happy, or more sad looking. See figure 4.4 for an example. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">Other relevant follow-up work</head><p>We unfortunately do not have space to discuss all follow-up work in depth, but will here highlight a selection of relevant recent work.</p><p>In addition to our original publication <ref type="bibr">(Kingma and Welling, 2014)</ref>, two later papers have proposed equivalent algorithms <ref type="bibr" target="#b106">(Rezende et al., 2014;</ref><ref type="bibr" target="#b77">Lázaro-Gredilla, 2014)</ref>, where the latter work applies the same reparameterization gradient method to the estimation of parameter posteriors, rather than amortized latent-variable inference.</p><p>In the appendix of <ref type="bibr">(Kingma and Welling, 2014)</ref> we proposed to apply the reparameterization gradients to estimation of parameter posteriors. In <ref type="bibr" target="#b6">(Blundell et al., 2015)</ref> this method, with a mixture-of-Gaussians prior and named Bayes by Backprop, was used in experiments with some promising early results. In <ref type="bibr">(Kingma et al., 2015)</ref> we describe a refined method, the local reparameterization trick, for further decreasing the variance of the gradient estimator, and applied it to estimation of Gaussian parameter posteriors. Further results were presented in <ref type="bibr">(Louizos et al., 2017;</ref><ref type="bibr">Louizos and Welling, 2017;</ref><ref type="bibr" target="#b84">Louizos and Welling, 2016)</ref> with increasingly sophisticated choices of priors and approximate posteriors. In <ref type="bibr">(Kingma et al., 2015;</ref><ref type="bibr" target="#b30">Gal and Ghahramani, 2016)</ref>, a similar reparameterization was used to analyze Dropout as a Bayesian method, coined Variational Dropout. In <ref type="bibr" target="#b94">(Molchanov et al., 2017)</ref> this method was further analyzed and refined. Various papers have applied reparameterization gradients for estimating parameter posteriors, including <ref type="bibr" target="#b27">(Fortunato et al., 2017)</ref> in the context of recurrent neural networks and <ref type="bibr" target="#b73">(Kucukelbir et al., 2017)</ref> more generally for Bayesian models and in <ref type="bibr" target="#b127">(Tran et al., 2017)</ref> for deep probabilistic programming. A Bayesian nonparametric variational family based in the Gaussian Process using reparameterization gradients was proposed in <ref type="bibr" target="#b128">(Tran et al., 2015)</ref>.</p><p>Normalizing flows <ref type="bibr" target="#b108">(Rezende and Mohamed, 2015)</ref> were proposed as a framework for improving the flexibility of inference models. In <ref type="bibr" target="#b65">Kingma et al., 2016</ref>, the first normalizing flow was proposed that scales well to high-dimensional latent spaces. The same principle was later applied in <ref type="bibr" target="#b99">(Papamakarios et al., 2017)</ref> for density estimation, and further refined in <ref type="bibr" target="#b58">(Huang et al., 2018)</ref>. Various other flows were proposed in <ref type="bibr" target="#b126">(Tomczak and Welling, 2016;</ref><ref type="bibr">Tomczak and Welling, n.d.)</ref> and <ref type="bibr" target="#b4">(Berg et al., 2017)</ref>.</p><p>As an alternative to (or in conjunction with) normalizing flows, one can use auxiliary variables to improve posterior flexibility. This principle was, to the best of our knowledge, first proposed in <ref type="bibr" target="#b117">Salimans et al., 2015.</ref> In this paper, the principle was used in a combination of variational inference with Hamiltonian Monte Carlo (HMC), with the momentum variables of HMC as auxiliary variables. Auxiliary variables were more elaborately discussed in in <ref type="bibr" target="#b86">(Maaløe et al., 2016)</ref> as Auxiliary Deep Generative Models. Similarly, one can use deep models with multiple stochastic layers to improve the variational bound, as demonstrated in <ref type="bibr">(Sønderby et al., 2016a)</ref> and <ref type="bibr" target="#b123">(Sønderby et al., 2016b)</ref> as Ladder VAEs.</p><p>There has been plenty of follow-up work on gradient variance reduction for the variational parameters of discrete latent variables, as opposed to continuous latent variables for which reparameterization gradients apply. These proposals include NVIL <ref type="bibr" target="#b91">(Mnih and Gregor, 2014)</ref>, MuProp <ref type="bibr" target="#b43">(Gu et al., 2015)</ref>, Variational inference for Monte Carlo objectives <ref type="bibr" target="#b92">(Mnih and Rezende, 2016)</ref>, the Concrete distribution <ref type="bibr" target="#b87">(Maddison et al., 2017)</ref> and Categorical Reparameterization with Gumbel-Softmax <ref type="bibr" target="#b59">(Jang et al., 2017)</ref>.</p><p>The ELBO objective can be generalized into an importance-weighted objective, as proposed in <ref type="bibr" target="#b11">(Burda et al., 2015)</ref> (Importance-Weighted Autoencoders). This potentially reduces the variance in the gradient, but has not been discussed in-depth here since (as often the case with importance-weighted estimators) it can be difficult to scale to highdimensional latent spaces. Other objectives have been proposed such as Rényi divergence variational inference <ref type="bibr" target="#b80">(Li and Turner, 2016)</ref>, Generative Moment Matching Networks <ref type="bibr" target="#b81">(Li et al., 2015)</ref>, objectives based on normalizing such as NICE and RealNVP flows <ref type="bibr" target="#b121">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b20">Dinh et al., 2014)</ref>, black-box α-divergence minimization <ref type="bibr" target="#b48">(Hernández-Lobato et al., 2016)</ref> and Bi-directional Helmholtz Machines <ref type="bibr" target="#b7">(Bornschein et al., 2016)</ref>.</p><p>Various combinations with adversarial objectives have been proposed. In <ref type="bibr" target="#b88">(Makhzani et al., 2015)</ref>, the "adversarial autoencoder" (AAE) was proposed, a probabilistic autoencoder that uses a generative adversarial network (GAN) <ref type="bibr" target="#b37">(Goodfellow et al., 2014)</ref> to perform variational inference. In <ref type="bibr" target="#b23">(Dumoulin et al., 2017)</ref> Adversarially Learned Inference (ALI) was proposed, which aims to minimize a GAN objective between the joint distributions q φ (x, z) and p θ (x, z). Other hybrids have been proposed as well <ref type="bibr" target="#b76">(Larsen et al., 2016;</ref><ref type="bibr" target="#b10">Brock et al., 2017;</ref><ref type="bibr" target="#b56">Hsu et al., 2017)</ref>.</p><p>One of the most prominent, and most difficult, applications of generative models is image modeling. In <ref type="bibr" target="#b74">(Kulkarni et al., 2015)</ref> (Deep convolutional inverse graphics network), a convolutional VAE was applied to modeling images with some success, building on work by <ref type="bibr" target="#b22">(Dosovitskiy et al., 2015)</ref> proposing convolutional networks for image synthesis. In <ref type="bibr" target="#b40">(Gregor et al., 2015)</ref> (DRAW), an attention mechanism was combined with a recurrent inference model and recurrent generative model for image synthesis. This approach was further extended in <ref type="bibr" target="#b39">(Gregor et al., 2016)</ref> (Towards Conceptual Compression) with convolutional networks, scalable to larger images, and applied to image compression. In <ref type="bibr" target="#b65">(Kingma et al., 2016)</ref>, deep convolutional inference models and generative models were also applied to images. Furthermore, <ref type="bibr" target="#b44">(Gulrajani et al., 2017)</ref> (PixelVAE) and <ref type="bibr" target="#b13">(Chen et al., 2017)</ref> (Variational Lossy Autoencoder) combined convolutional VAEs with the PixelCNN model <ref type="bibr">(Van Oord et al., 2016;</ref><ref type="bibr" target="#b129">Van den Oord et al., 2016)</ref>. Methods and VAE architectures for controlled image generation from attributes or text were studied in <ref type="bibr">(Kingma et al., 2014;</ref><ref type="bibr" target="#b138">Yan et al., 2016;</ref><ref type="bibr" target="#b89">Mansimov et al., 2015;</ref><ref type="bibr" target="#b10">Brock et al., 2017;</ref><ref type="bibr" target="#b134">White, 2016)</ref>. Predicting the color of pixels based on a grayscale image is another promising application <ref type="bibr" target="#b19">(Deshpande et al., 2017)</ref>. The application to semi-supervised learning has been studied in <ref type="bibr">(Kingma et al., 2014;</ref><ref type="bibr" target="#b101">Pu et al., 2016;</ref><ref type="bibr" target="#b137">Xu et al., 2017)</ref> among other work.</p><p>Another prominent application of VAEs is modeling of text and or sequential data <ref type="bibr" target="#b1">(Bayer and Osendorfer, 2014;</ref><ref type="bibr" target="#b9">Bowman et al., 2015;</ref><ref type="bibr" target="#b120">Serban et al., 2017;</ref><ref type="bibr" target="#b60">Johnson et al., 2016;</ref><ref type="bibr" target="#b62">Karl et al., 2017;</ref><ref type="bibr" target="#b28">Fraccaro et al., 2016;</ref><ref type="bibr" target="#b90">Miao et al., 2016;</ref><ref type="bibr" target="#b119">Semeniuta et al., 2017;</ref><ref type="bibr" target="#b140">Zhao et al., 2017;</ref><ref type="bibr" target="#b139">Yang et al., 2017;</ref><ref type="bibr" target="#b57">Hu et al., 2017)</ref>. VAEs have also been applied to speech and handwriting <ref type="bibr" target="#b14">Chung et al., 2015</ref>. Sequential models typically use recurrent neural networks, such as LSTMs <ref type="bibr" target="#b51">(Hochreiter and Schmidhuber, 1997)</ref>, as encoder and/or decoder. When modeling sequences, the validity of a sequence can sometimes be constrained by a context-free grammar. In this case, incorporation of the grammar in VAEs can lead to better models, as shown in <ref type="bibr" target="#b75">(Kusner et al., 2017)</ref> (Grammar VAEs), and applied to modeling molecules in textual representations.</p><p>Since VAEs can transform discrete observation spaces to continuous latent-variable spaces with approximately known marginals, they are interesting for use in model-based control <ref type="bibr" target="#b133">(Watter et al., 2015;</ref><ref type="bibr" target="#b100">Pritzel et al., 2017)</ref>. In <ref type="bibr" target="#b47">(Heess et al., 2015)</ref> (Stochastic Value Gradients) it was shown that the re-parameterization of the observed variables, together with an observation model, can be used to compute novel forms of policy gradients. Variational inference and reparameterization gradients have also been used for variational information maximisation for intrinsically motivated reinforcement learning <ref type="bibr" target="#b93">(Mohamed and Rezende, 2015)</ref> and VIME <ref type="bibr" target="#b54">(Houthooft et al., 2016)</ref> for improved exploration. Variational autoencoders have also been used as components in models that perform iterative reasoning about objects in a scene <ref type="bibr" target="#b25">(Eslami et al., 2016)</ref>.</p><p>In <ref type="bibr" target="#b49">(Higgins et al., 2017)</ref> (β-VAE) it was proposed to strengthen the contribution of D KL (q φ (z|x)||p θ (z)), thus restricting the information flow through the latent space, which was shown to improve disentanglement of latent factors, further studied in <ref type="bibr" target="#b12">(Chen et al., 2018)</ref>.</p><p>Other applications include modeling of graphs <ref type="bibr" target="#b69">(Kipf and Welling, 2016)</ref> (Variational Graph Autoencoders), learning of 3D structure from images <ref type="bibr" target="#b107">(Rezende et al., 2016b)</ref>, one-shot learning <ref type="bibr" target="#b105">(Rezende et al., 2016a)</ref>, learning nonlinear state space models <ref type="bibr" target="#b72">(Krishnan et al., 2017)</ref>, voice conversion from non-parallel corpora <ref type="bibr" target="#b55">(Hsu et al., 2016)</ref>, discriminationaware (fair) representations <ref type="bibr">(Louizos et al., 2015)</ref> and transfer learning <ref type="bibr" target="#b24">(Edwards and Storkey, 2017)</ref>.</p><p>The reparameterization gradient estimator discussed in this work has been extended in various directions <ref type="bibr" target="#b112">(Ruiz et al., 2016)</ref>, including acceptance-rejection sampling algorithms <ref type="bibr" target="#b95">(Naesseth et al., 2017)</ref>. The gradient variance can in some cases be reduced by 'carving up the ELBO' <ref type="bibr" target="#b53">(Hoffman and Johnson, 2016;</ref><ref type="bibr" target="#b109">Roeder et al., 2017)</ref> and using a modified gradient estimator. A second-order gradient estimator has also been proposed in <ref type="bibr" target="#b26">(Fan et al., 2015)</ref>.</p><p>All in all, this remains an actively researched area with frequently exciting developments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Directed probabilistic models form an important aspect of modern artificial intelligence. Such models can be made incredibly flexible by parameterizing the conditional distributions with differentiable deep neural networks.</p><p>Optimization of such models towards the maximum likelihood objective is straightforward in the fully-observed case. However, one is often more interested in flexible models with latent variables, such as deep latent-variable models, or Bayesian models with random parameters. In both cases one needs to perform approximate posterior estimation for which variational inference (VI) methods are suitable. In VI, inference is cast as an optimization problem over newly introduced variational parameters, typically optimized towards the ELBO, a lower bound on the model evidence, or marginal likelihood of the data. Existing methods for such posterior inference were either relatively inefficient, or not applicable to models with neural networks as components. Our main contribution is a framework for efficient and scalable gradient-based variational posterior inference and approximate maximum likelihood learning.</p><p>In this work we describe the variational autoencoder (VAE) and some of its extensions. A VAE is a combination of a deep latent-variable model (DLVM) with continuous latent variables, and an associated inference model. The DLVM is a type of generative model over the data. The inference model, also called encoder or recognition model, approximates the posterior distribution of the latent variables of the generative model. Both the generative model and the inference model are directed graphical models that are wholly or partially parameterized by deep neural networks. The parameters of the models, including the parameters of the neural networks such as the weights and biases, are jointly optimized by performing stochastic gradient ascent on the socalled evidence lower bound (ELBO). The ELBO is a lower bound on the marginal likelihood of the data, also called the variational lower bound. Stochastic gradients, necessary for performing SGD, are obtained through a basic reparameterization trick. The VAE framework is now a commonly used tool for various applications of probabilistic modeling and artificial creativity, and basic implementations are available in most major deep learning software libraries.</p><p>For learning flexible inference models, we proposed inverse autoregressive flows (IAF), a type of normalizing flow that allows scaling to high-dimensional latent spaces. An interesting direction for further exploration is comparison with transformations with computationally cheap inverses, such as NICE <ref type="bibr" target="#b20">(Dinh et al., 2014)</ref> and Real NVP <ref type="bibr" target="#b21">(Dinh et al., 2016)</ref>. Application of such transformations in the VAE framework can potentially lead to relatively simple VAEs with a combination of powerful posteriors, priors and decoders. Such architectures can potentially rival or surpass purely autoregressive architectures ( <ref type="bibr" target="#b129">Van den Oord et al., 2016)</ref>, while allowing much faster synthesis.</p><p>The proposed VAE framework remains the only framework in the literature that allows for both discrete and continuous observed variables, allows for efficient amortized latent-variable inference and fast synthesis, and which can produce close to state-of-the-art performance in terms of the log-likelihood of data.</p><p>Adam and Adamax optimization methods for choosing α t <ref type="bibr" target="#b68">(Kingma and Ba, 2015)</ref>; these methods are invariant to constant rescaling of the objective, and invariant to constant re-scalings of the individual gradients. As a result, L(θ, ξ) only needs to be unbiased up to proportionality. We iteratively apply eq. (A.15) until a stopping criterion is met. A simple but effective criterion is to stop optimization as soon as the probability of a holdout set of data starts decreasing; this criterion is called early stopping.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 2.2: Simple schematic of computational flow in a variational autoencoder.</figDesc><graphic coords="22,79.22,94.41,62.83,62.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 . 3 :</head><label>23</label><figDesc>Figure 2.3: Illustration of the reparameterization trick.The variational parameters φ affect the objective f through the random variable z ∼ q φ (z|x). We wish to compute gradients ∇ φ f to optimize the objective with SGD. In the original form (left), we cannot differentiate f w.r.t. φ, because we cannot directly backpropagate gradients through the random variable z. We can 'externalize' the randomness in z by re-parameterizing the variable as a deterministic and differentiable function of φ, x, and a newly introduced random variable . This allows us to 'backprop through z', and compute gradients ∇ φ f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure</head><label></label><figDesc>Figure 2.4:The maximum likelihood (ML) objective can be viewed as the minimization of DKL(q D,φ (x)||p θ (x)), while the ELBO objective can be viewed as the minimization of DKL(q D,φ (x, z)||p θ (x, z)), which upper bounds DKL(q D,φ (x)||p θ (x)). If a perfect fit is not possible, then p θ (x, z) will typically end up with higher variance than q D,φ (x, z), because of the direction of the KL divergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc><ref type="bibr" target="#b65">Kingma et al., 2016</ref> propose inverse autoregressive flow (IAF) based on a chain of transformations that are each equivalent to an inverse autoregressive transformation of eq. (3.19) and eq. (3.21). See algorithm 3 for pseudo-code of an approximate posterior with the proposed flow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 . 1 :</head><label>31</label><figDesc>Figure 3.1: Like other normalizing flows, drawing samples from an approximate posterior with Inverse Autoregressive Flow (IAF)<ref type="bibr" target="#b65">(Kingma et al., 2016)</ref> starts with a distribution with tractable density, such as a Gaussian with diagonal covariance, followed by a chain of nonlinear invertible transformations of z, each with a simple Jacobian determinant. The final iterate has a flexible distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>( a )</head><label>a</label><figDesc>Prior distribution (b) Factorized posteriors (c) IAF posteriors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 . 2 :</head><label>32</label><figDesc>Figure 3.2: Best viewed in color. We fitted a variational autoencoder (VAE) with a spherical Gaussian prior, and with factorized Gaussian posteriors (b) or inverse autoregressive flow (IAF) posteriors (c) to a toy dataset with four datapoints. Each colored cluster corresponds to the posterior distribution of one datapoint. IAF greatly improves the flexibility of the posterior distributions, and allows for a much better fit between the posteriors and the prior.</figDesc><graphic coords="48,55.53,76.54,110.38,112.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>VAE with top-down inference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 . 1 :</head><label>41</label><figDesc>Figure 4.1: Illustration, taken from Kingma et al., 2016, of two choices of directionality of the inference model. Sharing directionality of inference, as in (b), has the benefit that it allows for straightforward sharing of parameters between the generative model and the inference model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 . 2 :</head><label>42</label><figDesc>Figure 4.2: (a) Application of a VAE to chemical design in (Gómez-Bombarelli et al., 2018). A latent continuous representation z of molecules is learned on a large dataset of molecules. (b) This continuous representation enables gradient-based search of new molecules that maximizes f (z), a certain desired property.</figDesc><graphic coords="59,112.40,76.54,217.41,273.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 . 3 :</head><label>43</label><figDesc>Figure 4.3: An application of VAEs to interpolation between pairs of sentences, from<ref type="bibr" target="#b9">(Bowman et al., 2015)</ref>. The intermediate sentences are grammatically correct, and the topic and syntactic structure are typically locally consistent.</figDesc><graphic coords="60,137.48,76.53,167.24,122.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 4 . 4 :</head><label>44</label><figDesc>Figure 4.4: VAEs can be used for image resynthesis. In this example by White, 2016, an original image (left) is modified in a latent space in the direction of a smile vector, producing a range of versions of the original, from smiling to sadness.</figDesc><graphic coords="61,104.03,76.54,234.14,156.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Computation of unbiased estimate of singledatapoint ELBO for example VAE with a full-covariance Gaussian inference model and a factorized Bernoulli generative model. L mask is a masking matrix with zeros on and above the diagonal, and ones below the diagonal.</figDesc><table><row><cell>discussed in chapter</cell></row><row><cell>3.</cell></row><row><cell>Algorithm 2:</cell></row></table><note><p>Data: x: a datapoint, and optionally other conditioning information : a random sample from p( ) = N (0, I) θ: Generative model parameters φ: Inference model parameters q φ (z|x): Inference model p θ (x, z): Generative model Result:</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>where x is the context, such as the value of the datapoint. In case of models with multiple levels of latent variables, the context also includes the value of the previously sampled latent variables.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We are grateful for the help of <rs type="person">Tim Salimans</rs>, <rs type="person">Alec Radford</rs>, <rs type="person">Rif A. Saurous</rs> and others who have given us valuable feedback at various stages of writing.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example(s) Description x, y z</head><p>With characters in bold we typically denote random vectors. We also use this notation for collections of random variables variables.</p><p>x, y, z With characters in italic we typically denote random scalars, i.e. single real-valued numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X, Y, Z</head><p>With bold and capitalized letters we typically denote random matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P a(z)</head><p>The parents of random variable z in a directed graph.</p><p>diag(x) Diagonal matrix, with the values of vector x on the diagonal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix x y</head><p>Element-wise multiplication of two vectors. The resulting vector is (x 1 y 1 , ..., x K y K ) The parameters of a distribution are denoted with p(.; θ) or equivalently with subscript p θ (.).</p><p>We may use an (in-)equality sign within a probability distribution to distinguish between function arguments and value at which to evaluate. So p(x = a) denotes a PDF or PMF over variable x evaluated at the value of variable a. Likewise, p(x ≤ a) denotes a CDF evaluated at the value of a. p(.), q(.)</p><p>We use different letters to refer to different probabilistic models, such as p(.) or q(.). Conversely, we use the same letter across different marginals/conditionals to indicate they relate to the same probabilistic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.2 Definitions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Term Description</head><p>Probability density function (PDF)</p><p>A function that assigns a probability density to each possible value of given continuous random variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cumulative distribution function (CDF)</head><p>A function that assigns a cumulative probability density to each possible value of given univariate continuous random variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probability mass function (PMF)</head><p>A function that assigns a probability mass to given discrete random variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.3 Distributions</head><p>We overload the notation of distributions (e.g. p(x) = N (x; µ, Σ)) with two meanings: (1) a distribution from which we can sample, and (2) the probability density function (PDF) of that distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Term Description</head><p>Categorical(x; p) Categorical distribution, with parameter p such that i p i = 1. Recall the chain rule in probability:</p><p>Simply re-arranging terms above, the posterior distribution over the parameters θ, taking into account the data D, is:</p><p>where the proportionality (∝) holds since p(D) is a constant that is not dependent on parameters θ. The formula above is known as Bayes' rule, a fundamental formula in machine learning and statistics, and is of special importance to this work.</p><p>A principal application of Bayes' rule is that it allows us to make predictions about future data x , that are optimal as long as the prior p(θ) and model class p θ (x) are correct:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Alternative methods for learning in DLVMs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Maximum A Posteriori</head><p>From a Bayesian perspective, we can improve upon the maximum likelihood objective through maximum a posteriori (MAP) estimation, which maximizes the log-posterior w.r.t. θ. With i.i.d. data D, this is:</p><p>The prior p(θ) in equation (A.5) has diminishing effect for increasingly large N . For this reason, in case of optimization with large datasets, we often choose to simply use the maximum likelihood criterion by omitting the prior from the objective, which is numerically equivalent to setting p(θ) = constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Variational EM with local variational parameters</head><p>Expectation Maximization (EM) is a general strategy for learning parameters in partially observed models <ref type="bibr" target="#b18">(Dempster et al., 1977)</ref>. See section A.2.3 for a discussion of EM using MCMC. The method can be explained as coordinate ascent on the ELBO <ref type="bibr" target="#b97">(Neal and Hinton, 1998)</ref>.</p><p>In case of of i.i.d. data, traditional variational EM methods estimate local variational parameters φ (i) , i.e. a separate set of variational parameters per datapoint i in the dataset. In contrast, VAEs employ a strategy with global variational parameters. EM starts out with some (random) initial choice of θ and φ (1:N ) . It then iteratively applies updates:</p><p>until convergence. Why does this work? Note that at the E-step:</p><p>so the E-step, sensibly, minimizes the KL divergence of q φ (z|x) from the true posterior. Secondly, note that if q φ (z|x) equals p θ (z|x), the ELBO equals the marginal likelihood, but that for any choice of q φ (z|x), the M -step optimizes a bound on the marginal likelihood. The tightness of this bound is defined by D KL (q φ (z|x)||p θ (z|x)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.3 MCMC-EM</head><p>Another Bayesian approach towards optimizing the likelihood p θ (x) with DLVMs is Expectation Maximization (EM) with Markov Chain Monte Carlo (MCMC). In case of MCMC, the posterior is approximated by a mixture of a set of approximately i.i.d. samples from the posterior, acquired by running a Markov chain. Note that posterior gradients in DLVMs are relatively affordable to compute by differentiating the log-joint distribution w.r.t. z:</p><p>One version of MCMC which uses such posterior for relatively fast convergence, is Hamiltonian MCMC <ref type="bibr" target="#b96">(Neal, 2011)</ref>. A disadvantage of this approach is the requirement for running an independent MCMC chain per datapoint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Stochastic Gradient Descent</head><p>We work with directed models where the objective per datapoint is scalar, and due to the differentiability of neural networks that compose them, the objective is differentiable w.r.t. its parameters θ. Due to the remarkable efficiency of reverse-mode automatic differentiation (also known as the backpropagation algorithm <ref type="bibr" target="#b113">(Rumelhart et al., 1988)</ref>), the value and gradient (i.e. the vector of partial derivatives) of differentiable scalar objectives can be computed with equal time complexity. In SGD, we iteratively update parameters θ:</p><p>where α t is a learning rate or preconditioner, and L(θ, ξ) is an unbiased estimate of the objective L(θ), i.e. E ξ∼p(ξ) L(θ, ξ) = L(θ). The random variable ξ could e.g. be a datapoint index, uniformly sampled from {1, ..., N }, but can also include different types of noise such posterior sampling noise in VAEs. In experiments, we have typically used the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An analysis of logistic models: Exponential family connections and online performance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 SIAM International Conference on Data Mining</title>
		<meeting>the 2007 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="204" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning stochastic recurrent networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Osendorfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2014 Workshop on Advances in Variational Inference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Representation Learning: A Review and New Perspectives</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep generative stochastic networks trainable by backprop</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Laufer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="226" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sylvester Normalizing Flows for Variational Inference</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hasenclever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Variational Bayesian inference with stochastic search</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1367" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Weight Uncertainty in Neural Networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cornebise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1613" to="1622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bidirectional Helmholtz machines</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shabanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2511" to="2519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Auto-association by multilayer perceptrons and singular value decomposition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06349</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural photo editing with introspective adversarial networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<title level="m">Importance weighted autoencoders</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Isolating sources of disentanglement in VAEs</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2615" to="2625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Variational lossy autoencoder</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A recurrent latent variable model for sequential data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Re-interpreting importance weighted autoencoders</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cremer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Helmholtz machine</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Higher order statistical decorrelation without information loss</title>
		<author>
			<persName><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Brauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="247" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
	<note>References</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning diverse image colorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Jin</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6837" to="6845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">NICE: Non-linear independent components estimation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Density estimation using Real NVP</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to generate chairs with convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1538" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adversarially learned inference</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards a neural statistician</title>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attend, infer, repeat: Fast scene understanding with generative models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Szepesvari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3225" to="3233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fast second order stochastic backpropagation for variational inference</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Heller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1387" to="1395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Bayesian recurrent neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.02798</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Sequential neural models with stochastic layers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2199" to="2207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Gradient estimation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbooks in Operations Research and Management Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="575" to="616" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A theoretically grounded application of dropout in recurrent neural networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Made: Masked autoencoder for distribution estimation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="881" to="889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Amortized inference in probabilistic reasoning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CogSci</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Monte Carlo methods in financial engineering</title>
		<author>
			<persName><forename type="first">P</forename><surname>Glasserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">53</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Likelihood ratio gradient estimation for stochastic systems</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Glynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="75" to="84" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Automatic chemical design using a data-driven continuous representation of molecules</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gómez-Bombarelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sánchez-Lengeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sheberla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACS central science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Practical variational inference for neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="2348" to="2356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Towards conceptual compression</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Besse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="3549" to="3557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">DRAW: A Recurrent Neural Network For Image Generation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1462" to="1471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep AutoRegressive Networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1242" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Flow-GAN: Combining maximum likelihood and adversarial learning in generative models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05176</idno>
		<title level="m">MuProp: Unbiased backpropagation for stochastic neural networks</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">PixelVAE: A latent variable model for natural images</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Taiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning continuous control policies by stochastic value gradients</title>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2944" to="2952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rowland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<title level="m">Black-box α-divergence minimization</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">beta-vae: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">The &quot;Wake-Sleep&quot; algorithm for unsupervised neural networks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1158" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Stochastic variational inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Paisley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1303" to="1347" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Elbo surgery: yet another way to carve up the variational evidence lower bound</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop in Advances in Approximate Bayesian Inference, NIPS</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Vime: Variational information maximizing exploration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Turck</surname></persName>
		</author>
		<author>
			<persName><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1109" to="1117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Voice conversion from non-parallel corpora using variational autoencoder</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal and Information Processing Association Annual Summit and Conference (APSIPA)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Voice conversion from unaligned corpora using variational autoencoding wasserstein generative adversarial networks</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-T</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tsao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-M</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00849</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00955</idno>
		<title level="m">Controllable text generation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2083" to="2092" />
		</imprint>
	</monogr>
	<note>Neural Autoregressive Flows</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Composing graphical models with neural networks for structured representations and fast inference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wiltschko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Datta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2946" to="2954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep variational bayes filters: Unsupervised learning of state space models from raw data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Soelch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Smagt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Fast inference in sparse coding algorithms with applications to object recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno>CBLL-TR-2008-12-01</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Computational and Biological Learning Lab, Courant Institute, NYU. References</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep. No.</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Improved variational inference with inverse autoregressive flow</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4743" to="4751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Variational dropout and the local reparameterization trick</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2575" to="2583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Variational graph auto-encoders</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Optimization and sensitivity analysis of computer simulation models by the score function method</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Kleijnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Rubinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="413" to="427" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">Probabilistic graphical models: Principles and techniques</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Structured Inference Networks for Nonlinear State Space Models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2101" to="2109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Automatic differentiation variational inference</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="430" to="474" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Deep convolutional inverse graphics network</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2539" to="2547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Grammar variational autoencoder</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1945" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B L</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1558" to="1566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Doubly stochastic variational Bayes for non-conjugate inference</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lázaro-Gredilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Gradientbased learning applied to document recognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Rényi divergence variational inference</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1073" to="1081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Generative moment matching networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1718" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">An Application of the Principle of Maximum Information Preservation to Linear Systems</title>
		<author>
			<persName><forename type="first">R</forename><surname>Linsker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.00830</idno>
	</analytic>
	<monogr>
		<title level="m">The variational fair autoencoder</title>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc. Louizos</publisher>
			<date type="published" when="1989">1989. 2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Bayesian compression for deep learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3288" to="3298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Structured and efficient variational deep learning with matrix gaussian posteriors</title>
		<author>
			<persName><forename type="first">C</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1708" to="1716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Multiplicative normalizing flows for variational Bayesian neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2218" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Auxiliary deep generative models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644.References</idno>
		<title level="m">Adversarial autoencoders</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Generating images from captions with attention</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mansimov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Parisotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02793</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Neural variational inference for text processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1727" to="1736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Variational Inference for Monte Carlo Objectives</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2188" to="2196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Variational information maximisation for intrinsically motivated reinforcement learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2125" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Variational dropout sparsifies deep neural networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ashukha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vetrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2498" to="2507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Reparameterization gradients through acceptance-rejection sampling algorithms</title>
		<author>
			<persName><forename type="first">C</forename><surname>Naesseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Linderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="page" from="489" to="498" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">MCMC Using Hamiltonian Dynamics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Handbook of Markov Chain</title>
		<imprint>
			<biblScope unit="page" from="113" to="162" />
			<date type="published" when="2011">2011</date>
			<pubPlace>Monte Carlo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">A view of the EM algorithm that justifies incremental, sparse, and other variants</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning in Graphical Models</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="355" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Variational Bayesian Inference with stochastic search</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1367" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Masked autoregressive flow for density estimation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pavlakou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Neural episodic control</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2827" to="2836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Variational autoencoder for deep learning of images, labels and captions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2352" to="2360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Black Box Variational Inference</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="814" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Hierarchical variational models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="324" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Enabling dark energy science with deep generative models of galaxy images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lanusse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mandelbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">One-shot generalization in deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016a</date>
			<biblScope unit="page" from="1521" to="1529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Unsupervised learning of 3d structure from images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016b</date>
			<biblScope unit="page" from="4997" to="5005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Sticking the landing: Simple, lower-variance gradient estimators for variational inference</title>
		<author>
			<persName><forename type="first">G</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6925" to="6934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Rosca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.06847</idno>
		<title level="m">Distribution matching in variational inference</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">EM algorithms for PCA and SPCA</title>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="626" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">The generalized reparameterization gradient</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T R</forename><surname>Aueb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="460" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Modeling</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Efficient learning of deep Boltzmann machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="693" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">A structured variational auto-encoder for learning deep hierarchies of sparse features</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.08734</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Markov Chain Monte Carlo and Variational Inference: Bridging the Gap</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1218" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Fixed-Form variational posterior approximation through stochastic linear regression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">A hybrid convolutional variational autoencoder for text generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Semeniuta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.02390</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoderdecoder model for generating dialogues</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3295" to="3301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Deep unsupervised learning using nonequilibrium thermodynamics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">How to train deep variational autoencoders and probabilistic ladder networks</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Ladder variational autoencoders</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016b</date>
			<biblScope unit="page" from="3738" to="3746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Improving variational auto-encoders using convex combination linear inverse autoregressive flow</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Benelearn 2017: Proceedings of the Twenty-Sixth Benelux Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="0162">June 2017. 162</date>
			<biblScope unit="page" from="9" to="10" />
		</imprint>
		<respStmt>
			<orgName>Technische Universiteit Eindhoven</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title level="m" type="main">Improving variational autoencoders using householder flow</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09630</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Deep probabilistic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Saurous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06499</idno>
		<title level="m">The variational Gaussian process</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Conditional image generation with PixelCNN decoders</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Pixel Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Van Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1747" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12">2010. Dec</date>
		</imprint>
	</monogr>
	<note>References</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Graphical models, exponential families, and variational inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="305" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Embed to control: A locally linear latent dynamics model for control from raw images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Watter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boedecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2746" to="2754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>White</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04468</idno>
		<title level="m">Sampling Generative Networks: Notes on a Few Effective Techniques</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title level="m" type="main">Automated variational inference in probabilistic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wingate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.1299</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Variational autoencoder for semi-supervised text classification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="page" from="3358" to="3364" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Attribute2image: Conditional image generation from visual attributes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="776" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Improved variational autoencoders for text modeling using dilated convolutions</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3881" to="3890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="664" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
