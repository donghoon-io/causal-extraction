<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bayesian Estimation of Causal Direction in Acyclic Structural Equation Models with Individual-specific Confounder Variables and Non-Gaussian Distributions</title>
				<funder ref="#_zYauf9m">
					<orgName type="full">KAKENHI</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Shohei</forename><surname>Shimizu</surname></persName>
							<email>sshimizu@ar.sanken.osaka-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Sociology</orgName>
								<orgName type="institution">The Institute of Scientific and Industrial Research Osaka University</orgName>
								<address>
									<addrLine>Mihogaoka 8-1</addrLine>
									<postCode>567-0047 3210</postCode>
									<settlement>Ibaraki</settlement>
									<region>Osaka CB</region>
									<country>Japan Kenneth Bollen</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Hamilton Hall University of North</orgName>
								<address>
									<addrLine>Carolina Chapel Hill</addrLine>
									<postCode>27599-3210</postCode>
									<region>NC</region>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bayesian Estimation of Causal Direction in Acyclic Structural Equation Models with Individual-specific Confounder Variables and Non-Gaussian Distributions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Submitted 10/13; Revised 4/14;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>structural equation models</term>
					<term>Bayesian networks</term>
					<term>estimation of causal direction</term>
					<term>latent confounding variables</term>
					<term>non-Gaussianity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Several existing methods have been shown to consistently estimate causal direction assuming linear or some form of nonlinear relationship and no latent confounders. However, the estimation results could be distorted if either assumption is violated. We develop an approach to determining the possible causal direction between two observed variables when latent confounding variables are present. We first propose a new linear non-Gaussian acyclic structural equation model with individual-specific effects that are sometimes the source of confounding. Thus, modeling individual-specific effects as latent variables allows latent confounding to be considered. We then propose an empirical Bayesian approach for estimating possible causal direction using the new model. We demonstrate the effectiveness of our method using artificial and real-world data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Aids to uncover the causal structure of variables from observational data are welcomed additions to the field of machine learning <ref type="bibr" target="#b47">(Pearl, 2000;</ref><ref type="bibr" target="#b57">Spirtes et al., 1993)</ref>. One conventional approach makes use of Bayesian networks <ref type="bibr" target="#b47">(Pearl, 2000;</ref><ref type="bibr" target="#b57">Spirtes et al., 1993)</ref>. However, these suffer from the identifiability problem. That is, many different causal structures give the same conditional independence between variables, and in many cases one cannot uniquely estimate the underlying causal structure without prior knowledge <ref type="bibr" target="#b47">(Pearl, 2000;</ref><ref type="bibr" target="#b57">Spirtes et al., 1993)</ref>.</p><p>To address these issues, <ref type="bibr" target="#b52">Shimizu et al. (2006)</ref> proposed LiNGAM (Linear Non-Gaussian Acyclic Model), a variant of Bayesian networks <ref type="bibr" target="#b47">(Pearl, 2000;</ref><ref type="bibr" target="#b57">Spirtes et al., 1993)</ref> and structural equation models <ref type="bibr" target="#b20">(Bollen, 1989)</ref>. Unlike conventional Bayesian networks, LiNGAM is a fully identifiable model <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref>, and has recently attracted much attention in machine learning <ref type="bibr" target="#b58">(Spirtes et al., 2010;</ref><ref type="bibr" target="#b45">Moneta et al., 2011)</ref>. If causal relations exist among variables, LiNGAM uses their non-Gaussian distributions to identify the causal structure among the variables. LiNGAM is closely related to independent component analysis (ICA) <ref type="bibr">(Hyvärinen et al., 2001b)</ref>; the identifiability proof and estimation algorithm are partly based on the ICA theory. The idea of LiNGAM has been extended in many directions, including to nonlinear cases <ref type="bibr">(Hoyer et al., 2009;</ref><ref type="bibr" target="#b42">Lacerda et al., 2008;</ref><ref type="bibr" target="#b38">Hyvärinen et al., 2010;</ref><ref type="bibr" target="#b62">Zhang and Hyvärinen, 2009;</ref><ref type="bibr">Peters et al., 2011a)</ref>.</p><p>Many causal discovery methods including LiNGAM make the strong assumption of no latent confounders <ref type="bibr" target="#b56">(Spirtes and Glymour, 1991;</ref><ref type="bibr" target="#b25">Dodge and Rousson, 2001;</ref><ref type="bibr" target="#b52">Shimizu et al., 2006;</ref><ref type="bibr" target="#b35">Hyvärinen and Smith, 2013;</ref><ref type="bibr">Hoyer et al., 2009;</ref><ref type="bibr" target="#b62">Zhang and Hyvärinen, 2009)</ref>. These methods have been used in various application fields <ref type="bibr" target="#b50">(Ramsey et al., 2014;</ref><ref type="bibr" target="#b51">Rosenström et al., 2012;</ref><ref type="bibr" target="#b54">Smith et al., 2011;</ref><ref type="bibr" target="#b59">Statnikov et al., 2012;</ref><ref type="bibr" target="#b46">Moneta et al., 2013)</ref>. However, in many areas of empirical science, it is often difficult to accept the estimation results because latent confounders are ignored. In theory, we could take a non-Gaussian approach <ref type="bibr">(Hoyer et al., 2008b)</ref> that uses an extension of ICA with more latent variables than observed variables (overcomplete ICA) to formally consider latent confounders in the framework of LiNGAM. Unfortunately, current versions of the overcomplete ICA algorithms are not very computationally reliable since they often suffer from local optima <ref type="bibr" target="#b27">(Entner and Hoyer, 2011)</ref>. Thus, in this paper, we propose an alternative Bayesian approach to develop a method that is computationally simple in the sense that no iterative search in the parameter space is required and it is capable of finding the possible causal direction of two observed variables in the presence of latent confounders. We first propose a variant of LiNGAM with individual-specific effects. Individual differences are sometimes the source of confounding (von <ref type="bibr" target="#b61">Eye and Bergman, 2003)</ref>. Thus, modeling certain individual-specific effects as latent variables allows a type of latent confounding to be considered. A latent confounding variable is an unobserved variable that exerts a causal influence on more than one observed variables <ref type="bibr">(Hoyer et al., 2008b)</ref>. The new model is still linear but allows any number of latent confounders. We then present a Bayesian approach for estimating the model by integrating out some of the large number of parameters, which is of the same order as the sample size. Such a Bayesian approach is often used in the field of mixed models <ref type="bibr" target="#b24">(Demidenko, 2004)</ref> and multilevel models <ref type="bibr" target="#b41">(Kreft and De Leeuw, 1998)</ref>, although estimation of causal direction is not a topic studied within it.</p><p>Granger causality <ref type="bibr" target="#b29">(Granger, 1969)</ref> is another popular method to aid detection of causal direction. His method depends on the temporal ordering of variables whereas our method does not. Therefore, our method can be applied to cases where temporal information is not available, i.e., cross-sectional data, as well as those where it is available, i.e., time-series data.</p><p>The remainder of this paper is organized as follows. We first review LiNGAM <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref> and its extension to latent confounder cases <ref type="bibr">(Hoyer et al., 2008b)</ref> in Section 2. In Section 3, we propose a new mixed-LiNGAM model, which is a variant of LiNGAM with individual-specific effects. We also propose an empirical Bayesian approach for learning the model. We empirically evaluate the performance of our method using artificial and real-world sociology data in Sections 4 and 5, respectively, and present our conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>In this section, we first review the linear non-Gaussian structural equation model known as LiNGAM <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref>. We then discuss an extension of LiNGAM to cases where latent confounding variables exist <ref type="bibr">(Hoyer et al., 2008b)</ref>.</p><p>In LiNGAM <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref>, causal relations between observed variables x l (l = 1, • • • , d) are modeled as</p><formula xml:id="formula_0">x l = µ l + k(m)&lt;k(l) b lm x m + e l ,<label>(1)</label></formula><p>where k(l) is a causal ordering of the variables x l . The causal orders k(l)</p><formula xml:id="formula_1">(l = 1, • • • , d)</formula><p>are unknown and to be estimated. In this ordering, the variables x l form a directed acyclic graph (DAG) so that no later variable determines, i.e., has a directed path to, any earlier variable in the DAG. The variables e l are latent continuous variables called error variables, µ l are intercepts or regression constants, and b lm are connection strengths or regression coefficients.</p><p>In matrix form, the LiNGAM model in Equation ( <ref type="formula" target="#formula_0">1</ref>) is written as</p><formula xml:id="formula_2">x = µ + Bx + e,<label>(2)</label></formula><p>where the vector µ collects constants µ l , the connection strength matrix B collects regression coefficients (or connection strengths) b lm , and the vectors x and e collect observed variables x l and error variables e l , respectively. The zero/non-zero pattern of b lm corresponds to the absence/existence pattern of directed edges (direct effects). It can be shown that it is always possible to perform simultaneous, equal row and column permutations on the connection strength matrix B to cause it to become strictly lower triangular, based on the acyclicity assumption <ref type="bibr" target="#b20">(Bollen, 1989)</ref>. Here, strict lower triangularity is defined as a lower triangular structure with the diagonal consisting entirely of zeros. Errors e l follow non-Gaussian distributions with zero mean and non-zero variance, and are jointly independent. This model without assuming non-Gaussianity distribution is called a fully recursive model in conventional structural equation models <ref type="bibr" target="#b20">(Bollen, 1989)</ref>. The non-Gaussianity assumption on e l enables the identification of a causal ordering k(l) and the coefficients b lm based only on x <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref>, unlike conventional Bayesian networks based on the Gaussianity assumption on e l <ref type="bibr" target="#b57">(Spirtes et al., 1993)</ref>. To illustrate the LiNGAM model, the following example is considered, whose corresponding directed acyclic graph is provided in Figure <ref type="figure" target="#fig_0">1</ref>:</p><formula xml:id="formula_3">  x 1 x 2 x 3   =   0 0 3 -5 0 0 0 0 0     x 1 x 2 x 3   +   e 1 e 2 e 3   .</formula><p>In this example, x 3 is equal to error e 3 and is exogenous since it is not affected by either of the other two variables x 1 and x 2 . Thus, x 3 is in the first position of such a causal ordering such that B is strictly lower triangular, x 1 is in the second, and x 2 is the third, i.e., k(3) = 1, k(1) = 2, and k(2) = 3. If we permute the variables x 1 to x 3 according to the causal ordering, we have It can be seen that the resulting connection strength (or regression coefficient) matrix is strictly lower triangular. Several computationally efficient algorithms for estimating the model have been proposed <ref type="bibr" target="#b52">(Shimizu et al., 2006</ref><ref type="bibr" target="#b53">(Shimizu et al., , 2011;;</ref><ref type="bibr" target="#b35">Hyvärinen and Smith, 2013)</ref>. As with ICA, LiNGAM is identifiable under the assumptions of non-Gaussianity and independence among error variables <ref type="bibr" target="#b52">(Shimizu et al., 2006;</ref><ref type="bibr" target="#b23">Comon, 1994;</ref><ref type="bibr" target="#b28">Eriksson and Koivunen, 2003)</ref>.<ref type="foot" target="#foot_1">foot_1</ref> However, for the estimation methods to be consistent, additional assumptions, e.g., the existence of their moments or some other statistic, must be made to ensure that the statistics computed in the estimation algorithms exist. The idea of LiNGAM can be generalized to nonlinear cases <ref type="bibr">(Hoyer et al., 2009;</ref><ref type="bibr" target="#b60">Tillman et al., 2010;</ref><ref type="bibr" target="#b62">Zhang and Hyvärinen, 2009;</ref><ref type="bibr">Peters et al., 2011b)</ref>.</p><formula xml:id="formula_4">  x 3 x 1 x 2   =   0 0 0 3 0 0 0 -5 0     x 3 x 1 x 2   +   e 3 e 1 e 2   .</formula><p>The assumption of independence among e l means that there is no latent confounding variable <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref>. A latent confounding variable is an unobserved variable that contributes to the values of more than one observed variable <ref type="bibr">(Hoyer et al., 2008b)</ref>. However, in many applications, there often exist latent confounding variables. If such latent confounders are completely ignored, the estimation results can be seriously biased <ref type="bibr" target="#b47">(Pearl, 2000;</ref><ref type="bibr" target="#b57">Spirtes et al., 1993;</ref><ref type="bibr" target="#b20">Bollen, 1989)</ref>. Therefore, in <ref type="bibr">Hoyer et al. (2008b)</ref>, LiNGAM with latent confounders, called latent variable LiNGAM, was proposed, and the model can be formulated as follows:</p><formula xml:id="formula_5">x l = µ l + k(m)&lt;k(l) b lm x m + Q q=1 λ lq f q + e l ,</formula><p>where f q are non-Gaussian individual-specific effects f q with zero mean and unit variance and λ lq denote the regression coefficients (connection strengths) from f q to x l . This model is written in matrix form as follows:</p><formula xml:id="formula_6">x = µ + Bx + Λf + e,<label>(3)</label></formula><p>where the difference from LiNGAM in Equation ( <ref type="formula" target="#formula_2">2</ref>) is the existence of a latent confounding variable vector f . The vector f collects f q . The matrix Λ collects λ lq and is assumed to be of full column rank. Another way to represent latent confounder cases would be to use dependent error variables. Denoting Λf + e in Equation (3) by ẽ, we have</p><formula xml:id="formula_7">x = µ + Bx + Λf + e = µ + Bx + ẽ,</formula><p>where ẽi are dependent due to the latent confounders f q . Observed variables that are equal to dependent errors ẽi are connected by bi-directed arcs in their graphs. An example graph is given in Figure <ref type="figure">4</ref>. This representation can be more general since it is easier to extend it to represent nonlinearly dependent errors. In this paper, however, we use the aforementioned representation using independent errors and latent confounders since linear relations of the observed variables, latent confounders, and errors are necessary for our approach.</p><p>Without loss of generality, the latent confounders f q are assumed to be jointly independent since any dependent latent confounders can be remodeled by linear combinations of independent latent variables if the underlying model is linear acyclic and the error variables are independent <ref type="bibr">(Hoyer et al., 2008b)</ref>. To illustrate this, the following example model is considered:</p><formula xml:id="formula_8">f1 = e f1 (4) f2 = ω 21 f1 + e f2<label>(5)</label></formula><p>x 1 = λ 11 f1 + e 1</p><p>x 2 = λ 21 f1 + e 2</p><p>x 3 = λ 32 f2 + e 3</p><p>x 4 = b 43 x 3 + λ 42 f2 + e 4 ,</p><p>where errors e f1 (= f1 ), e f2 , and e 1 -e 4 are non-Gaussian and independent. The associated graph is shown in Figure <ref type="figure" target="#fig_1">2</ref>. The relations of f1 , f2 , and x 1 -x 4 are represented by a directed acyclic graph and latent confounders f1 and f2 are dependent. In matrix form, this example model can be written as</p><formula xml:id="formula_9">    x 1 x 2 x 3 x 4     =     0 0 0 0 0 0 0 0 0 0 0 0 b 43 0 0 0         x 1 x 2 x 3 x 4     +     λ 11 0 λ 21 0 0 λ 32 0 λ 42     f1 f2 +     e 1 e 2 e 3 e 4     .</formula><p>The relations of f1 and f2 to e f1 and e f2 in Equations ( <ref type="formula">4</ref>)-( <ref type="formula" target="#formula_8">5</ref>): we obtain</p><formula xml:id="formula_10">f1 f2 = 1 0 ω 21 1 e f1 e f2 , e1<label>x1</label></formula><formula xml:id="formula_11">    x 1 x 2 x 3 x 4     x =     0 0 0 0 0 0 0 0 0 0 0 0 b 43 0 0 0     B     x 1 x 2 x 3 x 4     x +     λ 11 0 λ 21 0 λ 32 ω 21 λ 32 λ 42 ω 21 λ 42     Λ e f1 e f2 f +     e 1 e 2 e 3 e 4     e .</formula><p>This is a latent variable LiNGAM in Equation (3) taking f 1 = e f1 and f 2 = e f2 since e f1 and e f2 are non-Gaussian and independent.</p><p>Moreover, the faithfulness of x l and f q to the generating graph is assumed. The faithfulness assumption <ref type="bibr" target="#b57">(Spirtes et al., 1993)</ref> here means that when multiple causal paths exist from one variable to another, their combined effect does not equal exactly zero <ref type="bibr">(Hoyer et al., 2008b)</ref>. The faithfulness assumption can be considered to be not very restrictive from the Bayesian viewpoint <ref type="bibr" target="#b57">(Spirtes et al., 1993)</ref> since the probability of having exactly the parameter values that do not satisfy faithfulness is zero <ref type="bibr" target="#b44">(Meek, 1995)</ref>.</p><p>In the framework of latent variable LiNGAM, it has been shown <ref type="bibr">(Hoyer et al., 2008b)</ref> that the following three models are distinguishable based on observed data, 2 i.e., the three different causal structures induce different data distributions:</p><formula xml:id="formula_12">Model 3 : x 1 = Q q=1 λ 1q f q + e 1 x 2 = Q q=1 λ 2q f q + e 2 , Model 4 : x 1 = Q q=1 λ 1q f q + e 1 x 2 = b 21 x 1 + Q q=1 λ 2q f q + e 2 ,</formula><p>Model 5 :</p><formula xml:id="formula_13">x 1 = b 12 x 2 + Q q=1 λ 1q f q + e 1 x 2 = Q q=1 λ 2q f q + e 2 ,</formula><p>, where λ 1q λ 2q = 0 due to the definition of latent confounders, that is, that they contribute to determining the values of more than two variables.</p><p>An estimation method based on overcomplete ICA <ref type="bibr" target="#b43">(Lewicki and Sejnowski, 2000)</ref> explicitly modeling all the latent confounders f q was proposed <ref type="bibr">(Hoyer et al., 2008b)</ref>. However, in current practice, overcomplete ICA estimation algorithms often get stuck in local optima and are not sufficiently reliable <ref type="bibr" target="#b27">(Entner and Hoyer, 2011)</ref>. A Bayesian approach for estimating the latent variable LiNGAM in Equation ( <ref type="formula" target="#formula_6">3</ref>) has been proposed in <ref type="bibr" target="#b30">Henao and Winther (2011)</ref>. These previous approaches that explicitly model latent confounders <ref type="bibr">(Hoyer et al., 2008b;</ref><ref type="bibr" target="#b30">Henao and Winther, 2011)</ref> need to select the number of latent confounders, and which can be quite large. This could lead to further computational difficulty and statistically unreliable estimates.</p><p>In <ref type="bibr" target="#b21">Chen and Chan (2013)</ref>, a simple approach based on fourth-order cumulants for estimating latent variable LiNGAM was proposed. Their approach does not need to explicitly model the latent confounders, however it requires the latent confounders f q to be Gaussian. The development of nonlinear methods that incorporate latent confounders is ongoing <ref type="bibr" target="#b63">(Zhang et al., 2010)</ref>.</p><p>None of these latent confounder methods incorporate the individual-specific effects that we model in the next section to consider latent confounders f q in the latent variable LiNGAM of Equation (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Linear Non-Gaussian Acyclic Structural Equation Model with Individual-specific Effects</head><p>In this section, we propose a new Bayesian method for learning the possible causal direction of two observed variables in the presence of latent confounding variables, assuming that the causal relations are acyclic, i.e., there is not a feedback relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model</head><p>The LiNGAM <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref> for observation i can be described as follows:</p><formula xml:id="formula_14">x (i) l = µ l + k(m)&lt;k(l) b lm x (i) m + e (i)</formula><p>l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The random variables e (i)</head><p>l are non-Gaussian and independent. The distributions of e (i)</p><formula xml:id="formula_15">l (i = 1, • • • , n) are</formula><p>commonly assumed to be identical<ref type="foot" target="#foot_3">foot_3</ref> for every l. A linear non-Gaussian acyclic structural equation model with individual-specific effects for observation i is formulated as follows:</p><formula xml:id="formula_16">x (i) l = µ l + μ(i) l + k(m)&lt;k(l) b lm x (i) m + e (i) l ,</formula><p>where the difference from LiNGAM is the existence of individual-specific effects μ(i) l . The parameters μ(i) l are independent of e</p><formula xml:id="formula_17">(i)</formula><p>l and are correlated with</p><formula xml:id="formula_18">x (i)</formula><p>l through the structural equations in our Bayesian approach, introduced below. This means that the observations are generated from the identifiable LiNGAM, possibly with different parameter values of the means µ l + μ(i) l . We call this a mixed-LiNGAM, named after mixed models <ref type="bibr" target="#b24">(Demidenko, 2004)</ref>, as it has effects µ l and b lm that are common to all the observations and individualspecific effects μ(i) l . We note that causal orderings of variables k(l) (l = 1, • • • , d) are identical for all the observations in the sample.</p><p>To use a Bayesian approach for estimating the mixed-LiNGAM, we need to model the distributions of error variables e l and prior distributions of the parameters including individual-specific effects μ(i) l , unlike previous LiNGAM methods <ref type="bibr" target="#b52">(Shimizu et al., 2006;</ref><ref type="bibr">Hoyer et al., 2008b)</ref>. These individual-specific effects, whose number is of the same order as the sample size, are integrated out in the Bayesian method developed in Section 3.2, assuming an informative prior for them similar to the estimation of conventional mixed models <ref type="bibr" target="#b24">(Demidenko, 2004)</ref>. More details on the distributions of error variables and prior distributions of parameters are given in Section 3.2. These distributional assumptions were implied to be robust to some extent to their violations, at least in the artificial data experiments of Section 4.</p><p>We now relate the mixed-LiNGAM model above with the latent variable LiNGAM <ref type="bibr">(Hoyer et al., 2008b)</ref>. The latent variable LiNGAM in Equation (3) for observation i is written as follows:</p><formula xml:id="formula_19">x (i) l = µ l + k(m)&lt;k(l) b lm x (i) m + Q q=1 λ lq f (i) q μ(i) l +e (i) l .</formula><p>This is a mixed-LiNGAM taking μ(i)</p><formula xml:id="formula_20">l = Q q=1 λ lq f (i)</formula><p>q . In contrast to the previous approaches for latent variable LiNGAM <ref type="bibr">(Hoyer et al., 2008b;</ref><ref type="bibr" target="#b30">Henao and Winther, 2011)</ref>, we do not explicitly model the latent confounders f q and rather simply include their sums μ(i)</p><formula xml:id="formula_21">l = Q q=1 λ lq f (i) q</formula><p>in our model as its parameters since our main interest lies in estimation of the causal relation of observed variables x l and not in the estimation of their relations with latent confounders f q . Our method does not estimate λ lq or the number of latent confounders Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Estimation of Possible Causal Direction</head><p>We apply a Bayesian approach to estimate the possible causal direction of two observed variables using the mixed-LiNGAM proposed above. We compare the following two mixed-LiNGAM models with opposite possible directions of causation. Model 1 is</p><formula xml:id="formula_22">x (i) 1 = µ 1 + μ(i) 1 + e (i) 1 x (i) 2 = µ 2 + μ(i) 2 + b 21 x (i) 1 + e (i) 2 ,</formula><p>where b 21 is non-zero. In Model 1, x 2 does not cause x 1 . The second model, Model 2, is</p><formula xml:id="formula_23">x (i) 1 = µ 1 + μ(i) 1 + b 12 x (i) 2 + e (i) 1 x (i) 2 = µ 2 + μ(i) 2 + e (i) 2 ,</formula><p>where b 12 is non-zero. In Model 2, x 1 does not cause x 2 . The two models have the same number of parameters, but opposite possible directions of causation. Once the possible causal direction is estimated, one can see if the common causal coefficient (connection strength) b 21 or b 12 is likely to be zero by examining its posterior distribution. 4 We focus here on estimating the possible direction of causation as in many previous works <ref type="bibr" target="#b25">(Dodge and Rousson, 2001;</ref><ref type="bibr">Hoyer et al., 2009;</ref><ref type="bibr" target="#b62">Zhang and Hyvärinen, 2009;</ref><ref type="bibr" target="#b21">Chen and Chan, 2013;</ref><ref type="bibr" target="#b35">Hyvärinen and Smith, 2013)</ref>, and do not go to the computation of the posterior distribution 5 since estimation of the possible causal direction of two observed variables in the presence of latent confounders has been a very challenging problem in causal inference and is the main topic of this paper.</p><p>We apply standard Bayesian model selection techniques to help assess the causal direction of x 1 and x 2 . We use the log-marginal likelihood for comparing the two models. The model with the larger log-marginal likelihood is regarded as the closest to the true model <ref type="bibr" target="#b39">(Kass and Raftery, 1995)</ref>.</p><p>Let D be the observed data set</p><formula xml:id="formula_24">[x (1) T , • • • , x (n) T ] T , where x (i) = [x (i) 1 , x<label>(i)</label></formula><p>2 ] T . Denote Models 1 and 2 by M 1 and M 2 . The log-marginal likelihoods of M 1 and M 2 are</p><formula xml:id="formula_25">log{p(M r |D)} = log{p(D|M r )p(M r )/p(D)} = log{p(D|M r )} + log{p(M r )} -log p(D) = log{ p(D|θ r , M r )p(θ r |M r , η r )dθ r } + log p(M r ) -log p(D) (r = 1, 2),</formula><p>where η 1 , η 2 are the hyper-parameter vectors regarding the distributions of the parameters θ 1 and θ 2 , respectively. Since the last term log p(D) is constant with respect to M r , we can drop it. To select suitable values for these hyper-parameters, we take an ordinary empirical Bayesian approach. First, we compute the log-marginal likelihood for every combination 4. <ref type="bibr" target="#b22">Chickering and Pearl (1996)</ref> considered a discrete variable model with known possible causal direction and proposed a Bayesian approach for computing the posterior distributions of causal effects in the presence of latent confounders. 5. Point estimates of the parameters including the common causal connection strengths b12 and b21 can be obtained by taking their posterior means based on their posterior distributions, for example.</p><p>of the two models M r and a number of candidate hyper-parameter values of η r . Next, we take the model and hyper-parameter values that give the largest log-marginal likelihood, and finally estimate that the model with the largest log-marginal likelihood is better than the other model. In basic LiNGAM <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref>, we have <ref type="bibr" target="#b38">(Hyvärinen et al., 2010;</ref><ref type="bibr" target="#b31">Hoyer and Hyttinen, 2009)</ref> </p><formula xml:id="formula_26">p(x) = l p e l   x l -µ l - k(m)&lt;k(l) b lm x m   .</formula><p>Thus, in the same manner, the likelihoods under mixed-LiNGAM p(D|θ r , M r ) (r = 1, 2) are given by</p><formula xml:id="formula_27">p(D|θ r , M r ) = Π n i=1 p(x (i) |θ r , M r ) =              Π n i=1 p e (i) 1 (x (i) 1 -µ 1 - μ(i) 1 |θ 1 , M 1 ) × p e (i) 2 (x (i) 2 -µ 2 - μ(i) 2 -b 21 x (i) 1 |θ 1 , M 1 ) for M 1 Π n i=1 p e (i) 1 (x (i) 1 -µ 1 - μ(i) 1 -b 12 x (i) 2 |θ 2 , M 2 ) × p e (i) 2 (x (i) 2 -µ 2 - μ(i) 2 |θ 2 , M 2 ) for M 2 .</formula><p>We model the parameters and their prior distributions as follows. <ref type="foot" target="#foot_4">6</ref> The prior probabilities of M 1 and M 2 are uniform:</p><formula xml:id="formula_28">p(M 1 ) = p(M 2 ).</formula><p>The distributions of the error variables e </p><formula xml:id="formula_29">(i)</formula><p>2 ) = h 2 2 as follows:</p><formula xml:id="formula_30">p e (i) 1 = Laplace(0, |h 1 |/ √ 2) p e (i) 2 = Laplace(0, |h 2 |/ √ 2).</formula><p>Here, we simply use a symmetric super-Gaussian distribution, i.e., the Laplace distribution, to model p e (i)</p><formula xml:id="formula_31">1</formula><p>and p e (i)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>, as suggested in <ref type="bibr" target="#b35">Hyvärinen and Smith (2013)</ref>. Such super-Gaussian distributions have been reported to often work well in non-Gaussian estimation methods including independent component analysis and LiNGAM <ref type="bibr">(Hyvärinen et al., 2001b;</ref><ref type="bibr" target="#b35">Hyvärinen and Smith, 2013)</ref>. In some cases, a wider class of non-Gaussian distributions might provide a better model for p e (i)</p><formula xml:id="formula_32">1</formula><p>and p e (i) 2 , e.g., the generalized Gaussian family <ref type="bibr">(Hyvärinen et al., 2001b)</ref>, a finite mixture of Gaussians, or an exponential family distribution combining the Gaussian and Laplace distributions <ref type="bibr" target="#b31">(Hoyer and Hyttinen, 2009)</ref>.</p><p>The parameter vectors θ 1 and θ 2 are written as follows:</p><formula xml:id="formula_33">θ 1 = [µ l , b 21 , h l , μ(i) l ] T (l = 1, 2; i = 1, • • • , n) θ 2 = [µ l , b 12 , h l , μ(i) l ] T (l = 1, 2; i = 1, • • • , n).</formula><p>The prior distributions of common effects are Gaussian as follows:</p><formula xml:id="formula_34">µ 1 ∼ N (0, τ cmmn µ 1 ) µ 2 ∼ N (0, τ cmmn µ 2 ) b 12 ∼ N (0, τ cmmn b 12 ) b 21 ∼ N (0, τ cmmn b 21 ) h 1 ∼ N (0, τ cmmn h 1 ) h 2 ∼ N (0, τ cmmn h 2 ),</formula><p>where If the data is generated from a latent variable LiNGAM, a special case of mixed-LiNGAM, as shown in Section 3.1, the individual-specific effects are the sums of many non-Gaussian independent latent confounders f q and are dependent. The central limit theorem states that the sum of independent variables becomes increasingly close to the Gaussian <ref type="bibr" target="#b19">(Billingsley, 1986)</ref>. Therefore, in many cases, it could be practical to approximate the non-Gaussian distribution of a variable that is the sum of many non-Gaussian and independent variables by a bell-shaped curve distribution <ref type="bibr" target="#b55">(Sogawa et al., 2011;</ref><ref type="bibr" target="#b21">Chen and Chan, 2013)</ref>. This motivates us to model the prior distribution of individual-specific effects by the multivariate t-distribution as follows:</p><formula xml:id="formula_35">τ cmmn µ 1 , τ cmmn</formula><formula xml:id="formula_36">μ(i) 1 μ(i) 2 = diag τ indvdl 1 , τ indvdl 2 T C -1/2 u,<label>(6)</label></formula><p>where τ indvdl 1 and τ indvdl 2 are constants, u ∼ t ν (0, Σ) and Σ = [σ ab ] is a symmetric scale matrix whose diagonal elements are 1s. A random variable vector u that follows the multivariate t-distribution t ν (0, Σ) can be created by y</p><formula xml:id="formula_37">√ v/ν</formula><p>, where y follows the Gaussian distribution N (0, Σ), v follows the chi-squared distribution with ν degrees of freedom, and y and v are statistically independent <ref type="bibr" target="#b40">(Kotz and Nadarajah, 2004)</ref>. Note that u i have energy correlations <ref type="bibr">(Hyvärinen et al., 2001a)</ref>, i.e., correlations of squares cov(u 2 i , u 2 j ) &gt; 0 due to the common variable v. C is a diagonal matrix whose diagonal elements give the variance of elements of u, i.e., C = ν ν-2 diag(Σ) for ν &gt; 2. The degree of freedom ν is here taken to be six. The kurtosis of the univariate Student's t-distribution with six degrees of freedom is three, the same as that of the Laplace distribution.</p><p>The hyper-parameter vectors η 1 and η 2 are</p><formula xml:id="formula_38">η l = [τ cmmn µ 1 , τ cmmn µ 2 , τ cmmn b 12 , τ cmmn b 21 , τ cmmn h 1 , τ cmmn h 2 , τ indvdl 1 , τ indvdl 2 , σ 21 ] T (l = 1, 2).</formula><p>We want to take the constants τ cmmn = 10 2 × var (x 2 ) so that they reflect the scales of the corresponding variables.</p><p>Moreover, we take an empirical Bayesian approach for the individual-specific effects. We test τ indvdl l = 0, 0.2 2 × var(x l ), ..., 0.8 2 × var(x l ), 1.0 2 × var(x l ) (l = 1, 2). That is, we uniformly vary the hyper-parameter value from that with no individual-specific effects, i.e., 0, to a larger value, i.e., 1.0 2 × var(x l ), which implies very large individual differences. Further, we test σ 12 = 0, ±0.3, ±0.5, ±0.7, ±0.9, i.e., the value with zero correlation and larger values with stronger correlations. This means that we test uncorrelated individual-specific effects as well as correlated ones. We take the ordinary Monte Carlo sampling approach to compute the log-marginal likelihoods with 1000 samples for the parameter vectors θ r (r = 1, 2).</p><p>The assumptions for our model are summarized in Table <ref type="table">1</ref>. Generally speaking, if the actual probability density function of individual-specific effects is unimodal and most often provides zero or very small absolute values and with few large values, i.e., many of the individual-specific effects are close to zero and many individuals have similar intercepts, the estimation is likely to work. If the individuals have very different intercepts, the estimation will not work very well.</p><p>An alternative way of modeling the prior distribution of individual-specific effects would be to use the multivariate Gaussian distribution as follows:</p><formula xml:id="formula_39">μ(i) 1 μ(i) 2 = diag τ indvdl 1 , τ indvdl 2 T z,</formula><p>where τ indvdl 1 and τ indvdl 2 are constants, z ∼ N (0, Σ) and Σ = [σ ab ] is a symmetric scale matrix whose diagonal elements are 1s. This Gaussian prior would be effective if the Gaussian approximation based on the central limit theorem works well, although a non-Gaussian prior would be more consistent with the non-Gaussian latent variable LiNGAM in Equation (3). Gaussian individual-specific effects or latent confounders would not lead to losing the identifiability <ref type="bibr" target="#b21">(Chen and Chan, 2013)</ref> since each observation still is generated by the identifiable non-Gaussian LiNGAM. However, if errors are Gaussian, there is no guarantee that our method can find correct possible causal direction. We could detect their Gaussianity by comparing our mixed-LiNGAM models with Gaussian error models based on their log-marginal likelihoods. If the errors are actually Gaussian or close to be Gaussian, Gaussian error models would provide larger log-marginal likelihoods. This would detect situations where our approach cannot find causal direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments on Artificial Data</head><p>We compared our method with seven methods for estimating the possible causal direction between two variables: i) LvLiNGAM 7 <ref type="bibr">(Hoyer et al., 2008b)</ref>; ii) SLIM 8 <ref type="bibr" target="#b30">(Henao and Winther, 2011)</ref> iii) LiNGAM-GC-UK <ref type="bibr" target="#b21">(Chen and Chan, 2013)</ref>; iv) ICA-LiNGAM 9 <ref type="bibr" target="#b52">(Shimizu et al., 2006)</ref>  We generated data using the following latent variable LiNGAM with Q latent confounding variables, which is a mixed-LiNGAM:</p><formula xml:id="formula_40">x (i) 1 = µ 1 + Q q=1 λ 1q f (i) q + e (i) 1 x (i) 2 = µ 2 + b 21 x (i) 1 + Q q=1 λ 2q f (i) q + e (i) 2 ,</formula><p>where µ 1 and µ 2 were randomly generated from N (0, 1), and b 21 , λ 1q , λ 2q were randomly generated from the interval (-1.5, -0.5) ∪ (0.5, 1.5). We tested various numbers of latent confounders Q = 0, 1, 6, 12. The zero values indicate that there are no latent confounders. An example graph used to generate artificial data is given in Figure <ref type="figure" target="#fig_5">3</ref>. The distributions of the error variables e 1 , e 2 , and latent confounders f q were identical for all observations. The distributions of the error variables e 1 , e 2 , and latent confounders f q were randomly selected from the 18 non-Gaussian distributions used in <ref type="bibr" target="#b18">Bach and Jordan (2002)</ref> to see if the Laplace distribution assumption on error variables and t-or Gaussian distribution assumption on individual-specific effects in our method were robust to different non-Gaussian distributions. These include symmetric/non-symmetric distributions, super-Gaussian/sub-Gaussian distributions, and strongly/weakly non-Gaussian distributions. The variances of e 1 and e 2 were randomly selected from the interval (0.5 2 , 1.5 2 ). The variances of f q were 1s.</p><p>We permuted the variables according to a random ordering and inputted them to the eight estimation methods. We conducted 100 trials, with sample sizes of 50, 100, and 200. For the data with the number of latent confounders Q = 0, all the methods should find the correct causal direction for large enough sample sizes, as there were no latent confounders, which here means no individual-specific effects. The last four comparative methods should find the data with the number of latent confounders Q = 1, 6, 12 very difficult to analyze, because, unlike the other approaches, they assume no latent confounders.</p><p>To evaluate the performance of the algorithms, we counted the number of successful discoveries of possible causal direction and estimated their standard errors.</p><p>Looking at Table <ref type="table">3</ref> as a whole there are several general observations that we can make. First though none of the procedures is infallible, several of them do quite well in that they choose the correct causal direction about 90% of the time. Second, overall our approach is the most successful across the conditions of the simulation. Specifically, in all but the cases of no confounding variables, one or both of our approaches have the highest percentages of success. In the situation of no confounding variables, ICA-LiNGAM, DirectLiNGAM, and Pairwise LINGAM have higher success percentages than our procedures. These generalizations need qualifications in that there are sampling errors that affect the estimates. Formal tests of significance across all conditions would be complicated. It would require taking account of multiple testing and the dependencies of the simulated samples under the same sample size and number of confounders. However, the standard errors of the estimated percentages serve to caution the reader not to judge the percentages alone without recognizing sampling variability. For instance, when there are no confounders and a sample size of 50, the ICA-LiNGAM procedure appears best with 93% success, but the success percentages of our two approaches fall within two standard errors of the 93% estimate. Alternatively, in the rows with 6 confounders and sample size 50 our approach with 88% success and a standard error of 3.25 appears sufficiently far from the success percentages of the other methods besides ours to make sampling fluctuations an unlikely explanation. In sum, taking all the evidence together, our approaches performed quite well and deserve further investigation under additional simulation conditions.</p><p>Table <ref type="table" target="#tab_2">4</ref> shows the average computational times. The computational complexity of the current implementation of our methods is clearly larger than that of the other linear methods ICA-LiNGAM, DirectLiNGAM, Pairwise LiNGAM, LvLiNGAM with 1 latent confounder, SLIM and LiNGAM-GC-UK and comparable to LvLiNGAM with 4 latent confounders and the nonlinear method PNL.</p><p>The MATLAB code for performing these experiments is available on our website.<ref type="foot" target="#foot_5">foot_5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">An Experiment on Real-world Data</head><p>We analyzed the General Social Survey data set, taken from a sociological data repository (<ref type="url" target="http://www.norc.org/GSS+Website/">http://www.norc.org/GSS+Website/</ref>). The data consisted of six observed variables: x 1 : prestige of father's occupation, x 2 : son's income, x 3 : father's education, x 4 : prestige of son's occupation, x 5 : son's education, and x 6 : number of siblings. <ref type="foot" target="#foot_6">15</ref> The sample selection was conducted based on the following criteria: i) non-farm background; ii) ages 35-44; iii) white; iv) male; v) in the labor force at the time of the survey; vi) not missing data for any of the covariates; and vii) data taken from 1972-2006. The sample size was 1380. The possible directions were determined based on the domain knowledge in <ref type="bibr" target="#b26">Duncan et al. (1972)</ref>, shown in Figure <ref type="figure">4</ref>. Note that there is no direct causal link from x 1 , x 3 , and x 6 to x 2 in the figure, however it is expected that each of these variables has non-zero total causal effects on x 2 given their indirect effects on x 2 . The causal relations of x 1 , x 3 , and x 6 usually are not modeled in the literature since there are many other determinants of these three exogenous observed variables that are not part of the model. However, the possible  causal directions among the three variables would be x 1 ← x 3 , x 6 ← x 1 , and x 6 ← x 3 based on their temporal orders.</p><p>Table <ref type="table" target="#tab_5">5</ref> shows the numbers of successes and precisions. Our mixed-LiNGAM approach with the t-distributed individual-specific effects gave the largest number of successful discoveries 12 and achieved the highest precision, i.e., num. successes / num. pairs = 12/15 = 0.80. The second best method was our mixed-LiNGAM approach with the Gaussian individualspecific effects, which found one less correct possible directions than the t-distribution version. The third best method was LvLiNGAM with 1 latent confounder, which found two less correct possible directions than the t-distribution version. This would be mainly because our two methods allow individual-specific effects and the other methods do not.</p><p>Table <ref type="table" target="#tab_6">6</ref> shows the estimated hyper-parameter values of our mixed-LiNGAM approach with the t-distributed individual-specific effects that performed best in the sociology data experiment. Either the estimated hyper-parameter τ indvdl 1 or τ indvdl 2 that represents the magnitudes of individual differences was non-zero in all pairs except (x 4 , x 5 ). The nonignorable influence of latent confounders was implied between the pairs (x 2 , x 4 ), (x 2 , x 6 ) and (x 3 , x 6 ) since both τ indvdl 1 or τ indvdl 2 were non-zero for the pairs. In addition, for the pair (x 2 , x 6 ), there might exist some nonlinear influence of latent confounders, since σ12 is zero, i.e., the individual-specific effects were linearly uncorrelated but dependent. <ref type="foot" target="#foot_7">16</ref> If σ12 were larger, it would have implied a larger linear influence of the latent confounders on the pair (x 2 , x 6 ). The estimates of the hyper-parameter τ indvdl 1 were very large for the pairs (x 2 , x 6 ) and (x 4 , x 1 ), which implied very large individual differences regarding x 2 and x 4 respectively. This might imply that the estimated directions could be less reliable, although they were correct in this example.</p><p>Another point is that both our methods with t-distributed and Gaussian individualspecific effects failed to find the possible direction x 5 ← x 1 , although the causal relation is expected to occur from the domain knowledge <ref type="bibr" target="#b26">(Duncan et al., 1972)</ref>. This failure would be attributed to the model misspecification since the sample size was very large. Since the estimate of the hyper-parameter τ indvdl 1 regarding x 5 was zero, the influence of latent confounders might be small for this pair, although the estimate of τ indvdl 2 was not small and the individual difference regarding x 5 seemed substantial. Modeling both latent confounders and nonlinear relations and/or allowing a wider class of non-Gaussian distributions might lead to better performance. This is an important line of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Possible directions</head><p>Our approach LvLiNGAM SLIM t-dist.</p><p>Gaussian Num. lat. conf. Num. lat. conf.     </p><formula xml:id="formula_41">1 4 1 4 10 x 1 (F O) ← x 3 (F E) x 2 (SI) ← x 1 (F O) x 2 (SI) ← x 3 (F E) x 2 (SI) ← x 4 (SO) x 2 (SI) ← x 5 (SE) x 2 (SI) ← x 6 (N S) x 4 (SO) ← x 1 (F O) x 4 (SO) ← x 3 (F E) x 4 (SO) ← x 5 (SE) x 4 (SO) ← x 6 (N S) x 5 (SE) ← x 1 (F O) x 5 (SE) ← x 3 (F E) x 5 (SE) ← x 6 (N S) x 6 (N S) ← x 1 (F O) x 6 (N S) ← x 3 (F E) Num.</formula><formula xml:id="formula_42">(F O) ← x 3 (F E) x 2 (SI) ← x 1 (F O) x 2 (SI) ← x 3 (F E) x 2 (SI) ← x 4 (SO) x 2 (SI) ← x 5 (SE) x 2 (SI) ← x 6 (N S) x 4 (SO) ← x 1 (F O) x 4 (SO) ← x 3 (F E) x 4 (SO) ← x 5 (SE) x 4 (SO) ← x 6 (N S) x 5 (SE) ← x 1 (F O) x 5 (SE) ← x 3 (F E) x 5 (SE) ← x 6 (N S) x 6 (N S) ← x 1 (F O) x 6 (N S) ← x 3 (F E) Num. of</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>We proposed a new variant of LiNGAM that incorporated individual-specific effects in order to allow latent confounders. We further proposed an empirical Bayesian approach to estimate the possible causal direction of two observed variables based on the new model. In experiments on artificial data and real-world sociology data, the performance of our method was better than or at least comparable to that of existing methods.</p><p>For more than two variables, one approach would be to apply our method on every pair of the variables. Then, we can estimate a causal ordering of all the variables by integrating the estimation results. This approach is computationally much simper than trying all the possible causal orderings. Once a causal ordering of the variables is estimated, the remaining problem is to estimate regression coefficients or their posterior distributions. Then, one can see if there are direct causal connections between these variables. Although this could still be computationally challenging for large numbers of variables, the problem reduces to a significantly simpler one by identifying their causal orders. Thus, it is sensible to develop methods that can estimate causal direction of two variables allowing latent confounders.</p><p>A reviewer suggested that we can generalize our model to more than two variables. Instead of a two-equation system in Table <ref type="table">1</ref> we could have any number of equations each with an individual-specific confounder variable, although this approach would be computationally challenging.</p><p>Future work will focus on extending the model to allow cyclic and nonlinear relations and a wider class of non-Gaussian distributions as well as evaluating our method on various real-world data. Another important direction is to investigate the degree to which the model selection is sensitive to the choice of prior distributions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example graph of LiNGAMs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example graph to illustrate the idea of independent latent confounders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>we could use various informative prior distributions for the individualspecific effects and then compare candidate priors using the standard model selection approach based on the marginal likelihoods. Below we provide two examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>so that the priors for the common effects are not very informative. It depends on the scales of variables when these constants are sufficiently large. In the experiments in Sections 4-5, we set τ cmmn µ 1 = τ cmmn b 12 = τ cmmn h 1 = 10 2 × var (x 1 ) and τ cmmn µ 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The associated graph of the model used to generate artificial data when the number of latent confounders Q = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>of the individual-specific effects for the variable pairs in the left-most column. σ 12 represents the correlation parameter value of the individual-specific effects for the variable pairs in the left-most column.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>; v) DirectLiNGAM 10 (Shimizu et al., 2011); vi) Pairwise LiNGAM 11 (Hyvärinen7. The code is available at http://www.cs.helsinki.fi/u/phoyer/code/lvlingam.tar.gz. 8. The code is available at http://cogsys.imm.dtu.dk/slim/. 9. The code is available at http://www.cs.helsinki.fi/group/neuroinf/lingam/lingam.tar.gz. 10. The code is available at http://www.ar.sanken.osaka-u.ac.jp/ ~sshimizu/code/Dlingamcode.html. 11. The code is available at http://www.cs.helsinki.fi/u/ahyvarin/code/pwcausal/.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 :</head><label>4</label><figDesc>Average CPU time (s)   Figure4: Status attainment model based on domain knowledge. Usually, the relations of x 1 , x 3 , and x 6 , represented by bi-directed arcs, are not modeled.</figDesc><table><row><cell>Father's</cell><cell></cell><cell></cell></row><row><cell>Education</cell><cell></cell><cell></cell></row><row><cell>(x3)</cell><cell>Son's</cell><cell></cell></row><row><cell></cell><cell>Education</cell><cell></cell></row><row><cell></cell><cell>(x5)</cell><cell></cell></row><row><cell>Father's Occupation (x1)</cell><cell>Son's</cell><cell>Son's Income (x2)</cell></row><row><cell></cell><cell>Occupation</cell><cell></cell></row><row><cell>Number of</cell><cell>(x4)</cell><cell></cell></row><row><cell>Siblings</cell><cell></cell><cell></cell></row><row><cell>(x6)</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of eight methods</figDesc><table><row><cell>Pairs analyzed</cell><cell>Possible</cell><cell>Estimated</cell><cell>τ indvdl 1</cell><cell>τ indvdl 2</cell><cell>σ12</cell></row><row><cell cols="2">directions</cell><cell>directions</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(x 1 (F O), x 3 (F E))</cell><cell>←</cell><cell>←</cell><cell>0.4 2 var(x 1 )</cell><cell>0</cell><cell>-0.7</cell></row><row><cell>(x 2 (SI), x 1 (F O))</cell><cell>←</cell><cell>←</cell><cell>0.8 2 var(x 2 )</cell><cell>0</cell><cell>0.3</cell></row><row><cell>(x 2 (SI), x 3 (F E))</cell><cell>←</cell><cell>←</cell><cell>0.8 2 var(x 2 )</cell><cell>0</cell><cell>-0.5</cell></row><row><cell>(x 2 (SI), x 4 (SO))</cell><cell>←</cell><cell>←</cell><cell cols="2">0.2 2 var(x 2 ) 0.4 2 var(x 4 )</cell><cell>-0.5</cell></row><row><cell>(x 2 (SI), x 5 (SE))</cell><cell>←</cell><cell>←</cell><cell cols="2">0 0.4 2 var(x 5 )</cell><cell>0</cell></row><row><cell>(x 2 (SI), x 6 (N S))</cell><cell>←</cell><cell>←</cell><cell cols="2">1.0 2 var(x 2 ) 0.6 2 var(x 6 )</cell><cell>0</cell></row><row><cell>(x 4 (SO), x 1 (F O))</cell><cell>←</cell><cell>←</cell><cell>1.0 2 var(x 4 )</cell><cell>0</cell><cell>0.9</cell></row><row><cell>(x 4 (SO), x 3 (F E))</cell><cell>←</cell><cell>←</cell><cell cols="2">0 0.2 2 var(x 3 )</cell><cell>-0.3</cell></row><row><cell>(x 4 (SO), x 5 (SE))</cell><cell>←</cell><cell>←</cell><cell>0</cell><cell>0</cell><cell>-0.3</cell></row><row><cell>(x 4 (SO), x 6 (N S))</cell><cell>←</cell><cell>←</cell><cell>0.6 2 var(x 4 )</cell><cell>0</cell><cell>-0.7</cell></row><row><cell>(x 5 (SE), x 1 (F O))</cell><cell>←</cell><cell>→</cell><cell cols="2">0 0.8 2 var(x 1 )</cell><cell>0.3</cell></row><row><cell>(x 5 (SE), x 3 (F E))</cell><cell>←</cell><cell>←</cell><cell>0.6 2 var(x 5 )</cell><cell>0</cell><cell>-0.5</cell></row><row><cell>(x 5 (SE), x 6 (N S))</cell><cell>←</cell><cell>←</cell><cell>0.2 2 var(x 5 )</cell><cell>0</cell><cell>-0.3</cell></row><row><cell>(x 6 (N S), x 1 (F O))</cell><cell>←</cell><cell>→</cell><cell>0.2 2 var(x 6 )</cell><cell>0</cell><cell>-0.9</cell></row><row><cell>(x 6 (N S), x 3 (F E))</cell><cell>←</cell><cell>→</cell><cell cols="2">0.2 2 var(x 6 ) 0.6 2 var(x 3 )</cell><cell>0.5</cell></row><row><cell cols="2">FO: Father's Occupation</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">FE: Father's Education</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SI: Son's Income</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SO: Son's Occupation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SE: Son's Education</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">NS: Number of Siblings</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Estimated hyper-parameter values of our method with t-distributed individualspecific effects</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>c 2014 Shohei Shimizu and Kenneth Bollen.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p><ref type="bibr" target="#b23">Comon (1994)</ref> and<ref type="bibr" target="#b28">Eriksson and Koivunen (2003)</ref> established the identifiability of ICA based on the characteristic functions of variables. Moments of some variables may not exist, but their characteristic functions always exist.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2"><p>If one or more error variables or latent confounders are Gaussian, it cannot be ensured that Models 3 to 5 will be distinguishable.Hoyer et al. (2008a)  considered cases with one or more Gaussian error variables in the context of basic LiNGAM.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3"><p>Relaxing this identically distributed assumption would lead to more general modeling of individual differences, however, this goes beyond the scope of the paper.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4"><p>This is an example. The modeling method could depend on the domain knowledge.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_5"><p>The URL is http://www.ar.sanken.osaka-u.ac.jp/ ~sshimizu/code/mixedlingamcode.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_6"><p>Although x6 is discrete, it can be considered as continuous because it is an ordinal scale with many points.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_7"><p>Two variables that follow the multivariate t-distribution are dependent, even when they are uncorrelated, as stated in Section 3.2.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>S.S. was supported by <rs type="funder">KAKENHI</rs> #<rs type="grantNumber">24700275</rs>. We thank <rs type="person">Aapo Hyvärinen</rs>, <rs type="person">Ricardo Silva</rs> and three reviewers for their helpful comments.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_zYauf9m">
					<idno type="grant-number">24700275</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model:</p><p>m + e (i) l</p><p>(l, m = 1, 2; l = m), where b lm are non-zero. e (i) l</p><p>(l = 1, 2; i = 1, • • • , n) are i.i.d.. e l (l = 1, 2) are mutually independent. e l (l = 1, 2) follow Laplace distributions with zero mean and standard deviations |h l |.</p><p>Prior distributions: µ l , b lm and h l (l = 1, 2; m = 1, 2; l = m) follow Gaussian distributions with zero mean and variance</p><p>and are independent of e (i)</p><p>) follow multivariate t-distributions with ν degrees of freedom, zero mean, variances τ indvdl l and correlation σ 12 (here, ν = 6).</p><p>Hyper-parameters:</p><p>and τ cmmn h l (l = 1, 2; m = 1, 2; l = m) are set to be large values so that the priors are not very informative. τ indvdl l (l = 1, 2) are uniformly varied from zero to large values. σ 12 are uniformly varied in the interval between -0.9 and 0.9.  <ref type="bibr" target="#b62">(Zhang and Hyvärinen, 2009)</ref>. Their assumptions are summarized in Table <ref type="table">2</ref>. The first seven methods assume linearity, and the eighth allows a very wide variety of nonlinear relations. The last four methods assume that there are no latent confounders. We tested the prior t-and Gaussian distributions for individual-specific effects in our approach. LvLiNGAM and SLIM require to specify the number of latent confounders. We tested 1 and 4 latent confounder(s) for LvLiNGAM since its current implementation cannot handle more than four latent confounders, whereas we tested 1, 4 and 10 latent confounders(s) for SLIM. LiNGAM-GC-UK <ref type="bibr" target="#b21">(Chen and Chan, 2013)</ref> assumes that errors are simultaneously super-Gaussian or sub-Gaussian and that latent confounders are Gaussian. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Sample size 50 100 200 Number of latent confounders Q = 0: Our approach (t-distributed individual-specific effects</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
		</imprint>
	</monogr>
	<note>3.25) 91 (2.86) 86 (3.47) Our approach (Gaussian individual-specific effects) 91 (2.86) 87 (3.36) 91 (2.86</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">LvLiNGAM (1 latent confounder)</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
		</imprint>
	</monogr>
	<note>4.44) 83 (3.76) 83 (3.76</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><surname>Lvlingam</surname></persName>
		</author>
		<idno>52 (5.00) 68 (4.66) 66 (4.74</idno>
		<imprint/>
	</monogr>
	<note>latent confounders</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><surname>Slim</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>latent confounders) 34 (4.74) 31 (4.62) 36 (4.80) SLIM (10 latent confounders) 30 (4.58) 29 (4.54) 30 (4.58</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Number of latent confounders Q = 1: Our approach (t-distributed individual-specific effects)</title>
		<idno>83 (3.76) 80 (4.00) 80 (4.00</idno>
		<imprint>
			<biblScope unit="volume">79</biblScope>
		</imprint>
	</monogr>
	<note>Our approach (Gaussian individual-specific effects. 4.07) 87 (3.36) 69 (4.62</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<idno>4.74) 71 (4.54) 73 (4.44</idno>
	</analytic>
	<monogr>
		<title level="j">LvLiNGAM (1 latent confounder)</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><surname>Lvlingam</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>latent confounders) 63 (4.83) 58 (4.94) 67 (4.70</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><surname>Slim</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>latent confounders) 40 (4.90) 34 (4.74) 44 (4.96) SLIM (10 latent confounders) 47 (4.99) 39 (4.88) 41 (4.92</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<idno>98) 58 (4.94) 61 (4.88</idno>
	</analytic>
	<monogr>
		<title level="j">Pairwise LiNGAM</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Number of latent confounders Q = 6: Our approach (t-distributed individual-specific effects</title>
		<idno>Post-nonlinear causal model 55 (4.97) 58 (4.94) 57 (4.95</idno>
		<imprint>
			<biblScope unit="volume">88</biblScope>
		</imprint>
	</monogr>
	<note>3.25) 81 (3.92) 87 (3.36) Our approach (Gaussian individual-specific effects) 84 (3.67) 85 (3.57) 87 (3.36</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><surname>Lvlingam</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>latent confounder) 58 (4.94) 70 (4.58) 70 (4.58</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName><surname>Lvlingam</surname></persName>
		</author>
		<idno>4.80) 61 (4.88) 63 (4.83</idno>
		<imprint>
			<biblScope unit="volume">64</biblScope>
		</imprint>
	</monogr>
	<note>latent confounders</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Number of latent confounders Q = 12: Our approach (t-distributed individual-specific effects</title>
		<idno>Post-nonlinear causal model 55 (4.97) 42 (4.94) 46 (4.98</idno>
		<imprint>
			<biblScope unit="volume">88</biblScope>
		</imprint>
	</monogr>
	<note>3.25) 86 (3.47) 89 (3.13) Our approach (Gaussian individual-specific effects) 91 (2.86) 89 (3.13) 91 (2.86</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<idno>5.00) 55 (4.97) 65 (4.77</idno>
	</analytic>
	<monogr>
		<title level="j">LvLiNGAM (1 latent confounder)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><surname>Lvlingam</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>latent confounders) 65 (4.77) 58 (4.94) 64 (4.80</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><surname>Slim</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">61</biblScope>
		</imprint>
	</monogr>
	<note>latent confounders) 45 (4.97) 51 (5.00) 63 (4.83) SLIM (10 latent confounders. 4.98) 54 (4.98</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Largest numbers of successful discoveries were underlined. Standard errors are shown in parentheses</title>
		<idno>Post-nonlinear causal model 51 (5.00) 43 (4.95) 46 (4.98</idno>
		<imprint/>
	</monogr>
	<note>which are computed assuming that the number of successes follow a binomial distribution. Table 3: Number of successful discoveries (100 trials</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Kernel independent component analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Probability and Measure</title>
		<author>
			<persName><forename type="first">P</forename><surname>Billingsley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Wiley-Interscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Bollen</surname></persName>
		</author>
		<title level="m">Structural Equations with Latent Variables</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Causality in linear nonGaussian acyclic models in the presence of latent Gaussian confounders</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1605" to="1641" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A clinician&apos;s tool for analyzing non-compliance</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th National Conference on Artificial Intelligence (AAAI1996)</title>
		<meeting>13th National Conference on Artificial Intelligence (AAAI1996)</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="1269" to="1276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Independent component analysis, a new concept</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="62" to="83" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Demidenko</surname></persName>
		</author>
		<title level="m">Mixed Models: Theory and applications</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On asymmetric properties of the correlation coefficient in the regression setting</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rousson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="54" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Socioeconomic Background and Achievement</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Featherman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Duncan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972">1972</date>
			<publisher>Seminar Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Discovering unconfounded causal relationships using linear nongaussian models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Entner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Frontiers in Artificial Intelligence</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">6797</biblScope>
			<biblScope unit="page" from="181" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Identifiability and separability of linear ICA models revisited</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koivunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth International Conference on Independent Component Analysis and Blind Signal Separation (ICA2003)</title>
		<meeting>Fourth International Conference on Independent Component Analysis and Blind Signal Separation (ICA2003)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="23" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Investigating causal relations by econometric models and cross-spectral methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="424" to="438" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sparse linear identifiable multivariate modeling</title>
		<author>
			<persName><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="863" to="905" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bayesian discovery of linear acyclic causal models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyttinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Conference on Uncertainty in Artificial Intelligence (UAI2009)</title>
		<meeting>25th Conference on Uncertainty in Artificial Intelligence (UAI2009)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="240" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Causal discovery of linear acyclic models with arbitrary distributions</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lacerda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Conference on Uncertainty in Artificial Intelligence (UAI2008)</title>
		<meeting>24th Conference on Uncertainty in Artificial Intelligence (UAI2008)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Estimation of causal effects using linear non-Gaussian causal models with hidden variables</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerminen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Palviainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="362" to="378" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Nonlinear causal discovery with additive noise models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pairwise likelihood ratios for estimation of non-Gaussian structural equation models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="111" to="152" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Topographic independent component analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1558" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<title level="m">Independent Component Analysis</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Estimation of a structural vector autoregressive model using non-Gaussianity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1709" to="1731" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">430</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Multivariate t-distributions and Their Applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G G</forename><surname>Kreft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">De</forename><surname>Leeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Introducing Multilevel Modeling</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Discovering cyclic causal models by independent components analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lacerda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Conference on Uncertainty in Artificial Intelligence (UAI2008)</title>
		<meeting>24th Conference on Uncertainty in Artificial Intelligence (UAI2008)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="366" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning overcomplete representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="337" to="365" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Strong completeness and faithfulness in Bayesian networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>11th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="411" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Causal search in structural vector autoregressive models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moneta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chlaß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Entner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Machine Learning Research: Workshop and Conference Proceedings, Causality in Time Series (Proc. NIPS2009 Mini-Symposium on Causality in Time Series)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="95" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Causal inference by independent component analysis: Theory and applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Moneta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Entner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oxford Bulletin of Economics and Statistics</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="705" to="730" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning, and Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000. 2009</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Causal inference on discrete data using additive noise models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2436" to="2450" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Identifiability of causal graphs using functional models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th Conference on Uncertainty in Artificial Intelligence (UAI2011)</title>
		<meeting>27th Conference on Uncertainty in Artificial Intelligence (UAI2011)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Non-Gaussian methods and high-pass filters in the estimation of effective connections</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sanchez-Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="986" to="1006" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Pairwise measures of causal direction in the epidemiology of sleep problems and depression</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rosenström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jokela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Puttonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hintsanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pulkki-Råback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Viikari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">T</forename><surname>Raitakari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Keltikangas-Järvinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">50841</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A linear non-Gaussian acyclic model for causal discovery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kerminen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2003">2003-2030, 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">DirectLiNGAM: A direct method for learning a linear non-Gaussian structural equation model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Inazumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Washio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1225" to="1248" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Salimi-Khorshidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Woolrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Network modelling methods for FMRI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="875" to="891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Estimating exogenous variables in data with more variables than observations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Sogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shimamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Washio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Imoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="875" to="880" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">An algorithm for fast recovery of sparse causal graphs</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Science Computer Review</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="67" to="72" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Causation, Prediction, and Search</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993. 2000</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Automated search for causal relations: Theory and practice</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tillman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Heuristics, Probability, and Causality: A Tribute to Judea Pearl</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Dechter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Geffner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Halpern</surname></persName>
		</editor>
		<imprint>
			<publisher>College Publications</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="467" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">New methods for separating causes from effects in genomics data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Statnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">I</forename><surname>Lytkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Aliferis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Suppl 8):S22</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Nonlinear directed acyclic structure learning with weakly additive noise models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Tillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1847" to="1855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Research strategies in developmental psychopathology: Dimensional identity and the person-oriented approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Eye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Bergman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Development and Psychopathology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="553" to="580" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">On the identifiability of the post-nonlinear causal model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th Conference in Uncertainty in Artificial Intelligence (UAI2009)</title>
		<meeting>25th Conference in Uncertainty in Artificial Intelligence (UAI2009)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Invariant Gaussian process latent variable models and application in causal discovery</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26th Conference in Uncertainty in Artificial Intelligence (UAI2010)</title>
		<meeting>26th Conference in Uncertainty in Artificial Intelligence (UAI2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="717" to="724" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
