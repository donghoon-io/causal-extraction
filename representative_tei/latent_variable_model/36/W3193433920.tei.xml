<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Bayesian Dynamic Compositional Model for Large Density Combinations in Finance *</title>
				<funder>
					<orgName type="full">BI Norwegian Business School</orgName>
				</funder>
				<funder ref="#_NqQ5xwY">
					<orgName type="full">University of Rome</orgName>
				</funder>
				<funder>
					<orgName type="full">Venice center of Economic and Risk Analytics</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-11-19">November 19, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Roberto</forename><surname>Casarin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Stefano</forename><surname>Grassi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Francesco</forename><surname>Ravazzolo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ca&apos; Foscari of Venice</orgName>
								<orgName type="institution" key="instit1">† University</orgName>
								<orgName type="institution" key="instit2">University of Rome</orgName>
								<orgName type="institution" key="instit3">Free University of Bozen</orgName>
								<address>
									<settlement>Bolzano</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Herman</forename><forename type="middle">K</forename><surname>Van Dijk</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tor</forename><surname>Vergata</surname></persName>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Norges Bank</orgName>
								<orgName type="institution" key="instit1">BI Norwegian Business School</orgName>
								<orgName type="institution" key="instit2">RCEA ¶ Econometric Institute</orgName>
								<orgName type="institution" key="instit3">Erasmus University Rotterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Bayesian Dynamic Compositional Model for Large Density Combinations in Finance *</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-19">November 19, 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C11</term>
					<term>C15</term>
					<term>C53</term>
					<term>E37 Density Combination</term>
					<term>Large Set of Predictive Densities</term>
					<term>Compositional Factor Models</term>
					<term>Nonlinear State Space</term>
					<term>Bayesian Inference</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A Bayesian dynamic compositional model is introduced that can deal with combining a large set of predictive densities. It extends the mixture of experts and the smoothly mixing regression models by allowing for combination weight dependence across models and time. A compositional model with Logistic-normal noise is specified for the latent weight dynamics and the class-preserving property of the logistic-normal is used to reduce the dimension of the latent space and to build a compositional factor model. The projection used in the dimensionality reduction is based on a dynamic clustering process which partitions the large set of predictive densities into a smaller number of subsets. We exploit the state space form of the model to provide an efficient inference procedure based on Particle MCMC. The approach is applied to track the Standard &amp; Poor 500 index combining 3712 predictive densities, based on 1856 US individual stocks, clustered in relatively small number of model sets. For the period 2007-2009, which included the financial crisis, substantial predictive gains are obtained, in particular, in the tails using Value-at-Risk. Similar predictive gains are obtained for the US Treasury Bill yield using a large set of macroeconomic variables. Evidence obtained on model set incompleteness and dynamic patterns in the financial clusters provide valuable signals for improved modelling and more effective economic and financial decisions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Predicting with large sets of data involving many model structures and explanatory variables is a topic of substantial interest to academic researchers as well as to professional and applied forecasters. It has been studied in several papers (e.g., see <ref type="bibr" target="#b75">Stock and Watson, 1999</ref><ref type="bibr">, 2002</ref><ref type="bibr">, 2005</ref><ref type="bibr">, 2014</ref><ref type="bibr" target="#b11">, and Bańbura et al., 2010)</ref>. The recent fast growth in (real-time) big data allows researchers to predict variables of interest more accurately (e.g., see <ref type="bibr" target="#b23">Choi and Varian, 2012;</ref><ref type="bibr" target="#b79">Varian, 2014;</ref><ref type="bibr" target="#b80">Varian and Scott, 2014;</ref><ref type="bibr" target="#b34">Einav and Levin, 2014)</ref>. <ref type="bibr">Stock and</ref><ref type="bibr">Watson (2005, 2014)</ref>, <ref type="bibr" target="#b11">Bańbura et al. (2010)</ref> and <ref type="bibr" target="#b58">Koop and Korobilis (2013)</ref> suggest that there are also potential gains from predicting using a large set of predictors. However, predicting with large data sets, many predictors and high-dimensional models requires new modelling strategies, efficient inference methods and extra computing power possibly resulting from parallel computing. We refer to <ref type="bibr" target="#b46">Granger (1998)</ref> for an early discussion of these issues.</p><p>We propose a Bayesian dynamic compositional model which deals with the combination of a large set of predictive densities using financial data. It extends <ref type="bibr" target="#b15">Billio et al. (2013)</ref> and <ref type="bibr" target="#b66">McAlinn and West (2019)</ref> in several directions.</p><p>In terms of methodology we introduce three innovations. First, we use the mixture o experts and/or smoothly mixing regression approaches <ref type="bibr" target="#b50">(Jacobs et al., 1991</ref><ref type="bibr" target="#b51">, Jordan and Jacobs, 1994</ref><ref type="bibr" target="#b52">, Jordan and Xu, 1995</ref><ref type="bibr" target="#b70">, Peng et al., 1996</ref><ref type="bibr" target="#b83">, Wood et al., 2002</ref><ref type="bibr" target="#b41">, Geweke and Keane, 2007</ref><ref type="bibr" target="#b81">, Villani et al., 2009)</ref> and extend these by allowing the combination weights to be dependent between models as well as to learn over time. Learning about model set incompleteness is also specified. In this context a diagnostic analysis is presented to signal particular types of missing information.</p><p>Second, a dimension reduction of the latent weight variables is introduced by making use of the class-preserving property of the logistic-normal distribution. The dimension reduction involves modelling the combination weights of the large set of densities as a dynamic factor model with a small number of factors. The projection onto a low dimension latent space uses a dynamic clustering process that allocates the predictive densities into mutually exclusive groups. We contribute to the literature on modelling variables <ref type="bibr" target="#b5">(Aitchinson and Shen, 1980;</ref><ref type="bibr">Aitchinson, 1982, e.</ref>g., see) and time-series on a bounded domain (e.g., see <ref type="bibr" target="#b82">Wallis, 1987;</ref><ref type="bibr" target="#b71">Quintana and West, 1988;</ref><ref type="bibr" target="#b48">Grunwald et al., 1993;</ref><ref type="bibr" target="#b19">Cargnoni et al., 1997;</ref><ref type="bibr" target="#b17">Brunsdon and Smith, 1998;</ref><ref type="bibr" target="#b27">Dey et al., 2001;</ref><ref type="bibr" target="#b59">Kynclova et al., 2015;</ref><ref type="bibr" target="#b74">Snyder et al., 2017;</ref><ref type="bibr" target="#b16">Boonen et al., 2019)</ref>.</p><p>Third, an efficient simulation-based Bayesian inferential procedure is derived. Given that the model can be represented as a nonlinear state space form where the measurement equation consists of a large finite mixture, Sequential Monte Carlo is used for efficient posterior approximation.<ref type="foot" target="#foot_0">foot_0</ref> Also, we propose a Bayesian diagnostic analysis of the model set incompleteness and use De Finetti's diagrams <ref type="bibr">(Ehm et al.,</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A dynamic compositional combination model for large sets of predictive densities</head><p>In this section we present a new compositional combination model which makes use of dynamic mixture processes in order to deal with large sets of predictive densities. For a recent survey about the evolution of predictive density combinations, see <ref type="bibr" target="#b0">Aastveit et al. (2019)</ref> and for background see <ref type="bibr" target="#b15">Billio et al. (2013)</ref>, <ref type="bibr" target="#b66">McAlinn and West (2019)</ref> and <ref type="bibr" target="#b12">Bastuerk et al. (2019)</ref>. When the number of models or experts is large the dimension of the latent space increases and overfitting issues can jeopardize the validity of the empirical analysis. We propose a dimensionality reduction strategy based on projections in the latent space and on dynamic clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">A dynamic mixture of density convolutions</head><p>A basic probabilistic approach to combine predictive information from different sources proceeds as follows. Let I t be an information set at time t and M = {M 1 , . . . , M n } a set of models or experts. In the mixture of experts literature the conditional predictive probability density f (y t |I t-1 , M) of an economic variable of interest y t is specified as a discrete mixture of conditional predictive probabilities of y t coming from individual models, or experts M i ∈ M with information sets I i,t-1 ⊂ I t-1 . The predictive distribution is the convex combination of predictive distributions with density given as:</p><formula xml:id="formula_0">f (y t |I t-1 , M) = n i=1 w it f (y t |I i,t-1 , M i ) (1)</formula><p>where w it , i = 1, . . . , n are the mixture weights such that 0 ≤ w it ≤ 1, w 1t + . . . + w nt = 1.</p><p>In this paper, we assume y t follows a discrete random probability measure G(•) over the set of predictors from the models M i , i = 1, . . . , n. The random measure is defined as:</p><formula xml:id="formula_1">G(y t ) = n i=1 δ(a it -y t )w it (2)</formula><p>with conditionally independent random atoms a it = ỹit + ε it i = 1, . . . , n and possibly dependent random probability weights w it i = 1, . . . , n, where δ(•) denotes the Dirac delta. <ref type="foot" target="#foot_1">2</ref> We denote with H 0t = H W 0t ⊗ H A 0t the product distribution of the sequences of the atoms a it , i = 1, . . . , n and of the weights w it , i = 1, . . . , n.</p><p>The first component of the atom ỹit follows the predictive density of the model</p><formula xml:id="formula_2">M i , i.e. ỹit ∼ f (ỹ it |I i,t-1 , M i ) (3)</formula><p>as in standard mixture of expert models.</p><p>The random variable ε it , being the difference between y t and ỹit , points towards two error sources. There may be predicting errors due to, for instance, sudden shocks in the series and there may be misspecification errors due to model set incompleteness. In this paper we focus on the latter, that is, a larger specification error in model M i implies a larger error ε it . Investigating the relative importance of a predicting error component is a topic for further research. In the following we assume the probability density functions of ε it , i = 1, . . . , n</p><formula xml:id="formula_3">ε it ∼ g(ε it |σ 2 it ) (4)</formula><p>are parametrized by the scaling process σ 2 it which controls for the level of uncertainty due to misspecification. In summary the distribution H A 0t has density given by</p><formula xml:id="formula_4">n i=1 R f (a it -ε it |I i,t-1 , M i )g(ε it |σ 2 it )dε it (5)</formula><p>As stated in the following, under these assumptions the predictive density combination model becomes a random finite mixture of convolutions of densities f (y t |I t-1 , M, σ 2 t ) where the process σ 2 t = {σ 2 1t , . . . , σ 2 nt } controls for the overall uncertainty level about the predictive models used in the combination.</p><p>Proposition 2.1. Let f (y t |I i,t-1 , M i , σ 2 it ) be a convolution of two densities:</p><formula xml:id="formula_5">f (y t |I i,t-1 , M i , σ 2 it ) = R f (y t |ỹ it , σ 2 it )f (ỹ it |I i,t-1 , M i )dỹ it (6)</formula><p>where f (y t |ỹ it , σ 2 it ) = g(y tỹit |σ 2 it ), then integrating out the random atoms of G(y t ) with respect to the measure H A 0t one obtains a predictive density combination model</p><formula xml:id="formula_6">f (y t |I t-1 , M, σ 2 t ) = n i=1 w it f (y t |I i,t-1 , M i , σ 2 it )<label>(7)</label></formula><p>When the uncertainty level tends to zero, max{σ it , i = 1, . . . , n} → 0 then g(y tỹit |σ 2 it ) → δ(y tỹit ) and one recovers the standard mixture of expert models in Eq. ( <ref type="formula">1</ref>), i.e. f (y</p><formula xml:id="formula_7">t |I t-1 , M, σ 2 t ) → f (y t |I t-1 , M).</formula><p>In the next subsection we specify a stochastic process for the latent weights w it with conditional distribution H W 0t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A compositional weight process</head><p>We represent the combination weights in our dynamic mixture model as a stochastic process on the simplex with logistic-normal noise. Exploiting the class-preserving property of the logistic-normal distribution, we project the weights onto a lower dimensional simplex while preserving their probabilistic properties.</p><p>In the following, we introduce some useful notation, definitions and results. For convenience, we omit the subindex t here. Let R m + be the positive orthant of R m we introduce the m-dimensional standard simplex</p><formula xml:id="formula_8">S m = {z ∈ R m + |z 1 + . . . + z m = 1} and V m = {v ∈ R m : v 1 + . . . + v m = 0} subspaces of R m of dimension m -1.</formula><p>We denote with ι m and I m the m-dimensional unit vector and m-dimensional identity matrix, respectively and define the ((m -1) × m matrix D m = (I m-1 , -ι m-1 ), and the (m -1)-dimensional square matrix <ref type="bibr">. . . , m, and</ref> </p><formula xml:id="formula_9">H m = (I m-1 + ι m-1 ι ′ m-1 ). Definition 2.1 (Composition function). The composition function is defined as C m (u) : R m + → S m , u → z = C m (u) where the i-th element of z is z i = u i /z m , i = 1,</formula><formula xml:id="formula_10">z m = u ′ ι m .</formula><p>In the following we denote with exp(x</p><formula xml:id="formula_11">) ∈ R m + the component-wise exponential of x ∈ R m , with log(v) ∈ R m the component-wise logarithmic transforms of v ∈ R m + and with u • v ∈ R m the Hadamard product between vectors u, v ∈ R n .</formula><p>We assume the simplex space S m is equipped with the following operations. </p><formula xml:id="formula_12">⊕ v = C m (u • z) (8)</formula><p>is a sum operation also called perturbation operation and</p><formula xml:id="formula_13">a ⊙ z = C m ((z a 1 , . . . , z a m ) ′ ) (9)</formula><p>is a scalar product operation also called power transform.</p><p>For details and background, see <ref type="bibr" target="#b3">Aitchinson (1986)</ref> and <ref type="bibr" target="#b4">Aitchinson (1992)</ref>. <ref type="bibr" target="#b14">Billheimer et al. (2001)</ref> showed that S m equipped with the perturbation and powering operations is a vector space. Moreover S m is an Hilbert space, i.e. a complete, inner product vector space.</p><p>Random combination weights with values on the simplex can be defined by introducing a probability space with support on the simplex S n . A probability measure on the simplex can be obtained by introducing a system of coordinates and a probability distribution on the coordinates. The following transformations can be used to define different systems of coordinates <ref type="bibr" target="#b32">(Egozcue et al., 2003)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.3 (Logratio transformations).</head><p>Given z ∈ S m , we define the additive (alr), centered (clr) and isometric (ilr) logratio transformations:</p><formula xml:id="formula_14">alr(z) = log(z -m /z m ) (10) clr(z) = log(z/g(z)) (11) ilr(z) = (D m V ) -1 D m log(z) (<label>12</label></formula><formula xml:id="formula_15">)</formula><p>where</p><formula xml:id="formula_16">V = (v 1 , . . . , v m ) is an orthonormal basis of V m , g(z) = (z 1 z 2 . . . z m ) 1/m is the geometric mean, z -m = (z 1 , . . . , z m-1 ) a subvector of z.</formula><p>The clr(•) transformation is an one-to-one map from S m to V m subspace of R m , whereas the alr(•) and ilr(•) are one-to-one maps from S m to R m-1 . The inverse transformations are clr</p><formula xml:id="formula_17">-1 (x) = C m (exp(x)), alr -1 (x) = C m ((exp(x -m ), 1)) and ilr -1 (x) = C m (exp(xΨ)) where Ψ is a ((m -1) × m)-dimensional contrast matrix such that ΨΨ ′ = I m -m -1 ι m ι ′ m .</formula><p>The following simple example illustrates the composition of alr(•) with alr -1 (•) which are the main transformations used in this paper.</p><p>Example 2.1. Let z = (z 1 , z 2 ) be a vector in S 2 then x = alr(z) is in R with element x 1 = log(z 1 /z 2 ). If we apply the inverse transformation we obtain a vector</p><formula xml:id="formula_18">v = alr -1 (x) in S 2 with elements v 1 = exp(x 1 )/(1 + exp(x 1 )) = z 1 /(1 + z 2 ) = z 1 since z 2 = 1 -z 1 .</formula><p>Note that it always possible to change the representation coordinates thanks to the following relationships: clr(z) = D ′ m H -1 m alr(z) and clr(z) = (D m V) -1 alr(z) where x ∈ S m , (see <ref type="bibr">Pawlowsky-Glahn and Buccianti, 2011, pp. 102-103)</ref>.</p><p>A probability distribution on S m can be defined by assuming a normal distribution for the elements of the logratio transformations in Definition 2.3. All coordinate systems provide the same probability distribution, called logisticnormal, but its parametrization and reference measure will depend on the system chosen (see <ref type="bibr">Pawlowsky-Glahn and Buccianti, 2011, ch. 7</ref>). Each coordinate system has its own drawback, the alr(•) depends on the choice of the coordinate used in the common denominator, ilr depends on the choice of the orthonormal basis V and the clr returns a singular distribution.</p><p>We choose the following definition of logistic-normal distribution (see <ref type="bibr" target="#b5">Aitchinson and Shen, 1980;</ref><ref type="bibr" target="#b2">Aitchinson, 1982</ref><ref type="bibr" target="#b3">Aitchinson, , 1986) )</ref> induced by the alr(•) transformation because it exhibits some useful properties for modelling purposes. We exploit the fact that the logistic-normal family is closed under perturbation and power transformations to propose a random weight process. The resulting family of compositional processes is invariant under the subcomposition and amalgamation operations which will be used to provide a graphical representation of high dimensional weight vectors.</p><p>Definition 2.4 (Logistic-normal distribution). The random vector z ∈ S m follows a logistic-normal distribution L m (µ, Υ) if its probability density function is</p><formula xml:id="formula_19">p(z|µ, Υ) = |2πΥ| -1/2   m j=1 z j   -1 exp - 1 2 (log(z/z m ) -µ) ′ (Υ) -1 (log(z -m /z m ) -µ) (13)</formula><p>with parameters µ ∈ R m-1 and Υ (m -1)-dimensional positive symmetric matrix, where</p><formula xml:id="formula_20">z m = 1 -z ′ -m ι m-1 .</formula><p>As stated in the following the logistic-normal distribution is related to the normal and the log-normal distributions.</p><p>Proposition 2.2. Let v ∼ N m (µ, Υ), and define u = exp(v) and z = alr -1 (v). Then u follows the m-variate log-normal distribution, Λ m (µ, Υ), and z follows a</p><formula xml:id="formula_21">m-variate logistic-normal distribution, L m (D m µ, D m ΥD ′ m ). Proof See Appendix A.</formula><p>The following example illustrates the inverse relationship between the logisticnormal and the normal distribution.</p><formula xml:id="formula_22">Example 2.2. Let z = (z 1 , z 2 ) be a vector in S 2 with distribution L 2 (D 2 µ, D 2 ΥD ′</formula><p>2 ) and apply the transformations used used in Example 2.1. The (i, j)-th element of the Jacobian of z = alr -1 (u) is ∂ j z i = u i δ(i-j)-u i u j and the Jacobian is |J| = u 1 u 2 and log(z 1 /z 2 ) = log(exp(u 1 )/(z 2 (1+exp(u 1 ))) with z 2 = 1-exp(u 1 )/(1+exp(u 1 )). It follows that by substituting log(z 1 /z 2 ) = u 1 in the density of u and by multiplying the by Jacobian, the distribution of z is N (D 2 µ, D 2 ΥD 2 ). Top plots in Figure <ref type="figure" target="#fig_1">1</ref> show the density function of L 2 (µ, υ 2 ) for different values of µ and υ 2 .</p><p>Distributions other than the logistic-normal can be used for weights such as the Dirichlet distribution, but as noted in <ref type="bibr" target="#b5">Aitchinson and Shen (1980)</ref> this distribution may be too simple to be realistic in the analysis of compositional data since the components of a Dirichlet composition have a correlation structure determined solely by the normalization operation in the composition. Extensions of the logisticnormal distribution can be considered such as the logistic skew-normal <ref type="bibr" target="#b65">(Mateu-Figueras et al., 2005)</ref> or the logistic Student-t <ref type="bibr" target="#b5">(Aitchinson and Shen, 1980;</ref><ref type="bibr" target="#b54">Katz and King, 1999)</ref>, but we leave this topic for future research.</p><p>Another relevant property of the logistic-normal distribution is the classpreserving property of the composition of the logistic-normal vectors (see <ref type="bibr" target="#b5">Aitchinson and Shen, 1980)</ref>. This property is used to build a stochastic process in the simplex with logistic-normal noise. </p><formula xml:id="formula_23">w i = d-1 j=1 z j z d a ij   1 + c i=1 d-1 j=1 z j z d a ij   -1 (14) i = 1, . . . , c, then w = (w 1 , . . . , w c ) ′ follows the logistic-normal L c+1 (Aµ, AΥA ′ ). Proof See Appendix A.</formula><p>We provides in the following the statistical interpretation of the coefficients A and illustrates how this property can be used to define dependent variables through transformation of a common latent factor.</p><p>Example 2.3. Let z = (z 1 , z 2 ) be a vector in S 2 with distribution L 2 (0, υ 2 ) and let A = (1, a) ′ a (2 × 1) matrix then the random vector w = (w 1 , w 2 , w 3 ) with <ref type="bibr">a)</ref>). The covariance between w 1 and w 2 is defined as Cov(w 1 , w 2 ) = Cov(log(w 1 /w 3 ), log(w 2 /w 3 )) = υ 2 a. This provides an interpretation of the coefficient matrix A appearing in Proposition 2.3.</p><formula xml:id="formula_24">w 1 = (z 1 /z 2 )/((z 1 /z 2 )+(z 1 /z 2 ) a +1), w 2 = (z 1 /z 2 ) a /((z 1 /z 2 )+(z 1 /z 2 ) a +1) and w 3 = 1 -w 1 -w 2 , follows a logistic-normal L 2 (0, υ 2 (1, a) ′ (1,</formula><p>Compositions are usually represented by means of the De Finetti's, or ternary, diagram. A point in the diagram has coordinates (z, v) ′ ∈ R 2 given by the following map from</p><formula xml:id="formula_25">S 3 → R 2 (z, v) = (Bz 1 , Cz 2 , Az 3 ) (15) with vertices A = (z 0 + 0.5, v 0 + √ 3/2) ′ , B = (z 0 , v 0 ) ′ and C = (z 0 + 1, v 0 )</formula><p>′ where (z 0 , v 0 ) ′ are coordinates arbitrarily chosen. See <ref type="bibr" target="#b18">Cannings and Edwards (1968)</ref> and <ref type="bibr" target="#b69">Pawlowsky-Glahn et al. (2015)</ref> for further details. In this diagram the weights (1, 0, 0), (0, 1, 0) and (0, 0, 1), correspond to the vertices B, C and A, respectively. The black square corresponds to the barycentre of the triangle (1/3, 1/3, 1/3). The last line in Fig. <ref type="figure" target="#fig_1">1</ref> provides the De Finetti's diagrams of the relationships given in the Example 2.3 and rappresented in the second line of the same plot. In this paper, we apply these results as follows. First, we assume that the n-dimensional vector of weights w t = (w 1t , . . . , w nt ) ′ of our mixture model in Eq. ( <ref type="formula" target="#formula_6">7</ref>) relates to a lower dimensional vector z t ∈ S m as follows</p><formula xml:id="formula_26">w t = φ At (z t ) (<label>16</label></formula><formula xml:id="formula_27">)</formula><p>where the map φ A (•) from S m to S n is defined in Proposition 2.3, and A t is a time-varying ((n -1) × (m -1)) projection matrix. Second, we apply the operations in Definition 2.2 and assume that the latent factors follow a random walk process with normal-logistic-normal innovations</p><formula xml:id="formula_28">z t = z t-1 ⊕ η t , η t ∼ L m (0 m , Υ)<label>(17)</label></formula><p>which is a flexible model for the latent weights.</p><p>Thanks to the classpreserving property of the logistic-normal the combination weights have conditional distribution H W 0t which is a logistic-normal as stated in the following. Corollary 2.1 (Weight dynamics). Let z t be a process defined in Eq. (17), A t an ((n -1) × (m -1)) matrix, then w t defined in Eq (16) belongs to the simplex S n and follows the logistic-normal distribution L n (A t alr(z t-1 ), A t ΥA ′ t ). Proof See Appendix A.</p><p>The class-preserving property allows for a projection from the large dimensional simplex S n onto the possibly lower space S m . Nevertheless, the effectiveness of the dimensionality reduction strategy and the probabilistic properties of the random vector w t depend crucially on the choice of the sequence of matrices A t , which will be discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dimensionality reduction and dynamic clustering</head><p>A contribution of this paper is to simplify the complexity of the combination exercise by reducing the dimension of the latent space of the weights while preserving crucial aspects such as their time variations and probabilistic properties.</p><p>Dimensionality reduction techniques are widely used in machine learning to reduce the dimension of high-dimensional datasets (e.g., see <ref type="bibr">Casarin and Veggente, 2020, and references therein)</ref>. The dependence structure in the data is used to reduce substantially the data dimension and to extract relevant information. In this paper we exploit the similarities between models or experts by specifying a dynamic clustering process in the space of predictive densities f (ỹ t |I i,t-1 , M i ).</p><p>The n predictors are clustered into m different groups with m &lt; n, following some (time-varying) features ψ it ∈ R d , i = 1, . . . , n, of the predictive densities. This allows to learn sequentially model dependence, a feature well documented on data but largely ignored in the predictive density combination literature.</p><p>Let N 1t , . . . , N mt be the m groups of predictors such that each predictor belongs only to one group, i.e. N it ∩ N jt = ∅ and N 1t ∪ N 2t ∪ . . . N mt = {1, 2, . . . , n}. Given the clustering of the predictors, we specify the (n × m) allocation matrix Ξ t with elements ξ ij,t = 1 if i ∈ N jt and ξ ij,t = 0 otherwise, and a (n × m) coefficient matrix B t . The two matrices allow us to project the n-dimensional latent variable w t onto a reduced dimension latent space by using the elements of Ãt = (Ξ t • B t ) in ( <ref type="formula" target="#formula_26">16</ref>). With this specification, if the i-th predictive density is allocated to the k-th cluster then its mixture weight w it will be driven by the latent factor z kt which is uniquely associated to the cluster k.</p><p>The dynamics of the allocation matrix Ξ t is given in the following. Let c jt ∈ R d , j = 1, . . . , m be the centroids defined as</p><formula xml:id="formula_29">c jt = 1 n jt i∈N jt ψ it (<label>18</label></formula><formula xml:id="formula_30">)</formula><p>where n jt = Card(N jt ) is the number of predictive densities in the j-th cluster at time t. At time t + 1 the allocation matrix updates as follows:</p><formula xml:id="formula_31">ξ ij,t+1 = 1 if j = j *</formula><p>and ξ ij,t+1 = 0 otherwise where j * = arg min{||ψ it+1c jt ||, j = 1, . . . , m} and || • || is the Euclidean norm. The centroids update as follows</p><formula xml:id="formula_32">c jt+1 = c jt + λ t (m jt+1 -c jt )<label>(19)</label></formula><p>where</p><formula xml:id="formula_33">m jt+1 = 1 n jt+1 i∈N jt+1 ψ it (20)</formula><p>and λ t ∈ [0, 1]. Note that the choice λ t = n jt+1 /(n c jt + n jt+1 ), with n c jt = t s=1 n js , implies a dynamic clustering with forgetting driven by the processing of the blocks of observations. In the application we fix λ = 0.99. The grouping of the predictors can change over time, following our dynamic clustering rule, but the number of clusters is assumed constant to preserve the interpretability of the factors.</p><p>For the elements b ij,t of the coefficient matrix B t we consider two alternative specifications. In the first one all coefficients in the cluster have the same weights:</p><formula xml:id="formula_34">b ij,t = 1 n jt I(ξ j,it = 1)<label>(21)</label></formula><p>This specification may have the undesirable property that the projection coefficients a ij,t = ξ ij,t b ij,t are constant within a group. For this reason, we also propose a second specification where each model contributes to the combination following its predicting performance g it (e.g. the log score in Eq. (C.14) in the Supplementary Material C), i.e.</p><formula xml:id="formula_35">b ij,t = I(ξ j,it = 1) t s=1 exp{g is } ḡit (<label>22</label></formula><formula xml:id="formula_36">)</formula><p>where ḡit = l∈N it t s=1 exp{g ls }. In order to use the projection matrix Ãt in the Eq. ( <ref type="formula" target="#formula_26">16</ref>) it is possible to choose A t as the ((n -1) × (m -1))-dimensional matrix obtained by removing the last column and the last row of Ãt .</p><p>Remark 1. Given the results in the preceding subsection, the chosen specification for A t returns a random weight vector w t with degenerate distribution on S n .</p><p>Proof See Appendix A.</p><p>The degeneracy is related to the rank deficiency of the matrix A t ΥA ′ t . The first source of degeneracy is due the presence of zeros in the last n mt rows of the matrix A t and can be removed by apply the class-preserving transformation to obtain a subvector of w t . Let us denote with n t = (n 1t + . . . + n m-1t ) the number of models assigned to the first m -1 clusters and let us assume that they correspond to the first n t elements of ỹt . Note that this simplifying assumption is not restrictive since it is possible to permute the rows of Ãt in order to have the coefficients for the last cluster in the last nn t rows. Then one can obtain a random vector (w 1t , . . . , w nt , (1w 1t -. . .w nt )) with logistic-normal distribution by applying the class-preserving transformation. The residual weight 1w 1t -. . .w nt is then assigned to the models in the last cluster. This can be obtained in two steps. First, we drop out the last nn t rows of the projection matrix A t and apply the class-preserving transformation by using the (n t × (m -1))-dimensional matrix A * t = (I nt , O n-nt )A t as projection matrix. Second, we set (w nt+1 , . . . , w nt ) = κa t where a t represents a nn t dimensional vector containing the elements in the last nn t rows of the last column of Ãt . The following results establishes the relationship between our logistic-normal linear model with distribution on the simplex S nt+1 and a Gaussian nonlinear model in R nt .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 2.2. Let us define the Gaussian random walk process</head><formula xml:id="formula_37">v t ∈ R m-1 t = 1, 2, . . . with v t ∼ N m-1 (v t-1 , Υ) and the following transformed processes x t = A * t v t , w * t = alr -1 (x t ), z t = alr -1 ((v t , 1)) and w * t = φ A (z t ).</formula><p>The transformed vectors have the following distributions</p><formula xml:id="formula_38">z t ∼ L m (z t-1 , Υ) (23) w * t ∼ L nt+1 (A * t v t-1 , A * t ΥA * ′ t )<label>(24)</label></formula><p>Proof See Appendix A.</p><p>The relationships with the Gaussian process given in the previous Corollary can be exploited in the inference procedures to easily generate samples for the latent weights or to derive filtering and smoothing recursions using the usual operations on R nt . Finally note that the second source of degeneracy is intrinsic to our projection strategy based on the allocation matrix Ξ t , which implies the rank deficiency of the matrix A * t ΥA * t , and on the assumption that the relationship between w t and z t is not subject to errors. Our approach can be extended to account for contemporaneous uncertainty with the addition of logistic-normal noise in the equation for w t . This is left for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">A compositional state-space model</head><p>We summarize the model defined in the previous subsections and show that it is a conditionally linear state-space model on the simplex. Extending the ⊙ product operation to the case of a matrix of real numbers allow us to write the transform φ A , as a linear matrix operation between simplices of different dimensions, denoted with ⊞.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 2. Let z ∈ S m be a composition, A a (n × m) real matrix and define the matrix multiplication</head><formula xml:id="formula_39">A ⊞ z = C n m j=1 z a 1j j , . . . , m j=1 z a n-1j j . If A is such that Aι m = 0 n and a im = -1, i = 1, . . . , n -1 and a n,j = 0 j = 1, . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, m, the transform defined in Proposition 2.3 can be written as φ</head><formula xml:id="formula_40">A (z) = A ⊞ z.</formula><p>This result enables us to obtain the following state-space representation of our compositional combination model. Let then the model in Equations ( <ref type="formula" target="#formula_6">7</ref>), ( <ref type="formula" target="#formula_26">16</ref>) and ( <ref type="formula" target="#formula_28">17</ref>) writes as</p><formula xml:id="formula_41">ε t = (ε 1t , . . . , ε nt ) ′ and ỹt = (ỹ 1t , . . . , ỹnt ) ′ , y t s t ∼ Ca n (w t ) (Model selection) ỹit |I i,t-1 , M i , i = 1, . . . , n (Time series models) b ij,t = 1/n jt , ∀i ∈ N jt (Weights within cluster) ξ ij,t = I(i ∈ N jt ) (Allocation variables) w t = φ At (z t ), A t = Ξ t • B t (Projection) σ 2 it = exp{h it }, h it = φ i h it-1 +ζ it (Volatility) c jt = c jt-1 + λ t (m jt -c jt-1 ) (Dynamic clustering) z t = z t-1 ⊕ η t η t ∼ L m (0, D m ΥD ′ m ) (Probability weights)</formula><formula xml:id="formula_42">y t = (ỹ t + ε t ) ′ s t , ε t ∼ N n (0, diag{σ 2 t })<label>(25)</label></formula><formula xml:id="formula_43">s t ∼ Ca n (w t ), w t = A t ⊞ z t (<label>26</label></formula><formula xml:id="formula_44">)</formula><formula xml:id="formula_45">z t = z t-1 ⊕ η t , η kt ∼ L m (0, D n ΥD ′ m ) (27)</formula><p>where s t is a model-selection categorical process and Ca n (w t ) denotes the ndimensional Multinoulli, or categorical, distribution with parameter w t ∈ S n . A graphical representation of the dimensionality reduction strategy implemented in our model is given in Fig. <ref type="figure" target="#fig_2">2</ref>. The observable variable y t (top box) depends on three latent processes (ellipses). The process s t allows for a dynamic selection of the models (see <ref type="bibr" target="#b39">George and McCulloch, 1993</ref>, for model selection with latent variables). The stochastic volatility process σ 2 it accounts for model set incompleteness as proposed in <ref type="bibr" target="#b15">Billio et al. (2013)</ref>. The compositional model for the factors z t allows for well-defined probability weights (see <ref type="bibr" target="#b68">Pawlowsky-Glahn and Buccianti, 2011;</ref><ref type="bibr" target="#b69">Pawlowsky-Glahn et al., 2015</ref>, for an introduction to compositional models).</p><p>In Fig. <ref type="figure" target="#fig_3">3</ref>-4 we provide simulated paths from our compositional model with five independent normal predictors ỹit ∼ N (-2 + i, 0.1i) i = 1, . . . , 5 and observation noise ε t ∼ N (0, 0.2). The common latent factors z 1t , z 2t , z 3t (i.e. m = 3) are associated with the first, second and third clusters, respectively, and have noise </p><formula xml:id="formula_46">distribution η t ∼ L 2 (0 2 , 0.2D 3 D ′ 3 ) i.i.d. t = 1, .</formula><p>. . , 500. The projection matrix</p><formula xml:id="formula_47">A t =         b 11,t 0 0 b 21,t 0 0 0 b 32,t 0 0 b 42,t 0 0 0 1         , b ij,t ∼ Λ 1 (0, 0.2), ∀i, j, t<label>(28)</label></formula><p>allocates models M 1 and M 2 to the first cluster, models M 3 and M 4 to the second cluster and model M 5 to the third cluster. Fig. <ref type="figure" target="#fig_3">3</ref> exhibits the trajectories of the common factors by using the De Finetti's, or ternary, diagram (left) and a time series plot (middle). In this diagram, weight vectors with probability 1 assigned to one cluster and 0 to the others, i.e. (1, 0, 0), (0, 1, 0) and (0, 0, 1), correspond to the vertices. Red and blue dots close to the vertices z 1t and z 3t , in the diagram, correspond to samples where cluster 1 and cluster 3, respectively receive weights close to one (blue and red subtrajectories in the time series plot). The barycentre of the triangle (black square) corresponds to the case of equally weighted clusters, i.e. (1/3, 1/3, 1/3).</p><p>As reference lines, we report in the diagram two deterministic trajectories</p><formula xml:id="formula_48">r 1t = alr -1 ((-10 + 20 t T , -20 + 40 t T , -30 + 60 t T )) r 2t = alr -1 ((-20 + 40 t T , -10 + 20 t T , -30 + 60 t T ))</formula><p>t = 1, . . . , T (dashed and solid lines, respectively). In the first trajectory, a weight close to 1 is assigned to cluster 1 at the beginning of the period, i.e. t = 0, and to cluster 3 at the end of the period, i.e. t = T . In the second trajectory unit weight is given to cluster 2 at t = 0 and to cluster 3 at t = T . Realizations of y t given random samples from the five predictors are in the right plot. Horizontal lines report the point predictions for the five predictors. For example, when the weight of the cluster 3, z 3t (middle plot, dotted-dashed, blue), increases, the weight of the fifth predictor w 5t increases resulting in values for y t close to 2 (right, plot blue line).</p><p>Figure <ref type="figure">4</ref>: De Finetti's diagram of the ternaries (w i,t , w j,t , w -(i,j)t ), j &gt; i with w -(i,j)t the amalgamation of w lt , l = i, j. In each plot the ternary samples (dots), the equal weight composition (square) and the reference lines (dashed and dotted). In the panels, colors indicate different sub-samples.</p><p>A way commonly found for reducing dimensionality of probabilistic weights is to sum some weights into a new weight which is called amalgamation. Definition 2.5 (Amalgamation). Given the composition w ∈ S m-1 , and a collection of indices A = {i 1 , . . . , i d } ⊂ {1, . . . , d}, md &gt; 0, and the complement set Ā = {1, . . . , n}/A the value</p><formula xml:id="formula_49">w A = i∈A w i is called amalgamated component. The vector (w Ā, w A ) ′ is called amalgamated composition which is in S m-d</formula><p>, where w Ā is the vector containing w j with j ∈ Ā.</p><p>See <ref type="bibr" target="#b32">Egozcue et al. (2003)</ref>, <ref type="bibr" target="#b31">Egozcue and Pawlowskky-Glahn (2005)</ref> and <ref type="bibr" target="#b37">Fiŝerová and Hron (2011)</ref> for further details on amalgamation and subcomposition operations. The amalgamation can be used in combination with the De Finetti's diagram for running weight comparisons and representation for high dimensional weight vectors. Figure <ref type="figure">4</ref> illustrates the pairwise comparison of the weight dynamics. In each diagram, the dots represent the ternary (w i,t , w j,t , w -(i,j),t ) with i = j where w -(i,j),t = l =i,j w l,t is the amalgamation of w l,t with l = i, j into a new weight w -(i,j),t . One can see that w 1t and w 2t move together (first plot) since they are driven by a common factor z 1t . Whereas w 1t does not depend on w 3t (second plot) and depends negatively on w 5t (third plot). Also w 3t and w 4t move together and have negative dependence with w 5t (last three plots).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Multiple-prediction extensions</head><p>In the case the same set of predictive densities is used for predicting a set of variables y 1t , . . . , y Kt , the model can be extended as follows:</p><formula xml:id="formula_50">y kt = (ỹ t + ε t ) ′ s kt , ε kt ∼ N (0, diag(σ 2 kt )) (<label>29</label></formula><formula xml:id="formula_51">)</formula><formula xml:id="formula_52">s kt ∼ Ca n (w kt ), w kt = A kt ⊞ z kt , (<label>30</label></formula><formula xml:id="formula_53">)</formula><formula xml:id="formula_54">z t = z t-1 ⊕ η t , η t ∼ L Km (0, I m ⊗ Υ)<label>(31)</label></formula><p>where the projection matrices A kt are driven by a common clustering process Ξ t and a variable-specific learning coefficient B kt which reflects the ability of each predictive density to predict the variable of interest y kt .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bayesian inference</head><p>The analytic solution of the optimal filtering problem is generally not known, also the clustered-based mapping of the predictor weights onto the subset of latent variables requires the solution of an optimization problem which is not available in closed form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Prior and posterior distributions</head><p>Let θ ∈ Θ be the parameter vector of the combination model, that is θ = (φ, Υ) with φ = (φ 1 , . . . , φ n ). We assume independent normal prior distributions N (0, s 2 ) for φ 1 , . . . , φ n and inverse Wishart distribution IW m (a, S) for Υ and denote with π(θ) the joint distribution.</p><p>In the following, u 1:t = (u 1 , . . . , u t ) indicates the collection of vectors u t from time 1 to time t and ω t = (s t , h t , z t ) the collection of latent variables with values in the latent space W = ({0, 1} n × R n × S m ). The joint posterior distribution is</p><formula xml:id="formula_55">π(θ|y 1:T ) = L(y 1:T |θ)π(θ) m(y 1:T ) (<label>32</label></formula><formula xml:id="formula_56">)</formula><p>where m(y 1:T ) is the marginal likelihood or model evidence and L(y 1:T |θ) the likelihood function given in integral form</p><formula xml:id="formula_57">W T t=1 f (y t |s t , h t )f (s t |z t , A t )f (h t |h t-1 , φ)f (z t |z t-1 , Υ)π(θ)dω 1:T (33)</formula><p>with f (y t |s t , h t ), f (s t |z t , A t ) and f (z t |z t-1 , Υ) the distributions in Eq. ( <ref type="formula" target="#formula_42">25</ref>)-( <ref type="formula">27</ref>) and f (h t |h t-1 , φ) the conditional distribution of the log-volatility process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Posterior approximation</head><p>The joint posterior is not tractable thus we apply Markov chain Monte Carlo (MCMC) <ref type="bibr" target="#b73">(Robert and Casella, 2004</ref>) combined with Sequential Monte Carlo <ref type="bibr" target="#b55">(Kitagawa, 1998;</ref><ref type="bibr" target="#b62">Liu and West, 2001;</ref><ref type="bibr" target="#b29">Doucet et al., 2001)</ref>. More specifically we consider the Particle Metropolis Hastings (PMH) algorithm discussed in <ref type="bibr" target="#b9">(Andrieu et al., 2010;</ref><ref type="bibr" target="#b10">Andrieu and Roberts, 2009)</ref>. At the k-th iteration of the PMH a candidate θ * is drawn from the proposal distribution q(θ * |θ (k-1) ) where θ (k-1) is the previous iteration value of the MCMC chain, and it is accepted with probability </p><formula xml:id="formula_58">α(θ * , θ (k-1) ) = min 1, LN (y 1:T |θ * )π(θ * )q(θ (k-1) |θ * ) LN (y 1:T |θ (k-1) )π(θ (k-1) )q(θ * |θ (k-1) ) (34) with LN (y 1:T |θ * ) = T t=1 fN (y t |y 1:t-1 )<label>(35)</label></formula><formula xml:id="formula_59">, σ 2 it )f (ỹ it |I i,t-1 , M i )dỹ it ≈ 1 M N j=1 f (y t |ỹ j it , σ 2 it )<label>(37)</label></formula><p>and π N (ω t ) is the approximated filtering distribution obtained by a Sequential Monte Carlo (SMC) algorithm, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>π(ω t |y</head><formula xml:id="formula_60">1:t ) = = L(y t |s t , h t ) L(y t |y 1:t ) W f (s t |z t , A t )f (h t |h t-1 , φ)f (z t |z t-1 , Υ)p(ω t-1 |y 1:t-1 )ω t-1 ≈ 1 N N j=1 L(y t |s j t , h j t ) L(y t |y 1:t ) f (s j t |z j t , A t )f (h j t |h j t-1 , φ)f (z j t |z j t-1 , Υ)<label>(38)</label></formula><p>In our SMC, given the initial set of particle Φ t = {ω j t , γj t } N j=1 and the projection matrix A t = Ξ t • B t we iterate the clustering, prediction, updating and resampling steps detailed in the following.</p><p>First, we evaluate the dynamic clustering process in Eq. ( <ref type="formula" target="#formula_32">19</ref>)-( <ref type="formula" target="#formula_35">22</ref>) by using the predictive distribution of the models or experts at time t + 1 and obtain the updated Ξ t+1 and B t+1 .</p><p>Second, we approximate the state predictive density as follows:</p><formula xml:id="formula_61">π N (ω t+1 |y 1:t ) = N j=1 p(ω t+1 |ω t )γ j t δ(ω j t -ω t )<label>(39)</label></formula><p>where p(ω</p><formula xml:id="formula_62">t+1 |ω t ) = f (s t+1 |z t+1 , A t+1 )f (h t+1 |h t , φ)f (z t+1 |z t , Υ)</formula><p>The approximated state filtered density is easily obtained</p><formula xml:id="formula_63">π N (ω t+1 |y 1:t+1 ) = N j=1 γ j t+1 δ(ω j t+1 -ω t+1 ) (<label>40</label></formula><formula xml:id="formula_64">)</formula><p>where γ j t+1 ∝ γj t fM (y t+1 |s j t+1 , h j t+1 ) is a set of normalized weights Since the systematic resampling of the particles introduces extra Monte Carlo variations and reduces the efficiency of the importance sampling algorithm, we do resampling only when the effective sample size (ESS) is below a given threshold. See <ref type="bibr" target="#b21">Casarin and Marin (2009)</ref> </p><formula xml:id="formula_65">for ESS calculation. At the t + 1-th iteration if ESS j t+1 &lt; κ, simulate Φ t+1 = {ω θ k j t+1 , γj t+1 } N j=1 from {ω θ j t+1 , γ j t+1 } N j=1 (e.</formula><p>g., multinomial resampling) and set γj t+1 = 1/N. We denote with k j the index of the j-th re-sampled particle in the original set Φ t+1 . If ESS t+1 ≥ κ set Φ t+1 = {ω θ j t+1 , γj t+1 } N j=1 . In the application with large number of predictors we apply the parallel evaluation of the dynamic clustering process and of the SMC algorithm as detailed in the Supplementary Material B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Empirical applications</head><p>As a first application we focus on the daily stock market case, briefly mentioned in the previous section. We report results on several features of the combined predictive density of a replication of the daily Standard &amp; Poor 500 (S&amp;P500) index, including the economic value of tail events like Value-at-Risk.</p><p>The second application considers quarterly bond market data and using the extended <ref type="bibr" target="#b77">Stock and Watson (2005)</ref> dataset, which includes 142 series sampled from 1959Q1 to 2011Q2, we predict the 3-month Treasury Bill interest rates.</p><p>In both exercises, we study incompleteness diagnostics and the weight patterns of the clusters over time which provide valuable signals that may lead to improved financial modelling and predicting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Predicting and tracking the S&amp;P500</head><p>Many investors of mutual funds, hedge funds and exchange-traded funds try to replicate the performance of the S&amp;P500 index by holding a set of stocks, which are not necessarily the exact same stocks included in the index. We collected 1856 individual stock daily prices quoted in the NYSE and NASDAQ from Datastream over the sample <ref type="bibr">March 18, 2002</ref><ref type="bibr">to December 31, 2009</ref>, for a total of 2034 daily observations for each individual series. To control for liquidity we impose that each stock has been traded a number of days corresponding to at least 40% of the sample size. We compute log returns for all stocks. The cross-section average statistics of all series are reported in Table <ref type="table">D</ref>.1 in Section D.1 of the Supplementary Material together with the results for S&amp;P500. <ref type="foot" target="#foot_2">3</ref>To ease on the computational workload, we apply an optimisation method to estimate the posterior modes of the parameters from a Normal GARCH(1,1) model and a Student-t GARCH(1,1) model<ref type="foot" target="#foot_3">foot_3</ref> using rolling samples of 1250 trading days (about five years) for each stock return:</p><formula xml:id="formula_66">y it = c i + κ it ζ it (41) κ 2 it = θ i0 + θ i1 ζ 2 i,t-1 + θ 2 κ 2 i,t-1 , i = 1, 2, . . . , n, (<label>42</label></formula><formula xml:id="formula_67">)</formula><p>where y it is the log return of stock i at day t, ζ it ∼ N (0, 1) and ζ it ∼ T (ν i ) for the Normal and t-Student cases, respectively. The number of degrees of freedom ν i is estimated in the latter model. We produce 784 one day ahead predictive densities from January 1, 2007 to December 31, 2009. Our out of sample period is associated with high volatility driven by the US financial crisis and includes, among others, events such as the acquisitions of Bear Stearns, the default of Lehman Brothers and all events of the following week.</p><p>In the dynamic clustering process we assume two clusters of predictive densities for the Normal GARCH(1,1) model and two clusters for the Student-t GARCH(1,1) model. The first two include Normal GARCH models with low (cluster one, labelled n1) and high (cluster two, labelled n2) volatility. The third cluster (labelled t1) includes Student-t GARCH models with low degrees of freedom and the fourth one (labelled t2) includes Student-t GARCH with high degrees of freedom. <ref type="foot" target="#foot_4">5</ref> The clustering of the densities is repeated every time a new prediction is produced and therefore the cluster composition varies over time.</p><p>Figure <ref type="figure">5</ref> presents results about these features. Normal models in cluster n1 differ substantially in terms of predicted variance (left plot, solid black line), having a rather low constant variance value over the entire period while cluster n2 has a variance more than double in size (left plot, dashed black line) including a shock in the latter part of 2008. Student-t models in cluster t1 have a relatively constant thick tail over the entire period (right plot, solid red line) while cluster t2 has values around 10 for the degrees of freedom (right plot, dashed red line) except during the crisis period, where the density collapses toward a normal density with degrees of freedom larger than 30. The Lehman Brother effect is visible in the figure, with an increase of volatility in the normal cluster n2 and a decrease in the degrees of freedom in the Student-t cluster t2.</p><p>Diagnostic for the combination model with four clusters is shown in Figure <ref type="figure">6</ref>. The average weights per cluster, that is the average of w it over i ∈ N jt , are in the left plot. De Finetti's diagrams in Figure <ref type="figure" target="#fig_5">7</ref> exhibit the pairwise comparison of the weight dynamics. In the diagrams the blue dots represent the ternary (z i,t , z j,t , z -(i,j),t ) where z -(i,j),t = l =i,j z l,t is the other model's total weight.</p><p>There is evidence of time variations in the weights, with three distinct subperiods, and of fat tails playing an important role. Before the crisis, clusters n2 and t1 have almost equal high weights (blue dots in the fourth diagram, In each plot the trajectory of the ternary (z it , z jt , z -(ij)t ), j &gt; i (blue line), the starting point (red dot), the ending point (black dot) and the equal weight composition (square).</p><p>Figure <ref type="figure">6</ref>), while clusters n1 and t2, both play a much less important role (third diagram). In the crisis period of 2008, cluster t1 receives almost all the weight with clusters n1 and n2 almost none (red dots on the dashed reference line in the sixth diagram). Some of the assets led the market experiencing large losses in that period. This results in very fat tailed densities and our combination scheme captures these features and assigns to cluster t1 more weight. In the period after the Lehman Brothers collapse cluster t1 receives again a substantial weight while the normal cluster with large variance n2 is getting gradually more weight (black dots, diagrams four and five).</p><p>We measure incompleteness for the model set Density Combination with Equal Weights and Stochastic Volatility, (DCEW-SV). Estimates of model set incompleteness are shown in Figure <ref type="figure">6</ref>. We compute the incompleteness contribution of each cluster as the average value of the squared posterior residuals. It is seen that n1 and t2 have the higher average incompleteness and n2 and t1 have lower average incompleteness. This diagnostic information confirms that clusters n1 and t2 give lower predictive accuracy. <ref type="foot" target="#foot_5">6</ref>We also plot the average estimate of the overall model incompleteness. This estimate has a 7% increase in September 2008, which is due to the default of Lehman Brothers and related following events. Interestingly, the volatility does not reduce in 2009, a year with large positive returns opposite the large negative returns in 2008.</p><p>We compare the performance of our approach with results from five different basic models applied to the S&amp;P500 log returns: a white noise model (or a random walk for prices), often used as a main benchmark in equity premium predictibility; the Normal GARCH(1,1) and the Student-t GARCH(1,1) models described above. In order to explore the sensitivity of our results for model set incompleteness in more detail, we include the Normal GJR GARCH(1,1) model in <ref type="bibr" target="#b42">Glosten et al. (1993)</ref> that includes leverage effects in the model set. This model is a richer model than the standard GARCH and should fit the data better. In fact, leverage effect is considered among the stylised facts of financial returns and the added feature may become relevant in our analysis. Finally, since it might difficult to know which of the GARCH models perform better ex-ante, we apply also an equal weight combination of the three GARCH models, labeled EW-GARCH.</p><p>Out-of-sample predicting result are presented in Table <ref type="table">1</ref>. The first three columns deal with location and shape features of the predictive densities. It is seen that our combination schemes produce the lowest Root Mean Squared Prediction Error (RMSPE) and Cumulative Rank Probability Score (CRPS) and the highest Log Score (LS), see also Section C in the Supplementary Material for more details.</p><p>The results indicate that the combination schemes are statistically superior to the no-predictability WN benchmark. The Normal GARCH(1,1) model, the Student-t GARCH(1,1) model and the Normal GJR GARCH(1,1) model fitted on the index also provide more accurate density predictions than the WN, but not on point predicting. For all three score criteria, the statistics given by the three individual models are inferior to our combination schemes.</p><p>We consider two statistics that refer to left and right tails of the predictive densities. These refer to weighted averages of the <ref type="bibr" target="#b43">Gneiting and Raftery (2007)</ref> quantile scores that are based on quantile predictions that correspond to the predictive densities from the different models. In the Supplementary Material it is shown that avQS-T emphasizes both tails and avQS-L the left tail of the predictive density relative to the realization 1-step ahead. To study how the models perform in the left tail predictions over time, we consider the cumulative sum of avQS-L and the most accurate model at observation t produces the lowest cumavQS-L i,h,t . The fourth and fifth columns of Table <ref type="table">1</ref> show results for tail evaluation. Our schemes provides the lowest avQS-T and avQS-L statistics, confirming the accuracy of the method in the tails of the distribution. See Figure <ref type="figure">D</ref>.1 in the Supplementary Material for a comparison of performance over time.</p><p>As economic measure, we apply a Value-at-Risk (VaR) based measure, see <ref type="bibr" target="#b53">Jorion (2006)</ref>. We compare the accuracy of our models in terms of violations, that is the number of times that negative returns exceed the VaR predictions at time t, with the implication that actual losses on a portfolio are worse than had been predicted. Higher accuracy results in numbers of violation close to nominal value of 1%. Moreover, to have a gauge of the severity of the violations we compute the total losses by summing the returns over the days of violation for each model. When looking to VaR violations, reported in the final column of Table <ref type="table">1</ref>, the number for all individual models is high and above 1%, with the WN higher than 3%. The dramatic events in our sample, including the Lehman default and all the other features of the US financial crisis provide an explanation for the result. It is important to note that the two combination schemes provide the best statistics, with violations very close to the 1% theoretical value. The property of our combination schemes to assign higher weights to the fat tail cluster t1 helps to model more accurately the lower tail of the index returns and covers more adequately risks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Treasury Bill predicting</head><p>We consider the extended <ref type="bibr" target="#b77">Stock and Watson (2005)</ref> dataset, which includes 142 series sampled at a quarterly frequency from 1959Q1 to 2011Q2. A graphical description of the data is given in Figure <ref type="figure">D</ref>.2 in the Supplementary Material. The dataset includes only revised series and not vintages of real-time data. <ref type="foot" target="#foot_6">7</ref> In order to deal with stationary series, we apply the series-specific transformation suggested in <ref type="bibr" target="#b77">Stock and Watson (2005)</ref>. We also re-scale the series to have zero mean.</p><p>We split the sample size 1959Q3-2011Q2 in two periods. The initial 102 observations from 1959Q3-1984Q1 are used as initial in-sample period; the remaining 106 observations from 1985Q1-2011Q2 are used as an out-of-sample period. We evaluate combined predictive densities of the 3-month Treasury Bill rate for h = 1, . . . , 5 step-ahead horizons using the large database.<ref type="foot" target="#foot_7">foot_7</ref> For all variables we apply a Gaussian autoregressive model of the first order AR(1) and a Dynamic Factor Model (DFM) with 5 factors described in <ref type="bibr" target="#b78">Stock and Watson (2012)</ref>.<ref type="foot" target="#foot_8">foot_8</ref> </p><p>Let y t be the variable of interest to be predicted (i.e., Treasury Bill rates), the AR(1) model</p><formula xml:id="formula_68">y it = α i + β i y it-1 + ζ it , ζ it ∼ N (0, σ 2 i ) (43)</formula><p>is estimated following a Bayesian inference approach and assuming a diffuse informative Normal-Inverse-Gamma prior with null means and variances equal to 100 for the independent prior distributions of α i and β. For the variance σ 2 i we use an Inverse-Gamma with degrees of freedom equal to the number of lags (one) and intercept, that is two. The AR(1) models are estimated recursively and h-step ahead (Bayesian) Student-t predictive densities are constructed using a direct approach extending each vintage with the new available observation; see for example <ref type="bibr" target="#b56">Koop (2003)</ref> for the exact formula of the mean, standard deviation and degrees of freedom.</p><p>We also consider the DFM with 5 factors described in Stock and Watson (2012) as another benchmark. More precisely:</p><formula xml:id="formula_69">ỹt = Λf t + ε f t , Φ(L)f t = η f t (44)</formula><p>where the y t is the variable of interest, f t = (f 1,t , . . . , f r,t ) ′ is an r vector of latent factors (in our case r = 5 or 7), Λ is a 1 × r matrix of factors loadings, Φ(L) is an (r × r) matrix lag polynomial of order 2 , ε f t is a (1 × 1) vector of idiosyncratic components and η rt is an r vector of innovations. In this formulation the term Λf t is the common component of y t . Bayesian estimation of the model described in equation ( <ref type="formula">44</ref>) is carried out using Gibbs Sampling given in <ref type="bibr" target="#b57">Koop and Korobilis (2009)</ref>. The clusters of predictive densities are identified by the dynamic clustering process, where our predictive densities are grouped in clusters depending on the persistence in the series. We are interested in the interpretation and behaviour of the clusters over the full sample and, for convenience, we impose that the cluster allocation of each model is fixed over the predicting vintages.<ref type="foot" target="#foot_9">foot_9</ref> Note that in the finance exercise this assumption is relaxed. We assume alternatively 5 and 7 clusters.<ref type="foot" target="#foot_10">foot_10</ref> In the grouping, we identify two clusters related to real activities; one cluster related to prices; and one cluster related to financial variables. The other clusters contains the remaining series. A detailed description of the 5 and 7 clusters is provided in Tables D.2-D.3 in the Supplementary Material.</p><p>As described in Section 2, we consider two alternative strategies for the specification of the weights b ijt : equal weights and score recursive weights, where in the second case we fix the log scores for the various horizons h. We note that we keep the volatility of the incompleteness term constant, for convenience. In the present analysis, the number of components matters more.</p><p>We construct dynamic combination models (D) with equal (EW) and log-score driven (LS) cluster weights, and with 5 and 7 clusters. We obtain four models: DCEW5, DCLS5, DCEW7 and DCLS7. For the variance-covariance matrix of the combination weights we use a very informative prior.</p><p>In Figure <ref type="figure">8</ref> shows the time patterns of the weights based on the DCLS7 scheme. The 6-th cluster has a large weight, but several other clusters have also large positive weights, namely, clusters 2, 4, and 5 while clusters 1 and 7 do not receive much weight. Apparently, variables such as Exports, Imports and GDP deflator included in the 6-th cluster play an important role in predicting interest rate. Also note that cluster 3, which includes the 3-month Treasury Bills, has the lowest weight in Figure <ref type="figure">8</ref>. This confirms evidence in <ref type="bibr" target="#b63">Ludvigson and Ng (2009)</ref> that relying only on the term structure information for predicting yields gives less accurate results than applying a large database including real and inflation factors.</p><p>Figure <ref type="figure" target="#fig_6">9</ref> shows the De Finetti's diagram of the weights within each cluster, which are driven by the common factors z jt , j = 1, . . . , 7 and the coefficients b ijt . The ternary diagrams indicate there are large differences across clusters: for clusters 2, 4, 5 and 6, only a few models have most of the weights, which we are able to identify as models 20, 1, 22 and 4. Also, within these clusters there are more heterogeneity over time and models, indicating that individual model performances change over time even if overall information given by each cluster is stable. As In each plot the estimated ternaries (z it , z jt , z -(ij)t ), j &gt; i and t = 1, . . . , 106 (red dots) for each cluster (different plots) where we choose the weight of the following reference models <ref type="bibr">21,</ref><ref type="bibr">20,</ref><ref type="bibr">10,</ref><ref type="bibr">1,</ref><ref type="bibr">22,</ref><ref type="bibr">4,</ref><ref type="bibr">19</ref>  indicate that differences in accuracy versus the AR benchmark are credibly different from zero at 5%, and 1%, respectively, using the Diebold-Mariano t-statistic for equal loss. The underlying p-values are based on t-statistics computed with a serial correlation-robust variance, using the pre-whitened quadratic spectral estimator of <ref type="bibr" target="#b8">Andrews and Monahan (1992)</ref>.</p><p>regards to the other clusters (1, 3 and 7) similar weights occur across models since the dots in the diagrams concentrate around the point (1/n j , 1/n j , (n j -2)/n j ).</p><p>Table <ref type="table" target="#tab_4">2</ref> reports the results to predict 3-month Treasury Bills for three different horizons and using three different scoring measures. For all variables, horizons and scoring measures our methodology provides more accurate predictions than the AR(1) benchmark and the DFM benchmark. The DFM model provides more accurate predictions than the AR(1) when focusing on the mean square prediction error and CRPS metrics, but not for LS evaluation. On the contrary, several of our combination schemes outperform this benchmark for all three metrics and horizons. The predictive gains are similar across different horizons, that is up to 10% relative to the AR benchmark in terms of RMSPE metrics and even larger for the log score and CRPS measures. <ref type="foot" target="#foot_11">12</ref> The combination that provides the largest gain is the one based on seven clusters and log score weights within clusters (DCLS7), resulting in the best statistics 8 times out of 9 cases in the Table . In most of the cases, the difference is statistically credible at the 1% level. Fan charts in Figure S.4 of the Supplementary Material show that the predictions are accurate even at our longest horizon, h = 5. Note that the combination based on 5 clusters and equal weights yields also accurate predictions.</p><p>We conclude that combining joint model predictions using multiple clusters with cluster-based weights provides substantial predictive gains, confirming recent evidence that machine learning type of tools are useful for predicting financial markets, see for example <ref type="bibr" target="#b49">Gu et al. (2020)</ref> and <ref type="bibr" target="#b13">Bianchi et al. (2020)</ref>. Of course, additional gains may be obtained by playing with a more detailed cluster grouping and different performance scoring rules for weights associated with models inside a cluster. This is left as a topic for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We proposed a Bayesian semi-parametric model to construct a time-varying weighted combination of a large set of predictive densities. The dimensionality reduction is based on clustering the set of predictive densities in mutually exclusive subsets. This modelling strategy reduces the dimension of the latent spaces and leads to a more parsimonious combination model. We provide several theoretical properties of the weights and propose an efficient procedure for posterior approximation of the latent weights.</p><p>We applied the methodology to large financial data sets and find substantial gains in point and density predicting for stock returns and Treasury yields. In a stock market application, we show, using our methodology, how 3712 predictive densities based on 1856 US individual stocks replicate the daily S&amp;P500 index return and predict accurately the economic value of tail events like Value-at-Risk. In a bond market exercise, we show that combining models with clusterbased weights increases predictive accuracy substantially; weights across clusters are very stable over time and horizons. Furthermore, weights within clusters are very volatile, indicating that individual model performances are very unstable, strengthening the use of density combinations.</p><p>The line of research presented in this paper can be extended in several directions. For example, the importance of the model clusters change following the variable to predict. This calls for the use of multivariate combination models. Some clusters have a substantial weight while others have only little weight and such a pattern may vary over time. This may lead to the construction of alternative models with asymmetric distributions in the combination weights with the aim to get more accurate out-of-sample predicting and to improve policy analysis. We notice also potential fruitful applications of our approach to dynamic portfolio allocation and to study the effects of the COVID-19 pandemic on financial predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proofs of the results in the paper</head><p>Proof of Proposition 2.1 Let a = (a 1t , . . . , a nt ) then our probability density combination model writes as</p><formula xml:id="formula_70">f (y t |I t-1 , M, σ 2 t ) = R n ×R n G(y t )H A 0t (da) (A.1) = R n ×R n n i=1 w it δ(ỹ it + ε it -y t ) n i=1 f (ỹ it |I i,t-1 , M i )g(ε it |σ 2 it )dỹ it dε it (A.2) n i=1 w it R R δ(ỹ it + ε it -y t )g(ε it |σ 2 it )dε it f (ỹ it |I i,t-1 , M i )dỹ it (A.3)</formula><p>where last line follows from Fubini's theorem and the conditional independence assumption for the atoms. Solving the integral with respect to ε it one obtains</p><formula xml:id="formula_71">f (y t |I t-1 , M, σ 2 t ) = n i=1 w it R g(y t -ỹit |σ 2 it )f (ỹ it |I i,t-1 , M i )dỹ it (A.4)</formula><p>which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof of Proposition 2.2</head><p>The Jacobian of the inverse transformation v = log(u) is the diagonal matrix J(v) = diag((u -1 1 , . . . , u -1 m ) ′ ) where diag(a) is the diagonal matrix with the elements of the vector a on the main diagonal. The probability density function of u is</p><formula xml:id="formula_72">p(u|µ, Υ) = |(2π)Υ| -1/2 |J(v)| exp (log(u) -µ) ′ Υ -1 (log(u) -µ) = -1/2   m j=1 u j   -1 exp - 1 2 (log(u) -µ) ′ Υ -1 (log(u) -µ) (A.5) which is the pdf of the m-variate log-normal distribution Λ m (µ, Υ). The transformation z = alr -1 (v) = C m ((exp(v -m ), 1) ′ ) implies z m = 1 - ι ′ m-1 z -m and z -m = u -m /(1 + ι ′ m-1 u -m ) (A.6)</formula><p>where</p><formula xml:id="formula_73">u -m = exp(v -m -v m ι m-1 ) = exp(D m v). By the properties of the log- normal distribution it follows that u -m ∼ Λ m-1 (D m µ, D m ΥD ′ m ). From Eq. A.6 one obtains z -m = (I m-1 -z -m ι m-1 )u m-1 and the inverse transformation u -m = (I m -z -m ι ′ m-1 ) -1 z -m = 1 1 + ι ′ m-1 z -m z -m (A.7)</formula><p>where the last equality follows from the Sherman-Morrison-Woodbury's formula</p><formula xml:id="formula_74">(A + xy ′ ) -1 = A -1 -A -1 xy ′ A -1 (1 + y ′ A -1 x) -1 (e.</formula><p>g., see <ref type="bibr">Gentle, 2007, p. 221)</ref>. The Jacobian of this transformation is</p><formula xml:id="formula_75">Ju -m = 1 d I m-1 - 1 d 2 ι m-1 z ′ -m (A.8) where d = 1 + ι ′ m-1 z -m . By applying the determinant rule |A + xy ′ | = |A|(1 + y ′ A -1 x) one obtains |Ju -m | = 1 d m-1 (1 - 1 d z ′ -m ι m-1 ) = 1 d m-1 1 + ι ′ m-1 z -m -ι ′ m-1 z -m d = d -m (A.9)</formula><p>and the density function where c = (1 + ι ′ m-1 u -m ) and we used</p><formula xml:id="formula_76">p(z|D m µ, D m ΥD ′ m ) = |(2π)D m ΥD m | -1/2 |Ju -m |   m-1 j=1 z j d   -1 exp log(z -m c) -D m µ) ′ (D m ΥD ′ m ) -1 (log(z -m c) -D m µ) = |(2π)D m ΥD m | -1/2   m j=1 z j   -1 exp log(z -m /z m ) -D m µ) ′ (D m ΥD ′ m ) -1 (log(z -m /z m ) -D m µ) (A.10) (R m-1 , N m-1 ) (R m-1 + , Λ m-1 ) (S m , L m ) exp</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C m alr</head><formula xml:id="formula_77">z m = 1 -ι ′ m-1 z -m = 1 -ι ′ m-1 u -m /(1 + ι ′ m-1 u -m ) which gives (1 + ι ′ m-1 u -m ) -1 = z m .</formula><p>In this proof we show that the logistic-normal can be obtained by transforming log-normal variables, an alternative proof can be obtained by considering the Jacobian of the inverse alr(•) transformation (see <ref type="bibr">Fig. A.1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof of Proposition 2.3</head><p>The weights w i can be written as <ref type="bibr">.11)</ref> where a i = (a i1 , . . . , a id-1 ) and u i = a i alr(z), i = 1, . . . , c. By applying the definition of alr -1 (•) one obtains w = (w 1 , . . . , w c ) ′ = arl -1 (u * ) and w c+1 = 1w 1 -. . .w c , where u * = (u ′ , κ) ′ with κ ∈ R, u = (u 1 , . . . , u c ) ′ = A alr(z). From the properties of logistic-normal it follows alr(z) ∼ N d-1 (µ, Υ) and A alr(z) ∼ N c (Aµ, AΥA ′ ). In conclusion w ∼ L c+1 (Aµ, AΥA ′ ) Proof of Corollary 2.1 From the definition of perturbation operator ⊕ and the properties of the log-normal distribution given in Proposition 2.2 it follows that the log-ratio process alr(z t ) = alr(z t-1 )+alr(η t ) follows N m-1 (alr(z t-1 ), Υ) and the random composition process z t = alr -1 (alr(z t )) ∼ L m (alr(z t-1 ), D m ΥD ′ m ). Then by setting w = w t , A = A t and z = z t in Proposition 2.3 one obtains the result.</p><formula xml:id="formula_78">w i = exp( d-1 j=1 a ij log(z j /z d ))   1 + c i=1 exp( d-1 j=1 a ij log(z j /z d ))   -1 = exp(u i ) 1 + c i=1 exp(u i ) -1 (A</formula><p>Proof of Remark 1 Without loss of generality, we assume that the n-n t elements in the cluster m correspond to the last nn t elements of ỹt . Under this assumption the projection matrix can be partitioned as follows</p><formula xml:id="formula_79">Ãt = A * t 0 nt O (n-nt)×(m-1) a t</formula><p>where 0 n and O n×m denote the null vector and matrix and a t is a n-n t dimensional vector such that a ′ t ι n-nt = 1. Matrix A t is thus equal to (A * ′ t , O ′ n-nt ) ′ and the scale matrix of the logistic-normal distribution is thus</p><formula xml:id="formula_80">(R d-1 , N d-1 ) (R m-1 , N m-1 ) (S m , L m ) (S d , L d ) A alr -1 φ A alr -1 x t v t z t w * t A alr -1 φ A alr</formula><formula xml:id="formula_81">A t ΥA ′ t = A * t Υ * A * ′ t O nt×(n-nt) O (n-nt)×(nt) O (n-nt)×(n-nt)</formula><p>where Υ * is the matrix given by the first n t rows and columns of Υ.</p><p>Proof of Corollary 2.2 For the easy of notation, in the following we assume d = n t +1 and A = A * t where A * t is the projection matrix defined in the proof of Remark 1. In the first part of the proof we show that by applying a chain of transformations, a Gaussian process in R m has a logistic-normal process representation on the simplex S d (dashed lines in Figure A.2). The process x t = Av t has a Gaussian distribution, x t ∼ N d-1 (Av t-1 , AΥA ′ ), and the transformed process w * t = alr -1 ((x t , 1)) is in S d and follows L d (Av t-1 , AΥA ′ ). In the second part we show that our compositional model in S d has an equivalent representation in a subspace of R d-1 (solid lines in Figure A.2). By Propositions 2.2 z t is in S m and follows L m (v t-1 , Υ) with v t-1 = alr(z t-1 ). By Corollary 2.1 the process w * t = φ A (z t ) is in S d and follows L d (Av t-1 , AΥ Ã′ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Parallel dynamic clustering</head><p>The parallel evaluation of the dynamic clustering process can be described as follows, see also <ref type="bibr" target="#b35">Favirar et al. (2008)</ref> and the reference therein. Assume, for simplicity, the n data points can be split in P subsets, N p = {(p-1)n p +1, . . . , pn p }, p = 1 . . . , P , with the equal number of elements n P . P is chosen according to the number of available cores.</p><p>1. Assign P sets of n P data points to different cores.</p><p>2. For each core p, p = 1, . . . , P 2a. find j i = arg min{j = 1, . . . , m| ||ψ it -c jt ||}, for each observation i ∈ N p assigned to the core p.</p><p>2.b find the local centroid updates m p,jt+1 , j = 1, . . . , m 3. Find the global centroid updates m jt+1 = 1/P P p=1 m p,jt+1 , j = 1, . . . , m 4. Update the centroids as in Eq. ( <ref type="formula" target="#formula_32">19</ref>).</p><p>The dynamic clustering is parallel in point 2) and 3) and this can be used in the GPU context as we do in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Predictive evaluation</head><p>To measure the predictive ability of our methodology, we consider several statistics for point and density predctions previously proposed in the literature. Assume we have n different approaches to predict the variable y.</p><p>Point predictions. We compare point predictions in terms of Root Mean Square Prediction Errors (RMSPE)</p><formula xml:id="formula_82">RMSP E i,h = 1 t * t t=t e i,t+h ,</formula><p>where t * = tt + h, t and t denote the beginning and end of the evaluation period, and e i,t+h is the h-step ahead square prediction error of model i.</p><p>Density predictions. The complete predictive densities are evaluated as follows.</p><p>Let f (y t+h |I it ) be a candidate density obtained from the approach i. The Logarithmic Score (LS) is then given as:</p><formula xml:id="formula_83">LS i,h = - 1 t * t t=t ln f (y t+h |I it ) (C.14)</formula><p>for all i and choose the model for which this score is minimal, or, as we report in our tables and use in the learning strategies, its opposite is maximal. We also evaluate density predictions based on the continuous rank probability score (CRPS); see, for example, <ref type="bibr" target="#b43">Gneiting and Raftery (2007)</ref>, <ref type="bibr" target="#b45">Gneiting and Ranjan (2013)</ref>, <ref type="bibr" target="#b47">Groen et al. (2013)</ref> and <ref type="bibr" target="#b72">Ravazzolo and Vahey (2014)</ref>. The CRPS for the model i measures the average absolute distance between the empirical cumulative distribution function (CDF) of y t+h , which is simply a step function in y t+h , and the empirical CDF that is associated with model i's predictive density:</p><formula xml:id="formula_84">CRPS i,t+h = +∞ -∞ F (z|I it ) -I [y t+h ,+∞) (z) 2 dz (C.15) = E t |ỹ i,t+h -y t+h | - 1 2 E t |ỹ * i,t+h -ỹ′ i,t+h |,</formula><p>where F (•|I it ) is the CDF from the predictive density f (y t+h |I it ) of model i and ỹ * i,t+h and ỹ′ i,t+h are independent random variables with common sampling density equal to the posterior predictive density f (y t+h |I it ). We report the sample average CRPS:</p><formula xml:id="formula_85">CRPS i,h = - 1 t * t t=t CRPS i,t+h . (C.16)</formula><p>Smaller CRPS values imply higher precisions and, as for the log score, we report the average CRPS i,h for each model i in all tables.</p><p>Tail predictions. Given that our approach produces complete predictive densities for the variable of interest, it is particularly suitable to compute tail events. We consider two statistics and an economic measure for tail events. We compute weighted averages of <ref type="bibr" target="#b43">Gneiting and Raftery (2007)</ref> quantile scores that are based on quantile predictions that correspond to the predictive densities from the different models, i.e., QS(α, i, t) = I{y t+1 ≦ F -1 (α, i)}α F -1 (α|I it )y t+1 , (C.17) with F -1 (α|I it ) is the 1-step ahead quantile prediction using prediction i for level α ∈ (0, 1). It can be shown that integrating (C.17) over α ∈ (0, 1) will result in the CRPS measure (C.15), see <ref type="bibr" target="#b44">Gneiting and Ranjan (2011)</ref>. <ref type="bibr" target="#b44">Gneiting and Ranjan (2011)</ref>, <ref type="bibr" target="#b47">Groen et al. (2013)</ref> and <ref type="bibr" target="#b61">Lerch et al. (2017)</ref> propose to integrate weighted versions of (C.17) over α, with these weights being fixed functions of α chosen such to emphasize in the predictive evaluation a certain area of the underlying predictive density. We use a discrete approximation to this integration and use weights that emphasize both tail and the left tail of the predictive density:</p><formula xml:id="formula_86">avQS-T i = 1 T -t 0 -1 T -1 s=t 0 -1   1 99 99 j=1 (2α j -1) 2 QS(α j , i, s + 1)   avQS-L i,h = 1 T -t 0 -1 T -1 s=t 0 -1   1 99 99 j=1 (1 -α j ) 2 QS(α j , i, s + 1)   (C.18)</formula><p>where α j = j/100 and QS(α j , i, s + 1) is defined in (C.17) for a quantile j. In (C.18), avQS-T emphasizes both tails and avQS-L the left tail of the predictive density relative to the realization 1-step ahead. To study how the models perform in the left tail prediction over time, we consider the cumulative sum of avQS-L:</p><formula xml:id="formula_87">cumavQS-L i,h,t = t s=t 0 -1 avQS-L i,h,s (C.19)</formula><p>The most accurate model at observation t produces the lowest cumavQS-L i,h,t . Finally, following <ref type="bibr" target="#b26">Clark and Ravazzolo (2015)</ref>, we apply the Diebold and Mariano (1995) t-tests for equality of the average loss (with loss defined as squared error, log score, or CRPS). In our tables presented below, differences in accuracy that are statistically different from zero are denoted by one, two, or three asterisks, corresponding to significance levels of 10%, 5%, and 1%, respectively. The underlying p-values are based on t-statistics computed with a serial correlationrobust variance, using the pre-whitened quadratic spectral estimator of <ref type="bibr" target="#b8">Andrews and Monahan (1992)</ref>. Monte Carlo evidence in <ref type="bibr" target="#b25">Clark and McCracken (2015)</ref> and <ref type="bibr" target="#b24">Clark and McCracken (2011)</ref> indicates that, with nested models, the Diebold-Mariano test compared against normal critical values can be viewed as a somewhat conservative (conservative in the sense of tending to have size modestly below nominal size) test for equal accuracy in the finite sample. Since the AR benchmark is always one of the model in the combination schemes, we treat each combination as nesting the baseline, and we report p-values based on one-sided tests, taking the AR as the null and the combination scheme in question as the alternative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional details on empirical results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Additional details on the S&amp;P500 application</head><p>Table <ref type="table">D</ref>.1 reports the cross-section average statistics, together with statistics for the S&amp;P500. Some series have much lower average returns than the index and volatility higher than the index up to 400 times. Heterogeneity in skewness is also very evident with the series with lowest skewness equal to -42.5 and the one with highest skewness equal to 27.3 compared to a value equal to -0.18 for the index. Finally, maximum kurtosis is 200 times higher than the index value. The inclusion in our sample of the crisis period explains such differences, with some stocks that realized enormously negative returns in 2008 and impressive positive returns in   <ref type="bibr">(vertical axis)</ref>. The vertical red lines indicate the different clusters. One can see for example that the series in the 2nd and 4th cluster (of 5) are more persistent then the series in the clusters 1, 3 and 5 (see also <ref type="bibr">Fig. D.3,</ref><ref type="bibr">bottom left)</ref>. Series in cluster 1, 2 and 4 are less volatile than series in the cluster 3 and 5. This information is also summarised by the mean value of the parameter estimates for the series that belong to the same cluster. See the values in Table <ref type="table">D</ref>.4. Looking at the composition of the predictor groups (see also Tables D.2-D.3), we find for the five clusters that:</p><p>1. The first cluster comprises capacity utilisation, employment variables, housing (building permits and new ownership started) and manufacturing variables (new orders, supplier deliveries index, inventories).</p><p>2. The second cluster contains exports, a large numbers of price indexes (e.g. prices indexes for personal consumption expenditures, and for gross domestic product) some money market variables (e.g. M1 and M2).</p><p>3. The third cluster includes real gross domestic product, consumption and consumption of non-durables, some industrial production indexes, and some financial market variables (e.g., S&amp;P industrial, corporate bonds and USD -GBP exchange rate). 4. The fourth cluster includes imports, some price indexes and financials such as government debt (3-and 6-months T-bills and 5-and 10-years T-bonds), stocks and exchange rates.</p><p>5. The fifth cluster mainly includes investments, industrial production indexes (total and many sector indexes), and employment.</p><p>Evidence is similar for the seven clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Computing time</head><p>In this section we compare the computational speed of CPU with GPU in the implementation of our combination algorithm for both the financial and macro application. Whether CPU computing is standard in econometrics, GPU approach to computing has been received large attention in economics only recently. See, for example, Aldrich (2014) for a review, <ref type="bibr" target="#b40">Geweke and Durham (2012)</ref> and <ref type="bibr" target="#b60">Lee et al. (2010)</ref> for applications to Bayesian inference and <ref type="bibr" target="#b7">Aldrich et al. (2011)</ref>, <ref type="bibr" target="#b67">Morozov and Mathur (2012)</ref> and <ref type="bibr" target="#b30">Dziubinski and Grassi (2013)</ref> for solving DSGE models.</p><p>The CPU and the GPU versions of the computer program are written in MATLAB, as described in <ref type="bibr" target="#b20">Casarin et al. (2015)</ref>. In the CPU setting, our test machine is a server with two Intel Xeon CPU E5-2667 v2 processors and a total of 32 core. In the first GPU setting, our test machine is a NVIDIA Tesla K40c GPU. The Tesla K40c card is with 12GB memory and 2880 cores and it is installed in the i (second column) and β i and σ 2 i (last column). In each plot the red dots represent the cluster means. We assume alternatively 5 (left) and 7 (right) clusters.</p><p>CPU server. In the second GPU setting, our test machine is a NVIDIA GeForce GTX 660 GPU card, which is a middle-level video card, with a total of 960 cores. The test machine is a desktop Windows 8 machine, has 16 GB of Ram and only requires a MATLAB parallel toolbox license.</p><p>We compare two sets of combination experiments, the density combination based on 4 clusters with equal weights within clusters and time-varying volatility, DCEW-SV, see Section 4.1, and the density combination based on 7 clusters with recursive log score weights within clusters, DCLS7, see Section D.2, for an increasing number of particles N. In both sets of experiments we calculated, in seconds, the overall average execution time reported in Table <ref type="table">D</ref>.5.</p><p>As the table shows, the CPU implementation is slower then the first GPU set-up in all cases. The NVIDIA Tesla K40c GPU provides gains in the order of magnitude from 2 to 4 times than the CPU. Very interestingly, even the second GPU set-up, which can be installed in a desktop machine, provides execution times comparable to the CPU in the financial applications and large gains in the macro applications. Therefore, the GPU environment seems the preferred one for our density combination problems and when the number of predictive density becomes very large a GPU server card gives the highest gains.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Proposition 2.3 (Class-preserving property). Let A a (c × d -1) matrix and z ∼ L d (µ, Υ) a logistic-normal vector. Define the following transform w = φ A (z) from S d to S c , with d &lt; c,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Top: distribution L 2 (µ, υ 2 ) for different values of υ 2 (left) and µ (right). Middle: values of the random variables w 1 and w 2 as functions of the random variable z 1 for different level of positive (left) and negative (right) covariance υ 2 a. Bottom: representation of the relationships in the De Finetti's diagrams.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Directed acyclic graph of state space model. It exhibits the hierarchical structure of the observations on the endogenous variable y t and the predicted variables ỹit (rectangles, solid line), the latent variables s t and z t (ellipses) and the link functions φ At , Ξ t and B t (rectangles, dashed line). The directed arrows show the causal dependence structure of the model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: De Finetti's diagram (left)  and the time series plot (middle) of the ternary (z 1,t , z 2,t , z 3,t ) and observations y t (right) with point predictions from the five predictors (horizontal dashed lines). In the panels, colors indicate different sub-samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: The figures present the average variance of the predictions from the two clusters for the Normal GARCH(1,1) models based on low (cluster 1, solid black line) and high (cluster 2, dashed black line) volatility in the left panel; and the average degree of freedom of the predictions from the two clusters for the Student-t GARCH(1,1) models based on low (cluster 3, solid red line) and high (cluster 4, dashed red line) degrees of freedom in the right panel. The degrees of freedom are bounded to 30.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: De Finetti's diagram for the pairwise subcomposition comparison between model weights.In each plot the trajectory of the ternary (z it , z jt , z -(ij)t ), j &gt; i (blue line), the starting point (red dot), the ending point (black dot) and the equal weight composition (square).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Figure9: De Finetti's diagrams for the pairwise comparison between model weights at horizon h = 1. In each plot the estimated ternaries (z it , z jt , z -(ij)t ), j &gt; i and t = 1, . . . , 106 (red dots) for each cluster (different plots) where we choose the weight of the following reference models21, 20, 10, 1, 22, 4, 19  for the clusters 1, . . . , 7, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure A. 1 :</head><label>1</label><figDesc>Figure A.1: Relationship between the space of real vector R m-1 endowed with the normal distribution, the positive real R m-1 + endowed with the log-normal distribution and the simplex S m endowed with the logistic-normal distribution L m .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A. 2 :</head><label>2</label><figDesc>Figure A.2: Relationships between Gaussian and logistic-normal representation of the latent probability space (left) and of the latent process (left) involved in our compositional factor model. In the directed edges the arrow indicates the results of the transformation, and the edge label defines the transformation applied. Note in that in this diagram we allow for mapping onto subspaces of R n .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>The left and right columns in Fig.D.3 show the clusters of series in the parameter space. The results show substantial evidence of different time series characteristics in several groups of series. The groups are not well separated when looking at the intercept values (see Fig. D.3, first and second row). However, the groups are well separated along two directions of the parameter space, which are the one associated with the variance and the one associated with persistence parameters (Fig.D.3, last row). The differences in terms of persistence, in the different groups, is also evident from the heat maps given in Fig.D.4. Different gray levels in the two graphs show the value of the variables (horizontal axis) over time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Figure D.2: Gray area: the set of series (standardised for a better graphical representation), at the monthly frequency, of the Stock and Watson dataset. Solid line: growth rate of real GDP (seasonally adjusted) for the US. Dashed line: inflation measured as the change in the GDP deflator index (seasonally adjusted). Dotted line: yields on US government 90-day T-Bills (secondary market). Dashed-dotted: total employment growth rate for private industries (seasonally adjusted).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Figure D.3: Pairwise scatter plots of the series features: α i and β i (first column), α i and σ 2i (second column) and β i and σ 2 i (last column). In each plot the red dots represent the cluster means. We assume alternatively 5 (left) and 7 (right) clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure</head><label></label><figDesc>Figure D.4: Normal cumulative density function for the standardised series. The series are ordered by cluster label. We assume alternatively 5 (left) and 7 (right) clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>In the approximated likelihood fM (y t |s t , h t ) is an unbiased standard Monte Carlo estimator of f (y t |I i,t-1 , M i , σ 2 it ) obtained with M independent draws from the predictive distributions, i.e.</figDesc><table /><note><p><p>the product of approximated predictive likelihood functions fN (y t |y</p>1:t ) = W fM (y t |s t , h t )f (s t |z t , A t )f (h t |h t-1 , φ)f (z t |z t-1 , Υ)π N (ω t )dω t (36) R f (y t |ỹ it</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>for the clusters 1, . . . , 7, respectively. Predicting results for h = 1, 3, 5 steps ahead 3-month Treasury Bill yields. Root mean square Prediction error (PE), Logarithmic Score (LS) and the Continuous Rank Probability Score (CRPS) are reported. Bold numbers indicate the best statistic for each horizon and loss function. One or two asterisks</figDesc><table><row><cell></cell><cell></cell><cell>h=1</cell><cell></cell><cell>h=3</cell><cell></cell><cell>h=5</cell></row><row><cell></cell><cell>PE</cell><cell>LS</cell><cell>CRPS PE</cell><cell>LS</cell><cell>CRPS PE</cell><cell>LS</cell><cell>CRPS</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">3-month Treasury Bills</cell><cell></cell></row><row><cell>AR</cell><cell cols="2">0.569 -1.058</cell><cell cols="2">0.363 0.518 -1.038</cell><cell cols="2">0.343 0.545 -1.041</cell><cell>0.358</cell></row><row><cell cols="3">BDFM 0.553  *  -1.190</cell><cell cols="2">0.359 0.516 -1.092</cell><cell cols="2">0.392 0.517 -1.089</cell><cell>0.401</cell></row><row><cell cols="8">DCEW5 0.519 -0.778  *  *  0.288  *  *  0.509 -0.772  *  *  0.283 0.525 -0.791  *  *  0.292  *</cell></row><row><cell cols="3">DCLS5 0.740 -1.254</cell><cell cols="2">0.448 0.532 -1.210</cell><cell cols="2">0.381 0.584 -1.286</cell><cell>0.424</cell></row><row><cell cols="8">DCEW7 0.525 -0.783  *  *  0.289  *  0.514 -0.768  *  *  0.284  *  0.522 -0.786  *  *  0.289  *</cell></row><row><cell cols="8">DCLS7 0.512  *  *  -0.773  *  *  0.284  *  0.514 -0.770  *  *  0.284  *  0.511  *  -0.793  *  *  0.289  *</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table D.4: Cluster means for the 5 (top table) and 7 (bottom table) cluster analysis. The first column, k, indicates the cluster number given in</figDesc><table><row><cell></cell><cell></cell><cell>5 clusters</cell><cell></cell></row><row><cell>k</cell><cell>α</cell><cell>β</cell><cell>σ 2</cell></row><row><cell cols="4">1 0.049 0.752 0.270</cell></row><row><cell cols="4">2 0.021 -0.074 0.390</cell></row><row><cell cols="4">3 0.124 0.157 1.260</cell></row><row><cell cols="4">4 0.054 -0.338 1.335</cell></row><row><cell cols="4">5 0.100 0.466 0.811</cell></row><row><cell></cell><cell></cell><cell>7 clusters</cell><cell></cell></row><row><cell>k</cell><cell>α</cell><cell>β</cell><cell>σ 2</cell></row><row><cell cols="4">1 0.109 0.434 0.454</cell></row><row><cell cols="4">2 0.185 0.263 0.862</cell></row><row><cell cols="4">3 0.019 -0.116 0.224</cell></row><row><cell cols="4">4 0.090 -0.321 0.665</cell></row><row><cell cols="4">5 0.137 0.091 1.250</cell></row><row><cell cols="4">6 0.124 -0.437 1.297</cell></row><row><cell cols="4">7 0.026 0.817 0.197</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>TableD.5: Observed total time (in seconds) and CPU/GPU ratios for the algorithm on CPU and GPU on different machines and with different numbers of particles. The CPU is a 32 core Intel Xeon CPU E5-2667 v2 two processors and the GPU1 is a NVIDIA Tesla K40c GPU and the GPU2 is a NVIDIA GeForce GTX 660. "Ratio 1" refers to the CPU/GPU 1 ratio and "ratio 2" refers to the CPU/GPU 2 ratios. Number below 1 indicates the CPU is faster, number above one indicates that the GPU is faster.</figDesc><table><row><cell>DCEW-SV</cell><cell></cell><cell></cell><cell>DCLS7</cell><cell></cell></row><row><cell cols="2">Draws 100 500 1000</cell><cell>100</cell><cell cols="2">500 1000</cell></row><row><cell cols="2">CPU 1032 5047 10192</cell><cell cols="3">5124 25683 51108</cell></row><row><cell cols="2">GPU 1 521 2107 4397</cell><cell cols="3">1613 6307 14017</cell></row><row><cell cols="2">GPU 2 1077 5577 13541</cell><cell cols="3">2789 13895 27691</cell></row><row><cell>Ratio 1 1.98 2.39</cell><cell>2.32</cell><cell>3.18</cell><cell>4.07</cell><cell>3.65</cell></row><row><cell>Ratio 2 0.96 0.90</cell><cell>0.75</cell><cell>1.84</cell><cell>1.85</cell><cell>1.85</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We implement parallel sequential filtering and clustering to exploit the computing power of graphics processing units (GPU).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We recall that δ(ab) = 1 if a = b and zero otherwise.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>It has been suggested to make use of the information about shares outstanding in order to determine better the time behaviour of weights. We leave this as a topic for further research.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Given our flat prior, these estimates are equal to maximum likelihood estimates and also are approximate Bayes mean estimates.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Low degrees of freedom occur jointly with a large scale and high degrees of freedom occur jointly with a low scale.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>We note that one may experiment with a larger set of individual models, see for example<ref type="bibr" target="#b40">Geweke and Durham (2012)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>See Aastveit et al. (2018)  for a real-time application, with fewer series, of combined density nowcasting and the role of model set incompleteness over vintages and time.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>We restrict the presentation to results for h = 1, 3, 5 horizons.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>We note that one more experiment would be to make use of a DFM structure for the models in our combination approach and compare results with our choice of the AR model structure. Given the extensive work that we did empirically, we prefer to leave this as a topic for future research.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>We also experimented just using the initial sample and the results were similar.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10"><p>Interestingly,<ref type="bibr" target="#b78">Stock and Watson (2012)</ref> find that a factor model with 5 factors provides superior predictions to factor models with less factors. We also investigate combinations with a lower number of clusters, precisely 2 and 3 clusters, but predictions are less accurate.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11"><p>One would expect that RMSPE's are monotonic decreasing over longer horizons. This is not everywhere observed and is due to the fact of model misspecification.</p></note>
		</body>
		<back>

			<div type="funding">
<div> *   <p>The present paper should not be reported as representing the views of <rs type="person">Norges Bank</rs>. The views expressed are those of the authors and do not necessarily reflect those of <rs type="affiliation">Norges Bank</rs>. <rs type="person">Roberto Casarin</rs>'s research is supported by the <rs type="funder">Venice center of Economic and Risk Analytics</rs>. <rs type="person">Stefano Grassi</rs> gratefully acknowledges financial support from the <rs type="funder">University of Rome</rs> '<rs type="programName">Tor Vergata' under Grant "Beyond Borders</rs>" (CUP: <rs type="grantNumber">E84I20000900005</rs>). This paper is part of the research activities at the <rs type="institution">Centre for Applied Macroeconomics and Commodity Prices (CAMP)</rs> at the <rs type="funder">BI Norwegian Business School</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_NqQ5xwY">
					<idno type="grant-number">E84I20000900005</idno>
					<orgName type="program" subtype="full">Tor Vergata&apos; under Grant &quot;Beyond Borders</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Parallel implementation B.1 Parallel sequential filtering</head><p>With regard to the filtering part, we use M parallel conditional SMC filters, where each filter is conditioned on the predictor vector sequence ỹs , s = 1, . . . , t. We initialise independently the M particle sets: Φ j 0 = {ω ij 0 , γij 0 } N i=1 , j = 1, . . . , M. Each particle set Φ j 0 contains N i.i.d. random variables ω ij 0 with random weights γij 0 . We initialise the set of predictors, by generating i.i.d. samples ỹj 1 , j = 1, . . . , M, from p(ỹ 1 |y 0 ) where y 0 is an initial set of observations for the variable of interest.</p><p>Then, at the iteration t + 1 of the combination algorithm, we approximate the predictive density p(ỹ t+1 |y 1:t ) as follows</p><p>where ỹj t+1 , j = 1, . . . , M, are i.i.d. samples from the predictive densities and δ x (y) denotes the Dirac mass at x.</p><p>We assume an independent sequence of particle sets Φ j t = {ω ij 1:t , γij t } N i=1 , j = 1, . . . , M, is available at time t + 1 and that each particle set provides the approximation p N,j (ω t |y 1:t , ỹj</p><p>of the filtering density, p(ω t |y 1:t , ỹj 1:t ), conditional on the j-th predictor realisation, ỹj 1:t . Then M independent conditional SMC algorithms are used to find a new sequence of M particle sets, which include the information available from the new observation and the new predictors. Each SMC algorithm iterates, for j = 1, . . . , M, the steps given in section 3.</p><p>After collecting the results from the different particle sets, it is possible to obtain the following empirical predictive density</p><p>For horizons h &gt; 1, we apply a direct predicting approach (see <ref type="bibr" target="#b64">Marcellino et al., 2006)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2009.</head><p>D.1 shows for the time series of the full sample the cumulative avQS-L for the Student-t GARCH(1,1) model, the best ex-post GARCH model, the combination of GARCH models and DCEW model set. We note that our method requires some observations in the beginning to catch up with the other models. However, from August 2007 when stock markets start to experience large stress, it provides the most accurate tail predictions. The gap between the three models increases steadily over time and it becomes substantially larger after the collapse of Bear Stearns. With the default of the Lehman brothers, the accuracy of all three schemes reduces sharply until November/December 2008 when central banks and governments from around the World started to take actions which reduced the volatility in financial markets. Our DCEW, however, provides the lowest statistic until the end of the sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Additional details on the Treasury Bill predicting</head><p>We consider the extended <ref type="bibr" target="#b77">Stock and Watson (2005)</ref> dataset, which includes 142 series sampled at a quarterly frequency from 1959Q1 to 2011Q2. A graphical description of the data is given in Figure D.2.</p><p>For each variable we estimate a Gaussian autoregressive model of the first order, AR(1),</p><p>using the first 60 observations from each series. Then we identify the clusters of parameters by applying our clustering algorithm on the vectors, θi = ( αi , βi , σ2 i ) ′ , of least square estimates of the AR(1) parameters. A detailed description of the 5 and 7 clusters is provided in Tables D.2-D.3. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The evolution of forecast density combinations in economics</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Aastveit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ravazzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Oxford Research Encyclopedia of Economics and Finance</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Combined density nowcasting in an uncertain economic environment</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Aastveit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ravazzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business Economics &amp; Statistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="145" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The statistical analysis of compositional data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aitchinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series, Series B</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="139" to="177" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The Statistical Analysis of Compositional Data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aitchinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On criteria for measures of compositional difference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aitchinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Geology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="365" to="379" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Logistic-normal distributions: Some properties and uses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aitchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gpu computing in economics</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Aldrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Economics</title>
		<editor>
			<persName><forename type="first">L</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Schmedders</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2014">2014</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Tapping the supercomputer under your desk: Solving dynamic equilibrium models with graphics processors</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Aldrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fernández-Villaverde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Gallant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Rubio Ramırez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Dynamics and Control</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="386" to="393" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An improved heteroskedasticity and autocorrelation consistent covariance matrix estimator</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W K</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Monahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="953" to="966" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Particle markov chain monte carlo methods</title>
		<author>
			<persName><forename type="first">C</forename><surname>Andrieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Holenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series, Series B</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="269" to="342" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The pseudo-marginal approach for efficient monte carlo computations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Andrieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="697" to="725" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large Bayesian vector auto regressions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bańbura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Giannone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Reichlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Econometrics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="71" to="92" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Forecast density combinations of dynamic models and data driven portfolio strategies</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bastuerk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Borowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hoogerheide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page" from="170" to="186" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bond risk premiums with machine learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Buechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Review of Financial Studies</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Statistical interpretation of species composition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Billheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guttorp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Fagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the America Statistical Association</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1205" to="1214" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Timevarying combinations of predictive densities usif nonlinear filtering</title>
		<author>
			<persName><forename type="first">M</forename><surname>Billio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Casarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ravazzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="213" to="232" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Forecasting compositional risk allocations</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Boonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guillen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Santolino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insurance: Mathematics and Economics</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The time series analysis of compositional data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brunsdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Official Statistics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="237" to="253" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Natural selection and the De Finetti diagram</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cannings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W F</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Human Genetics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="421" to="428" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian forecasting of multinomial time series through conditionally gaussian dynamic models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cargnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">438</biblScope>
			<biblScope unit="page" from="640" to="647" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Parallel sequential Monte Carlo for efficient density combination: the DeCo Matlab toolbox</title>
		<author>
			<persName><forename type="first">R</forename><surname>Casarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ravazzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jounal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Online data processing: Comparison of Bayesian regularized particle filters</title>
		<author>
			<persName><forename type="first">R</forename><surname>Casarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Marin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="239" to="258" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Random projection methods in economics and finance</title>
		<author>
			<persName><forename type="first">R</forename><surname>Casarin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Veggente</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Essentials of Machine Learning in Finance and Accounting</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Petr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Uddin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Abedin</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge Taylor &amp; Francis</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Predicting the present with Google trends</title>
		<author>
			<persName><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Varian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economic Record</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="2" to="9" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Testing for unconditional predictive ability</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mccracken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Oxford Handbook of Economic Forecasting</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Clements</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Hendry</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Nested forecast model comparisons: a new approach to testing equal accuracy</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Mccracken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page" from="160" to="177" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The macroeconomic forecasting performance of autoregressive models with alternative specifications of time-varying volatility</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ravazzolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Econometrics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="551" to="575" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Compositional time series analysis of mortality proportions</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Iyengar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ravishanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics -Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2281" to="2291" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Comparing predictive accuracy</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">X</forename><surname>Diebold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Mariano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business &amp; Economic Stastistics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="253" to="263" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Sequential Monte Carlo Methods in Practice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gordon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Heterogeneous computing in economics: A simplified approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Dziubinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grassi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Economics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="485" to="495" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Groups of parts and their balances in compositional data analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Egozcue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pawlowskky-Glahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Geology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="795" to="828" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Isometric logratio transformations for compositional data analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Egozcue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pawlowskky-Glahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mateu-Figueras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Barcelo-Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Geology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="279" to="300" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Of quantiles and expectiles: consistent scoring functions, choquet representations and forecast rankings</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ehm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kruger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B</title>
		<imprint>
			<biblScope unit="issue">78</biblScope>
			<biblScope unit="page" from="505" to="562" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Economics in the age of big data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Einav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">346</biblScope>
			<biblScope unit="issue">6210</biblScope>
			<biblScope unit="page" from="715" to="718" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A parallel implementation of K-Means clustering on GPUs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Favirar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rebolledo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Campbell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
	<note>Proceedings of</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m">International Conference on Parallel and Distributed Processing Techniques and Applications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="14" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the interpretation of orthonormal coordinates for compositional data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fiŝerová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Geosciences</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="455" to="468" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Matrix Algebra: Theory, computations, and applications in statistics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Gentle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>1 edition</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Variable selection via gibbs sampling</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="881" to="889" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Massively parallel sequential Monte Carlo for Bayesian inference. Working papers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Geweke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Durham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>National Bureau of Economic Research, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Smoothly mixing regressions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Geweke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page" from="252" to="290" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">On the relation between the expected value and the volatility of the nominal excess return on stocks</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Glosten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jagannathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Runkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1779" to="1801" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Strictly proper scoring rules, prediction, and estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="359" to="378" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Comparing density forecasts using threshold and quantile weighted scoring rules</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business and Economic Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="411" to="422" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Combining predictive distributions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1747" to="1782" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Extracting information from mega-panels and highfrequency data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Neerlandica</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="258" to="272" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Real-time inflation forecasting in a changing world</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J J</forename><surname>Groen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Paap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ravazzolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business &amp; Economic Stastistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="29" to="44" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Time series of continuous proportions</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">K</forename><surname>Grunwald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guttorp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society B</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="103" to="116" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Empirical Asset Pricing via Machine Learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Review of Financial Studies</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2223" to="2273" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adaptive mixtures of local experts</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neural Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Hierarchical mixtures of experts and the EM algorithm</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal Neural Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="181" to="214" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Convergence results for the EM approach to mixtures of experts architectures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1409" to="1431" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Value at Risk: The New Benchmark for Managing Financial Risk</title>
		<author>
			<persName><forename type="first">P</forename><surname>Jorion</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A statistical model for multiparty electoral data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="15" to="32" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Self-organizing state space model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kitagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1203" to="1215" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Koop</surname></persName>
		</author>
		<title level="m">Bayesian Econometrics</title>
		<imprint>
			<publisher>John Wiley and Sons</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bayesian multivariate time series methods for empirical macroeconomics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Korobilis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Econometrics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="267" to="358" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Large time-varying parameter VARs</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Korobilis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">177</biblScope>
			<biblScope unit="page" from="185" to="198" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Modeling compositional time series with vector autoregressive models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kynclova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Filzmoser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="303" to="314" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">On the utility of graphic cards to perform massively parallel simulation with advanced Monte Carlo methods</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Holmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="769" to="789" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Forecaster&apos;s dilemma: Extreme events and forecast evaluation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lerch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thorarinsdottir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ravazzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gneiting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="106" to="127" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Combined parameter and state estimation in simulation based filtering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sequential Monte Carlo Methods in Practice</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Doucet</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Gordon</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Macro factors in bond risk premia</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Ludvigson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Review of Financial Studies</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5027" to="5067" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A comparison of direct and iterated multistep AR methods for forecasting macroeconomic time series</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marcellino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="499" to="526" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">The additive logistic skew-normal distribution on the simplex</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mateu-Figueras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pawlowsky-Glahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Â´-</forename><surname>Barcelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vidal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="205" to="214" />
		</imprint>
		<respStmt>
			<orgName>Stochastic Environmental Research and Risk Assessment</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Dynamic bayesian predictive synthesis in time forecasting</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mcalinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="169" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Massively parallel computation using graphics processors with application to optimal experimentation in dynamic control</title>
		<author>
			<persName><forename type="first">S</forename><surname>Morozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mathur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Economics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="151" to="182" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Pawlowsky-Glahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buccianti</surname></persName>
		</author>
		<title level="m">Compositional Data Analysis: Theory and Applications</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Pawlowsky-Glahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Egozcue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tolosana-Delgado</surname></persName>
		</author>
		<title level="m">Modeling and Analysis of Compositional Data</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Bayesian inference in mixturesof-experts and hierarchical mixtures-of-experts models with an application to speech recognition</title>
		<author>
			<persName><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="953" to="960" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Time series analysis of compositional data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Quintana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian Statistics 3</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Bernardo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Degroot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Lindley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="747" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Forecast densities for economic aggregates from disaggregate ensembles</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ravazzolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Vahey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Nonlinear Dynamics and Econometrics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="367" to="381" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Monte Carlo Statistical Methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Forecasting compositional time series: A state space approach</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Ord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Mclaren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Beaumont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="502" to="512" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Forecasting inflation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Monetary Economics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="293" to="335" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Forecasting using principal components from a large number of predictors</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="1167" to="1179" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Implications of dynamic factor models for VAR analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Watson</surname></persName>
		</author>
		<idno>No. 11467</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">NBER Working Paper</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Disentangling the channels of the 2007-09 recession</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Stock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brookings Papers on Economic Activity</title>
		<editor>
			<persName><forename type="middle">J H</forename><surname>Spring</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Watson</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="368" to="381" />
			<date type="published" when="2012">2012. 2014</date>
		</imprint>
	</monogr>
	<note>Journal of Econometris</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Machine learning: New tricks for econometrics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Varian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economics Perspectives</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3" to="28" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Predicting the present with bayesian structural time series</title>
		<author>
			<persName><forename type="first">H</forename><surname>Varian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Mathematical Modelling and Numerical Optimisation</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="4" to="23" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Regression density estimation using smooth adaptive Gaussian mixtures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Villani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Giordani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page" from="155" to="173" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Time series analysis of bounded economic variables</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Wallis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Time Series Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="115" to="123" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Bayesian mixture of splines for spatially adaptive nonparametric regression</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="513" to="528" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
