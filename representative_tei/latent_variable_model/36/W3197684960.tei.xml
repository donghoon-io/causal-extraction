<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Probing Commonsense Explanation in Dialogue Response Generation</title>
				<funder ref="#_2vxRX36 #_RQHzZ2m">
					<orgName type="full">Defense Advanced Research Projects Agency</orgName>
				</funder>
				<funder ref="#_hWRksMr">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_aJPk8Gt">
					<orgName type="full">DARPA MCS program</orgName>
				</funder>
				<funder>
					<orgName type="full">INK</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pei</forename><surname>Zhou</surname></persName>
							<email>peiz@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pegah</forename><surname>Jandaghi</surname></persName>
							<email>jandaghi@isi.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hyundong</forename><surname>Cho</surname></persName>
							<email>jcho@isi.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bill</forename><forename type="middle">Yuchen</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jay</forename><surname>Pujara</surname></persName>
							<email>jpujara@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
							<email>xiangren@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Probing Commonsense Explanation in Dialogue Response Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Humans use commonsense reasoning (CSR) implicitly to produce natural and coherent responses in conversations. Aiming to close the gap between current response generation (RG) models and human communication abilities, we want to understand why RG models respond as they do by probing RG model's understanding of commonsense reasoning that elicits proper responses. We formalize the problem by framing commonsense as a latent variable in the RG task and using explanations for responses as textual form of commonsense. We collect 6k annotated explanations justifying responses from four dialogue datasets and ask humans to verify them and propose two probing settings to evaluate RG models' CSR capabilities. Probing results show that models fail to capture the logical relations between commonsense explanations and responses and fine-tuning on in-domain data and increasing model sizes do not lead to understanding of CSR for RG. We hope our study motivates more research in making RG models emulate the human reasoning process in pursuit of smooth human-AI communication 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Response generation (RG) systems, which have the basic goal of mimicking human conversation, have as of yet an unmeasured ability to understand communicative intents. In general, standard neural language models build correlative models of linguistic stimuli rather than deep understanding of humanlevel meaning <ref type="bibr" target="#b1">(Bender and Koller, 2020)</ref>. As such, there is reason to suspect that, while RG systems today have impressive performance on common metrics <ref type="bibr">(Zhang et al., 2020b;</ref><ref type="bibr" target="#b29">Roller et al., 2021)</ref>, they achieve this performance without truly understanding human communication. Commonsense reasoning (CSR), defined as "the basic level of practical knowledge and reasoning concerning everyday 1 Our code and data are on our project page: <ref type="url" target="https://sites.google.com/usc.edu/cedar">https:// sites.google.com/usc.edu/cedar</ref>. situations and events that are commonly shared among most people" <ref type="bibr" target="#b32">(Sap et al., 2020)</ref>, is critical in human communication. Specifically, CSR helps establish a common ground consisting of "mutual knowledge" between participants, which is key to smooth communication <ref type="bibr" target="#b4">(Clark and Schaefer, 1989;</ref><ref type="bibr" target="#b3">Clark and Brennan, 1991)</ref>.</p><p>For example, consider a conversation between two friends shown in Figure <ref type="figure" target="#fig_0">1</ref>. The reason the person on the right (responder) is happy is not indicated explicitly, but it is common sense that finding a buyer for the house (that the responder is likely aiming to sell) makes one happy, which explains the response "I'm so happy". Motivated by how humans communicate, we ask a main research question: do RG models understand the implicit CSR that explains why a response makes sense? This will help us analyze whether the RG models that seem to produce human-like responses really understand the reasoning process that justifies the response, which is important to build a reliable and robust dialogue system. Furthermore, understanding implicit common sense behind RG can also help make models generate more natural and coherent responses.To answer this important research question, we present our initial findings from annotating commonsense explanations in dialogues and evaluating RG models for commonsense reasoning capabilities.</p><p>We first present a probing setup for evaluating common sense in RG, called CEDAR: Common sEnse in DiAlogue Response generation. We start with formalizing CSR in RG by considering common sense as a latent variable that helps explain the observed variable "response" in the RG process -similar to how humans use common sense in communication <ref type="bibr" target="#b11">(Hilton, 1990)</ref>. To instantiate implicit common sense for probing, we use textual explanations of the response as the common sense embedded in the dialogue context. To understand whether RG models can comprehend implicit common sense, we corrupt explanations to break the logical coherence and compare model behaviors between a valid explanation and a corrupted one.</p><p>To operationalize the probing, we collect the first annotations on commonsense explanations that justify dialogue responses. Each annotation is a dialogue-specific explanation that explicitly describes what might cause the response in one of the five dimensions: event, emotion, location, possession, and attribute, inspired by human cognitive psychology <ref type="bibr" target="#b13">(Kintsch and Van Dijk, 1978)</ref>. We find through pilot studies that directly asking people to annotate result in explanations with high variation and subjectivity, to account for this, we first generate candidate explanations by adopting a large textto-text language model trained on a story explanation dataset, namely GLUCOSE <ref type="bibr" target="#b22">(Mostafazadeh et al., 2020)</ref>, under the dialogue setting. Next, we conduct a carefully designed two-stage human verification process with a qualification test and the main annotation task. We present our findings from verifying 6k generated explanations on 1,200 dialogues sampled from four public dialogue datasets.</p><p>Using the annotated explanations, we probe state-of-the-art (SOTA) RG models for two CSRrelated abilities: (i) the ability to understand whether the commonsense explanation can justify a response, and (ii) the ability to attribute logically-coherent explanations for dialogue responses. These are inspired by what showcases human understanding of common sense in conver-sational communication. Our probing setup contrasts valid explanations with corrupted version. Corruptions are generated via two methods: logical corruptions that disrupt logical coherence, and complete corruption where we disrupt the grammatical naturalness of the sentence.</p><p>We find that the models fail to understand common sense that elicits proper responses according to performance on our probing settings and some models even do not distinguish gibberish sentences. Fine-tuning on in-domain dialogues and verified explanations do not help with understanding. We also find interesting cases that show potential statistical biases in RG models. We hope our annotated explanations and probing findings encourage more studies on making RG models communicates with deep understanding of human reasoning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Formulation and Challenges</head><p>This section first introduces how we incorporate common sense as a latent variable in the RG setting. Then we specify two challenges that arise in order to examine whether RG models can comprehend common sense to arrive at responses similarly as humans do. Lastly, we present our solutions to the challenges by instantiating common sense as textual explanation and proposing two probing settings to evaluate if models reason about common sense when generating responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Common Sense in Response Generation</head><p>Preliminaries We consider the classic dialogue response generation (RG) setup <ref type="bibr" target="#b37">(Weizenbaum, 1966;</ref><ref type="bibr" target="#b28">Ritter et al., 2011;</ref><ref type="bibr" target="#b34">Sordoni et al., 2015)</ref>: given a dialogue history H, generate an appropriate response R. Most state-of-the-art (SOTA) neural RG models generate a response given a dialogue history as a conditional language modeling problem. Specifically, given a history (H) consisting of a sequence of dialogue turns from the dialogue history x 1 , x 2 , ..., x n (each containing a sequence of tokens) and a response (R) sentence y comprised of a sequence of tokens y 1 , y 2 , ..., y m , RG models aim to learn the conditional probability distribution by training on human dialogues:</p><formula xml:id="formula_0">P θ (R|H) = m i=1 P θ (y i |y &lt;i , x 1 , ..., x n ).</formula><p>(1)</p><p>Common Sense as a Latent Variable As illustrated in Figures <ref type="figure" target="#fig_0">1</ref> and<ref type="figure" target="#fig_1">2</ref>, when humans respond in a conversation, we use common sense implicitly to establish common ground <ref type="bibr" target="#b9">(Grice, 1975;</ref><ref type="bibr" target="#b3">Clark and Brennan, 1991)</ref>, reach mutual understanding, and help produce natural responses for smooth communication. We consider common sense to be latent because it is infrequently stated due to the cooperative principle that states that participants should "not make your contribution more informative than is required" (Grice, 1975). However, the reasoning it enables is an integral part establishing common ground and critical for communication. To formalize this process, we consider common sense (CS) as an important latent variable in the modeling of a dialogue response when given the historyi.e, P (R|H, CS). Other latent factors such as the environment in which the conversation happens and background information of the participants can also influence the dialogue, but here we focus on common sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Probing Setup</head><p>Current RG models generate responses in an end-toend manner with only input from dialogue history (i.e., H), making it non-trivial to examine if they understand the implicit common sense behind RG process (also see Figure <ref type="figure" target="#fig_1">2</ref> for an illustration). We instantiate implicit common sense in dialogues and then design probes to evaluate models' grasp of common sense. This leads to two key challenges: 1) how to instantiate abstract and implicit common sense CS in dialogues? and 2) how to probe RG models' understanding of common sense in dialogue response generation?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instantiate Common Sense Using Explanations</head><p>We use natural language explanations justifying why a response makes common sense as a proxy to instantiate common sense in RG. Traditional studies have tied common sense and the ability to provide explanations for events and actions closely <ref type="bibr" target="#b10">(Hansen, 1980;</ref><ref type="bibr" target="#b12">Hilton and Slugoski, 1986)</ref>, which also holds true in a conversational setting <ref type="bibr" target="#b11">(Hilton, 1990)</ref>. Specifically, as shown in Figure <ref type="figure" target="#fig_0">1</ref>, "I want to make sure my house is sold" is a potential explanation about what leads to "hiring a real estate agent" in the response and this explanation requires understanding the commonsense relation that a real estate agent helps sell a house and the desire to sell a house motivates a person to hire an agent. Formally, we concretize the abstract latent variable common sense CS in textual form as an explanation E explaining what might cause the response R given the history H. We introduce our process of collecting such explanations for RG in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probe Models' Understanding in Two Settings</head><p>We then draw inspiration from human reasoning process behind dialogue response generation to design two probing tasks. First, humans use common sense implicitly to produce natural and coherent responses in conversations <ref type="bibr" target="#b4">(Clark and Schaefer, 1989)</ref>. Common sense helps humans determine what responses make sense in certain context. We want to see if providing common sense in the form of explanation also helps RG models arrive at coherent and natural responses more easily. Second, humans can perform causal attribution on an event or an action by finding reasons that might cause it <ref type="bibr" target="#b11">(Hilton, 1990)</ref>. If the person producing the response is asked about why they are feeling happy, they can easily respond with reasons about their reasoning process. We are interested in examining can RG models also generate responses to justify a previous response when asked. We probe RG models in a contrastive manner, by comparing model behaviors with a valid explanation E to the response and a corrupted E that breaks logical coherence. We introduce the two settings in more detail as follows.</p><p>Inference Probing Here we directly measure if P (R|E, H) &gt; P (R|E , H) for RG models, i.e., can models assign a higher probability to the response when provided with valid common sense in the form of explanations compared to logicallyincoherent explanations? Since existing RG models are not trained to take explanations as additional input, the probing results may be confounded by the model's unfamiliarity with the probing set-ting. To account for this issue, we 1) probe on a knowledge-grounded RG model that is used to taking in additional knowledge sentences as input and 2) fine-tune RG models on a proportion of our collected explanation and compare the effects. We discuss results and issues about probing models fine-tuned on explanations in Section 5.3.</p><p>If the model assigns a similar or lower probability to the response given a valid explanation compared to a logically-incoherent explanation, it indicates that the reason why this response makes sense is not clear for models.</p><p>Attribution Probing Here we examine if P (E|H, R) &gt; P (E |H, R), i.e., can RG models perform causal attribution as humans by assigning a higher probability to a valid explanation of the response (that makes sense) compared to a corrupted explanation, given the dialogue history and the response? To address the unfamiliarity of models, we make the probing setting close to real dialogues by continuing the conversation (consisting of H and R) with "why" to prompt the models to generate an explanation. We also conduct fine-tuning on a proportion of our collected explanations similarly to the first setting discussed in Section 5.3.</p><p>If the model prefers the attribution of the response that is incoherent with the response by giving it a higher probability, it indicates that the model fails to generate valid reasons for responses, which requires understanding the implicit common sense behind dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Generating Commonsense Explanations for Dialogue Responses</head><p>To get explanation annotations for dialogue responses, we first automatically generate commonsense causal explanations and then manually verify via crowdsourcing. We use a text-to-text model trained on commonsense story explanation dataset GLUCOSE <ref type="bibr" target="#b22">(Mostafazadeh et al., 2020)</ref> as the generator and conduct 2-stage human verification on generated explanations. We first introduce the model we use, the adaptation of the model on dialogue data, and our verification process to ensure the quality of generated explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generating Commonsense Explanations</head><p>GLUCOSE is a large-scale dataset of implicit commonsense causal explanations grounded in a story context <ref type="bibr" target="#b22">(Mostafazadeh et al., 2020)</ref>. Given a short story and a sentence X in the story, GLU-COSE contains human annotations of five dimensions of causal explanation related to X (an event/emotion/location/possession/attribute leads to X), each in a semi-structured form "antecedent connective consequent." Using the collected explanations, the authors train state-of-the-art neural models and find that the trained models are able to produce commonsense inferences on unseen stories. More details about how models are trained on GLUCOSE are included in Appendix A.</p><p>We consider using a model trained on GLU-COSE to automatically generate commonsense explanations in dialogues for several reasons. First, it generates contextual commonsense explanations that provides causal knowledge about what justifies a sentence. Second, it provides fine-grained causal explanations along different dimensions. Last but not least, we have conducted multiple rounds of pilot studies to directly ask workers to write out commonsense explanations for a response, but the subjectivity of this open-ended task led to large variations in quality. Instead we ask workers to verify explanations generated from a model.</p><p>We sample 1,200 dialogues from 4 dialogue datasets (300 from each): DailyDialog <ref type="bibr" target="#b15">(Li et al., 2017)</ref>, <ref type="bibr">EmpatheticDialogues (Rashkin et al., 2019)</ref>, MuTual <ref type="bibr" target="#b5">(Cui et al., 2020)</ref>, and SocialIQAprompted dialogues <ref type="bibr" target="#b43">(Zhou et al., 2021)</ref>. We generate 6k commonsense causal explanations (5 dimensions for each dialogue), using the last turn as the response and the previous turns as dialogue history (after filtering short turns). We follow <ref type="bibr" target="#b43">Zhou et al. (2021)</ref>'s approach to select dialogues that contain at least a one-hop triple from ConceptNet <ref type="bibr" target="#b20">(Liu and Singh, 2004)</ref>. We use the same hyperparameters and weights from the best-performing 770M T5 model from <ref type="bibr" target="#b22">Mostafazadeh et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Verification</head><p>To ensure the quality of generated explanations, we carefully design a two-stage human verification process with a qualification test and the main task.</p><p>Workers must first pass a qualification test (QT) that tests their understanding of the CS criteria necessary for our main annotation tasks (more details in Appendix B). We consider three criteria, requiring generated explanations to pass all three to be considered a valid commonsense explanation for a response. We ask three workers on Amazon Mechanical Turk (MTurk) to annotate the three criteria for each explanation.</p><p>Criteria 1). Relevant. A good causal explanation has to focus on explaining what could cause the response in the dialogue context <ref type="bibr" target="#b11">(Hilton, 1990)</ref>. An example of an irrelevant explanation for the example shown in Figure <ref type="figure" target="#fig_0">1</ref> is "I possess a house enables I live in a house" since "living in a house" is not what the response is about, so it doesn't help explain the response. 2). Non-trivial. We observe that sometimes the model simply duplicates a previous dialogue turn as the cause, which trivially associates history and response. We are interested in implicit and specific commonsense so we filter out explanations that parrot a previous turn. For example, "I found a buyer for the house motivates Oh Boy! I'm so happy. I knew hiring a real estate agent was a good idea." 3). Plausible. We ask humans to verify if the generated explanation plausibly identifies a likely cause for the response. An example of an implausible explanation is "I am in a house enables I am so happy" since "I am in a house" is not the direct cause why the person producing the response is feeling so happy, "found a buyer for the house" is. This is the hardest criterion for humans to decide due to its subjectivity nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We present results of our verification of 6k explanations from three in-house annotators. To filter ambiguous explanations and be strict about the quality of verified explanations, we only consider explanations valid if all three annotators have agreed that they satisfy all three criteria, i.e., 100% agreement for all verified explanations. For the annotated explanation, passing rates (agreed by 3 workers) for criterion (relevant, non-trivial, plausible) are (55%, 73%, 37%) -yielding an overall passing rate of 26% (1,560 explanations). Passing rates for the five dimensions (event, emotion, location, possession, attribute) are (31%, 33%, 13%, 24%, and 29%), with more details in Appendix B. Figure <ref type="figure" target="#fig_2">3</ref> presents examples for different dimension, full data is included in the supplementary material. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Probing Setup</head><p>We probe RG models' capability of understanding and using the explanation E in a contrastive manner (Sec. 2.2). This section first introduces the corruption types under two categories, then we introduce evaluation metrics, and finally we discuss several SOTA RG models with different neural architectures that we probe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corruption Types</head><p>We use verified explanations generated from GLU-COSE T5 model as valid explanations and define two categories of corruptions to corrupt the explanation to be logically-invalid and/or grammatically unnatural. We consider three logical corruptions that invalidate the logical connection between explanation and response, as well as three complete corruptions that break both logical coherence and naturalness of the sentence. Examples covering showing corruption types of a valid explanation are shown in Figure <ref type="figure" target="#fig_3">4</ref>, for which "I found a buyer for the house" is the antecedent, "causes" is the connective, and "I am so happy" is the consequent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logical Corruptions</head><p>We consider three ways to invalidate the logic of the explanation: 1) Swapped that swaps the antecedent and consequent of the explanation, 2) Negation that negates the connective word of the explanation, 3) Incorrect that uses an explanation from the same dialogue historyresponse instance that is rated as incorrect (if any) during the verification. <ref type="bibr" target="#b30">Sankar et al. (2019)</ref> who design perturbations to apply on dialogue history and analyze sensitivity of RG models by measuring the perplexity of the response, we consider three operations that completely break the naturalness of the explanation: 1) Shuffle that randomly shuffles the words of the explanation, 2) Dropped that drops 30% of the words uniformly, 3) for different response generation models on 4 dialogues datasets against two categories of corruptions. Accuracy is the bianry accuracy of giving a lower loss to the valid explanation than the corrupted one and ∆ NLL is the average difference of per-token NLL between the loss of a corrupted inference and a valid inference (the more positive the better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Complete Corruptions Inspired by</head><p>Reversed reverses the ordering of all the words in the explanation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Protocol and Metrics</head><p>We use two metrics to measure RG models' capability to distinguish valid commonsense causal explanations from invalid explanations. The standard way of modeling P θ in Equation ( <ref type="formula">1</ref>) in generative models is using Maximum Likelihood Estimation (MLE) approach and minimize the conditional negative log-likelihood loss (NLL), i.e., L(P θ , R, H) = -m i=1 log P θ (y i |y &lt;i , x 1 , ..., x n ). Since NLL is a direct measure of the probability distribution learned by the models, we use the same NLL measure for probing RG models' behavior. To measure performance of RG models, we directly compare the average per-token NLL when given a valid explanation and when given an invalid explanation to the response.</p><p>We first consider binary accuracy of giving a lower loss (higher probability) to the valid explanation than the corrupted one. A random-guessing baseline for the accuracy is 0.5. To further measure how confident the model is in determining the validity of commonsense explanations, we also compute the average difference ∆N LL by subtracting the loss of the valid inference from the invalid inference loss. The closer to zero the difference is, the less confident the model is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Response Generation Models</head><p>We experiment with multiple models from two neural architectures: GPT-2-based <ref type="bibr" target="#b23">(Radford et al., 2019)</ref> unidirectional transformer language model and Seq2Seq-based transformer <ref type="bibr" target="#b36">(Vaswani et al., 2017)</ref> models. For GPT-2-based models, we use DialoGPT that is trained on 147M multi-turn conversation-like exchanges extracted from Red-dit <ref type="bibr">(Zhang et al., 2020b)</ref> and GPT-2 trained on TopicalChat <ref type="bibr" target="#b8">(Gopalakrishnan et al., 2019)</ref> as the knowledge-grounded RG model. For seq2seq models, we use BlenderBot <ref type="bibr" target="#b29">(Roller et al., 2021)</ref> and BART <ref type="bibr" target="#b14">(Lewis et al., 2020)</ref>. More details about these RG models are included in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Probing Results and Analysis</head><p>We present results and findings for our two probing settings using different dialogue RG models across four datasets for which we collected verified explanations. For each human-validated explanation, we generate a corrupted version using one of our six corruption types, and compare the NLL for the probe target according to our two settings.</p><p>In Tables <ref type="table" target="#tab_0">1</ref> and<ref type="table" target="#tab_1">2</ref>, we show both binary accuracy and average difference in NLL for dialogues from four datasets under the two settings and aggregate the six corruption types into two categories. We also sample 5% of the dialogues for human verification under the same two probe settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">How Does Probability of Response</head><p>Change Given Explanations?</p><p>All models are insensitive to the relation between explanations and responses. As shown in the left portion of Table <ref type="table" target="#tab_0">1</ref>, we find that when comparing a valid explanation with a logically corrupted (LC) one, all models, regardless of left-toright or seq2seq model architecture, have accuracy around 50-60%, near a random guessing baseline, with extremely small differences in NLL (some even negative). This suggests that the RG models do not understand the causal relation between the explanation and the response since they give similar probabilities to the response when conditioned on a valid explanation and on a incoherent expla- nation, while humans can easily identify the valid explanation.</p><p>Even gibberish does not change response probability much. Surprisingly, we find that even when corrupting the explanation so completely that it becomes unnatural English, most seq2seq RG models still generate responses with a roughly equal likelihood (left2right models perform better but still lag human performance) as shown in the right portion of Table <ref type="table" target="#tab_0">1</ref>. <ref type="bibr" target="#b30">Sankar et al. (2019)</ref> find that the increase in perplexity of the response is tiny when they perturb the dialogue context, but here we find that there might even not be any increase in perplexity when conditioned on gibberish compared to a valid explanation expressed in English, while humans can identify the natural explanation perfectly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Can RG Models Attribute Valid Reasons for the Responses?</head><p>Logically incoherent attribution confuses the models. Similar to the inference probing setting, for logically corrupted one, all models have accuracy around 50-60% and tiny differences in NLL from the left part of Table <ref type="table" target="#tab_1">2</ref>. This indicates that the RG models cannot identify a logically-valid reason for a response from a reason that is similarly natural in terms of grammar but with totally different and invalid logical implications for the dialogue. Humans, from our sampled dialogues, again show much higher accuracy in this setting.</p><p>Models can confidently distinguish valid attribution from unnatural ones. For complete corruptions (CC), we find that except for BART, RG models perform much better in identifying a valid explanation compared to a completely corrupted one with most accuracy being close to 1 and rel- Figure <ref type="figure">5</ref>: Model size Effects on the two probing settings for BART aggregated across four datasets and types of corruptions. We find that except for the attribution setting against complete corruptions, increasing size does not impact much on probing performance. atively larger NLL differences. We conclude that these RG models find generating a valid explanation more natural than completely corrupted ones, which is expected since they are trained to generate natural sentences. However, combining this finding with the previous observation, we find that these RG models can discern unnatural sentences by giving a low probability, but fail to determine the logical validity of the reasons for responses, posing doubts on whether they understand CSR behind a response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis of Probing Results</head><p>Unfamiliarity with probing format is not the bottleneck. Since these RG models are not trained directly to take additional knowledge as input to generate responses or generate explanations for responses (although explaining happens often in dialogues), these poor results may be due to the probing setup. We thus fine-tune BART-base on 50% of our verified explanations in the same format as our two settings and probe on the rest. We find even when the model is accustomed to the Figure <ref type="figure">6</ref>: Fine-tuning (on in-domain dialogues) Effects on the two probing settings for three models aggregated across four datasets and types of corruptions. We find that in general fine-tuning does not help and sometimes even hurt the probing performance.</p><p>tasks, the accuracy against logical corruptions for both settings is still around 60%. Although it is possible that with more data the performance can be improved, we also note that training with explanations also makes the model biased to prefer explanations over corrupted ones due to pattern matching. For example, no explanations contain negated connectives, which might be used to gain an advantage unrelated to understanding common sense when compared against negated corruption.</p><p>To probe a model that is accustomed to the task but not exposed to explanation patterns, we consider a GPT-2-based <ref type="bibr" target="#b23">(Radford et al., 2019)</ref> model trained on TopicalChat <ref type="bibr" target="#b8">(Gopalakrishnan et al., 2019)</ref>, a knowledge-grounded dialogue dataset. The model is trained on given input of dialogue history concatenated with a knowledge sentence that the response needs to use. We treat the commonsense explanation as the knowledge sentence as they both provide necessary information that leads to the response. We find that the model performs similarly to DialoGPT on our probing setting for logical corruptions, providing evidence that the reason why these RG models cannot identify causal relations behind dialogue responses is not because the model is not used to taking explanation as input.</p><p>Model size does not help with understanding common sense. Comparing BART-base and BART-large in Figure <ref type="figure">5</ref>, we find that except for the attribution setting with complete corruptions, size does not change probing results (even lower accuracy against logical corruptions), indicating that the size of RG model is not the key to understand commonsense explanations for dialogue responses. Fine-tuning on in-domain dialogues sometimes have opposite effects. Since these RG models are trained on different dialogue datasets that are not necessarily in the same domain as probing dialogues, we also explore the effects of fine-tuning on in-domain dialogues, dialogues from the 4 datasets we use for probing. Three pairs of model (before and after fine-tuning) results are shown in Figure <ref type="figure">6</ref> and we do not find significant differences. We even find sometimes fine-tuning hurts the probing results, which might be due to models picking up statistical patterns while training on similar dialogues, relying less on "reasoning", if any.</p><p>Potential biases on certain perturbation types.</p><p>The observations above are general trends of the models performance, but we also find interesting corner cases indicating potential biases in the models when we breakdown performance for six corruption types shown in Figure <ref type="figure" target="#fig_6">7</ref> on the attribution probing setting. For the Negated corruption type, DialoGPT and BART have accuracy around 30%, meaning that for 70% of the time, they prefer generating explanations with negated relations in it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Commonsense Reasoning The majority of recent CSR benchmarks <ref type="bibr" target="#b38">(Zellers et al., 2018;</ref><ref type="bibr" target="#b35">Talmor et al., 2019;</ref><ref type="bibr" target="#b2">Bisk et al., 2020;</ref><ref type="bibr" target="#b31">Sap et al., 2019;</ref><ref type="bibr">Lin et al., 2021c</ref><ref type="bibr">Lin et al., ,a, 2020) )</ref> test a model's ability to choose the correct option given a context and a question. Recent work also aims to probe models in these tasks to see if reasoning is actually achieved <ref type="bibr">(Richardson and Sabharwal, 2020;</ref><ref type="bibr">Richardson et al., 2020;</ref><ref type="bibr" target="#b44">Zhou et al., 2020;</ref><ref type="bibr">Lin et al., 2021b)</ref>. <ref type="bibr" target="#b0">Arabshahi et al. (2020)</ref> focuses on if-thenbecause reasoning in conversations and design a theorem prover. In RG, several works have tried to incorporate commonsense <ref type="bibr" target="#b42">(Zhou et al., 2018;</ref><ref type="bibr">Zhang et al., 2020a)</ref> using ConceptNet, a commonsense knowledge graph <ref type="bibr" target="#b20">(Liu and Singh, 2004)</ref> to make responses more natural-sounding.</p><p>Dialogue Response Generation Recent work focused on fine-tuning large pre-trained transformer models <ref type="bibr" target="#b23">(Radford et al., 2019;</ref><ref type="bibr">Zhang et al., 2020b)</ref> on dialogue data. Many dialogue datasets have been collected with different focuses such as incorporating knowledge <ref type="bibr" target="#b8">(Gopalakrishnan et al., 2019;</ref><ref type="bibr">Dinan et al., 2019b</ref><ref type="bibr">), empathy (Rashkin et al., 2019)</ref>, personality <ref type="bibr" target="#b40">(Zhang et al., 2018)</ref> and reasoning <ref type="bibr" target="#b5">(Cui et al., 2020</ref>) within dialog systems.</p><p>There has also been work on combining a variety of datasets to exhibit multiple attributes <ref type="bibr" target="#b29">(Roller et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We study commonsense reasoning in dialogue response generation aiming to close the gap between current RG models and human communication abilities. Specifically we formalize the problem by framing commonsense as a latent variable in the RG task and using explanations for responses as textual form of commonsense. We design an explanation collection procedure for RG and propose two probing settings to evaluate RG models' CSR capabilities. We hope our study motivates more research in making RG models emulate human reasoning process in pursuit of smooth human-AI communication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A GLUCOSE Detail</head><p>GLUCOSE contains human annotations of ten dimensions of causal explanation related to X. Five of the dimensions are about events and states happening before X and five are about those happening after X. Specifically, inspired by cognitive psychology, the authors of GLUCOSE consider events, emotions, location states, possession states, and other attributes as the five dimensions of causal inferences. According to their evaluation, the bestperforming model is T5 <ref type="bibr" target="#b24">(Raffel et al., 2020)</ref> (with 770M parameters) with the input formulated as #d : S * [X], where d is the dimension and S * [X] is the story S with sentence X surrounded by asterisks". An illustrated example of inputs of outputs of the T5 model trained on GLUCOSE is shown in Figure <ref type="figure">8</ref>.</p><p>To adopt the T5 model trained on GLUCOSE to our task: generating explanations about what might cause producing a response given a dialogue history, we append the dialogue history turns together, enclose the response we are interested in explaining with asterisks, and fill in dimension number 1 to 5 to ask for what event, emotion, location, possession, and attribute could cause, motivate, or enable the response. In other words, we formulate our queries as #d : H * [R], where d is the dimension 1 to 5 and H * [R] is the dialogue history H appended with the response R surrounded with asterisks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Verification Detail</head><p>Table <ref type="table">3</ref> shows the general pass rate for each criterion and the overall pass rate (need to pass all three criteria). Figure <ref type="figure">9</ref> shows distribution of valid and invalid explanations separated by the five causal dimensions. We find the explanations about a location state that causes the response have a lower valid rate (13%) than others. This might be due to that in some dialogues the location information is not important in explaining the response and thus it is difficult to come up with a plausible reason about a location that leads to the response. All other dimensions have a similar rate of 25-30%.</p><p>To ensure annotation quality, the workers first need to pass a qualification test (QT) that tests their understandings of the criteria to be able to do our main annotation tasks. Our QT contains eight questions, each contains a dialogue history, a response, and an explanation and we ask them to choose whether this explanation satisfies a specific criterion from the three above. The eight questions The valid rates are 31%, 33%, 13%, 24%, and 29% for the five dimensions.</p><p>are formed into 4 pairs each consisting of a training question and a testing question and each pair focuses on the same criterion. For the relevance and non-trivial criteria, we have one pair for each and for the plausible criterion, we have two pairs since it is trickier to determine than the other two. We provide the right answer with explanation for the training question whether they answer it correctly or not and use the testing questions for assessment of their understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Model Detail</head><p>DialoGPT extends the GPT-2 architecture that adopts the generic transformer language model <ref type="bibr" target="#b36">(Vaswani et al., 2017)</ref>  Table <ref type="table">3</ref>: Passing rates for the three criteria and the overall valid rate (need to pass all three) from verification.  model 2 <ref type="bibr">(Zhang et al., 2020b)</ref>.</p><p>BlenderBot is proposed by <ref type="bibr" target="#b29">Roller et al. (2021)</ref> using a standard seq2seq transformer architecture <ref type="bibr" target="#b36">(Vaswani et al., 2017)</ref>. The model aims to blend multiple conversational skills. Human evaluations show their best models beat existing approaches in multi-turn dialogue in terms of engagingness and humanness. We use the 400M Blender-Bot model distilled from 2.7B parameter model 3 .</p><p>BART is proposed by <ref type="bibr" target="#b14">Lewis et al. (2020)</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1:A motivating example for our study. We want to know whether RG models understand the implicit common sense that justifies dialogue responses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Probing setting illustrations. We draw inspirations from human reasoning process during communication and probe RG models' understanding of implicit common sense in RG in two ways (red and blue dotted lines).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Examples of human-verified commonsense explanations for the dialogue shown in Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Examples of different corruption types to a commonsense causal explanation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Corruption results breakdown on the attribution probing settings aggregated across four datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Figure 8:Example input and output from GLUCOSE-trained T5 model on a dialogue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Example of qualification test question with shown explanation.</figDesc><graphic coords="14,70.87,70.87,453.53,143.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Example of the verification task question with three criteria for verifiers to choose.</figDesc><graphic coords="14,70.87,248.36,453.54,234.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>using a standard seq2seq architecture with a bidirectional BERT encoder and a left-to-right GPT decoder. It uses denoising pre-training objectives and has shown to outperform previous models in multiple 2 https://huggingface.co/microsoft/DialoGPT-medium 3 https://huggingface.co/facebook/ blenderbot-400M-distill language generation tasks including ConvAI2(Dinan et al., 2019a). We use both BART-base and BART-large with 139M and 406M parameters, respectively 4 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Logical Corruption Average [Accuracy/∆ NLL] Complete Corruption Average [Accuracy/∆ NLL] Inference probing results</figDesc><table><row><cell>Models</cell><cell>DD</cell><cell>ED</cell><cell>MuTual</cell><cell>SocialIQA</cell><cell>DD</cell><cell>ED</cell><cell>MuTual</cell><cell>SocialIQA</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Inference Probing</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DialoGPT (l2r)</cell><cell cols="3">0.57/-0.01 0.60/0.03 0.62/0.03</cell><cell>0.64/0.03</cell><cell cols="3">0.71/0.15 0.77/0.25 0.79/0.22</cell><cell>0.87/0.40</cell></row><row><cell cols="5">TopicalChat-GPT2 (l2r) 0.49/-0.00 0.50/-0.00 0.49/-0.00 0.50/-0.00</cell><cell cols="3">0.76/0.23 0.79/0.24 0.78/0.24</cell><cell>0.81/0.27</cell></row><row><cell>BlenderBot (s2s)</cell><cell cols="3">0.46/0.00 0.55/0.02 0.51/0.02</cell><cell>0.50/0.01</cell><cell cols="3">0.45/-0.02 0.43/-0.05 0.49/-0.03</cell><cell>0.41/-0.03</cell></row><row><cell>BART-base (s2s)</cell><cell cols="2">0.53/0.07 0.60/0.19</cell><cell>0.57/0.07</cell><cell>0.54/0.09</cell><cell cols="3">0.36/-0.38 0.41/-0.23 0.43/-0.27</cell><cell>0.43/-0.21</cell></row><row><cell>BART-large (s2s)</cell><cell cols="3">0.51/-0.03 0.52/-0.01 0.48/-0.06</cell><cell>0.52/0.00</cell><cell cols="3">0.49/-0.05 0.55/0.06 0.52/0.01</cell><cell>0.57/0.11</cell></row><row><cell>DialoGPT-ft (l2r)</cell><cell cols="4">0.50/-0.05 0.39/-0.54 0.44/-0.33 0.43/-0.25</cell><cell cols="3">0.63/0.11 0.76/0.24 0.66/0.15</cell><cell>0.78/0.31</cell></row><row><cell>BART-base-ft (s2s)</cell><cell cols="3">0.59/0.02 0.58/0.01 0.58/0.02</cell><cell>0.60/0.03</cell><cell cols="3">0.57/0.04 0.72/0.07 0.59/0.04</cell><cell>0.70/0.09</cell></row><row><cell>BART-large-ft (s2s)</cell><cell cols="3">0.57/0.02 0.44/-0.01 0.53/0.01</cell><cell>0.48/0.00</cell><cell cols="3">0.35/-0.06 0.54/0.02 0.37/-0.04</cell><cell>0.48/-0.00</cell></row><row><cell>Human</cell><cell>1.0</cell><cell>1.0</cell><cell>0.9</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Attribution probing results for different response generation models on 4 dialogues datasets against two categories of corruptions.</figDesc><table><row><cell>Models</cell><cell cols="8">Logical Corruption Average [Accuracy/∆ NLL] Complete Corruption Average [Accuracy/∆ NLL] DD ED MuTual SocialIQA DD ED MuTual SocialIQA</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Attribution Probing</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DialoGPT (l2r)</cell><cell cols="3">0.46/-0.07 0.47/-0.04 0.48/0.03</cell><cell>0.49/0.00</cell><cell cols="3">0.91/1.60 0.93/2.32 0.92/1.90</cell><cell>0.93/2.36</cell></row><row><cell cols="4">TopicalChat-GPT2 (l2r) 0.57/0.05 0.55/0.10 0.57/0.10</cell><cell>0.55/0.09</cell><cell cols="3">0.97/2.75 0.97/3.08 0.96/2.93</cell><cell>0.96/2.93</cell></row><row><cell>BlenderBot (s2s)</cell><cell cols="3">0.60/0.04 0.59/0.05 0.60/0.05</cell><cell>0.58/0.06</cell><cell cols="3">0.83/0.45 0.87/0.72 0.86/0.58</cell><cell>0.84/0.55</cell></row><row><cell>BART-base (s2s)</cell><cell cols="7">0.39/-0.19 0.41/-0.14 0.44/-0.10 0.42/-0.13 0.52/0.08 0.50/0.01 0.52/0.14</cell><cell>0.51/0.10</cell></row><row><cell>BART-large (s2s)</cell><cell cols="7">0.42/-0.15 0.41/-0.19 0.41/-0.18 0.40/-0.18 0.88/1.37 0.91/1.30 0.91/1.40</cell><cell>0.94/1.44</cell></row><row><cell>DialoGPT-ft (l2r)</cell><cell cols="3">0.43/-0.09 0.41/-0.04 0.47/0.01</cell><cell>0.46/0.00</cell><cell cols="3">0.93/2.01 0.96/2.60 0.93/2.22</cell><cell>0.95/2.70</cell></row><row><cell>BART-base-ft (s2s)</cell><cell cols="7">0.37/-0.16 0.36/-0.14 0.37/-0.19 0.37/-0.13 0.63/0.37 0.77/0.62 0.60/0.26</cell><cell>0.58/0.27</cell></row><row><cell>BART-large-ft (s2s)</cell><cell cols="7">0.36/-0.28 0.41/-0.13 0.35/-0.30 0.37/-0.23 0.45/0.02 0.83/1.04 0.54/0.30</cell><cell>0.63/0.41</cell></row><row><cell>Human</cell><cell>1.0</cell><cell>1.0</cell><cell>0.9</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell><cell>1.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>by training on 147M multi-turn conversation-like exchanges extracted from Reddit. We use the 345M DialoGPT</figDesc><table><row><cell cols="2">Criterion Passing Rate</cell></row><row><cell>Relevant</cell><cell>55%</cell></row><row><cell>Non-trivial</cell><cell>73%</cell></row><row><cell>Plausible</cell><cell>37%</cell></row><row><cell>All three</cell><cell>26%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0"><p>https://huggingface.co/models?search=bart</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank anonymous reviewers for providing insightful feedback along with <rs type="person">Brendan Kennedy</rs>, <rs type="person">Peifeng Wang</rs>, and members from <rs type="funder">INK</rs> and JAUNTS lab. This research is supported in part by the <rs type="funder">DARPA MCS program</rs> under Contract No. <rs type="grantNumber">N660011924033</rs>, the <rs type="funder">Defense Advanced Research Projects Agency</rs> with award <rs type="grantNumber">W911NF-19-20271</rs>,  <rs type="grantNumber">NSF IIS 2048211</rs>, and <rs type="funder">NSF</rs> <rs type="grantNumber">SMA 182926</rs>.   </p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_aJPk8Gt">
					<idno type="grant-number">N660011924033</idno>
				</org>
				<org type="funding" xml:id="_2vxRX36">
					<idno type="grant-number">W911NF-19-20271</idno>
				</org>
				<org type="funding" xml:id="_RQHzZ2m">
					<idno type="grant-number">NSF IIS 2048211</idno>
				</org>
				<org type="funding" xml:id="_hWRksMr">
					<idno type="grant-number">SMA 182926</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics and Broader Impact</head><p>Our work aims to examine RG model's ability to understand common sense for dialogue responses. <ref type="bibr" target="#b33">Sheng et al. (2021)</ref> have found biases in DialoGPT responses and <ref type="bibr">Mehrabi et al. (2021)</ref> have found representational harms in common sense resources. We acknowledge that the generated responses from models we use in probing experiments might contain biases. All of the dialogue datasets and models are in English, which benefits English speakers more. We have conducted human verification using Amazon Mechanical Turks. We pay turkers around $14 per hour, well above the highest state minimum wage and engage in constructive discussions if they have concerns about the process. We also give each annotation instance enough time so that we do not pressure annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logical Corruption Avg Complete Corruption Avg</head><p>Corruption Categories Figure <ref type="figure">12</ref>: Dataset differences on the causality probing setting for DialoGPT model, we find that there is no drastic differences in probing performances across four datasets for logical corruptions, i.e., the conclusion that RG model fails to understand causality holds true for all datasets. We see difference in accuracy ranging from 70% to 90% for complete corruptions.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Conversational neuro-symbolic commonsense reasoning</title>
		<author>
			<persName><forename type="first">Forough</forename><surname>Arabshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikayla</forename><surname>Gawarecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Azaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2020. 2006.10022</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Climbing towards NLU: On meaning, form, and understanding in the age of data</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.463</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5185" to="5198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PIQA: reasoning about physical commonsense in natural language</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Lebras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020-02-07">2020. February 7-12, 2020</date>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="7432" to="7439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Grounding in communication</title>
		<author>
			<persName><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><surname>Brennan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Contributing to discourse</title>
		<author>
			<persName><forename type="first">H</forename><surname>Herbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">F</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><surname>Schaefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="294" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MuTual: A dataset for multi-turn dialogue reasoning</title>
		<author>
			<persName><forename type="first">Leyang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.130</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1406" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">2019a. The second conversational intelligence challenge (convai2)</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Malykh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno>ArXiv preprint, abs/1902.00098</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Wizard of wikipedia: Knowledge-powered conversational agents</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06">2019. 2019. May 6-9, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Topical-chat: Towards knowledge-grounded open-domain conversations</title>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behnam</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinglang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Gottardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanjeev</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anu</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raefer</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1891" to="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Logic and conversation</title>
		<author>
			<persName><surname>Herbert P Grice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech acts</title>
		<imprint>
			<publisher>Brill</publisher>
			<date type="published" when="1975">1975</date>
			<biblScope unit="page" from="41" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Commonsense attribution</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ranald</surname></persName>
		</author>
		<author>
			<persName><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">996</biblScope>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conversational processes and causal explanation</title>
		<author>
			<persName><forename type="first">Hilton</forename><surname>Denis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Knowledgebased causal attribution: The abnormal conditions focus model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><forename type="middle">R</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><surname>Slugoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Toward a model of text comprehension and production</title>
		<author>
			<persName><forename type="first">Walter</forename><surname>Kintsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teun A</forename><surname>Van Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">363</biblScope>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.703</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">Marjan Ghazvininejad,. 2020</date>
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DailyDialog: A manually labelled multi-turn dialogue dataset</title>
		<author>
			<persName><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuzi</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
	<note>Long Papers). Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Xiaoyang Qiao, and Xiang Ren. 2021a. Common sense beyond English: Evaluating and improving multilingual language models for commonsense reasoning</title>
		<author>
			<persName><forename type="first">Seyeon</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.102</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1274" to="1287" />
		</imprint>
	</monogr>
	<note>Long Papers). Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Xiang Ren, and William Cohen. 2021b. Differentiable open-ended commonsense reasoning</title>
		<author>
			<persName><forename type="first">Haitian</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><surname>Zaheer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.366</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="4611" to="4625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">2021c. RiddleSense: Reasoning about riddle questions featuring linguistic creativity and commonsense knowledge</title>
		<author>
			<persName><forename type="first">Ziyi</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong-Ho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.131</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1504" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CommonGen: A constrained text generation challenge for generative commonsense reasoning</title>
		<author>
			<persName><forename type="first">Wangchunshu</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.165</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1823" to="1840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conceptnet-a practical commonsense reasoning tool-kit</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Push</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BT technology journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="226" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Jay Pujara, Xiang Ren, and Aram Galstyan. 2021. Lawyers are dishonest? quantifying representational harms in commonsense knowledge resources</title>
		<author>
			<persName><forename type="first">Ninareh</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><surname>Morstatter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">GLUCOSE: GeneraLized and COntextualized story explanations</title>
		<author>
			<persName><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lori</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Buchanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauren</forename><surname>Berkowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Or</forename><surname>Biran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.370</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4569" to="4586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards empathetic opendomain conversation models: A new benchmark and dataset</title>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Boureau</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1534</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5370" to="5381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Probing natural language inference models through semantic fragments</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">S</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="8713" to="8721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">What does my QA model know? devising controlled probes using expert knowledge</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00331</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="572" to="588" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<publisher>UK. Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recipes for building an open-domain chatbot</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">Michael</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="300" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Do neural dialog systems use the conversation history effectively? an empirical study</title>
		<author>
			<persName><forename type="first">Chinnadhurai</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1004</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="32" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Social IQa: Commonsense reasoning about social interactions</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1454</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4463" to="4473" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Commonsense reasoning for natural language processing</title>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-tutorials.7</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="27" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Investigating ad hominems in dialogue responses</title>
		<author>
			<persName><forename type="first">Emily</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prem</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.60</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="750" to="767" />
		</imprint>
	</monogr>
	<note>nice try, kiddo</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/N15-1020</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">CommonsenseQA: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1421</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">2017. 2017. December 4-9, 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Eliza-a computer program for the study of natural language communication between man and machine</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Weizenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="45" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">SWAG: A large-scale adversarial dataset for grounded commonsense inference</title>
		<author>
			<persName><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Grounded conversation generation as guided traverses in commonsense knowledge graphs</title>
		<author>
			<persName><forename type="first">Houyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.184</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2031" to="2043" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Personalizing dialogue agents: I have a dog, do you have pets too?</title>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1205</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2204" to="2213" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">DIALOGPT : Largescale generative pre-training for conversational response generation</title>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.30</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="270" to="278" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Commonsense knowledge aware conversation generation with graph attention</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haizhou</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2018/643</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-13">2018. 2018. July 13-19, 2018</date>
			<biblScope unit="page" from="4623" to="4629" />
		</imprint>
	</monogr>
	<note>ijcai.org</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Commonsensefocused dialogues for response generation: An empirical study</title>
		<author>
			<persName><forename type="first">Pei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Behnam</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seokhwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<publisher>Singapore and Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Rica: Evaluating robust inference capabilities based on commonsense axioms</title>
		<author>
			<persName><forename type="first">Pei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<idno>abs/2005.00782</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
