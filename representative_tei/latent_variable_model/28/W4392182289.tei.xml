<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Counterfactual Generation with Identifiability Guarantees</title>
				<funder ref="#_BgyGvEV">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
				<funder>
					<orgName type="full">Salesforce Inc.</orgName>
				</funder>
				<funder>
					<orgName type="full">KDDI Research Inc.</orgName>
				</funder>
				<funder ref="#_UZFvcNG #_bQr6dUS #_eyp42mR">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder>
					<orgName type="full">Amazon Research</orgName>
				</funder>
				<funder>
					<orgName type="full">Apple Inc.</orgName>
				</funder>
				<funder ref="#_5mR3nDY #_gPBzaGW #_G87h7xD #_PBhEdjJ">
					<orgName type="full">UK Engineering and Physical Sciences Research Council</orgName>
				</funder>
				<funder>
					<orgName type="full">Microsoft Research</orgName>
				</funder>
				<funder ref="#_8EjHwNc #_wtnGfGG">
					<orgName type="full">UK Research and Innovation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-02-23">23 Feb 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hanqi</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Warwick</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Mohamed Bin Zayed</orgName>
								<orgName type="institution">University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>3 King&apos;s</addrLine>
									<settlement>College London</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lin</forename><surname>Gui</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yuejie</forename><surname>Chi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>3 King&apos;s</addrLine>
									<settlement>College London</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Xing</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>3 King&apos;s</addrLine>
									<settlement>College London</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Mohamed Bin Zayed</orgName>
								<orgName type="institution">University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yulan</forename><surname>He</surname></persName>
							<email>yulan.he@kcl.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Warwick</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>3 King&apos;s</addrLine>
									<settlement>College London</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Mohamed Bin Zayed</orgName>
								<orgName type="institution">University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Counterfactual Generation with Identifiability Guarantees</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-02-23">23 Feb 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2402.15309v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Counterfactual generation lies at the core of various machine learning tasks, including image translation and controllable text generation. This generation process usually requires the identification of the disentangled latent representations, such as content and style, that underlie the observed data. However, it becomes more challenging when faced with a scarcity of paired data and labeling information. Existing disentangled methods crucially rely on oversimplified assumptions, such as assuming independent content and style variables, to identify the latent variables, even though such assumptions may not hold for complex data distributions. For instance, food reviews tend to involve words like "tasty", whereas movie reviews commonly contain words such as "thrilling" for the same positive sentiment. This problem is exacerbated when data are sampled from multiple domains since the dependence between content and style may vary significantly over domains. In this work, we tackle the domain-varying dependence between the content and the style variables inherent in the counterfactual generation task. We provide identification guarantees for such latent-variable models by leveraging the relative sparsity of the influences from different latent variables. Our theoretical insights enable the development of a doMain AdapTive counTerfactual gEneration model, called (MATTE). Our theoretically grounded framework achieves state-of-the-art performance in unsupervised style transfer tasks, where neither paired data nor style labels are utilized, across four large-scale datasets. Code is available at <ref type="url" target="https://github.com/hanqi-qi/Matte.git">https://github.com/hanqi-qi/Matte.git</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Counterfactual generation serves as a crucial component in various machine learning applications, such as controllable text generation and image translation. These applications aim at producing new data with desirable style attributes (e.g., sentiment, tense, or hair color) while preserving the other core information (e.g., topic or identity) <ref type="bibr" target="#b31">[Li et al., 2019</ref><ref type="bibr">, 2022</ref><ref type="bibr">, Xie et al., 2023</ref><ref type="bibr">, Isola et al., 2017</ref><ref type="bibr">, Zhu et al., 2017]</ref>. Consequently, the central challenge in counterfactual generation is to learn the underlying disentangled representations.</p><p>To achieve this goal, prior work leverages either paired data that only differ in style components <ref type="bibr" target="#b42">[Rao and Tetreault, 2018</ref><ref type="bibr" target="#b45">, Shang et al., 2019</ref><ref type="bibr">, Xu et al., 2019b</ref><ref type="bibr">, Wang et al., 2019b]</ref>, or utilizes style labeling information <ref type="bibr" target="#b21">[John et al., 2019</ref><ref type="bibr" target="#b14">, He et al., 2020</ref><ref type="bibr" target="#b5">, Dathathri et al., 2020</ref><ref type="bibr" target="#b57">, Yang and Klein, 2021</ref><ref type="bibr" target="#b35">, Liu et al., 2022]</ref>. However, collecting paired data or labels can be labour-intensive and even infeasible in many real-world applications <ref type="bibr" target="#b2">[Chou et al., 2022</ref><ref type="bibr" target="#b1">, Calderon et al., 2022</ref><ref type="bibr">, Xie et al., 2023]</ref>. This has prompted recent work <ref type="bibr" target="#b24">[Kong et al., 2022</ref><ref type="bibr">, Xie et al., 2023]</ref> to delve into unsupervised identification of latent variables by tapping into multiple domains. To attain identifiability guarantees, a prevalent assumption made in these works <ref type="bibr" target="#b24">[Kong et al., 2022</ref><ref type="bibr">, Xie et al., 2023]</ref> is that the content and the style latent variables are independent of each other. However, this assumption is often violated in practical applications. First, the dependence between content and style variables can be highly pronounced. For example, to express a positive sentiment, words such as "tasty" and "flavor" are typically used in conjunction with food-related content. In contrast, words like "thrilling" are more commonly used with movie-related content <ref type="bibr" target="#b31">[Li et al., 2019</ref><ref type="bibr" target="#b34">[Li et al., , 2022]]</ref>. Moreover, the dependence between content and style often varies across different distributions. For example, a particular cuisine may be highly favored locally but not well received internationally. This varying dependence between content and style variables poses a significant challenge in obtaining the identifiability guarantee. To the best of our knowledge, this issue has not been addressed in previous studies.</p><p>In this paper, we address the identification problem of the latent-variable model that takes into account the varying dependence between content and style (see <ref type="bibr">Fig 1)</ref>. To this end, we adopt a natural notion of influence sparsity inherent to a range of unstructured data, including natural languages, for which the influences from the content and the style differ in their scopes. Specifically, the influence of the style variable on the text is typically sparser compared to that of the content variable, as it is often localized to a smaller fraction of the words <ref type="bibr" target="#b33">[Li et al., 2018]</ref> and plays a secondary role in word selection. For instance, the tense of a sentence is typically reflected in only its verbs which are affected by the sentence content information. Our contributions can be summarised as: 1) We show identification guarantees for both the content and the style components, even when their interdependence varies. This approach removes the necessity for a large number of domains with specific variance properties <ref type="bibr" target="#b24">[Kong et al., 2022</ref><ref type="bibr">, Xie et al., 2023]</ref>. 2) Guided by our theoretical findings, we design a doMain AdapTive counTerfactual gEneration model (MATTE). It does not require paired data or style annotations but allows style intervention, even across substantially different domains. 3) We validate our theoretical discoveries by demonstrating state-of-the-art performance on the unsupervised style transfer task, which demands representation disentanglement, an integral aspect of counterfactual generation. in the previous two types of work, it may not hold for complex data distributions. For instance, in the case of generating text, each topic-related latent factor may influence a large number of components. Instead, we adopt a relative sparsity assumption, where we only require the influence of one subspace to be sparser than the other. Unlike prior work <ref type="bibr" target="#b61">[Zheng et al., 2022]</ref>, each latent variable is allowed to influence a non-sparse set of components, and the influence can overlap arbitrarily within each subspace. Importantly, we necessitate neither many domains/classes nor paired data as prior work mentioned above.</p><p>3 Disentangled Representation for Counterfactual Generation  <ref type="bibr">variable (i.e., text)</ref> x is generated from content c and style s. Both content c and style s are influenced by the domain variable u and the content also influences the style. s is the exogenous variable of s, representing the independent information of s.</p><p>In this section, we discuss the connection between counterfactual generation and the identification of the data-generating process shown in Fig <ref type="figure" target="#fig_0">1</ref>.</p><p>Disentangled latent representation. The data-generating process in Figure <ref type="figure" target="#fig_0">1</ref> can be expressed in Equation <ref type="formula">1</ref>:</p><formula xml:id="formula_0">c ‚àº p(c|u), s ‚àº p(s|c, u), x = g(c, s),</formula><p>(1) where the data (e.g., text) x ‚àà X are generated by latent variables z := [c, s] ‚àà Z ‚äÜ R dz through a smooth and invertible generating function g(‚Ä¢) : Z ‚Üí X . The latent space comprises two subspaces: the content variable c ‚àà C ‚äÜ R dc and the style variable s ‚àà S ‚äÜ R ds . We define c as the description of the main topic, e.g., "We ordered the steak recommended by the waitress,", and s comprises supplementary details connected to the primary topic, e.g., the sentiment towards the dish, as exemplified in "it was delicious!". Consequently, the counterfactual generation task here is to preserve the content information c while altering the stylistic aspects represented by s.</p><p>Content-style dependence. In many real-world problems, content c can significantly impact style s.</p><p>For instance, when it comes to the positive descriptions of food (content), words like "delicious" are more prevalent than terms like "effective". Intuitively, the content c acts to constrain the range of vocabulary choices for style s. As a result, the counterfactually generated data should preserve the inherent relationship between c and s. We directly model this dependence as:</p><p>s := g s (s; c, u),</p><p>(2) where g s characterizes the influence from c to s and the exogenous variable s accounts for the inherent randomness of s. In the running example, s can be interpreted as the randomness involved in choosing a word from the vocabulary defined by content c, encompassing words similar to "delicious" such as "tasty","yummy". In contrast, prior work <ref type="bibr" target="#b24">[Kong et al., 2022</ref><ref type="bibr">, Xie et al., 2023]</ref> assumes the independence between c and s thus neglecting this dependence.</p><p>Challenges from multiple domains. As we outlined in Section 1, the ability to handle domain shift is crucial for unsupervised counterfactual generation. Domain embedding u represents a specific domain and the domain distribution shift influences both the marginal distribution of content p(c|u) and the dependence of content on style p(s|c, u). The change in content distribution p(c|u) across different domains u reflects the variability in the subjects of sentences across these domains. For example, it can manifest as a change from discussing food in restaurant reviews to actors in movie reviews. The change in content-style dependence p(s|c, u) signifies that identical sentence subjects (i.e., content) could be associated with disparate stylistic descriptions in different domains. For instance, the same political question could provoke significantly different sentiments among various demographic groups. Such considerations are absent in prior work <ref type="bibr" target="#b24">[Kong et al., 2022]</ref>. Here, we learn a shared model (p(c|‚Ä¢), g s (s, c, ‚Ä¢)) and domain-specific embeddings u. This approach enables effective knowledge transfer across domains and manages distribution shifts efficiently. For a target domain œÑ , which may have limited available data, we can learn u œÑ using a small amount of unlabeled data x œÑ while preserving the multi-domain information in the shared model.</p><p>In light of the above discussion, the essence of counterfactual generation now revolves around the task of discerning the disentangled representation (c, s) within the data-generating process (Fig <ref type="figure" target="#fig_0">1</ref>) across various domains with unlabeled data (x, u): if we can successfully identify (c, s), we could perform counterfactual reasoning by manipulating s while preserving both the content information and the content-style dependence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Identifiability of the Latent Variables</head><p>In this section, we introduce the identification theory for the content c and the style s sequentially and then discuss their implications for methodological development.</p><p>We introduce notations and definitions that we use throughout this work. When working with matrices, we adopt the following indexing notations: for a matrix M, the i-th row is denoted as M i,: , the j-th column is denoted as M :,j , and the (i, j) entry is denoted as [M] i,j . We can also use this notation to refer to specific sets of indices within a matrix. For an index set I ‚äÜ {1, . . . , m} √ó {1, . . . , n}, we use I i,: to denote the set of column indices whose row coordinate is i, i.e., I i,: := {j : (i, j) ‚àà I}, and analogously I :,j to denote the set of row indices whose column coordinate is j.</p><p>In addition, we define a subspace of R n using an index set S: R n S = {z ‚àà R n |‚àÄi / ‚àà S, z i = 0}, i.e., it consists of all vectors in R n whose entries are zero for all indices not in S. Finally, we can define the support of a matrix-valued function M(x) : X ‚Üí R m√ón as the set of indices whose corresponding entries are nonzero for some input value x, i.e., Supp(M) := {(i, j) : ‚àÉx ‚àà X , s.t., [M(x)] i,j Ã∏ = 0}.  We show that the subspace c can be identified. That is, we can estimate a generative model (p ƒâ, p ≈ù|ƒâ , ƒù)<ref type="foot" target="#foot_0">foot_0</ref> following the data-generating process in Equation 1 and the estimated variable ƒâ can capture all the information of c without interference from s. In the following, we denote the Jacobian matrices J g (z)'s and J ƒù (·∫ë)'s supports as G and ƒú respectively. Further, we denote as T a set of matrices with the same support as that of the matrix-valued function J -1 g (c)J ƒù (ƒâ). Assumption 1 (Content identification).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Influence Sparsity for Content Identification</head><formula xml:id="formula_1">ùë• ! ùë• " ùë• # ùë• $ ùë• % ùëê ! ùëê " ùëê # ùë† ! ùë† "</formula><p>i. g is smooth and invertible and its inverse g -1 is also smooth.</p><p>ii. For all i ‚àà {1, . . . , d x }, there exist {z (‚Ñì) } |Gi,:| ‚Ñì=1</p><p>and T ‚àà T , such that span({J g (z (‚Ñì) ) i,:</p><formula xml:id="formula_2">} |Gi,:| ‚Ñì=1 ) = R dz</formula><p>Gi,: and [J g (z (‚Ñì) )T] i,: ‚àà R dz ƒúi,:</p><p>. iii. For every pair (c jc , s js ) with j c ‚àà [d c ] and j s ‚àà {d c + 1, . . . , d z }, the influence of s js is sparser than that of c jc , i.e., ‚à•G :,jc ‚à• 0 &gt; ‚à•G :,js ‚à• 0 .</p><p>Theorem 1. We assume the data-generating process in Equation 1 with Assumption 1. If for given dimensions (d c , d s ), a generative model (p ƒâ, p ≈ù|ƒâ , ƒù) follows the same generating process and achieves the following objective:</p><p>arg min p ƒâ ,p ≈ù,ƒù j ≈ù‚àà{dc +1,...,dz } ƒú:,j ≈ù 0 subject to:</p><formula xml:id="formula_3">p x(x) = px(x), ‚àÄx ‚àà X ,<label>(3)</label></formula><p>then the estimated variable ƒâ is an one-to-one mapping of the true variable c. That is, there exists an invertible function h c (‚Ä¢) such that ƒâ = h c (c).</p><p>A proof can be found in Appendix A.5.</p><p>Interpretation. Theorem 1 states that by matching the marginal distribution p x (x) under a sparsity constraint of ≈ù subspace, we can successfully eliminate the influence of s from the estimated ƒâ. This warrants that the content information can be fully retained without being entangled with the style information for a successful counterfactual generation. We can further identify s from that of s when the dependence g s function is invertible in its argument s <ref type="bibr" target="#b24">[Kong et al., 2022]</ref>. Discussion on assumptions. Assumption 1-i. ensures that the information of all latent variables [c, s] is preserved in the observed variables x, which is a necessary condition for latent-variable identification <ref type="bibr" target="#b19">[Hyvarinen et al., 2019</ref><ref type="bibr" target="#b24">, Kong et al., 2022]</ref>. Assumption 1-ii. ensures that the influence from the latent variable z varies sufficiently over its domain. This excludes degenerate cases where the Jacobian matrix is partially constant, and thus, its support fails to faithfully capture the influence between latent variables and the observed variables. Assumption 1-iii. encodes the observation that the s subspace exerts a relatively sparser influence on the observed data than the subspace c (Fig 2 .). This is reasonable for language, where the main event largely predominant the sentence and the stylistic variable play complementary and local information for particular attributes, e.g., tense, sentiment, and formality <ref type="bibr">[Xu et al., 2019a</ref><ref type="bibr" target="#b50">, Wang et al., 2021</ref><ref type="bibr" target="#b44">, Ross et al., 2021]</ref>. For the language data, x corresponds to a piece of text (e.g., a sentence) with its dimension d x equal to the number of words multiplied by the word embedding dimension, i.e., multiple dimensions of x correspond to a single word. Therefore, even if a word is simultaneously influenced by both c and s, the influence from the content c tends to be denser on this word's embedding dimension, as content usually takes precedence in word selection over style.</p><p>Contrast with prior work. <ref type="bibr" target="#b61">Zheng et al. [2022]</ref> impose sparse influence constraints on the generating function g in an absolute sense -each latent component should have a very sparse influence on the observed data. In contrast, Theorem 1 only calls for relative sparsity between two subspaces where each latent component's influence may not be sparse and unique as in <ref type="bibr" target="#b61">Zheng et al. [2022]</ref>.</p><p>We believe this is reasonable for many real-world applications like languages. <ref type="bibr" target="#b24">Kong et al. [2022]</ref> assume the independence between the two subspaces and identify the content subspace by resorting to its invariance and sufficient variability of the style subspace over multiple domains. However, as discussed in Section 3, the invariance of the content subspace is often violated, and so is the independence assumption. In contrast, we permit the content subspace to vary over domains and allow for the dependence between the two subspaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Partially Intersecting Influences for Style Identification</head><p>In this section, we show the identifiability for the style subspace s, under one additional condition: the influences from the two subspaces c and s do not fully overlap.</p><p>Assumption 2 (Partially intersecting influence supports). For every pair (c jc , s js ), the supports of their influences on x do not fully intersect, i.e., ‚à•G :,jc ‚à© G :,js ‚à• 0 &lt; min{‚à•G :,jc ‚à• 0 , ‚à•G :,js ‚à• 0 }.</p><p>Theorem 2. We follow the data-generating process Equation <ref type="formula">1</ref>and Assumption 1 and Assumption 2. We optimize the objective function in Equation 3 together with min (j ƒâ ,j ≈ù)‚àà{1,...,dc }√ó{dc+1,...,dz} ƒú:,j ƒâ ‚à© ƒú:,j ≈ù 0 .</p><p>(4)</p><p>The estimated style variable ≈ù is a one-to-one mapping to the true variable s. That is, there exists an invertible mapping h s (‚Ä¢) between s and ≈ù, i.e., ≈ù = h s (s).</p><p>The proof can be found in Appendix A.6. Interpretation. Theorem 2 states that we can recover the style subspace s if the influences from the two subspaces do not interfere with each other (Fig <ref type="figure" target="#fig_2">2</ref>). This condition endows the subspaces distinguishing footprints and thus forbids the content information in c from contaminating the estimated style variable ≈ù. The identification of s is crucial to counterfactual generation tasks: if the estimated style variable ≈ù does capture all the true style variable s, intervening on ≈ù cannot fully alter the original style that is intended to be changed. Discussion on assumptions. Assumption 2 prescribes that each content component c jc and each style component s js do not fully contain each other's influence support. Together with Theorem 1, this assumption is essential to the identification of s, without which ≈ùjs may absorb the influence from c jc . Assumption 2 does not demand the supports of the entire subspaces c and s to be partially intersecting or even disjoint, and the latter directly implies Assumption 2. This assumption is plausible for many real-world data distributions, especially for unstructured data like languages and images -certain dimensions in the pixels and word embeddings may reflect the information of either the content or the style.</p><p>Contrast with prior work. <ref type="bibr" target="#b24">Kong et al. [2022]</ref> obtains the identifiability of the style subspace s by exploiting the access to multiple domains over which the marginal distribution of s (i.e., p(s|u)) varies substantially over domains u. This hinges on the independence between the two subspaces and is not applicable when the marginal distribution of s only varies over the content c, i.e., p(s|c, u).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A Framework for Unsupervised Counterfactual Generation</head><p>In this section, we translate the theoretical insights outlined in Section 4 into an unsupervised counterfactual generation framework. Guided by the theory, we can approximate the underlying data-generating process depicted in Fig <ref type="figure" target="#fig_0">1</ref> and recover the disentangled latent components.</p><formula xml:id="formula_4">ùëî !"# ùëì "$# ùë• ùë• !"# ùë† s ~ùëÅ(0,1) ùëü $ ùë¢ c ~ùëÅ(0,1) ùëê ùëü % in te rv e n e ùëß ùë• &amp;!'()*"! Figure 3: Our VAE-based framework -MATTE.</formula><p>During training, the input x is fed to the encoder fenc to derive the latent variable z = [c, s], which is then passed to the decoder gdec for reconstruction. Flow modules, denoted as rc and rs, are implemented to model the causal influences on c and s respectively, which yields the creation of exogenous variables c and s. To generate transferred data xtransfer, we intervene on the style exogenous variable s while keeping the original content variable c unchanged (indicated by the green arrows).</p><p>In the following, we will describe each module in our VAE-based estimation framework (Fig <ref type="figure">3</ref>), the learning objective, and the procedure for counterfactual generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">VAE-based Estimation Framework</head><p>Given input sentences x from various domains, we use the VAE encoder f enc to parameterize the posterior distribution q fenc (z|x) and sample z ‚àº q fenc (z|x). <ref type="foot" target="#foot_1">3</ref> The posterior sample z is then fed into the VAE decoder g dec for reconstruction x rec = g dec (z), as in conventional VAE training.</p><p>We split z into two components: c and s. As shown in Fig <ref type="figure" target="#fig_0">1</ref>, both c and s encompass information of a particular domain u, and s is also influenced by c. We parameterize such influences using flow-based models <ref type="bibr" target="#b9">[Dolatabadi et al., 2020</ref><ref type="bibr" target="#b10">, Durkan et al., 2019]</ref> r c and r s , respectively:</p><formula xml:id="formula_5">c = r c (c; u), s = r s (s; u, c),<label>(5)</label></formula><p>where c and s are exogenous variables that are independent of each other, and u and (u, c) act as contextual information for the flow models r c (‚Ä¢; u) and r s (‚Ä¢; u, c). This design promotes parameter sharing across domains, as we only need to learn a domain embedding u (c.f., a separate flow model per domain). As part of the evidence-lower-bound (ELBO) objective in VAE, we regularize the distributions of z = [c, s] to align with the prior p(z) using Kullback-Leibler (KL) divergence. Consequently, the VAE learning objective can be expressed as:</p><formula xml:id="formula_6">L VAE := -log p fenc,gdec (x rec ) + KL(q fenc,rc,rs (z|x)|p(z)),<label>(6)</label></formula><p>where the prior p(z) is set to a standard Gaussian distribution, N (0, I), consistent with typical VAE implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Sparsity Regularization for Identification Guarantees</head><p>Guided by the insights from Theorem 1 and Theorem 2, the sparsity constraint on the influence of s (i.e., Equation <ref type="formula" target="#formula_3">3</ref>) and the partially intersecting influence constraint (i.e., Equation <ref type="formula">4</ref>) are crucial to faithfully recover and disentangle the latent representations c and s. Sparsity of the style influence. To implement Equation 3, we compute the Jacobian matrix J gdec (z) for the decoder function on-the-fly and apply ‚Ñì 1 regularization to the columns corresponding to the style variable [J gdec (z)] :,dc+1:dz to control its sparsity. That is,</p><formula xml:id="formula_7">L sparsity = ‚à•[J gdec (z)] :,dc+1:dz ‚à• 1 .</formula><p>Partially intersecting influences. To encourage sparsity in the intersection of influence between c and s (as defined in Equation <ref type="formula">4</ref>), we select K output dimensions I s of J gdec (z) that capture the most substantial influence from s and another set of K output dimensions I c that receive the least influence from c. Subsequently, we apply ‚Ñì 1 regularization to the influence from c on the output dimensions at the intersection</p><formula xml:id="formula_8">I s ‚à© I c , i.e., L partial = ‚à•[J gdec (z)] Is‚à©Ic,1:dc ‚à• 1 .</formula><p>Content variable masking. In practice, the content dimensionality d c is a design choice. When d c is set excessively large, the sparsity regularization term L sparsity may cause the style variable s to lose its influence, squeezing the information of s into the content variable c. To handle this issue, we apply a trainable soft mask that operates on c to dynamically control its dimensionality.</p><p>In sum, the overall training objective is as follows:</p><formula xml:id="formula_9">L := L VAE + Œª sparsity ‚Ä¢ L sparsity + Œª partial ‚Ä¢ L partial + Œª c-mask ‚Ä¢ L c-mask ,<label>(7)</label></formula><p>where Œª's are weight parameters to balance various loss terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Style Intervention</head><p>As discussed in Section 3, the content-style dependence should be preserved when generating counterfactual text to ensure linguistic consistency. This can be achieved by intervening on the exogenous style variable s of the original sample. Specifically, we feed the original sample x to the encoder f enc to obtain variables [c, s]. Subsequently, we pass the style variable s through the flow models r s to obtain its exogenous counterpart s, i.e., s = r s (s; c, u). To carry out style transfer, we set the original variable s to the desired style value stransfer , which is the average of the exogenous style values of randomly selected samples with the desired style. As the flow model r s is invertible, we can obtain the transferred style variable s transfer = r -1 s (s transfer ; c, u), which, together with the original content variable c, generates the new sample x transfer = g dec ([c, s transfer ]). This process is illustrated in Fig 3 using green arrows. We demonstrate the importance of preserving the content-style dependence and provide evidence that our approach can indeed fulfill this purpose (Fig <ref type="figure" target="#fig_4">4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>We validate our theoretical findings by conducting experiments on multiple-domain sentiment transfer tasks, which require effective disentanglement of factors, a concept at the core of our identifiability theory. Datasets and Evaluation Schema. The proposed method is trained on four-domain datasets (Tab 1), i.e, movie (Imdb) <ref type="bibr" target="#b8">[Diao et al., 2014]</ref>, restaurant (Yelp) <ref type="bibr" target="#b33">[Li et al., 2018</ref>], ecommerce (Amazon) <ref type="bibr" target="#b33">[Li et al., 2018]</ref> and news (Yahoo) <ref type="bibr" target="#b60">[Zhang et al., 2015</ref><ref type="bibr">, Li et al., 2019]</ref>. <ref type="foot" target="#foot_3">4</ref> From common practice <ref type="bibr" target="#b59">[Yang et al., 2018</ref><ref type="bibr" target="#b29">, Lample et al., 2019]</ref>, we evaluate the generated sentences in terms of the four automatic metrics: (1) Accuracy.</p><p>We train a CNN classifier on the original style-labelled dataset, which has over 95.0% accuracy when evaluated on the four separate validation datasets. Subsequently, we employ it to evaluate the transformed sentences, gauging how effectively they convey the intended attributes. ( <ref type="formula">2</ref> For human evaluation, we invited three evaluators proficient in English to rate the sentiment reverse, semantic preservation, fluency and overall transfer quality using a 5-point Likert scale, where higher scores signify better performance. Furthermore, they were asked to rank the generated sentences produced from different models, with the option to include tied items in their ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Sentiment transfer</head><p>Baselines. We compare our model with the state-of-the-art text transfer models that do not rely on style labels, along with a supervised model, B-GST <ref type="bibr" target="#b48">[Sudhakar et al., 2019]</ref>, which is based on GPT2 <ref type="bibr" target="#b40">[Radford et al., 2019]</ref> and accomplishes style transfer through a combination of deletion, retrieval, and generation. The other VAE-based baselines can be divided into two groups based on their architecture: those with LSTM backbones and those utilizing pretrained language models (PLM). Within the LSTM group, Œ≤-VAE <ref type="bibr" target="#b15">[Higgins et al., 2017]</ref> encourages disentanglement by progressively increasing the latent code capacity. JointTrain <ref type="bibr" target="#b34">[Li et al., 2022]</ref> uses the GloVe embedding to initialize s and learns c through LSTM. CPVAE <ref type="bibr" target="#b55">[Xu et al., 2020]</ref> is the state-of-the-art unsupervised style transfer model, which maps the style variable to a k-dimensional probability simplex to model different style categories. In the PLM group, we use GPT2 <ref type="bibr" target="#b40">[Radford et al., 2019]</ref> as the backbone and introduce an additional variational layer after fine-tuning its embedding layer to generate the latent variable z, referred to as GPT2-FT. Also, we consider Optimus <ref type="bibr" target="#b30">[Li et al., 2020]</ref>, which is one of the most widely-used pretrained VAE models, utilizing BERT <ref type="bibr" target="#b7">[Devlin et al., 2019]</ref> as the encoder and GPT2 as the decoder. Quantitative performance. Among LSTM baselines in Table <ref type="table" target="#tab_1">2</ref>, Œ≤-VAE shows high sentiment transfer accuracy and fluency but poor content preservation. We observed that many generated sentences follow simple but repetitive patterns, e.g., 2.2% transferred sentences in Yelp containing the phrase "I highly recommend" while only 0.6% original sentences do. They are fluent and correctly sentiment flipped but their semantics are significantly different from the original sentences, indicating a generation degradation problem<ref type="foot" target="#foot_5">foot_5</ref> . CPVAE achieves an overall better G-Score than all the other baselines across three domains (except for Yelp). Compared with the other LTSM-based methods, its superiority in content preservation is pronounced. PLMs models achieve overall better BLEU scores compared with the LSTM group. Optimus outperforms GPT2-FT, which can be partly explained by the fact that the variational layer in Optimus has been pretrained on 1,990K Wikipedia sentences. Our model is built on top of CPVAE with the proposed causal influence modules and sparsity regularisations. It gains consistent improvements in G-score and fluency across all datasets over all the other unsupervised methods. Compared with the supervised method, despite a relatively large gap in accuracy due to the lack of supervision, our approach achieves comparable BLEU scores.</p><p>The human evaluation results in Table <ref type="table" target="#tab_3">3</ref> show that human annotators favour Optimus in terms of content preservation and fluency, but MATTE ranks the best-performing method with 58.5% support set, compared to 41.00% for Optimus.  Src3 These come in handy with those tender special moments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CPVAE</head><p>These come in handy with those sexy care employees. Optimus These are fateless in their only safe place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MATTE</head><p>These come in handy with those poorly executed characteristics. Qualitative results. We randomly selected three sentences from the test sets and analyzed the results generated by the top-performing baselines in Table <ref type="table" target="#tab_4">4</ref>. For Src 1, although all the methods successfully transfer the original sentiment of the sentence, CPVAE generates the word 'flavourful' for the content guy, resulting in an unnatural sentence. This issue arises because CPVAE fails to identify the domain-specific content-style dependency, i.e., the Src domain is in IMDB, while the transferred sentence incorrectly uses the style word 'flavourful' which is commonly used in Yelp.</p><p>While Optimus can generate relatively fluent sentences partly due to its powerful decoder, it hardly maintains the original semantics (Src 2, 3), indicating a lack of effective disentanglement between c and s. These failure modes demonstrate the importance of a proper disentanglement of content and style and modelling the causal influence between the two across domains. Benefiting from theoretical insights, our approach manages to reflect the content influence across different domains in Src 1 and retain the content information in Src2, 3. (3) After introducing the style sparsity regularization L sparsity as specified in Theorem 1, we observe a significant increase of BLEU over CausalDep, verifying Theorem 1 that the style influence sparsity facilitates content identification ¬ß4.1. (4) We further introduce L partial inspired by Theorem 2, which controls the intersection of content and style influence supports. This improvement in style identification, i.e., the recovery of accuracy over L sparsity corroborates Theorem 2. (5) The incorporation of L c-mask arrive at our full model, which further improves the style identification, consistent with our motivation in ¬ß 5.3. It also exhibits the best G-score across all the datasets, with the most predominant improvement over CausalDep on the Yahoo dataset, where the G-score increases from 21.39% to 29.01 %.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Ablation Study</head><p>The importance of content-style dependence. We demonstrate the importance of content-style dependence by visualizing the changes in negative log-likelihood (NLL) induced by different ways of style intervention, namely flipping s as in our method and flipping s which breach the content-style dependence. If the NLL increases after the style transfer, it indicates that the new variables are located in a lower density region <ref type="bibr" target="#b61">[Zheng et al., 2022</ref><ref type="bibr" target="#b55">, Xu et al., 2020]</ref>. Fig <ref type="figure" target="#fig_4">4</ref> shows the histograms of NLLs for all the Amazon test samples, both before and after a style transfer. We can see that the NLL distribution changes negligibly when we flip s, in contrast with the significant change caused by flipping s. This implies that flipping s enables better preservation of the joint distribution of the original sentence. The generated sentences resulting from flipping s exhibit a higher level of semantic fidelity to the original sentence, with a clear inverse sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Comparison with large language model</head><p>As widely recognized, large language models (LLMs) have demonstrated an impressive capability in text generation. However, we consider the principles of counterfactual generation to be complementary to the development of LLMs. We aim to leverage our theoretical insights to further enhance the capabilities of LLMs. We provide examples in Table <ref type="table">6</ref> where LLMs struggle with sentiment transfer, primarily due to their tendency to overlook the broader and implicit sentiments while accurately altering invidivual sentiment words. Consequently, it is reasonable to anticipate that LLMs could benefit from the principles of representation learning, as developed in our work.</p><p>Table 6: A Sentiment transfer example, on which ChatGPT fails to completely reverse the overall sentiment of the sentence, although it successfully negates individual words within text. In contrast, our method achieves the sentiment reversal with minimal changes. ChatGPT-p1 and ChatGPT-p2 represent results obtained from two different prompts, i.e., p1: "Flip the sentiment of the following sentences, but keep the content unchanged as much as possible."; p2: "Please invert the sentiment while preserving content as much as possible in the following sentence that originates from the original domain.". We further validate our theoretical insights within additional content-style disentanglement scenarios. As tense has a relatively sparse influence on sentences compared to their content, we choose tense (past and present) as another style for illustration. Specifically, we collect 1000 sentences in either past or present tense from the Yelp Dev set and derive their style representations, denoted as s, by feeding these sentences into our well-trained model. The projection results of CPVAE and MATTE are shown in 5. The distinct separation between the red and blue data points indicates a more discriminative and better disentangled style variabl. However, in the case of CPVAE, some blue data points are mixed within the lower portion of the red region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Visualization of style variable</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and limitations</head><p>Prior work <ref type="bibr" target="#b24">[Kong et al., 2022</ref><ref type="bibr">, Xie et al., 2023]</ref> have employed multiple domains to achieve unsupervised representation disentanglement. However, the assumed independence between the content and style variables often does not hold in real-world data distributions, particularly in natural languages. To tackle this challenge, we address the identification problem in latent-variable models by leveraging the sparsity structure in the data-generating process. This approach provides identifiability guarantees for both the content and the style variables. We have implemented a controllable text generation method based on these theoretical guarantees. Our method outperforms existing methods on various large-scale style transfer benchmark datasets, thus validating our theory. It is important to note that while our method shows promising empirical results for natural languages, the sparsity assumption (Assumption 1-iii.) may not hold for certain data distributions like images, where the style component could exert dense influences on pixel values. In such cases, we may explore other forms of inherent sparsity in the given distribution, e.g., sparse dependencies between content and style or sparse changes over multiple domains, to achieve identifiability guarantees and develop empirical approaches accordingly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Ablation Results on Amazon and Yahoo Datasets</head><p>We show the ablation study of the Amazon and Yahoo datasets in Table <ref type="table" target="#tab_6">8</ref>. The full model achieves the best G-score and PPL on the two datasets. CausalDep improves the BLEU and PPL. Œª sparsity greatly improves the content preservation at the cost of sentiment acc. After incorporating the L partial and L c-mask , the sentiment acc is recovered. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Semantic Preservation Measurement by CTC score</head><p>As BLEU has limitations in capturing semantic relatedness beyond literal word-level overlap, we adopt CTC score <ref type="bibr" target="#b6">[Deng et al., 2021]</ref> as a complementary evaluation for semantics preservation measurement. For the semantics alignment from a to b, CTC considers the matching embeddings, i.e., maximum cosine similarity of all the tokens in a with the tokens in b, and vice versa. Then, the final semantic preservation is in F1 -style definition with one direction result as precision, and the other one as recall. The evaluation results of all the baselines and MATTE are shown in Table <ref type="table" target="#tab_7">9</ref>.</p><p>The CTC score still favours Optimus and MATTE, with most inferior results on Œ≤-VAE, which are similar trends under the BLEU evaluation schema. Admittedly, the CTC score differences are less discriminative than BLEU -this phoneme is also observed in <ref type="bibr" target="#b35">Liu et al. [2022]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Diversity measurements for generated sentences</head><p>To further demonstrate the generation degradation issue-generate oversimplified and repetitious sentences, we use diversity-2 <ref type="bibr" target="#b32">[Li et al., 2016]</ref>, the ratio of distinct two-grams in all the two-grams in the generated sentences to evaluate the transferred sentences. The diversity-2 for original sentences is also included for better comparison. The results in Table <ref type="table" target="#tab_8">10</ref> show that all the other methods except for Œ≤-VAE generated sentences with similar diversity-2 as the original sentences, but the sentences generated by Œ≤-VAE have much lower diversity than the original ones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Proof for Theorem 1</head><p>The original Assumption 1 and Theorem 1 are copied below for reference.</p><p>Assumption 1 (Content identification). i. g is smooth and invertible and its inverse g -1 is also smooth.</p><p>ii. For all i ‚àà {1, . . . , d x }, there exist {z . iii. For every pair (c jc , s js ) with j c ‚àà [d c ] and j s ‚àà {d c + 1, . . . , d z }, the influence of s js is sparser than that of c jc , i.e., ‚à•G :,jc ‚à• 0 &gt; ‚à•G :,js ‚à• 0 . Theorem 1. We assume the data-generating process in Equation 1 with Assumption 1. If for given dimensions (d c , d s ), a generative model (p ƒâ, p ≈ù|ƒâ , ƒù) follows the same generating process and achieves the following objective: arg min p ƒâ ,p ≈ù,ƒù j ≈ù‚àà{dc +1,...,dz } ƒú:,j ≈ù 0 subject to:</p><formula xml:id="formula_10">p x(x) = px(x), ‚àÄx ‚àà X ,<label>(3)</label></formula><p>then the estimated variable ƒâ is an one-to-one mapping of the true variable c. That is, there exists an invertible function h c (‚Ä¢) such that ƒâ = h c (c).</p><p>Proof. We first define the notation z = [c, s] and the indeterminacy function:</p><formula xml:id="formula_11">h := ƒù-1 ‚Ä¢ g,</formula><p>which is an invertible function h : Z ‚Üí ·∫ê as g is invertible by Assumption 1-i.. According to the chain rule, we have the following relation among the Jacobian matrices:</p><formula xml:id="formula_12">J ƒù (·∫ë) = J g (z)J -1 h (z).<label>(8)</label></formula><p>We define the support notations as follows:</p><formula xml:id="formula_13">G := supp(J g (z)), ƒú := supp(J ƒù (·∫ë)), T := supp(J -1 h (z)).</formula><p>In the following, we will show that (j c , j ≈ù) / ‚àà T for any j c ‚àà {1, . . . , d c } and j ≈ù ‚àà {d c + 1, . . . , d c + d s }. That is, [J -1 h (z)] jc,j ≈ù = 0, for any j c ‚àà {1, . . . , d c } and j ≈ù ‚àà {d c + 1, . . . , d c + d s }, which implies that c is not influenced by ≈ù.</p><p>Because of Assumption 1-ii., for any i ‚àà {1, . . . , d v1 + d v2 }, there exists {z</p><formula xml:id="formula_14">(‚Ñì) } |Gi,:| ‚Ñì=1 , such that span({J g (z (‚Ñì) ) i,: } |Gi,:| ‚Ñì=1 ) = R dz Gi,: . Since {J g (z (‚Ñì) ) i,: } |Gi,:|</formula><p>‚Ñì=1 forms a basis of R dz Gi,: , for any j 0 ‚àà G i,: , we can express canonical basis vector e j0 ‚àà R dz Gi,: as:</p><formula xml:id="formula_15">e j0 = ‚Ñì‚ààGi,: Œ± ‚Ñì ‚Ä¢ J g (z (‚Ñì) ) i,: ,<label>(9)</label></formula><p>where Œ± ‚Ñì ‚àà R is a coefficient.</p><p>Also, following Assumption 1-ii., there exists a deterministic matrix T where T j1,j2 Ã∏ = 0 iff (j 1 , j 2 ) ‚àà T and</p><formula xml:id="formula_16">T j0,: = e ‚ä§ j0 T = ‚Ñì‚ààGi,: Œ± ‚Ñì ‚Ä¢ J g (z (‚Ñì) ) i,: T ‚àà R dz ƒúi,: ,<label>(10)</label></formula><p>where ‚àà is because each element in the summation belongs to R dz ƒúi,:</p><p>. Therefore, ‚àÄj ‚àà G i,: , T j,: ‚àà R dz ƒúi,:</p><p>. Equivalently, we have:</p><formula xml:id="formula_17">‚àÄ(i, j) ‚àà G, {i} √ó T j,: ‚äÇ ƒú.<label>(11)</label></formula><p>As both J g and J ƒù are invertible, J h (z) is an invertible matrix and thus has a non-zero determinant.</p><p>Expressing J h (z) with the Leibniz formulae gives:</p><formula xml:id="formula_18">det(J h (z)) = œÉ‚ààP dz Ô£´ Ô£≠ sign(œÉ) dz j=1 J g (z) œÉ(j),j Ô£∂ Ô£∏ Ã∏ = 0,<label>(12)</label></formula><p>where P dz is the set of all d z -permutations.</p><p>Equation 12 indicates that there exists œÉ ‚àà P dz , such that dz j=1 J g (z) œÉ(j),j Ã∏ = 0. Equivalently, we have ‚àÄj ‚àà [d z ], (œÉ(j), j) ‚àà T .</p><p>(13) Therefore, for a specific j ≈ù ‚àà {d c + 1, . . . , d z }, it follows that (œÉ(j ≈ù), j ≈ù) ‚àà T . Further, Equation <ref type="formula" target="#formula_17">11</ref>shows that for any i x ‚àà [d x ], s.t., (i x , œÉ(j ≈ù)) ‚àà G, we have {i x } √ó T œÉ(j ≈ù ),: ‚äÜ ƒú. Together, it follows that</p><formula xml:id="formula_19">(i x , œÉ(j ≈ù)) ‚àà G =‚áí (i x , j ≈ù) ‚àà ƒú. (<label>14</label></formula><formula xml:id="formula_20">)</formula><p>Equation 14 suggests that the column œÉ(j ≈ù) of the true generating function support G is included in the column j ≈ù of the estimated generating function support ƒú. Together with Assumption 1-iii., it follows that j ≈ù‚àà{dc +1,...,dz} ƒú:,j ≈ù 0 ‚â• js‚àà{dc+1,...,dz} ‚à•G :,js ‚à• 0 ,</p><p>where the permutation œÉ(‚Ä¢) connects the indices of s and those of ≈ù. We note that Equation 15 is a lower-bound of the objective Equation 3, which can be attained by a minimizer ƒù = g.</p><p>In the following, we show by contradiction that the support of J -1 h (z) does not contain (j c , j ≈ù), for any j c ‚àà [d c ] and any j ≈ù ‚àà {d c + 1, . . . , d c }, i.e., (j c , j ≈ù) / ‚àà T .</p><p>We suppose that a specific (j ‚Ä≤ c , j ‚Ä≤ ≈ù) ‚àà T , where j ‚Ä≤ c ‚àà [d c ] and any j ‚Ä≤ ≈ù ‚àà {d c + 1, . . . , d c }. We note that the argument for Equation 14 also applies to (j 1 , j 2 ) ‚àà T for any j 1 , j 2 ‚àà [d z ]. Thus, we would have </p><p>where the inequality (1) is due to Assumption 1-iii. that the influence of c on x is denser than that of s.</p><p>However, as discussed above, there exists an optimizer that attains the lower-bound Equation <ref type="formula" target="#formula_21">15</ref>. Equation 17 contradicts the minimization objective Equation 3. Therefore, (j ‚Ä≤ c , j ‚Ä≤ ≈ù) Ã∏ ‚àà T , for any j ‚Ä≤ c ‚àà [d c ] and any j ‚Ä≤ ≈ù ‚àà {d c + 1, . . . , d c }. As discussed above, this implies that c is not influenced by ≈ù. Further, it follows from the invertibility of h(‚Ä¢) that [J h (z)] j ƒâ ,js = 0, for any j ƒâ ‚àà {1, . . . , d c } and j s ‚àà {d c + 1, . . . , d c + d s }, which implies that ƒâ is not influenced by s. These two conditions and the invertibility of h(‚Ä¢) imply that ƒâ and c form a one-to-one mapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Proof for Theorem 2</head><p>The original Assumption iii. and Theorem 2 are copied below for reference. Assumption 2 (Partially intersecting influence supports). For every pair (c jc , s js ), the supports of their influences on x do not fully intersect, i.e., ‚à•G :,jc ‚à© G :,js ‚à• 0 &lt; min{‚à•G :,jc ‚à• 0 , ‚à•G :,js ‚à• 0 }. Theorem 2. We follow the data-generating process Equation 1 and Assumption 1 and Assumption 2. We optimize the objective function in Equation 3 together with min (j ƒâ ,j ≈ù)‚àà{1,...,dc }√ó{dc+1,...,dz} ƒú:,j ƒâ ‚à© ƒú:,j ≈ù 0 .</p><p>(4)</p><p>The estimated style variable ≈ù is a one-to-one mapping to the true variable s. That is, there exists an invertible mapping h s (‚Ä¢) between s and ≈ù, i.e., ≈ù = h s (s).</p><p>Proof. As shown in Section A.5, there exists a d z -permutation œÉ(‚Ä¢) such that ‚àÄj ‚àà [d z ], (œÉ(j), j) ‚àà T . Also, we have shown in Theorem 1 that (j c , j ≈ù) / ‚àà T for j c ‚àà [d c ] and j ≈ù ‚àà {d c + 1, . . . , d z }, which implies that œÉ(j ≈ù) ‚àà {d c + 1, . . . , d z }. Thus, it follows that for any</p><formula xml:id="formula_23">j ƒâ ‚àà [d c ], œÉ(j ƒâ) ‚àà [d c ].</formula><p>In the following, we show by contradiction that (j s , j ƒâ) Ã∏ ‚àà T for any j s ‚àà {d c + 1, . . . , d z } and j ƒâ ‚àà [d c ]. We suppose that (j ‚Ä≤ s , j ‚Ä≤ ƒâ) ‚àà T . Analogous to Equation <ref type="formula">16</ref>, we would have that (j ‚Ä≤ s , j ‚Ä≤ ƒâ) ‚àà T =‚áí (i x , j ‚Ä≤ ƒâ) ‚àà ƒú, ‚àÄi x ‚àà {i ‚àà [d x ] : (i x , j ‚Ä≤ s ) ‚àà G}.</p><p>It would follow that ƒú:,j ‚Ä≤ ƒâ ‚äá G :,œÉ(j ‚Ä≤ ƒâ ) ‚à™ G :,j ‚Ä≤ s . Also, to attain the objective Equation 3 in Theorem 1, we have j ‚Ä≤ ≈ù := œÉ -1 (j ‚Ä≤ s ) ‚àà {d c + 1, . . . , d z }, s.t., ƒú:,j ‚Ä≤ ≈ù = G :,j ‚Ä≤ s . It would follow that ƒú:,j ‚Ä≤ ƒâ ‚äá ƒú:,j ‚Ä≤ ≈ù . Further, we would have ƒú:,j ‚Ä≤ ƒâ ‚à© ƒú:,j ‚Ä≤ ≈ù 0 = ƒú:,j ‚Ä≤ ≈ù 0 = G :,j ‚Ä≤ s 0 &gt;</p><p>(2)</p><formula xml:id="formula_25">G :,œÉ(j ‚Ä≤ ƒâ ) ‚à© G :,œÉ(j ‚Ä≤ ≈ù) 0 ,<label>(19)</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: The data generation process: The grey shading indicates the variable is observed. The observed variable (i.e., text) x is generated from content c and style s. Both content c and style s are influenced by the domain variable u and the content also influences the style. s is the exogenous variable of s, representing the independent information of s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sparsity in Jg.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>) BLEU<ref type="bibr" target="#b39">[Papineni et al., 2002]</ref>. It compares the n-grams in the generated text with those in the original text, measuring how well the original content is retained 5 . (3) G-score. It represents the geometric mean of the predicted probability for the ground-truth style category and the BLEU score. Due to its comprehensive nature, it is our primary metric. (4) Fluency. It is the perplexity score of GPT-2<ref type="bibr" target="#b40">[Radford et al., 2019]</ref> -lower perplexity values indicate a higher levels of fluency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Histograms of negative log-likelihood (NLL) of 1000 Amazon test samples evaluated on the original latent variable and intervened ones. left: flips s, right flips s. The table shows the corresponding sentences. Ablation studies in Table 5 are used to verify our theoretical results in ¬ß 4 7 . On top of the backbone, CPVAE, we incrementally add each component of our method: (1)Indep considers the domain influence on c (i.e., the r c module in Fig 3), while neglecting the independence between c and s. It experiences a large accuracy boost in conjunction with a significant degradation in BLEU, suggesting poor retention of the content information. (2) CausalDep takes into account the dependency between content and style by incorporating the module r s in Fig 3. This ameliorates the content retention problem and strikes an overall better balance, as reflected by the raised BLEU score and G-score, although causal dependence in CausalDep is not sufficient for identification without proper regularization.(3) After introducing the style sparsity regularization L sparsity as specified in Theorem 1, we observe a significant increase of BLEU over CausalDep, verifying Theorem 1 that the style influence sparsity facilitates content identification ¬ß4.1. (4) We further introduce L partial inspired by Theorem 2, which controls the intersection of content and style influence supports. This improvement in style identification, i.e., the recovery of accuracy over L sparsity corroborates Theorem 2. (5) The incorporation of L c-mask arrive at our full model, which further improves the style identification, consistent with our motivation in ¬ß 5.3. It also exhibits the best G-score across all the datasets, with the most predominant improvement over CausalDep on the Yahoo dataset, where the G-score increases from 21.39% to 29.01 %.</figDesc><graphic coords="9,108.00,290.73,205.93,182.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The style variables of sentences in past-tense (blue) and presenttense (red) following a UMAP projection. Left: CPVAE; Right: MATTE.</figDesc><graphic coords="10,365.40,412.46,138.60,58.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure6: The Sentiment Acc (left) and BLEU (right) with different Œªsparsity. Among the four datasets, sentiment acc generally decreases as the Œªsparsity becomes larger; BLEU increases instead. This observation aligns with our content identifiability theory. We determine the Œªsparsity with the best G-score, i.e., 1E-4.</figDesc><graphic coords="18,136.38,70.68,338.79,109.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(‚Ñì) } |Gi,:| ‚Ñì=1 and T ‚àà T , such that span({J g (z (‚Ñì) ) i,: } |Gi,:| ‚Ñì=1 ) = R dz Gi,: and [J g (z (‚Ñì) )T] i,: ‚àà R dz ƒúi,:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>≈ù) ‚àà T =‚áí (i x , j ‚Ä≤ ≈ù) ‚àà ƒú, ‚àÄi x ‚àà {i ‚àà [d x ] : (i x , j ‚Ä≤ c ) js‚àà{dc+1,...,dz}‚à•G :,js ‚à• 0 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Dataset on four domains.</figDesc><table><row><cell>Domains</cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell>IMDB</cell><cell cols="3">344,175 27,530 27,530</cell></row><row><cell>Yelp</cell><cell cols="2">444,102 63,484</cell><cell>1000</cell></row><row><cell cols="3">Amazon 554,998 2,000</cell><cell>1,000</cell></row><row><cell>Yahoo</cell><cell>4,000</cell><cell>4,000</cell><cell>4,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>¬±0.80 50.45 ¬±2.62 32.09 ¬±1.81 48.58 ¬±2.08 82.00 ¬±0.20 32.06 ¬±1.34 35.43 ¬±0.92 50.45 ¬±2.38 LSTM Œ≤-VAE [Higgins et al., 2017] 38.27 ¬±1.03 11.37 ¬±3.03 9.05 ¬±1.19 43.59 ¬±3.07 40.30 ¬±0.92 7.58 ¬±2.73 6.86 ¬±1.08 59.34 ¬±3.81 JointTrain [Li et al., 2022] 24.13 ¬±0.52 23.26 ¬±2.85 12.28¬±1.91 70.11 ¬±2.76 14.20 ¬±0.62 31.72 ¬±1.91 12.74 ¬±0.95 84.07 ¬±2.37 CPVAE [Xu et al., 2020] 20.15 ¬±0.40 49.82 ¬±1.25 20.01 ¬±0.96 70.18 ¬±2.78 14.50 ¬±0.30 51.47 ¬±1.81 16.84 ¬±0.92 72.81 ¬±2.26 PLM GPT2-FT [Radford et al., 2019] 15.20 ¬±0.25 28.93 ¬±3.16 12.19 ¬±2.84 71.08 ¬±2.19 12.00 ¬±0.42 39.62¬±1.92 14.49 ¬±1.35 78.37 ¬±2.14 Comparison with unsupervised methods across four domain datasets with supervised B-GST as an upper bound reference. The top and the second-best results are in bold.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">IMDB</cell><cell></cell><cell></cell><cell>Yelp</cell><cell></cell></row><row><cell></cell><cell>Model</cell><cell>Acc(‚Üë)</cell><cell>BLEU(‚Üë)</cell><cell>G-score(‚Üë)</cell><cell>PPL(‚Üì)</cell><cell>Acc(‚Üë)</cell><cell>BLEU(‚Üë)</cell><cell>G-score(‚Üë)</cell><cell>PPL(‚Üì)</cell></row><row><cell></cell><cell cols="9">B-GST [Sudhakar et al., 2019] 36.20 Optimus [Li et al., 2020] 14.07 ¬±0.20 59.04 ¬±1.68 17.47 ¬±1.21 61.90 ¬±2.61 13.60 ¬±0.30 69.82 ¬±1.92 21.24 ¬±1.83 52.56 ¬±2.01</cell></row><row><cell></cell><cell>MATTE</cell><cell cols="8">32.43 ¬±0.28 45.10 ¬±2.91 25.92 ¬±1.62 50.08 ¬±2.02 34.30 ¬±0.26 50.14 ¬±2.51 26.34 ¬±1.37 51.51 ¬±2.09</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Amazon</cell><cell></cell><cell></cell><cell cols="2">Yahoo</cell></row><row><cell></cell><cell>Model</cell><cell>Acc(‚Üë)</cell><cell>BLEU(‚Üë)</cell><cell>G-score(‚Üë)</cell><cell>PPL(‚Üì)</cell><cell>Acc(‚Üë)</cell><cell>BLEU(‚Üë)</cell><cell>G-score(‚Üë)</cell><cell>PPL(‚Üì)</cell></row><row><cell></cell><cell>B-GST [Sudhakar et al., 2019]</cell><cell cols="8">60.45 ¬±0.65 56.02 ¬±2.36 47.67 ¬±1.68 49.01 ¬±3.18 84.30 ¬±0.40 40.39 ¬±2.81 38.65 ¬±1.64 58.20 ¬±2.19</cell></row><row><cell>LSTM</cell><cell>Œ≤-VAE Higgins et al. [2017] JointTrain Li et al. [2022] CPVAE Xu et al. [2020]</cell><cell cols="8">50.08¬±0.68 32.90 ¬±0.42 23.21 ¬±2.16 18.33 ¬±1.07 84.63¬±2.76 35.33 ¬±0.28 14.04 ¬±1.72 11.62¬±0.92 67.34 ¬±2.84 8.04 ¬±2.62 9.39 ¬±1.24 33.09 ¬±2.53 55.47 ¬±0.40 3.77 ¬±1.32 5.85 ¬±1.71 52.17 ¬±3.06 32.60 ¬±0.20 41.08 ¬±1.28 30.08 ¬±1.15 77.61 ¬±3.12 43.92 ¬±0.30 25.44 ¬±1.37 20.28 ¬±0.95 76.28 ¬±2.67</cell></row><row><cell>PLM</cell><cell cols="9">GPT2-FT [Radford et al., 2019] 30.46 ¬±0.30 40.34¬±2.82 26.72¬±1.93 79.36¬±2.63 17.90 ¬±0.40 44.19 ¬±1.86 15.99 ¬±1.11 70.99 ¬±2.37 Optimus [Li et al., 2020] 24.80 ¬±0.20 62.50 ¬±1.55 28.53 ¬±1.22 74.66 ¬±3.10 27.10 ¬±0.15 32.73 ¬±1.82 19.17 ¬±1.69 73.18 ¬±2.76</cell></row><row><cell></cell><cell>MATTE</cell><cell cols="8">34.50 ¬±0.24 52.25 ¬±1.48 35.73 ¬±1.14 63.37 ¬±2.22 38.45 ¬±0.20 42.40 ¬±1.35 29.01 ¬±2.30 56.12 ¬±2.57</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Human evaluation results from Optimus It is a long time now and I always get this food. MATTE I had it a long time now and I never played it.</figDesc><table><row><cell>three annotators. The Cohen's Kappa co-</cell></row><row><cell>efficient among every two annotators over</cell></row><row><cell>the Best-rank is 0.46. Human annotators</cell></row><row><cell>favour Optimus in terms of content preser-</cell></row><row><cell>vation and fluency, but MATTE ranks the</cell></row><row><cell>best-performing method with more than</cell></row><row><cell>58% support set after considering the style</cell></row><row><cell>reverse success rate.</cell></row></table><note><p><p><p><p><p><p><p>Src1: This guy is an awful actor. .</p>CPVAE</p>The guy is very flavorful. Optimus The guy is an amazing actor.</p>MATTE</p>This guy is an amazing actor! Src2: I had it a long time now and I still love it.</p>CPVAE</p>I had it a long time before and I've never eaten it.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Generated style-transferred Sentences. , represent sentiment polarity.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Ablation results on sentiment transfer on two domains. CausalDep incorporates style flow rs to model dependency of c on s, while Indep assumes the independence between the two variables. ‚ñ≤ marks the improvements overBackbone, while ‚ñ≥ over the CausalDep.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>IMDB</cell><cell></cell><cell></cell><cell></cell><cell>Yelp</cell><cell></cell></row><row><cell>Model</cell><cell cols="8">Acc(‚Üë) BLEU(‚Üë) G-score(‚Üë) PPL(‚Üì) Acc(‚Üë) BLEU(‚Üë) G-score(‚Üë) PPL(‚Üì)</cell></row><row><cell>Backbone</cell><cell>20.15</cell><cell>49.82</cell><cell>20.01</cell><cell>70.18</cell><cell>14.50</cell><cell>51.47</cell><cell>16.84</cell><cell>72.81</cell></row><row><cell cols="3">Indep [Kong et al., 2022] 45.00 ‚ñ≤ 30.88</cell><cell>19.89</cell><cell cols="3">61.85 ‚ñ≤ 61.90 ‚ñ≤ 25.67</cell><cell>21.24 ‚ñ≤</cell><cell>73.78</cell></row><row><cell>CausalDep</cell><cell cols="2">28.71 ‚ñ≤ 39.63</cell><cell>21.85 ‚ñ≤</cell><cell cols="3">53.25 ‚ñ≤ 22.10 ‚ñ≤ 48.98</cell><cell>25.98 ‚ñ≤</cell><cell>55.14 ‚ñ≤</cell></row><row><cell>:w. / L sparsity</cell><cell>21.55</cell><cell>56.59 ‚ñ≥</cell><cell>20.90</cell><cell>65.26</cell><cell>13.20</cell><cell>56.26 ‚ñ≥</cell><cell>14.59</cell><cell>54.10 ‚ñ≥</cell></row><row><cell>:w. / L partial</cell><cell cols="2">30.18 ‚ñ≥ 51.95</cell><cell>25.57 ‚ñ≥</cell><cell>54.66</cell><cell cols="2">33.70 ‚ñ≥ 49.09</cell><cell>25.81 ‚ñ≥</cell><cell>52.87 ‚ñ≥</cell></row><row><cell>:w. / L c-mask (Full)</cell><cell cols="2">32.43 ‚ñ≥ 45.10</cell><cell>25.92 ‚ñ≥</cell><cell cols="3">50.08 ‚ñ≥ 34.30 ‚ñ≥ 50.14</cell><cell>26.34 ‚ñ≥</cell><cell>51.51 ‚ñ≥</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 :</head><label>8</label><figDesc>Ablation results on sentiment transfer on two domains. CausalDep incorporates style flow rs to model dependency of c on s, while Indep assumes the independence between the two variables. ‚ñ≤ marks the improvements overBackbone, while ‚ñ≥ over the CausalDep.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Amazon</cell><cell></cell><cell></cell><cell></cell><cell>Yahoo</cell><cell></cell></row><row><cell>Model</cell><cell>Acc(‚Üë)</cell><cell cols="3">BLEU(‚Üë) G-score(‚Üë) PPL(‚Üì)</cell><cell>Acc(‚Üë)</cell><cell cols="3">BLEU(‚Üë) G-score(‚Üë) PPL(‚Üì)</cell></row><row><cell>Backbone</cell><cell>32.60</cell><cell>41.08</cell><cell>30.08</cell><cell>77.61</cell><cell>43.92</cell><cell>25.44</cell><cell>20.28</cell><cell>76.28</cell></row><row><cell cols="2">Indep [Kong et al., 2022] 48.80 ‚ñ≤</cell><cell>39.50</cell><cell>31.76 ‚ñ≤</cell><cell>77.95</cell><cell>51.70</cell><cell>23.44</cell><cell>21.12 ‚ñ≤</cell><cell>56.95 ‚ñ≤</cell></row><row><cell>CausalDep</cell><cell>33.50 ‚ñ≤</cell><cell>45.25 ‚ñ≤</cell><cell>32.54 ‚ñ≤</cell><cell>66.98 ‚ñ≤</cell><cell>41.50</cell><cell>31.55 ‚ñ≤</cell><cell>21.39 ‚ñ≤</cell><cell>64.29 ‚ñ≤</cell></row><row><cell>:w. / Lsparsity</cell><cell>27.10</cell><cell>62.73 ‚ñ≥</cell><cell>34.73 ‚ñ≥</cell><cell cols="2">63.37 ‚ñ≥ 27.32</cell><cell>48.21 ‚ñ≥</cell><cell>25.16 ‚ñ≥</cell><cell>60.03 ‚ñ≥</cell></row><row><cell>:w. / Lpartial</cell><cell>33.10</cell><cell>58.54 ‚ñ≥</cell><cell>34.04</cell><cell>64.42</cell><cell cols="2">38.12 ‚ñ≥ 41.74</cell><cell>28.03 ‚ñ≥</cell><cell>58.04 ‚ñ≥</cell></row><row><cell>:w. / Lc-mask(Full)</cell><cell cols="2">34.50 ‚ñ≥ 52.25</cell><cell>35.73 ‚ñ≥</cell><cell cols="3">63.37 ‚ñ≥ 38.45 ‚ñ≥ 42.40 ‚ñ≥</cell><cell>29.01 ‚ñ≥</cell><cell>56.12 ‚ñ≥</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 :</head><label>9</label><figDesc>CTC score, a complementary evaluation for semantics preservation. Œ≤-VAE displays the least impressive performance, and Optimus and Matte exhibit the overall best results.</figDesc><table><row><cell></cell><cell></cell><cell>IMDB Yelp</cell><cell cols="2">Amazon Yahoo</cell></row><row><cell></cell><cell>BGST</cell><cell>0.468 0.458</cell><cell>0.472</cell><cell>0.458</cell></row><row><cell></cell><cell>Œ≤-VAE</cell><cell>0.436 0.433</cell><cell>0.433</cell><cell>0.413</cell></row><row><cell></cell><cell>JointTrain</cell><cell>0.456 0.462</cell><cell>0.455</cell><cell>0.437</cell></row><row><cell></cell><cell>CPVAE</cell><cell>0.462 0.463</cell><cell>0.461</cell><cell>0.443</cell></row><row><cell></cell><cell>GPT2-FT</cell><cell>0.459 0.459</cell><cell>0.458</cell><cell>0.448</cell></row><row><cell></cell><cell>Optimus</cell><cell>0.465 0.468</cell><cell>0.465</cell><cell>0.446</cell></row><row><cell></cell><cell>Matte</cell><cell>0.465 0.464</cell><cell>0.466</cell><cell>0.452</cell></row><row><cell>Dataset</cell><cell cols="4">IMDB (0.34) Yelp (0.63) Amazon (0.64) Yahoo(0.44)</cell></row><row><cell>Œ≤-VAE</cell><cell>0.11</cell><cell>0.46</cell><cell>0.37</cell><cell>0.22</cell></row><row><cell cols="2">JointTrain 0.21</cell><cell>0.59</cell><cell>0.56</cell><cell>0.37</cell></row><row><cell>CPVAE</cell><cell>0.32</cell><cell>0.59</cell><cell>0.57</cell><cell>0.45</cell></row><row><cell>MATTE</cell><cell>0.32</cell><cell>0.62</cell><cell>0.61</cell><cell>0.45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 10 :</head><label>10</label><figDesc>Diversity-2 for the transferred sentences. Diversity for the original sentences is included in the bracket for comparison. Œ≤-VAE has significantly fewer distinct 2-gram than original datasets. This results are consistent with evaluation results on BLEU.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>As our theory is not contingent on the availability of multiple domains, we drop the domain index u in our notations in this section for ease of exposition.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>For the sake of simplicity, in this section, we discuss estimated variables without the ‚Ä¢ notation, as in ¬ß</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Dataset and detailed experiment configurations can be found in Appendix, A.1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>We also adopt CTC score<ref type="bibr" target="#b6">[Deng et al., 2021]</ref>, to mitigate potential issues brought by the word-overlap measurements in BLEU, as it considers the matching embeddings. The evaluation results are shown in Table9.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>The diversity-n<ref type="bibr" target="#b32">[Li et al., 2016]</ref> also indicates repetitious pattern and the evaluation results are in Table10.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>The results on Amazon and Yahoo are in Appendix, Table</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8"><p>https://stanfordnlp.github.io/stanfordnlp/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9"><p>The implementation refers to ConditionedSpline in https://docs.pyro.ai/en/stable/_modules/ pyro/distributions/transforms/spline.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank anonymous reviewers for their constructive feedback. This work was funded by the <rs type="funder">UK Engineering and Physical Sciences Research Council</rs> (grant no. <rs type="grantNumber">EP/T017112/1</rs>, <rs type="grantNumber">EP/T017112/2</rs>, <rs type="grantNumber">EP/V048597/1</rs>, <rs type="grantNumber">EP/X019063/1</rs>). YH is supported by a <rs type="grantName">Turing AI Fellowship</rs> funded by the <rs type="funder">UK Research and Innovation</rs> (grant no. <rs type="grantNumber">EP/V020579/1</rs>, <rs type="grantNumber">EP/V020579/2</rs>). The work of LK and YC is supported in part by <rs type="funder">NSF</rs> under the grants <rs type="grantNumber">CCF-1901199</rs> and <rs type="grantNumber">DMS-2134080</rs>. This project is also partially supported by <rs type="funder">NSF</rs> Grant <rs type="grantNumber">2229881</rs>, the <rs type="funder">National Institutes of Health (NIH)</rs> under Contract <rs type="grantNumber">R01HL159805</rs>, a grant from <rs type="funder">Apple Inc.</rs>, a grant from <rs type="funder">KDDI Research Inc.</rs>, and generous gifts from <rs type="funder">Salesforce Inc.</rs>, <rs type="funder">Microsoft Research</rs>, and <rs type="funder">Amazon Research</rs>.</p></div>
			</div>
			
			<div type="funding">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Src:</head><p>The buttons to extend the arms worked exactly one time before breaking. ChatGPT-p1: The buttons to extend the arms failed to work from the beginning, never functioning even once. ChatGPT-p2: The buttons to extend the arms never worked, even once, and remained functional until they broke. Our: The buttons to extend the arms worked exactly as described. Src: I love that it uses natural ingredients but it was ineffective on my skin. ChatGPT-p1: I dislike that it uses natural ingredients, but it was highly effective on my skin. ChatGPT-p2: I dislike that it uses natural ingredients, but it was highly effective on my skin. Our: I like that it uses natural ingredients, and it was also good. Src: This case is cute however this is the only good thing about it. ChatGPT-p1: This case is not cute; however, it is the only good thing about it. ChatGPT-p2: This case is not cute at all; however, it is the only bad thing about it. Ours:This case is cute and overall a valuable product.</p></div>
			</div>


			<listOrg type="funding">
				<org type="funding" xml:id="_5mR3nDY">
					<idno type="grant-number">EP/T017112/1</idno>
				</org>
				<org type="funding" xml:id="_gPBzaGW">
					<idno type="grant-number">EP/T017112/2</idno>
				</org>
				<org type="funding" xml:id="_G87h7xD">
					<idno type="grant-number">EP/V048597/1</idno>
				</org>
				<org type="funding" xml:id="_PBhEdjJ">
					<idno type="grant-number">EP/X019063/1</idno>
					<orgName type="grant-name">Turing AI Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_8EjHwNc">
					<idno type="grant-number">EP/V020579/1</idno>
				</org>
				<org type="funding" xml:id="_wtnGfGG">
					<idno type="grant-number">EP/V020579/2</idno>
				</org>
				<org type="funding" xml:id="_UZFvcNG">
					<idno type="grant-number">CCF-1901199</idno>
				</org>
				<org type="funding" xml:id="_bQr6dUS">
					<idno type="grant-number">DMS-2134080</idno>
				</org>
				<org type="funding" xml:id="_eyp42mR">
					<idno type="grant-number">2229881</idno>
				</org>
				<org type="funding" xml:id="_BgyGvEV">
					<idno type="grant-number">R01HL159805</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Implementation Details</head><p>In this section, we first introduce the dataset. We then provide the network architecture details of MATTE. The hyperparameter selection criteria and the training details are summarized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.1 Dataset</head><p>We use four domain datasets to train our unsupervised model, i.e., Imdb, Yelp, Amazon and Yahoo, and follow the data split provided by <ref type="bibr" target="#b31">Li et al. [2019]</ref>. The datasets can be downloaded via <ref type="url" target="https://github.com/cookielee77/DAST">https://github.com/cookielee77/DAST</ref>. The dataset details can be found in Table <ref type="table">1</ref>. We set the sequence length L as 25, which is the 90 percentile of the sentence length of the training dataset. Therefore, shorter sentences are padded and longer sentences are clipped. The vocabulary size is set to 10000. For the sentiment transfer, we collect 100 positive sentences in dev set based on their sentiment labels to derive s transfer to flip the sentiment of the negative sentences in the test set, and vice versa. For the tense transfer, we use stanfordnlp tool 8 to identify the tense for the main verb, then collect 100 sentences of present tense in dev set to derive s transfer to flip the past-tense sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.2 Model Architecture</head><p>We summarize our network architecture below and describe it in detail in Table <ref type="table">7</ref>.</p><p>Encoder: According to <ref type="bibr" target="#b55">Xu et al. [2020]</ref>, the encoder is fed with a text span x[t 1 : t 1 + m] extracted from the original sentence x, where t 1 is a random word position index, m is set to 10 if t 1 + m is smaller than L. H word is the word embedding dimension, set to 256. H lstm is the hidden states of LSTM, set to 1024. H z is the dimension of the latent variable, set to 80. The output of the encoder is the ¬µ, œÉ and z. All of them are in shape [BS, H z ].</p><p>Decoder: Decoder is fed with the input sentence span and the generated latent variable. The final reconstructed sentence span is one timestamp delay compared to the input span, i.e., x t1+1:(t1+1)+m . This is generated by applying beam search to the sequence of output probability over the vocabulary V . The L recon is to calculate the cross-entropy loss between the output probability and target sequence span.</p><p>Content Flow r c : We apply Deep Dense Sigmoid Flow (DDSF) <ref type="bibr" target="#b17">[Huang et al., 2018]</ref> to derive the content noise term. To incorporate the domain information, we leverage the domain embedding (after MLP) to parameterize the flow model. Style Flow r s : We apply spline flow <ref type="bibr" target="#b10">[Durkan et al., 2019]</ref> to derive the noise term. Similarly, we use the conditional flow 9 with extra input. The conditional input is the combination of content variable and domain embedding. Specially, they are concatenated firstly and the result are fed into a MLP with Tanh activation to derive a attention score Œ± The conditional input is actually the doctProdcut.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.3 Training</head><p>Training details. The models were implemented in PyTorch 2.0. and Python 3.9. The VAE network is trained for a maximum of 25 epochs and a mini-batch size of 64 is used. We use early stops if the validation reconstruction loss does not decrease for three epochs. For the encoder, we use the Adam optimizer and the learning rate of 0.001. For the decoder, we use SGD with a learning rate of 0.1. For the content and style flow, we use Adam optimizer and the learning rate is 0.001. We set three different random seeds and report the average results.</p><p>Training objective. The VAE-based model is mainly trained with L recon and L VAE . We use a training trick to better jointly train the other three objectives. The L sparsity could cram the information of s to c, while the L c-mask is used to prevent the ill-posed situation where s have zero influence. Therefore, we involve both L sparsity and L c-mask at the beginning of the training phrase. For L partial , it is used to sparsify the influence intersection but their separate influences change very frequently in the initial training stages. So we involve it after 3 epochs.</p><p>Computing hardware and running time. We used a machine with the following CPU specifications: AMD EPYC 7282 CPU. We use NVIDIA GeForce RTX 3090 with 24GB GPU memory. It costs approximately 190ms to run our model on this machine per epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Additional Results</head><p>This section presents additional results on the hyperparameter sensitivity and the ablation studies on more datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Hyperparameter Sensitivity</head><p>We discuss the effect of the three loss weights Œª sparsity ,Œª partial and Œª c-mask in the training objective. We have performed a grid search of</p><p>The model performance is relatively sensitive to Œª sparsity , so we plot the sentiment accuracy and BLEU as a function of Œª sparsity in Figure <ref type="figure">6</ref>.</p><p>where (2) is due to Assumption 2.</p><p>We note that the lower-bound for Equation 4 is (j ƒâ ,j ≈ù)‚àà{1,...,dc }√ó{dc+1,...,dz} ƒú:,j ƒâ ‚à© ƒú:,j ≈ù 0 ‚â• (j ƒâ ,j ≈ù )‚àà{1,...,dc}√ó{dc+1,...,dz} G :,œÉ(j ƒâ ) ‚à© G :,œÉ(j ≈ù) 0</p><p>(20)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>=</head><p>(jc,js)‚àà{1,...,dc}√ó{dc+1,...,dz}</p><p>which can be achieved by G = ƒú. Note that the lower-bounds for both Equation 3 and Equation 4 can be attained simultaneously by G = ƒú. Hence, optimizing the sum of the two objectives does not alter the optimal value of either.</p><p>Applying a similar argument as that in Equation <ref type="formula">15</ref>, we would have that (j ƒâ ,j ≈ù)‚àà{1,...,dc }√ó{dc+1,...,dz} ƒú:,j ƒâ ‚à© ƒú:,j ≈ù 0 = (j ƒâ ,j ≈ù)‚àà{1,...,dc }√ó{dc+1,...,dz}\{(j </p><p>where ( <ref type="formula">3</ref>) is due to Equation 19. Hence, this was not the minimizer of Equation <ref type="formula">4</ref>. By contradiction, we have that (j s , j ƒâ) / ‚àà T for any j s ‚àà {d c + 1, . . . , d z } and j ƒâ ‚àà [d c ]. This implies that s is not influenced by ƒâ. Further, it follows from the invertibility of h(‚Ä¢) that [J h (z)] j ≈ù,jc = 0, for any j ≈ù ‚àà {d c +1, . . . , d z } and j c ‚àà [d c ], which implies that ≈ù is not influenced by c. These two conditions and the invertibility of h(‚Ä¢) imply that ≈ù and s form a one-to-one mapping.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An information-maximization approach to blind separation and blind deconvolution</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1129" to="1159" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DoCoGen: Domain counterfactual generation for low resource domain adaptation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Calderon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reichart</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-long.533</idno>
		<ptr target="https://aclanthology.org/2022.acl-long.533" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7727" to="7746" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Counterfactuals and causability in explainable artificial intelligence: Theory, algorithms, and applications</title>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jorge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="59" to="83" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Independent component analysis, a new concept</title>
		<author>
			<persName><forename type="first">P</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="314" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Style transformer: Unpaired text style transfer without disentangled latent representation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1601</idno>
		<ptr target="https://aclanthology.org/P19-1601" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="5997" to="6007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Plug and play language models: A simple approach to controlled text generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dathathri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1edEyBKDS" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Compression, transduction, and creation: A unified framework for evaluating natural language generation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.emnlp-main.599</idno>
		<ptr target="https://aclanthology.org/2021.emnlp-main.599" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11">Nov. 2021</date>
			<biblScope unit="page" from="7580" to="7605" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<title level="s">Long and Short Papers</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">June 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars)</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Invertible generative modeling using linear rational splines</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Dolatabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v108/dolatabadi20a.html" />
	</analytic>
	<monogr>
		<title level="m">The 23rd International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Calandra</surname></persName>
		</editor>
		<meeting><address><addrLine>Palermo, Sicily, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-08-28">2020, 26-28 August 2020. 2020</date>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="4236" to="4246" />
		</imprint>
	</monogr>
	<note>PMLR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural spline flows</title>
		<author>
			<persName><forename type="first">C</forename><surname>Durkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bekasov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Cf-vae: Causal disentangled representation learning with vae and causal flows</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.09010</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The incomplete rosetta stone problem: Identifiability results for multi-view nonlinear ica</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mehrjou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hidden markov nonlinear ica: Unsupervised learning from nonstationary time series</title>
		<author>
			<persName><forename type="first">H</forename><surname>H√§lv√§</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvarinen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="939" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A probabilistic formulation of unsupervised text style transfer</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<idno>CoRR, abs/2002.03912</idno>
		<ptr target="https://arxiv.org/abs/2002.03912" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
		<author>
			<persName><surname>Vae</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Sy2fzU9gl" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Toward controlled generation of text</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural autoregressive flows</title>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2078" to="2087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Nonlinear independent component analysis: Existence and uniqueness results</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyv√§rinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="429" to="439" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Nonlinear ica using auxiliary variables and generalized contrastive learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="859" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Disentangled representation learning for non-parallel text style transfer</title>
		<author>
			<persName><forename type="first">V</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bahuleyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vechtomova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><forename type="middle">A</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>M√†rquez</surname></persName>
		</author>
		<author>
			<persName><surname>Editors</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p19-1041</idno>
		<ptr target="https://doi.org/10.18653/v1/p19-1041" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08-02">July 28-August 2, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="424" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">CTRL: A conditional transformer language model for controllable generation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno>CoRR, abs/1909.05858</idno>
		<ptr target="http://arxiv.org/abs/1909.05858" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Variational autoencoders and nonlinear ica: A unifying framework</title>
		<author>
			<persName><forename type="first">I</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hyvarinen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2207" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Partial disentanglement for domain adaptation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Akinwande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11455" to="11472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Identification of nonlinear latent hierarchical models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Understanding masked autoencoders via hierarchical latent variable models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2023-06">June 2023b</date>
			<biblScope unit="page" from="7918" to="7928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Variational inference of disentangled latent concepts from unlabeled observations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Balakrishnan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1kG7GZAW" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Disentanglement via mechanism sparsity regularization: A new principle for nonlinear ica</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Everett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Le Priol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Causal Learning and Reasoning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="428" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiple-attribute text rewriting</title>
		<author>
			<persName><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimus: Organizing sentences via pre-trained modeling of a latent space</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.378</idno>
		<ptr target="https://aclanthology.org/2020.emnlp-main.378" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11">Nov. 2020</date>
			<biblScope unit="page" from="4678" to="4699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Domain adaptive text style transfer</title>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1325</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1325" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">November 3-7, 2019. 2019</date>
			<biblScope unit="page" from="3302" to="3311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1014</idno>
		<ptr target="https://aclanthology.org/N16-1014" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Delete, retrieve, generate: a simple approach to sentiment and style transfer</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-1169</idno>
		<idno>doi: 10.18653</idno>
		<ptr target="https://doi.org/10.18653/v1/n18-1169" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Ji</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Stent</surname></persName>
		</editor>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">June 1-6, 2018. 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="18" to="1169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Low resource style transfer via domain adaptive meta learning</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.naacl-main.220</idno>
		<ptr target="https://doi.org/10.18653/v1/2022.naacl-main.220" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Carpuat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Marneffe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">V M</forename><surname>Ru√≠z</surname></persName>
		</editor>
		<meeting>the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022<address><addrLine>Seattle, WA, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">July 10-15, 2022. 2022</date>
			<biblScope unit="page" from="3014" to="3026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<title level="m">Composable text controls in latent space with odes</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Weakly-supervised disentanglement without compromises</title>
		<author>
			<persName><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>R√§tsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tschannen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="6348" to="6359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Disentangling disentanglement in variational autoencoders</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rainforth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Siddharth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/mathieu19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</editor>
		<meeting>the 36th International Conference on Machine Learning, ICML<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06">2019, 9-15 June 2019. 2019</date>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="4402" to="4412" />
		</imprint>
	</monogr>
	<note>PMLR</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An identifiable double vae for disentangled representations</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Filippone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Michiardi</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v139/mita21a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Meila</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021-07">Jul 2021</date>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
	<note>PMLR</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
		<ptr target="https://aclanthology.org/P02-1040/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">July 6-12, 2002. 2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Dear sir or madam, may i introduce the gyafc dataset: Corpus, benchmarks and metrics for formality style transfer</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter</title>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Textsettr: Label-free text style extraction and tunable targeted restyling</title>
		<author>
			<persName><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Uthus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Parekh</surname></persName>
		</author>
		<idno>CoRR, abs/2010.03802</idno>
		<ptr target="https://arxiv.org/abs/2010.03802" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><surname>Tailor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.07150</idno>
		<title level="m">Generating and perturbing text with semantic controls</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Semi-supervised text style transfer: Cross projection in latent space</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Style transfer from non-parallel text by crossalignment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<idno>CoRR, abs/1705.09655</idno>
		<ptr target="http://arxiv.org/abs/1705.09655" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Sorrenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>K√∂the</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04872</idno>
		<title level="m">Disentanglement by nonlinear ica with general incompressibleflow networks (gin)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">transforming&quot; delete, retrieve, generate approach for controlled text style transfer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sudhakar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maheswaran</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1322</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1322" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">November 3-7, 2019. 2019</date>
			<biblScope unit="page" from="3267" to="3277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Self-supervised learning with data augmentations provably isolates content from style</title>
		<author>
			<persName><forename type="first">J</forename><surname>Von K√ºgelgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sch√∂lkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Besserve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04619</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Controllable gradient item retrieval</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="768" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Controllable unsupervised text attribute transfer via editing entangled latent representation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Harnessing pre-trained neural networks with rules for formality style transfer</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3573" to="3578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multi-domain image generation and translation with identifiability guarantees</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=U2g8OGONA_V" />
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On variational learning of controllable representations for text without supervision</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C K</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On variational learning of controllable representations for text without supervision</title>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C K</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v119/xu20a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning, ICML 2020</title>
		<meeting>the 37th International Conference on Machine Learning, ICML 2020</meeting>
		<imprint>
			<date type="published" when="2020-07-18">13-18 July 2020. 2020</date>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="10534" to="10543" />
		</imprint>
	</monogr>
	<note>PMLR</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Formality style transfer with hybrid textual annotations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<idno>ArXiv, abs/1903.06353</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">FUDGE: controlled text generation with future discriminators</title>
		<author>
			<persName><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hakkani-T√ºr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.276</idno>
		<ptr target="https://doi.org/10.18653/v1/2021.naacl-main.276" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021">June 6-11, 2021</date>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Nonlinear ICA using volumepreserving transformations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=AMpki9kp8Cn" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Unsupervised text style transfer using language models as discriminators</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">On the identifiability of nonlinear ICA: Sparsity and beyond</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Wo1HF2wWNZb" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Belgrave</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017-10">Oct 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Contrastive learning inverts the data generating process</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
