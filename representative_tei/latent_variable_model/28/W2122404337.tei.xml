<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic Alignment Models for Neural Coding</title>
				<funder ref="#_PaTFZJW">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
				<funder ref="#_5xEzsdP">
					<orgName type="full">European Research Council</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2014-03-13">March 13, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sepp</forename><surname>Kollmorgen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Richard</forename><forename type="middle">H R</forename><surname>Hahnloser</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Neuroinformatics</orgName>
								<orgName type="institution">University of Zurich/ETH Zurich</orgName>
								<address>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Indiana University</orgName>
								<address>
									<country key="US">United States of America</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic Alignment Models for Neural Coding</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-03-13">March 13, 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1371/journal.pcbi.1003508</idno>
					<note type="submission">Received March 3, 2013; Accepted January 28, 2014;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, there have been remarkable advances in modeling the relationships between the sensory environment, neuronal responses, and behavior. However, most models cannot encompass variable stimulus-response relationships such as varying response latencies and state or context dependence of the neural code. Here, we consider response modeling as a dynamic alignment problem and model stimulus and response jointly by a mixed pair hidden Markov model (MPH). In MPHs, multiple stimulus-response relationships (e.g., receptive fields) are represented by different states or groups of states in a Markov chain. Each stimulus-response relationship features temporal flexibility, allowing modeling of variable response latencies, including noisy ones. We derive algorithms for learning of MPH parameters and for inference of spike response probabilities. We show that some linear-nonlinear Poisson cascade (LNP) models are a special case of MPHs. We demonstrate the efficiency and usefulness of MPHs in simulations of both jittered and switching spike responses to white noise and natural stimuli. Furthermore, we apply MPHs to extracellular single and multi-unit data recorded in cortical brain areas of singing birds to showcase a novel method for estimating response lag distributions. MPHs allow simultaneous estimation of receptive fields, latency statistics, and hidden state dynamics and so can help to uncover complex stimulus response relationships that are subject to variable timing and involve diverse neural codes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Neural response models are used to relate neural activity to sensory stimuli and motor behavior. A very common type of neural response model is comprised of a linear stage, at which one or more linear filters (often referred to as receptive fields) are applied to the stimulus, and a subsequent non-linear stage that converts the filter outputs into a spiking probability that feeds into a Poisson process generating the spikes <ref type="bibr" target="#b0">[1]</ref>. More precisely, the spiking probability (i.e., the instantaneous rate of the Poisson process) of a neuron is modeled as P spike S j ð Þ ~f BS ð Þ, where the column vector S represents the stimulus, f the nonlinearity, and B is a row vector containing the linear filter or a matrix in case of several filters. Variations of these linear-nonlinear Poisson cascade models (LNP models) have been studied extensively <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. Parameter estimation techniques range from spike triggered averaging in case of one linear filter and white noise stimuli, to spike triggered covariance <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref> in case of several linear filters, and maximally informative dimensions, in case of one or several linear filters and no restrictions on the distribution of stimuli <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>. Although these techniques are effective in many domains, they fail in others, where the neural code might be more intricate (detailed below).</p><p>A crucial assumption about the relationship between stimulus and response inherent in these techniques is that the response latency of the cell, the filters (or receptive fields), and the nonlinearity all are assumed to be the same throughout the experiment (Fig. <ref type="figure" target="#fig_0">1A</ref>). This assumption of a fixed stimulus-response relationship is, however, not necessarily valid. On the one hand, the relationship between stimulus and response, the neural code, could vary in time (Fig. <ref type="figure" target="#fig_0">1C</ref>). On the other hand, the response latency could be noisy or vary systematically (Fig. <ref type="figure" target="#fig_0">1A</ref>).</p><p>The extent to which a fixed stimulus-response relationship applies to neurophysiological data is unclear. In terms of spike timing, a fixed relationship entails both constant response latency and an amount of spike-time-jitter that is smaller than the relevant temporal structure of the receptive field. However, noisy response latencies (Fig. <ref type="figure" target="#fig_0">1A</ref>) are observed in almost all electrophysiological studies because neural systems are intrinsically noisy. Variations in response latency to a repeated stimulus (measured as the standard deviation of time of first spike after stimulus onset) in the range of 3-5 ms have been reported already at a very low stage of the visual system, in retinal ganglion cells <ref type="bibr" target="#b6">[7]</ref>. Variability in response latency can be notably larger in cortical areas. For instance, variations in first-spike latency (again measured as the standard deviation) of up to 12.5 ms have been observed in single cells in ferret primary visual cortex in response to flashed natural images <ref type="bibr" target="#b7">[8]</ref>. Furthermore, systematically varying response latencies have been demonstrated in various model systems, e.g., image contrast modulates response latency both in retinal ganglion cells <ref type="bibr" target="#b8">[9]</ref> and in visual cortical neurons <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>, fueling discussions about the role of spike latency in neural coding <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. In a recent study, latencies of cells in macaque inferotemporal cortex were found to systematically differ for primate and non-primate face stimuli, with latency differences on the order of tens of milliseconds <ref type="bibr" target="#b13">[14]</ref>.</p><p>When latencies are strongly fluctuating or spike time-jitter is large, many modeling techniques that assume a fixed stimulusresponse relationship, such as spike triggered averaging, yield suboptimal results <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>: The estimated receptive fields are blurred and the accuracy of predicted responses to novel stimuli is low (Fig. <ref type="figure" target="#fig_0">1B</ref>).</p><p>Fixed stimulus-response relationships can also be violated in case of changes in intrinsic or hidden brain states <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. For example, neurons in the primary somatosensory cortex of the rat undergo up and down states given by two separate membrane potentials. Spiking responses to whisker deflections in these cells are dependent on whether neurons are in the up or the down state: in the down state, a reliable response is observed, whereas in the up state activity is largely stimulus independent <ref type="bibr" target="#b18">[19]</ref>. Stimulus context can also induce changes in internal states. For instance, in an awake marmoset study of single-unit responses in the auditory cortex to sequences of 2 sound stimuli, responses to the second stimulus were not static but depended strongly on the first stimulus. This modulation in second-stimulus responses can last longer than 1.5 seconds <ref type="bibr" target="#b19">[20]</ref>. We illustrate dependence of neural computation on intrinsic states in a cartoon (Fig. <ref type="figure" target="#fig_0">1C</ref>) in which the simulated neuron switches between 2 static receptive fields. Response switching has also been observed in the amphibian retina. Ganglion-cell activity is typically dominated by OFF responses. However, a large peripheral image shift (as occurs during head saccades) can induce a switch (for a few hundred milliseconds) from transmitting OFF signals to transmitting ON signals <ref type="bibr" target="#b20">[21]</ref>. One of the most compelling examples of response switching has been observed in songbirds: many neurons in cortical motor and auditory areas are responsive to playback of sound stimuli except when birds are singing, at which times responses are locked to the song but not influenced by sound playback <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. Hence, if such neural responses were to be modeled across singing and non-singing states, anything but a twostate model would be inadequate. Indeed, many classical models fail in cases of response switching: the estimated classical receptive fields contain superimposed structures derived from the switched responses, which yields sub-optimal results (Fig. <ref type="figure" target="#fig_0">1D</ref>).</p><p>To address variable response latencies and dynamic neural codes we consider the problem of neural response modeling as an alignment problem. We introduce mixed pair hidden Markov models (MPHs) as novel neural response models allowing for dynamic alignment of stimulus and response without fixed stimulusresponse assumptions. In the case of varying spike latencies (e.g. when a neuron fires in response to a particular stimulus but with a variable latency or lag, Fig. <ref type="figure" target="#fig_0">1A,</ref><ref type="figure">B</ref>), MPHs help to detect corresponding stimulus-response parts by associating individual spikes with particular stimulus time points; and, they help to uncover stimulus-response relationships including the spike-jitter statistics and the receptive field of the neuron. In case of switching dynamics (e.g., when a neuron switches between being responsive to either one stimulus or another depending on the behavioral state of the animal or a cueing stimulus, Fig. <ref type="figure" target="#fig_0">1C</ref>), MPHs help to identify parameters such as the receptive-field switching probabilities and the switching events. Our MPH approach to dynamic alignment combines response switching (context dependency) and spike-time jitter or systematically varying latencies (flexible timing) in one unified framework. We show how to use stimuli and neural responses to jointly estimate all model parameters including spike time jitter, systematically varying latencies, and switching probabilities. We demonstrate the benefits of dynamic alignment on simulated data and on extracellular data recorded in cortical brain areas of singing birds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixed Pair Hidden Markov Models</head><p>We solve the alignment problem by jointly modeling stimulus and response by a mixed pair hidden Markov model (MPH), which is a generative model for both the stimulus and neural response. In MPHs, different neural codes, i.e. different relationships between neural activity and sensory input, can coexist as different states or groups of states in a Markov chain. MPHs are unlike classical hidden Markov models because they dynamically operate on pairs of sequences -neural activity and stimulusinstead of single sequences (i.e. a joint sequence of neural activity and stimulus). For a mathematically detailed introduction to MPHs (and an introduction to HMMs), see the Materials and Methods section.</p><p>We explain the workings of MPHs in intuitive terms by considering first the special case of jittered spike times (Fig. <ref type="figure" target="#fig_0">1A</ref>). We assume spikes are associated with the stimulus (i.e. a time window of the stimulus <ref type="bibr" target="#b0">[1]</ref>) that precede the spikes by an average time lag dT. Instead of associating spikes and stimuli at a constant lag dT (such as is the case for standard spike triggered methods including STA, STC, maximally informative dimensions, etc..), MPHs associate an individual spike with a stimulus at the individual lag dTze (in units of stimulus-response bins, e being an integer, e can be different for each spike). MPHs achieve this flexibility via three different types of hidden states and by keeping track of the momentary lag dTze and its evolution. First, matching states (M-states) associate a spike with a stimulus at the current lag dTze by modeling the joint probability distribution of spike and stimulus (Fig. <ref type="figure" target="#fig_1">2A</ref>, middle). The simplest case are Gaussian stimulus models comprising two Gaussians, one of which models stimuli jointly occurring with spikes and the other models stimuli not occurring with spikes (Fig. <ref type="figure" target="#fig_1">2A</ref>, middle). A model with only a single such M-state is bound to a fixed lag dT and is equivalent to an LNP model (under appropriate parameter constraints, see also the section on LNP equivalence below). To achieve a variable lag, we introduce two more types of states: X-states (X stands for the stimulus sequence) and R-states (R stands for response sequence). These states can change the momentary lag dTze as follows. An X-state models the stimulus (but not the response) via some probability distribution, for instance a Gaussian (Fig. <ref type="figure" target="#fig_1">2A</ref>, left). The X-state changes the current lag from dTze to dTze{1. Analogously, an R-state models only the spiking response (but not the stimulus) via a discrete probability distribution (e.g. spike or no-spike, Fig. <ref type="figure" target="#fig_1">2A,</ref><ref type="figure">right</ref>). An R-state changes the current lag from dTze to dTzez1. An MPH consisting of an M, X, and R state</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Summary</head><p>The brain computes using electrical discharges of nerve cells, so called spikes. Specific sensory stimuli, for instance, tones, often lead to specific spiking patterns. The same is true for behavior: specific motor actions are generated by specific spiking patterns. The relationship between neural activity and stimuli or motor actions can be difficult to infer, because of dynamic dependencies and hidden nonlinearities. For instance, in a freely behaving animal a neuron could exhibit variable levels of sensory and motor involvements depending on the state of the animal and on current motor plans-a situation that cannot be accounted for by many existing models. Here we present a new type of model that is specifically designed to cope with such changing regularities. We outline the mathematical framework and show, through computer simulations and application to recorded neural data, how MPHs can advance our understanding of stimulus-response relationships. can thus model a spike-stimulus pair via the M state or via the X and the R state. In general fewer states are preferred as there is a cost associated with switching from one state to another. Thus, an MPH will try to keep the lag between stimulus and spike constant unless there is evidence for changing the lag via X and R states.</p><p>Intuitively, one can think of an MPH as a finite state automaton that processes symbols from two sequences at the same time, the stimulus (X-sequence) and the response sequence (R-sequence). Under this analogy, M-states process one symbol of each sequence (they match a symbol pair from X and R), X-states process only a stimulus symbol, and R-states process only a response-symbol. The automaton keeps track of two pointers that indicate the current position in the stimulus sequence as well as the current position in the response sequence. The pointer difference corresponds to the current lag dT+e (the ''automaton'' considers all possible lags, weighted probabilistically).</p><p>A sequence of hidden states in an MXR-MPH (M, X, and R states) can be depicted as a path in an alignment matrix that spans all possible pairings between stimulus and response (Fig. <ref type="figure" target="#fig_1">2B</ref>): An M-State corresponds to diagonal movement along the matrix from position (t,u), i.e. position t in the stimulus sequence and u in the response sequence, to position (tz1,uz1). An X-State corresponds to horizontal movement from position (t,u) to (tz1,u) and an R-State corresponds to vertical movement from position (t,u) (A) Architecture of the minimal MPH that allows for neural codes with varying latencies, i.e. flexible timing. This MPH has 3 hidden states, one X-state that models only the stimulus, one R-state that models only the neural response, and one M-state that jointly models stimulus and response. The probability distributions over stimuli (bottom) are illustrated as low dimensional projections (stimulus dimension 2 coincides with the receptive field of the M-state). (B) Hidden state sequences in that model correspond to paths in the alignment matrix: a diagonal step leading into position (t,u) implies that stimulus and response at times t and u are jointly modeled by an M-state, a horizontal step implies modeling of only the stimulus at time t, and a vertical step implies modeling of only the response at time u (deviations from the diagonal reflect jittered spikes detected by the model). Depicted stimulus and spiking responses are from figure <ref type="figure" target="#fig_0">1A</ref>. (C) The minimal MPH for modeling state-dependent neural codes. The MPH can switch between several M-states, each of which represents a different RF. The (projected) stimulus distributions given a spike (spike triggered stimulus ensemble) are centered on the respective RFs (indicated by black arrows). (D) Adding states to the model turns the alignment matrix into an alignment tensor composed of several planes (strictly speaking, B depicts a tensor as well; we just projected all the states onto one plane). The switch from state 1 to State 2 is indicated (green arrow). doi:10.1371/journal.pcbi.1003508.g002 to (t,uz1). A change in the temporal relationship between stimulus and response (i.e. spike jitter) is reflected in non-diagonal (horizontal or vertical) steps in the alignment matrix (with step size provided by the discretization of stimulus and neural response sequences, Fig. <ref type="figure" target="#fig_1">2B</ref>). This 3-state model will be applied to simulated and real data in the next section.</p><p>In order to handle state-dependent (switching) neural responses (Fig. <ref type="figure" target="#fig_0">1C</ref>), we consider MPHs with several M-states (Fig. <ref type="figure" target="#fig_1">2C</ref>). Multiple M states add another dimension to the alignment matrix, which we henceforth call alignment tensor (Fig. <ref type="figure" target="#fig_1">2D</ref>). The simplest switching-enabling MPH has two M-states but no X or R states. Each M-state is associated with a particular receptive field to be estimated (here we use 'receptive field' in the most general way, independent of linearity and related assumptions). With several M states, spikes can be associated to stimuli via one of several joint probability distributions over spike and stimulus. Probabilistic transitions between M states allow the MPH to switch between receptive fields, which is shown on simulated and real data below.</p><p>The general MPH has several M-, X-, and R-States and thus simultaneously permits flexible timing and context dependency. The parameters defining probabilistic transitions into and out of hidden states are:</p><p>A ij : Transition probability of transiting from hidden state i to hidden state j, I i : Initial probability of hidden state i, F i : Final probability of hidden state i.</p><p>The parameters defining emission probabilities are: b i x t ð Þ: Emission probability density of the stimulus x t given hidden X-state i (x t is a vector and typically spans a window of the stimulus around time t), b i r u ð Þ: Discrete emission probability distribution of the response r u given hidden R-state i (r u is part of a discrete set, e.g. {0, 1} for spike or no spike), b i x t ,r u ð Þ: Mixed discrete-continuous emission probability of stimulus-response pair x t ,r u ð Þ given hidden state i</p><p>As emission probability densities associated with X and M states we use multivariate Gaussians or mixtures of Gaussians, respectively. For hidden X-state i we write the emission probability density as</p><formula xml:id="formula_0">b i x ð Þ~X K k~1 c ik N(x,m ik ,S ik ),</formula><p>where c ik is the weight of the k th mixture component, K denotes the total number of mixture components (which may vary for different hidden states, i.e. some c ik can be zero), and m ik and S ik denote the Gaussian mean and covariance matrix of the k th mixture component. For M states we keep track of one such multivariate Gaussian for each response state r u (each response state is associated with a distinct stimulus emission).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Special Cases of MPHs</head><p>In the following we present detailed analyses of the spike-jitter and response-switching MPH architectures. First, we discuss an MPH with only one M-state (M-MPH) and multivariate Gaussian stimulus models. We show that, under appropriate parameter constraints, such a model is equivalent to a 1-dimensional LNP model and describe its relation to linear regression and linear discriminant analysis and the resulting strengths and limitations.</p><p>Second, we discuss an extension of that M-MPH to a model that also possesses an X-and an R-state (MXR-MPH). We illustrate in simulations how this model can account for spike time jitter and varying latencies on white noise and on natural stimuli. Third, we treat an extension of the M-MPH to multiple M-states (M n -MPH) and illustrate through simulations how this model can account for switching dynamics and context dependency. All of these models can be cascaded with an additional non-linearity so that they form NNP cascades (as opposed to LNP cascades). In the chapter that then follows, we apply these models to data recorded from single units of cells in the behaving bird.</p><p>The M-MPH with multivariate Gaussian stimulus models and equal covariances. An MPH characterized by one Mstate, multivariate Gaussian stimulus models with shared covariance matrix, and no X and R states is equivalent to an LNP model. In the following we calculate both the linear filter and the LNP non-linearity. Let m 0 ,S 0 ,m 1 ,S 1 ,p 0 , and p 1 be the parameters of an MPH with one M-state and Gaussian stimulus models, where m 0 ,S 0 are the mean and the covariance matrix of the stimulus given no spike is emitted and m 1 ,S 1 are the mean and the covariance matrix of the stimulus given emission of a spike. In this section, we assume identical covariance matrices: S 1 ~S0 ~S. p 1 ,p 0 are the marginal (or prior) probabilities of a spike and no spike and X ~x1 ,x 2 , . . . ,x T , x t [ n denotes the stimulus sequence and R~r 1 ,r 2 , . . . ,r U , r u [f0, . . . ,Bg the response sequence. In the examples to follow, stimulus and response have the same length, T~U (T=U can be useful too, for instance, when stimulus and spiking response are differently binned).</p><p>In this simple MPH the posterior probability of a spike at time t is given by</p><formula xml:id="formula_1">P(r t ~1 Dx t ~x)~P (r t ~1,x t ~x) P r t ~1,x t ~x ð Þ zP(r t ~0,x t ~x) ~p1 e {0:5 x{m 1 ð Þ T S {1 x{m 1 ð Þ p 1 e {0:5 x{m 1 ð Þ T S {1 x{m 1 ð Þ zp 0 e {0:5 x{m 0 ð Þ T S {1 x{m 0 ð Þ<label>ð1Þ</label></formula><p>By using p 0 zp 1 ~1 and rearranging terms, we can transform Eq. 1 to</p><formula xml:id="formula_2">1 P r t ~1Dx t ~x ð Þ {1~p 0 e {0:5 x{m 0 ð Þ T S {1 x{m 0 ð Þ (1{p 0 )e {0:5 x{m 1 ð Þ T S {1 x{m 1 ð Þ :<label>ð2Þ</label></formula><p>By taking the logarithm on both sides of Eq. 2 we find</p><formula xml:id="formula_3">log 1 P r t ~1Dx t ~x ð Þ {1 ~log p 0 1{p 0 {0:5 m 0 zm 1 ð Þ T S {1 m 0 {m 1 ð Þ zx T S {1 (m 0 {m 1 ):<label>ð3Þ</label></formula><p>Hence, log</p><formula xml:id="formula_4">1 P rt~1Dxt~x ð Þ {1 is affine-linear in x.</formula><p>Equivalence between this simple MPH and linear non-linear neural response models follows after applying the sigmoid function, w x ð Þ~1 e x z1 , on both sides of (3) and assuming m 0 ~0, which yields</p><formula xml:id="formula_5">P r t ~1Dx t ~x ð Þ ~w c{x T S {1 m 1 À Á ,<label>ð4Þ</label></formula><p>where the constant c is given by c~log p 0 1{p 0 z0:5m T 1 S {1 m 1 . Hence, the posterior spike probability P r t ~1Dx t ~x ð Þfor this MPH agrees with that of an LNP model with linear filter (or receptive field) B~S {1 m 1 and non-linearity</p><formula xml:id="formula_6">w(c{z):<label>ð5Þ</label></formula><p>For non-white stimuli, i.e. S=I with I the identity matrix, the receptive field B of the MPH is given by</p><formula xml:id="formula_7">B~S {1 X T t~1 r t : x t ! ,<label>ð6Þ</label></formula><p>which is known as reverse correlation, corrected spike triggered average <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>, or simply as linear regression. Moreover, for white stimuli, i.e. S~I, the receptive field B~m 1 of the MPH is the spike triggered average (STA) -the mean of the spike triggered ensemble. Hence, the M-MPH performs a linear regression cascaded with a sigmoid non-linearity and is equivalent to a one dimensional LNP model with a sigmoid non-linearity (Eq. 5).</p><p>Note that the M-MPH's receptive field (Eq. 6) always corresponds to the linear regression solution. Consequently, the M-MPH's receptive field estimate is optimal whenever linear regression is the correct model. In particular, it follows that the MPH parameter estimates can be optimal even when the spike triggered ensemble and its complement are non-Gaussian -for instance in case of white noise stimuli and a threshold non-linearity <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26]</ref>. The same is true when the overall stimulus distribution is non Gaussian -for instance for non-Gaussian natural stimuli and a linear ''non-linearity'' <ref type="bibr" target="#b25">[26]</ref>. However, although the receptive field estimate does not depend on Gaussian assumptions, the nonlinearity (Eq. 5) does, see e.g. <ref type="bibr" target="#b25">[26]</ref>. In <ref type="bibr" target="#b25">[26]</ref>, the authors suggest to re-estimate the non-linearity (decision boundary) of a linear discriminant model to obtain a non-linearity estimate not corrupted by Gaussian assumptions.</p><p>Inspired by <ref type="bibr" target="#b25">[26]</ref>, we cascade the MPH with an additional nonlinearity that can be estimated from the data subsequent to the estimation of the MPH (compare Materials and Methods for details of the estimation). Such cascading is standard practice for neural response models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref> and is also part of LNP models. The cascaded M-MPH with shared covariance can fit any one-dimensional LNP model on white-noise data (provided that the operation of the LNP model leads to a change of mean of the spike triggered ensemble, which is the case for all monotone non-linearities and for most others) <ref type="bibr" target="#b0">[1]</ref>. However, for non-white data and certain nonlinearities, the linear regression estimate can be biased <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, so that MPHs too will infer an incorrect receptive field (see also below, where we apply MPHs to natural stimuli). In these cases, using Gaussian mixtures as stimulus models might be advisable (see discussion).</p><p>M-MPH with free covariance matrices and Gaussian mixture models. One interesting extension of that simple MPH results from assuming S 1 =S 0 . This case is analogous to quadratic discriminant analysis <ref type="bibr" target="#b25">[26]</ref>. The MPH implements a model quadratic in x. One further extension is to use mixtures of Gaussians as emission distributions instead of individual Gaussians (see discussion), in which case g is generally not quadratic anymore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The MXR-MPH and Its Application to Simulated Data with Spike-Time-Jitter</head><p>In the following we demonstrate the ability of MXR-MPHs (Fig. <ref type="figure" target="#fig_1">2A</ref>) to recover the correct receptive field (RF) on simulated data with noisy latencies, i.e. spike-time-jitter. When predicting spiking probabilities on novel data, the MXR-MPH outperforms purely spike-triggered methods.</p><p>For the MXR-MPH, we denote the stimulus means and covariance matrices in the M-State by m M0 ,S M0 (non-spiking) and m M1 ,S M1 (spiking) and in the in the X-State by m X ,S X . In accordance with the section on LNP equivalence and to simplify this general MPH, we introduce the following parameter constraints: First, we fix all covariance matrices to identity matrices:</p><formula xml:id="formula_8">S M0 ~SM1 ~SX ~I:</formula><p>Second, we fix the means m M0 and m X to zero (equal to the mean of the stimulus ensemble). Third, we do not allow the Rstate to generate spikes (zero spike emission probability) because we require that each spike is matched to a stimulus (note that if we allowed the R-state to generate spikes, the model would distinguish between spikes generated by the M-state and spikes generated by the R-state -such distinction could be used for distinguishing stimulus driven from spontaneous activity, which was not our focus). Given these parameter constraints, the remaining free parameters in the model are the receptive field m M1 (the mean of the spike triggered stimulus ensemble, Fig. <ref type="figure" target="#fig_1">2C</ref>), and the transition probabilities among X, R, and M-state. After training the MPH, the jitter statistics are implicit in the model's parameters; below we show how to explicitly compute the jitter statistics for natural stimuli.</p><p>Application to white data. To test the model, we first created artificial data by sampling spike trains from an LNP model in response to a white noise stimulus consisting of 10 5 time bins (arbitrary timescale), and 42 dimensions or stimulus channels (e.g. pixels on a one dimensional screen or frequency bands in a spectrogram). We split the stimulus into 500 sequences of equal duration and generated 25 trials of LNP spiking responses for each of those sequences (Fig. <ref type="figure" target="#fig_2">3A</ref>). The LNP model was composed of one linear filter that spanned 11 time bins (Fig. <ref type="figure" target="#fig_2">3C</ref>) and a sigmoid nonlinearity (red line in Fig. <ref type="figure" target="#fig_2">3G</ref>). We generated a total of 28702 LNP spikes (,0.015 spikes/bin). We randomly jittered the individual LNP spikes (Fig. <ref type="figure" target="#fig_2">3A</ref>) with i.i.d. spike shifts drawn from a discretized log-normal distribution with zero mean (Fig. <ref type="figure" target="#fig_2">3B</ref>). The variance of that distribution controls the total amount of jitter: As variance increases, the distribution becomes more asymmetric with a heavy right-side tail (we choose such an asymmetric jitter distribution to increase the difficulty of the problem). To 450 of the 500 stimulus-response sequences we fitted both an MXR-MPH and a reverse correlation model (resulting filters are depicted in Fig. <ref type="figure" target="#fig_2">3C</ref>). The remaining 50 sequences served as validation set.</p><p>The STA, which is the optimal solution in case of jitter-free data, yielded a poor approximation of the true receptive field (Fig. <ref type="figure" target="#fig_2">3C</ref>). The main problem for STA was that the (jittered) spiketriggered stimulus ensemble did not separate well from its complement (Fig. <ref type="figure" target="#fig_2">3D</ref>, middle) when projected onto the underlying (true) RF. In contrast, the receptive field m M1 estimated using the MXR-MPH (Fig. <ref type="figure" target="#fig_2">3C</ref>) was very close to the true RF, and the reconstructed spike-triggered ensemble (computed by aligning stimulus and response through the generalized Viterbi algorithm, see Materials and Methods) was well separated from the full stimulus ensemble (Fig. <ref type="figure" target="#fig_2">3D,</ref><ref type="figure">right</ref>). We ran the spiking-probability inference algorithm outlined in Materials and Methods on the independent validation set. The MPH-predicted spike responses were in general much better than STA-predicted responses (Fig. <ref type="figure" target="#fig_2">3E</ref>, instead of using correlation coefficients, we could have evaluated performance through the average likelihood of the models given the data; we opted for CCs to ensure easy interpretability and connect to existing literature). For small jitter, MPH and STA responses were equally good; however, with increasing jitter, the MXR-MPH performance dropped much less than that of STA. Similar superiority of the MXR-MPH was also seen in RF estimation, evaluated in terms of the angle between estimated and true RFs (Fig. <ref type="figure" target="#fig_2">3F</ref>, to discount for arbitrary shifts in RF position that could be induced by the asymmetric jitter kernels we also designed a shift-invariant measure by time-shifting the estimated RF relative to the true RF and considering only the minimal angles; this gave virtually identical results).</p><p>We elucidate the influence of various non-linearities, by having evaluated MPHs and STA-models for various sigmoidal nonlinearities of the (true) LNP model (Fig. <ref type="figure" target="#fig_2">3G</ref>, the non-linearities were chosen such that the resulting models each yield an average rate of about 0.015 spikes/bin). We found that RF estimation and response prediction of the MPH was the better the steeper the non-linearities (Fig. <ref type="figure" target="#fig_2">3H</ref>). Furthermore, the difference between cascaded and non-cascaded MPH is not large (Fig. <ref type="figure" target="#fig_2">3H</ref>). The improved performance for steep nonlinearities is to be expected because the non-linearity is needed to separate the action of the linear filter from the action of the jitter kernel in the underlying LNP model (i.e. without non-linearity the linear kernel of the LNP model and the jitter kernel simply act as two subsequent linear operations which no longer can be uniquely disentangled).</p><p>Application to natural stimuli. We also tested the MXR-MPH on jittered responses to natural stimuli (a problem that, to our knowledge, has not yet been addressed in the literature). We sampled spike trains from an LNP model in response to spectrograms of birdsongs (Fig. <ref type="figure" target="#fig_3">4A</ref>). We used 250 zebra finch songs (50 of the songs served as a validation set), yielding a total of 66025 time bins (4 ms each) and 20332 generated spikes (mean rate/bin ,0.012).</p><p>We fixed the model covariance matrices to the covariance S of the stimulus ensemble:</p><formula xml:id="formula_9">S M0 ~SM1 ~SX ~S=I:</formula><p>Furthermore, we fixed the means m M0 and m X to the actual stimulus mean. As for white noise stimuli, the MPH performed better than reverse correlation on RF estimation and response prediction (Fig. <ref type="figure" target="#fig_3">4E,</ref><ref type="figure" target="#fig_3">4F</ref>).</p><p>We computed the jitter statistics via the alignment kernel of the MXR-MPH (the alignment kernel is a weighted average of spike shift counts associated with each possible hidden state sequence (i.e. each path in the alignment tensor, Fig. <ref type="figure" target="#fig_1">2B</ref>) where the weights correspond to the respective probabilities of the hidden state sequences given model and data, see Materials and Methods). Our simulations showed that the model did not over-fit the data by detecting jitter when none was present (Fig. <ref type="figure" target="#fig_3">4B</ref>, left) and that the alignment kernel could be estimated quite well even when jitter was large (Fig. <ref type="figure" target="#fig_3">4B,</ref><ref type="figure">right</ref>).</p><p>The MPH allows for stimulus-response modeling both for correlated and uncorrelated jitter: Correlated jitter can be accounted for by decreasing the transition probabilities onto X and R-states, which in turn decreases the probability of nondiagonal movement in the alignment tensor (thus leading to correlated stimulus-response lags across successive spikes). To model uncorrelated jitter, the transition probabilities can be chosen such that the likelihood of a chunk of the stimulus-response pair being modeled with only X-and R-states equals the likelihood of modeling it with M-states only. In that case, constant time lags and changing time lags between successive spikes are equally likely and jitter is uncorrelated (provided that successive spikes are further apart than the jitter size).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The M 2 -MPH and Its Application to Simulated Data with Switching Dynamics</head><p>MPHs with several M states support context dependency. They can model multiple stimulus-response relationships associated, for instance, with distinct behavioral states of an animal. To demonstrate this flexibility of MPHs, we simulated a neuron that randomly switches (according to a Markov process with equal probabilities) between two linear-nonlinear models (each defined as in the previous section), i.e., neural responses were governed by a hidden state sequence that determined which receptive field was active at any given time (Fig. <ref type="figure" target="#fig_4">5A</ref>). We generated responses of this artificial neuron to 100 white noise sequences, each spanning 1000 time bins (arbitrary timescale), and 21 dimensions or stimulus channels. For each sequence, spike responses were generated using the switching LNP model, resulting in a total of 4374 spikes on average (mean 0.044 spikes/bin). We generated and tested data for different RF combinations, characterized by different rotations in the plane of one of the RFs (Fig. <ref type="figure" target="#fig_4">5B</ref>, left). To uncover the hidden switching dynamics and the two RFs, we trained a Gaussian M 2 -MPH with two M-states A and B (Fig. <ref type="figure" target="#fig_1">2C</ref>). Gaussian parameters were constrained in the following way: First, we imposed zero means: m A0 ~mB0 ~0; and second, we fixed all covariance matrices to the identity matrix. The remaining free parameters of the model were the means m A1 and m B1 of the spike-triggered ensembles (i.e., the STA estimate (dashed line). (B) Applied spike jitter is i.i.d. among spikes and log-normally distributed with zero mean (3 different jitter distributions are shown; they differ in terms of variance v and symmetric/asymmetric shape). Results for the jitter kernel with variance v~16 are shown in panels A, C and D. (C) RFs estimated through STA on unjittered spikes (true RF), STA on jittered spikes (STA), and MPH on jittered spikes (MPH). The STA RF is blurred whereas the MPH RF closely resembles the true RF. Dotted black lines indicate the midpoints of the RFs. (D) Projections of all stimuli (gray lines) and the spike triggered stimulus ensembles (black lines) onto the underlying (true) RF for the unjittered spikes (left), the jittered spikes (middle), and the MPH reconstruction (right, obtained via dynamic alignment using the generalized Viterbi algorithm). (E) Response prediction. To evaluate the models we computed correlation coefficients (CCs) between predicted and actual firing rates on the validation set and for different jitter variances. For small spike jitter, performances of STA and MPH are comparable. As the jitter magnitude increases, STA performance drops much more severely than does MPH performance. Also shown is an upper bound for the CC computed by sampling and cross-correlating jittered responses. (F) MPH robustness to jitter is demonstrated also when assessed as similarity between the estimated RF and the true RF (similarity computed as normalized scalar product, i.e. cosine of angle between RFs). (G) We assessed the influence of different non-linearities (labeled A-E, ordered by steepness) on prediction quality for both the MPH as well as the cascaded MPH (cMPH). (H) Shallow non-linearities decrease the upper bound of prediction quality (black line) as well as the MPH (red lines) and STA (green line) performance for the unjittered (left) and the jittered case (right). The cascaded MPH (red line) shows slight improvements over the non-cascaded one (dotted red line). doi:10.1371/journal.pcbi.1003508.g003 We compared the MPH with STA and STC <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6]</ref> models. For all three models, we computed RF estimates and the response prediction performance. The trained MPH faithfully recovered both RFs, whereas the (single) RF estimated of STA consisted of a superposition of the two RFs, and the RFs estimated using STC were severely corrupted by noise in most cases (Fig. <ref type="figure" target="#fig_4">5B</ref>). As a result, the MPH predicted responses better on an independent validation set than did STA and STC (Fig. <ref type="figure" target="#fig_4">5C</ref>, averaged over 10 runs). We assessed the quality of the recovered RFs of all three methods and all 37 tested rotations by matching each original RF to the recovered RF with smallest distance and by averaging the two distances. The MPH recovers the RF much better then STA or STC (Fig. <ref type="figure" target="#fig_4">5D</ref>, average over 10 runs; drops in MPHreconstruction quality are due to local minima, compare figure text).</p><p>The degraded performance of the STC model has two reasons. First, the covariance of the spike triggered ensemble needs to be reliably estimated (with quadratically many degrees of freedom as there are stimulus dimensions compared to a linear number of degrees of freedom for the M 2 -MPH). Second, the linear filters uncovered by STC are orthogonal <ref type="bibr" target="#b0">[1]</ref>, whereas the M 2 -MPH is not constrained in this way.</p><p>It is possible to show that the M 2 -MPH firing rate p t to a stimulus is given by</p><formula xml:id="formula_10">p t ~lA w A X t RF A ð Þ zl B w B (X t RF B ),</formula><p>where w 1 ,w 2 : ? 0,1 ½ are two non-linearities and l A and l B are the prior probabilities of hidden states A and B, respectively. The STA model, on the other hand, is bound to model firing rates as p t ~w(X t (l A RF A zl B RF B )):</p><p>An extreme example that illustrates the failure of RF estimation with STAs is a neural response model that pools over two filters RF A ~{RF B and l A ~lB ~0:5. In that case the estimated RF using STA is uniform and has no predictive power at all, unlike the MPH (e.g. Fig. <ref type="figure" target="#fig_4">5C</ref>, rotation angle 180u). A less extreme but potentially more relevant case is that of complex cells in primary visual cortex with overlapping excitatory and inhibitory oriented receptive subfields (such cells are often modeled by pooling over four oriented filters that are phase shifted 0 0 , 90 0 , 180 0 , and 270 0 , respectively <ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref>). A switching M 4 -MPH with four M-states can recover these phase shifted filters, whereas STA yields only a blurred RF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Application to Songbird Spike Data</head><p>To demonstrate that MPHs work well in practice even when the amount of available data is small and the true spike generating process is unknown, we apply the MXR-and the M n -MPH to extracellular spike data recorded in the forebrain nucleus interface of the nidopallium (NIf) of songbirds (Fig. <ref type="figure" target="#fig_5">6A</ref>). NIf is a higherorder song-control nucleus; lesion and inactivation studies have shown that NIf exhibits both sensory and motor functions <ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref>. Multi-unit NIf activity is generally strongest shortly before and during syllable production and weakest during the times corresponding to silent intervals between syllables <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>. These findings suggest a pre-vocal role of NIf spikes during song, prompting us to expect in singing birds a negative latency of NIf spikes relative to song (spikes precede sounds, as opposed to a positive latency that would result if NIf firing was sensory during vocal production). Due to the difficulty of recording in singing animals, available spike trains are relatively short (the average total spike train duration was 73 s per cell) and contain few spikes (,1500 spikes per cell).</p><p>To investigate latencies of NIf single-unit spikes relative to song, we first fitted an LNP model using reverse correlation (RC, Fig. <ref type="figure" target="#fig_5">6C</ref>, left). To overcome problems of over-fitting (due to the limited amount of data available) we used a regularized version of the stimulus covariance matrix:</p><formula xml:id="formula_11">S 0 ~SzaI, a~T r S ð Þ n ,<label>ð7Þ</label></formula><p>where n denotes the number of stimulus dimensions, S denotes the unregularized stimulus covariance matrix and a denotes its normalized trace (such regularization yielded better generalization performance). Next, we trained a MXR-MPH on large 0.25 s song spectrogram windows (with covariance matrices in M and X states fixed to the regularized stimulus covariance matrix S 0 in Eq. 7).</p><p>The MPH RF was similar to the reverse correlation RF (Fig. <ref type="figure" target="#fig_5">6B</ref>), but it reflected more clearly that the cell fired before sounds and not thereafter (consider for example the stronger inhibitory band near 10 ms). MPH and reverse correlation encoding performances on a test set were comparable (Fig. <ref type="figure" target="#fig_5">6D</ref>, left data points). Note that by construction, differences between MXR-MPH and reverse correlation RFs arise from spike-time-jitter.</p><p>To characterize response latencies (and jitter) we estimated probability distributions of the temporal offset t between stimulus and response in M-states via the alignment kernel (Fig. <ref type="figure" target="#fig_5">6B,</ref><ref type="figure">left</ref>). Negative lags in the alignment kernel imply that spikes occur before corresponding events in the stimulus, whereas positive lags imply that spikes occur thereafter. The alignment kernel was centered at a small negative time lag and exhibited a small temporal spread, revealing high temporal precision of NIf spike trains. Predicted responses (5-fold cross validation) for the reverse correlation model and the MXR-MPH were equally good (Fig. <ref type="figure" target="#fig_5">6D</ref>, left data points), confirming high temporal precision of NIf spike trains.</p><p>The MPH allowed us to strongly reduce model complexity by shrinking linear filters (RF sizes) down to less than 30 ms. For such short RFs, the cell latency is reflected entirely in the alignment kernel. Based on the RF estimate in Fig. <ref type="figure" target="#fig_5">6B</ref> and 6C, we expected the jitter kernel to be centered near 230 to 240 ms. Indeed, the kernel peaked near 240 ms (Fig. <ref type="figure" target="#fig_5">6C</ref>, right), implying that the MPH aligned spikes to portions of the stimulus occuring about 40 ms after the spike, suggesting a premotor function of this cell and thus agreeing with the hypothesized premotor function of NIf.</p><p>Additionally we trained an M n -MPH with various numbers of states on the same NIf cell (unlike for the M 2 -MPH applied in the section on switching dynamics we did not constrain the means). The M n -MPH showed modest improvements over reverse correlation, its peak validation CC occurred at 8 states (Fig. <ref type="figure" target="#fig_5">6D</ref>), suggesting that this NIf cell fires prior to several distinct song features.</p><p>responses. For small overall jitter, performances of reverse correlation and MPH are comparable. As the overall jitter magnitude increases, reverse correlation performance drops much more severely than does MPH performance. (F) RC performance drops even stronger when assessed in terms of similarity between the estimated and the true RFs. doi:10.1371/journal.pcbi.1003508.g004</p><p>We also analyzed data for another recording site in NIf, composed of 54 s of singing with concurrent spiking (1659 spikes, about 60 stereotyped song motifs). The RF estimated using reverse correlation (Fig 6E <ref type="figure">,</ref><ref type="figure">left</ref>) revealed diffuse spectrotemporal tuning, making it difficult to decide whether this cell is sensory or motor in function. By contrast, the MPH alignment kernel (Fig. <ref type="figure" target="#fig_5">6E,</ref><ref type="figure">right</ref>) quite clearly revealed a motor function in this cell, evidenced by the predominance of negative alignment shifts. The MPH RF showed a rather narrow frequency tuning near 2,6 kHz (Fig. <ref type="figure" target="#fig_5">6E,</ref><ref type="figure">middle</ref>). Encoding performance for the MXR-MPH with large RF was again similar to reverse correlation (Fig. <ref type="figure" target="#fig_5">6H</ref>, left data points), yet an M n -MPH yielded slightly superior performance (Fig. <ref type="figure" target="#fig_5">6H</ref>, right data points).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We introduced a novel technique for neural response modeling and receptive field estimation that overcomes limitations of fixed stimulus-response relationships. We proposed to view neural coding as an alignment problem that can be tackled by mixed pair hidden Markov models (MPHs), which jointly model stimulus and response and can naturally account for noisy or systematically varying latencies as well as for context dependent neural codes that depend on internal (hidden) states. Discrete pair HMMs have been used in the context of gene alignment to find corresponding parts in related gene sequences <ref type="bibr" target="#b37">[38]</ref>. To our knowledge they have not yet been applied to response modeling.</p><p>We demonstrated that simple MPHs with Gaussian stimulus models and a fixed shared covariance matrix are equivalent to one dimensional LNP models with sigmoid non-linearity and we extended these basic MPHs to allow flexible timing and context dependency. Thereby MPHs endow standard RF estimation techniques such as spike triggered averaging (STA) and reverse correlation with flexible timing and context dependency. We tested our approach on simulated and real data and demonstrated the benefits of alignment in terms of improved predictability of simulated and real neural responses, improved receptive field estimates as well as the capability of estimating jitter latency statistics and switching states.</p><p>Key properties of MPHs are: 1) X-and R-states that model stimulus or response alone and allow for flexible timing via dynamic temporal alignment, and 2) M-states that allow for context dependency via model switching. Using our estimation techniques, these three types of states can be freely combined in a highly flexible approach to neural coding and decoding without the need to develop additional algorithms.</p><p>We derived MPH parameters estimation updates for Gaussian mixture models with unrestricted covariance matrices (Materials and Methods). The (non-mixture) Gaussian MPHs we studied performed well in simulations (including natural stimuli), even though the assumption of Gaussian stimulus models can be violated by natural stimuli <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b38">39]</ref>. In these cases, mixtures of Gaussians can be useful to approximate arbitrary stimulus distributions and overcome problems of receptive field biases <ref type="bibr" target="#b26">[27]</ref>. Beyond mixtures of Gaussians, EM update equations for other mixture families are known as well <ref type="bibr" target="#b39">[40]</ref> and could be adapted to MPHs.</p><p>Other modeling approaches have been pursued to estimate neural responses in the presence of spike time jitter <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b40">41]</ref>. One approach is to simultaneously estimate the jitter distribution and the RF using the EM algorithm <ref type="bibr" target="#b15">[16]</ref>. This technique has been successfully applied to white noise stimuli (identity covariance) <ref type="bibr" target="#b15">[16]</ref>, but not to stimuli with non-identity covariance, i.e. natural stimuli. Furthermore, in <ref type="bibr" target="#b15">[16]</ref> the jitter of adjacent spikes is assumed to be independent -an assumption that might be violated in cases where jitter depends on slowly varying internal states or is correlated for other reasons. The dynamic alignment technique we present here generalizes these approaches in two ways. First, in MPHs there is no need to constrain the stimulus covariance matrix, so that natural stimuli can be readily processed. Second, MPHs can account for correlated as well as uncorrelated jitter among adjacent or nearby spikes and thus allow modeling of both systematically and slowly varying spike latencies. Furthermore, in <ref type="bibr" target="#b15">[16]</ref> the jitter distribution is explicitly assumed to be of Gaussian form whereas the jitter distribution of the MPH is implicit in the transition probabilities and has degrees of freedom commensurate with the number of hidden states and their transitions.</p><p>The ability of MPHs to emulate switching models is particularly useful given that switching dynamics are important in many neural systems. A number of other approaches have been introduced to handle response switching and context dependency. Several of them are based on hidden Markov models <ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref>. The hidden states in these models typically reflect neural activity but not the stimulus. Models with hidden states that reflect both stimulus and response, such as switching Kalman filters <ref type="bibr" target="#b48">[49]</ref> or generalized linear models with hidden states <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref>, have also been proposed. These models are similar to MPHs with only M-states but no Xand R-states. Furthermore, our approach extends these models in that stimulus-response relationships within each hidden state can be quadratic (single Gaussians, unconstrained covariance matrices) or formed by Gaussian mixtures. Another way of modeling context dependencies are ''multi-linear'' models encompassing a multiplicative context term (by itself modeled through a ''multi-linear'' model) that depends on the projection of the stimulus (in some time window) onto a set of basis functions <ref type="bibr" target="#b51">[52]</ref>. MPHs complement such approaches by allowing more complex types of contextual influence via the underlying Markov structure. This is also an advantage over techniques like spike triggered covariance that can recover multiple filters <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref> but cannot attribute Markovian dynamics to the individual filters. For instance, MPHs allow for context effects over very long time scales, context effects depending on hidden neural states such as up and down states (in this case MPHs also allow to infer the up and down states, for instance through the generalized Viterbi algorithm), and left-to-right HMMs <ref type="bibr" target="#b39">[40]</ref> can incorporate behavioral context in stereotyped motor actions such as birdsong.</p><p>MPHs can bridge between data analysis and theories of neural function. Some theories of cortical function assume discrete modules of computation and representation <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref>, for example synfire chains <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b57">58]</ref> or, more generally, cell assemblies. In these theories, the role of neural activity does not only depend on the identity of the neuron but also on the (hidden) identity of modules the neuron belongs to at a certain time.</p><p>The MPHs we developed to align stimulus and neural response are based on stimuli represented with continuous probability densities and neural activity represented with discrete probabilities. It is noteworthy that both fully continuous pair HMMs that align two continuous sequences and fully discrete pair HMMs also have interesting applications. For instance, we have shown previously that a fully continuous pair HMM can be used to align the songs of a juvenile bird to the song of the bird's tutor in order to identify the parts of the song that were copied and the locations where insertions were made <ref type="bibr" target="#b58">[59]</ref>. We have also demonstrated how fully discrete pair HMMs can be used to align spike trains <ref type="bibr" target="#b58">[59]</ref>: by learning a discrete pair HMM on pairs of related spike trains, we obtained a ''distance'' measure between spike-trains, thereby generalizing state of the art spike train metrics <ref type="bibr" target="#b59">[60]</ref>.</p><p>MPHs are useful for both neural encoding and decoding. We presented algorithms for inferring neural responses and their probabilities given the stimulus (encoding). However, by symmetry of MPHs, the inference algorithms we designed can in principle be ''inverted'' to estimate the stimulus given neural activity (decoding) so that decoding and encoding of brain activity essentially have become the same problem.</p><p>MPHs are based on classical hidden Markov models and learning and inference algorithms other than the EM algorithm are readily available. For instance, for model parameter estimation we could have used (much faster) Viterbi training <ref type="bibr" target="#b37">[38]</ref> or we could have optimized criteria other than data likelihood <ref type="bibr" target="#b60">[61]</ref>. Also, there exists a large variety of very powerful analytical and computational tools developed for classical hidden Markov models that can be adapted to MPHs <ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref>.</p><p>We will make a code package for fitting MPHs available through our website (www.ini.ch/,skollmor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Methods</head><p>Consider two dies at a game of chance, one with equal probabilities for its six faces (fair die) and the other with unequal probabilities (loaded die). Suppose that their holders can exchange dies for one another without you knowing. Suppose furthermore that these die switches occur randomly. All you observe is the sequence of faces without knowing whether the fair or loaded die is in place: the identity of the die is hidden from you. Hidden Markov models (HMMs) account for exactly these kinds of situations involving hidden variables. In the die example we can use an HMM with two states, L (loaded) and F (fair), for the two dies. At any point in time the HMM is in one of the two states corresponding to the die that is in use. Associated with each of the two states are the probabilities for the different faces to come up. These emission probabilities are unknown and can be learned from observations (the distribution is uniform for the fair die and nonuniform for the loaded one). Transitions between states (dies) are governed by unknown transitions probabilities that model how likely the die holders switch dies at any time. For two states, transitions are modeled by an unknown 2 by 2 transition matrix that can also be learned from observations.</p><p>An HMM can produce observations by randomly choosing transitions (die switches) and observations or emissions (faces that come up) which results in an observation sequence and an underlying hidden state sequence. However, HMMs are so useful because they can be applied in reverse: given an observation sequence, we can estimate good parameters (emission and transition probabilities) for the underlying HMM as well as the underlying hidden state sequence, which we never directly observed.</p><p>In a classical HMM (applied to stimulus-response modeling) the time lag between the stimulus and the response is fixed and together stimulus and response probabilistically depend on some hidden (non-observed) variable with Markov dynamics.</p><p>In an MPH, spike and stimuli also probabilistically depend on some hidden variable, but rather than being paired at a fixed time lag, spike and stimulus pairing is dynamic, governed by a probabilistic process. Note that MPHs are different from factorial hidden Markov models which employ a distributed state representation but model a single (possibly multidimensional) observation sequence <ref type="bibr" target="#b63">[64]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Formal Definition of the MPH</head><p>In the following, we present a precise definition of the MPH architecture and its learning and inference algorithms.</p><p>We denote the stimulus sequence by X ~x1 ,x 2 , . . . ,x T and the spiking response by R~r 1 ,r 2 , . . . ,r U where T and U are their respective durations (typically T~U). x t [ n are real vectors (e.g. sound spectrograms) and r u [f0, . . . ,Bg are integers (e.g., number of spikes, typically r u [f0,1g in small time bins with zero or one spike). We denote a position in the combined stimulus-response alignment matrix as t,u ð Þ, Fig. <ref type="figure" target="#fig_1">2c</ref>. The model has three types of hidden states: X-states, which model only the stimulus, R-States which model only the response, and M-States which jointly model stimulus and response (Fig. <ref type="figure" target="#fig_1">2c</ref>). We denote the sets of these states by X S , R S , and M S . Additionally we define the union of states Z S ~XS | R S | M S . We denote sequences of hidden states by C~c 1 ,c 2 , . . . ,c H with c i [Z S and use the notation c (t,u) to refer to the hidden state occupied at sequence position (t,u). Note that in general T=U=H because all of stimulus, response, and hidden state sequences may be of different length. The parameters of the MPH are defined in the following.</p><p>A: </p><formula xml:id="formula_12">b i x ð Þ~X K k~1 c ik N(x,m ik ,S ik ), i[X S ,</formula><p>where c ik is the weight of the k th mixture component, K denotes the total number of mixture components (which may vary for different hidden states but this freedom is not reflected in our notation), and m ik and S ik denote Gaussian mean and covariance matrix of the kth mixture component. For M states we keep track of one such density for each possible value of r u (distinct stimulus emission for each spiking state).</p><p>In the following, we define algorithms for inference in MPHs. Some of them are generalizations of well-known algorithms for normal HMMs. To infer the spiking response for a given stimulus, we derive new algorithms. In the following we denote conditional probabilities of the form P Data D Model Paramters ð Þ simply by P Data ð Þ, i.e., for readability we will omit the dependence on model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalized Viterbi Algorithm</head><p>Assume that we have trained MPH model parameters on some data and now would like to apply the MPH to novel stimulusresponse pairs. In a switching model (Fig. <ref type="figure" target="#fig_1">2e</ref>), we would like to estimate the most likely hidden state sequence given the data to identify the switching events. In a flexible timing model (Fig. <ref type="figure" target="#fig_1">2b</ref>) we would like to determine the optimal alignment between stimulus and response to estimate the jitter of individual spikes. In that latter case, the alignment consists of temporal offsets between stimulus and response on a moment-to-moment basis.</p><p>The generalized Viterbi algorithm for MPHs can be applied in both situations to efficiently compute the most likely hidden state sequence C Ã for a given stimulus-response sequence (X ,R):</p><formula xml:id="formula_13">C Ã ~argmax C P(CDX ,R)~argmax C P C,X ,R ð Þ :</formula><p>We apply an extension of the Viterbi algorithm for classical HMMs <ref type="bibr" target="#b37">[38]</ref>. First, let v j (t,u) be the probability of the most likely sequence that models the stimulus up to (and including) time t, the response up to time u, and that ends in hidden state j. Additionally, for any state j and sequence position (t,u), we keep track of the most likely precursor state in g j (t,u). v j (t,u) and g j t,u ð Þ can be computed recursively (Table <ref type="table" target="#tab_1">1</ref>).</p><p>A good way to visualize the generalized Viterbi algorithm is to think of it as filling up an T|U|DZ S D alignment tensor (Fig. <ref type="figure" target="#fig_1">2f</ref>). The final state of the most likely hidden state sequence is then given by c Ã H ~argmax j[ZS v Ã j (T,U) and the complete state sequence can be obtained by iteratively back-tracking the most likely precursor states g j t,u ð Þ:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalized Forward Algorithm</head><p>In many cases, we are interested in computing statistics over all possible sequences. For instance, to compute the probability P(X ,R) of generating a sequence pair (X ,R) given a particular MPH (for example to compare different MPHs), we need to consider the overall probability of (X ,R) independent of the alignment. Hence we have to consider all possible hidden state sequences and not just the one with maximal likelihood. First, let a j t,u ð Þ be the probability of observing the stimulus up to (and including) time t, the response up to time u, and of ending in hidden state j. The computation of a j t,u ð Þ is very similar to the computation of v j t,u ð Þ, except that the max operation is replaced with a summation (to take all hidden state sequences into account, Table <ref type="table" target="#tab_3">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalized Backward Algorithm</head><p>The backward algorithm is analogues to the forward algorithm. We present it here because it is an integral part of the EM algorithm for MPHs and the computation of posterior probabilities (see below). The backward probability b j (t,u) is the probability of observing the stimulus from time t to the end and the response from time u to the end (excluding x t ,r u ), beginning at position (t,u) and in hidden state j (c (t,u) ~j). b j (t,u) is computed recursively (Table <ref type="table" target="#tab_4">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computing Posterior Probabilities</head><p>Assume we have trained an MPH on some data and want to determine the probability distribution over hidden states for a given stimulus-response pair and sequence position (t,u). Building on the definitions of a j t,u ð Þ and b j t,u ð Þ (Table <ref type="table" target="#tab_3">2</ref> and<ref type="table" target="#tab_4">3</ref>), the posterior probability P(c t,u ð Þ ~jDX ,R) of being in hidden state j at sequence position (t,u) given sequence-pair (X ,R) can be expressed in terms of forward and backward probabilities:</p><formula xml:id="formula_14">P c t,u ð Þ ~j D X ,R ~aj t,u ð Þb j (t,u) P(X ,R) :<label>ð8Þ</label></formula><p>Computing Alignment Kernels</p><p>Intuitively, the alignment kernel F A t ð Þ is a histogram of spike shifts over all possible state paths weighted by their respective probability.</p><formula xml:id="formula_15">F A t ð Þ ! P(t~u{t,c t,u ð Þ [M S ,r u ~1DX ,R)</formula><p>The alignment kernel is easily computed using posterior probabilities (Eq. 8) in M-and R-States at all sequence positions (t,u) which fulfill r u ~1:</p><formula xml:id="formula_16">F A t ð Þ ! X u{t~t j [ M S | R S r u ~1 P(c t,u ð Þ ~jDX ,R):</formula><p>Negative lags t in the alignment kernel imply that spikes occur before corresponding events in the stimulus, whereas positive lags imply that spikes occur thereafter.   </p><formula xml:id="formula_17">g j t,u ð Þ~arg max i[ZS ½A ij v i (t{1,u{1) j[X S : v j t,u ð Þ~b j x t ð Þmax i[ZS ½A ij v i (t{1,u) g j t,u ð Þ~arg max i[ZS ½A ij v i (t{1,u) j[Y S : v j t,u ð Þ~b j r u ð Þmax i[ZS ½A ij v i (t,u{1) g j t,u ð Þ~arg max i[ZS ½A ij v i (t,u{1) Termination: v Ã j T,U<label>ð</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning Model Parameters</head><p>To train an MPH on a set of stimulus-response pairs, we apply a generalization of the EM algorithm. That algorithm is analogous to its normal HMM counterpart <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40]</ref>. In the expectation step, the a j t,u ð Þ and b j (t,u) (Table <ref type="table" target="#tab_3">2</ref> and 3) are used to compute the probability of each state at each sequence position, as well as the expected number of transitions between hidden state pairs. The model parameters are then re-estimated in such a way as to locally maximize the likelihood of the stimulus-response pair. For simplicity of notation we define f i,j t,u ð Þ as the probability of transiting from state j to state i at sequence position (t,u):</p><formula xml:id="formula_18">f i,j t,u ð Þ ~ai t,u ð ÞA ij b j t,u ð Þb j (tz1,uz1)=P(X ,R) if j[M S a i t,u ð ÞA ij b j t ð Þb j (tz1,u)=P(X ,R) if j[X S a i t,u ð ÞA ij b j u ð Þb j (t,uz1)=P(X ,R) if j[Y S 8 &gt; &lt; &gt; :</formula><p>Based on f i,j t,u ð Þ, the new transition probabilities are given by</p><formula xml:id="formula_19">Â A ij ~Pt P u f ij t,u ð Þ P t P u P j f ij (t,u) :</formula><p>Initial probabilities are updated similarly:</p><formula xml:id="formula_20">Î I i 0 ! P j f ij (1,1) if j[M S P j f ij (1,0) if j[X S P j f ij (0,1) if j[Y S 8 &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; :</formula><p>:</p><p>The new discrete emission probabilities for R-States are given by b</p><formula xml:id="formula_21">b i r ð Þ ~Pt P uDru~r P j f ij (t,u) P t P u P j f ij (t,u)</formula><p>,</p><p>where i[Y S and r[f0, . . . ,Bg.</p><p>The update of emission density parameters for X states depends on the type of continuous probability distribution used. For Gaussian mixtures with K mixture components, new means and covariance matrices for the components can be computed as follows. For simplicity, we first define c k i (t,u), where i[X S and k[f1::Kg:</p><formula xml:id="formula_22">c k i t,u ð Þ ~ai t,u ð Þb i t,u ð Þ P j a j t,u ð Þb j t,u ð Þ ! c ik n X t , m ik , S ik ð Þ P l c il n X t , m il , S il ð Þ</formula><p>The updated mixture weights, ĉ c ik , the means, m m ik , and the covariance matrices Ŝ S ik are then computed as follows:</p><formula xml:id="formula_23">ĉ c ik ~Pt P u c k i t,u ð Þ P l P t P u c l i t,u ð Þ , m m ik ~Pt P u c k i t,u ð Þ À Á X t P t P u c k i t,u ð Þ , Ŝ S ik ~Pt (½ P u c k i t,u ð Þ½X t {m m ik ½X t {m m ik T ) P t P u c k i t,u ð Þ :</formula><p>The updates for M-states are analogous. To compute the updated parameters of the mixture associated with r[f0,::Bg (where Bz1 is the number of possible neural responses, i.e. B is the maximum number of spikes per time bin), we sum only over those sequence positions u that fulfill r u ~r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Most Likely Pair of Response and Hidden State Sequences</head><p>Given an MPH that was trained on some stimulus-response pairs, we can predict spiking responses to novel stimuli. This is known as encoding. Conversely, we can reconstruct stimuli from spiking responses, known as decoding. In the following, we derive two encoding algorithms for MPHs. First, we show how to compute the most likely pair of hidden-state and neural response sequences, C,R ð Þ Ã , for a given stimulus X . This algorithm is an extension of the generalized Viterbi algorithm (Table <ref type="table" target="#tab_1">1</ref>). We only present the algorithm for encoding. By symmetry, a decoding algorithm can be derived analogously.</p><p>Let again v j (t,u) be the probability of the most likely hidden state sequence that models the stimulus up to time t and the response up to time u and ends in state j. We want to compute a neural response R Ã ~rÃ 1 ,r Ã 2 , . . . ,r Ã U such that P(R Ã ,C Ã ½R Ã ,X ) is maximized, where C Ã ½R Ã ,X denotes the most likely state path for the sequence pair ½R Ã ,X (Table <ref type="table" target="#tab_1">1</ref>). This is accomplished by always choosing the instantaneous neural response r Ã u , u~1::U such that it maximizes the emission probability in the recursion equations (Table <ref type="table" target="#tab_5">4</ref>).</p><p>As in the generalized Viterbi algorithm (Table <ref type="table" target="#tab_1">1</ref>), we keep track of the most likely precursor states in g j t,u ð Þ. Additionally, we store the emissions that maximize the first factor on the right hand side of the recursion equations as r Ã j t,u ð Þ. We recover the most likely pair of hidden state sequence and neural response by considering the r Ã j t,u ð Þ associated with the most likely state at that position (we assume that U~T; generalization to unknown U is possible, but irrelevant for our purposes).</p><p>This encoding strategy yields a spike train which depends on the most likely hidden state sequence. Such dependence can be a problem if many pairs of hidden state sequences exist with similarly high probability. Also, another caveat is that this algorithm does not provide spiking probabilities. Ideally, we would like to account for all possible hidden state sequences and compute an overall spiking or response probability for each point in time. Such improvement can be done through an extension of the forward algorithm, presented next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computing the Response Probability Distribution as a Function of Time</head><p>Here we compute the probability distribution P(r t DX ) of the response r t at time t given a stimulus sequence X : We can retrieve this probability as a posterior (using Eq. 8) after rewriting our model in the following way.</p><p>1. Replace each M-State by X-and R-states. If the response is encoded using the two symbols 0 and 1 (r u [f0,1g), an M-State is replaced by two X-states, X 0 and X 1 , representing P(x t Dr u ~0) and P(x t Dr u ~1) respectively and two R-states: R 0 which never generates a spike, and R 1 which always generates a spike. X 0 is connected to R 0 and X 1 is connected to R 1 (with probability 1 in both cases). Each connection onto the former M-state is now replaced by a pair of connections to X 0 and X 1 , with transition probabilities each given by the product of the original transition probability and the marginal probability of a non-spike (X 0 ) or spike (X 1 ) (computed by integrating the emission density of the M-state). By construction the model that results from applying this step is equivalent to the original model as far as inference is concerned. 2. Replace each of the R states in the model (except those that have been generated in step 1) by two R-states:R 0 that never emits a spike and R 1 that always emits a spike. As in Step 1, the probability of spiking is encoded in the new transitions onto R 0 and R 1 . By construction, the resulting model is equivalent as far as inference is concerned.</p><p>With this reformulation, we can now easily express P(r t DX ) using sums over posterior probabilities of the R 0 and R 1 states: P r t ~1 D X ð Þ ~Pu~1...U, j[fR 1 g P P (c t,u ð Þ ~jDX ) P u~1...U, j[fR 1 | R 0 g P P (c t,u ð Þ ~jDX )</p><p>, where P P (c t,u ð Þ ~jDX ) denotes the posterior probability of hidden state j in the rewritten model, fR 1 g and fR 0 g denote the sets of all 'spiking' and non-spiking R-states, respectively. Note that by construction P P (c t,u ð Þ ~jDX ) is independent of the response R. In this paper we always use this algorithm for inferring spiking probabilities in MPHs.</p><p>Cascaded MPHs. Inspired by <ref type="bibr" target="#b25">[26]</ref> and the standard practice of forming model cascades in neural response modeling <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>, we cascade the MPH, forming an NNP (non-linear-non-linear) model. For the M-MPH (section on LNP equivalence), we can realize arbitrary LNP non-linearities h : . . Given h we define a mapping z : z(p)~h({w {1 (p)zc) operating on the posterior spike probability p in Eq. 4. Applying this mapping z to Eq. 4 yields the desired spike probability p spike ~z(p)~h(x T m 1 ).</p><p>Alternatively, we can estimate the optimal mapping z(p) that yields the nonlinearity h that best describes the data. We estimate this mapping from the data using the conditional probability z(p)~P(r t ~1Dp)~P (r t ~1, p) P(p) :</p><p>Thus, the optimal (discretized) mapping z corresponds to pointwise division of two histograms, the histogram of posterior spiking probabilities given an actual spike in the numerator and the histogram of all posterior spiking probabilities in the denominator (see also <ref type="bibr" target="#b0">[1]</ref>).</p><p>In practice, we first estimate the MPH parameters and then reestimate the non-linearity via the mapping z in (Eq. 9). When applying this cascaded MPH, we first compute the posterior spiking probabilities and then remap these using z. These response predictions are bound to give better results on the training set and will also improve validation performance (unless the mapping z is over-fitted). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Varying response latencies and context dependent neural coding. (A) Varying latencies. Sequence of 8 dimensional white noise stimuli (e.g. successive frames on a one dimensional screen with 8 pixels). An LNP model generates spikes (black bars) if a chunk of stimulus (dashed rectangles) is similar enough to its receptive field (dashed rectangles). Jitter-free or ideal spikes (vertical black bars, 'ideal spiking') are produced with some fixed latency (dashed diagonal lines). Jittered spikes (black bars, 'observed spiking') are produced by randomly jittering ideal spikes (gray bars) forward or backward in time (green arrows). The jitter of adjacent spikes can be independent or correlated. The jittered spikes are the basis for fitting neural response models. (B) Receptive field (RF) estimates using spike triggered stimulus averaging (STA) on unjittered spikes (true RF), jittered spikes (STA), and the MPH on jittered spikes (MPH). Noisy response latencies lead to blurring of STA RFs, but not of MPH RFs. (C) State-dependent coding. For the same white noise stimulus, spikes are generated from one of two LNP models depending on hidden states I and II (green lines) determining which model is used. (D) The true RFs are superimposed when estimated with STA. A two-states MPH can faithfully recover the two RFs. doi:10.1371/journal.pcbi.1003508.g001</figDesc><graphic coords="3,58.05,60.78,470.78,572.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Two minimal MPHs for flexible timing and context dependent coding. (A) Architecture of the minimal MPH that allows for neural codes with varying latencies, i.e. flexible timing. This MPH has 3 hidden states, one X-state that models only the stimulus, one R-state that models only the neural response, and one M-state that jointly models stimulus and response. The probability distributions over stimuli (bottom) are illustrated as low dimensional projections (stimulus dimension 2 coincides with the receptive field of the M-state). (B) Hidden state sequences in that model correspond to paths in the alignment matrix: a diagonal step leading into position (t,u) implies that stimulus and response at times t and u are jointly modeled by an M-state, a horizontal step implies modeling of only the stimulus at time t, and a vertical step implies modeling of only the response at time u (deviations from the diagonal reflect jittered spikes detected by the model). Depicted stimulus and spiking responses are from figure 1A. (C) The minimal MPH for modeling state-dependent neural codes. The MPH can switch between several M-states, each of which represents a different RF. The (projected) stimulus distributions given a spike (spike triggered stimulus ensemble) are centered on the respective RFs (indicated by black arrows). (D) Adding states to the model turns the alignment matrix into an alignment tensor composed of several planes (strictly speaking, B depicts a tensor as well; we just projected all the states onto one plane). The switch from state 1 to State 2 is indicated (green arrow). doi:10.1371/journal.pcbi.1003508.g002</figDesc><graphic coords="4,58.05,60.78,469.13,411.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The MXR-MPH applied to white noise stimuli and spike-time-jitter. (A) A white noise stimulus (top) with spiking responses (black bars) generated by an LNP-type model neuron (LNP output, the LNP RF size is indicated by the black rectangle). The jittered versions (jittered) of the LNP spike trains with corresponding firing rate (thick gray line) are shown below. The MPH estimate of firing rate (black full line) is more accurate than</figDesc><graphic coords="7,58.05,60.78,484.21,627.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The MPH applied to natural stimuli and jittered spike responses. (A) An example log-spectrogram of zebra finch song (top, high sound amplitudes in red and low amplitudes in blue), spiking responses generated by an LNP-type model (middle, LNP output), their jittered versions (below), and the corresponding jittered firing rate (bottom, gray line). The MPH-predicted response (MPH, full line) of the jittered firing rate is more accurate than the reverse correlation prediction (RC, dashed line). (B) Applied spike jitter is i.i.d. among spikes and log-normally distributed with zero mean. Two different jitter distributions are shown, they differ in terms of variance v and symmetric/asymmetric shape (gray curves v~0:5 left, and v~32 right). The MPH-estimated jitter kernels are shown in black. The MPH misses some jittered spikes (right), as revealed by the excessive peak at zero time lag. Results for the jitter kernel with variance v~32 are shown in panels A, C, and D. (C) RFs estimated through reverse correlation for unjittered data (true RF), jittered data (RC) as well as the MPH receptive field estimate (MPH). The STA RF is blurred whereas the MPH RF closely resembles the true RF. Dotted black lines indicate the midpoints of the RFs. (D) Projections of all stimuli (gray lines) and the spike triggered stimulus ensembles (black lines) onto the underlying (true) RF for the unjittered spikes (left), the jittered spikes (middle), as well the MPH reconstruction (right, obtained via dynamic alignment using the generalized Viterbi algorithm). (E) Correlation coefficients (CCs) between predicted and true firing rates on the validation set for different jitter variances. Also shown is an upper bound for the CC computed by sampling and cross-correlating jittered</figDesc><graphic coords="9,58.05,60.78,482.80,535.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The MPH applied to white noise stimuli and switched responses. (A) A white noise stimulus (top), the randomly switched states of a switching LNP model (middle, black curve), and the observed spike train (middle, black rasters) and firing rate (bottom, gray line). The MPHpredicted firing rate (bottom, black line) to a test stimulus is closer to the observed firing rate than is the STA prediction (blue line) or the STC prediction (dotted green line). (B) The MPH RF estimates (MPH, 2 nd column) capture well the underlying true RFs (True RFs, 1 st column) for all relative angles, unlike the STA RF estimates (STA, 3 rd column) or the STC RF estimates (STC, 4 th column). (C) We evaluated the models by computing CCs between predicted and observed firing rates on a validation set and for different pairs of LNP filters that were generated by rotating one of the RFs. The cascaded MPH (black line) performs slightly better than the non-cascaded MPH (gray line). Both MPHs perform better than STC (green line) and STA (blue line). (D) Quality of RF reconstruction, shown is the cosine angle between true and model RFs (compare main text). The MPH reconstructed the true RFs more faithfully (black line) than did STA (blue line) and STC (green line). The occasional drops in MPH performance (larger error bars) are due to local optima that can be circumvented by starting the MPH-parameter optimization from different initial conditions (the orange line is from the best model -in terms of likelihood on the training set -out of 3 initial conditions). Both, panels (C) and (D) show average results from 10 simulations (with standard errors indicated). doi:10.1371/journal.pcbi.1003508.g005</figDesc><graphic coords="11,58.05,60.78,481.10,429.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. The MXR-and M n -MPH applied to single-unit activity in NIF of a singing zebra finch. (A) Raw extracellular voltage trace timealigned to a log-power sound spectrogram of a zebra finch song (high sound amplitudes in red and low amplitudes in blue). (B) The MXR-MPH's RF estimate (left, high and low sound amplitudes in red and blue respectively). The red blob at about +30 ms is an indication that this cell is premotor. The width of the window is ,0.25 s. The MXR-MPH's alignment kernel (right) is concentrated near 210 ms, yielding a total lead of NIf spikes on song of about 40 ms. (C) The RF estimated with reverse correlation (left) is similar to the MXR-MPH's RF. Middle: RF and jitter kernel of an MXR-MPH with much narrower RF window (about 10 ms wide). The total dimension of the RF is 605 (5 columns times 121 rows). Because the RF is so narrow, the spike latency is now clearly reflected in the alignment kernel (right), centered around a negative alignment shift of about 40 ms, implying that the model aligns spikes to portions of the song that occur about 40 ms after the spike. Hence, the alignment kernel strongly suggests a premotor function of this cell. (D) Predictions (5-fold cross validation) of the MXR-MPH (left, red bar) are similar to reverse correlation (blue bar). Using the non cascaded version (green bar) yields a slight drop in performance. An M n -MPH yields a modest improvement in prediction performance (right, peaking at 8 states) in both the cascaded (cMPH) and non-cascaded forms (MPH, error bars depict 95% confidence intervals). (E) Results for a different data set (a different cell producing 1659 spikes during about 54 s of song data containing about 60 song motifs). The RF estimated using RC reveals diffuse spectrotemporal tuning, making it nearly impossible to decide whether this cell is sensory or motor in function. By contrast, the MPH alignment kernel (right) quite clearly reveals a motor function in this cell, evidenced by the predominance of negative alignment shifts. Also, the MPH RF shows a rather narrow frequency tuning near 2.6 kHz (middle). (F) The MXR-MPH firing-rate predictions for this cell were comparable to reverse correlation predictions; M n -MPHs again yield a modest improvement in prediction performance. doi:10.1371/journal.pcbi.1003508.g006</figDesc><graphic coords="12,58.05,60.78,488.30,441.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Matrix of transition probabilities. A ij denotes the probability of transiting from hidden state i to hidden state j[Z S I i x t ð Þ for i[X S : Emission probability density of the stimulus x t given hidden X-state i[X S b i r u ð Þ for i[R S : Discrete emission probability distribution of the response r u given hidden R-state i[R S b i x t ,r u ð Þ for i[M S : Mixed discrete-continuous emission probability of stimulus-response pair x t ,r u ð Þ given hidden state i[M S As emission probability densities associated with X and M states we use multivariate Gaussians or mixtures of Gaussians, respectively:</figDesc><table /><note><p>i : Initial probability of hidden state i[Z S F i : Final probability of hidden state i[Z S b</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>The generalized Viterbi algorithm.</figDesc><table><row><cell>Initialization:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>The generalized forward algorithm.</figDesc><table><row><cell>Initialization:</cell></row></table><note><p>i[ZS ½A ij a i (t,u{1) Termination: P(X ,R)~P j[ZS a j (T,U)F j doi:10.1371/journal.pcbi.1003508.t002</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>The generalized backward algorithm.</figDesc><table><row><cell>Initialization:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Extended Viterbi algorithm to compute most likely pair of hidden state and neural response sequences for a given stimulus.</figDesc><table><row><cell>Initialization:</cell></row></table><note><p>doi:10.1371/journal.pcbi.1003508.t004</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>PLOS Computational Biology | www.ploscompbiol.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>March 2014 | Volume 10 | Issue 3 | e1003508</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank <rs type="person">Sylvia Schro</rs> ¨der for very helpful discussions of the manuscript. We also thank <rs type="person">Alexei Vyssotski</rs> and <rs type="person">Georg Keller</rs> for providing the recorded spike trains in singing birds. Additionally, we thank <rs type="person">Michael Pfeiffer</rs> and <rs type="person">Florian Bla</rs> ¨ttler for helpful discussions.</p></div>
			</div>
			<div type="funding">
<div><p>This work was funded by the <rs type="funder">Swiss National Science Foundation</rs> (grant <rs type="grantNumber">31003A_127024</rs>) and by the <rs type="funder">European Research Council</rs> under the European Community's <rs type="programName">Seventh Framework Programme</rs> (<rs type="grantNumber">FP7/2007-2013/ERC Grant AdG 268911</rs>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PaTFZJW">
					<idno type="grant-number">31003A_127024</idno>
				</org>
				<org type="funding" xml:id="_5xEzsdP">
					<idno type="grant-number">FP7/2007-2013/ERC Grant AdG 268911</idno>
					<orgName type="program" subtype="full">Seventh Framework Programme</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>All experiments were carried out in accordance with protocols approved by the Veterinary Office of the Canton of Zurich, Switzerland.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Short Introduction to Hidden Markov Models</head><p>We provide a short introduction to ''normal'' hidden Markov models and the associated terminology for readers unfamiliar with them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational Complexity and Optimization of the Algorithms</head><p>Filling out the alignment tensor used to compute forward and backward probabilities (Fig. <ref type="figure">2f</ref>) in a fully connected model requires O TUS 2 À Á computations and additional O(TS) computations for emission probabilities in M and X states (as before, T denotes the length of the X sequence (stimulus), U the length of the R sequence (response); and S is the number of hidden states). We usually reduce this complexity by limiting the allowed temporal offset between stimulus and response to a maximal lag set by a parameter w. In that case, we compute only the part of the alignment tensor within a band of width w around the diagonal. Hence, the complexity reduces to O(TwS 2 ). In the EM algorithm, the computational complexity is O(TwS 2 ).</p><p>The MPHs we studied had mostly constrained parameters, in particular constrained covariance matrices and means. We have found that free covariance matrices tend to make the models prone to over fitting and slow down training as more iterations of the EM algorithm are required (for instance, the M-MPH discussed in the section on LNP equivalence reaches the optimum in one iteration. Using free covariance matrices, convergence is gradual and it takes many more steps for the likelihood change to drop below a predefined threshold).</p><p>The EM algorithm only converges to local optima; we found that this problem can be alleviated by running the training several times from different initializations (compare Fig. <ref type="figure">5D</ref> and the accompanying text).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subjects and Electrophysiology</head><p>All experiments were carried out in accordance with protocols approved by the Veterinary Office of the Canton of Zurich, Switzerland. Data were collected from juvenile male zebra finches (60-92 days old). The electrophysiological procedures are explained in detail elsewhere <ref type="bibr" target="#b64">[65]</ref>. Briefly, microdrives were implanted using methods previously described <ref type="bibr" target="#b64">[65]</ref>. After each experiment, the brain was removed for histological examination of unstained slices to verify the location of reference lesions. Cells were recorded during singing. During recording sessions, birds were housed in a sound isolation chamber equipped with a microphone. Extracellular voltage traces were digitized at 33 kHz and recorded for offline spike sorting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>Conceived and designed the experiments: SK RHRH. Analyzed the data: SK. Contributed reagents/materials/analysis tools: SK. Wrote the paper: SK RHRH.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spike-triggered neural characterization</title>
		<author>
			<persName><forename type="first">O</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/16889482" />
	</analytic>
	<monogr>
		<title level="j">J Vis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="484" to="507" />
			<date type="published" when="2006-02-17">2006. 17 February 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analyzing neural responses to natural signals: maximally informative dimensions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Sharpee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/15006095" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="223" to="250" />
			<date type="published" when="2004-02-17">2004. 17 February 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From response to stimulus: adaptive sampling in sensory physiology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Benda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gollisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Machens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Herz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.conb.2007.07.009</idno>
		<ptr target="http://dx.doi.org/10.1016/j.conb.2007.07.009" />
	</analytic>
	<monogr>
		<title level="j">Curr Opin Neurobiol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="430" to="436" />
			<date type="published" when="2007-07">2007. July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Convergence properties of three spike-triggered analysis techniques</title>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/12938766" />
	</analytic>
	<monogr>
		<title level="j">Network</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="437" to="464" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spectral methods for neural characterization using generalized quadratic models</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Priebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/4993-spectral-methods-for-neural-characterization-using-generalized-quadratic-models" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013-01-22">2013. 22 January 2014</date>
			<biblScope unit="page" from="2454" to="2462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-Time Performance of a Movement-Sensitive Neuron in the Blowfly Visual System: Coding and Information Transfer in Short Spike Sequences</title>
		<author>
			<persName><forename type="first">V</forename><surname>Steveninck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
		<ptr target="http://rspb.royalsocietypublishing.org/content/234/1277/379.short" />
	</analytic>
	<monogr>
		<title level="j">Proc R Soc B Biol Sci</title>
		<imprint>
			<biblScope unit="volume">234</biblScope>
			<biblScope unit="page" from="379" to="414" />
			<date type="published" when="1988-07-07">1988. 7 July 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Rapid neural coding in the retina with relative spike latencies</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gollisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meister</surname></persName>
		</author>
		<ptr target="http://www.sciencemag.org/content/319/5866/1108.abstract" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="page" from="1108" to="1111" />
			<date type="published" when="2008-07">2008. July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The sparseness of neuronal responses in ferret primary visual cortex</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Tolhurst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Thompson</surname></persName>
		</author>
		<ptr target="http://www.jneurosci.org/cgi/content/abstract/29/8/2355" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2355" to="2370" />
			<date type="published" when="2009-07">2009. July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Variation in the response latency of cat retinal ganglion cells</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Levick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The simultaneous coding of orientation and contrast in the responses of V1 complex cells</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Gawne</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/10958519" />
	</analytic>
	<monogr>
		<title level="j">Exp Brain Res</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="293" to="302" />
			<date type="published" when="2000-07">2000. July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Temporal Coding of Contrast in Primary Visual Cortex: When, What, and Why</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Reich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Mechler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Victor</surname></persName>
		</author>
		<ptr target="http://jn.physiology.org/cgi/content/abstract/85/3/1039" />
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1039" to="1050" />
			<date type="published" when="2001-07">2001. July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Latency: another potential code for feature binding in striate cortex</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Gawne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Kjaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Richmond</surname></persName>
		</author>
		<ptr target="http://jn.physiology.org/cgi/content/abstract/76/2/1356" />
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="1356" to="1360" />
			<date type="published" when="1996-07">1996. July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The temporal resolution of neural codes: does response latency have a unique role?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Oram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dritschel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Payne</surname></persName>
		</author>
		<ptr target="http://rstb.royalsocietypublishing.org/cgi/content/abstract/357/1424/987" />
	</analytic>
	<monogr>
		<title level="j">Philos Trans R Soc Lond B Biol Sci</title>
		<imprint>
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="page" from="987" to="1001" />
			<date type="published" when="2002-07-22">2002. 22 July 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Differences in onset latency of macaque inferotemporal neural responses to primate and non-primate faces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Esteky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tanaka</surname></persName>
		</author>
		<ptr target="http://jn.physiology.org/cgi/content/abstract/94/2/1587" />
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="1587" to="1596" />
			<date type="published" when="2005-09">2005. September 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Spatial and temporal jitter distort estimated functional properties of visual sensory neurons</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Sheiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-C</forename><surname>Yen</surname></persName>
		</author>
		<ptr target="http://www.springerlink.com/content/c" />
	</analytic>
	<monogr>
		<title level="j">J Comput Neurosci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="309" to="319" />
			<date type="published" when="2009">2009. 1365573t6285360. 12 April 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Estimating receptive fields in the presence of spike-time jitter</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gollisch</surname></persName>
		</author>
		<idno type="DOI">10.1080/09548980600569670</idno>
		<ptr target="http://informahealthcare.com/doi/abs/10.1080/09548980600569670" />
	</analytic>
	<monogr>
		<title level="j">Network</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="103" to="129" />
			<date type="published" when="2006-04-12">2006. 12 April 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">State-dependent computations: spatiotemporal processing in cortical networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">V</forename><surname>Buonomano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<ptr target="http://www.nature.com/nrn/journal/v10/n2/full/nrn2558.html#B12" />
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="113" to="125" />
			<date type="published" when="2009-07-06">2009. 6 July 2011</date>
		</imprint>
	</monogr>
	<note>Accessed</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neuronal computations with stochastic network states</title>
		<author>
			<persName><forename type="first">A</forename><surname>Destexhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Contreras</surname></persName>
		</author>
		<ptr target="http://www.sciencemag.org/content/314/5796/85.abstract" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">314</biblScope>
			<biblScope unit="page" from="85" to="90" />
			<date type="published" when="2006-07-21">2006. 21 July 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effect of subthreshold up and down states on the whisker-evoked response in somatosensory cortex</title>
		<author>
			<persName><forename type="first">Rns</forename><surname>Sachdev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wilson</surname></persName>
		</author>
		<ptr target="http://jn.physiology.org/cgi/content/abstract/92/6/3511" />
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="3511" to="3521" />
			<date type="published" when="2004-07-18">2004. 18 July 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long-lasting modulation by stimulus context in primate auditory cortex</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="http://jn.physiology.org/cgi/content/abstract/94/1/83" />
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="83" to="104" />
			<date type="published" when="2005-06-20">2005. 20 June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Retinal Ganglion Cells Can Rapidly Change Polarity from Off to On</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Geffen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sej</forename><surname>Meister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/17341132" />
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural processing of auditory feedback during vocal practice in a songbird</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhr</forename><surname>Hahnloser</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature07467</idno>
		<ptr target="http://dx.doi.org/10.1038/nature07467" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">457</biblScope>
			<biblScope unit="page" from="187" to="190" />
			<date type="published" when="2009-06">2009. June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gating of auditory responses in the vocal control system of awake songbirds</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Konishi</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/10196550" />
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="513" to="518" />
			<date type="published" when="1998-09-18">1998. 18 September 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Estimating linear-nonlinear models using Re ´nyi divergences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kouh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Sharpee</surname></persName>
		</author>
		<idno type="DOI">10.1080/09548980902950891</idno>
		<ptr target="http://informahealthcare.com/doi/abs/10.1080/09548980902950891" />
	</analytic>
	<monogr>
		<title level="j">Network</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="49" to="68" />
			<date type="published" when="2009-04-12">2009. 12 April 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Feature analysis of natural sounds in the songbird auditory forebrain</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Theunissen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Doupe</forename></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/11535690" />
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="1445" to="1458" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<idno type="DOI">10.1007/b94608</idno>
		<ptr target="http://www.springerlink.com/index/10.1007/b94608" />
	</analytic>
	<monogr>
		<title level="m">The Elements of Statistical Learning</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="337" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Beyond GLMs: A Generative Mixture Modeling Approach to Neural System Identification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Chagas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arnstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1003356#pcbi.1003356.e057</idno>
		<ptr target="http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.1003356#pcbi.1003356.e057" />
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1003356</biblScope>
			<date type="published" when="2013-12-18">2013. 18 December 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dimensionality reduction in neural models: an information-theoretic generalization of spike-triggered average and covariance analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pillow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/16889478" />
	</analytic>
	<monogr>
		<title level="j">J Vis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="414" to="428" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Receptive field organization of complex cells in the cat&apos;s striate cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Tolhurst</surname></persName>
		</author>
		<ptr target="http://jp.physoc.org/content/283/1/79.abstract?ijkey=17" />
	</analytic>
	<monogr>
		<title level="m">f32190a8f456a0d4124f 1439738b91a9d161ff&amp;keytype2 = tf_ipsecsha</title>
		<imprint>
			<date type="published" when="1978-12-17">1978. 17 December 2012</date>
			<biblScope unit="volume">283</biblScope>
			<biblScope unit="page" from="79" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Spatiotemporal energy models for the perception of motion</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bergen</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/3973762" />
	</analytic>
	<monogr>
		<title level="j">J Opt Soc Am A</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="284" to="299" />
			<date type="published" when="1985-12-02">1985. 2 December 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spatial structure of complex cell receptive fields measured with natural images</title>
		<author>
			<persName><forename type="first">J</forename><surname>Touryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">Y</forename></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/15748852" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="781" to="791" />
			<date type="published" when="2005-06">2005. June 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Regulation of learned vocal behavior by an auditory motor cortical nucleus in juvenile zebra finches</title>
		<author>
			<persName><forename type="first">K</forename><surname>Naie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhr</forename><surname>Hahnloser</surname></persName>
		</author>
		<idno type="DOI">10.1152/jn.01035.2010</idno>
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="291" to="300" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sensorimotor nucleus NIf is necessary for auditory processing but not vocal motor output in the avian song system</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Raksin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Schmidt</surname></persName>
		</author>
		<ptr target="http://jn.physiology.org/content/93/4/2157.short" />
	</analytic>
	<monogr>
		<title level="j">J Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="2157" to="2166" />
			<date type="published" when="2005-07-27">2005. 27 July 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Lesion of a higher-order song nucleus disrupts phrase level complexity in Bengalese finches</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hosino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Okanoya</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/10923650" />
	</analytic>
	<monogr>
		<title level="j">Neuroreport</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2091" to="2095" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Bengalese finch: a window on the behavioral neurobiology of birdsong syntax</title>
		<author>
			<persName><forename type="first">K</forename><surname>Okanoya</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/15313802" />
	</analytic>
	<monogr>
		<title level="j">Ann N Y Acad Sci</title>
		<imprint>
			<biblScope unit="volume">1016</biblScope>
			<biblScope unit="page" from="724" to="735" />
			<date type="published" when="2004-08">2004. August 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Short bouts of vocalization induce longlasting fast c oscillations in a sensorimotor nucleus</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<ptr target="http://www.jneurosci.org/content/31/39/13936.short" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="13936" to="13948" />
			<date type="published" when="2011-09-25">2011. 25 September 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neuronal control of bird song production</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mccasland</surname></persName>
		</author>
		<ptr target="http://www.jneurosci.org/content/7/1/23.short" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="23" to="39" />
			<date type="published" when="1987-09-25">1987. 25 September 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">R</forename><surname>Durbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mitchison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Sequence Analysis</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Modulation spectra of natural sounds and ethological theories of auditory processing</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Theunissen</surname></persName>
		</author>
		<ptr target="http://link.aip.org/link/?JASMAN/114/3394/1" />
	</analytic>
	<monogr>
		<title level="j">J Acoust Soc Am</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page">3394</biblScope>
			<date type="published" when="2003-05">2003. May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A tutorial on hidden Markov models and selected applications in speech recognition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=18626" />
	</analytic>
	<monogr>
		<title level="j">Proc IEEE</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="257" to="286" />
			<date type="published" when="1989-07-27">1989. 27 July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dejittered spike-conditioned stimulus waveforms yield improved estimates of neuronal feature selectivity and spike-timing precision of sensory interneurons</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">N</forename><surname>Aldworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gedeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">I</forename><surname>Cummins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Dimitrov</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/15930380" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="5323" to="5332" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Hidden Markov modelling of simultaneously recorded cells in the associative cortex of behaving monkeys</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abeles</surname></persName>
		</author>
		<idno type="DOI">10.1088/0954-898X_8_3_005</idno>
		<ptr target="http://informahealthcare.com/doi/abs/10.1088/0954-898X_8_3_005" />
	</analytic>
	<monogr>
		<title level="j">Network: Comput. Neural Syst</title>
		<imprint>
			<biblScope unit="volume">897</biblScope>
			<biblScope unit="page" from="297" to="322" />
			<date type="published" when="1997-11-20">1997. 20 November 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cortical activity flips among quasi-stationary states</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abeles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Meilijson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Seidemann</surname></persName>
		</author>
		<ptr target="http://www.pubmedcentral.nih.gov/articlerender.fcgi" />
	</analytic>
	<monogr>
		<title level="m">?artid = 41017&amp;tool = pmcentrez&amp;rendertype = abstract</title>
		<imprint>
			<date type="published" when="1995-07">1995. July 2011</date>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="8616" to="8620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A hidden Markov model approach to neuron firing patterns</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Camproux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Saunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chouvet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Thalabard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thomas</surname></persName>
		</author>
		<ptr target="http://linkinghub.elsevier.com/retrieve/pii/S0006349596794341" />
	</analytic>
	<monogr>
		<title level="j">Biophys J</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="2404" to="2412" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Analysis, classification, and coding of multielectrode spike trains with hidden Markov models</title>
		<author>
			<persName><forename type="first">G</forename><surname>Radons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Du ¨lfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kru</forename><surname>¨ger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/7948227" />
	</analytic>
	<monogr>
		<title level="j">Biol Cybern</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Neural ensemble states in prefrontal cortex identified using a hidden Markov model with a modified EM algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rainer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0925-2312(00)00266-6</idno>
		<ptr target="http://dx.doi.org/10.1016/S0925-2312" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="266" to="266" />
			<date type="published" when="2000-11-20">2000. 20 November 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Spike correlations in a songbird agree with a simple markov population model</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhr</forename><surname>Hahnloser</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.0030249</idno>
		<ptr target="http://dx.plos.org/10.1371/journal.pcbi.0030249" />
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">249</biblScope>
			<date type="published" when="2007-11-20">2007. 20 November 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Efficient estimation of hidden state dynamics from spike trains</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dan</surname></persName>
		</author>
		<ptr target="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67" />
	</analytic>
	<monogr>
		<title level="j">Adv Neural Inf Process Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="7313" to="7314" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Variational Learning for Switching State-Space Models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1162/089976600300015619</idno>
		<ptr target="http://www.mitpressjournals.org/doi/abs/10.1162/089976600300015619" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="831" to="864" />
			<date type="published" when="2000-04-20">2000. 20 April 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Neural Decoding of Hand Motion Using a Linear State-Space Model With Hidden States</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Hatsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/19497822" />
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="370" to="378" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Population decoding of motor cortical activity using a generalized linear model with hidden states</title>
		<author>
			<persName><forename type="first">V</forename><surname>Lawhern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hatsopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<ptr target="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2921213&amp;tool=pmcentrez&amp;rendertype=abstract" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci Methods</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page" from="267" to="280" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sahani</surname></persName>
		</author>
		<ptr target="http://www.jneurosci.org/content/28/8/1929.short" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1929" to="1942" />
			<date type="published" when="2008-05">2008. May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Movshon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
		<ptr target="http://www.cell.com/neuron/fulltext/S0896-6273(05)00468-X" />
	</analytic>
	<monogr>
		<title level="m">Spatiotemporal elements of macaque v1 receptive fields</title>
		<imprint>
			<date type="published" when="2005-05">2005. May 2013</date>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="945" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Isolation of Relevant Visual Features from Random Stimuli for Cortical Complex Cells</title>
		<author>
			<persName><forename type="first">J</forename><surname>Touryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">Y</forename></persName>
		</author>
		<ptr target="http://www.jneurosci.org/content/22/24/10811" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="10811" to="10818" />
			<date type="published" when="2002-12-17">2002. 17 December 2012</date>
		</imprint>
	</monogr>
	<note>abstract?ijkey = 75844c6092d5d53a05a047a1aa8a909ce7691529&amp;keytype2 = tf_ipsecsha</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Characterizing Responses of Translation-Invariant Neurons to Natural Stimuli: Maximally Informative Invariant Dimensions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eickenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Rowekamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kouh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Sharpee</surname></persName>
		</author>
		<idno type="DOI">10.1162/NECO_a_00330?journalCode=neco</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2384" to="23421" />
			<date type="published" when="2012-07">2012. July 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A model of neocortex</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bienenstock</surname></persName>
		</author>
		<idno type="DOI">10.1088/0954-898X_6_2_004</idno>
		<ptr target="http://informahealthcare.com/doi/abs/10.1088/0954-898X_6_2_004" />
	</analytic>
	<monogr>
		<title level="j">Network: Comput Neural Syst</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="179" to="224" />
			<date type="published" when="1995-11-03">1995. 3 November 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Synfire chains and cortical songs: temporal modules of cortical activity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ikegaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cossart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Aronov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lampl</surname></persName>
		</author>
		<ptr target="http://www.sciencemag.org/content/304/5670/559.abstract" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">304</biblScope>
			<biblScope unit="page" from="559" to="564" />
			<date type="published" when="2004-07-05">2004. 5 July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Modeling compositionality by dynamic binding of synfire chains</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abeles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hayon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lehmann</surname></persName>
		</author>
		<ptr target="http://www.springerlink.com/content/t565584112517216/" />
	</analytic>
	<monogr>
		<title level="j">J Comput Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="179" to="201" />
			<date type="published" when="2004-07">2004. July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Hidden Markov Models in the Neurosciences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Blaettler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kollmorgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Herbst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hahnloser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hidden Markov Models</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Dymarski</surname></persName>
		</editor>
		<imprint>
			<publisher>InTech</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="169" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Metric-space analysis of spike trains: theory, algorithms, and application</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Purpura</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/q-bio/0309031" />
	</analytic>
	<monogr>
		<title level="j">Netw Comput Neural Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="127" to="164" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A minimum discrimination information approach for hidden Markov modeling. ICASSP &apos;87</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ephraim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dembo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
		<ptr target="http://ieeexplore.ieee.org/articleDetails.jsp" />
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers</publisher>
			<date type="published" when="1987-09-25">1987. 25 September 2012</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
	<note>?arnumber = 1169727&amp;contentType = Conference+ Publications</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The Hierarchical Hidden Markov Model: Analysis and Applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<ptr target="http://www.springerlink.com/index/H7630R4U78J0XHU1.pdf" />
	</analytic>
	<monogr>
		<title level="j">Computer (Long Beach Calif)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="41" to="62" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Hidden Markov Model Induction by Bayesian Model Merging</title>
		<author>
			<persName><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Omohundro</surname></persName>
		</author>
		<ptr target="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.43" />
	</analytic>
	<monogr>
		<title level="j">Adv Neural Inf Process Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="470" to="471" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Factorial Hidden Markov Models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/16204097" />
	</analytic>
	<monogr>
		<title level="j">Mach Learn</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="245" to="273" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Miniature motorized microdrive and commutator system for chronic neural recording in small animals</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Fee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><forename type="middle">A</forename></persName>
		</author>
		<ptr target="http://www.ncbi.nlm.nih.gov/pubmed/11716944" />
	</analytic>
	<monogr>
		<title level="j">J Neurosci Methods</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2001-01">2001. January 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
