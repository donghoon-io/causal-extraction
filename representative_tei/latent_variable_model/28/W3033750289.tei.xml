<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ChOracle: A Unified Statistical Framework for Churn Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2019-09-15">15 Sep 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Seyed</roleName><forename type="first">Ali</forename><surname>Khodadadi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Abbas</forename><surname>Hosseini</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ehsan</forename><surname>Pajouheshgar</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Farnam</forename><surname>Mansouri</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Hamid</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
						</author>
						<title level="a" type="main">ChOracle: A Unified Statistical Framework for Churn Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-09-15">15 Sep 2019</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1909.06868v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Churn Prediction</term>
					<term>User Modeling</term>
					<term>Marked Temporal Point Processes</term>
					<term>Recurrent Neural Network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>User churn is an important issue in online services that threatens the health and profitability of services. Most of the previous works on churn prediction convert the problem into a binary classification task where the users are labeled as churned and non-churned. More recently, some works have tried to convert the user churn prediction problem into the prediction of user return time. In this approach which is more realistic in real world online services, at each time-step the model predicts the user return time instead of predicting a churn label. However, the previous works in this category suffer from lack of generality and require high computational complexity. In this paper, we introduce ChOracle, an oracle that predicts the user churn by modeling the user return times to service by utilizing a combination of Temporal Point Processes and Recurrent Neural Networks. Moreover, we incorporate latent variables into the proposed recurrent neural network to model the latent user loyalty to the system. We also develop an efficient approximate variational algorithm for learning parameters of the proposed RNN by using back propagation through time. Finally, we demonstrate the superior performance of ChOracle on a wide variety of real world datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>U SERS are the main part of any service both in online and offline worlds, and hence user acquisition and retention is of utmost importance for service providers. Recent studies show that retaining existing users is considerably less expensive than acquiring new ones, and existing users are more profitable than the newcomers <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Therefore, it is common to pay more attention to user retention than user acquisition, specially in online services. Considering the growing rate of online services, user churn which broadly refers to the loss of customers is an important issue. User churn is more challenging in online services due to the factors such as low switching costs, large number of competitors, and the free nature of many services. Therefore, many research efforts have been directed toward predicting user churn, in recent years. Once the potential churners identified, the customer relationship management (CRM) systems can target them with appropriate incentives such as tailored promotions <ref type="bibr" target="#b3">[4]</ref> or gamification methods <ref type="bibr" target="#b4">[5]</ref> to sustain their interest in their current services.</p><p>Churn prediction is studied in different domains such as telecommunication industry <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, banking <ref type="bibr" target="#b8">[9]</ref>, P2P networks <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, online gaming <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, community based question answering (CQA) services <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref> and other online services <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>. There exist different definitions for churn in the literature, corresponding to various service domains. The definitions for churn can be divided into three types: Active which is the case for subscription based services, and the churn happens when the contract is terminated and user leaves the service. Hidden which is the case for free services and happens when the user does not use the service • A. Khodadadi, S.A. Hosseini, E. Pajouheshgar, F. Mansouri, H.R. Rabiee are with the Department of Computer Engineering, Sharif University of Technology, Tehran, Iran Email: {khodadadi, a_hosseini, pajouheshgar, fmansouri}@ce.sharif.edu, rabiee@sharif.edu.</p><p>for a significant amount of time. And, Partial which is the case when user do not use all the available features of the service, and instead uses those features in other services. For example, a drop in the level of user activity can be a sign of partial churn. Most of the previous works in the churn prediction use the active and hidden definitions of churn, and convert the churn prediction problem into a binary classification problem. They usually use an observation window in which they observe the user activity, and a churn window in which they predict the user churn. If the user has no activity in the churn window, he is labeled as churned, otherwise it is labeled as nonchurned. Fig. <ref type="figure" target="#fig_0">1</ref> illustrates the different windows used in this type of churn prediction methods. The main effort in these methods is set on feature engineering and they aggregate the user history in the observation window into a single point or a sequence of points with a churn label, then this data is used to train a common classification method. Even though this method simplifies the application of different classical learning models on the datasets, there is many drawbacks in this approach which makes it inappropriate for many of the existing social media services. First, aggregating all temporal user history in a single point exposes the loss of some useful information that can be used to improve the prediction performance. Second, the choice of the thresholds for the observation and churn windows and the features selected for churn prediction are application dependent which implies that current methods could not be generalized to other domains. Moreover, the current classification based approaches can not efficiently capture the partial definition of churn, which is one of the main challenges of current online services. Moreover, in free online services, users may use different competitors simultaneously, and an decrease in usage may be a preliminary indicator of churn. In addition, the churn definition may differ from a user to another. While a level of activity for an active user may be a sign of churn, it may mean nothing for a less active user. Finally, the current approaches can not distinguish between those who churned at the beginning of churn window and the ones that departed later, while for churn prediction it is important to identify the churning time of a user just in time for making the appropriate plans to avoid churns in a timely manner.</p><p>Recently, some methods have approached the churn prediction problem in a different manner. They try to predict the exact returning time or accordingly exact absence gap of each user to the service for each session in order to predict if the user will leave the system or not <ref type="bibr" target="#b17">[18]</ref>. This approach do not suffer many shortcomings of the classification based methods and it utilizes the history of interactions of user with the service for churn prediction. In addition, the requirement to define observation and churn windows is mitigated. Moreover, by predicting the next interaction time of user with the service and observing deviations from the expected behavior, the service providers can detect the user churn at the early stages and also capture the partial definitions of churn. The authors in <ref type="bibr" target="#b17">[18]</ref> proposed a hazard model from survival analysis to predict user return times to the service. For the first time, they converted the classification approach in this literature into a regression problem, and used the survival analysis to solve the problem. Though innovative, their proposed method suffers from some weaknesses. First, their proposed method needs many feature engineering efforts, and is well suited for music streaming services, and is not applicable to other services. Second, for each session they aggregated the user history data into a single point with some features and lose many temporal information about the exact timing of previous events. The authors in <ref type="bibr" target="#b18">[19]</ref> also proposed the neural survival recommender. Their proposed method, maps the gap between the user sessions into hourly beans, then it learns a very large vector of these hourly intensities by using recurrent neural networks. Though their focus is on recommender systems but their approach can be utilized for returning time predictions. This method also suffers from some drawbacks. It needs to learn very high dimensional vectors for each session that may impose curse of dimensionality when the number of events per user are not very high. Moreover, it quantizes the temporal gaps between sessions into hourly beans that may result in loss of information.</p><p>In this paper, we introduce ChOracle, an oracle to predict the churn which is able to resolve the aforementioned challenges in the previous works. The proposed method models the future absence gaps of users from the service by utilizing the timing and durations of previous sessions. It exploits the strangeness of temporal point processes and recurrent neural networks in an innovative session based manner to model the return times, session to the service and session durations. Since it only uses user return times and session duration information, it can be considered as a general purpose method that can be used in a broad range of online services. The overall contributions of this paper are:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We analyze the users interactions with the service in granularity of sessions, and propose to use user return times and session durations to predict user churn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We propose a special Marked Temporal Point Process to model user return times to the service or accordingly their absence gaps and predict session durations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We utilize RNNs to code the history of user interactions with the service and define the intensity function of proposed temporal point process. Thus the proposed method is not bounded to parametric forms of intensity function, and is able to define and learn general intensity functions. We also incorporate latent random variables into the proposed RNN to add more flexibility to the model. This increases the expressive power of the proposed method and make it capable of handling highly structured data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We introduce a variational lower bound for the complete log likelihood as the objective function, and propose an approach to maximize it through back propagation through time (BPTT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>We conduct several experiments on real datasets to demonstrate the performance of proposed method. To this end, we utilize several datasets from different domains. 1   Related Work. The works most closely related to the proposed method can be divide into two groups: Churn prediction methods and Temporal point process based methods. These are two independent lines of research and to the best of our knowledge we are the first to systematically combine these two and propose a unified statistical framework for churn prediction.</p><p>Churn prediction is studied in a wide range of domains, including telecommunications <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, online games <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, P2P networks <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, and community based question answering (CQA) services <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. The current literature mainly uses the hidden definition of churn and convert the problem into a binary classification problem. The most common topic that is addressed by the previous work is focused on evaluating different predictive models that are trained on a domain-specific dataset. In this context, the main effort is set on engineering appropriate features for the task and different machine learning methods are evaluated such as decision trees <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b19">[20]</ref>, logistic regression <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref>, neural networks <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b20">[21]</ref>, random forests <ref type="bibr" target="#b8">[9]</ref>,</p><p>1. The codes and data are available at <ref type="url" target="https://github.com/alikhodadai/ChOracle">https://github.com/alikhodadai/ChOracle</ref>. <ref type="bibr" target="#b13">[14]</ref>, and support vector machines <ref type="bibr" target="#b21">[22]</ref>. Hence, they are very application dependent and suffer from the lack of generalization. Most of the previous works use the intrinsic features of users and service, and aggregate the features over the entire observation period and pay little attention to the temporal aspects of user behavior. While this approach simplifies the problem, but it results in loss of some important information about the temporal aspects of user behavior that can be utilized in churn prediction. The authors in <ref type="bibr" target="#b22">[23]</ref> used some temporal aspects of data and considered the problem as a sequence classification problem, and proposed a recurrent neural network to classify the sequences. While using temporal information, their approach suffers from many drawbacks. The authors in <ref type="bibr" target="#b1">[2]</ref> used the partial definition of churn and tried to use social network features on churn prediction but they did not paid any attention to the temporal aspects of user behavior. To conclude, the previous works on classification based methods for churn prediction, mainly focused on the hidden definition of churn and little attention is paid to partial definition of churn while this is the case for current social media services. They used popular classification based methods for classification, and temporal information about the user interactions with the service is neglected while it is important for better prediction of the user churn.</p><p>On the other hand, survival analysis and point process based methods have attracted a lot of interest in different mining problems such as modeling marked temporal events <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, user behavior modeling <ref type="bibr" target="#b4">[5]</ref>, modeling the diffusion of products <ref type="bibr" target="#b27">[28]</ref> and recommendation systems <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. Most of these works try to model user return time to enhance another primary task such as recommendation, and are not focussed on modeling the return time itself. Besides, they mainly model the user return times to the items, while in the churn prediction we are interested in predicting the user return time to the service not individual items. They also try to model the mark of events as a countable finite variable, while we propose to model the session duration as an infinite continuous random variable. The works in <ref type="bibr" target="#b17">[18]</ref> and <ref type="bibr" target="#b18">[19]</ref> are the ones that are somehow related to our work. To the best of our knowledge, Kapoor et al. in <ref type="bibr" target="#b17">[18]</ref> for the first time approached the churn prediction problem in a return time prediction manner and tried to model the user return time to the service. They used the Cox proportional hazard function to model user return times. While simple, their proposed method suffers from many shortcomings. To name a few, they aggregated the user history in a single point which results in loss of many temporal information. Furthermore, their approach needs many feature engineering efforts which makes it applicable to a specific service and endangers the generality of their approach. The authors in <ref type="bibr" target="#b18">[19]</ref> also tried to model user return times to the service. But, their primary goal is the recommendation task. They proposed to model user return times to the service not the items, and proposed a method for next-basket recommendation. They learn a large vector of fixed intensities binned for every hour, and hence their method suffers from high computational complexity. To conclude, the literature on point processes mainly do not focussed on the return time prediction as the main goal, but as a covariate for other primary tasks. They mainly modeled the return times to the items not the whole service and the proposed point processes have single purpose parametric forms which suffers from lack of generality. On the other hand, we propose a general purpose model, that only uses user return times and session durations information to predict user return times to the service. However, our proposed method concentrates on service level and do not need any feature engineering efforts and do not suffer from high computational complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Temporal Point Processes</head><p>A temporal point process is a powerful mathematical tool for modeling random events over time. More formally, a temporal point process is a stochastic process whose realizations consists of a list of time-stamped events {t 1 , t 2 , . . . , t n } with t i ∈ R + . Different types of activities over a service, can be considered as events generated by a point process. In our case, the sessions of a user in the service can be considered as the events generated by the process.</p><p>The length of the time interval between successive events is referred to as the inter-event duration. A temporal point process can be completely specified by distribution of its inter-event durations <ref type="bibr" target="#b30">[31]</ref>. Let H t denote the history of events up to time t, then by applying the chain rule we have:</p><formula xml:id="formula_0">f (t 1 , . . . , t n ) = n i=1 f (t i |t 1 , . . . , t i-1 ) = n i=1 f (t i |H ti ) (1)</formula><p>Therefore, to specify a point process, it suffices to define f * (t) = f (t|H t ), which is the conditional density function of an event occurring at time t given the history of events.</p><p>A temporal point process can also be defined in terms of counting process N (t) which denotes the number of events up to time t. The increment of the process, dN (t), in an infinitesimal window [t, t + dt), is parametrized by the conditional intensity function λ * (t). The function λ * (t) is formally defined as the expected rate of events occurring at time t given the history of events, that is:</p><formula xml:id="formula_1">λ * (t)dt = E[dN (t)|H t ]<label>(2)</label></formula><p>There is a bijection between the conditional intensity function (intensity for short) and the conditional density function:</p><formula xml:id="formula_2">λ * (t) = f * (t) 1 -F * (t)<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">F * (t) is the Cumulative Distribution Function (CDF) of f * (t).</formula><p>Using the definition of λ * (t) in Eq.3, the likelihood of a list of events (t 1 , . . . , t n ) which is observed during a time window [0, T ), can be defined as:</p><formula xml:id="formula_4">L = n i=1 λ * (t i ) exp - T 0 λ * (s)ds (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>where n is the number of observed events and T is the duration of observation. Intuitively, λ * (t) is the probability of an event occurring in time interval [t, t + dt) given the history of events up to t, and it is a more intuitive way to characterize a temporal point process by its intensity function <ref type="bibr" target="#b31">[32]</ref>. For example, a temporal Poisson process can be characterized as a special case of a temporal point process with a history-independent intensity function which is constant over time, i.e. λ * (t) = λ <ref type="bibr" target="#b32">[33]</ref>. Users' actions usually exhibit complex longitudinal dependencies such as self-excitation, where a user tends to repeat what he has done recently. Such behavioral patterns can not be characterized by a homogeneous Poisson process, and hence more advanced temporal point processes are needed. Hawkes process is a temporal point process with a particular intensity function which is able to capture the self-excitation property. The intensity function of a Hawkes process is given by:</p><formula xml:id="formula_6">λ * (t) = µ + αg ω (t) dN (t) = µ + α ti&lt;t g ω (t -t i ) (5)</formula><p>where µ is a constant base intensity, α is a weighting parameter which controls the impact of previous events on the current intensity, g ω (t) is a kernel which defines the temporal impact of events on the future intensity, and is the convolution operator. In the case that g ω (t) is a decreasing function, Hawkes process produces clustered point patterns over time and hence is able to model the self-excitation property of users events. The right hand side of Eq. 5 comes from the fact that the number of events occurred in a small window [t, t + dt) is dN (t) = ti∈Ht δ(tt i ), where δ(t) is a Dirac delta function.</p><p>Each event can also be associated with some auxiliary information known as the mark of an event. For example, the song user played in a music streaming service, the item user bought in an online retailer service, or the question user answered in a CQA website can be considered as the marks of events. In our case, the user sessions can be considered as the events and the duration of sessions can be considered as the mark of events. A marked temporal point process is a point process for modeling such events. If k denotes the mark of the events, then the intensity of the marked temporal point process is given by:</p><formula xml:id="formula_7">λ * (t, k) = λ * (t)f * (k|t)<label>(6)</label></formula><p>where λ * (t) denotes the temporal intensity function, and f * (k|t) is the conditional probability density function of observing an event with mark k at time t. Therefore, in order to determine a temporal point process, we need a temporal intensity which shows the rate of occurring event given the history and a conditional probability density function over marks. In the marked case, the likelihood of a list of events {(t 1 , k 1 ), . . . , (t n , k n )} which is observed during a time window [0, T ), can be defined as:</p><formula xml:id="formula_8">L = n i=1 λ * (t i , k i ) exp - T 0 λ * (s)ds<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Recurrent Neural Networks</head><p>Recurrent neural networks (RNNs) are a class of neural networks suited for dealing with sequential data. In traditional neural networks we assume that all inputs are independent of each other which do not holds in many real world situations. For instance, if we want to predict the next word in a sequence, it is highly correlated with the words that came before it, or if we want to predict the next location a user will check in, it is also correlated with the locations he has previously checked in. RNNs are feed-forward neural networks that allow connections between hidden units. More specifically, additional edges are added to the network so that the hidden state of the current time step is fed as the input to the network in the next time step. As a result the same structure is repeated at adjacent time steps through time, and hence they are called recurrent neural networks. This small modification results in an important property for RNNs: The hidden state at the current time step, depends on all the previous hidden states and hence all the previous inputs. This memory property is the main engine of RNNs that give them an excellent predictive power. Let consider h t and x t as the hidden state and input at time step t, respectively. The hidden state depends on both the current input and the hidden state of previous time step as follows:</p><formula xml:id="formula_9">h t = σ(W xh x t + W hh h t-1 + b h )<label>(8)</label></formula><p>where, W xh and W hh are the weight matrices that connects the input to the current hidden state, and previous hidden state to the current hidden state, respectively. b h is the bias vector, and σ(.) is the activation function. The Sigmoid, hyperbolic tangent, and ReLU are examples of popular activation functions. The initial state h 0 only depends on the input, and each state can be calculated in a similar fashion. Fig. <ref type="figure" target="#fig_1">2</ref> illustrates the recurrent nature of and RNN that is unrolled through the time. The weight matrices are learned using training data by an approach called back propagation through time (BPTT).</p><p>In practice, RNNs has shown state of the art performance in general purpose sequence modeling tasks such as sequence-to-sequence translation <ref type="bibr" target="#b33">[34]</ref>, handwriting recognition <ref type="bibr" target="#b34">[35]</ref>, image captioning <ref type="bibr" target="#b35">[36]</ref>, and discrete time-series prediction <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CHORACLE: A CHURN PREDICTION FRAME-WORK BASED ON RNNS</head><p>As we mentioned in the introduction section, a recent approach in churn prediction is to predict the returning time of the user to the service. Temporal Point Process (TPP) is a strong mathematical framework for modeling the underlying patterns governing the temporal data. The major limitation of existing studies that use TPPs to model temporal data is that they often draw parametric assumptions about the conditional intensity function. Each parametric form determines different temporal characteristics for the point</p><formula xml:id="formula_10">Time t i d i g i+1 t i+1</formula><p>d i+1 u Fig. <ref type="figure">3</ref>: Illustration of user session data. Each session i + 1 has a starting point t i+1 , a previous absence gap g i+1 = t i+1t i , which is the gap between consecutive sessions, a duration d i+1 in terms of time the user spent on the service or the number of items user consumed. In the first case the d is a continuous variable, while in the second it is an infinite discrete random variable.</p><p>process and tries to correctly decide which form to use. This is a hard task that needs sufficient domain knowledge. The authors in <ref type="bibr" target="#b26">[27]</ref> proposed a unified model that do not need parametric assumptions about the intensity function.</p><p>To this end, they combined the temporal point processes and recurrent neural networks by letting the RNN to determine the value of intensity function of temporal point process at each time-step. Though innovative, their approach suffers a limitation caused by RNNs. The hidden state in an RNN is a deterministic function of input and the previous state, and the only source of variability is the conditional output probability function which can limit the expressiveness of the model for highly structured data where some latent random variables govern the temporal dynamics of data <ref type="bibr" target="#b37">[38]</ref>.</p><p>To tackle this challenge, in this section, we propose a mathematical framework to define the conditional intensity function of a temporal point process using recurrent neural networks. We incorporate latent random variables into the recurrent neural network to model the variability observed in the data. The latent variable can be interpreted as the latent loyalty of users to the service that increases the expressive power of proposed method. Hence, the proposed method, is able to better predict the returning times of users to the system and user churn. In the followings, we first specify some notations and then discuss the proposed framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations and Conventions</head><p>We cast the churn prediction problem as a return time prediction problem. Moreover, in order to predict user returns to the service, it is better to model user sessions in a system level instead of detailed user events. Besides, we argue that knowing how long the user stayed at the system in each session in addition to the true return times, can improve the predictions and help to better model future return times and the user churn. Let H(T ) = {S u (T )} U u=1 denote the collection of all sequences of user sessions in the system up to time T , where U is the total number of users and S u (T ) is the sequence of sessions of user u till time T . That means</p><formula xml:id="formula_11">S u (t) = {s u i } n u (t)</formula><p>i=1 , where, s u i is the ith session of user u in the system and is denoted as</p><formula xml:id="formula_12">s u i = (t u i , d u i )</formula><p>, where t u i is the time that the session i is started, and d u i is the duration of session. d u i can either be the duration of the session in terms of time or the number of actions the user taen in the system. Fig. <ref type="figure">3</ref> provides some intuitions about the definitions of session duration, absence gap and session start times in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Formulation</head><p>The key idea is to model both absence gap and session duration in order to predict churns through return times.</p><p>To this end, we propose a temporal point process to jointly model the next return time and session duration given all previous sessions of a user. To be able to capture general dependencies between the current and previous sessions, we let an RNN to jointly model the nonlinear dependency of current return time and session duration to the past sessions. Indeed, the output of RNN at each time-step will define the intensity function of temporal point process. To add more flexibility and expressiveness to the proposed model, we add latent random variables to the RNN. In the context of churn prediction, this latent variables can be interpreted as the current loyalty of user to the system. This latent variables will make the proposed method capable to deal with highly structured data. Fig. <ref type="figure" target="#fig_2">4</ref> presents the overall view of the proposed RNN based TPP.</p><p>Given a sequence of events, S u (t</p><formula xml:id="formula_13">) = {(t u i , d u i )} n u (t)</formula><p>i=1 , at time-step i, the tuple (g u i , d u i ) is fed into the RNN, where g u i is the current gap, and is calculated as <ref type="figure"></ref>and<ref type="figure">d u</ref> i is the duration of session i. We also consider a latent random variable z u i , which reflects the current loyalty of user u to the system at step i. From now on, for simplicity we remove the superscript u from inputs and variables. Using the aforementioned inputs g i , d i and variable z i , the update equation for the hidden state of RNN at time-step i will be as follows:</p><formula xml:id="formula_14">g u i = t u i -t u i-1 ,</formula><formula xml:id="formula_15">h i = f θ (g i , d i , z i , h i-1 )<label>(9)</label></formula><p>where, g i and d i are the current inputs, z i is the current value of latent random variable, and h i-1 is the hidden state of RNN at the previous time step. f θ can be any activation function such as Sigmoid (σ(.)) or ReLU (R(.)). The output of RNN at time-step i is the probability density functions of g i+1 and d i+1 . In the following, we describe how p(g i+1 |z i , h i ) and p(d i+1 |z i , h i ) can be calculated. As we mentioned, we use temporal point processes to model the return times to the system and let RNN to define the conditional intensity function of the temporal point process at each time-step. Hence, to define p(g i+1 |z i , h i ), we should define λ * (g i+1 |z i , h i ) of associated point process.</p><formula xml:id="formula_16">(g i , d i ) f(g i+1 | z i , h i ) h i z i P(d i+1 | z i , h i ) P(z i+1 | h i ) (g i+1 , d i+1 ) f (g i+2 | z i+1 , h i+1 ) h i+1 z i+1 P(d i+2 | z i+1 , h i+1 ) P(z i+2 | h i+1 )</formula><p>We propose the following formulation for the conditional intensity function:</p><formula xml:id="formula_17">λ * (g|z i , h i ) = exp w z z i + w h h i + w t g + b t<label>(10)</label></formula><p>where, exp(.) is used to meet the required condition for conditional intensity function to be always positive (∀t, λ * (t) ≥ 0). We can define the probability density function of next absence gap using the defined intensity function:</p><formula xml:id="formula_18">g i+1 |z i , h i ∼ f * (g|z i , h i )<label>(11)</label></formula><formula xml:id="formula_19">f * (g|z i , h i ) = λ * (g|z i , h i ) exp(- g 0 λ * (s|z i , h i )ds)<label>(12)</label></formula><p>It is worth noting that since h i is a function of previous hidden states that depend on the related inputs, (relation 9), f * (g|z i , h i ) will depend on all previous history. i.e. f * (g i+1 |z i , h i ) = f * (g i+1 |z ≤i , g ≤i , d ≤i ).</p><p>In the same way, we try to model the duration of next session at each time step. We consider d i+1 as the number of events occurred during the session i + 1. We also assume that it has a Poisson distribution with a parameter γ. Therefore, at each time-step i we need to model the parameter γ i to model the next session duration. We propose the following formulation for γ i :</p><formula xml:id="formula_20">γ i = exp(w z,γ z i + w h,γ h i + b γ )<label>(13)</label></formula><p>Where, w z,γ , w h,γ are the weight vectors that will be learned through the learning of RNN. Therefore, the probability density function of next session duration can be defined as:</p><formula xml:id="formula_21">p(d i+1 = k|z i , h i ) = γ k i e -γi k! (<label>14</label></formula><formula xml:id="formula_22">)</formula><p>We also consider the latent variable z i to define the loyalty to the system in time step i and hence we consider it in [0, 1] interval, where 0 means no loyalty to the system, and 1 is the highest loyalty and engagement with the system. To this end, we consider a prior logit-normal distribution for z:</p><formula xml:id="formula_23">p(z i |h i-1 ) = p θp (z i |h i-1 ) = P (N (µ 0 , σ 2 0 )),<label>(15)</label></formula><p>where, θ p = {µ 0 , σ 2 0 }</p><p>In order to generate this distribution, at each time-step of RNN we use a multilayer perceptron network (MLP) that accepts the previous hidden state as input and outputs µ 0 and σ 0 . The weights of this MLP is also shared between all time-steps and are learned through the learning phase of RNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Learning</head><p>Given the collection of all sequences of events and their latent random variables until time T , i.e. {S u (T ), Z u (T )} U u=1 , where S u (T ) is the sequence of sessions of user u, and Z u (T ) is the sequence of latent random variables of user u, we can define the joint log-likelihood as:</p><formula xml:id="formula_24">L S u (T ),Z u (T ) U u=1 = u log P S u (T )|Z u (T ) + log P Z u (T ) = u i log P (g u i |z u i-1 , h i-1 )+ log P (d u i |z u i-1 , h i-1 ) + log P (z u i |h i-1 )<label>(16)</label></formula><p>where, the first term is the probability density of event timings or absence gaps, the second term is the probability density of session durations, and the third term is the prior probability of latent variables.</p><p>Given the latent random variables, we can simply maximize this joint log-likelihood by using the Back Propagation Through Time (BPTT). However, in real data we do not have the latent variables at hand, and hence we can not directly maximize the complete joint log-likelihood in Eq. 16.</p><p>Utilizing the approach used in Variational Inference <ref type="bibr" target="#b38">[39]</ref> and Variational Auto-Encoder (VAE) <ref type="bibr" target="#b39">[40]</ref>, we try to maximize the evidence lower bound (ELBO) as the objective function. The objective function will be a time-step-wise variational lower bound as follows:</p><formula xml:id="formula_25">u E q(z u 1:T |g u 1:T ,d u 1:T ) T i=1 log P (g u i |z u i-1 , h i-1 )+ log P (d u i |z u i-1 , h i-1 ) -KL q(z u i |g u i , d u i , h i-1 ) p(z u i |h i-1 ) (<label>17</label></formula><formula xml:id="formula_26">)</formula><formula xml:id="formula_27">d i g i h i-1 z i h i h i+1 d i+1 g i+1 z i+1</formula><p>Fig. <ref type="figure">5</ref>: Graphical model of proposed inference method. Black lines show how the hidden state is inferred. Red lines show how the next absence gap and session duration is predicted, and Blue lines show how the latent variable is inferred.</p><p>Where q(.) is the approximate posterior of latent random variables z. We also define the approximate posterior to be a logit-normal distribution, and define it by modeling its parameters through MLPs. By maximizing this variational lower bound with respect to corresponding parameters, all the models will be learned. We also use BPTT to learn the variational lower bound. Fig. <ref type="figure">5</ref> illustrates the graphical model of the proposed model. The exact derivation of Eq.17 is provided in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Churn Prediction</head><p>It is worth mentioning that predicting the next absence gap and the next session duration is the first step in our churn prediction, and alarms can be triggered based on application needs, at the next step. For instance, in the simplest case, if the predicted values for the next session exceeds some thresholds, i.e. if ĝu i+1 &gt; θ g ∧ du i+1 &lt; θ d , where θ g and θ d are the predefined thresholds, then the alarms can be triggered. This is equivalent to the latent definition of churn in the literature. One can also consider some more complex thresholds. For example, the thresholds can be defined based on the expected behavior of user as</p><formula xml:id="formula_28">ĝu i+1 &gt; E[g u ] ∧ du i+1 &gt; E[d u ]</formula><p>which is equivalent to the partial definition of churn. Since choosing this thresholds is application dependent, we concentrate on prediction through exact values, and leave the detailed investigation of churners and churn alarms to future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We evaluate the performance of ChOracle on large-scale real world datasets. We first describe the competitor baselines and the datasets. Then, we study the convergence of proposed learning algorithm. Next, we evaluate the performance of the proposed method in predicting the absence gap of users and their future session durations. Finally, we study the impact of session based approach on the performance of proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Competitor baselines</head><p>We cast the churn prediction problem into a return time prediction problem. Therefore, we evaluate performance of the proposed method in both predicting the next absence gap and next session duration. However, none of the previous works have tried to do this type of evaluation. Only some works have tried to predict the return time of users to the items. However, the main goal of many of these works are neither churn prediction nor return time prediction to the system, but some of them can be modified to predict user return times to the system for comparisons. Therefore, to evaluate the performance of proposed method in predicting the next return time to the system, we compared ChOracle with the following models.</p><p>• RMTPP <ref type="bibr" target="#b26">[27]</ref>. This method tries to model the intensity function of a temporal point process using recurrent neural networks. It learns a general intensity function that can predict next event time and marker. Although its primary intention is not for churn prediction and its markers have discrete finite values, but we used its temporal part for return time prediction to the system.</p><p>• NSR <ref type="bibr" target="#b18">[19]</ref>. The Neural Survival Recommender is designed for recommendation purposes and tries to model the return times of users to the items. But, since it also tries to model the temporal point process using RNNs based on a different approach, we also compared its performance in return time prediction with the proposed method.</p><p>As discussed in the related works section, the authors in <ref type="bibr" target="#b17">[18]</ref> have also tried to model the user return times to service, however their method is application dependent and uses detailed specific features that makes it only applicable to music streaming services. Since in our experiments we used datasets from different general domains and only use high level user interaction data such as session duration and absence gap, we did not include this method in the competitor baselines.</p><p>Experimental Setup. For implementation of deep networks, we used TensorFlow <ref type="bibr" target="#b40">[41]</ref>, a scalable deep learning library in python. To be fair, we trained all three methods that are based on neural networks (ChOracle, RMTPP, NSR) with 70 iterations on the train data with the learning rate of 0.001. We used a single LSTM layer with 300 hidden units. We did not use any embedding for the proposed method, RMTPP, and NSR. This will impact the results but will help us to evaluate the performance of methods without any help of embeddings. We selected 80% of users as the training set and the remaining 20% as the test set. We set the session length threshold to 1 hour for all datasets and experiments, except when explicitly stated. More information about the session length is provided in related subsections of the results.</p><p>In addition, we set w t = 0 in Eq. 10, in implementation of ChOracle. For simplicity in calculations of the KL divergence, instead of using z we used logit(z) which has a Gaussian distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dataset Description</head><p>We evaluated the performance of ChOracle on four real datasets from different domains; Last.fm, Tianchi Alibaba Mobile Commerce, Foursquare, and IPTV. All datasets contain timestamped actions which make them appropriate benchmarks for comparing the proposed method to the other state-of-the-art methods.</p><p>Last.fm. This dataset contains the music listening logs of 1200 users and 1000 artists. There are around 418K events in total which spans a period of 6 months.</p><p>Tianchi Mobile Data. It contains the user interactions with items in Alibaba's mobile M-Commerce platform <ref type="bibr" target="#b41">[42]</ref>. The dataset includes four behavior types: click, collect, addto-cart, and payment. We only considered the click events. Our data contains roughly 1000 users, 2100 items, and a total of 1.2M events.</p><p>Foursquare Data. This dataset contains Foursquare users' check-ins in London <ref type="bibr" target="#b42">[43]</ref>. We selected the active users with more than 30 check-ins and the venues with more than 50 check-ins which resulted in 67K check-ins of 890 users in London, which spans from Mar. 2011 to Sep. 2011.</p><p>IPTV Data. This dataset contains the users' history of watching TV programs on online TV streaming services <ref type="bibr" target="#b28">[29]</ref>. The dataset contains 7100 users and 436 TV programs. The dataset contains 2.4M events and spans a period of 11 months.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convergence Analysis</head><p>In fig. <ref type="figure" target="#fig_3">6</ref> we illustrate the convergence behavior of the proposed method. We investigated how the Loss, and MAE changes through epochs on the train data. First row presents the Loss against number of epochs for different datasets. The presented Loss is the negative of ELBO introduced in Eq. 17 divided by the number of events; i.e. negative of average ELBO per event. Since we try to maximize the ELBO as the objective function, we expect that the its negative decreases with an increase in the number of epochs. As it can be clearly seen from the first row, with an increase in the number of epochs the loss decreases in all data sets. It cab be also noticed that after about 20 epochs, the loss converges to a fixed value which is a sign of fast convergence in all datasets. As the main goal of ChOracle is to predict when the user will comeback to the system, in the second row, we also presented the MAE of absence gap, and session duration prediction on the train data for different datasets. Minimizing the absence gap, and session duration prediction error is not the main objective of the optimization, but as the second row shows, minimizing the loss will result in minimizing the absence gap, and session duration prediction error in all datasets. As it can be seen, the absence gap prediction error converges rapidly for Tianchi and Last.fm datasets while it takes more epochs for Foursquare and IPTV datasets to converge. In the contrary, the session duration prediction error converges rapidly for Foursquare and IPTV datasets while it took more epochs to converge for Tianchi, and Last.fm datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Absence Gap Prediction</head><p>In fig. <ref type="figure" target="#fig_4">7</ref> we illustrate the performance of different methods in predicting the next absence gap of users on the test data. As depicted, the proposed method outperforms the competitors in all datasets. The NSR performance is close to the proposed method in Tianchi and Last.fm datasets (Figs. <ref type="figure" target="#fig_4">7a,</ref><ref type="figure" target="#fig_4">7b</ref>). As we mentioned previously, the NSR method suffers from high complexity and requires more computational power to reach the desirable results. It learns a vector of length 4320 for each event that is the intensity function of a temporal point process for about 180 days. The Foursquare dataset has only 800 users and many of its sessions contain just 1 event. Hence, NSR do not perform well for the Foursquare  dataset. IPTV dataset contains about 5000 users and about 1M events. When we tried to fit NSR on the IPTV dataset by using a simulation server with 12GB of GPU, we faced out of memory (OOM) errors, since the data did not fit in the memory. To resolve this issue, we reduced the length of prediction to only 500 future hours and hence it could not well predict the future events. This is depicted in the Fig. <ref type="figure" target="#fig_4">7d</ref>. The RMTPP method, which only uses RNNs to model the timing of events, can not well describe the latent patterns that govern the temporal dynamics of the events. It only performs close to the proposed method for the IPTV dataset, which has a lot of training data. However, for datasets with fewer data, it cannot well describe the patterns governing the temporal dynamics of data. Instead, the proposed method which uses RNNs to define the intensity function of temporal point process and incorporates the latent variables into the RNNs, can well describe the latent patterns that govern the temporal dynamics of events. Moreover, it does not suffer from high computational complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Session Duration Prediction</head><p>We also studied performance of the proposed method in predicting the next session duration. We chose the number of events in the session as its duration. For example, the session duration for Last.fm dataset is the number of songs the user listened in a session, and the session duration for Tianchi, Foursquare, and IPTV is the number of products the user clicked, the number of checkins the user did, and the number of tv programs the user watched in the session, respectively. The results is presented in Table . 1. It should be noted that our primary goal is not to exactly predict the session duration and we only use it for better prediction of the future return times. As the results demonstrate, the proposed method performs better on the Foursquare and IPTV datasets compared to Tianchi and Last.fm. Since the session duration in Foursquare and IPTV datasets is less than the Tianchi and Last.fm datasets, the average error is also expected to be less for those datasets. The Mean Relative Error (MRE) is the same over all datasets which shows that relative performance do not change over different datasets, and the differences in MAE is because of different scales in session duration of different datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact of Session Threshold on the performance</head><p>There is no explicit notion of session in the datasets we used for our experiments. Therefore, we manually segmented the events into sessions. To this end, we selected a minimum gap (ψ g ) and if the gap between two consecutive events (i, i + 1) is less than the threshold (t i+1t i &lt; ψ g ) we assume that they belong to the same session. We used this method to create session based events. The choice of threshold ψ g is application dependent and may affect the results. Fig. <ref type="figure" target="#fig_5">8</ref> shows the impact of session length threshold ψ g on performance of the proposed method both in predicting the next absence gap and next session duration. To this end, we plotted the MRE of these two metrics against the session threshold. As illustrated in this figure, with increasing the threshold ψ g , the MRE of absence gap prediction decreases for all datasets. Because with increasing the threshold the resulting sessions will be longer and the gaps between sessions increases, and as a result the relative error decreases. In the contrary, with an increase in the threshold there is no significant change in the MRE of next session predictions, and the results do not change dramatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>In this work, we presented a novel framework, ChOracle, for churn prediction in online services. ChOracle models the user absence gaps and session durations, by extending temporal point processes. In order to model general temporal intensities, ChOracle uses recurrent neural networks to define the intensity function of temporal point processes. Therefore, it can adaptively model different intensity functions. We also incorporated latent random variables into the hidden states of RNN, which adds more expressive power to the model and enables ChOracle to deal with highly structured data. The last but not the least, we derived a variational lower bound as the objective function. By maximizing this objective function we can learn all the parameters by using back propagation through time (BPTT). Experiments on real world datasets demonstrate the superiority of the proposed framework over state-of-the-art methods.</p><p>For future work, one may use more specific data about user sessions to improve the predictive performance of the proposed method. We also would like to investigate defining churners based on predicted absence gaps in a real world scenario. Another interesting venue for future work is utilizing generative adversarial neural networks (GAN) <ref type="bibr" target="#b43">[44]</ref> to model the intensity functions of temporal point processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A DERIVATION OF ELBO</head><p>For simplicity, we derive the ELBO for event sequence of a single user u, since it is straightforward to generalize the results to many users. L S u (T ) = log P S u (T ), Z u (T ) dZ = log p(g 1:T , d 1:T , z 1:T )dz 1:T = log q(z 1:T |g 1:T , d 1:T ) p(g 1:T , d 1:T , z 1:T ) q(z 1:T |g 1:T , d 1:T ) dz 1:T ≥ q(z 1:T |g 1:T , d 1:T ) log p(g 1:T , d 1:T , z 1:T ) q(z 1:T |g 1:T , d 1:T ) dz 1:T = q(z 1:T |g 1:T , d  </p><p>and hence, ELBO will be as follows:</p><p>L S u (T ) = E q(z 1:T |g 1:T ,d </p><p>In our experiments, to calculate the expectation with respect to the q(.) distribution, we draw L samples from it and then compute the ELBO as follows:</p><p>L S u (T ) = </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig.1: Churn windows in the literature. The data is gathered for the users on an Observation window. The model is trained based on the data for those who are active in an Activity window. The churn label is assigned to the users based on their activity in a Churn window after observation window. The length of these windows is an important parameter in churn prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: An RNN unrolled through the time. The same structure is repeated at adjacent time steps.</figDesc><graphic coords="4,312.00,43.70,252.01,125.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Illustration of proposed RNN based temporal point process. The inputs are the previous absence gap (g i ) and the session duration (d i ), and the outputs are the probability distributions of next absence gap, next session duration and the next latent variable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: The convergence of proposed method. First row presents the Loss on train data against different epochs for (a) Tinachi, (b) Last.fm, (c) Foursquare, and (d) IPTV datasets. Second row, presents the MAE of absence prediction and MAE of session duration prediction on train data against different epochs. The threshold for session extraction is set to 1 hour.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Performance of different methods in predicting the next absence gap of users on test data for (a) Tianchi, (b) Last.fm, (c) Foursquare, and (d) IPTV datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Impact of session threshold ψ g on the results for a) Tianchi, b) Last.fm, c) Foursquare, and d) IPTV datasets. blue plot shows the MRE of absence gap prediction, red plot shows the MRE of session length prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>B = q(z 1 :</head><label>1</label><figDesc>T |g 1:T , d 1:T )× i log p(z i |z &lt;i , g &lt;i , d &lt;i )log q(z i |z &lt;i , g ≤i , d ≤i ) dz= i q(z ≤i |g ≤i , d ≤i )× log p(z i |z &lt;i , g &lt;i , d &lt;i )log q(z i |z &lt;i , g ≤i , d ≤i ) dz =i q(z &lt;i |g &lt;i , d &lt;i )× KL q(z i |z &lt;i , g ≤i , d ≤i ) p(z i |z &lt;i , g &lt;i , d &lt;i ) dz = -E q(z 1:T |g 1:T ,d 1:T ) i KL q(z i |z &lt;i , g ≤i , d ≤i ) p(z i |z &lt;i , g &lt;i , d &lt;i )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 :</head><label>1</label><figDesc>Session Duration Prediction Results</figDesc><table><row><cell>Dataset</cell><cell cols="4">Tianchi Last.fm Foursquare IPTV</cell></row><row><cell>MAE</cell><cell>23.48</cell><cell>7.57</cell><cell>1.43</cell><cell>3.13</cell></row><row><cell>MRE</cell><cell>1.25</cell><cell>1.16</cell><cell>1.06</cell><cell>1.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1:T )× log T i=1 p(z i |z &lt;i , g &lt;i , d &lt;i )p(g i |z &lt;i , g &lt;i , d &lt;i )p(d i |z &lt;i , g &lt;i , d &lt;i ) i q(z i |z &lt;i , g ≤i , d ≤i ) i |z &lt;i , g &lt;i , d &lt;i ) + log p(d i |z &lt;i , g &lt;i , d &lt;i ) dz = E q(z 1:T |g 1:T ,d 1:T ) i log p(g i |z &lt;i , g &lt;i , d &lt;i ) + log p(d i |z &lt;i , g &lt;i , d &lt;i )</figDesc><table /><note><p><p><p><p>dz</p><ref type="bibr" target="#b17">(18)</ref> </p>We can decompose the above equation into two parts:</p>A = q(z 1:T |g 1:T , d 1:T )× i log p(g</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>log p(g i |z l &lt;i , g &lt;i , d &lt;i )+ log p(d i |z l &lt;i , g &lt;i , d &lt;i ) + KL q(z l i |z l &lt;i , g ≤i , d ≤i ) p(z l i |z l &lt;i , g &lt;i , d &lt;i ) s.t. z l 1:T ∼ q(z 1:T |g 1:T , d 1:T )(22)</figDesc><table><row><cell>1</cell><cell>L</cell><cell></cell></row><row><cell>L</cell><cell>l=1</cell><cell>i</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>He has received numerous awards and honors for his Industrial, scientific and academic contributions. He has acted as chairman in a number of national and international conferences, and holds three patents. He is also a Member of IFIP Working Group 10.3 on Concurrent Systems, and a Senior Member of IEEE. His research interests include statistical machine learning, Bayesian statistics, data analytics and complex networks with applications in complex networks, multimedia systems, cloud and IoT privacy, bioinformatics, and brain networks.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dynamic churn prediction framework with more effective use of rare event data: The case of private banking</title>
		<author>
			<persName><forename type="first">Ö</forename><forename type="middle">G</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Arıtürk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="7889" to="7903" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Churn in social networks: A discussion boards case study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Karnstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Computing (SocialCom), 2010 IEEE Second International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Customer base analysis: partial defection of behaviourally loyal clients in a non-contractual fmcg retail setting</title>
		<author>
			<persName><forename type="first">W</forename><surname>Buckinx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Poel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="252" to="268" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Customer churn prediction in telecommunications</title>
		<author>
			<persName><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Kechadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1414" to="1425" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Continuous-time user modeling in presence of badges: A probabilistic approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khodadadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Tavakoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3162050</idno>
		<ptr target="http://doi.acm.org/10.1145/3162050" />
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2018-03">Mar. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predicting customer behavior in telecommunications</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Wolniewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dodier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A customer churn prediction model in telecom industry using boosting</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1659" to="1665" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Behavioral modeling for churn prediction: Early indicators and accurate predictors of custom defection and loyalty</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Manoj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blumenstock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Big Data (BigData Congress)</title>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="677" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Customer churn prediction using improved balanced random forests</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ying</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="5445" to="5449" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Modeling churn in p2p networks</title>
		<author>
			<persName><forename type="first">O</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Znati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simulation Symposium, 2007. ANSS&apos;07. 40th Annual</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Understanding churn in peer-to-peer networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stutzbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rejaie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM SIGCOMM Conference on Internet Measurement, ser. IMC &apos;06</title>
		<meeting>the 6th ACM SIGCOMM Conference on Internet Measurement, ser. IMC &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="189" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Churn prediction in mmorpgs: A social influence based approach</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kawale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Science and Engineering, 2009. CSE&apos;09. International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="423" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Churn prediction for high-value players in casual social games</title>
		<author>
			<persName><forename type="first">J</forename><surname>Runge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Garcin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence and Games (CIG), 2014 IEEE Conference</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Churn prediction in new users of yahoo! answers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pelleg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Rokhlenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on World Wide Web</title>
		<meeting>the 21st International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="829" to="834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">User churn in focused question answering sites: characterizations and prediction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pudipeddi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on World Wide Web</title>
		<meeting>the 23rd International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="469" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Social network user lifetime</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Network Analysis and Mining</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="297" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Early activity diversity: Assessing newcomer retention from first-session activity</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Karumur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<idno type="DOI">10.1145/2818048.2820009</idno>
		<ptr target="http://doi.acm.org/10.1145/2818048.2820009" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing, ser. CSCW &apos;16</title>
		<meeting>the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing, ser. CSCW &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="595" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A hazard based approach to user return time prediction</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1719" to="1728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural survival recommender</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="515" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Turning telecommunications call details to churn prediction: a data mining approach</title>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I.-T</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert systems with applications</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="112" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Customer churn prediction by hybrid neural networks</title>
		<author>
			<persName><forename type="first">C.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="12" to="547" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Churn prediction in subscription services: An application of support vector machines while comparing two parameter-selection techniques</title>
		<author>
			<persName><forename type="first">K</forename><surname>Coussement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Poel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert systems with applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="313" to="327" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Predicting user churn on streaming services using recurrent neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Martins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hnp3: A hierarchical nonparametric point process for modeling content diffusion over social media</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khodadadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arabzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining (ICDM)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="943" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Coevolve: A joint point process model for information diffusion and network co-evolution</title>
		<author>
			<persName><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1954" to="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Shaping social activity by incentivizing users</title>
		<author>
			<persName><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2474" to="2482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Recurrent marked temporal point processes: Embedding event history to vector</title>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gomez-Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1555" to="1564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Correlated Cascades: Compete or Cooperate</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zarezade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khodadadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st AAAI Conference on Artificial Intelligence</title>
		<meeting>the 31st AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Coevolutionary latent feature processes for continuous-time user-item interactions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="4547" to="4555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recurrent poisson factorization for temporal recommendation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khodadadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arabzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Rabiee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">An introduction to the theory of point processes: volume II: general theory and structure</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Daley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vere-Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Survival and event history analysis: a process point of view</title>
		<author>
			<persName><forename type="first">O</forename><surname>Aalen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Borgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gjessing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Poisson processes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F C</forename><surname>Kingman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A novel connectionist system for unconstrained handwriting recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bertolami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="855" to="868" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cooperative coevolution of elman recurrent neural networks for chaotic time series prediction</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="116" to="123" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A recurrent latent variable model for sequential data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Graphical models, exponential families, and variational inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="305" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Stochastic gradient vb and the variational auto-encoder</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Purchase behavior prediction in m-commerce with an optimized sampling methods</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Data Mining Workshop (ICDMW)</title>
		<imprint>
			<date type="published" when="2015-11">Nov 2015</date>
			<biblScope unit="page" from="1085" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Measuring urban social diversity using interconnected geosocial networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hristova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Musolesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Panzarasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mascolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Wasserstein learning of deep generative point process models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farajtabar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="3247" to="3257" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
