<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DiffusionDialog: A Diffusion Model for Diverse Dialog Generation with Latent Space</title>
				<funder ref="#_cvht9Wp">
					<orgName type="full">Collaborative Innovation Center of Novel Software Technology and Industrialization</orgName>
				</funder>
				<funder ref="#_RPMKdr6">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder>
					<orgName type="full">Priority Academic Program Development of Jiangsu Higher Education Institutions</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jianxiang</forename><surname>Xiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenhua</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Haodong</forename><surname>Liu</surname></persName>
							<email>liuhaodong05@meituan.com</email>
							<affiliation key="aff1">
								<address>
									<country>Meituan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yin</forename><surname>Bai</surname></persName>
							<email>baiyin@meituan.com</email>
							<affiliation key="aff1">
								<address>
									<country>Meituan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jia</forename><surname>Cheng</surname></persName>
							<email>jia.cheng.sh@meituan.com</email>
							<affiliation key="aff1">
								<address>
									<country>Meituan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
							<email>wlchen@suda.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DiffusionDialog: A Diffusion Model for Diverse Dialog Generation with Latent Space</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Dialogue System</term>
					<term>Diffusion Model</term>
					<term>One-to-many Modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In real-life conversations, the content is diverse, and there exists the one-to-many problem that requires diverse generation. Previous studies attempted to introduce discrete or Gaussian-based continuous latent variables to address the one-to-many problem, but the diversity is limited. Recently, diffusion models have made breakthroughs in computer vision, and some attempts have been made in natural language processing. In this paper, we propose DiffusionDialog, a novel approach to enhance the diversity of dialogue generation with the help of diffusion model. In our approach, we introduce continuous latent variables into the diffusion model. The problem of using latent variables in the dialog task is how to build both an effective prior of the latent space and an inferring process to obtain the proper latent given the context. By combining the encoder and latent-based diffusion model, we encode the response's latent representation in a continuous space as the prior, instead of fixed Gaussian distribution or simply discrete ones. We then infer the latent by denoising step by step with the diffusion model. The experimental results show that our model greatly enhances the diversity of dialog responses while maintaining coherence. Furthermore, in further analysis, we find that our diffusion model achieves high inference efficiency, which is the main challenge of applying diffusion models in natural language processing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Open-domain dialogue generation is a crucial component in dialogue systems. With the development of pre-trained language models, current models are capable of generating fluent and relevant dialogues <ref type="bibr" target="#b22">(Radford et al., 2019;</ref><ref type="bibr" target="#b23">Raffel et al., 2020)</ref>. However, there is still a lack of exploration in generating diverse responses, because there may be multiple appropriate responses when presented with a single context, and that's known as the oneto-many mapping problem, shown as figure <ref type="figure" target="#fig_1">1</ref>. To model the one-to-many relationship between dialog history and response, <ref type="bibr" target="#b3">Bao et al. (2019)</ref> introduce discrete latent variables, but the diversity of response is constrained by the categories of discrete latent variables, making it challenging to achieve fine-grained diversity generation. <ref type="bibr" target="#b31">Sun et al. (2021)</ref> and <ref type="bibr">Chen et al. (2022b)</ref> introduce continuous latent variable which can relief the problem of the discrete latent variables, but the prior of the model is limited by the inflexible prior distribution, which cannot model the distribution of the response well.</p><p>As an alternative solution of one-to-many problem, we propose the integration of a diffusion model <ref type="bibr" target="#b11">(Ho et al., 2020)</ref>, which have shown its' superiority of generating high-quality and diverse results in the fields of image and audio genera- *</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>*Corresponding author</head><p>He is a good guy.  tion <ref type="bibr" target="#b6">(Dhariwal and Nichol, 2021;</ref><ref type="bibr" target="#b24">Ramesh et al., 2022;</ref><ref type="bibr" target="#b25">Rombach et al., 2022;</ref><ref type="bibr" target="#b12">Kong et al., 2020)</ref>. As for text-generation, DiffuSeq <ref type="bibr" target="#b9">(Gong et al., 2022)</ref> uses the Diffusion-LM <ref type="bibr" target="#b16">(Li et al., 2022)</ref> structure for sequence-to-sequence tasks in a nonautoregressive manner, and both models perform diffusion operations in the embedding space. However, there are several important drawbacks. Firstly, the inference speed of the model will be greatly limited by the context length, especially in multi-turn dialogue scenarios where time consumption can be disastrous. Secondly, these models need to be trained from scratch and cannot take advantage of pre-trained language models. Some work has also attempted to combine diffusion models with latent variable. For example, LATENTOPS <ref type="bibr" target="#b18">(Liu et al., 2022)</ref> applies diffusion models in latent space for controllable text generation tasks, this approach involves training multiple classifiers for different control requirements, and using the corresponding classifier to guide the inference of diffusion model in order to achieve controlled generation of text. However, as a complex conditional generation task, it is difficult to train classifiers to guide the latent inference process for dialogue generation.</p><p>In this work, we propose a structure that combines a latent-based diffusion model with a pretrained language model to address the one-tomany modeling problem in multi-turn dialogues, called DiffusionDialog. DiffusionDialog integrates a encoder-decoder structured pre-trained language model Bart <ref type="bibr" target="#b13">(Lewis et al., 2019</ref>) and a latent-based <ref type="bibr" target="#b32">(Vaswani et al., 2017)</ref> diffusion model with transformer decoder structure. It performs inference of the diffusion model in the fixeddimensional latent space, and combines the diffusion model with the language model for specific response generation. Instead of learning to approximate the fixed prior (e.g. Gaussian distribution) of the latent variable, our diffusion model learns a more flexible prior distribution from the encoder, enabling the generation of responses with finergrained diversity. And due to the low-dimensional nature of the latent space, our diffusion model overcomes the slow inference speed issue which is the major problem of diffusion models.</p><p>The contributions of this paper can be summarized as follows:</p><p>1. We propose a novel approach to address the one-to-many problem in dialogue using a combination of a latent-based diffusion model and a pre-trained language model. 2. To the best of our knowledge, our work is the first to apply a latent diffusion model to dialog generation. By reasoning in the latent space, the inference efficiency of our diffusion model is significantly improved.</p><p>3. Through comparative experiments, we demonstrate the effectiveness of our model, which can generate responses that are rich in diversity while ensuring fluency and coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Dialog Generation with Latent Variable</head><p>The objective of dialog system is to estimate the conditional distribution p(x|c).</p><formula xml:id="formula_0">Let d = [u 1 , ..., u k ] denote a dialogue comprising of k ut- terances. Each utterance is represented by u i = [w 1 , ..., w |ui| ],</formula><p>where w n refers to the n-th word in u i . Additionally, we define c = [u 1 , ..., u k-1 ] as the dialogue context, which constitutes the k -1 historical utterances, and x = u k as the response, which denotes the next utterance in the dialogue.</p><p>Finding a direct connection between the discrete token sequences x and c can be challenging. To address this issue, we propose the use of a continuous latent variable z, which serves as a high-level representation of the response. In this two-step response generation process, we first sample a latent variable z from a distribution p θ (z|c) that resides in a latent space Z. Subsequently, we decode the response x from z and c as p θ (x|z, c).And this process can be estimated as</p><formula xml:id="formula_1">p θ (x|c) = z p θ (z|c)p θ (x|z, c)d z .</formula><p>(1)</p><p>Since the optimal z is intractable, we optimize the posterior distribution of z as q ϕ (z|x) considering the x. And we approximate the posterior with the prior distribution p θ (z|c),</p><formula xml:id="formula_2">log p θ (x|c) = log z q ϕ (z|x)p θ (x|z, c) ≥ E z∼q ϕ (z|x) [log p θ (x|z, c)] -KL(q ϕ (z|x), p θ (z|c)).</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Diffusion Model in Latent Space</head><p>Diffusion model is designed to operate in fixed and continuous domain, consisting forward and reverse processes. In this work, we perform forward and reverse process in learned latent space representing the high-level semantic of response. Suppose posterior as z 0 ∼ q ϕ (z|x), in the forward process, z 0 is corrupted with standard Gaussian noise in large amount of step, forming a Markov chain of z 0 , z 1 , ..., z T , with z T ∼ N (0, I):</p><formula xml:id="formula_3">q(z t |z t-1 ) = N (z t ; 1 -β t z t-1 , β t I),<label>(3)</label></formula><p>where β t ∈ (0, 1) controls the scale of the noise in a single step.</p><p>In the reverse progress, diffusion model learn to reconstruct z 0 from z T by learning p θ (z t-1 |z t ) = N (z t-1 ; µ θ (z t , t), Σ θ (z t , t)), Since the q(z t-1 |z t , z 0 ) has a closed form,the canonical objective is the variational lower bound of log p θ (z 0 ),</p><formula xml:id="formula_4">L vlb = E q [D KL (q (z T | z 0 ) ∥p θ (z T ))] +E q T t=2 D KL (q (z t-1 | z t , z 0 ) ∥p θ (z t-1 | z t , t)) -log p θ (z 0 | z 1 ) .</formula><p>(4) To promote stability in training, we take advantage of the simplified objective proposed by Ho et al. as L simple ,</p><formula xml:id="formula_5">L simple (z 0 ) = T t=1 E q(zt|z0) ∥µ θ (z t , t) -μ (z t , z 0 ) ∥ 2 , (5)</formula><p>where μ(z t , z 0 ) refers to q(z t-1 |z t , z 0 ), and µ θ (z t , z 0 ) is learned by diffusion model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DiffusionDialog</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Model Architecture</head><p>Our model introduces a hierarchical generation process with latent variable. Firstly it obtains latent variable reflecting the semantic of response from the context and then generate the response considering the latent variable and the context (Equation <ref type="formula">1</ref>), thus the response generation involves three key components: the dialogue context c, the response r, and the latent variable z.</p><p>We combines encoder-decoder structured pretrained language model Bart with a latent-based diffusion model to handle the two-stage generation, the figure 2 illustrates our model, and we explain our model by illustrating the function of each part of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Bart Encoder</head><p>The bart encoder plays a dual role in our model, encoding both the contex and the latent variables.</p><p>For context, following the PLATO, in addition to token and position embeddings, it also incorporates turn embeddings to align with the context turn number, and role embeddings to align with the speaker's role. As a result, the final embedding input of the context is the sum of corresponding token, turn, role, and position embeddings.</p><p>For latent variables, since the priors are untraceable, bart encoder learns the priors of the latent variable q ϕ (z|x) which represents the high-level semantic information about the response.</p><p>To connect the latent space, we concatenate a special token in front of the response to encode the semantic information of the response. We refer to this special token as latent toke. Therefore, the input format for latent variable encoding is [l, w x 1 , w x 2 ..., w x n ], n refers to the length of response x.</p><p>We append a multilayer perceptron to obtain a representation of the posterior distribution z 0 ∼ q ϕ (z|x) :</p><formula xml:id="formula_6">z 0 = M LP (h [L] ),<label>(6)</label></formula><p>where h [L] ∈ R d refers to the final hidden state of the latent token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Latent Diffusion Denoiser</head><p>After obtaining z 0 from the bart encoder, we sample a time step t ∈ [1, T ] uniformly and add noise to the latent variable according to Equation 3, resulting in a noised latent z t . The latent diffusion denoiser is trained to denoise the latent. It adopts the structure of a transformer decoder, taking the noised latent variable as inputs and incorporates the context hidden state with cross-attention mechanism, and a timestep embedding is also added before the first Transformer block to inform the model of the current timestep,</p><formula xml:id="formula_7">z0 = Denoiser(z t , e t , h c ),<label>(7)</label></formula><p>where e t refers to the embedding of the timestep t.</p><p>Since the context hidden state is fixed during inference, the inference time required for the diffusion model is short.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Bart Decoder</head><p>To guide the response generation of the decoder using latent variables, we adopt the memory scheme from OPTIMUS <ref type="bibr" target="#b37">(Li et al., 2020)</ref>. Specifically, we project the latent variable z as a key-value pair and concatenate them to the left of the token hidden state to introduce the latent variable into the decoder.</p><formula xml:id="formula_8">H (l+1) = M ultiHead(H (l) , h (l) M em ⊕ H (l) , h (l) M em ⊕ H (l) ),</formula><p>where H (l) refers to the token hidden state of the l-th layer, and h</p><p>M em is calculated as:</p><formula xml:id="formula_10">h (l) M em = z key z value = W l M z,<label>(8)</label></formula><p>where W l M ∈ R d×2d is a weight matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training</head><p>During our training process for dialogue generation, we utilize three different loss functions: negative log-likelihood (NLL) loss, bag-of-words (BOW) loss, and latent denoising (LD) loss. Detailed descriptions will be provided in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Response semantic capture</head><p>To enable the latent variable to capture the overall semantic information of the response, we adopt the bag-of-words (BOW) <ref type="bibr" target="#b36">(Zhao et al., 2017)</ref> loss, which is used to enable the latent variable to predict the tokens in the response in a non-autoregressive manner.</p><formula xml:id="formula_11">L BOW = -E z0∼q ϕ (z|r) N n=1 log p(r t |z 0 ) = -E z0∼q ϕ (z|r) N n=1 log e fr n v∈V e fv .<label>(9)</label></formula><p>The symbol V refers to the entire vocabulary. The function f attempts to non-autoregressively predict the words that make up the target response.</p><formula xml:id="formula_12">f = softmax (W 2 h z + b 2 ) ∈ R |V | .</formula><p>(10)  In the given equation, h z represents the hidden state of the latent variable, while |V | denotes the size of the vocabulary. The estimated probability of word r n is denoted by f rn . BOW loss disregards the word order and compels the latent variable to capture the overall information of the target response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Latent Denoising</head><p>For each training step, we sample a time step t and obtain z t referring to Equation 3. To better capture the semantic information of the latent variables, our diffusion model predicts z 0 directly instead of z t-1 given z t , denoted as L z0-simple , a variant of L simple in Equation <ref type="formula">5</ref>:</p><formula xml:id="formula_13">L z0-simple (z 0 ) = T t=1 E zt ∥p (z t , c, t) -z 0 ∥ 2 . (<label>11</label></formula><formula xml:id="formula_14">)</formula><p>where our latent diffusion denoiser p (z t , h c , t) predicts z 0 directly. Thus at each time step, the loss of latent denoising is:</p><formula xml:id="formula_15">L LD = ∥p (z t , t, c) -z 0 ∥ 2 . (<label>12</label></formula><formula xml:id="formula_16">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Response Generation</head><p>In our model, the response is generated by conditioning on both the latent variable and the context.</p><p>To train the response generation we adopt the commonly used NLL loss,</p><formula xml:id="formula_17">L N LL = -E z0∼p(z|c,zt,t) log p(r | c, z0 ) = -E z0∼p(z|c,zt,t) N n=1 log p (r t | c, z0 , r &lt;t ) .</formula><p>(13) Note that z0 is the posterior distribution predicted by the latent diffusion denoiser, we adopt this approach to reduce the gap between training and inference. In order to optimize the NLL loss, the denoiser's prediction needs to not only be close to the prior distribution z 0 in the spatial domain, but also approximate the response in the semantic domain.</p><p>In summary, our model aims to minimize the overall objective function, which is defined as the integrated loss:</p><formula xml:id="formula_18">L = L N LL + L BOW + L LD .<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Inference</head><p>The inference in our model consists of two stages. Firstly, starting from a Gaussian noise, the latent diffusion denoiser performs multiple rounds of inference to denoise the latent variable and obtain the final semantic representation z 0 , conditioned on the hidden state of the context which is encoded by the encoder. Then the response generator generates the final response in an auto-regressive manner, conditioned on both z 0 and the context hidden state.</p><p>For ease of displaying the training and inference process of our model, we outline our approach in Figure <ref type="figure">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Datasets and Evaluation</head><p>Following PLATO <ref type="bibr" target="#b3">(Bao et al., 2019)</ref>,we evaluate the performance of our model on two commonly used public dialog datasets.</p><p>DailyDialog <ref type="bibr" target="#b17">(Li et al., 2017</ref>) is a high-quality conversational dataset that primarily focuses on daily dialogues.</p><p>Persona-Chat <ref type="bibr" target="#b35">(Zhang et al., 2018)</ref> is sourced from authentic conversations between human annotators who are randomly matched and assigned a given persona information. Paired annotators engage in natural conversation and attempt to know each other better throughout the dialogue. Table <ref type="table" target="#tab_1">1</ref> summarizes the descriptions and statistics of these datasets. In DailyDialog, 12.1% of the development set and 13.0% of the test set appeared in the training set, indicating the presence of data leakage, while no such issue is observed in PersonaChat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Training</head><formula xml:id="formula_19">Input: a dialog corpus D={(c i , r i )} |D| i=1 1: repeat 2: sample context and response (c, r) from D 3: h c = Encoder(c) 4: z 0 ∼ q ϕ (z|r) = Encoder([l; x])[0] 5: L BOW = - N n=1 log p(r t |z 0 ) 6: t ∼ Uniform({1, . . . , T }) 7: ϵ ∼ N (0, I) 8: z t = √ ᾱt z 0 + √ 1 -ᾱt ϵ 9: z0 = Denoiser(z t , h c , t) 10: L LD = -∥ z0 -z 0 ∥ 2 11: L N LL = - N n=1 log p (r t | c, z0 , r &lt;t ) 12: Take gradient descent step on ∇ θ [L = L LD + L N LL + L BOW ] 13: until converged Algorithm 2 Inference 1: h c = Encoder(c) 2: zT ∼ N (0, I) 3: for t = T, . . . , 1 do 4: z0 = Denoiser( zt , h c , t) 5: ϵ ∼ N (0, I) 6: zt-1 = √ ᾱt-1 z0 + √ 1 -ᾱt-</formula><p>For evaluation, we mainly evaluate our model on fluency and diversity. We adopt the same metrics used in PLATO, which is widely used:</p><p>BLEU-1/2 <ref type="bibr" target="#b21">(Papineni et al., 2002)</ref> which measures the coherence of generated response to the given context by calculating the 1/2-grams overlapping between the generated response and references.</p><p>Distinct-1/2 <ref type="bibr" target="#b15">(Li et al., 2015)</ref> which measures the diversity of generated response by calculating the number of unique 1/2-grams divided by the total number of generated words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Compared Baselines</head><p>In our experiments, the following models were selected as our baselines.</p><p>Seq2Seq(Vinyals and Le, 2015) is a sequenceto-sequence model with attention. IVAE MI <ref type="bibr" target="#b7">(Fang et al., 2019)</ref>  Both of PLATO and DialogVED address the one-tomany problem in dialogue tasks and are the main objects of comparison in our study.</p><p>To accurately evaluate the impact of our latent variable with diffusion model, we compare our model to the version without the latent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">Model Configuration</head><p>Our model consists of two parts: one is a encoderdecoder structure Transformer model Bart-base, which is composed of 6 layers of encoder and 6 layers of decoder. The other part of our model is a latent denoiser, which is a structure of 6 layers of transformer decoder with latent token embedding and 128-dimensional time step embedding. Our diffusion steps T = 2, 000 and noise schedule is square-root schedule. Our maximum context squence length is 256 and our maximum response sequence length 128, The model uses the BPE tokenization <ref type="bibr" target="#b27">(Sennrich et al., 2015)</ref> which is commonly used.</p><p>During training, We use Adamw optimizer <ref type="bibr" target="#b19">(Loshchilov and Hutter, 2017)</ref> with a learning rate of 1 × 10 -4 , the batch size is 128, We also adopt a warmup strategy where we linearly increase the learning rate from initial learning rate 1 × 10 -7 , the totall training steps for DailyDialog is 10000, and for PersonaChat is 20000. We select the checkpoint with the lowest validation loss for Model DailyDialog BLEU-1 BLEU-2 Distinct-1 Distinct-2 Seq2Seq <ref type="bibr" target="#b33">(Vinyals and Le, 2015)</ref> 0.336 0.238 0.030 0.128 iVAE_MI <ref type="bibr" target="#b7">(Fang et al., 2019)</ref> 0  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Main Results</head><p>Table <ref type="table" target="#tab_3">2</ref> summarizes the experimental results on Persona-Chat and Daily Dialog.</p><p>Note that both the PLATO and DialogVED models have been pre-trained on a large corpus of dialogue data. Additionally, the DialogVED model is based on Bart-large(0.47B), which gives it a significant advantage in terms of the number of parameters compared to our model(0.21B).</p><p>The PLATO model uses discrete latent variables, while DialogVED uses a VAE-based continues latent variable, We compared our model with these two models to demonstrate the advantages of handling latent variables using the diffusion model.</p><p>To more effectively evaluate the impact of our latent discrete variable, we also conducted a comparison with the version that does not include a latent variable (referred to as 'Our w/o Latent'). It accepts the same context embedding input as our model, and also using Bart-base as it's backbone, sharing the same training settings as our method with latent variables.</p><p>The last line represents the upper bound of our model, we generate 10 different latent variable for the same context and use them to generate corresponding responses as candidates. We select the candidate with the highest overlap with the reference, i.e., the highest Bleu-1 score, as our final result.</p><p>DiffusionDialog represents the result of our model with one candidate, and all models use Beam Search for decoding, with a beam size of 5. Our diffusion model utilizes the DDIM <ref type="bibr">(Song et al., 2020a)</ref> acceleration technique during inference, with a sampling time step of 50 for the purpose of performance and time efficiency, the results under different inference time steps will be discussed in detail in the later section.</p><p>As shown in Table <ref type="table" target="#tab_3">2</ref>, our model achieves very high results on the Dist metric. However, compared to the version without latent variable, there is a certain decrease in the Bleu metric, but our model still achieves competitive results in models that have not been pre-trained on dialogue data. The performance of our method without latent variable on the Bleu metric is similar to that of PLATO, which we attribute to the performance of the Bart pre-training model, benefiting from the encoder-decoder architecture and generative pre-training. Compared to DialogVED, which has the same architecture as ours but has more parameters and is pre-trained on dialogue data, our model's Bleu score is much lower.</p><p>We notice that the drop in Bleu score due to the introduction of latent variables is smaller on PersonaChat than on DailyDialog. Combining with the statistics in  formance also demonstrate the potential of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Case Analysis</head><p>In order to further demonstrate the generative capabilities of our model, we provide some generated responses in Table <ref type="table" target="#tab_4">3</ref>. The table illustrates five of these responses, which showcase the model's ability to generate diverse, relevant, and fluent response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Inference Speed</head><p>We compare the inference speed of our model with DialogVED, PLATO, DiffuSeq, and the results are shown in Table <ref type="table" target="#tab_6">4</ref>. Note that the framwork used for inference among the models are different. PLATO was run on paddlepaddle, DialogVED was run on fairseq, DiffuSeq and our model was just run on pytorch. The number following DiffusionDialog and DiffuSeq represents the number of time steps used for inference.</p><p>As the table shows, due to the absence of inference on latent variables, the inference time for our method without latent is very short, and Dif-fusionDialog is comparable When the number of inference time steps is 10, which demonstrates the high efficiency of our model's inference.</p><p>DiffuSeq, like DiffusionDialog, utilizes a diffusion model for text generation. We compare Diffusion-Dialog with the DiffuSeq model to demonstrate the advantage in inference speed of our diffusion model.</p><p>To ensure fairness in comparison, we set the maximum input length of these models to 256. At inference time steps of 10, 100, and 1000, our model required less time for inference than the DiffuSeq model. Moreover, as the number of infer- PLATO introduces discrete latent variables, which require generating all candidate responses based on these latent variables, thereby requiring a considerable amount of time. In this comparative experiment, we used 20 discrete latent variables (K = 20), the same as the official version provided. For DialogVED, we used their large version with P = 64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Sampling Steps</head><p>During inference, the diffusion model requires a large number of sampling steps, which is a significant bottleneck for the inference speed. And prior work, e.g., DiffuSeq <ref type="bibr" target="#b9">(Gong et al., 2022)</ref> suffers from a significant drop in generation quality when reducing the sampling steps. In order to investigate the performance of our model on the test dataset under different numbers of sampling steps, we present the results in Table <ref type="table" target="#tab_7">5</ref>.</p><p>As shown in the table, our method achieves competitive results with as few as 10 on both dataset. It should be noted that as the number of sampling steps increases, the performance of our model on PersonaChat, as measured by the BLEU metric, first decreases and then improves. At 1000 time steps, all metrics reach their peak, but the difference between 1000 and 10 steps is not significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">One-to-many Modeling</head><p>The existence of multiple suitable responses for a given context is referred to as the one-to-many problem. Some works introduce latent variable to model the relationship, CVAE <ref type="bibr" target="#b36">(Zhao et al., 2017)</ref> utilizes Gaussian distribution to capture variations in responses at the discourse level, since a simple distribution over the latent variables has a lack of granularity in modeling the semantic information of the responses, DialogWAE <ref type="bibr" target="#b10">(Gu et al., 2018)</ref> develop a Gaussian mixture prior network to enrich the latent space, instead of the single Gaussian prior of VAE. iVAE MI <ref type="bibr" target="#b7">(Fang et al., 2019)</ref> address the challenge with implicit learning. Di-alogVED <ref type="bibr">(Chen et al., 2022b)</ref> incorporates continuous latent variables into an enhanced encoder-decoder pre-training framework to increase the relevance and diversity of responses. PLATO <ref type="bibr" target="#b3">(Bao et al., 2019)</ref> introduces discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Both of PLATO and DialogVED are pretrained with large dialog corpus, providing a strong baseline for one-to-many modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Diffusion Models for Sequence Learning</head><p>Since Diffusion model <ref type="bibr" target="#b6">(Dhariwal and Nichol, 2021;</ref><ref type="bibr">Song et al., 2020b)</ref> has achieved breakthroughs in the field of image processing. There have been many works attempting to apply diffusion models to the field of natural language processing. Considering the discrete nature of texts, D3PM <ref type="bibr" target="#b2">(Austin et al., 2021)</ref> introduce Markov transition matrices to diffuse the source data instead of Gaussian noise, Analog Bits <ref type="bibr">(Chen et al., 2022a)</ref> represents discrete data as binary bits, and then training a continuous diffusion model to model these bits as real numbers. Diffusion-LM <ref type="bibr" target="#b16">(Li et al., 2022)</ref> develop a non-autoregressive language model based on continuous diffusions with an embedding function and rounding process, iteratively denoises a sequence of Gaussian vectors into words. DiffuSeq <ref type="bibr" target="#b9">(Gong et al., 2022)</ref> propose a diffusion model designed for sequence-to-sequence text generation tasks utilizing encoder-only Transformers. And SeqDif-fuSeq <ref type="bibr" target="#b34">(Yuan et al., 2022)</ref> approach sequence-tosequence text generation with Encoder-Decoder Transformers. LD4LG <ref type="bibr" target="#b20">(Lovelace et al., 2022)</ref> learn the continuous diffusion models in the latent space of a pre-trained encoder-decoder model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper presents DiffusionDialog, which combines an encoder-decoder structured pre-trained language model with diffusion model. By utilizing the diffusion model to learn the latent space and infer the latent by denoising step by step, we greatly enhance the diversity of dialog response while keeping the coherence and achieving high inference efficiency. As experimental results shows, our model has achieved a over 50% increase in the dist metric and accelerate inference speed over 50 times compared to the DiffuSeq model. Overall, this work provides a novel idea for applying diffusion model into natural language processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Limitations</head><p>As shown in the experiments, the accuracy of our model is not yet high enough. We identified two main reasons for this: 1) we have not conducted extensive pre-training, and 2) the structure and training methods of the model are not yet optimal. We will attempt to address these issues in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>great shape of body What do you think of Tom? Sorry, but i don't konw We always have a good time together</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: one to many problem in dialog generation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: frame work of DiffusionDialog.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>1 ϵ 7: end for 8: response r = Decoder( z0 , h c ) Summary of datasets used in the experiments, overlap means percentage of data leaks.</figDesc><table><row><cell cols="3">Figure 3: The training and inference algorithm of</cell></row><row><cell cols="2">DiffusionDialog.</cell><cell></cell></row><row><cell></cell><cell>DailyDialog</cell><cell>PersonaChat</cell></row><row><cell>train</cell><cell>76052 samples \</cell><cell>122499 samples \</cell></row><row><cell>dev</cell><cell>7069 samples 12.1% overlap</cell><cell>14602 samples \</cell></row><row><cell>test</cell><cell>6740 samples 13.0% overlap</cell><cell>14056 samples \</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Experimental results on DailyDialog and PersonaChat with automatic evaluations. PLATO and DialogVED is pretrained with large dialog corpus, and DialogVED is based on Bart Large. The best values are underlined, and the best results with base-PLMs is written in bold.</figDesc><table><row><cell>.309</cell><cell>0.249</cell><cell>0.029</cell><cell>0.250</cell></row></table><note><p>context [P1]It's a lovely day out today, isn't it? [P2]It's beautiful. Enjoy it while it lasts. It's supposed to get cold tomorrow.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Examples of response generation with our model.</figDesc><table><row><cell>inference. The experiment is carried out on one</cell></row><row><cell>single 1080Ti GPU.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>, we can infer that the data</cell></row><row><cell>leakage in the test set and development set of</cell></row><row><cell>DailyDialog penalizes the diversity of generated</cell></row><row><cell>results.</cell></row><row><cell>The improvement in our model's Dist value com-</cell></row><row><cell>pared to PLATO and DialogVED indicates that in-</cell></row><row><cell>troducing latent variables based on the diffusion</cell></row><row><cell>model can more effectively improve the diversity of</cell></row><row><cell>generated responses compared to discrete latent</cell></row><row><cell>variables and continuous latent variables based</cell></row><row><cell>on a fixed Gaussian prior. Meanwhile, our exper-</cell></row><row><cell>iments on the upper bound of our model's per-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Comparison of inference speed among models, models with symbol ⋄ utilize diffusion model.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Impact of number of sampling steps on performance.</figDesc><table><row><cell>Steps</cell><cell cols="3">DailyDialog Bleu-1 Bleu-2 Dist-1 Dist-2 Bleu-1 Bleu-2 Dist-1 Dist-2 PersonaChat</cell></row><row><cell>10</cell><cell>0.350</cell><cell>0.318 0.071 0.369 0.385</cell><cell>0.331 0.031 0.172</cell></row><row><cell>100</cell><cell>0.348</cell><cell>0.319 0.073 0.372 0.380</cell><cell>0.328 0.031 0.169</cell></row><row><cell>1000</cell><cell>0.352</cell><cell>0.327 0.074 0.373 0.389</cell><cell>0.331 0.032 0.181</cell></row><row><cell cols="3">ence steps increased, our model's speed advan-</cell><cell></cell></row><row><cell>tage grew.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8.">Acknowledgments</head><p>This work is supported by the <rs type="funder">National Natural Science Foundation of China</rs> (Grant No.  <rs type="grantNumber">62261160648</rs> and <rs type="grantNumber">62376177</rs>). This work is also supported by <rs type="funder">Collaborative Innovation Center of Novel Software Technology and Industrialization</rs>, the <rs type="funder">Priority Academic Program Development of Jiangsu Higher Education Institutions</rs>, and the joint research project of Meituan and <rs type="institution">Soochow University</rs>. We would also like to thank the anonymous reviewers for their insightful and valuable comments.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_RPMKdr6">
					<idno type="grant-number">62261160648</idno>
				</org>
				<org type="funding" xml:id="_cvht9Wp">
					<idno type="grant-number">62376177</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Audio visual scene-aware dialog</title>
		<author>
			<persName><forename type="first">Huda</forename><surname>Alamri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Cartillier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irfan</forename><surname>Essa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><forename type="middle">K</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiori</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7558" to="7567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Structured denoising diffusion models in discrete state-spaces</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Daniel D Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rianne</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="17981" to="17993" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07931</idno>
		<title level="m">Plato: Pre-trained dialogue generation model with discrete latent variable</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">2022a. Analog bits: Generating discrete data using diffusion models with self-conditioning</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruixiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.04202</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">2022b. Dialogved: A pre-trained latent variable encoderdecoder model for dialog response generation</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bolun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhen</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bartuer</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.13031</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Diffusion models beat gans on image synthesis</title>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Nichol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8780" to="8794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Implicit deep latent variable models for text generation</title>
		<author>
			<persName><forename type="first">Le</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.11527</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Large-scale transfer learning for natural language generation</title>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Golovanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rauf</forename><surname>Kurbanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Nikolenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyryl</forename><surname>Truskovskyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Tselousov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6053" to="6058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Diffuseq: Sequence to sequence text generation with diffusion models</title>
		<author>
			<persName><forename type="first">Shansan</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mukai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangtao</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.08933</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Dialogwae: Multimodal response generation with conditional wasserstein auto-encoder</title>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.12352</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ajay</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6840" to="6851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaji</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.09761</idno>
		<title level="m">Diffwave: A versatile diffusion model for audio synthesis</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>Bart</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Optimus: Organizing sentences via pre-trained modeling of a latent space</title>
		<author>
			<persName><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04092</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03055</idno>
		<title level="m">A diversity-promoting objective function for neural conversation models</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Diffusion-lm improves controllable text generation</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Thickstun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori B</forename><surname>Hashimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4328" to="4343" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuzi</forename><surname>Niu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.03957</idno>
		<title level="m">Dailydialog: A manually labelled multi-turn dialogue dataset</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeyu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junwei</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuguang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.00638</idno>
		<title level="m">Composable text controls in latent space with odes</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<title level="m">Decoupled weight decay regularization</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Latent diffusion for language generation</title>
		<author>
			<persName><forename type="first">Justin</forename><surname>Lovelace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eliot</forename><surname>Shekhtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.09462</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5485" to="5551" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Hierarchical text-conditional image generation with clip latents</title>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Casey</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.06125</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">High-resolution image synthesis with latent diffusion models</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Rombach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Blattmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Lorenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Björn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="10684" to="10695" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cmu sinbad&apos;s submission for the dstc7 avsd challenge</title>
		<author>
			<persName><forename type="first">Ramon</forename><surname>Sanabria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Palaskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Metze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DSTC7 at AAAI2019 workshop</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.07909</idno>
		<title level="m">Neural machine translation of rare words with subword units</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenlin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02502</idno>
		<title level="m">Denoising diffusion implicit models</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.13456</idno>
		<title level="m">Score-based generative modeling through stochastic differential equations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Generating relevant and coherent dialogue responses using self-separated conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoxiong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiamou</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03410</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.10325</idno>
		<title level="m">Seqdiffuseq: Text diffusion with encoder-decoder transformers</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Personalizing dialogue agents: I have a dog</title>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07243</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>do you have pets too? arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10960</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The design and implementation of xiaoice, an empathetic social chatbot</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="93" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
