<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">From Orthogonality to Dependency: Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-05-25">25 May 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ruichu</forename><surname>Cai</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhifan</forename><surname>Jiang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zijian</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Mohamed bin Zayed</orgName>
								<orgName type="institution">University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Weilin</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xuexin</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zhifeng</forename><surname>Hao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Shantou University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yifan</forename><surname>Shen</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Mohamed bin Zayed</orgName>
								<orgName type="institution">University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Mohamed bin Zayed</orgName>
								<orgName type="institution">University of Artificial Intelligence</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">From Orthogonality to Dependency: Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-05-25">25 May 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2405.16083v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T22:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing methods for multi-modal time series representation learning aim to disentangle the modality-shared and modality-specific latent variables. Although achieving notable performances on downstream tasks, they usually assume an orthogonal latent space. However, the modality-specific and modality-shared latent variables might be dependent on real-world scenarios. Therefore, we propose a general generation process, where the modality-shared and modality-specific latent variables are dependent, and further develop a Multi-modAl TEmporal Disentanglement (MATE) model. Specifically, our MATE model is built on a temporally variational inference architecture with the modality-shared and modality-specific prior networks for the disentanglement of latent variables. Furthermore, we establish identifiability results to show that the extracted representation is disentangled. More specifically, we first achieve the subspace identifiability for modality-shared and modality-specific latent variables by leveraging the pairing of multi-modal data. Then we establish the component-wise identifiability of modality-specific latent variables by employing sufficient changes of historical latent variables. Extensive experimental studies on multi-modal sensors, human activity recognition, and healthcare datasets show a general improvement in different downstream tasks, highlighting the effectiveness of our method in real-world scenarios. * Equal contributions Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most of the existing works for time series analysis <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref> are usually devised for homogeneous data, with the assumption that time series are sampled from the same modality. However, the heterogeneous time series data <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>, which are sampled from multiple modalities and not compatible with these methods, are also common in several real-world applications, e.g., Internet of Things (IoT) <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>, health care <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>, and finance <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. To model the multi-modal time series data, one mainstream solution is to disentangle the modality-specific and modality-shared latent variables from the observational time series signal.</p><p>Several methods are proposed to disentangle the modality-specific and modality-shared temporally latent variables. One mainstream approach is based on the contrastive learning method. For example, Deldari et.al proposes COCOA <ref type="bibr" target="#b17">[18]</ref>, which learns modality-shared representations by aligning the representation from the same timestamp, and Ouyang et.al propose Cosmo <ref type="bibr" target="#b18">[19]</ref>, which extracts modality-shared representations by using a iterative fusion learning strategy. Considering that the modality-specific representations also play an important role in the downstream task, Liu et.al <ref type="bibr" target="#b8">[9]</ref> use an orthogonality restriction and simultaneously leverage the modality-shared and modality-specific representations. Considering the multi-view setting as a special case of the multi-modal setting, Huang et.al <ref type="bibr" target="#b19">[20]</ref> develop the identifiability results of the latent temporal process by minimizing the contrastive objective function. In summary, these methods usually assume that the modalityshared and modality-specific latent variables are orthogonal, hence they can be disentangled by using different contrastive-learning-based constraints. Please refer to Appendix A1 for further discussion of related works, including multi-modal representation learning, multi-modal time series modeling, and the identifiability of generative models.  Although these methods achieve outstanding performance on several applications, the orthogonality of modality-shared and modalityspecific latent space may be too difficult to satisfy in real-world scenarios. Figure <ref type="figure" target="#fig_1">1</ref> provides an example of physiological indicators of diabetics, where brain-related and heartrelated signals are observed in time series data. Specifically, Figure <ref type="figure" target="#fig_1">1</ref> (a) denotes the true data generation process, where the causal directions from insulin concentration to blood pressure and heart rate denote how diabetes leads to complications of heart disease and high blood pressure. As shown in Figure <ref type="figure" target="#fig_1">1</ref> (b), existing methods that apply orthogonal constraints on the estimated latent variables despite the dependent true latent sources, lead to the entanglement of latent variables and further the suboptimal performance of downstream tasks.</p><p>To address the aforementioned challenge of dependent latent sources, we propose a multi-modal temporal disentanglement framework to estimate the ground-truth latent variables with identifiability guarantees. Specifically, we first leverage the pair-wise multi-modal data to establish the subspace identifiability of latent variables. Sequentially, we leverage the independent influence of historical latent variables to further show the component-wise identifiability of latent variables. Building on the theoretical results, we develop the Multi-modAl TEmporal Disentanglement (MATE) model, which incorporates variational inference neural architecture with modality-shared and modalityspecific prior networks. The proposed MATE is validated through extensive downstream tasks for multi-modal time series data. The impressive performance that outperforms state-of-the-art methods demonstrates its effectiveness in real-world applications.</p><p>2 Problem Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Generation Process of Multi-modal Time Series</head><p>To show how to learn disentangled representation for multi-modal time series data, we first introduce the data generation process as shown in Figure <ref type="figure" target="#fig_2">2</ref>. Specifically, we assume that the existence of M modalities S = {S 1 , S 2 , • • • , S M }. For each modality S m , time series data with discrete time steps x sm 1:T = {x sm 1 , x sm 2 , • • • , x sm T } with the length of T are drawn from a distinct distribution, represented as p(x sm 1:T ). Moreover, x sm t is generated from the modality-shared and modality-specific latent variables z c t , z sm t by an invertible and nonlinear mixing function g m shown as follows:</p><formula xml:id="formula_0">x sm t = g m (z c t , z sm t ).<label>(1)</label></formula><p>For convenience, we let z m t = {z c t , z sm t } be the latent variables of m-th modality. And we further let z c t = (z c t,i ) nc i=1 and z sm t = (z sm t,i ) n i=nc+1 . More specifically, the i-th dimension modality-shared latent variables z c t,i are time-delayed and related to the historical modality-shared latent variables z c t-τ with the time lag of τ via a nonparametric function f c i . Similarly, the modality-specific latent variables are generated via another nonparametric function f m i , which are formalized as follows: where PA denote the set of latent variables that directly cause z c t,i or z sm t,i , and ϵ sm t,i , ϵ c t,i denote the independent noise. Combining the example of diabetics in Figure <ref type="figure" target="#fig_1">1,</ref><ref type="figure" target="#fig_1">x s1</ref> t and x s2 t can be considered as brain-related and heart-related signals, respectively. The modality-shared variables z c t denote the insulin concentration and z s1 t , z s2 t denote the blood pressure and heart rate, respectively. z c t → {z s1 t , z s2 t } denotes that insulin concentration influences blood pressure and heart rate.</p><formula xml:id="formula_1">z c t,i = f c i (PA(z c t,i ), ϵ c t,i ), ϵ c t,i ∼ p ϵ c t,i z sm t,i = f m i (PA(z sm t,i ), ϵ sm t,i ), ϵ sm t,i ∼ p ϵ sm t,i ,<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Problem Definition</head><p>Based on the aforementioned data generation process, we further provide the problem definition. Specifically, We first suppose to have a set of M sensory modalities. Then, for each group of time series from M modalities, we let y be the corresponding label. Given the labeled multi-modal time series training set with the size of D, i.e., {X i , y i } D i=1 , we aim to obtain a model that can extract disentangled representations for multi-modal time series data, which can benefit the downstream tasks, i.e. estimate correct label. More mathematically, our goal is to estimate the distribution of the modality-specific latent variables p(z s1 1:T ), • • • , p(z s M 1:T ) and the modality-shared latent variables p(z c 1:T ) by modeling the observed multi-modal time series data, which are formalized as follows:</p><formula xml:id="formula_2">ln p(x s 1 1:T , • • • , x s M 1:T ) = z s 1 1:T • • • z s M 1:T z c 1:T ln p(x s 1 1:T , • • • , x s M 1:T |z s 1 1:T , • • • , z s M 1:T , z c 1:T ) + M m=1 ln p(z sm 1:T |z c 1:T ) + ln p(z c 1:T ) dz s 1 1:T • • • dz s M 1:T dz c 1:T .<label>(3)</label></formula><p>Therefore, to achieve this goal, we first devise a temporal variational inference architecture with prior networks to reconstruct the modality-specific and modality-shared latent variables, which are shown in Section 3. Sequentially, we further propose theoretical analysis to show that these estimated modality-shared and modality-specific latent variables are identifiable, which are shown in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MATE: Multi-modal Temporal Disentanglement Model</head><p>Based on the data generation process in Figure <ref type="figure" target="#fig_2">2</ref>, we proposed the Multi-modal temporal Disentanglement (MATE) model as shown in Figure <ref type="figure" target="#fig_3">3</ref>, which is built upon the variation auto-encoder. Moreover, it includes the shared prior networks and the private prior networks, which are used to preserve the dependence between the modality-specific and modality-shared latent variables. Furthermore, we devise a modality-shared constraint to enforce the invariance of modality-shared latent variables from different modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Variational-Inference-based Neural Architecture</head><p>We begin with the evidence lower bound (ELBO) based on the proposed data generation process. Without loss of generality, we consider two modalities, i.e., M = 2, so the ELBO can be formalized as Equation <ref type="bibr" target="#b3">(4)</ref>. Please refer to Appendix A3 for the details of derivation.  and L r denotes the reconstruct loss and it can be formalized as:</p><formula xml:id="formula_3">p(x s 1 1:T , x s 2 1:T ) ≥ Lr -DKL(q(z c 1:T |x s 1 1:T , x s 2 1:T )||p(z c 1:T )) Lc -DKL(q(z s 1 1:T |x s 1 1:T , z c 1:T )||p(z s 1 1:T |z c 1:T )) Ls 1 -DKL(q(z s 2 1:T |x s 2 1:T , z c 1:T )||p(z s 2 1:T |z c 1:T )) Ls 2 ,<label>(4)</label></formula><formula xml:id="formula_4">Lr =E q(z s 1 1:T |x s 1 1:T ,z c 1:T )) E q(z c 1:T |x s 1 1:T ,x s 2 1:T ) ln p(x s 1 1:T |z s 1 1:T , z c 1:T ) + E q(z s 2 1:T |x s 2 1:T ,z c 1:T ) E q(z c 1:T |x s 1 1:T ,x s 2 1:T ) ln p(x s 2 1:T |z s 2 1:T , z c 1:T )),<label>(5)</label></formula><p>where q(z s1 1:T |x s1 1:T , z c 1:T ), q(z s2 1:T |x s2 1:T z c 1:T ), and q(z c 1:T |x s1 1:T , x s2 1:T ) are used to approximate the prior distributions of modality-specific and modality-shared latent variables and are implemented by neural architecture based on convolution neural networks (CNNs). In practice, we devise a modality-specific encoder for each modality, which can be formalized as follows:</p><formula xml:id="formula_5">z s 1 1:T , z c 1 1:T = ψs 1 (x s 1 1:T ), z s 2 1:T , z c 2 1:T = ψs 2 (x s 2 1:T ),<label>(6)</label></formula><p>Moreover, since z c1 1:T and z c2 1:T should be as similar as possible, we further devise a modality-shared constraint as shown in Equation <ref type="bibr" target="#b6">(7)</ref>, which restricts the similarity of modality-shared latent variables between any two pairs of modalities.</p><formula xml:id="formula_6">Ls = s i ,s j ,∈S,i̸ =j log z cs i 1:T • z cs j 1:T |z cs i 1:T ||z cs j 1:T |<label>(7)</label></formula><p>By using the modality-shared constraint, we can simply let z c 1:T = z c1 1:T be the estimated modalityshared latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As for p(x s1</head><p>1:T |z s1 1:T , z c 1:T )) and p(x s2 1:T |z s2 1:T , z c 1:T )), which model the generation process from latent variables to observations via Multi-layer Perceptron networks (MLPs) as shown in Equation <ref type="bibr" target="#b7">(8)</ref>.</p><formula xml:id="formula_7">xs 1 1:T = ϕs 1 (z s 1 1:T , z c 1:T ), xs 2 1:T = ϕs 2 (z s 2 1:T , z c 1:T )<label>(8)</label></formula><p>Finally, the p(z s1 1:T |z c 1:T ), p(z s2 1:T |z c 1:T ) and p(z c 1:T ) in Equation ( <ref type="formula" target="#formula_3">4</ref>) denotes the prior distribution of latent variables, which are introduced in subsection 3.2. Please refer to Appendix A5 for more details on the architecture of the proposed MATE model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Specific and Shared Prior Networks</head><p>Shared Prior Networks for Modality-shared Estimation: To model the shared prior distribution p(z c 1:T ), we first review the transition function of shared latent variables in Equation <ref type="bibr" target="#b1">(2)</ref>. Without loss of generality, we consider the time-lag as 1, hence we let {r c i } be a set of inverse transition functions that take z c t,i , z c t-1 as input and output the independent noise, i.e., ϵ c t,i = r c i (z c t,i , z c t-1 ). Note that these inverse transition functions can be implemented by simple MLPs. Sequentially, we devise a transformation σ c := {ẑ c t-1 , ẑc t } → {ẑ c t-1 , εc t } and its corresponding Jacobian can be formalized as</p><formula xml:id="formula_8">J σ c = I 0 * diag ∂r c i ∂ ẑc t,i</formula><p>, where * denotes a matrix. By applying the change of variables formula, we have the following equation, we estimated the prior distribution as follows:</p><formula xml:id="formula_9">log p(ẑ c t-1 , ẑc t ) = log p(ẑ c t-1 , εc t ) + log |det(Jσc )|.<label>(9)</label></formula><p>Moreover, we can rewrite Equation <ref type="bibr" target="#b8">(9)</ref> to Equation (10) by using independent noise assumption.</p><formula xml:id="formula_10">log p(ẑ c t |ẑ c t-1 ) = log p(ε c t ) + nc i=1 log | ∂r c i ∂ ẑc t,i |. (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>As a result, the prior distribution shared latent variables can be estimated as follows:</p><formula xml:id="formula_12">p(ẑ c 1:T ) = p(ẑ c 1 ) T τ =2 nc i=1 log p(ε c τ,i ) + nc i=1 log | ∂r c i ∂ ẑc τ,i | ,<label>(11)</label></formula><p>where p(ε c τ,i ) is assumed to follow a standard Gaussian distribution. Private Prior Networks for Modality-private Prior Estimation: We assign each modality an individual prior network and take modality s 1 as an example. Similar to the derivation of the shared prior networks, we let {r s1 i } be a set of inverse transition functions that take z s1 t,i , z s1 t-1 and z c t as input and output the independent noise, i.e., ϵ s1 t,i = r s1 i (z s1 t,i , z s1 t-1 , z c t ). Therefore, we can estimate the prior distribution of specific latent variables in a similar manner as shown in Equation <ref type="bibr" target="#b11">(12)</ref>.</p><formula xml:id="formula_13">p(ẑ s 1 1:T |ẑ c 1:T ) = p(ẑ s 1 1 |ẑ c 1:T ) T τ =2 n i=nc+1 log p(ε s 1 τ,i |ẑ c 1:T ) + n i=nc+1 log | ∂r s 1 i ∂ ẑs 1 τ,i | . (<label>12</label></formula><formula xml:id="formula_14">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Summary</head><p>By using the estimating private and shared priors to calculate the KL divergence in Equation ( <ref type="formula" target="#formula_3">4</ref>), we can reconstruct the latent variables by modeling the observations from different modalities. Note that our method can be considered a flexible backbone architecture for multi-modal time series data, the learned latent variables can be applied to any downstream tasks. Therefore, by letting L y be the objective function of a downstream task and combining Equation ( <ref type="formula" target="#formula_3">4</ref>) with the modality-shared constrain in Equation ( <ref type="formula" target="#formula_6">7</ref>), the total loss of the proposed MATE model can be formalized as follows:</p><formula xml:id="formula_15">L total = -αLr + β(Lc + Ls 1 + Ls 2 ) + γLs + Ly,<label>(13)</label></formula><p>where α, β and γ are hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Theoretical Analysis</head><p>To show the proposed method can learn the disentangled representation, we first provide the definition of subspace and component-wise identifiability. We further provide theoretical analysis regarding identifiability. Specifically, we leverage nonlinear ICA to show the subspace-identifiability (Theorem 1) and component-wise identifiability (Corollary 1.1) of the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Subspace Identifiability and Component-wise Identifiability</head><p>Before introducing the theoretical results about identifiability, we first provide a brief introduction to subspace identification and component-wise identification. As for subspace identification <ref type="bibr" target="#b20">[21]</ref>, the subspace identification of latent variables z t means that for each ground-truth z t,i , there exits ẑt and an invertible function h i : R n → R, such that z t,i = h i (ẑ t ). As for component-wise identifiability <ref type="bibr" target="#b21">[22]</ref>, the component-wise identifiability of z t,i means that for each ground-truth z t,i , there exits ẑt,j and an invertible function h i : R → R, such that z t,i = h i (ẑ t,j ). Note that the subspace identifiability provides a coarse-grained theoretical guarantee for representation learning, ensuring that all the information is preserved. While the component-wise identifiability provides a coarse fine theoretcial guarantee, ensuring that the estimated and ground-truth latent variables are one-to-one coresponding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Subspace Identifiability of Latent Variables</head><p>Based on the definition of latent causal process, we first show that the modality-shared and modalityspecific latent variables are subspace identifiable, i.e., the estimated modality-shared latent variables ẑc t (modality-specific latent variables ẑsm t ) contains all and only information in the true modalityshared latent variables z c t (modality-specific latent variables z sm t ). Since the multi-modal time series data are pair-wise, without loss of generality, we consider modality s m as the example.</p><p>Theorem 1. (Subspace Identification of the Modality-shared and Modality-specific Latent Variables) Suppose that the observed data from different modalities is generated following the data generation process in Figure <ref type="figure" target="#fig_2">2</ref>, and we further make the following assumptions:</p><p>• A1 (Smooth and Positive Density:) The probability density of latent variables is smooth and positive, i.e., p(z t |z t-1 ) &gt; 0 over Z t and Z t-1 .</p><p>• A2 (Conditional Independence:</p><formula xml:id="formula_16">) Conditioned on z t-1 , each z c t,i is independent of z c t,j for i, j ∈ {1, • • • , n c }, i ̸ = j. And conditioned on z t-1 and z c t , each z sm t,i is independent of z sm t,j , for i, j ∈ {n c + 1, • • • , n}, i ̸ = j.</formula><p>• A3 (non-singular Jacobian): Each g m has non-singular Jacobian matrices almost anywhere and g m is invertible.</p><p>• A4 (Linear Independence:) For any</p><formula xml:id="formula_17">z s * t ∈ Z s * t , there exist n c + 1 values of z sm t-1,k , k = n c + 1, • • • , n,</formula><p>such that these vectors v t,j are linearly independent, where v t,j,k are defined as follows:</p><formula xml:id="formula_18">vt,j = ∂ 2 log p(z sm t,j |z m t-1 , z c t ) ∂z sm t,j ∂z sm t-1,nc+1 , • • • , ∂ 2 log p(z sm t,j |z m t-1 , z c t ) ∂z sm t,j ∂z sm t-1,n<label>(14)</label></formula><p>Then if ĝ1 :</p><formula xml:id="formula_19">Z c t × Z s1 t → X s1 t and ĝ2 : Z c t × Z s2 t → X s2</formula><p>t assume the generating process of the true model (g 1 , g 2 ) and match the joint distribution p(x s1 t , x s2 t ) of each time step then z c t and z sm t are subspace identifiable.</p><p>Proof Sketch: The proof can be found in Appendix A2.1. First, we construct an invertible transformation h m between the ground-truth latent variables and estimated ones. Sequentially, we prove that the ground truth modality-shared latent variables are not the function of modality-specific latent variables by leveraging the pairing time series from different modalities. Sequentially, we leverage sufficient variability of historical information to show that the modality-specific latent variables are not the function of the estimated modality-shared latent variables. Moreover, by leveraging the invertibility of transformation h m , we can obtain the Jacobian of h m as shown in Equation ( <ref type="formula" target="#formula_20">15</ref>),</p><formula xml:id="formula_20">J hm =    A := ∂z c t ∂ẑ c t B := ∂z c t ∂ẑ sm t = 0 C := ∂z sm t ∂ẑ c t = 0 D := ∂z sm t ∂ẑ sm t ,   <label>(15)</label></formula><p>where B = 0 and C = 0, since the ground truth modality-shared latent variables are not the function of modality-specific latent variables and the modality-specific latent variables are not the function of the estimated modality-shared latent variables, respectively.</p><p>Discussion of the Assumptions: The proof can be found in Appendix A2.1. The first and the second assumptions are common in the existing identification results <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. The third assumption is also common in <ref type="bibr" target="#b24">[25]</ref>, meaning that the influence from each latent source to observation is independence.</p><p>The final assumption means that the historical information changes sufficiently, which can be easily satisfied with sufficient time series data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Component-wise Identifiability of Modality-shared Latent Variables</head><p>Based on Theorem 1, we further establish the component-wise identifiability result as follows.</p><p>Corollary 1.1. (Component-wise Identification of the Modality-shared and Modality-specific Latent Variables) Suppose that the observed data from different modalities is generated following the data generation process in Figure <ref type="figure" target="#fig_2">2</ref>, and we further make the assumption A1, A2 and the following assumptions:</p><p>• A5 (Linear Independence:) For any z t ∈ Z t , there exist 2n + 1 values of z m t-1,k , k = 1, • • • , n, such that these vectors v t,l are linearly independent, where v t,l are defined as follows:  Then if ĝ1 :</p><formula xml:id="formula_21">v t,l = ∂ 3 log p(z c t,l |z m t-1 ) ∂ 2 z c t,l ∂z m t-1,1 , • • • , ∂ 3 log p(z c t,l |z m t-1 ) ∂ 2 z c t,l ∂z m t-1,n , ∂ 2 log p(z c t,l |z m t-1 ) ∂z c t,l ∂z m t-1,1 , • • • , ∂ 2 log p(z c t,l |z m t-1 ) ∂z c t,l ∂z m t-1,n , ∂ 3 log p(z sm t,l |z m t-1 , z c t ) ∂ 2 z sm t,l ∂z m t-1,1 , • • • , ∂ 3 log p(z sm t,l |z m t-1 , z c t ) ∂ 2 z sm t,l ∂z m t-1,n , ∂ 2 log p(z sm t,l |z m t-1 , z c t ) ∂z sm t,l ∂z m t-1,1 , • • • , ∂ 2 log p(z sm t,l |z m t-1 , z c t ) ∂z sm t,l ∂z m t-1,n<label>(16)</label></formula><formula xml:id="formula_22">Z c t × Z s1 t → X s1 t and ĝ2 : Z c t × Z s2 t → X s2</formula><p>t assume the generating process of the true model (g 1 , g 2 ) and match the joint distribution p(x s1 t , x s2 t ) of each time step then z c t is component-wise identifiable.</p><p>Proof Sketch and Discussion: The proof can be found in Appendix A2.2. Based on Theorem 1, we employ similar assumptions like <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b22">23]</ref> to construct a full-rank linear system with only zero solution, which ensures the component-wise identifiability of latent variables, i.e., the estimated and ground truth latent variables are one-to-one corresponding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Relationships between Identifiability and Representation Learning</head><p>Intuitively, the proposed method is more general since existing methods with orthogonal latent space are a special case of the data generation process shown in Figure <ref type="figure" target="#fig_2">2</ref>. We further discuss how these identifiability results benefit the representation learning for multi-modal time-series sensing signals. First, the subspace identifiability results show that the modality-shared and modality-specific latent variables are disentangled under the dependent latent process, naturally boosting the downstream tasks that require modality-shared representations. Second, the component-wise identifiability result uncovers the latent causal mechanisms of multi-modal time series data, which potentially provides the interpretability for multi-modal representation learning, i.e., finding the unobserved confounders. Third, by identifying the latent variables, we can further model the data generation process, which enhances the robustness of the representation of multi-modal time series sensing signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setup</head><p>Datasets: To evaluate the effectiveness of our method, we consider the different downstream tasks: classification, KNN evaluation, and linear probing on several multi-modality time series classification datasets. Specifically, we consider the WIFI <ref type="bibr" target="#b25">[26]</ref>, and KETI <ref type="bibr" target="#b26">[27]</ref> datasets. Moreover, we further consider the human motion prediction datasets like Motion <ref type="bibr" target="#b27">[28]</ref>, HumanEva-I <ref type="bibr" target="#b28">[29]</ref>, H36M <ref type="bibr" target="#b29">[30]</ref>, UCIHAR <ref type="bibr" target="#b30">[31]</ref>, PAMAP2 <ref type="bibr" target="#b31">[32]</ref>, and RealWorld-HAR <ref type="bibr" target="#b32">[33]</ref>, which consider different positions of the human body as different modalities. Moreover, we also consider two healthcare datasets such as MIT-BIH <ref type="bibr" target="#b33">[34]</ref> and D1NAMO <ref type="bibr" target="#b34">[35]</ref>, which are related to arrhythmia and noninvasive type 1 diabetes. Please refer to Appendix A6.1 for more details on the dataset descriptions.</p><p>Evaluation Metric. We use ADAM optimizer <ref type="bibr" target="#b35">[36]</ref> in all experiments and report the accuracy and the Macro-F1 as evaluation metrics. All experiments are implemented by Pytorch on a single NVIDIA RTX A100 40GB GPU. Please refer to Appendix A5 for the details of the model implementation.</p><p>Baselines. To evaluate the performance of the proposed MATE, we consider the different types of baselines. We first consider the convention ResNet <ref type="bibr" target="#b36">[37]</ref>. Sequentially, we consider several baselines for multi-modal sensing data like STFNets <ref type="bibr" target="#b37">[38]</ref>, THAT <ref type="bibr" target="#b38">[39]</ref>, LaxCat <ref type="bibr" target="#b39">[40]</ref>, UniTS <ref type="bibr" target="#b40">[41]</ref>, and RFNet <ref type="bibr" target="#b41">[42]</ref>. Moreover, we also consider methods based on contrastive learning like MaCNN <ref type="bibr" target="#b42">[43]</ref>, SenseHAR <ref type="bibr" target="#b43">[44]</ref>, CPC <ref type="bibr" target="#b44">[45]</ref>, SimCLR <ref type="bibr" target="#b45">[46]</ref>, TS-TCC <ref type="bibr" target="#b46">[47]</ref>, Cocoa <ref type="bibr" target="#b17">[18]</ref>, TS2Vec <ref type="bibr" target="#b47">[48]</ref>, Mixing-up <ref type="bibr" target="#b48">[49]</ref>, TFC <ref type="bibr" target="#b17">[18]</ref>, and CroSSL <ref type="bibr" target="#b49">[50]</ref>. Finally, we consider the recently proposed FOCAL <ref type="bibr" target="#b8">[9]</ref> which considers an orthogonal latent space between domain-shared and domain-specific latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Discussion</head><p>Time Series Classification: Experimental results for time series classification are shown in Table <ref type="table" target="#tab_1">1</ref> and 2. According to the experiment results, we can find that the proposed MATE model achieves the best accuracy and F1 score across different datasets. Compared with the methods based on contrastive learning and the conventional supervised learning methods, the contrastive-learning-based methods achieve better performance since they can disentangle the modality-shared and modality-specific latent variables to some extent. Moreover, since our method explicitly considers the dependence between the modality-shared and modality-specific latent variables, it outperforms the other methods like Focal and CroSSL. More interestingly, as for the experiment results of the DINAMO datasets, our method achieves a clear improvement compared with the methods with the assumption of an orthogonal latent space, which indirectly evaluates the guess mentioned in Figure <ref type="figure" target="#fig_1">1</ref>. Please refer to Appendix A6.2 for more experiment results.</p><p>KNN Evaluation Following the setting of <ref type="bibr" target="#b8">[9]</ref>, we consider both the modality-shared/modalityspecific latent variables and use a KNN classifier with all available labels. Experiment results are shown in Table <ref type="table" target="#tab_3">3</ref>. According to the experiment results, we can find that the proposed MATE still outperforms the other baselines like CroSSL. This is because the representation from our method preserves the dependencies of modality-shared and modality-specific latent variables, hence the representation contains richer semantic information and finally leads to better alignment results. Linear Probing We consider the linear probing task with four different label ratios (100%, 10%, 5%, and 1%) as shown in Table <ref type="table" target="#tab_4">4</ref> and Table <ref type="table" target="#tab_5">5</ref>. The proposed MATE still consistently outperforms the state-of-the-art baselines in different label rates. Specifically, our method achieves 0.7% improvement with 100% lables , 16% improvement with 10% labels, 18% improvement with 5% labels, and 24% improvement with 1% labels. Note that our method still achieves an ideal performance in RealWorld-HAR dataset even with only 10% ratio labels, indirectly reflecting that MATE captures sufficient semantic information with limited labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Visualization Results</head><p>We further provide the visualization results to evaluate that the proposed method can capture the semantic information effectively, which are shown in Figure <ref type="figure" target="#fig_7">A2</ref>. According to the visualization results, we can find that our method can form better clusters with distinguished margins, meaning that the proposed method can well disentangle the latent variables. In the meanwhile, since the other methods assume the orthogonal latent space, they can not well extract the disentangled representation,  and hence results in confusing clusters with unclear margins, for example, the entanglement among the "Walking", "Walking Up", and "Walking Down" in Figure <ref type="figure" target="#fig_7">A2</ref> (b) and (e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Studies</head><p>To evaluate the effectiveness of each loss term, we further devise four model variants as follows. a) MATE-p: we remove the KL divergence terms for domain-specific latent variables. b) MATE-s: we remove the KL divergence terms for domain-shared latent variables. c) MATE-r: We remove the reconstruction loss. d) MATE-c: We remove the modality-shared constraint. Experiment results of the ablation studies on the D1NAMO and Motion datasets are shown in Figure <ref type="figure" target="#fig_1">A1</ref>. We can draw the following conclusions 1) all the loss terms play an important role in the representation learning. 2) In the D1NAMO dataset, by removing the KL divergence terms for domain-shared and domain-specific latent variables, the model performance drops, showing that these loss terms benefit the identifiability of latent variables under dependence latent space. 3) Moreover, the drop in the performance of MATE-r and MATE-c reflects that the reconstruction loss and the modality-shared constraint conducive to preserving the semantic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We propose a representation learning framework for multi-modal time series data with theoretical guarantees, which breakthroughs the conventional orthogonal latent space assumption. Based on the data generation process for multi-modal time series data with dependent latent subspace, we devise a general disentangled representation learning framework with identifiability guarantees. Compared with the existing methods, the proposed MATE model can learn the disentangled time series representations even in the dependent latent subspace, hence our method is closer to the real-world scenarios. Evaluation on the time series classification, KNN evaluation, and linear probing on several multi-modal time series datasets illustrate the effectiveness of our method. Our future work would focus on the more general multi-modal time series data like audio and video data. Multimodality representation learning <ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref> aims to mean information from different modalities, and have lots of applications like Visual Question Answering (VQA) <ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b56">[57]</ref><ref type="bibr" target="#b57">[58]</ref><ref type="bibr" target="#b58">[59]</ref><ref type="bibr" target="#b59">[60]</ref>. The mainstream methods include self-supervised learning <ref type="bibr" target="#b60">[61]</ref><ref type="bibr" target="#b61">[62]</ref><ref type="bibr" target="#b62">[63]</ref>, masked autoencoders <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b56">57]</ref>, and the generative model-based methods <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b66">67]</ref>. Multi-modality time series data is underexplored in literature, despite being often encountered in practice. One of the mainstream methods for multi-modality time series representation learning is to extract the modality-shared representation. Previously, Deldari et.al <ref type="bibr" target="#b17">[18]</ref> extracted the modality-shared representation by computing the cross-correlation of different modalities and minimizing the similarity between irrelevant instances. Deng <ref type="bibr" target="#b67">[68]</ref> proposes multimodality data augmentation to learn inter-modality and intra-modality representations. Recently, Kara <ref type="bibr" target="#b68">[69]</ref> devised a factorized multi-modal fusion mechanism for leveraging cross-modal correlations to learn modality-specific representations. And Liu et.al <ref type="bibr" target="#b8">[9]</ref> leverage both the modality-shared and modality-specific representation for downstream tasks. However, most of this method implicitly assumes that the latent space is orthogonal, which may be hard to meet in real-world scenarios. In this paper, we propose a data generation process with dependent subspace for mutli-modality time series data and devise a flexible model with theoretical guarantees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1.2 Identifiability of Generative Model</head><p>To achieve identifiability <ref type="bibr" target="#b69">[70]</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref> for causal representation, several researchers use the independent component analysis (ICA) to recover the latent variables with identification guarantees <ref type="bibr" target="#b72">[73]</ref><ref type="bibr" target="#b73">[74]</ref><ref type="bibr" target="#b74">[75]</ref><ref type="bibr" target="#b75">[76]</ref>.</p><p>Conventional methods assume a linear mixing function from the latent variables to the observed variables <ref type="bibr" target="#b76">[77]</ref><ref type="bibr" target="#b77">[78]</ref><ref type="bibr" target="#b78">[79]</ref><ref type="bibr" target="#b79">[80]</ref>. Since the linear mixing process is hard to meet in real-world scenarios, recently, some researchers have established the identifiability via nonlinear ICA by using different types of assumptions like auxiliary variables or sparse generation process <ref type="bibr" target="#b80">[81]</ref><ref type="bibr" target="#b81">[82]</ref><ref type="bibr" target="#b82">[83]</ref><ref type="bibr" target="#b83">[84]</ref><ref type="bibr" target="#b84">[85]</ref>. Specifically, Aapo et.al <ref type="bibr" target="#b85">[86]</ref><ref type="bibr" target="#b86">[87]</ref><ref type="bibr" target="#b87">[88]</ref><ref type="bibr" target="#b88">[89]</ref> first achieve the identifiability by assuming the latent sources with exponential family and introducing auxiliary variables e.g., domain indexes, time indexes, and class labels. And Zhang et.al <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b89">[90]</ref><ref type="bibr" target="#b90">[91]</ref><ref type="bibr" target="#b91">[92]</ref> achieve the component-wise identification results for nonlinear ICA without using the exponential family assumption. To achieve identifiability without any supervised signals, several researchers employ sparsity assumptions <ref type="bibr" target="#b80">[81]</ref><ref type="bibr" target="#b81">[82]</ref><ref type="bibr" target="#b82">[83]</ref><ref type="bibr" target="#b83">[84]</ref><ref type="bibr" target="#b84">[85]</ref>. For example, Lachapelle et al. <ref type="bibr" target="#b92">[93,</ref><ref type="bibr" target="#b93">94]</ref> introduced mechanism sparsity regularization as an inductive bias to identify causal latent factors. And Zhang et.al <ref type="bibr" target="#b94">[95]</ref> use the sparse structures of latent variables to achieve identifiability under distribution shift.</p><p>Researchers also employ nonlinear ICA to achieve identifiability of time series data <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b95">96,</ref><ref type="bibr" target="#b96">97]</ref>. For example, Aapo et.al <ref type="bibr" target="#b86">[87]</ref> ) adopt the independent sources premise and capitalize on the variability in variance across different data segments to achieve identifiability on nonstationary time series data. And Permutation-based contrastive learning is employed to identify the latent variables on stationary time series data. Recently, LEAP <ref type="bibr" target="#b23">[24]</ref> and TDRL <ref type="bibr" target="#b22">[23]</ref> have adopted the properties of independent noises and variability historical information. And Song et.al <ref type="bibr" target="#b97">[98]</ref> identify latent variables without observed domain variables. As for the identifiability of modality, Imant et.al <ref type="bibr" target="#b98">[99]</ref> present the identifiability results for multimodal contrastive learning. Yao et.al <ref type="bibr" target="#b72">[73]</ref> consider the identifiability of multi-view causal representation under the partially observed settings. In this paper, we leverage the fairness of multi-modality data and variability historical information to achieve identifiability for multi-modality time series data.</p><p>A2 Proof of Modality-shared Latent Variables z c t A2.1 Proof of Subspace Identification Theorem A1. (Subspace Identification of the Modality-shared and Modality-specific Latent Variables) Suppose that the observed data from different modalities is generated following the data generation process in Figure <ref type="figure" target="#fig_2">2</ref>, and we further make the following assumptions:</p><p>• A1 (Smooth and Positive Density:) The probability density of latent variables is smooth and positive, i.e., p(z t |z t-1 ) &gt; 0 over Z t and Z t-1 .</p><p>• A2 (Conditional Independence:</p><formula xml:id="formula_23">) Conditioned on z t-1 , each z c t,i is independent of z c t,j for i, j ∈ {1, • • • , n c }, i ̸ = j. And conditioned on z t-1 and z c t , each z sm t,i is independent of z sm t,j , for i, j ∈ {n c + 1, • • • , n}, i ̸ = j.</formula><p>• A3 (non-singular Jacobian): Each g m has non-singular Jacobian matrices almost anywhere and g m is invertible.</p><p>• A4 (Linear Independence:) For any z s * t ∈ Z s * t , there exist n c + 1 values of z sm t-1,k , k = n c + 1, • • • , n, such that these vectors v t,j are linearly independent, where v t,j are defined as follows:</p><formula xml:id="formula_24">vt,j = ∂ 2 log p(z sm t,j |z m t-1 , z c t ) ∂z sm t,j ∂z sm t-1,nc+1 , • • • , ∂ 2 log p(z sm t,j |z m t-1 , z c t ) ∂z sm t,j ∂z sm t-1,n<label>(17)</label></formula><p>Then if ĝ1 : Z c t × Z s1 t → X s1 t and ĝ2 : Z c t × Z s2 t → X s2 t assume the generating process of the true model (g 1 , g 2 ) and match the joint distribution p(x s1 t , x s2 t ) of each time step then z c t is subspace identifiable.</p><p>Proof. For (x 1 t , x 2 t ) ∼ p(x 1 t , x 2 t ), because of the matched joint distribution, we have the following relations between the true variables z c t , z s1 t , z s2 t and the estimated ones ẑc t , ẑs1 t , ẑs2 t :</p><formula xml:id="formula_25">x s1 t = g 1 (z c t , z s1 t ) = ĝ1 (ẑ c t , ẑs1 t )<label>(18)</label></formula><formula xml:id="formula_26">x s2 t = g 2 (z c t , z s2 t ) = ĝ2 (ẑ c t , ẑs2 t )<label>(19)</label></formula><formula xml:id="formula_27">(ẑ c t , ẑs1 t , ẑs2 t ) = ĝ-1 (x s1 t , x s2 t ) = ĝ-1 (g(z c t , z s1 t , z s2 t )) := h(z c t , z s1 t , z s2 t ),<label>(20)</label></formula><p>where ĝ1 , ĝ2 are the estimated invertible generating function and h := ĝ-1 • g denotes a smooth and invertible function that transforms the true variables z c t , z s1 t , z s2 t to the estimated ones ẑc t , ẑs1 t , ẑs2 t . By combining Equation ( <ref type="formula" target="#formula_27">20</ref>) and ( <ref type="formula" target="#formula_25">18</ref>), we have</p><formula xml:id="formula_28">g 1 (z c t , z s1 t ) = ĝ1 (h c,s1 (z c t , z s1 t , z s2 t )). (<label>21</label></formula><formula xml:id="formula_29">) For i ∈ {1, • • • , n x s 1 } and j ∈ {1, • • • , n s2 },</formula><p>we take a partial derivative of the i-th dimension of x s1 t on both sides of Equation ( <ref type="formula" target="#formula_28">21</ref>) w.r.t. z s2 t,j and have:</p><formula xml:id="formula_30">0 = ∂g 1,i (z c t , z s1 t ) ∂z s2 t,j = ∂ĝ 1,i (h c,s1 (z c t , z s1 t )) ∂z s2 t,j . (<label>22</label></formula><formula xml:id="formula_31">)</formula><p>The aforementioned equation equals 0 because there is no z s2 t,j in the left-hand side of the equation. By expanding the derivative on the right-hand side, we further have:</p><formula xml:id="formula_32">k∈{1,••• ,nc+ns 1 } ∂ĝ 1,i (z c t , z s1 t ) ∂h (c,s1),k • ∂h (c,s1),k (z c t , z s1 t , z s2 t ) ∂z s2 t,j = 0. (<label>23</label></formula><formula xml:id="formula_33">)</formula><p>Since ĝ1 is invertible, the determinant of J ĝ1 does not equal to 0, meaning that for</p><formula xml:id="formula_34">n c + n s1 different values of ĝ1,i , each vector [ ∂ ĝ1,i(z c t ,z s 1 t ) ∂h (c,s 1 ),1 , • • • , ∂ ĝ1,i(z c t ,z s 1 t ) ∂h (c,s 1 ),nc +ns 1</formula><p>] are linearly independent. Therefore, the (n c + n s1 ) × (n c + n s1 ) linear system is invertible and has the unique solution as follows:</p><formula xml:id="formula_35">∂h (c,s1),k (z c t , z s1 t , z s2 t ) ∂z s2 t,j = 0. (<label>24</label></formula><formula xml:id="formula_36">)</formula><p>According to Equation <ref type="bibr" target="#b23">(24)</ref>, for any k ∈ {1,  <ref type="formula" target="#formula_27">20</ref>) and ( <ref type="formula" target="#formula_26">19</ref>), we have</p><formula xml:id="formula_37">g 2 (z c t , z s2 t ) = ĝ2 (h c,s2 (z c t , z s1 t , z s2 t )).<label>(25)</label></formula><p>For i ∈ {1, • • • , n x s 2 } and j ∈ {1, • • • , n s1 }, we take a partial derivative of the i-th dimension of x s2 t on both sides of Equation ( <ref type="formula" target="#formula_37">25</ref>) w.r.t z s1 t,j and have:</p><formula xml:id="formula_38">0 = ∂g 2,i (z c t , z s2 t ) ∂z s1 t,j = ∂ĝ 2,i (h c,s2 (z c t , z s2 t ) ∂z s1 t,j = k∈{1••• ,nc+ns 2 } ∂ĝ 2,i (z c t , z s2 t ) ∂h (c,s2),k • ∂h (c,s2),k (z c t , z s1 t , z s2 t ) ∂z s1 t,j (26) Since ĝ2 is invertible, for n c + n s2 different values of ĝ2,i , each vector [ ∂ ĝ2,i(z c t ,z s 2 t ) ∂h (c,s 2 ),1 , • • • , ∂ ĝ2,i(z c t ,z s 2 t ) ∂h (c,s 2 ),nc +ns 2</formula><p>] are linearly independent. Therefore, the (n c + n s2 ) × (n c + n s2 ) linear system is invertible and has the unique solution as follows:</p><formula xml:id="formula_39">∂h (c,s2),k (z c t , z s1 t , z s2 t ) ∂z s1 t,j = 0,<label>(27)</label></formula><p>meaning that {z c t , z s2 t } does not depend on z s1 t . According to Equation (20), we have ẑc t = h c (z c t , z s1 t , z s2 t ). By using the fact that {z c t , z s2 t } does not depend on z s1 t and {z c t , z s1 t } does not depend on z s2 t , we have ẑc t = h c (z c t ), i.e., the modality-shared latent variables are subspace identifiable.</p><p>Since the matched marginal distribution of p(x s1 t |x s1 t-1 ), we have:</p><formula xml:id="formula_40">∀x s1 t-1 ∈ X s1 t-1 , p(x s1 t |x s1 t-1 ) = p(x s1 t |x s1 t-1 ) ⇐⇒ p(ĝ 1 (ẑ 1 t )|x s1 t-1 ) = p(g 1 (z 1 t )|x s1 t-1 ),<label>(28)</label></formula><p>where z 1 t = {z c t , z s1 t } and ẑ1 t = {ẑ c t , ẑs1 t }. Sequentially, by using the change of variables formula, we can further obtain Equation ( <ref type="formula" target="#formula_41">29</ref>)</p><formula xml:id="formula_41">p(ĝ 1 (ẑ 1 t )|x s1 t-1 ) = p(g 1 (z 1 t )|x s1 t-1 ) ⇐⇒ p(g -1 1 • ĝ1 (ẑ 1 t )|x s1 t-1 )|J g -1 1 | = p(z 1 t |x s1 t-1 )|J g -1 1 | ⇐⇒ p(h 1 (ẑ 1 t )|x s1 t-1 ) = p(z 1 t |x s1 t-1 ) ⇐⇒ p(h 1 (ẑ 1 t )|ẑ 1 t-1 ) = p(z 1 t |z 1 t-1 ),<label>(29)</label></formula><p>where h 1 := g -1 1 • ĝ1 is the transformation between the ground-true and the estimated latent variables. J g -1</p><formula xml:id="formula_42">1</formula><p>denotes the absolute value of Jacobian matrix determinant of g -1</p><p>1 . Since we assume that g 1 and ĝ1 are invertible, |J g -1 | ̸ = 0 and h 1 is also invertible.</p><p>According to the A2 (conditional independent assumption), we can have Equation ( <ref type="formula" target="#formula_43">30</ref>)</p><formula xml:id="formula_43">p(z 1 t |z 1 t-1 ) = n i=1 p(z 1 t,i |z 1 t-1 ); p(ẑ 1 t |ẑ 1 t-1 ) = n i=1 p(ẑ 1 t,i |ẑ 1 t-1 ).<label>(30)</label></formula><p>For convenience, we take logarithm on both sides of Equation ( <ref type="formula" target="#formula_43">30</ref>) and have:</p><formula xml:id="formula_44">log p(z 1 t |z 1 t-1 ) = n i=1 log p(z 1 t,i |z 1 t-1 ); log p(ẑ 1 t |ẑ 1 t-1 ) = n i=1 log p(ẑ 1 t,i |ẑ 1 t-1 ).<label>(31)</label></formula><p>By combining Equation <ref type="bibr" target="#b30">(31)</ref> and Equation ( <ref type="formula" target="#formula_41">29</ref>), we have:</p><formula xml:id="formula_45">p(h 1 (ẑ 1 t )|ẑ 1 t-1 ) = p(z 1 t |z 1 t-1 ) ⇐⇒ p(ẑ 1 t |ẑ 1 t-1 )|J h -1 | = p(z 1 t |z 1 t-1 ) ⇐⇒ n i=1 log p(ẑ 1 t,i |ẑ 1 t-1 ) = n i=1 log p(z 1 t,i |z 1 t-1 ) -log |J h -1 |,<label>(32)</label></formula><p>where J h -1 are the Jacobian matrix of h -1 .</p><p>Sequentially, we take the first-order derivative with ẑc t,i , where i ∈ {1, • • • , n c } and have:</p><formula xml:id="formula_46">∂ log p(ẑ 1 t |ẑ 1 t-1 ) ∂ ẑc t,i = nc j=1 ∂ log p(ẑ c t,j |ẑ 1 t-1 ) ∂ ẑc t,i + n j=nc+1 ∂ log p(ẑ s1 t,j |ẑ 1 t-1 , ẑc t ) ∂ ẑc t,i = nc j=1 ∂ log p(z c t,j |z 1 t-1 ) ∂z c t,j • ∂z c t,j ∂ ẑc t,i + n j=nc+1 ∂ log p(z s1 t,j |z 1 t-1 , z c t ) ∂z s1 t,j • ∂z s1 t,j ∂ ẑc t,i - ∂|J h -1 | ∂ ẑc t,i .<label>(33)</label></formula><p>Then we further take the second-order derivative w.r.t z s1 t-1,k , where k ∈ {n c + 1, • • • , n} and we have:</p><formula xml:id="formula_47">nc j=1 ∂ 2 log p(ẑ c t,j |ẑ 1 t-1 ) ∂ ẑc t,i ∂z s1 t-1,k + n j=nc+1 ∂ 2 log p(ẑ s1 t,j |ẑ 1 t-1 , ẑc t ) ∂ ẑc t,i ∂z s1 t-1,k = nc j=1 ∂ 2 log p(z c t,j |z 1 t-1 ) ∂z c t,j ∂z s1 t-1,k • ∂z c t,j ∂ ẑc t,i + n j=nc+1 ∂ 2 log p(z s1 t,j |z 1 t-1 , z c t ) ∂z s1 t,j ∂z s1 t-1,k • ∂z s1 t,j ∂ ẑc t,i - ∂ 2 |J h -1 | ∂ ẑc t,i ∂z s1 t-1,k .<label>(34)</label></formula><p>Since ẑc t,j does not change across different values of z s1 t-1,k , then</p><formula xml:id="formula_48">∂ 2 log p(ẑ c t,j |ẑ 1 t-1 ) ∂ ẑc t,i ∂z s 1 t-1,k = 0. Since ∂ 2 log p(ẑ s 1 t,j |ẑ 1 t-1 ,ẑ c t ) ∂ ẑc t,i does not change across different values of z s1 t-1,k , then ∂ 2 log p(ẑ s 1 t,j |ẑ 1 t-1 ,ẑ c t ) ∂ ẑc t,i ∂z s 1 t-1,k = 0.</formula><p>Moreover, since</p><formula xml:id="formula_49">∂ 2 log p(z c t,j |z 1 t-1 ) ∂z c t,j ∂z s 1 t-1,k</formula><p>and <ref type="formula" target="#formula_47">34</ref>) can be further rewritten as:</p><formula xml:id="formula_50">∂ 2 |J h -1 | ∂ ẑc t,i ∂z s 1 t-1,k = 0, Equation (</formula><formula xml:id="formula_51">n j=nc+1 ∂ 2 log p(z s1 t,j |z 1 t-1 , z c t ) ∂z s1 t,j ∂z s1 t-1,k • ∂z s1 t,j ∂ ẑc t,i = 0.<label>(35)</label></formula><p>By leveraging the linear independence assumption, the linear system denoted by Equation ( <ref type="formula" target="#formula_51">35</ref>) has the only solution</p><formula xml:id="formula_52">∂z s 1 t,j ∂ ẑc t,i = 0.</formula><p>As h 1 is smooth, its Jacobian can written as:</p><formula xml:id="formula_53">J h1 =   A := ∂z c t ∂ẑ c t B := ∂z c t ∂ẑ s 1 t = 0 C := ∂z s 1 t ∂ẑ c t = 0 D := ∂z s 1 t ∂ẑ s 1 t .  <label>(36)</label></formula><p>Therefore, z s1 t is subspace identifiable. Similarly,we can prove that z sm t is subspace identifiable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2.2 Proof of Component-wise Identification</head><p>Corollary A1. (Component-wise Identification of the Modality-shared and Modality-specific Latent Variables) Suppose that the observed data from different modalities is generated following the data generation process in Figure <ref type="figure" target="#fig_2">2</ref>, and we further make the following assumptions:</p><p>• A1 (Smooth and Positive Density:) The probability density of latent variables is smooth and positive, i.e., p(z t |z t-1 ) &gt; 0 over Z t and Z t-1 .</p><p>• A2 (Conditional Independence:) Conditioned on z t-1 , each z c t,i is independent of z c t,j for i, j ∈ {1, • • • , n c }, i ̸ = j. And conditioned on z t-1 and z c t , each z sm t,i is independent of z sm t,j , for i, j</p><formula xml:id="formula_54">∈ {n c + 1, • • • , n}, i ̸ = j.</formula><p>• A3 (Linear Independence:) For any z t ∈ Z t , there exist 2n + 1 values of z m t-1,k , k = 1, • • • , n, such that these vectors v t,l are linearly independent, where v t,l are defined as follows:</p><formula xml:id="formula_55">v t,l = ∂ 3 log p(z c t,l |z m t-1 ) ∂ 2 z c t,l ∂z m t-1,1 , • • • , ∂ 3 log p(z c t,l |z m t-1 ) ∂ 2 z c t,l ∂z m t-1,n , ∂ 2 log p(z c t,l |z m t-1 ) ∂z c t,l ∂z m t-1,1 , • • • , ∂ 2 log p(z c t,l |z m t-1 ) ∂z c t,l ∂z m t-1,n , ∂ 3 log p(z sm t,l |z m t-1 , z c t ) ∂ 2 z sm t,l ∂z m t-1,1 , • • • , ∂ 3 log p(z sm t,l |z m t-1 , z c t ) ∂ 2 z sm t,l ∂z m t-1,n , ∂ 2 log p(z sm t,l |z m t-1 , z c t ) ∂z sm t,l ∂z m t-1,1 , • • • , ∂ 2 log p(z sm t,l |z m t-1 , z c t ) ∂z sm t,l ∂z m t-1,n<label>(37)</label></formula><p>Then if ĝ1 :</p><formula xml:id="formula_56">Z c t × Z s1 t → X s1 t and ĝ2 : Z c t × Z s2 t → X s2</formula><p>t assume the generating process of the true model (g 1 , g 2 ) and match the joint distribution p(x s1 t , x s2 t ) of each time step then z c t is component-wise identifiable.</p><p>Proof. Then we let z 1 t = {z c t , z s1 t } and ẑ1 t = {ẑ c t , ẑs1 t }. According to Equation (2), we have ẑt = h 1 (z t ), where h 1 := ĝ1 -1 • g 1 is an invertible function. Sequentially, it is straightforward to see that if the components of ẑs1 t are mutually independent conditional on ẑs1 t-1 and ẑc t , the components of ẑc t are mutually independent conditional on ẑc t-1 , then for any i ̸ = j, we have:</p><formula xml:id="formula_57">∂ 2 log p(ẑ s1 t |ẑ s1 t-1 , ẑc t ) ∂ ẑs1 t,i ∂ ẑs1 t,j = 0, ∂ 2 log p(ẑ c t |ẑ c t-1 ) ∂ ẑc t,i ∂ ẑc t,j = 0,<label>(38)</label></formula><p>by assuming that the second-order derivative exists. The Jacobian matrix of the mapping from</p><formula xml:id="formula_58">(x s1 t-1 , z 1 t ) to (x s1 t-1 , ẑ1 t ) is I 0 * H s 1 t</formula><p>, where H s1 t denotes the absolute value of the determinant of this Jacobian matrix is</p><formula xml:id="formula_59">|H s1 t |. Therefore, p(ẑ 1 t , x s1 t-1 ) • |H s1 t | = p(z 1 t , x s1 t-1 )</formula><p>. Dividing both sides of this equation by p(x s1 t-1 ) gives</p><formula xml:id="formula_60">p(ẑ 1 t |x s1 t-1 ) • |H s1 t | = p(z 1 t |x s1 t-1 ).<label>(39)</label></formula><p>Since p(z</p><formula xml:id="formula_61">1 t |z 1 t-1 ) = p(z 1 t |g 1 (z 1 t-1 )) = p(z 1 t |x s1 t-1</formula><p>) and similarly p( ẑ1 t |ẑ 1 t-1 ) = p(ẑ 1 t |x s1 t-1 ), so we further have:</p><formula xml:id="formula_62">log p(ẑ 1 t |ẑ 1 t-1 ) = log p(z 1 t |z 1 t-1 ) -log |H s1 t |.<label>(40)</label></formula><p>According to Equation <ref type="bibr" target="#b39">(40)</ref> , we take the first-order derivative with ẑc t,i , where i ∈ {1, • • • , n c } and have: </p><formula xml:id="formula_63">∂ log p(ẑ</formula><p>Sequentially, for k = 1, • • • , n c , and each value z c t-1,k , the third-order derivative w.r.t. v c t-1,k , and we have:</p><formula xml:id="formula_65">nc l=1 ∂ 3 log p(ẑ c t,l |ẑ 1 t-1 ) ∂ ẑc t,i ∂ ẑc t,j ∂z c t-1,k + n l=nc+1 ∂ 3 log p(ẑ s1 t,l |ẑ 1 t-1 , ẑc t ) ∂ ẑc t,i ∂ ẑc t,j ∂z c t-1,k = nc l=1 ∂ 3 log p(z c t,l |z 1 t-1 ) ∂ 2 z c t,l ∂z c t-1,k • ∂z c t,l ∂ ẑc t,j • ∂z c t,l ∂ ẑc t,i + nc l=1 ∂ 2 log p(z c t,l |z 1 t-1 ) ∂z c t,l ∂z c t-1,k • ∂ 2 z c t,l ∂ ẑc t,i ∂ ẑc t,j + n l=nc+1 ∂ 3 log p(z s1 t,l |z 1 t-1 , z c t ) ∂ 2 z s1 t,l ∂z c t-1,k • ∂z s1 t,l ∂ ẑc t,j • ∂z s1 t,l ∂ ẑc t,i + n l=nc+1 ∂ 2 log p(z s1 t,l |z 1 t-1 , z c t ) ∂z s1 t,l ∂z c t-1,k • ∂ 2 z s1 t,l ∂ ẑc t,i ∂ ẑc t,j - ∂ 3 log |H s1 t | ∂ ẑc t,i ∂ ẑc t,j ∂z c t-1,k .<label>(43)</label></formula><p>Since according to Equation <ref type="bibr" target="#b37">(38)</ref>,then <ref type="formula" target="#formula_65">43</ref>) can be further rewritten as: = 0.</p><formula xml:id="formula_66">∂ 3 log p(ẑ c t,l |z 1 t-1 ) ∂ ẑc t,i ∂ ẑc t,j ∂z c t-1,k = 0. Since ẑs1 t,l does not change across different values of z c t-1,k , then ∂ 3 log p(ẑ s 1 t,l |ẑ 1 t-1 ,ẑ c t ) ∂ ẑc t,i ∂ ẑc t,j ∂z c t-1,k = 0. Equation (</formula><formula xml:id="formula_67">nc l=1 ∂ 3 log p(z c t,l |z 1 t-1 ) ∂ 2 z c t,l ∂z c t-1,k • ∂z c t,l ∂ ẑc t,j • ∂z c t,l ∂ ẑc t,i + nc l=1 ∂ 2 log p(z c t,l |z 1 t-1 ) ∂z c t,l ∂z c t-1,k • ∂ 2 z c t,</formula><p>(</p><formula xml:id="formula_68">)<label>44</label></formula><p>where we have made use of the fact that entries of H s1 t do not depend on z c t-1,l . Then by leveraging the linear independence assumption, the linear system denoted by Equation <ref type="bibr" target="#b43">(44)</ref>  = 0. According to Equation (36),we have:</p><formula xml:id="formula_69">J h1 =   A := ∂z c t ∂ẑ c t B := ∂z c t ∂ẑ s 1 t = 0 C := ∂z s 1 t ∂ẑ c t = 0 D := ∂z s 1 t ∂ẑ s 1 t   .<label>(45)</label></formula><p>Since h 1 is invertible and for i, j ∈ {1, • • • , n c },  </p><formula xml:id="formula_70">∂z c t,l ∂ ẑc t,i • ∂z c t,l ∂ ẑc t,j = 0 and ∂z s 1 t,l ∂ ẑc t,i • ∂z s 1 t,l ∂ ẑc t,j = 0 implies that for each k = 1, • • • , n c ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3 Evidence Lower Bound</head><p>In this subsection, we show the evidence lower bound. We first factorize the conditional distribution according to the Bayes theorem. </p><formula xml:id="formula_71">ln p(x s 1 1:T , x s<label>2</label></formula><formula xml:id="formula_72">1:T ) = ln p(x s 1 1:T , x s 2 1:T , z s 1 1:T , z s 2 1:T , z c 1:T ) p(z s 1 1:T , z s 2 1:T , z c 1:T |x s 1 1:T , x s<label>2</label></formula><formula xml:id="formula_73">1:T ) = ln p(x s 1 1:T |z s 1 1:T , z c 1:T )p(x s 2 1:T |z s 2 1:T , z c 1:T )p(z s 1 1:T |z c 1:T )p(z s 2 1:T |z c 1:T )p(z c 1:T ) p(z s 1 1:T |x s 1 1:T , z c 1:T )p(z s 2 1:T |x s 2 1:T , z c 1:T ))p(z c 1:T |x s 1 1:T , x s 2 1:T ) =E q(z s 1 1:T |x s 1 1:T ,z c 1:T ) E q(z s 2 1:T |x s 2 1:T ,z c 1:T ) E q(z c 1:T |x s 1 1:T ,x s 2 1:T ) ln p(x s 1 1:T |z s 1 1:T , z c 1:T )p(x s 2 1:T |z s 2 1:T , z c 1:T )p(z c 1:T )p(z s 1 1:T |z c 1:T )p(z s 2 1:T |z c 1:T ) q(z s 1 1:T |x s 1 1:T , z c 1:T )q(z s 2 1:T |x s 2 1:T , z c 1:T )q(z c 1:T |x s 1 1:T , x s<label>2</label></formula><formula xml:id="formula_74">1:T ) + D KL (q(z s 1 1:T |x s 1 1:T , z c 1:T )||p(z s 1 1:T |x s 1 1:T , z c 1:T )) + D KL (q(z s 2 1:T |x s 2 1:T , z c 1:T )||p(z s 2 1:T |x s 2 1:T , z c 1:T )) + D KL (q(z c 1:T |x s 1 1:T , x s 2 1:T )||p(z c 1:T |x s 1 1:T , x s 2 1:T )) ≥E q(z s 1 1:T |x s 1 1:T ,z c 1:T ) E q(z s 2 1:T |x s 2 1:T ,z c 1:T ) E q(z c 1:T |x s 1 1:T ,x s 2 1:T ) ln p(x s 1 1:T |z s 1 1:T , z c 1:T )p(x s 2 1:T |z s 2 1:T , z c 1:T )p(z c 1:T )p(z s 1 1:T |z c 1:T )p(z s 2 1:T |z c 1:T ) q(z s 1 1:T |x s 1 1:T , z c 1:T )q(z s 2 1:T |x s 2 1:T , z c T )q(z c 1:T |x s 1 1:T , x s 2 1:T ) = E q(z s 1 1:T |x s 1 1:T ,z c 1:T ) E q(z s 2 1:T |x s 2 1:T ,z c 1:T ) E q(z c 1:T |x s 1 1:T ,x s<label>2</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4 Prior Estimation</head><p>Shared Prior Estimation: We first consider the prior of ln p(z c 1:T ). We consider the time lag as L = 1,we devise a transformation σ c := {ẑ c t-1 , ẑc t } → {ẑ c t-1 , εc t }. Then we write this latent process as a transformation map σ (note that we overload the notation σ for transition functions and for the transformation map):</p><formula xml:id="formula_75">ẑc t-1 ẑc t = σ ẑc t-1 εc t .</formula><p>By applying the change of variables formula to the map f , we can evaluate the joint distribution of the latent variables p(ẑ c t-1</p><formula xml:id="formula_76">ẑc t ) as p(ẑ c t-1 , ẑc t ) = p(ẑ c t-1 εc t ) |det Jσ| ,<label>(48)</label></formula><p>where σ σ is the Jacobian matrix of the map f , which is naturally a low-triangular matrix:</p><formula xml:id="formula_77">Jσ = 1 0 ∂ ẑc t ∂ ẑc t-1 ẑc t εc t .</formula><p>Let {r c i } i=1,2,3,••• be a set of learned inverse transition functions that take the estimated latent causal variables, and output the noise terms, i.e., εt,i = r c i (ẑ c t,i , ẑc t-1 ). Then we design a transformation A → B with low-triangular Jacobian as follows:</p><formula xml:id="formula_78">[ẑ c t-1 , ẑc t ] ⊤ A mapped to [ẑ c t-1 , εc t ] ⊤ B , with J A→B = I 0 * diag ∂r c i ∂ ẑc t-1,i .<label>(49)</label></formula><p>Similar to Equation ( <ref type="formula" target="#formula_78">49</ref>), we can obtain the joint distribution of the estimated dynamics subspace as:</p><formula xml:id="formula_79">log p(A) = log p(B) + log(|det(J A→B )|).<label>(50)</label></formula><p>Finally, we have:</p><formula xml:id="formula_80">log p(ẑ c t |z c t-1 ) = log p(ε c t ) + n i=n d +1 log | ∂r c i ∂ ẑc t-1,i |.<label>(51)</label></formula><p>As a result, the prior distribution shared latent variables can be estimated as follows:</p><formula xml:id="formula_81">p(ẑ c 1:T ) = p(ẑ c 1 ) T τ =2   n i=n d +1 log p(ε c τ,i ) + n i=n d +1 log | ∂r c i ∂ ẑc τ -1,i |   ,<label>(52)</label></formula><p>where we assume p(ε c τ,i ) follows a standard Gaussian distribution.</p><p>As for the modality-specific prior estimation, we can obtain a similar derivation, by considering the modality-shared prior as condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A5 Implementation Details</head><p>We summarize our network architecture below and describe it in detail in Table <ref type="table" target="#tab_13">A1</ref>. We also provide the training details on Table <ref type="table" target="#tab_2">A2</ref> and A3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A6 Experiment Details A6.1 Dataset Descriptions</head><p>In this paper, we consider the WIFI <ref type="bibr" target="#b25">[26]</ref>, and KETI <ref type="bibr" target="#b26">[27]</ref> datasets. Moreover, we further consider the human motion prediction datasets like Motion <ref type="bibr" target="#b27">[28]</ref>, HumanEva-I <ref type="bibr" target="#b28">[29]</ref>, H36M <ref type="bibr" target="#b29">[30]</ref>, UCIHAR <ref type="bibr" target="#b30">[31]</ref>, PAMAP2 <ref type="bibr" target="#b31">[32]</ref>, and RealWorld-HAR <ref type="bibr" target="#b32">[33]</ref>which consider different positions of the human body as different modalities. Moreover, we also consider two healthcare datasets such as MIT-BIH <ref type="bibr" target="#b33">[34]</ref> and D1NAMO <ref type="bibr" target="#b34">[35]</ref>, which are related to arrhythmia and noninvasive type 1 diabetes.</p><p>Motion <ref type="bibr" target="#b27">[28]</ref> dataset is a subset of the OPPORTUNITY Activity Recognition Dataset <ref type="bibr" target="#b27">[28]</ref>. Following the experimental setting of a recent device-based HAR study <ref type="bibr" target="#b43">[44]</ref>, we consider 5 sensors worn at 5 different locations on the human body: lower arm, left upper arm, right lower arm, right upper arm and the back. Each device contains an accelerometer, a gyroscope, and a magnetometer, and all three sensors generate three-axis readings. We focus on a 4-class prediction consisting of high-level locomotion activities (sit, stand, walk and lie).</p><p>D1NAMO <ref type="bibr" target="#b34">[35]</ref> is acquired on 20 healthy subjects and 9 patients with type-1 diabetes. The acquisition has been made in real-life conditions with the Zephyr BioHarness 3 wearable device. The dataset consists of ECG, breathing, and accelerometer signals, as well as glucose measurements and annotated food pictures.</p><p>WIFI <ref type="bibr" target="#b25">[26]</ref> dataset contains the amplitude and phase of wireless signals sent by three antennas. Each antenna transmits at 30 subcarriers, and the receiver base sampling frequency is 1000 Hz. The dataset contains 7 classes of activity, including lying down, falling, picking up, running, sitting down, standing up and walking. We also use a sliding window of 256 timestamps to get the segmented examples.</p><p>KETI <ref type="bibr" target="#b26">[27]</ref> dataset was collected from 51 rooms in a large university office building. Each room is instrumented with 4 sensors monitoring CO2, temperature, humidity and light intensity, with occupancy monitored by an additional PIR sensor in the room. Readings are recorded every 10 seconds, and the dataset contains one week worth of data. In this experiment, we target at human occupation prediction using the readings of these sensors.</p><p>HumanEVA-I [29] comprises 3 subjects each performing 5 actions. We apply the original frame rate (60 Hz) and a 15-joint skeleton removing the root joint to build human motions.</p><p>H36M <ref type="bibr" target="#b29">[30]</ref> consists of 7 subjects (S1, S5, S6, S7, S8 ,S9 and S11) performing 15 different motions.</p><p>We apply the original frame rate (50 Hz) and a 17-joint skeleton removing the root joint to build human motions.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A6.2.2 Full Experiment Results</head><p>Table <ref type="table" target="#tab_14">A5</ref> and Table <ref type="table" target="#tab_15">A6</ref> show the full results for the classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A7 Limitation</head><p>Although our method can learn disentangled representation for multi-modal time series data with identifiability guarantees, it requires the assumption that the mixing function is invertible. However, this assumption might be hard to meet in real-world scenarios. Therefore, how to leverage the temporal context information to address this challenge will be an interesting direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A8 Broader Impacts</head><p>The proposed MATE model extracts the disentangled modality-shared and modality-specific latent variables for multi-modal time series modeling, which benefits the construction of precise and robust systems for time series data.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of physiological indicators of diabetics, where brain-related and heart-related signals are observations. (a) In the true generation process, observations are generated from dependent latent sources. (b) In the estimation process, enforcing orthogonality on estimated sources can result in the entanglement of latent sources and meaningless noises.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Data generation process of time series data with two modalities. The grey and white nodes denote the observed and latent variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Illustration of the proposed MATE model, we consider two modalities for a convenient understanding, more modalities can be easily extended. The modality-specific encoders are used to extract the latent variables of different modalities. The specific prior networks and the shared prior network are used to estimate the prior distribution for KL divergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure</head><label></label><figDesc>Figure A1 provides the results of ablation studies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure A2 :</head><label>A2</label><figDesc>Figure A2: The t-SNE visualization of the extracted domain-shared latent variables.</figDesc><graphic coords="28,119.99,334.76,366.44,79.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Time series classification for Motion, Seizure, WIFI, and KETI datasets.</figDesc><table><row><cell></cell><cell></cell><cell>Motion</cell><cell cols="2">DINAMO</cell><cell>WIFI</cell><cell></cell><cell>KETI</cell><cell></cell></row><row><cell>Model</cell><cell cols="8">Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1</cell></row><row><cell>ResNet</cell><cell>89.96</cell><cell>91.41</cell><cell>91.88</cell><cell>65.00</cell><cell>90.29</cell><cell>88.14</cell><cell>96.05</cell><cell>84.59</cell></row><row><cell>MaCNN</cell><cell>85.57</cell><cell>86.93</cell><cell>90.17</cell><cell>48.56</cell><cell>88.81</cell><cell>87.80</cell><cell>93.05</cell><cell>71.93</cell></row><row><cell>SenenHAR</cell><cell>88.95</cell><cell>88.66</cell><cell>89.56</cell><cell>47.23</cell><cell>94.63</cell><cell>92.75</cell><cell>96.43</cell><cell>84.74</cell></row><row><cell>STFNets</cell><cell>89.07</cell><cell>88.84</cell><cell>90.51</cell><cell>47.50</cell><cell>80.52</cell><cell>75.93</cell><cell>89.21</cell><cell>69.55</cell></row><row><cell>RFNet-base</cell><cell>89.93</cell><cell>91.70</cell><cell>90.76</cell><cell>58.79</cell><cell>86.31</cell><cell>82.56</cell><cell>95.12</cell><cell>81.45</cell></row><row><cell>THAT</cell><cell>89.66</cell><cell>91.38</cell><cell>92.76</cell><cell>71.64</cell><cell>95.59</cell><cell>94.86</cell><cell>96.33</cell><cell>85.12</cell></row><row><cell>LaxCat</cell><cell>60.25</cell><cell>41.01</cell><cell>90.64</cell><cell>54.56</cell><cell>76.36</cell><cell>73.85</cell><cell>93.33</cell><cell>70.67</cell></row><row><cell>UniTS</cell><cell>91.02</cell><cell>92.73</cell><cell>90.88</cell><cell>58.39</cell><cell>95.83</cell><cell>94.49</cell><cell>96.04</cell><cell>84.08</cell></row><row><cell>COCOA</cell><cell>88.31</cell><cell>89.27</cell><cell>90.69</cell><cell>55.00</cell><cell>87.76</cell><cell>84.51</cell><cell>92.68</cell><cell>74.72</cell></row><row><cell>FOCAL</cell><cell>89.37</cell><cell>90.91</cell><cell>90.52</cell><cell>52.00</cell><cell>94.15</cell><cell>92.68</cell><cell>94.88</cell><cell>78.47</cell></row><row><cell>CroSSL</cell><cell>91.32</cell><cell>89.94</cell><cell>91.05</cell><cell>53.13</cell><cell>76.80</cell><cell>68.45</cell><cell>93.63</cell><cell>76.25</cell></row><row><cell>MATE</cell><cell>92.44</cell><cell>93.75</cell><cell>93.31</cell><cell>73.72</cell><cell>96.95</cell><cell>96.20</cell><cell>97.00</cell><cell>86.93</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Time series classification for human motion prediction and healthcare datasets.</figDesc><table><row><cell></cell><cell cols="2">HumanEVA</cell><cell>H36M</cell><cell></cell><cell cols="2">UCIHAR</cell><cell cols="2">MIT-BIH</cell></row><row><cell>Model</cell><cell cols="8">Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1</cell></row><row><cell>ResNet</cell><cell>86.68</cell><cell>86.51</cell><cell>92.44</cell><cell>92.27</cell><cell>93.12</cell><cell>93.01</cell><cell>98.52</cell><cell>97.62</cell></row><row><cell>MaCNN</cell><cell>86.27</cell><cell>86.12</cell><cell>78.54</cell><cell>77.73</cell><cell>84.57</cell><cell>84.06</cell><cell>97.26</cell><cell>96.07</cell></row><row><cell>SenenHAR</cell><cell>85.77</cell><cell>86.00</cell><cell>67.69</cell><cell>67.44</cell><cell>87.77</cell><cell>87.47</cell><cell>95.82</cell><cell>94.79</cell></row><row><cell>STFNets</cell><cell>86.07</cell><cell>85.76</cell><cell>61.67</cell><cell>57.20</cell><cell>81.64</cell><cell>81.64</cell><cell>91.63</cell><cell>88.97</cell></row><row><cell>RFNet-base</cell><cell>97.15</cell><cell>96.18</cell><cell>94.14</cell><cell>93.14</cell><cell>95.63</cell><cell>95.16</cell><cell>98.64</cell><cell>97.85</cell></row><row><cell>THAT</cell><cell>85.95</cell><cell>85.90</cell><cell>81.28</cell><cell>81.27</cell><cell>93.06</cell><cell>93.06</cell><cell>98.49</cell><cell>97.56</cell></row><row><cell>LaxCat</cell><cell>86.28</cell><cell>86.20</cell><cell>86.09</cell><cell>85.84</cell><cell>89.00</cell><cell>88.78</cell><cell>97.77</cell><cell>96.77</cell></row><row><cell>UniTS</cell><cell>97.90</cell><cell>97.52</cell><cell>94.96</cell><cell>94.81</cell><cell>94.75</cell><cell>94.72</cell><cell>98.75</cell><cell>97.95</cell></row><row><cell>COCOA</cell><cell>93.46</cell><cell>91.63</cell><cell>84.12</cell><cell>83.85</cell><cell>94.11</cell><cell>93.96</cell><cell>97.76</cell><cell>96.64</cell></row><row><cell>FOCAL</cell><cell>92.15</cell><cell>91.83</cell><cell>89.73</cell><cell>89.30</cell><cell>94.36</cell><cell>94.36</cell><cell>98.67</cell><cell>97.84</cell></row><row><cell>CroSSL</cell><cell>86.29</cell><cell>86.06</cell><cell>87.35</cell><cell>83.62</cell><cell>94.45</cell><cell>93.83</cell><cell>97.96</cell><cell>95.06</cell></row><row><cell>MATE</cell><cell>98.90</cell><cell>98.82</cell><cell>96.12</cell><cell>95.99</cell><cell>95.97</cell><cell>95.93</cell><cell>98.97</cell><cell>98.34</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>KNN evaluation results on Realworld-HAR and PAMAP2 datasets.</figDesc><table><row><cell></cell><cell cols="2">RealWorld-HAR</cell><cell cols="2">PAMAP2</cell></row><row><cell>Model</cell><cell cols="4">Accuracy Macro-F1 Accuracy Macro-F1</cell></row><row><cell>CPC SimCLR TS-TCC COCOA TS2Vec Mixing-up TFC FOCAL CroSSL</cell><cell>88.94 89.24 89.47 85.90 70.25 85.34 81.58 89.62 85.90</cell><cell>90.30 90.64 90.71 85.79 62.39 86.41 78.73 90.18 85.69</cell><cell>89.19 91.87 92.19 88.52 56.21 92.28 72.37 94.17 83.83</cell><cell>87.92 91.06 91.35 87.99 47.09 90.95 63.52 93.01 83.63</cell></row><row><cell>MATE</cell><cell>91.66</cell><cell>92.79</cell><cell>94.75</cell><cell>94.76</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Linear probing results under different label ratios on RealWorld-HAR.</figDesc><table><row><cell>Label Ratio</cell><cell>100%</cell><cell></cell><cell>10%</cell><cell></cell><cell>5%</cell><cell></cell><cell>1%</cell><cell></cell></row><row><cell></cell><cell cols="8">Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1</cell></row><row><cell>CPC</cell><cell>89.47</cell><cell>90.35</cell><cell>79.49</cell><cell>78.85</cell><cell>76.62</cell><cell>72.79</cell><cell>49.34</cell><cell>30.84</cell></row><row><cell>SimCLR</cell><cell>89.54</cell><cell>90.52</cell><cell>84.21</cell><cell>85.32</cell><cell>79.76</cell><cell>78.93</cell><cell>48.35</cell><cell>34.59</cell></row><row><cell>TS-TCC</cell><cell>89.70</cell><cell>90.71</cell><cell>82.56</cell><cell>84.53</cell><cell>79.16</cell><cell>79.91</cell><cell>53.25</cell><cell>39.71</cell></row><row><cell>Cocoa</cell><cell>86.83</cell><cell>86.60</cell><cell>65.57</cell><cell>65.24</cell><cell>56.58</cell><cell>56.53</cell><cell>44.03</cell><cell>43.50</cell></row><row><cell>TS2Vec</cell><cell>70.98</cell><cell>62.92</cell><cell>64.77</cell><cell>56.46</cell><cell>62.44</cell><cell>52.59</cell><cell>56.16</cell><cell>46.30</cell></row><row><cell>Mixing-up</cell><cell>85.34</cell><cell>86.41</cell><cell>77.32</cell><cell>77.92</cell><cell>72.34</cell><cell>71.27</cell><cell>53.89</cell><cell>42.99</cell></row><row><cell>TFC</cell><cell>82.58</cell><cell>78.73</cell><cell>72.02</cell><cell>64.82</cell><cell>68.13</cell><cell>62.15</cell><cell>63.85</cell><cell>54.38</cell></row><row><cell>FOCAL</cell><cell>90.21</cell><cell>90.68</cell><cell>88.58</cell><cell>89.68</cell><cell>87.28</cell><cell>87.56</cell><cell>79.32</cell><cell>74.78</cell></row><row><cell>CroSSL</cell><cell>87.33</cell><cell>87.42</cell><cell>85.74</cell><cell>85.32</cell><cell>81.14</cell><cell>81.32</cell><cell>56.46</cell><cell>47.08</cell></row><row><cell>MATE</cell><cell>90.42</cell><cell>91.59</cell><cell>90.21</cell><cell>91.38</cell><cell>88.96</cell><cell>90.28</cell><cell>82.63</cell><cell>76.29</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Linear probing results under different label ratios on UCIHAR.</figDesc><table><row><cell>Label Ratio</cell><cell>100%</cell><cell></cell><cell>10%</cell><cell></cell><cell>5%</cell><cell></cell><cell>1%</cell><cell></cell></row><row><cell></cell><cell cols="8">Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1 Accuracy Macro-F1</cell></row><row><cell>CPC</cell><cell>72.09</cell><cell>71.45</cell><cell>69.71</cell><cell>68.63</cell><cell>61.41</cell><cell>60.70</cell><cell>34.57</cell><cell>30.49</cell></row><row><cell>SimClR</cell><cell>86.27</cell><cell>86.14</cell><cell>78.94</cell><cell>78.35</cell><cell>68.01</cell><cell>67.24</cell><cell>46.46</cell><cell>39.20</cell></row><row><cell>TS-TCC</cell><cell>91.11</cell><cell>91.09</cell><cell>85.12</cell><cell>84.77</cell><cell>76.29</cell><cell>74.45</cell><cell>61.34</cell><cell>58.62</cell></row><row><cell>Cocoa</cell><cell>91.76</cell><cell>91.86</cell><cell>67.47</cell><cell>66.79</cell><cell>53.83</cell><cell>53.52</cell><cell>33.49</cell><cell>32.86</cell></row><row><cell>TS2Vec</cell><cell>70.48</cell><cell>68.37</cell><cell>63.22</cell><cell>61.06</cell><cell>62.48</cell><cell>60.49</cell><cell>49.18</cell><cell>42.29</cell></row><row><cell>Mixing-up</cell><cell>90.23</cell><cell>90.07</cell><cell>86.09</cell><cell>85.71</cell><cell>78.56</cell><cell>77.88</cell><cell>33.78</cell><cell>20.31</cell></row><row><cell>TFC</cell><cell>65.53</cell><cell>65.27</cell><cell>53.52</cell><cell>45.25</cell><cell>40.91</cell><cell>38.67</cell><cell>45.45</cell><cell>44.12</cell></row><row><cell>FOCAL</cell><cell>92.94</cell><cell>92.84</cell><cell>89.69</cell><cell>89.46</cell><cell>80.80</cell><cell>79.92</cell><cell>67.32</cell><cell>63.13</cell></row><row><cell>CroSSL</cell><cell>92.73</cell><cell>92.82</cell><cell>87.91</cell><cell>87.80</cell><cell>77.22</cell><cell>76.71</cell><cell>48.59</cell><cell>47.46</cell></row><row><cell>MATE</cell><cell>93.69</cell><cell>93.65</cell><cell>90.84</cell><cell>90.77</cell><cell>81.75</cell><cell>80.84</cell><cell>68.86</cell><cell>63.52</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Proof of Subspace Identification . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 A2.2 Proof of Component-wise Identification . . . . . . . . . . . . . . . . . . . . . . . 21</figDesc><table><row><cell>Supplement to</cell><cell></cell></row><row><cell cols="2">"From Orthogonality to Dependency: Learning Disentangled</cell></row><row><cell>Representation for Multi-Modal Time-Series Sensing Signals"</cell><cell></cell></row><row><cell>Appendix organization:</cell><cell></cell></row><row><cell>A1 Related Works</cell><cell>17</cell></row><row><cell cols="2">A1.1 Multi-modality Representation Learning . . . . . . . . . . . . . . . . . . . . . . . 17</cell></row><row><cell cols="2">A1.2 Identifiability of Generative Model . . . . . . . . . . . . . . . . . . . . . . . . . . 18</cell></row><row><cell>A2 Proof of Modality-shared Latent Variables z c t</cell><cell>18</cell></row><row><cell>A2.1 A3 Evidence Lower Bound</cell><cell>23</cell></row><row><cell>A4 Prior Estimation</cell><cell>23</cell></row><row><cell>A5 Implementation Details</cell><cell>24</cell></row><row><cell>A6 Experiment Details</cell><cell>24</cell></row><row><cell>A7 Limitation</cell><cell>27</cell></row><row><cell>A8 Broader Impacts</cell><cell>27</cell></row><row><cell>A1 Related Works</cell><cell></cell></row><row><cell>A1.1 Multi-modality Representation Learning</cell><cell></cell></row></table><note><p>A6.1 Dataset Descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 A6.2 More Experiment Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 A6.2.1 Ablation Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 A6.2.2 Full Experiment Results . . . . . . . . . . . . . . . . . . . . . . . . . . . 27</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Then we further take the second-order derivative w.r.t ẑc t,j , where j ∈ {1, • • • , n c } and we have:</figDesc><table><row><cell></cell><cell>nc l=1</cell><cell cols="3">∂ 2 log p(ẑ c t,l |ẑ 1 t-1 ) ∂ ẑc t,i ∂ ẑc t,j</cell><cell cols="2">+</cell><cell cols="4">n l=nc+1</cell><cell cols="5">∂ 2 log p(ẑ s1 t,l |ẑ 1 t-1 , ẑc t ) ∂ ẑc t,i ∂ ẑc t,j</cell></row><row><cell>=</cell><cell>nc l=1</cell><cell cols="3">∂ 2 log p(z c t,l |z 1 t-1 ) ∂ 2 z c t,l</cell><cell>•</cell><cell cols="3">∂z c t,l ∂ ẑc t,j</cell><cell>•</cell><cell cols="2">∂z c t,l ∂ ẑc t,i</cell><cell cols="2">+</cell><cell>nc l=1</cell><cell>∂ log p(z c t,l |z 1 t-1 ) ∂z c t,l</cell><cell>•</cell><cell>∂ 2 z c t,l ∂ ẑc t,i ∂ ẑc t,j</cell></row><row><cell>+</cell><cell cols="2">n l=nc+1</cell><cell cols="6">∂ 2 log p(z s1 t,l |z 1 t-1 , z c t ) ∂ 2 z s1 t,l</cell><cell>•</cell><cell cols="2">∂z s1 t,l ∂ ẑc t,j</cell><cell>•</cell><cell cols="2">∂z s1 t,l ∂ ẑc t,i</cell><cell>+</cell><cell>n l=nc+1</cell><cell>∂ log p(z s1 t,l |z 1 t-1 , z c t ) ∂z s1 t,l</cell><cell>•</cell><cell>∂ 2 z s1 t,l ∂ ẑc t,i ∂ ẑc t,j</cell><cell>-</cell><cell>∂ 2 log |H s1 t | ∂ ẑc t,j t,i ∂ ẑc</cell><cell>.</cell></row><row><cell></cell><cell>=</cell><cell cols="2">nc l=1</cell><cell cols="4">1 t |ẑ 1 t-1 ) ∂ ẑc t,i ∂ log p(z c t,l |z 1 = t-1 ) nc l=1 ∂z c t,l •</cell><cell cols="8">∂ log p(ẑ c t,l |ẑ 1 t-1 ) ∂ ẑc t,i ∂z c t,l ∂ ẑc t,i + n l=nc+1 ∂ log p(z s1 n + l=nc+1 t,l |z 1 ∂ log p(ẑ s1 t,l |ẑ 1 t-1 , ẑc t ) ∂ ẑc t,i t-1 , z c t ) ∂z s1 t,l • ∂z s1 t,l ∂ ẑc t,i -∂ log |H s1 t | t,i ∂ ẑc</cell><cell>.</cell><cell>(41)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>has the only solution</figDesc><table><row><cell>∂z c t,l ∂ ẑc t,i</cell><cell>•</cell><cell>∂z c t,l ∂ ẑc t,j</cell><cell>= 0 and</cell><cell>∂ 2 z c t,l ∂ ẑc t,i ∂ ẑc t,j</cell><cell>= 0 and</cell><cell>∂z t,l s 1 ∂ ẑc t,i</cell><cell>•</cell><cell>∂z ∂ ẑc s 1 t,l t,j</cell><cell>= 0 and</cell><cell>s 1 t,l ∂ 2 z ∂ ẑc t,i ∂ ẑc t,j</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>there is exactly one non-zero component in each column of matrices A and C. Since we have proved that ẑc t = h c (z c t ) and C = 0, there is exactly one non-zero component in each column of matrices A. Therefore, z c t is component-wise identifiable. Based on Equation<ref type="bibr" target="#b39">(40)</ref>, we further let i, j, k ∈ {n c + 1, • • • , n}, and its three-order derivation w.r.t.</figDesc><table><row><cell cols="4">ẑs1 t,i , ẑs1 t,j , z s1 t-1,l can be written as</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>nc l=1</cell><cell>∂ 3 log p(z c t,l |z 1 t-1 ) ∂ 2 z c t,l ∂z s1 t-1,k</cell><cell>•</cell><cell>∂z c t,l ∂ ẑs1 t,j</cell><cell>•</cell><cell>∂z c t,l ∂ ẑs1 t,i</cell><cell>+</cell><cell>nc l=1</cell><cell>∂ 2 log p(z c t,l |z 1 t-1 ) ∂z c t,l ∂z s1 t-1,k</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>exactly one non-zero component in each row of B and D. Since B = 0 ,then z s1 t is component-wise identifiable. Similarly, we can prove that z sm t is component-wise identifiable.</figDesc><table><row><cell cols="14">By using the linear independence assumption, the linear system denoted by Equation (44) has the only solution ∂z c t,l ∂ ẑs 1 t,i • ∂z c t,l ∂ ẑs 1 t,j = 0 and ∂ 2 z c t,l ∂ ẑs 1 t,i ∂ ẑs 1 t,j = 0 and ∂z s 1 t,l ∂ ẑs 1 t,i • ∂z s 1 t,l ∂ ẑs 1 t,j = 0 and s 1 ∂ 2 z t,l ∂ ẑs 1 t,j t,i ∂ ẑs 1 = 0, meaning</cell></row><row><cell cols="3">that there is</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>•</cell><cell>∂ 2 z c t,l ∂ ẑs1 t,i ∂ ẑs1 t,j</cell><cell></cell><cell></cell></row><row><cell>+</cell><cell>n l=nc+1</cell><cell>∂ 3 log p(z s1 t,l |z 1 t-1 , z c t ) ∂ 2 z s1 t,l ∂z s1 t-1,k</cell><cell>•</cell><cell>∂z s1 t,l ∂ ẑs1 t,j</cell><cell>•</cell><cell>∂z s1 t,l ∂ ẑs1 t,i</cell><cell>+</cell><cell>n l=nc+1</cell><cell cols="2">∂ 2 log p(z s1 t,l |z 1 t-1 , z c t ) ∂z s1 t,l ∂z s1 t-1,k</cell><cell>•</cell><cell>∂ 2 z s1 t,l ∂ ẑs1 t,j t,i ∂ ẑs1</cell><cell>= 0.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(46)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table A1 :</head><label>A1</label><figDesc>Architecture details. BS: batch size, T: length of time series, LeakyReLU: Leaky Rectified Linear Unit, |x t |: the dimension of x t .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table A5 :</head><label>A5</label><figDesc>Time series classification for Motion, Seizure, WIFI, and KETI datasets. ResNet 89.96(0.234) 91.41(0.139) 88.64(0.262) 88.58(0.273) 90.29(0.519) 88.14(0.648) 96.05(0.387) 84.59(1.181) MaCNN 85.57(2.117) 86.93(2.429) 90.17(0.172) 48.56(1.666) 88.81(3.821) 87.80(3.353) 93.05(1.411) 71.93(2.178) SenenHAR 88.95(0.369) 88.66(0.276) 89.56(0.620) 47.23(0.182) 94.63(0.614) 92.75(0.686) 96.43(0.143) 84.74(0.379) STFNets 89.07(0.098) 88.84(0.229) 90.51(0.450) 47.50(0.132) 80.52(0.245) 75.93(1.262) 89.21(0.808) 69.55(0.476) RFNet-base 89.93(0.281) 91.70(0.408) 90.76(0.252) 58.79(4.911) 86.31(1.765) 82.56(2.313) 95.12(0.478) 81.45(1.077) THAT 89.66(0.488) 91.38(0.521) 92.76(0.292) 71.64(2.229) 95.59(1.027) 94.86(1.126) 96.33(0.283) 85.12(1.143) LaxCat 60.25(3.678) 41.01(4.381) 90.64(0.362) 54.56(2.013) 76.36(1.492) 73.85(2.155) 93.33(1.449) 70.67(0.335) UniTS 91.02(0.399) 92.73(0.432) 90.88(0.362) 58.39(4.048) 95.83(0.812) 94.49(1.383) 96.04(0.613) 84.08(1.601) COCOA 88.31(0.254) 89.27(0.702) 90.69(0.189) 55.00(1.495) 87.76(0.531) 84.51(0.728) 92.68(1.062) 74.72(1.987) FOCAL 89.37(0.083) 90.91(0.191) 90.52(0.220) 52.00(2.104) 94.15(0.208) 92.68(0.377) 94.88(0.371) 78.47(1.043) CroSSL 91.32(0.992) 89.94(1.353) 91.05(0.438) 53.13(0.781) 76.80(2.206) 68.45(3.054) 93.63(0.504) 76.25(1.538) MATED 92.44(0.160) 93.75(0.154) 93.31(0.170) 73.72(1.148) 96.95(0.231) 96.20(0.431) 97.00(0.097) 86.93(0.924)</figDesc><table><row><cell></cell><cell cols="2">Motion</cell><cell cols="2">DINAMO</cell><cell>WIFI</cell><cell></cell><cell>KETI</cell><cell></cell></row><row><cell>Model</cell><cell>Accuracy</cell><cell>Macro-F1</cell><cell>Accuracy</cell><cell>Macro-F1</cell><cell>Accuracy</cell><cell>Macro-F1</cell><cell>Accuracy</cell><cell>Macro-F1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table A6 :</head><label>A6</label><figDesc>Time series classification for human motion prediction and healthcare datasets. ResNet 86.68(0.327) 86.51(0.247) 92.44(0.278) 92.27(0.289) 93.12(0.630) 93.01(0.637) 98.52(0.066) 97.62(0.083) MaCNN 86.27(0.047) 86.12(0.041) 78.54(0.430) 77.73(0.647) 84.57(0.851) 84.06(0.936) 97.26(0.186) 96.07(0.194) SenenHAR 85.77(1.078) 86.00(1.185) 67.69(0.525) 67.44(0.490) 87.77(1.228) 87.47(1.252) 95.82(0.036) 94.79(0.735) STFNets 86.07(0.368) 85.76(0.291) 61.67(1.481) 57.20(1.112) 81.64(0.521) 81.64(0.339) 91.63(0.369) 88.97(0.217) RFNet-base 97.15(0.616) 96.18(0.457) 94.14(0.674) 93.14(0.710) 95.63(0.952) 95.16(1.414) 98.64(0.139) 97.85(0.108) THAT 85.95(0.226) 85.90(0.207) 81.28(0.351) 81.27(0.182) 93.06(0.364) 93.06(0.422) 98.49(0.159) 97.56(0.237) LaxCat 86.28(0.023) 86.20(0.045) 86.09(2.516) 85.84(2.495) 89.00(0.476) 88.78(0.429) 97.77(0.113) 96.77(0.131) UniTS 97.90(0.561) 97.52(0.879) 94.96(0.461) 94.81(0.152) 94.75(0.526) 94.72(0.528) 98.75(0.078) 97.95(0.099) COCOA 93.46(0.293) 91.63(1.469) 84.12(1.670) 83.85(1.820) 94.11(0.425) 93.96(0.616) 97.76(0.241) 96.64(0.979) FOCAL 92.15(1.428) 91.83(1.214) 89.73(0.270) 89.30(0.282) 94.36(0.098) 94.36(0.190) 98.67(0.053) 97.84(0.103) CroSSL 86.29(0.045) 86.06(0.273) 87.35(1.447) 83.62(1.546) 94.45(0.170) 93.83(0.530) 97.96(0.167) 95.06(0.071) MATED 98.90(0.108) 98.82(0.094) 96.12(0.036) 95.99(0.037) 95.97(0.258) 95.93(0.273) 98.97(0.065) 98.34(0.147)</figDesc><table><row><cell></cell><cell cols="2">HumanEVA</cell><cell cols="2">H36M</cell><cell cols="2">UCIHAR</cell><cell cols="2">MIT-BIH</cell></row><row><cell>Model</cell><cell>Accuracy</cell><cell>Macro-F1</cell><cell>Accuracy</cell><cell>Macro-F1</cell><cell>Accuracy</cell><cell>Macro-F1</cell><cell>Accuracy</cell><cell>Macro-F1</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>RealWorld-HAR <ref type="bibr" target="#b32">[33]</ref> is a public dataset using an accelerometer, gyroscope, magnetometer, and light signals from the forearm, thigh, head, upper arm, waist, chest, and shin to recognize eight common human activities performed by 15 subjects, including climbing stairs down and up, jumping, lying, standing, sitting, running/jogging, and walking.In our experiments, we only used the data collected from the "shin" sensor, including the accelerometer (ACC) and gyroscope. The sampling rate for all selected sensors was set at 100Hz.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Self-supervised learning for time series analysis: Taxonomy, progress, and prospects</title>
		<author>
			<persName><forename type="first">Kexin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingsong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaoli</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongyao</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guansong</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haomin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqi</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingsong</forename><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.14735</idno>
		<title level="m">Foundation models for time series analysis: A tutorial and survey</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Difformer: Multi-resolutional differencing transformer with dynamic ranging for time series analysis</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ce</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Timesnet: Temporal 2d-variation modeling for general time series analysis</title>
		<author>
			<persName><forename type="first">Haixu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tengge</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The eleventh international conference on learning representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Moderntcn: A modern pure convolution structure for general time series analysis</title>
		<author>
			<persName><forename type="first">Donghao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xue</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Twelfth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">One fits all: Power general time series analysis by pretrained lm</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peisong</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring progress in multivariate time series forecasting</title>
		<author>
			<persName><forename type="first">Zezhi</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.06119</idno>
	</analytic>
	<monogr>
		<title level="m">Comprehensive benchmarking and heterogeneity analysis</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Mtsa-snn: A multi-modal time series analysis model based on spiking neural network</title>
		<author>
			<persName><forename type="first">Chengzhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingyu</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuliang</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.05423</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Focal: Contrastive learning for multimodal timeseries sensing signals in factorized orthogonal latent space</title>
		<author>
			<persName><forename type="first">Shengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoyoshi</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruijie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhas</forename><surname>Diggavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mani</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Abdelzaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Towards multimodal deep learning for activity recognition on mobile devices</title>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Radu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sourav</forename><surname>Nicholas D Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cecilia</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahesh</forename><forename type="middle">K</forename><surname>Mascolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fahim</forename><surname>Marina</surname></persName>
		</author>
		<author>
			<persName><surname>Kawsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct</title>
		<meeting>the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="185" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Indoor localization via multi-modal sensing on smartphones</title>
		<author>
			<persName><forename type="first">Han</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zimu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longfei</forename><surname>Shangguan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<meeting>the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="208" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Utilizing expert features for contrastive learning of time-series representations</title>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Manuel T Nonnenmacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ingo</forename><surname>Oldenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Steinwart</surname></persName>
		</author>
		<author>
			<persName><surname>Reeb</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="16969" to="16989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">M3care: Learning with missing modalities in multimodal healthcare data</title>
		<author>
			<persName><forename type="first">Chaohe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liantao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinghao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasha</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangtao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfeng</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2418" to="2428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-modality machine learning predicting parkinson&apos;s disease. npj</title>
		<author>
			<persName><surname>Mary B Makarious</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hampton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hirotaka</forename><surname>Vitale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lana</forename><surname>Iwaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anant</forename><surname>Sargent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivo</forename><surname>Dadu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Violich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Saffo</surname></persName>
		</author>
		<author>
			<persName><surname>Bandres-Ciga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parkinson&apos;s Disease</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A ready-to-use machine learning tool for symmetric multi-modality registration of brain mri</title>
		<author>
			<persName><forename type="first">Juan</forename><surname>Eugenio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iglesias</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6657</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Financial time series forecasting with multi-modality graph neural network</title>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangzhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page">108218</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain adaptive multimodality neural attention network for financial forecasting</title>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lecheng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yada</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingrui</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2230" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cocoa: Cross modality contrastive learning for sensor data</title>
		<author>
			<persName><forename type="first">Shohreh</forename><surname>Deldari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaqib</forename><surname>Hao Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">V</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flora</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><surname>Salim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cosmo: contrastive fusion learning with small data for multimodal human activity recognition</title>
		<author>
			<persName><forename type="first">Xiaomin</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivy</forename><forename type="middle">Wang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoliang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianwei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual International Conference on Mobile Computing And Networking</title>
		<meeting>the 28th Annual International Conference on Mobile Computing And Networking</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="324" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Latent processes identification from multi-view time series</title>
		<author>
			<persName><forename type="first">Zenan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haobo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nenggan</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.08164</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Subspace identification for multi-source domain adaptation</title>
		<author>
			<persName><forename type="first">Zijian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruichu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Partial disentanglement for domain adaptation</title>
		<author>
			<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petar</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Akinwande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="11455" to="11472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Temporally disentangled representation learning</title>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="26492" to="26503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning temporally causal latent processes from general temporal data</title>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuewen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changyin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.05428</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Understanding masked autoencoders via hierarchical latent variable models</title>
		<author>
			<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">Q</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuejie</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="7918" to="7928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A survey on behavior recognition using wifi channel state information</title>
		<author>
			<persName><forename type="first">Siamak</forename><surname>Yousefi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hirokazu</forename><surname>Narui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sankalp</forename><surname>Dayal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahrokh</forename><surname>Valaee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="98" to="104" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">High-dimensional time series clustering via cross-predictability</title>
		<author>
			<persName><forename type="first">Dezhi</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamin</forename><surname>Whitehouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="642" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collecting complex activity datasets in highly rich networked sensor environments</title>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Daniel Roggen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirco</forename><surname>Calatroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Holleczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerhard</forename><surname>Förster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Tröster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Lukowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Bannach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alois</forename><surname>Pirkl</surname></persName>
		</author>
		<author>
			<persName><surname>Ferscha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 Seventh international conference on networked sensing systems (INSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Alexandru O Balan</surname></persName>
		</author>
		<author>
			<persName><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="27" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments</title>
		<author>
			<persName><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A public domain dataset for human activity recognition using smartphones</title>
		<author>
			<persName><forename type="first">Davide</forename><surname>Anguita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Ghio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luca</forename><surname>Oneto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Parra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Luis Reyes-Ortiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Esann</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Introducing a new benchmarked dataset for activity monitoring</title>
		<author>
			<persName><forename type="first">Attila</forename><surname>Reiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didier</forename><surname>Stricker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 16th international symposium on wearable computers</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="108" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On-body localization of wearable devices: An investigation of position-aware activity recognition</title>
		<author>
			<persName><forename type="first">Timo</forename><surname>Sztyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heiner</forename><surname>Stuckenschmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Pervasive Computing and Communications (PerCom)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The impact of the mit-bih arrhythmia database</title>
		<author>
			<persName><forename type="first">B</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><forename type="middle">G</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE engineering in medicine and biology magazine</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="45" to="50" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The open d1namo dataset: A multi-modal dataset for research on non-invasive type 1 diabetes management</title>
		<author>
			<persName><forename type="first">Fabien</forename><surname>Dubosson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Eudes</forename><surname>Ranvier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Bromuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean-Paul</forename><surname>Calbimonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schumacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatics in Medicine Unlocked</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="92" to="100" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stfnets: Learning sensing signals from the time-frequency perspective with short-time fourier neural networks</title>
		<author>
			<persName><forename type="first">Shuochao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ailing</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenjun</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huajie</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaohan</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2192" to="2202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Two-stream convolution augmented transformer for human activity recognition</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="286" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Explainable multivariate time series classification: a deep neural network which learns to attend to important variables as well as time intervals</title>
		<author>
			<persName><forename type="first">Tsung-Yu</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasant</forename><surname>Honavar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM international conference on web search and data mining</title>
		<meeting>the 14th ACM international conference on web search and data mining</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="607" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Units: Short-time fourier inspired neural networks for sensory time series classification</title>
		<author>
			<persName><forename type="first">Shuheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranak</forename><surname>Roy Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajesh</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dezhi</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems</title>
		<meeting>the 19th ACM Conference on Embedded Networked Sensor Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="234" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rf-net: A unified meta-learning framework for rf-enabled one-shot human activity recognition</title>
		<author>
			<persName><forename type="first">Shuya</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyue</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Conference on Embedded Networked Sensor Systems</title>
		<meeting>the 18th Conference on Embedded Networked Sensor Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="517" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multimodal deep learning for activity and context recognition</title>
		<author>
			<persName><forename type="first">Valentin</forename><surname>Radu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sourav</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cecilia</forename><surname>Mascolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahesh</forename><forename type="middle">K</forename><surname>Marina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fahim</forename><surname>Kawsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies</title>
		<meeting>the ACM on interactive, mobile, wearable and ubiquitous technologies</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sensehar: a robust virtual activity sensor for smartphones and wearables</title>
		<author>
			<persName><forename type="first">Jeya</forename><surname>Vikranth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeyakumar</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Liangzhen</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naveen</forename><surname>Suda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mani</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Conference on Embedded Networked Sensor Systems</title>
		<meeting>the 17th Conference on Embedded Networked Sensor Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="15" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Self-supervised contrastive representation learning for semi-supervised time-series classification</title>
		<author>
			<persName><forename type="first">Emadeldeen</forename><surname>Eldele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Ragab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chee-Keong</forename><surname>Kwoh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cuntai</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Ts2vec: Towards universal representation of time series</title>
		<author>
			<persName><forename type="first">Zhihan</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juanyong</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianmeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congrui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunhai</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bixiong</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="8980" to="8987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Mixing up contrastive learning: Self-supervised representation learning for time series</title>
		<author>
			<persName><forename type="first">Kristoffer</forename><surname>Wickstrøm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Kampffmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Øyvind Mikalsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Jenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="54" to="61" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Crossl: Cross-modal self-supervised learning for time-series through latent masking</title>
		<author>
			<persName><forename type="first">Shohreh</forename><surname>Deldari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitris</forename><surname>Spathis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Malekzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fahim</forename><surname>Kawsar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flora</forename><forename type="middle">D</forename><surname>Salim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akhil</forename><surname>Mathur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM International Conference on Web Search and Data Mining</title>
		<meeting>the 17th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="152" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Understanding and constructing latent modality structures in multi-modal representation learning</title>
		<author>
			<persName><forename type="first">Qian</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qing</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Son</forename><surname>Dinh Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Belinda</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trishul</forename><surname>Chilimbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="7661" to="7671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">High-modality multimodal transformer: Quantifying modality &amp; interaction heterogeneity for high-modality representation learning</title>
		<author>
			<persName><forename type="first">Paul Pu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Tsaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yudong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shentong</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Russ</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Machine Learning Research</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cross-linked unified embedding for cross-modality representation learning</title>
		<author>
			<persName><forename type="first">Xinming</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi-Jie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Mostafavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ge</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="15942" to="15955" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">M3ae: Multimodal representation learning for brain tumor segmentation with missing modalities</title>
		<author>
			<persName><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donghuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinghan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liansheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yefeng</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1657" to="1665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multi-modal alignment using representation codebook</title>
		<author>
			<persName><forename type="first">Jiali</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Son</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Belinda</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trishul</forename><surname>Chilimbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="15651" to="15660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Masked vision and language modeling for multi-modal representation learning</title>
		<author>
			<persName><forename type="first">Gukyeong</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erhan</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Bhotika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.02131</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Align before fuse: Vision and language representation learning with momentum distillation</title>
		<author>
			<persName><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramprasaath</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akhilesh</forename><surname>Gotmare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9694" to="9705" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Efficient vision-language pretraining with visual concepts and hierarchical alignment</title>
		<author>
			<persName><forename type="first">Mustafa</forename><surname>Shukor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Couairon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2208.13628</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Vision-language pre-training with triple contrastive learning</title>
		<author>
			<persName><forename type="first">Jinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiali</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Son</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampath</forename><surname>Chanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liqun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Belinda</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trishul</forename><surname>Chilimbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="15671" to="15680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A survey on contrastive self-supervised learning</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramesh</forename><surname>Ashwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">Zaki</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debapriya</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fillia</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><surname>Makedon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technologies</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">S4l: Self-supervised semisupervised learning</title>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Self-supervised learning: Generative or contrastive</title>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fanjin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="857" to="876" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Masked autoencoders are scalable vision learners</title>
		<author>
			<persName><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="16000" to="16009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Xinyang</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.14204</idno>
		<title level="m">Multimodal masked autoencoders learn transferable representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Learning sequential latent variable models from multimodal time series data</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Limoyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Ablett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Kelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Autonomous Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="511" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Mvae: Multimodal variational autoencoder for fake news detection</title>
		<author>
			<persName><forename type="first">Dhruv</forename><surname>Khattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaipal</forename><surname>Singh Goud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The world wide web conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2915" to="2921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Multi-modality spatio-temporal forecasting via self-supervised learning</title>
		<author>
			<persName><forename type="first">Jiewen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renhe</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.03255</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Freqmae: Frequency-aware masked autoencoder for multi-modal iot sensing</title>
		<author>
			<persName><forename type="first">Denizhan</forename><surname>Kara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoyoshi</forename><surname>Kimura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianshi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruijie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yigong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Abdelzaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on Web Conference 2024</title>
		<meeting>the ACM on Web Conference 2024</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="2795" to="2806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Learning interpretable concepts: Unifying causal representation learning and foundation models</title>
		<author>
			<persName><forename type="first">Goutham</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryon</forename><surname>Aragam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Ravikumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.09236</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Object-centric architectures enable efficient causal representation learning</title>
		<author>
			<persName><forename type="first">Amin</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Hartford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.19054</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Causal component analysis</title>
		<author>
			<persName><forename type="first">Liang</forename><surname>Wendong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armin</forename><surname>Kekić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Julius Von Kügelgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Besserve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Multi-view causal representation learning with partial observability</title>
		<author>
			<persName><forename type="first">Dingling</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danru</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Perouz</forename><surname>Taslakian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Georg</forename><surname>Martius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julius</forename><surname>Von Kügelgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.04056</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Toward causal representation learning</title>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><forename type="middle">Rosemary</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="612" to="634" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Causal triplet: An open challenge for intervention-centric causal representation learning</title>
		<author>
			<persName><forename type="first">Yuejiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Zietlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Conference on Causal Learning and Reasoning (CLeaR)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">The incomplete rosetta stone problem: Identifiability results for multi-view nonlinear ica</title>
		<author>
			<persName><forename type="first">Luigi</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Paul K Rubenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Mehrjou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="217" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Independent component analysis, a new concept</title>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Comon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal processing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="314" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Independent component analysis: recent advances</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">371</biblScope>
			<biblScope unit="page">20110534</biblScope>
			<date type="published" when="1984">1984. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Te-Won</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Te-Won</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>Independent component analysis</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Kernel-based nonlinear independent component analysis</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laiwan</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Independent Component Analysis and Signal Separation</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="301" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">On the identifiability of nonlinear ica: Sparsity and beyond</title>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignavier</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="16411" to="16422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Nonlinear independent component analysis: Existence and uniqueness results</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petteri</forename><surname>Pajunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="429" to="439" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Identifiability of latent-variable and structural-equation models: from linear to nonlinear</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Monti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.02672</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ica</title>
		<author>
			<persName><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Monti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Diederik Kingma, and Aapo Hyvarinen</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12768" to="12778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Identifying semantic component for robust molecular property prediction</title>
		<author>
			<persName><forename type="first">Zijian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zunhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruichu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenhui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuguang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.04837</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Variational autoencoders and nonlinear ica: A unifying framework</title>
		<author>
			<persName><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2207" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Unsupervised feature extraction by time-contrastive learning and nonlinear ica</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Morioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Nonlinear ica of temporally dependent stationary sources</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Morioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="460" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Nonlinear ica using auxiliary variables and generalized contrastive learning</title>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="859" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Multi-domain image generation and translation with identifiability guarantees</title>
		<author>
			<persName><forename type="first">Shaoan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Eleventh International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Identification of nonlinear latent hierarchical models</title>
		<author>
			<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Biwei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuejie</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.07916</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Counterfactual generation with identifiability guarantees</title>
		<author>
			<persName><forename type="first">Hanqi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingjing</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujie</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">37th International Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Synergies between disentanglement and sparsity: Generalization and identifiability in multi-task learning</title>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyat</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Bertrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="18171" to="18206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Lachapelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.07732</idno>
		<title level="m">Partial disentanglement via mechanism sparsity</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Causal representation learning from multiple distributions: A general setting</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignavier</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujia</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.05052</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Hidden markov nonlinear ica: Unsupervised learning from nonstationary time series</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hermanni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="939" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Citris: Causal identifiability from temporal intervened sequences</title>
		<author>
			<persName><forename type="first">Phillip</forename><surname>Lippe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sindy</forename><surname>Löwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuki</forename><forename type="middle">M</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stratis</forename><surname>Gavves</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="13557" to="13603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Temporally disentangled representation learning under unknown nonstationarity</title>
		<author>
			<persName><forename type="first">Xiangchen</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiran</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yewen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinshuai</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=V8GHCGYLkf" />
	</analytic>
	<monogr>
		<title level="m">Thirty-seventh Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<author>
			<persName><forename type="first">Imant</forename><surname>Daunhawer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Bizeul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuele</forename><surname>Palumbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><forename type="middle">E</forename><surname>Vogt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.09166</idno>
		<title level="m">Identifiability results for multimodal contrastive learning</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
