<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Nonlinear Markov Models for Human Motion</title>
				<funder ref="#_ajmRkPW">
					<orgName type="full">Microsoft Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Andreas</forename><forename type="middle">M</forename><surname>Lehrmann</surname></persName>
							<email>alehrmann@tue.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems Tuebingen</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
							<email>pgehler@tue.mpg.de</email>
							<affiliation key="aff1">
								<orgName type="institution">MPI for Intelligent Systems Tuebingen</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
							<email>sebastian.nowozin@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Nonlinear Markov Models for Human Motion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dynamic Bayesian networks such as Hidden Markov Models (HMMs) are successfully used as probabilistic models for human motion. The use of hidden variables makes them expressive models, but inference is only approximate and requires procedures such as particle filters or Markov chain Monte Carlo methods. In this work we propose to instead use simple Markov models that only model observed quantities. We retain a highly expressive dynamic model by using interactions that are nonlinear and non-parametric. A presentation of our approach in terms of latent variables shows logarithmic growth for the computation of exact loglikelihoods in the number of latent states. We validate our model on human motion capture data and demonstrate state-of-the-art performance on action recognition and motion completion tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Statistical models for human motion are important in many areas of computer vision and graphics. In addition to being interesting in their own right <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b21">22]</ref>, their applications include areas as diverse as animation, robotics, tracking <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27]</ref>, and activity recognition <ref type="bibr" target="#b3">[4]</ref>. While great progress has been made in the past decade, the problem remains challenging because of the high dimensionality, nonlinearity and multimodality of natural human motion. Ideally, a good probabilistic model should account for all of those challenges, but unfortunately expressive models often result in intractable estimation and inference problems. We now review the most popular approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Dynamic Bayesian Networks</head><p>In recent years, modelling of human motion has been tackled from several different perspectives. Among the most popular methods are latent variable models following the state-space equations (see also Figure <ref type="figure" target="#fig_1">2a</ref>),</p><formula xml:id="formula_0">z t = f (z t-1 , z ) ↔ p z (z t | z t-1 ) ,<label>(1)</label></formula><formula xml:id="formula_1">x t = g (z t , x ) ↔ p x (x t | z t ) ,<label>(2)</label></formula><p>where x t are observable variables such as joint positions or joint angles, z t are hidden variables, and</p><p>x , z are random perturbations. Although filtering and smoothing distributions for z t are within this framework, they are only tractable for either a discrete state space (forward(-backward) algorithm) or for linear functions f, g and additive Gaussian noise (Kalman filter/smoother) <ref type="bibr" target="#b13">[14]</ref>.</p><p>Efficient and exact solutions for the general nonlinear and/or non-Gaussian cases do not exist <ref type="bibr" target="#b7">[8]</ref>. To perform inference we therefore need to resort to approximate methods, such as the extended Kalman filter and its derivates <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18]</ref>, or to Sequential Monte Carlo methods like particle filters <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b6">7]</ref>. Augmenting the state-space model with discrete switching variables leads to a Switching Linear Dynamical System (SLDS). Exact inference in this model is intractable even for the Gaussian-linear case <ref type="bibr" target="#b1">[2]</ref> and learning has turned out to be a challenge in itself <ref type="bibr" target="#b12">[13]</ref>.</p><p>Equations <ref type="bibr" target="#b0">(1)</ref><ref type="bibr" target="#b1">(2)</ref> and their extensions form the basis for a number of statistical models for human motion: Wang et al. <ref type="bibr" target="#b28">[29]</ref> assume a linear combination of nonlinear basis functions for f, g and additive Gaussian noise for x , z . Marginalizing over f, g leads to a Gaussian Process Dynamical Model (GPDM), whose latent trajectories have to be learned by a combination of Scaled Conjugate Gradient and a version of EM using Hybrid Monte Carlo techniques. Urtasun et al. <ref type="bibr" target="#b27">[28]</ref> extend the GPDM framework by introducing a prior for latent positions that preserves local topological structure. Pavlović et al. <ref type="bibr" target="#b21">[22]</ref> use approximate variational inference to learn an SLDS and perform inference in it. Taylor et al. <ref type="bibr" target="#b25">[26]</ref> consider a latent space consisting of binary variables and use a conditional RBM to model human motion. While inference tasks are easy in this model, learning relies on approximations like contrastive divergence <ref type="bibr" target="#b15">[16]</ref>. Models inspired by physics and biology include <ref type="bibr" target="#b29">[30]</ref> and <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Contributions</head><p>In this work we propose to leave out the latent space altogether. Instead we model human motion by means of an expressive Markov model that is both simple enough to al-low for efficient and exact inference yet flexible enough to accurately model real human motion data. Due to our nonparametric representation, we achieve a high level of realism. Specifically, our work makes the following four contributions: 1. We introduce the Dynamic Forest Model (DFM) and describe its training and regularization, building upon work on autoregressive trees <ref type="bibr" target="#b19">[20]</ref>; 2. We present a formulation of our approach in terms of latent variables, thereby allowing a direct comparison to Hidden Markov Models; 3. We show how DFMs can be used as accurate and efficient models of human motion data; 4. We empirically validate DFMs on challenging action recognition and motion completion tasks, outperforming both HMMs and GPDMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Nonlinear Markov Models</head><p>In this section we present our model and its training procedure. A Markov model describes a conditional distribution of the present state x t given a limited number of past observations pa(x t ) := x (t-K):(t-1) . That is, at each time step t a fixed number of K previous observations are combined to form a prediction x t . The prediction is then an order-K Markov process,</p><formula xml:id="formula_2">p (x t | pa (x t )) = p x t | x (t-K):(t-1) .<label>(3)</label></formula><p>If the mean of this distribution can be written as a fixed linear combination of the previous observations, the Markov model is said to be linear <ref type="bibr" target="#b10">[11]</ref>. When this is not the case, the model is a nonlinear Markov model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Autoregressive Trees</head><p>Autoregressive (AR) trees <ref type="bibr" target="#b19">[20]</ref> are a type of probabilistic AR model for time-series data <ref type="bibr" target="#b10">[11]</ref> in which the regression function is given by a decision tree.</p><p>To represent the distribution in equation ( <ref type="formula" target="#formula_2">3</ref>) the tree evaluates features φ (pa (x t )) ∈ R F extracted from the previous K frames and, using this information, decides among a set of simpler distributions stored at its leaf nodes. This is illustrated in Figure <ref type="figure" target="#fig_2">1</ref>. We store in each leaf one multivariate normal distribution with linearly regressed mean but fixed covariance matrix. In this case, the predictive expectation can be obtained by the linear dynamics</p><formula xml:id="formula_3">E [x t | pa (x t )] = A φ (pa (x t )) .</formula><p>Although this is a simple linear prediction, the choice of which matrix A is used is governed by the decision tree and thus a function of φ (pa (x t )). 1 For example, by testing for statistics such as average joint velocities in the past K frames, the tree may easily distinguish a running from a walking motion, and hence is able to select the appropriate linear dynamics. 1 In general one can use different features for linear prediction and leaf node selection.</p><formula xml:id="formula_4">A 1 , Σ 1 A 2 , Σ 2 A 3 , Σ 3 A 4 , Σ 4 1 2 3 4</formula><p>Figure <ref type="figure" target="#fig_2">1</ref>: Autoregressive tree. A decision tree is evaluated on a set of features extracted from K previously observed frames, φ (pa (x t )). At each leaf i of the tree a linear autoregressive model is stored. If leaf i is reached, the predictive filtering distribution is defined as p</p><formula xml:id="formula_5">(x t | pa (x t )) = N (A i φ (pa (x t )) , Σ i ).</formula><p>In the original work on autoregressive trees a single tree is learned by greedily optimizing a penalized likelihood objective <ref type="bibr" target="#b19">[20]</ref>. The authors show applications to short-term forecasting of univariate economic data but note that 95% of their trees do not contain any splits, i.e., they are common AR models. Here, we propose extensions to AR trees that enable us to take advantage of deeper trees and to cope with high-dimensional inputs, eventually allowing their use for classification, synthesis and upscaling of complex human motion data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Dynamic Forests</head><p>Because a single tree is prone to overfitting and limited in its expressiveness due to its unimodal predictive distribution, we will instead learn an ensemble of C &gt; 1 trees, {T c } c=1,...,C . Each tree is trained separately using bagging <ref type="bibr" target="#b4">[5]</ref>, that is, resampling the training set framewise with replacement. The predictions of the individual trees are then averaged to produce the prediction of the forest. Since each tree has a Gaussian posterior, the forest posterior is given by a multimodal mixture of Gaussians,</p><formula xml:id="formula_6">p (x t | pa (x t )) = 1 C C c=1 N x t µ (c,t) , Σ (c,t) .</formula><p>Here, (c, t) := (c, φ(pa(x t ))) denotes the leaf node that is selected by the c'th tree at the t'th time step and each mixture component has the mean vector µ (c,t) := A (c,t) φ(pa(x t )).</p><p>We call this new approach a Dynamic Forest Model (DFM) and continue with a description of its training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Training</head><p>We provide a bottom-up description of the training procedure, i.e., we start with the estimation of a leaf model and then consider the task of learning the tree structure.   </p><formula xml:id="formula_7">, D = (X i ) i=1,...,N . Each se- quence X i is a concatenation of T i frames, hence X i = (x (i) t ) t=1,.</formula><p>..,Ti . The t'th frame of the i'th sequence is represented by a fixed-length vector x (i) t ∈ R d . We will often drop the sequence index i to keep the notation uncluttered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Training the Leaf Model</head><p>Learning a model for a leaf node amounts to estimating a regression matrix A and a covariance matrix Σ . Each leaf accommodates a subset {(φ(pa(x t )), x t )} t∈D of the training data, namely those feature vectors and regression targets that reach it. We use the available data points to estimate A using ridge regression <ref type="bibr" target="#b16">[17]</ref>. To this end, let Φ denote all column-wise concatenated feature vectors φ(pa(x t )) that are assigned to the leaf. Likewise, and in the same order, we concatenate all the desired predictions column-wise into a matrix U . The matrix A now has the closed-form solution</p><formula xml:id="formula_8">A := U Φ ΦΦ + γI -1 ,</formula><p>where γ &gt; 0 is the ridge regularization parameter.</p><p>To determine the covariance matrix Σ , we first use the ground truth to compute the residual vectors r t := x t -A φ(pa(x t )). The set of all the residual vectors is then used to estimate a matrix Σ by means of the sample covariance. While the estimate of A is generally quite accurate, we observed that the covariance estimate Σ may become inaccurate for high dimensions and small sample sizes. In some cases the estimated matrices are even singular. We therefore regularize our initial estimate by projecting Σ to an isotropic target with full rank,</p><formula xml:id="formula_9">Σ := d -1 tr Σ I,</formula><p>a measure that proved to be important for the success of our approach. We also experimented with a convex combination of the sample covariance matrix and a diagonal shrinkage target <ref type="bibr" target="#b23">[24]</ref>, but it did not improve the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Training the Tree Structure</head><p>To determine the tree structure, we use a greedy training procedure, as is commonly used in the literature <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10]</ref>. We start with a single node and recursively split leaf nodes by selecting the best among a set of hyperplane splits. Each candidate split is sampled from a proposal distribution p s , e.g., by uniformly sampling a data point and a coordinate. A candidate split s at leaf introduces child nodes u and v, each of which receives a subset of the data present at . After estimating a leaf model for u and v according to section 2.3.1, we determine the quality of the proposed split by measuring the resulting reduction in residual error,</p><formula xml:id="formula_10">Z s := E -(E u + E v ) ,</formula><p>where E η is given as the sum of squared residuals norms,</p><formula xml:id="formula_11">E η := t∈Dη r t 2 .</formula><p>The split that achieves the largest score Z s is selected and the training proceeds recursively.</p><p>Implementation of DFMs is easy and analytical solutions for the score function and the least squares regressor make learning very efficient. The required training time can be controlled by the number of trees, their depth and the number of tested splits. Algorithm 1 summarizes DFM training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Latent space view and comparison to Hidden Markov Models</head><p>In this section we will compare our Dynamic Forest Model with the class of Hidden Markov Models. For an easier comparison we formulate DFMs as a latent variable model, thereby making explicit the relationship between decision tree leaves and latent states.</p><p>Consider a tree T c with l leaf nodes. By introducing latent variables z t with l states we arrive at the latent variable model depicted in Figure <ref type="figure" target="#fig_1">2c</ref> for order K = 2. In this formulation the joint distribution of an observed sequence X and latent variables Z is given by Algorithm 1 Probabilistic DFM training </p><formula xml:id="formula_12">p (X, Z) = T t=K+1 p (x t | pa (x t )) p (z t | pa (z t )) .</formula><p>Since the latent states are deterministic predictions from observations, their distributions can be understood as delta functions p (z t | pa (z t )) = δ (z t -(c, t)).</p><p>In the DFM, information between latent variables has to flow through observed variables, whereas in HMMs the latent variables have a direct interaction. Because the latent states are determined from observations only they are conditionally independent given the observed sequence. This is different to Hidden Markov Models. To be precise the DFM encodes the following conditional independence statements for all t &gt; K + 1:</p><formula xml:id="formula_13">z t ⊥ ⊥ {z 1 , . . . , z t-1 } | pa (z t ) , x t ⊥ ⊥ x 1 , . . . , x t-(K+1) | pa (x t ) .</formula><p>It is this factorization that allows to compute the marginal likelihood in a single summation,</p><formula xml:id="formula_14">log p (X) = log z K+1 ,...,z T p (X, Z)<label>(4)</label></formula><formula xml:id="formula_15">= T t=K+1 log p (x t | x t-K , . . . , x t-1 , (c, t)) .</formula><p>Under the assumption of balanced trees, the cost for the computation of log-likelihoods in a DFM is O (log (l) T ), which is sublinear in the number of latent states. The time complexity of Hidden Markov Models for the same task scales according to O l<ref type="foot" target="#foot_0">foot_0</ref> T , which is quadratic.</p><p>The additional efficiency in our model relies on two implicit assumptions: 1. We assume that we can identify the correct latent state. At time t, we put the entire probability mass on a single latent state that we select based on the feature vector φ (pa (x t )). Our approach thus stands and falls with the design of this feature vector and the information it encodes. A Hidden Markov Model on the other hand can incorporate prior knowledge from the application domain (e.g., occlusion reasoning, object-object interactions, or compositionality <ref type="bibr" target="#b2">[3]</ref>) by refining the model used for the hidden state sequence; 2. We assume that long-range dependencies are negligible. Whereas we do not model interactions beyond order K, Hidden Markov Models do have a long-term memory due to the Markov process on the hidden state sequence, thereby rendering the observation sequence non-Markov ([14], Section 1.3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We demonstrate the usefulness of DFMs on three different tasks: action recognition, motion completion and prediction of 3D motion from 2D inputs. Our experiments are based on the MSRC-12 dataset <ref type="bibr" target="#b11">[12]</ref> and a modified version of the CMU dataset 2 as used by Wang et al. <ref type="bibr" target="#b28">[29]</ref>.</p><p>Technically, we represent a human motion sequence of length T as a temporal sequence of d-dimensional body poses. This yields a matrix X ∈ R d×T which can be used as part of an ensemble training according to section 2. Depending on the dataset, the individual poses in the columns of X are given in either joint angles or world coordinates. In our experiments, the feature mapping φ (pa (x t )) concatenates all vectors in the subsequence pa (x t ) and adds a constant that models an intercept and allows for affine regression functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Human Action Recognition</head><p>The MSRC-12 dataset comprises sequences of people performing a total of 12 iconic and metaphoric gestures. Every sequence is the output of the Kinect's human body tracker, which gives a noisy estimate of 20 joints. These are defined in xyz-world coordinates, resulting in a d = 60 dimensional vector x t per frame.</p><p>We use the iconic gestures from this dataset, which amounts to 296 sequences of about 1000 frames length each. The task is to classify sequences to their six iconic gesture classes G = {Duck, Goggles, Shoot, . . . Throw, Change weapon, Kick}.   Each class comprises approximately 50 sequences coming from 30 different persons. In order to assess the generalization capabilities of our approach across persons, we employ 5-fold leave-person-out cross-validation, i.e., each fold consists of 24 persons for training and 6 persons for testing. We train |G| different DFMs {T g } g∈G per fold, one for each gesture, according to Algorithm 1. We report classification accuracies obtained with dynamic forests consisting of 12 trees, all of which were trained with 2 10 tested splits. We use a fixed ridge regularization of 10 -5 but vary the tree depth and Markov order. In order to assign an unseen test sequence X to its corresponding class g * , we compute the log-likelihood of the sequence under each of the individual per-gesture models and assign it to the class maximizing this quantity,</p><formula xml:id="formula_16">g * := argmax g ∈G log p (X | T g ) ,<label>(5)</label></formula><p>where the log-likelihoods are given according to (4).</p><p>Baseline methods. We compare DFMs to four different baseline methods. Two of them, k-nearest neighbours (k-NN) and Support Vector Machines (SVM), are standard classification methods, the other two, Hidden Markov Models (HMM) and Dynamic Time Warping (DTW), are more specialized dynamic models and tailored to time-series data.</p><p>For the k-NN and SVM approaches we classify all length-four subsequences in a given test sequence. The class label of the entire sequence is determined by taking the majority vote over all of those subsequences. In order to classify a subsequence using k-NN we compare it to all ≈ 256,000 subsequences of the training set and find the knearest neighbours with respect to the Euclidean distance. The parameter k is set to 6, which yields best performance on the test set in the range k = 1, . . . , 8. The SVM classifier is also trained on all ≈ 256,000 subsequences. We use the implementation <ref type="bibr" target="#b8">[9]</ref> with a one-vs-rest classifier and a Gaussian RBF kernel.</p><p>DTW is a powerful time-series classifier that aligns two sequences by computing a possibly nonlinear warping path between them, thereby ignoring variations in duration and speed. We use the reference implementation of the Fast-DTW authors <ref type="bibr" target="#b22">[23]</ref> and vary the search radius between 2 4 and 2 8 . A test sequence is classified by calculating the warp distance to all training sequences (normalized by path length) and assigning it to the class of the training sequence with minimal warp distance.</p><p>For the HMM experiments we use the implementation of <ref type="bibr" target="#b20">[21]</ref>, training one HMM per gesture class. The original authors tuned their implementation for the same type of Kinect skeletal data we use. The implementation supports the use of raw features and PCA-reduced features (+PCA) and we report results for both options. The PCA features are obtained by constructing subsequences of length four and using the coefficients of the first 12 principal components. This is a powerful preprocessing step that is necessary for the HMM to work. To find the number of hidden states, we perform model selection, testing 5, 10, 20, and 40 hidden states, and report the best test performance. At test-time we classify a sequence by evaluating the marginal log-likelihood for each HMM and assign the sequence to the class of highest likelihood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Results</head><p>Table <ref type="table" target="#tab_1">1a</ref> shows the quantitative results of our DFM and a comparison to the baseline methods. The worst performance was delivered by the k-NN approach (78.4%), which is not surprising given its naïve exhaustive search. Overall the time-series models tend to perform better than the simple classification baselines. That said, DTW (81.1%) still falls short of the SVM accuracy (83.1%), but mostly due to its weak performance on the "Shoot" class (46.9%). Varying the search radius does not alleviate this problem and the maximum is already attained for 2 4 . For the HMM the best result is obtained with 10 hidden states. Note that the HMM requires strong preprocessing: Using raw data the performance is inferior at 63.6% and only the PCA features make the HMM perform at 84.4%. Our DFM achieves an accuracy of 90.9% and outperforms all other evaluated methods, notably without relying on any form of preprocessing. This indicates that DFMs are very robust with respect to the fea-  tures used. In Table <ref type="table" target="#tab_1">1b</ref> we show DFM results for different tree depths and Markov orders. For comparison, we also include accuracies for a single tree of depth 4. The results of the DFM are both better and more stable, proving the point that our approach reduces overfitting and increases predictive power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Motion Completion</head><p>In this experiment we apply the DFM to a motion completion task on walking sequences and compare our results to a recent Gaussian Process Dynamical Model (GPDM). Furthermore, we demonstrate the suitability of the presented framework for more complex actions and provide some general insights into training of DFMs. All of our motion completion experiments use the CMU motion capture database, a rich and noiseless data source of people performing different activities. All sequences are given by 56 joint angles and an additional 6 parameters governing the global translation and orientation.</p><p>Motion completion refers to the task of recovering consecutively missing frames from a motion sequence. More specifically, given a complete motion sequence</p><formula xml:id="formula_17">X = x 1:i , x (i+1):(i+j) , x (i+j+1):T ∈ R d×T ,</formula><p>we remove the subsequence x (i+1):(i+j) of length j in the middle and estimate x(i+1):(i+j) from the remaining frames based on our model.</p><p>As in <ref type="bibr" target="#b28">[29]</ref>, we use the following three preprocessing steps for all CMU sequences: 1. A modified skeleton (reducing the number of degrees of freedom from 62 to 50); 2. Temporal downsampling by a factor of four; 3. Centering of all variables.</p><p>After that, we take the first T = 50 frames of the 8 test sequences listed in Table <ref type="table" target="#tab_3">2a</ref> and consider 12 different starting positions i ∈ S = {4, . . . , 15} for the removal of j = 31 frames. The sequences come from 5 different subjects walking at different speeds and with different styles. Infilling of the missing frames involves training of a DFM {T c } c=1,...,C with a total of 29 sequences, all of them preprocessed in the same way as described above and none of them part of the test set. The estimate for missing frame j ∈ {1, . . . , 31} in run i is then given by the conditional expectation x(i) i+jx i+j 2 j as a measure of reconstruction quality. Although a direct comparison to the GPDM is illustrative, our model is not limited to simple actions such as walking. In fact, complex actions benefit more from our nonlinear and non-parametric approach. To fortify this claim, we train two additional DFMs on more challenging gestures: forward jump and golf swing. In particular, we use the same set of preprocessing steps as before and train DFMs on 7 (forward jump) and 8 (golf swing) training sequences, with 1 sequence in each category reserved for testing. Both test sequences are missing 31 frames and the RMSE is again averaged over 12 runs.</p><formula xml:id="formula_18">x(i) i+j = E x (i) i+j pa x (i) i+j = 1 C C c=1 A (c,i+j ) φ pa x (i) i+j</formula><p>While our experiments on walking sequences use a representation in joint angles to allow comparison with the results in <ref type="bibr" target="#b28">[29]</ref>, our experience has shown that DFMs perform better when trained on a representation in xyz-world coordinates. In particular, the ability to benefit from deep trees  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Results</head><p>Table <ref type="table" target="#tab_3">2a</ref> summarizes the quantitative results of the experiments on walking sequences and compares our findings with simple linear interpolation (LI) and the Gaussian Process Dynamical Model (GPDM). As expected, linear interpolation performs worst, with an average RMSE of 81.86. The original authors of the GPDM <ref type="bibr" target="#b28">[29]</ref> consider four different learning procedures and we restate the numbers for the two best performing approaches: B-GPDM, which adds a balancing term to MAP estimation, and 2-MAP, which is a two-stage process involving a Hybrid Monte Carlo version of EM and Scaled Conjugate Gradient. The former performs slightly better (49.31 vs. 52.52). We compare these results with a DFM consisting of 12 trees. Our method achieves a lower RMSE on 5 out of 8 test sequences.</p><p>Table <ref type="table" target="#tab_3">2b</ref> shows our results for the actions 'forward jump' and 'golf swing'. DFMs are suited for these more complex actions just as well. Both gestures take full advantage of our distributed approach and the minimum error is reached for a tree depth of 4. The Table also suggests that depth is more important than order: While we do see some improvement with increasing Markov order, the error decreases much more substantially with increasing tree depth.</p><p>Our assumption that long-range dependencies are only of minor importance thus seems to hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Predicting 3D from 2D</head><p>For our last demonstration we consider the task of predicting 3D motion from 2D inputs. In combination with the output of a pose estimation pipeline, we see potential applications like automatic character animation from videos.</p><p>In particular, we use the same walking sequences and preprocessing steps as we did in section 4.2 but train our model with pairs of 2D inputs and 3D outputs, where we obtain the 2D data from orthographic projections to the xzplane (top view) and the yz-plane (side view).</p><p>Our results are summarized in Table <ref type="table" target="#tab_4">3</ref>. When using 2D views from the top, our findings are in accordance with those in the previous section, i.e., the RMSE decreases considerably when using deeper trees and higher Markov orders, although the former seems to have a higher influence. For example, note the decrease in error of 84% between the best performing model, a tree of depth 4 and Markov order 4, and its counterpart of depth 1. For 2D views from the side, the test sequences cannot take advantage of higher orders, but the benefit from deep trees still leads to a substantial improvement of 59% compared to trees of depth 1.</p><p>Finally, we want to complement our numerical assessment of the model quality with a visual inspection of the reconstructed sequences: Figure <ref type="figure" target="#fig_6">3a</ref> shows a stickman visualization of the available 2D input data (projections to xzplane). Based on the predicted 3D motion trajectories from our model (Figure <ref type="figure" target="#fig_6">3b</ref>), we can then produce a realistic looking animation of a SCAPE model ([1], Figure <ref type="figure" target="#fig_6">3c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Computational aspects</head><p>One of the major benefits in using DFMs instead of latent variable models lies in their combination of being both flexible and tractable. The calculation of an exact log-likelihood for our action classification experiment takes only 0.04 sec. when using a dynamic forest with 12 trees of depth 4. We can thus classify a sequence in around 0.23 sec. Likewise, one synthesis step in our motion completion experiment takes 0.05 sec. All numbers refer to our Matlab implementation. 3 Table <ref type="table" target="#tab_1">1a</ref> shows how that compares to the other methods. The DFM is almost twice as fast as an HMM and magnitudes faster than the remaining methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have proposed the Dynamic Forest Model (DFM) as a new approach to human motion modelling, generalizing autoregressive trees and introducing new training and regularization techniques. Our presentation of DFMs in terms of latent variables has allowed a direct comparison to HMMs. Instead of relying on a latent space, we use a non-parametric and nonlinear Markov model that allows exact and efficient inference while at the same time being able to represent complex conditional mixture distributions. We proposed the use of bagging to avoid overfitting, which effectively complements other regularization techniques like ridge regression and isotropic covariance estimation.</p><p>The effectiveness of this approach has been demonstrated in three different application scenarios, namely action recognition, motion completion, and prediction of 3D trajectories from 2D inputs. The comparison with popular baselines and state-of-the-art latent variable models like HMMs and GPDMs has shown that DFMs perform excellent in those areas, while still being computationally efficient. Given the positive findings of this work, we believe that human motion models based on DFMs could be useful in many areas beyond the ones mentioned in this work, including tracking, character animation and pose correction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: (a) Discrete time Hidden Markov Models represent a probability distribution of a sequence of observations (x t ) t by a Markov model on a sequence of hidden variables z t and a conditional observation distribution p(x t |z t ). (b) Marginalization over the hidden variables yields a joint distribution p(x 1:T ) over the observed variables, effectively coupling all variables.(c) Latent space formulation of our proposed nonlinear Markov model for order K = 2. A decision tree implicitly selects a latent state and we can view the nonlinear Markov model as an order-K approximation to (b), in which filtering inference and computation of log-likelihoods of observed sequences is very efficient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Table 1 :</head><label>1</label><figDesc>Action classification results. (a) Accuracies and runtimes of DFMs and four baseline models. DFMs outperform all other evaluated methods. (b) Classification accuracies of DFMs as a function of depth, order, and number of trees. The result in bold is shown in more detail in (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>.</head><label></label><figDesc>The estimates x(i) = (x (i) i+j ) j =1,...,j of all 12 runs are subsequently combined to give an average RMS error per frame RMSE(</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) Input: 2D trajectory (top view). (b) Output: Stick model visualization of predicted 3D trajectory. (c) Output: SCAPE model visualization of predicted 3D trajectory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visualization of a 2D→3D experiment. In (a), we show every third frame of a 2D input sequence for which we want to reconstruct the red subsequence in 3D. In (b) and (c), we show two animations of the output from our model: A stick model (top right) and a SCAPE model that was fitted based on our reconstruction (bottom). Ground truth data is shown in blue/light skin, reconstructions in red/dark skin.</figDesc><graphic coords="7,50.11,132.04,494.98,70.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>1 :</head><label>1</label><figDesc>input: time-series data D 2: input: number of ensemble trees C &gt; 1 3: input: number of split tests M ≥ 1 4: input: split proposal distribution ps 5: output: dynamic forest {Tc} c=1,...,C</figDesc><table><row><cell cols="2">6: procedure TRAINDFM(D, C, M, ps)</cell></row><row><cell>7:</cell><cell>for c = 1, . . . , C do</cell></row><row><cell>8:</cell><cell>Bootstrap resample the training set</cell></row><row><cell>9:</cell><cell>Tc ← a growable root node ρ</cell></row><row><cell>10:</cell><cell>while there is a growable leaf in Tc do</cell></row><row><cell>11:</cell><cell>Z  *  ← -∞</cell></row><row><cell>12:</cell><cell>for m = 1, . . . , M do</cell></row><row><cell>13:</cell><cell>Sample split s ∼ ps</cell></row><row><cell>14:</cell><cell>Partition data at w.r.t. s</cell></row><row><cell>15:</cell><cell>Zs ← Compute score for s</cell></row><row><cell>16:</cell><cell>if Zs &gt; Z  *  then</cell></row><row><cell>17:</cell><cell>(s  *  , Z  *  ) ← (s, Zs)</cell></row><row><cell>18:</cell><cell>end if</cell></row><row><cell>19:</cell><cell>end for</cell></row><row><cell>20:</cell><cell>Split leaf using split s  *</cell></row><row><cell>21:</cell><cell>end while</cell></row><row><cell>22:</cell><cell>for leaf in tree Tc do</cell></row><row><cell>23:</cell><cell>Build least squares regressor at</cell></row><row><cell>24:</cell><cell>end for</cell></row><row><cell>25:</cell><cell>end for</cell></row><row><cell>26:</cell><cell>return Ensemble {Tc} c=1,...,C</cell></row><row><cell cols="2">27: end procedure</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Motion completion results. (a) Walking: Joint angle RMSE of our DFM approach and two baseline models. LI = Linear Interpolation; GPDM = Gaussian Process Dynamical Model. (b) Jump forward and golf swing: World coordinate RMSE of our DFM approach as a function of tree depth and Markov order. Note the decrease of the error with increasing tree depth and/or Markov order.</figDesc><table><row><cell>Seq. no.</cell><cell>LI</cell><cell cols="2">GPDM</cell><cell>DFM</cell><cell>Gesture</cell><cell>Depth</cell><cell></cell><cell cols="2">Order</cell><cell></cell></row><row><cell></cell><cell></cell><cell>B-GPDM</cell><cell>2-MAP</cell><cell>(ours)</cell><cell></cell><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row><row><cell>07-01</cell><cell>88.72</cell><cell>65.38</cell><cell>68.69</cell><cell>28.94</cell><cell></cell><cell>1</cell><cell>10.93</cell><cell>7.44</cell><cell>7.06</cell><cell>6.89</cell></row><row><cell>07-02</cell><cell>90.13</cell><cell>64.47</cell><cell>64.43</cell><cell>33.87</cell><cell>Golf</cell><cell>2</cell><cell>9.15</cell><cell>9.62</cell><cell>6.19</cell><cell>5.96</cell></row><row><cell>08-01</cell><cell>113.71</cell><cell>70.05</cell><cell>72.61</cell><cell>30.47</cell><cell>swing</cell><cell>3</cell><cell>4.82</cell><cell>5.16</cell><cell>5.79</cell><cell>4.35</cell></row><row><cell>08-02</cell><cell>112.26</cell><cell>72.11</cell><cell>90.80</cell><cell>28.59</cell><cell></cell><cell>4</cell><cell>4.58</cell><cell>4.17</cell><cell>4.75</cell><cell>4.31</cell></row><row><cell>12-02 12-03 16-21 35-03</cell><cell>62.02 58.87 68.10 61.07</cell><cell>37.06 40.40 32.87 12.15</cell><cell>26.60 23.16 53.13 20.74</cell><cell>35.83 29.79 24.00 16.45</cell><cell>Forward jump</cell><cell>1 2 3 4</cell><cell>17.28 39.59 12.94 11.08</cell><cell>17.07 12.01 11.47 11.27</cell><cell>18.45 11.70 10.53 11.41</cell><cell>16.38 10.61 10.44 9.19</cell></row><row><cell>Mean</cell><cell>81.86</cell><cell>49.31</cell><cell>52.52</cell><cell>28.49</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">(a) Joint angle representation: RMSE for 8</cell><cell cols="6">(b) World coordinate representation: RMSE for</cell></row><row><cell cols="5">walking sequences and different models.</cell><cell cols="6">two more complex gestures. Results are shown</cell></row><row><cell cols="5">The best results are highlighted in bold.</cell><cell cols="6">for different tree depths and Markov orders.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>3D from 2D results. RMSE of predicted 3D trajectory given a 2D input. Deeper trees perform consistently better, while the effect of the Markov order varies.</figDesc><table><row><cell cols="2">2D Input Depth</cell><cell></cell><cell cols="2">Markov order</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row><row><cell></cell><cell>1</cell><cell cols="3">6.08 6.18 8.17 7.72</cell></row><row><cell>Top</cell><cell>2 3</cell><cell cols="3">3.55 3.53 3.44 3.71 2.19 1.92 1.71 1.55</cell></row><row><cell></cell><cell>4</cell><cell cols="3">1.87 1.37 1.24</cell><cell>1.23</cell></row><row><cell></cell><cell>1</cell><cell cols="3">7.31 8.03 8.96 9.37</cell></row><row><cell>Side</cell><cell>2 3</cell><cell cols="3">4.11 4.23 4.62 5.30 3.13 3.23 3.35 3.76</cell></row><row><cell></cell><cell>4</cell><cell>2.97</cell><cell cols="2">3.19 3.39 3.65</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Dataset obtained from mocap.cs.cmu.edu.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The first author was supported by <rs type="funder">Microsoft Research</rs> through its <rs type="grantName">PhD Scholarship Programme</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ajmRkPW">
					<orgName type="grant-name">PhD Scholarship Programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">SCAPE: Shape completion and animation of people</title>
		<author>
			<persName><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rodgers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>SIGGRAPH</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Barber</surname></persName>
		</author>
		<title level="m">Bayesian Reasoning and Machine Learning</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coupled hidden Markov models for complex action recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning and recognizing human dynamic in video sequences</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Classification and Regression Trees</title>
		<author>
			<persName><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Olshen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Stone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<pubPlace>Wadsworth</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An overview of existing methods and recent advances in sequential Monte Carlo. Proceedings of the IEEE</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Godsill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Inference in Hidden Markov Models</title>
		<author>
			<persName><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Moulines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rydéen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decision forests: A unified framework for classification, regression, density estimation, manifold learning and semi-supervised learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends. Comp. Graphics and Vision</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Nonlinear Time Series: Nonparametric and Parametric Methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Instructing people for training gestural interactive systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fothergill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Mentis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CHI</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonparametric Bayesian learning of switching linear dynamical systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sudderth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hidden Markov Models and Dynamical Systems</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Novel approach to nonlinear/non-Gaussian Bayesian state estimation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Salmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proc. F. Radar and Signal Proc</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ridge regression: Biased estimation for nonorthogonal problems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hoerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kennard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gaussian filters for nonlinear filtering problems</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Automatic Control</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A new extension of the Kalman filter to nonlinear systems</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Julier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Uhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AeroSense: 11th Int. Symp. Aerospace/Defense Sensing, Simulation and Controls</title>
		<meeting>AeroSense: 11th Int. Symp. Aerospace/Defense Sensing, Simulation and Controls</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Autoregressive tree models for time-series analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Action points: A representation for low-latency online human action recognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<idno>MSR-TR-2012-68. 5</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning switching linear models of human motion</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Maccormick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Toward accurate dynamic time warping in linear time and space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Data Anal</title>
		<imprint>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A shrinkage approach to largescale covariance matrix estimation and implications for functional genomics</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Strimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Molec. Biol</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">HumanEva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling human motion using binary latent variables</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">3D people tracking with Gaussian process dynamical models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Modeling human locomotion with topologically constrained latent variable models. 2nd Workshop on Human Motion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Gaussian process dynamical models for human motion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<date type="published" when="2007">2008. 1, 4, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Optimizing walking controllers for uncertain inputs and environments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimizing locomotion controllers using biologically-based actuators and objectives</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Hamner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Delp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
