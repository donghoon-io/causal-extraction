<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Optimizing Causal Interventions in Hybrid Bayesian Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Maarten</forename><forename type="middle">C</forename><surname>Vonk</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Anna</forename><forename type="middle">V</forename><surname>Kononova</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Diederick</forename><surname>Vermetten</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jacob</forename><surname>De Nobel</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Sebastiaan</forename><surname>Brand</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ninoslav</forename><surname>Malekovic</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Bäck</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alfons</forename><surname>Laarman</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Centre for Strategic Studies</orgName>
								<orgName type="institution">Leiden University Diederick Vermetten Leiden University Jacob de Nobel Leiden University</orgName>
								<address>
									<addrLine>Sebastiaan Brand Leiden University Ninoslav Malekovic The Hague</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Thomas Bäck Leiden University Alfons Laarman Leiden University</orgName>
								<orgName type="institution" key="instit2">Leiden University</orgName>
								<orgName type="institution" key="instit3">Leiden Institute of Advanced Computer Science Leiden University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Optimizing Causal Interventions in Hybrid Bayesian Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.21203/rs.3.rs-4634770/v1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian Networks, Knowledge Compilation, Causal Inference, Optimal Causal Interventions, Heuristic Optimization, Do-operator Bayesian Networks</term>
					<term>Knowledge Compilation</term>
					<term>Causal Inference</term>
					<term>Optimal Causal Interventions</term>
					<term>Heuristic Optimization</term>
					<term>Do-operator</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Causality is increasingly integrated into decision-making processes. Often, the goal is to optimize over causal interventions to achieve speciőc policy objectives. However, research into causal optimization has bifurcated into either the online optimization of interventions in causal models or the offline optimization of decision rules in causal inŕuence diagrams. This paper introduces an approximate method for offline optimizing interventions in arbitrary hybrid Bayesian networks using observational data. The optimization problem is approached by compiling discretized Bayesian networks as binary decision diagrams, whereafter running interventional queries is very efficient. This efficiency is exploited by running heuristic optimization algorithms to optimize over the interventional queries. By running experiments on a variety of large hybrid Bayesian networks, we demonstrate the practical utility of our method and discuss policy relevance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the realm of decision-making challenges, policymakers draw increasingly on methods from causality to enhance policy analysis <ref type="bibr" target="#b20">[21]</ref>. The underlying rationale is that by comprehending the causal dynamics inherent in a policy problem, one can craft more efficacious policy interventions. Consequently, optimizing causal interventions is crucial for informed decision-making in uncertain environments.</p><p>Computing the probabilistic effects of interventions, that involve forcing assignments of variables, relies on the do-calculus <ref type="bibr" target="#b32">[33]</ref> to convert the resulting interventional distributions to observational ones. Often, the observational distributions can be computed using Bayesian network inference techniques <ref type="bibr" target="#b19">[20]</ref>. Given the limitations of these techniques in the continuous setting <ref type="bibr" target="#b35">[36]</ref>, there has been a focused research effort on discretizing Bayesian networks (BNs) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b28">29</ref> Fig. <ref type="figure">1:</ref> The methodology used in this paper. After discretizing and estimating the conditional probability tables (CPTs) of the Bayesian network (BN), the network is encoded into conjunctive normal form (CNF). This encoding allows the compilation as a binary decision diagram (BDD) once, before the optimization starts. In the optimization process, heuristic optimization algorithms make use of the cheap weighted model counting operation on BDDs to compute the otherwise prohibitively costly interventional distributions. which allows for the application of established discrete Bayesian network inference methods. However, the discrete Bayesian network inference techniques needed to compute the effect of interventions are computationally expensive, making optimization over multiple possible interventions even costlier. To tackle these computational challenges, we approach this problem with binary decision diagrams (BDDs). Inference with BDDs first requires performing a computationally expensive compilation step, after which computing inference queries can be done in time linear in the size of the BDD <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b43">44]</ref>. While compiling a BN into a BDD is a heuristic compression method without theoretical guarantees of reducing inference complexity, it often proves much faster in practice <ref type="bibr" target="#b43">[44]</ref> and is particularly advantageous when optimizing over multiple interventional queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Approach and Contributions</head><p>In this paper, we propose a methodology (see Figure <ref type="figure">1</ref>) to solve the offline Causal Global Optimization problem <ref type="bibr" target="#b1">[2]</ref> on hybrid Bayesian networks by encoding discretized versions of the BNs as binary decision diagrams. We subsequently showcase the performance of the heuristic optimization algorithms that use these efficient encodings to optimize over interventional queries. A variety of synthetic and real-world causal Bayesian networks with different characteristics have been subjected to the proposed methodology to ensure generalizability of the results and application diversity. Our contribution is three-fold:</p><p>• We extend the implementation of the do-operator and interventional distributions to decision diagrams encoded from Bayesian networks without unobserved confounders.</p><p>• We compare and evaluate the performance of various optimization algorithms for optimizing causal interventions, thereby establishing their potential in causal contexts. • Through practical demonstrations, we highlight the real-world value of our proposed methodology for decision-makers.</p><p>This paper is structured as follows. First, we discuss related research in Section 1.2. Then, the problem statement is formulated in Section 2, whereafter, our methodology is introduced in Section 3. The methodology is applied in Section 4. Finally, Section 5 reflects on the findings and identifies future research avenues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Related Work</head><p>Research on causal decision-making is increasingly gaining traction. Earlier approaches have focused on online learning, with a particular focus on causal multiarmed-bandit problems. In these problems, an agent balances the explorationexploitation trade-off through interventions in a causal system <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>Extending bandits to the continuous domain and letting an agent carry out exploratory interventions prior to choosing the optimal intervention leads to the formulation of the online Causal Global Optimization problem <ref type="bibr" target="#b1">[2]</ref>, which has been further extended to the dynamic <ref type="bibr" target="#b0">[1]</ref>, constrained <ref type="bibr" target="#b2">[3]</ref>, stochastic <ref type="bibr" target="#b18">[19]</ref>, contextual <ref type="bibr" target="#b3">[4]</ref> and adversarial settings <ref type="bibr" target="#b39">[40]</ref>.</p><p>While the aforementioned approaches all pertain to online scenarios, where agents progressively acquire knowledge through actions, performing interventions in real scenarios can be impractical or unethical. Therefore, the realm of causal decision-making also receives attention in the offline context. In this setting, (causal) Bayesian networks can be extended to (causal) influence diagrams, distinguishing clearly among nodes representing chance, decision, and utility <ref type="bibr" target="#b14">[15]</ref>. Decision nodes consist of decision rules, which are sets of guidelines dictating actions in response to various assignments in parent nodes <ref type="bibr" target="#b19">[20]</ref>. Effective methods for maximizing utility in influence diagrams by optimizing decision rules have been suggested <ref type="bibr" target="#b19">[20]</ref>. These methods optimize the decision rules with respect to the (causal) structure of the diagram but do not consider causal interventions containing the do-operator.</p><p>Similarly, outside the online realm, there has been much research on optimizing individualized treatment <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b4">5]</ref>. These works go one step further in the causal hierarchy <ref type="bibr" target="#b6">[7]</ref> by optimizing the counterfactual mean of the outcome with respect to the modified interventional distribution rather than the interventional mean. Nevertheless, their emphasis on one-dimensional treatments frees them from the computational complexities of the multi-dimensional interventions discussed in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Statement</head><p>Throughout this paper, we denote random variables and their assignments using upper and lower case, respectively. Vectors are indicated in bold. The set of random variables is denoted by X = {X 1 , . . . , X n }, where random variable X i takes values x i in corresponding state space Ω Xi . A graph is denoted by G = (V , E) with nodes V = {V 1 , . . . , V n } and edges E ⊆ V × V . The graph is called directed when every edge in the graph has a direction, and it is called cyclic when there exists a directed path from a node to itself. When the graph is directed and not cyclic it is called a directed acyclic graph.</p><p>A Bayesian network (BN) represents random variables by the nodes of a directed acyclic graph. The probabilistic dependencies of the random variables are captured by the graph's edges. Let P (x 1 , . . . , x n ) be the joint probability distribution of random variables X i associated to nodes V i ∈ V in the corresponding directed acyclic graph G = (V , E). The joint probability can be factorized according to the structure of the Bayesian network <ref type="bibr" target="#b32">[33]</ref>:</p><formula xml:id="formula_0">P (x 1 , . . . x n ) = n ∏ i=1 P (x i | pa i )</formula><p>where pa i represents the assignment of the random variables that correspond to parents of V i . When P (x i | pa i ) is discrete, it can be expressed through a conditional probability table (CPT) <ref type="bibr" target="#b43">[44]</ref>.</p><p>In the case of causal Bayesian networks, the edges in BNs convey a causal meaning, and the do-operator can be used to model causal interventions. The behavior of the do-operator within a causal BN leads to a truncated factorization of the distribution <ref type="bibr" target="#b44">[45]</ref>. Suppose X K , X S ⊂ X and X K ⋂ X S = ∅. Then:</p><formula xml:id="formula_1">P (x S | do(X K = x K )) = ∑ xi|i∉K ⋃ S ∏ i∉K P (x i | pa i ).<label>(1)</label></formula><p>More efficiently, the do-operator can be implemented by means of an adjustment set <ref type="bibr" target="#b40">[41]</ref>, that is, a set X J ⊂ X for which:</p><formula xml:id="formula_2">P (x S | do(X K = x K )) = ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ P (x S | x K ) if X J = ∅, ∑ x J P (x S | x K , x J )P (x J ) otherwise.</formula><p>(</p><formula xml:id="formula_3">)<label>2</label></formula><p>We focus on the Causal Global Optimization (CGO) problem <ref type="bibr" target="#b1">[2]</ref> defined in Equation 3. The variables in the Bayesian network X can be further dissected into intervenable variables Z, context variables C, and outcome variable Y<ref type="foot" target="#foot_0">foot_0</ref> . The goal is then to optimize the interventions among intervenable variables that minimize the expected value of the outcome variable in the associated interventional distribution:</p><formula xml:id="formula_4">X * K , x * K = arg min X K ⊂Z,x K ∈Ω X K E∥Y | do(X K = x K ))∥.<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>The highlighted methodology components in Figure <ref type="figure">1</ref>, as discussed in this section, include the discretization of the hybrid Bayesian network, inference using the BDD encoding of this discretization, and the specifics of the optimization algorithms. More detailed information about inferring the CPTs, CNF formulas, and the BDD encodings can be found in <ref type="bibr" target="#b43">[44]</ref>. <ref type="foot" target="#foot_1">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discretization</head><p>The discretization process involves dividing the continuous state space of random variable X i , denoted as Ω Xi into distinct bins B j ∶ j = 1, . . . , m so that they form a complete partition of Ω Xi . Each bin B j is associated with the sample mean of the data points contained within that bin, 1 |Bj | ∑ xi∈Bj x i , where |B j | indicates the number of data points x i contained within bin B j .</p><p>Two types of discretization have been considered. The equal width (EW) discretization technique involves dividing the state spaces Ω Xi into bins of consistent width. On the other hand, the equal frequency (EF) discretization method separates the samples into quantiles. Because the EF showed better accuracy performance in the context of BN inference <ref type="bibr" target="#b43">[44]</ref>, discretizations in this paper involve this method. We infer the discretized conditional probability values with a Bayesian method with empirical Bayes priors as described in <ref type="bibr" target="#b43">[44]</ref> to prevent positivity violations <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">BDD Encoding and Inference</head><p>A binary decision diagram (BDD) <ref type="bibr" target="#b11">[12]</ref> is a rooted directed acyclic graph which typically represents a Boolean function f ∶ {0, 1} n → {0, 1}, although for our purposes it is used to represent a pseudo-Boolean function f ∶ {0, 1} n → R (i.e. a discrete probability distribution). The two relevant properties of BDDs are their ability to compactly represent many functions by identifying redundancies, and their support for polynomial-time operations (e.g., computing marginal probabilities) based on BDD size.</p><p>A Bayesian network is encoded in a BDD by first encoding each CPT entry in a small Boolean expression. From these, a BDD can be built using primitive BDD operations for logical and (∧), or (∨), not (¬), etc. Consider, for example, the BN given in Figure <ref type="figure">2a-2b</ref>. Boolean variables {a 0 , b 0 , b 1 } are introduced to encode the values of A and B, while Boolean variables ω i are used to refer to specific probabilities. For example, the CPT entry</p><formula xml:id="formula_5">P (B = 2 | A = 0) = 0.2 is encoded as (¬a 0 ∧ ¬b 1 ∧ b 0 ) ⇒ ω 2</formula><p>, where ¬a 0 corresponds to A = 0 and ¬b 1 ∧ b 0 corresponds to B = 2 dec = 10 bin . A mapping val(⋅) from ω i 's to probabilities (val(ω 2 ) = 0.2 for this CPT entry) is stored separately.</p><p>Given a BDD that encodes a BN, computing marginal or conditional probabilities reduces to so-called weighted model counting <ref type="bibr" target="#b12">[13]</ref>, in which different paths In the BDD solid (dashed) edges correspond to positive (negative) assignments to variables.</p><p>through the decision diagram are traversed and probabilities are multiplied and added along the way. During this traversal, every node in the BDD only needs to be visited (at most) once, and thus, weighted model counting can be done in time linear in the size of the BDD. In this paper, the do-operator has been implemented through the adjustment formula (Equation <ref type="formula" target="#formula_3">2</ref>) that utilizes the efficiently computed marginal and conditional distribution. A more detailed description of the encoding and the weighted model counting procedure can be found in <ref type="bibr" target="#b43">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Optimization</head><p>Given the above discretization and encoding mechanisms, interventional queries can be computed and the CGO problem can be addressed heuristically. To illustrate this point, we select a variety of optimization algorithms from the blackbox optimization literature <ref type="bibr" target="#b5">[6]</ref>, implemented in the Nevergrad <ref type="bibr" target="#b34">[35]</ref> platform. Our set of algorithms includes: (a) RandomSearch as a baseline, (b) two evolutionary algorithms (Differential Evolution <ref type="bibr" target="#b38">[39]</ref> (DE) and (1+1) Evolutionary Strategy <ref type="bibr" target="#b9">[10]</ref> (OnePlusOne)), (c) local search methods (BFGS <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b37">38]</ref> and Powell's method <ref type="bibr" target="#b33">[34]</ref>), (d) the algorithm wizard 'NGOpt39' <ref type="bibr" target="#b27">[28]</ref>, which automatically selects an optimizer based on problem characteristics such as the number of variables. To track the optimization performance, we use IOHexperimenter <ref type="bibr" target="#b29">[30]</ref>, a benchmarking module from the IOHprofiler environment <ref type="bibr" target="#b41">[42]</ref>, which allows us to fully track the optimization process.</p><p>For each optimization algorithm and each network, we perform 10 independent runs of 2000 evaluations of the objective function each, where an evaluation consists of calculating the expected value of the outcome variable given an intervention set (see Equation <ref type="formula" target="#formula_3">2</ref>), which is to be minimized in all networks considered in this paper (see Equation <ref type="formula" target="#formula_4">3</ref>). To represent the problem inside the optimization algorithms, we note that each node we can intervene on takes a value between 0 and the number of bins if it is intervened on; for convenience, we then use a negative value if no intervention is performed on this node. Within the Nevergrad library, such a representation gets translated to a real-valued one to allow continuous optimization algorithms to tackle this problem as well <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>This section details the experiments presented in the paper, considers their policy implications where relevant, and evaluates the performance of optimization algorithms. The discretizations were selected to maximize bin count without overfitting the sample data <ref type="bibr" target="#b43">[44]</ref> or exceeding 64GB RAM during BDD compilation. Figure <ref type="figure" target="#fig_2">4</ref> presents the optimization results and Table <ref type="table" target="#tab_1">1</ref> summarizes the Bayesian network features and discretizations. Toy This dataset <ref type="bibr" target="#b1">[2]</ref> contains a three-node X → Z → Y Bayesian network discretized into 100 bins. While not interesting from an optimization perspective, it benchmarks inference quality post-discretization, focusing on possibly-optimal minimal intervention set <ref type="bibr" target="#b23">[24]</ref> {Z}. Most optimization algorithms quickly converge to the optimal solution in the discretization, Y = -1.866, which is near the known exact solution Y = -1.856.</p><p>Mixed Confounding (MC) This synthetic dataset, depicted in Figure <ref type="figure" target="#fig_1">3a</ref>, is called mixed confounding as it contains many continuous as well as discrete variables that causally influence more than one variable in the graph, as further specified in Csuite benchmarking causal datasets <ref type="bibr" target="#b16">[17]</ref>. After discretizing continuous variables into 30 bins, we conducted two experiments on outcome variables X 10 and X 11 , both with the minimum intervention set <ref type="bibr" target="#b23">[24]</ref> {X 2 , X 3 , X 4 , X 5 , X 6 , X 7 , X 8 }. Figures <ref type="figure" target="#fig_2">4a</ref> and<ref type="figure" target="#fig_2">4b</ref> illustrate that both DE and NGOpt19 outperform other optimization algorithms.</p><p>Climate The dataset comprises 294 samples, tapping into the interplay between climate and conflict as depicted in Figure <ref type="figure" target="#fig_1">3b</ref>. It includes conflict, climate, environmental, and demographic data at the municipal level in southeastern Iraq. An understanding of the variables and the details of the empirically verified causal structure can be found in <ref type="bibr" target="#b25">[26]</ref>. The outcome variable is the number of conflict fatalities. The interventions in consideration are precipitation, rice production, and population density, although direct intervention may be challenging. Indirect policy measures such as water management and development projects can be targeted to increase water availability and balance demographic distribution respectively.</p><p>Figure <ref type="figure" target="#fig_2">4e</ref> shows that DE and NGOpt19 are the best-performing algorithms. The tables in Figure <ref type="figure" target="#fig_2">4f</ref> indicate best-found objective values and intervention values compared to the sample means in the dataset. With interventions tailored to increasing rice supply/production, equitable population management leading to a more balanced demographic distribution, and increased precipitation or related water management interventions, the expected value of conflict fatalities can be reduced by 85.9% with respect to the mean.</p><p>Mehra This conditional linear Gaussian BN from bnlearn <ref type="bibr" target="#b36">[37]</ref> explores the correlation between air pollution and health outcomes <ref type="bibr" target="#b42">[43]</ref>. Due to its considerable size, the compilation of BDD is restricted to those segments of the network pertinent to the optimization task. <ref type="foot" target="#foot_3">4</ref> The results can be seen in Figure <ref type="figure" target="#fig_2">4c</ref>, where the identified best-performing algorithm is Randomsearch closely followed by DE and NGOpt39 (same applies to the dataset below).</p><p>Arth This enormous Gaussian BN from bnlearn, originating from the GeneNet package, features plant expression data <ref type="bibr" target="#b31">[32]</ref>. Like the Mehra dataset, the size necessitates limiting the BDD compilation to only those parts of the network that are essential for optimization. The results are available in Figure <ref type="figure" target="#fig_2">4d</ref>. Performace of Optimization Algorithms We observe that the more local methods (BFGS, Powell, OnePlusOne) perform rather poorly. Only DE and NGOpt are able to outperform the Randomsearch baseline, suggesting that the underlying optimization problem might be multimodal. This might also be connected to the choice of internal problem representation selected from Nevergrad, as working directly on the discrete variables might be more suitable for these local search methods. While this points to a need for further examination of the specifics of the optimization procedure, the results nevertheless illustrate that in general these problems contain sufficient structure that heuristic black-box optimizers can improve over the performance of Randomsearch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper proposes a methodology to solve the offline causal global optimization problem for large hybrid causal Bayesian networks using only observational data. The methodology consists of discretizing the hybrid Bayesian network and encoding to binary decision diagrams. Once the BDD is compiled, query costs become negligible, allowing the deployment of heuristic optimization algorithms that optimize for the best intervention.</p><p>Our contribution is three-fold. First, we have extended the use of interventional distributions to decision diagrams encoded from Bayesian networks in cases without unobserved confounders. Second, the encoding enables cheap evaluations of interventional queries that allow us to compare and evaluate various heuristic optimization algorithms aimed at optimizing causal interventions. Finally, we have demonstrated the practical utility of our methodology for decisionmakers through its application to an empirically based causal Bayesian network.</p><p>Since collecting interventional data can be costly, impractical, or unethical, our research is limited to observational data only. Using strictly observational data brings as a limitation that optimal interventions may lie beyond the current observational domain of the variables.</p><p>We propose the following future research avenues: although some results suggest that discretization does not necessarily lead to a loss of information, future research could further specify for which data structure or distributions this is the case or even include the loss of information due to discretization in the optimization loop. The latter would lead to a multi-objective optimization problem. Alternatively, the proposed methodology could be benchmarked against methodologies incorporating different known approximate inference methods, such as sampling methods or variational inference <ref type="bibr" target="#b19">[20]</ref>.</p><p>As demonstrated, the encodings of Bayesian networks to decision diagrams bring computational advantages that pave the way for the integration of optimization within the field of causality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>5 AFig. 2 :</head><label>52</label><figDesc>Fig.2: An example BN (a,b) and the corresponding BDD (c). The probabilities corresponding to the Boolean variables ω i are stored separately (d). In the BDD solid (dashed) edges correspond to positive (negative) assignments to variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Bayesian network structures corresponding to the mixed confounding and climate experiments. The hybrid nodes are distinguished by interior line patterns: dashed lines oriented from the top-left to bottom-right denote nodes with continuous values, whereas those from the top-right to bottom-left signify nodes with discrete values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(Fig. 4 :</head><label>4</label><figDesc>Fig. 4: The best-found expected value of the interventional distributions of 6 optimization algorithms over 2000 evaluations, averaged over 10 runs for the 4 considered datasets (a-e). For the climate dataset, the table in (f) corresponds to found objective y * and intervention values x * compared to sample mean values ȳ, x.</figDesc><graphic coords="10,134.77,458.56,171.18,117.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>],</figDesc><table><row><cell>Estimating</cell><cell>Conversion</cell><cell>Compiling</cell></row><row><cell>CPT's</cell><cell>to CNF</cell><cell>BDD</cell></row><row><cell></cell><cell>Optimization loop</cell><cell></cell></row><row><cell>Discretization of BN</cell><cell>Optimization of inter-ventions</cell><cell>Weighted Model Counting Inference</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Characteristics of the used Bayesian networks.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Origin Samples Network</cell><cell cols="3">Max Discretization Intervention</cell></row><row><cell></cell><cell></cell><cell cols="3">nodes edges parents 3</cell><cell>bins</cell><cell>variables</cell></row><row><cell>Toy [2]</cell><cell>synthetic 1000</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>100</cell><cell>1</cell></row><row><cell>MC [17]</cell><cell>synthetic 4000</cell><cell>12</cell><cell>15</cell><cell>6</cell><cell>30</cell><cell>7</cell></row><row><cell cols="2">Climate [26] real-world 293</cell><cell>8</cell><cell>11</cell><cell>3</cell><cell>20</cell><cell>3</cell></row><row><cell>Mehra [43]</cell><cell>real-world 5000</cell><cell>24</cell><cell>71</cell><cell>9</cell><cell>4</cell><cell>8</cell></row><row><cell>Arth [32]</cell><cell>real-world 5000</cell><cell cols="2">107 150</cell><cell>17</cell><cell>6</cell><cell>5</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>In this case, we consider a one-dimensional outcome variable, although the proposed methodology is generalizable to multiple outcome variables.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The methodology is available on https://github.com/sebastiaanbrand/bn-dd.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The maximum number of parents is a proxy for computational complexity.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Because of the nature of the do-operator and the adjustment formula of Equation 2, nodes that are not marginalized or conditioned upon in the optimization step can be eliminated from the compilation.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimizing Causal Interventions in Hybrid Bayesian Networks 11</title>
		<author>
			<persName><forename type="first">V</forename><surname>Aglietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dhir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Damoulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10549" to="10560" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Dynamic causal bayesian optimization</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Causal bayesian optimization</title>
		<author>
			<persName><forename type="first">V</forename><surname>Aglietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paleyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>González</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3155" to="3164" />
		</imprint>
		<respStmt>
			<orgName>AISTATS</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Aglietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Malek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ktena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.20011</idno>
		<title level="m">Constrained causal bayesian optimization</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Arsenyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Grosnit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bou-Ammar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2301.12412</idno>
		<title level="m">Contextual causal bayesian optimisation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Policy learning with observational data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Athey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="133" to="161" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evolutionary algorithms for parameter optimizationÐthirty years later</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="81" to="122" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On Pearl&apos;s hierarchy and the foundations of causal inference</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ibeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Icard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Probabilistic and Causal Inference</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bandits with unobserved confounders: A causal approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Forney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A comparison of methods for discretizing continuous variables in bayesian networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Beuzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Splinter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental modelling &amp; software</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="61" to="66" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evolution strategies-a comprehensive introduction</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Schwefel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3" to="52" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Convergence of a Class of Double-rank Minimization Algorithms: 2. The New Algorithm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Broyden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMA Journal of Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Graph-based algorithms for Boolean function manipulation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bryant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="677" to="691" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On probabilistic inference by weighted model counting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chavira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darwiche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artiőcial Intelligence</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">6-7</biblScope>
			<biblScope unit="page" from="772" to="799" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weighted positive binary decision diagrams for exact probabilistic inference</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lucas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. Journal of Approximate Reasoning</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="411" to="432" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Agent incentives: A causal perspective</title>
		<author>
			<persName><forename type="first">T</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Langlois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="11487" to="11495" />
			<date type="published" when="2021-05">May 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A new approach to variable metric algorithms</title>
		<author>
			<persName><forename type="first">R</forename><surname>Fletcher</surname></persName>
		</author>
		<idno type="DOI">10.1093/comjnl/13.3.317</idno>
		<ptr target="https://doi.org/10.1093/comjnl/13.3.317" />
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="322" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Geffner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.02195</idno>
		<title level="m">Deep end-to-end causal inference</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A family of variable-metric methods derived by variational means</title>
		<author>
			<persName><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">109</biblScope>
			<biblScope unit="page" from="23" to="26" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Gultchin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aglietti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2306.06409</idno>
		<title level="m">Functional causal bayesian optimization</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Probabilistic graphical models: principles and techniques</title>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Kreif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Diazordaz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1903.00402</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1903.00402" />
		<title level="m">Machine learning in policy evaluation: new tools for causal inference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Causal bandits: Learning good interventions via causal inference</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lattimore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Structural causal bandits: Where to intervene?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Structural causal bandits with non-manipulable variables</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4164" to="4172" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Targeted learning on variable importance measure for heterogeneous treatment effect</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Laan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.13324</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Angling for causality behind security: Natural causes of armed conŕict in iraq</title>
		<author>
			<persName><forename type="first">N</forename><surname>Malekovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vonk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Birkman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sweijs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kononova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<idno type="DOI">10.20944/preprints202402.0556.v1</idno>
		<ptr target="https://doi.org/10.20944/preprints202402.0556.v1" />
		<imprint>
			<date type="published" when="2024-02">February 2024</date>
			<publisher>Preprints</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">tmle3mopttx: Targeted learning and variable importance with optimal individualized categorical treatment</title>
		<author>
			<persName><forename type="first">I</forename><surname>Malenica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Laan</surname></persName>
		</author>
		<ptr target="https://github.com/tlverse/tmle3mopttx" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>r package version 1.0.0</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Black-box optimization revisited: Improving algorithm selection wizards through massive benchmarking</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Inference in hybrid bayesian networks using dynamic discretization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tailor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Marquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="219" to="233" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">IOHexperimenter: Benchmarking platform for iterative optimization heuristics</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Nobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vermetten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<idno>CoRR abs/2111.04077</idno>
		<ptr target="https://arxiv.org/abs/2111.04077" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Comparative analysis of discretization methods in bayesian networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Nojavan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Stow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environmental Modelling &amp; Software</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="64" to="71" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Opgen-Rhein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Strimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC systems biology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Causality. Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An efficient method for őnding the minimum of a function of several variables without calculating derivatives</title>
		<author>
			<persName><forename type="first">M</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Nevergrad -A gradient-free optimization platform</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rapin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Teytaud</surname></persName>
		</author>
		<ptr target="https://GitHub.com/FacebookResearch/Nevergrad" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A review of inference algorithms for hybrid bayesian networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Salmerón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rumí</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Langseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Madsen</surname></persName>
		</author>
		<idno type="DOI">10.1613/jair.1.11228</idno>
		<ptr target="https://doi.org/10.1613/jair.1.11228" />
	</analytic>
	<monogr>
		<title level="j">Journal of Artiőcial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="799" to="828" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning bayesian networks with the bnlearn R package</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scutari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Conditioning of quasi-newton methods for function minimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Shanno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">111</biblScope>
			<biblScope unit="page" from="647" to="656" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Differential evolution -a simple and efficient heuristic for global optimization over continuous spaces</title>
		<author>
			<persName><forename type="first">R</forename><surname>Storn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Optimization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Sussex</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sessa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makarova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Adversarial causal bayesian optimization</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Separators and adjustment sets in causal graphs: Complete criteria and an algorithmic framework</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Der Zander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liśkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Textor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artiőcial Intelligence</title>
		<imprint>
			<biblScope unit="volume">270</biblScope>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Vermetten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>De Nobel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Doerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<ptr target="https://iohprofiler.github.io/" />
		<title level="m">IOHproőler: Iterative Optimization Heuristics Proőler</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>wiki available at</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modeling air pollution, climate, and health data using bayesian networks: A case study of the english regions</title>
		<author>
			<persName><forename type="first">C</forename><surname>Vitolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scutari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ghalaieny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Earth and Space Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="76" to="88" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Efficient inference in Bayesian networks with continuous variables a discretization and knowledge compilation approach</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Vonk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Malekovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Laarman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Kononova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page">4620451</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Disentangling causality: assumptions in causal discovery and inference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Vonk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Malekovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bäck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Kononova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artiőcial Intelligence Review</title>
		<imprint>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
