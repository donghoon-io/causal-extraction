<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Autoregressive Models as Causal Inference Engines</title>
				<funder ref="#_yz98nF8">
					<orgName type="full">Samsung Advanced Institute of Technology</orgName>
				</funder>
				<funder ref="#_dHJFpgJ">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">Ministry of Science and ICT (MSIT) of the Republic of Korea</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-07-04">4 Jul 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><forename type="middle">Jiwoong</forename><surname>Im</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Data Science</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="department" key="dep3">Computer Science</orgName>
								<orgName type="department" key="dep4">Center for Data Science</orgName>
								<orgName type="institution" key="instit1">New York University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
								<orgName type="institution" key="instit4">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kevin</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Data Science</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="department" key="dep3">Computer Science</orgName>
								<orgName type="department" key="dep4">Center for Data Science</orgName>
								<orgName type="institution" key="instit1">New York University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
								<orgName type="institution" key="instit4">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nakul</forename><surname>Verma</surname></persName>
							<email>verma@cs.columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Data Science</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="department" key="dep3">Computer Science</orgName>
								<orgName type="department" key="dep4">Center for Data Science</orgName>
								<orgName type="institution" key="instit1">New York University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
								<orgName type="institution" key="instit4">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
							<email>kyunghyun.cho@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Data Science</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="department" key="dep3">Computer Science</orgName>
								<orgName type="department" key="dep4">Center for Data Science</orgName>
								<orgName type="institution" key="instit1">New York University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
								<orgName type="institution" key="instit4">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Autoregressive Models as Causal Inference Engines</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-07-04">4 Jul 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2409.18581v3[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing causal inference (CI) models are often restricted to data with low-dimensional confounders and singleton actions. We propose an autoregressive (AR) CI framework capable of handling complex confounders and sequential actions commonly found in modern applications. Our approach accomplishes this using sequencification, which transforms data from an underlying causal diagram into a sequence of tokens. Sequencification not only accommodates training with data generated from a large class of DAGs, but also extends existing CI capabilities to estimate multiple causal quantities using a single model. We can directly compute probabilities from interventional distributions, simplifying inference and improving outcome prediction accuracy. We demonstrate that an AR model adapted for CI is efficient and effective in various complex applications such as navigating mazes, playing chess endgames, and evaluating the impact of certain keywords on paper acceptance rates, where we consider causal queries beyond standard reinforcement learning-type questions.</p><p>Autoregressive (AR) models are a standard framework for learning conditional probability distributions and predicting values in sequential or time-series data. Neural network-based AR models are widely used in applications such as language modeling for next-token prediction and text generation <ref type="bibr" target="#b3">(Devlin et al., 2019;</ref><ref type="bibr" target="#b29">Radford et al., 2019;</ref><ref type="bibr" target="#b36">Touvron et al., 2023)</ref>. As demonstrated by large language models (LLMs), AR models can capture complex relationships and scale effectively to large datasets. Recent studies <ref type="bibr" target="#b10">(Gupta et al., 2023;</ref><ref type="bibr" target="#b44">Zhang et al., 2024;</ref><ref type="bibr" target="#b43">Xu et al., 2024)</ref> show that fine-tuning pre-trained LLMs utilizes knowledge from an internet-scale text corpus, enhancing performance on various tasks.</p><p>We demonstrate that AR models can also be employed for causal inference by transforming observational data into a sequence following an underlying causal ordering. To achieve this, we employ sequencification for representing data based on a known causal diagram, specified as a directed acyclic graph (DAG). A neural network-based AR model can then learn the conditional probability distributions implied by the DAG. This allows for efficient sampling of sequential actions and high-dimensional confounders, enabling Monte Carlo estimation to approximate various causal effects. Furthermore, since the AR model learns all conditional distributions in the sequence, a single model trained on sequencified data can be used to compute a wide range of interventional distributions.</p><p>Our methodology is designed to handle variable-length sequential actions, combinatorially large action spaces, and high-dimensional confounders. These capabilities encompass a variety of common causal inference tasks, including average treatment effect (ATE) estimation, individual treatment effect (ITE) estimation, interventional distribution approximation, etc. To the best of our knowledge, all prior work can only accommodate fixed-length covariates and actions, and most evaluate on relatively low-dimensional data.</p><p>We conduct empirical studies across a variety of exemplar tasks, such as navigating mazes, playing chess endgames, and evaluating the impact of specific keywords on paper acceptance rates. The experiments show that our framework can (1) infer causal effects involving high-dimensional variables, (2) generalize to unseen confounders and action sequences, and (3) leverage pre-trained LLMs to answer text-based causal questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Previous work has explored the use of deep learning or AR models for estimating causal effects. Here, we provide a brief overview of the relevant studies.</p><p>Sequencification for statistical engines. Various machine learning fields have used linearized representations for tasks. In natural language processing (NLP), linearization (which we refer to as sequencification) is used to convert a syntactic tree into a sequence for building language model-based parsers <ref type="bibr" target="#b40">(Vinyals et al., 2015;</ref><ref type="bibr" target="#b21">Liu et al., 2022;</ref><ref type="bibr" target="#b33">Sheng et al., 2023)</ref>. In reinforcement learning (RL), an episode can be encoded as a sequence of states, actions, and rewards. An autoregressive model is then trained on these sequences to capture relationships among the variables <ref type="bibr" target="#b1">(Chen et al., 2021;</ref><ref type="bibr" target="#b13">Janner et al., 2021)</ref>. These instances suggest that AR models trained on sequencified data can effectively learn statistical dependencies among multiple high-dimensional variables.</p><p>Language models as causal engines. Several works have used language models for high-dimensional CI tasks (</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Modeling causal relationships is important across various fields for informed decision-making <ref type="bibr" target="#b11">(Holland, 1986;</ref><ref type="bibr" target="#b2">Cochran &amp; Rubin, 1973;</ref><ref type="bibr" target="#b28">Pearl, 2010)</ref>. However, existing causal inference (CI) algorithms are often limited by their inability to handle sequential variable-length actions and high-dimensional covariates <ref type="bibr" target="#b22">(Louizos et al., 2017;</ref><ref type="bibr" target="#b19">Kumor et al., 2021;</ref><ref type="bibr" target="#b12">Im et al., 2021;</ref><ref type="bibr" target="#b23">Lu et al., 2022;</ref><ref type="bibr" target="#b45">Zhong et al., 2022)</ref>. This work aims to address these shortcomings by designing a CI engine applicable to complex data involving high-dimensional variables.</p><p>Consider a medical setting where a doctor prescribes a sequence of treatments to the patient. In this scenario, the number of treatments that the patient undergoes is not necessarily fixed (e.g. additional procedures may be assigned depending on patient response or two medications might be combined into one). As a result, the number of possible treatment sequences grows combinatorially. Moreover, the medical decision may be dependent on high-dimensional data describing the condition of the patient, such as text from electronic health records. For successful treatment effect estimation, we want a framework that can accommodate arbitrary-length action sequences for complex, high-dimensional confounding data. To tackle this problem, we propose using neural network-based autoregressive (AR) models for causal inference. distributions <ref type="bibr" target="#b22">(Louizos et al., 2017;</ref><ref type="bibr" target="#b17">Kocaoglu et al., 2017;</ref><ref type="bibr" target="#b12">Im et al., 2021)</ref>. Normalizing flows have also been used for causal effect estimation. For example, <ref type="bibr" target="#b18">Krause et al. (2023)</ref> develop a doubly robust density estimator for potential outcomes by combining a nuisance and target normalizing flow.</p><p>For deep autoregressive models, <ref type="bibr" target="#b24">Monti et al. (2020)</ref> introduce an AR flow model that learns an invertible density transformation between variables. Their approach enables direct computation of interventional and counterfactual distributions without the need for complex latent variable manipulations. <ref type="bibr" target="#b8">Garrido et al. (2021)</ref> use neural AR density estimators <ref type="bibr" target="#b20">(Larochelle &amp; Murray, 2011)</ref> to model causal mechanisms and predict causal effects using Pearl's do-calculus <ref type="bibr" target="#b27">(Pearl, 2009)</ref>.</p><p>Other studies examine treatment effect estimation in more complex, multi-dimensional scenarios. <ref type="bibr" target="#b7">Frauen et al. (2025)</ref> propose a model-agnostic learner for a sequence of actions over a fixed time horizon. An interesting line of work focuses on real-valued actions (e.g. amount of medical dosage administered) for heterogeneous dose-response estimation using different neural-network architectures, including generative adversarial networks <ref type="bibr" target="#b0">Bica et al. (2020)</ref>, varying coefficient models <ref type="bibr" target="#b26">Nie et al. (2021)</ref>, and contrastive representation learning <ref type="bibr" target="#b46">Zhu et al. (2024)</ref>.</p><p>Causal Generative Models. Another approach to CI models data as part of a generative process and learns a causal generative model. These methods typically parameterize relationships in a known causal diagram using neural networks. For causal effect identification and estimation, <ref type="bibr" target="#b42">Xia et al. (2023)</ref> use neural causal models trained via gradient-based optimization with a minimization-maximization objective. Rahman &amp; <ref type="bibr" target="#b30">Kocaoglu (2024)</ref> introduce a modular learning framework for optimizing causal generative models in semi-Markovian settings by decomposing the data distribution into c-factors <ref type="bibr" target="#b35">(Tian &amp; Pearl, 2002)</ref>. Their method can use pre-trained generative models to learn individual conditional distribution components.</p><p>Existing limitations. Previous works exhibit notable weaknesses compared to our approach. First, most methods are validated only on relatively low-dimensional variables (tens of dimensions) and fixed-length actions. In contrast, our AR model is designed to handle high-dimensional confounders and variable-length series of actions where the number of possible sequences grows exponentially. This makes it applicable to settings with high-dimensional data and arbitrarily long sequence of treatments. Second, prior studies often focus on estimating specific causal effects or learning generative models by optimizing individual components of the causal structure. We instead use a unified end-to-end AR model that can estimate multiple causal queries. Third, we extend existing CI capabilities by leveraging pre-trained language models for settings where domain knowledge is essential for accurate inference (e.g. NLP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head><p>This section outlines the background knowledge of causal effect estimation and language models necessary for understanding our methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CI problem formulation</head><p>We study interactions between the following set of variables: an observable confounder X, action A, and outcome Y . Causal relationships are represented as a directed acyclic graph (DAG), where edges denote direct effects (cf. Figure <ref type="figure" target="#fig_0">1a</ref>). By applying the backdoor adjustment formula <ref type="bibr" target="#b27">(Pearl, 2009)</ref>, we can compute the potential outcome resulting from an intervention on the action:</p><formula xml:id="formula_0">Y a := E Y [Y | do(A = a)] := x,y y • p(Y = y | A = a, X = x)p(X = x).</formula><p>(1)</p><p>The notation do(A = a) represents an intervention on A, setting its value to a. Typically, the confounder X is assumed to be low-dimensional to avoid computing density estimates p(x) in high dimensions. Our goal is to model causal effects when typical assumptions in prior CI work are violated, including settings with complex confounders and combinatorially large action spaces.</p><p>We make the following set of standard assumptions in causal inference: (1) unconfoundedness, which states that Y 0 , Y 1 ⊥ ⊥ A | X, and (2) positivity, which requires that p(a, x, y) &gt; 0 for all triplets (a, x, y). </p><formula xml:id="formula_1">X Y A (a) X Y A 1 A 2 (b) X 1 X 2 Y A (c)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Language models</head><p>Language models (LMs) are designed to predict and generate text by learning linguistic patterns from a training corpus. Let W denote the vocabulary of the text corpus, which includes special ⟨start⟩ and ⟨end⟩ tokens. LMs estimate the probability of a sequence of tokens w = (w 1 , • • • , w T ) ∈ W T in an autoregressive manner, where w 1 = ⟨start⟩ and w T = ⟨end⟩. The probability of the sequence w is decomposed into the product of next-token probabilities:</p><formula xml:id="formula_2">p(w) = p(w 1 ) • p(w 2 | w 1 )p(w 3 | w 1 , w 2 ) • • • p(w T | w 1 , . . . , w T -1 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Language models as statistical inference engines</head><p>As suggested by Equation <ref type="formula">1</ref>, CI requires accurate estimation of statistical quantities to calculate causal effects. In this section, we describe how an AR model can be adapted into a statistical inference engine for any DAG involving a set of confounders, actions, and outcomes using sequencification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Causal graphs</head><p>We assume the underlying causal DAG G = (V, E) is known, where the vertices V i ∈ V represent random variables and the edges E i→j ∈ E denote conditional dependencies. Moreover, the graph satisfies the Markov property, meaning the joint probability distribution can be factored into a causally-consistent ordering,</p><formula xml:id="formula_3">p G (V 1 , V 2 , . . . , V M ) = M i=1 p G (V i | Pa(V i )),</formula><p>where Pa(V i ) := {V j ∈ V | E j→i ∈ E} is the set of parent nodes of V i . We assume that the graph G is fully specified and that all variables within G are observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sequencification</head><p>Suppose V i takes the value v i from its corresponding distribution. Let string(•) be an injective function that maps v i to a sequence of tokens: string(v i ) = (⟨start i ⟩, w 1 , w 2 , . . . , w Lv i ). Here, ⟨start i ⟩ is a special token indicating the beginning of the string representation for v i , and L vi is the length of string(v i ) excluding the ⟨start i ⟩ token. We define ⟨start i ⟩ uniquely for each i so that each random variable can be uniquely identified from its string representation by its corresponding initial token.</p><p>Let t = (V i1 , V i2 , . . . , V i M ) be a permutation of the random variables. We say t is a topological ordering if V i precedes V j in the ordering for all edges E i→j . Let T denote the set of all topological orderings. Consider N samples drawn from the underlying causal diagram G: (v</p><formula xml:id="formula_4">(n) 1 , v (n) 2 , • • • , v (n) M ) ∼ p G (V 1 , V 2 , • • • , V M ) for n = 1, . . . , N .</formula><p>For each sample, we construct a string s (n) by concatenating the string representations of all random variables according to a topological ordering t (n) selected uniformly at random from T . Formally, t (1) , t (2) , . . . , t (N ) i.i.d.  ∼ Uniform(T ) and</p><formula xml:id="formula_5">s (n) = string(v (n) i1 ) ⊕ string(v (n) i2 ) ⊕ • • • ⊕ string(v (n) i M ) ⊕ ⟨end⟩,</formula><p>where t (n) = (V i1 , V i2 , . . . , V i M ) and ⊕ denotes string concatenation. We refer to the process of converting observed samples into a sequence of tokens as sequencification.</p><p>Sequencification supports any data that can be transformed into a linear sequence of tokens. For example, tokens may represent specific values for numerical (e.g., binary) data or subwords for text, depending on the problem domain. Our approach can also handle mixed data modalities, as different variables may have separate tokenization strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Randomized topological orderings</head><p>We randomize over topological orderings consistent with the causal graph to obtain robust estimates of conditional probabilities. For instance, if a node in the graph has multiple independent parents, randomizing the order in which the parents are sequenced helps prevent the model from overfitting to any particular ordering. As a result, different samples may be concatenated using distinct topological orderings. However, because the data is generated by ancestor sampling v</p><formula xml:id="formula_6">(n) i | Pa(v (n) i ), values that causally influence string(v (n)</formula><p>i ) will always appear earlier in s (n) .</p><p>A natural question that may arise is how to obtain a good estimate when samples are sequencified according to different topological orderings. This is achieved by using the special ⟨start i ⟩ token at the start of each variable V i during sequencification, which indicates its position in the sequence (regardless of the topological ordering used).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Autoregressive statistical inference engines</head><p>After sequentification, we can train an AR language model, parameterized by θ, on the sequencified dataset D = {s (1) , s (2) , . . . , s (N ) } by the minimizing negative log-likelihood:</p><formula xml:id="formula_7">L(θ) = - 1 N N n=1 log p θ (s (n) ) = - 1 N N n=1 |s (n) | t=1 log p θ s (n) t s (n) 1:t-1 ,<label>(2)</label></formula><p>where | • | denotes the length of a string and s</p><p>(n) t is the t th token in s (n) . The trained model can estimate any conditional probability on G by computing p</p><formula xml:id="formula_8">G (V i | Pa(V i )) ≃ p θ (v i | Pa(v i ))</formula><p>. This is efficiently done by autoregressively traversing the sequence and calculating next-token probabilities using Monte Carlo estimation over the topological orderings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Language models as causal inference engines</head><p>In this section, we illustrate how to infer causal effects by leveraging statistical quantities from a trained AR model, thereby transforming it into a causal inference engine. After learning the conditional distribution over G using an AR model, we can estimate causal quantities by deriving the appropriate identification formula from the known causal diagram. Sequencification, combined with knowledge of G, allows us to estimate various causal effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Estimating causal quantities</head><p>We express the CI problem as a language modeling task. Given our DAG that consists of three variables (the observed confounder X, action A, and outcome Y ), we sequencify the data as follows:</p><formula xml:id="formula_9">s (n) = string(x (n) ) ⊕ string(a (n) ) ⊕ string(y (n) ) ⊕ ⟨end⟩.</formula><p>In our formulation, x (n) and a (n) can be high-dimensional vector values and the action space can be combinatorially large. Without loss of generality, we treat the outcome variable Y as a scalar, represented using a single token.</p><p>We can use the trained AR model to compute the distribution of Y after intervening on A. This is typically intractable when X is high-dimensional because the sample complexity of computing a non-parametric density estimate is exponential in the number of dimensions. However, we can approximate the interventional distribution by sampling from p θ (X) and applying Monte Carlo estimation.</p><formula xml:id="formula_10">p θ (Y = y | do(A = a)) = x p θ (y | A = a, x)p θ (x) ≃ 1 S S s=1 p θ (y | A = a, x (s) ),<label>(3)</label></formula><p>where x (s) ∼ p(X).</p><p>Furthermore, we can intervene on a prefix subsequence of A even when the action space is large. By expressing A = A 1 ⊕ A 2 and marginalizing out A 2 , we can compute the effect of intervening on only A 1 .</p><formula xml:id="formula_11">p(Y = y | do(A 1 = a 1 )) = x a2 p θ (y | A 1 = a 1 , A 2 = a 2 , x)p θ (a 2 | a 1 , x) p θ (x) (4) ≃ 1 S S s=1 p θ (y | a 1 , a (s) 2 , x (s) ),<label>(5)</label></formula><p>where</p><formula xml:id="formula_12">x (s) ∼ p(X) and a (s) 2 ∼ p(A 2 | a 1 , x (s)</formula><p>). For combinatorially large action spaces, Equation 4 is generally intractable because the marginalization requires exponentially many operations.</p><p>Similarly, we can condition on a prefix of the confounder by letting X = X 1 ⊕ X 2 and marginalizing out X 2 .</p><formula xml:id="formula_13">p(Y = y | do(A = a), x 1 ) = X2 x2 p θ (y | A = a, x 2 , x 1 ) p θ (x 2 | x 1 ) ≃ 1 S S s=1 p θ (y | A = a, x (s) 2 , x 1 ) (6)</formula><p>where</p><formula xml:id="formula_14">x (s) 2 ∼ p(X 2 | X 1 = x 1</formula><p>). The causal diagrams for these scenarios are shown in Figure <ref type="figure" target="#fig_0">1</ref>. Note that we can only intervene on prefixes of the action A 1 (or condition on prefixes of the confounder X 1 ) because this ensures the marginalization step samples A 2 (or respectively X 2 ) conditioned on preceding variables.</p><p>We emphasize that all causal quantities can be computed by a single language model trained on sequencified observations. Our approach enables efficient sampling and computation of conditional</p><formula xml:id="formula_15">p(Y | A = a), interventional p(Y | do(A = a)), partial interventional p(Y | do(A = a 1 )), and conditional interventional p(Y | do(A = a), X 1 = x 1 )</formula><p>distributions, all using a unified model. This provides an end-to-end framework for computing a variety of causal queries using a single model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>While the partial interventional distribution p(Y | do</head><formula xml:id="formula_16">(A 1 = a 1 )) is computable by effectively discarding A 2 ,</formula><p>training an AR model on sequencified data that explicitly includes A 1 and A 2 is more flexible. Our approach can efficiently estimate not only partial interventional distributions but also interventions on A 1 and A 2 simultaneously, providing a unified framework for handling multiple causal queries. A similar argument holds for partially conditioning on the confounders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We demonstrate the effectiveness of our approach in estimating causal effects for sequential actions and highdimensional confounders while also assessing robustness to distribution shifts. Our experiments showcase the ability to (1) infer potential outcomes with sequential actions and high-dimensional confounders, (2) efficiently approximate potential outcomes via Monte Carlo sampling, and (3) leverage knowledge from a pre-trained LLM. We evaluate our method across three environments: a maze setting for navigational decision-making, a chess environment analyzing strategic moves in king vs. king-rook endgames, and the PeerRead dataset which examines the impact of theorem presence on academic paper acceptance. The maze experiments demonstrate that our unified AR model can estimate interventions, partial interventions, and conditional interventions using Equations 3, 4, and 6, respectively. In contrast, a traditional offline reinforcement learning (RL) model fails to capture all three causal effects. In the chess experiments, we highlight the effectiveness of our method in estimating effects via Monte Carlo approximation using Equation 5 and its robustness to distribution shifts in the test data. Finally, the PeerRead setting demonstrates that the AR model can estimate effects in high-dimensional confounder scenarios and leverage pre-trained language models to improve text-based analysis. These diverse settings enable a comprehensive evaluation of the effectiveness and robustness of our approach for CI under variable-length action sequences and highdimensional confounders such as text. Moreover, our framework is also competitive with existing methods on benchmark treatment effect estimation tasks, as shown in Appendix E.</p><p>All AR models are trained using a vanilla transformer <ref type="bibr" target="#b38">(Vaswani et al., 2017)</ref> unless otherwise specified. Additional details on the model architecture and training process can be found in Appendix A.<ref type="foot" target="#foot_0">foot_0</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Maze navigation experiments</head><p>In this experiment, we show that a unified AR model can estimate multiple types of causal queries using Equations 3, 4, and 6. Compared to a baseline offline RL model, our approach offers greater flexibility for causal inference tasks.</p><p>We generate a synthetic maze dataset to analyze the causal effect of traversing different paths. The goal is to determine the distance to the exit after following a given path. The confounding variable X represents the starting position, the action A is a sequence of moves, and the outcome Y denotes the distance from the final position to the exit. <ref type="foot" target="#foot_1">2</ref> We evaluate potential outcomes when intervening on a complete path (cf. Figure <ref type="figure" target="#fig_1">2a</ref>) or partial path (cf. Figure <ref type="figure" target="#fig_1">2b</ref>). The obstacle positions are fixed but are not known to the model. The end position is fixed at the bottom-right corner, while the starting position is randomly selected from the open spaces with a probability proportional to its distance from the endpoint. Moves in the path are determined by selecting a direction based on the current position. Let the current square be in the ith row from the top and the jth column from the left. The next move is chosen according to the probabilities: This policy encourages paths to move towards the bottom-right corner. All actions are possible at any position, however moves that would collide with obstacles or walls in the maze are treated as no action.</p><formula xml:id="formula_17">p up = p left = 0.1, p right = 0.8i i + j , p down = 0.8j i + j .</formula><p>Paths are fixed to contain exactly six moves.</p><p>We train an AR model on sequencified data and use a deep Q-learning (DQL) model as an offline reinforcement learning (RL) baseline. The AR model is given only the starting position and must infer the effect of each move along the path. The DQL model follows the standard RL framework, where the current position is known after each move. In Appendix B, we vary the dimensionality of the maze and the length of the path to demonstrate the scalability of our framework in terms of the input and action dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Causal inference using sequential actions</head><p>We estimate potential outcomes for all paths of length six in a 4 × 4 maze using Equation <ref type="formula" target="#formula_10">3</ref>. Additionally, we compute potential outcomes conditioned on the starting row (from the top of the maze) X 1 ∈ {1, 2, 3, 4} using Equation <ref type="formula">6</ref>. Ground truth values are computed using the corresponding equations with the outcome outcome E Y [Y | a, x] equal to the true number of additional moves required to reach the end of the maze after starting in position x and taking path a. For the RL method, we predict the potential outcome as the q-value after taking the final action in the intervention.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> presents the error distribution for potential outcome estimates across all paths. In all settings, both models produce estimates that closely match the ground truth. Our AR model performs comparably to the offline RL baseline in terms of mean estimation error. The AR error distribution exhibits a large tail, which can be attributed to differences in training setups. It is worth emphasizing that the RL model knows the exact position after each move in the path and therefore only needs to predict one step ahead each time, whereas our AR framework only knows the starting position and has to predict six future steps. As expected, the extra knowledge available to the RL model lowers the variance. However, even without this knowledge, our model achieves slightly lower overall error. These results demonstrate that our approach can accurately predict both intervention and conditional intervention queries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Causal inference using partial actions</head><p>In addition to computing complete interventions, we can also intervene on partial actions. To illustrate this scenario, we estimate potential outcomes when intervening on the initial moves in a path. Specifically, we decompose A = A 1 ⊕ A 2 , where A 1 represents the first four moves and A 2 the remaining two moves, and compute p(Y | do(A 1 = a 1 )). Ground truth potential outcomes are calculated using Equation 4 by marginalizing over all possible remaining paths A 2 . For the RL method, we intervene on the first four moves, while the remaining path is determined according to the learned policy.</p><p>Figure <ref type="figure" target="#fig_3">4</ref> shows the error distribution for potential outcome estimates across all possible four-move interventions. Our AR model accurately computes these estimates using Equation <ref type="formula">4</ref>. In contrast, the offline RL model does not learn the distribution p(a 2 | a 1 , x) but instead optimizes for the best policy. As a result, it fails to predict partial interventions without modifications, such as discarding information about A 2 during training. This highlights the greater flexibility of our AR framework, which allows interventions on any subset of initial moves with a single model. These experiments demonstrate that a single AR model can accurately estimate interventional, partial interventional, and conditional interventional distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Chess endgame experiments</head><p>In this section, we evaluate the performance of our AR model with Monte Carlo sampling, following Equation 5, and assess its robustness to distribution shifts. To explore these aspects in a more complex two-player setting, we use a synthetic chess dataset featuring king vs. king-rook endgames, where White moves first and Black holds the rook. We demonstrate that our AR model can accurately compute causal effects and identify optimal action sequences by comparing potential outcome estimates. Additionally, we leverage Monte Carlo sampling to refine estimates when only partial data is available and introduce a distribution shift between training and testing data to assess generalization.</p><p>To formulate our causal query, we ask: on average, across all starting positions, which pieces should Black move on the first two turns to checkmate White the fastest? Our question aims to uncover a general strategy for king vs. king-rook endgames, much like how controlling the center is a fundamental principle in the opening. More broadly, it parallels CI in scenarios with multiple initial conditions, where the objective is to identify the most effective strategy across a wide range of situations rather than an individual configuration. Each endgame comprises a two-move chess game, potentially incomplete. The covariate X is the initial piece positions. The action A = (a 1 , a 2 , a 3 , a 4 ) represents alternating White and Black moves. Since we consider Black's perspective, we are interested in causal quantities involving a 2 and a 4 . We assume Black plays optimally after selecting which piece to maneuver, so each action only dictates whether to move the king or the rook, but not to which location. The outcome variable y is the number of additional moves required to checkmate with optimal play.<ref type="foot" target="#foot_2">foot_2</ref> Formally, we are interested in finding We evaluate the ground truth using the chess engine Stockfish<ref type="foot" target="#foot_3">foot_3</ref> . Figure <ref type="figure" target="#fig_1">2c</ref> displays an example endgame.</p><p>We construct three training datasets: one Randomized Control Trial (RCT), which selects each action uniformly at random between moving the king or the rook, and two non-RCT datasets, labeled non-RCT 1 and non-RCT 2 , with distinct action policies. The policy functions for non-RCT 1 and non-RCT 2 are defined as follows, where d is the Hamming distance between the kings:</p><formula xml:id="formula_18">π 1 (a 2 , a 4 = king) = d 16</formula><p>, π 2 (a 2 , a 4 = king) = 0.8 if black king is in center 4 × 4 square 0.2 otherwise .</p><p>π 1 encourages the two kings to be closer while π 2 pushes the Black king towards the edge of the board, both of which are required for checkmate. We use different RCT and non-RCT data to demonstrate robustness in the presence or absence of X → A and under varying action assignment mechanisms.</p><p>The testing dataset consists of all 223,660 valid starting positions. To assess out-of-distribution generalization, we use two distinct policies for White in the training and testing phases. White plays uniformly at random over non-optimal moves (unless no such legal moves are available) during training and plays optimally at test time. This introduces a distribution shift, which we use to evaluate generalization and robustness to new settings. Additionally, we show that our proposed AR framework produces more accurate causal estimates by using Monte Carlo sampling from p θ (X) when given only a subset of the testing data.</p><p>We compute the ground truth potential outcomes for all actions and compare them with three different model estimates: the exact model estimate using the entire test dataset, the approximate model estimate using a subset of the test data, and the Monte Carlo model estimate, which also uses the same data subset but additionally generates samples from the model. The approximate and Monte Carlo estimates reflect real-world scenarios, where obtaining a large number of RCT samples is often difficult. We train a nonautoregressive multilayer perceptron (MLP) as a baseline for comparison.</p><p>Figure <ref type="figure" target="#fig_4">5</ref> presents our three model estimates for the AR and MLP model. As the number of samples in the Monte Carlo approximation increases, the potential outcome estimate converges to the exact estimate.</p><p>Our results demonstrate that potential outcomes can be efficiently and accurately approximated with an AR model using only a fraction of the test data. Additionally, there is a gap between the AR exact model estimate and the ground truth, caused by the distribution shift in how White plays between the training and test data. The potential outcomes for the remaining actions are provided in Appendix C. By comparing all potential outcome estimates, we can answer our causal question and conclude that, aggregated across all starting positions, moving the rook twice initially is the best strategy for Black.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">PeerRead experiments</head><p>We use the PeerRead dataset <ref type="bibr" target="#b15">(Kang et al., 2018)</ref> to estimate causal effects in a semi-realistic setting with high-dimensional text confounders. Our results demonstrate that an AR model can leverage pre-trained language models to enhance CI in text-based settings. The dataset consists of paper draft submissions to top computer science conferences, such as NeurIPS, ICML, and ICLR, along with their acceptance or rejection decisions. We investigate the impact of including "theorems" on acceptance likelihood and evaluate how well our model captures this causal effect. Building on prior work, we focus on computational linguistics, machine learning, and artificial intelligence papers submitted between 2007 and 2017 <ref type="bibr" target="#b39">(Veitch et al., 2020)</ref>.</p><p>The covariate X represents the paper's abstract text, the action A is a binary variable indicating the presence of the keyword "theorem", and the outcome Y is a binary variable indicating acceptance or rejection. Since real-world counterfactual outcomes are inaccessible, we follow prior methods by generating synthetic outcomes based on the action A and the title buzziness Z (i.e., whether the title contains "deep", "neural", "embed", or "adversarial net"). For example, z = 1 and a = 1 likely correspond to a deep learning paper that includes a theorem, while z = 0 and a = 1 may represent a theoretical machine learning paper or a deep learning paper with a theorem but without a buzzy title.</p><p>Define π(z) as the proportion of data samples with a i = 1 among those satisfying z i = z. Let β be a parameter controlling the level of confounding between title buzziness and the outcome. Following <ref type="bibr" target="#b39">Veitch et al. (2020)</ref>, we generate outcomes using the model:</p><formula xml:id="formula_19">Y i ∼ Bernoulli(σ(0.25a i + β(π(z i ) -0.2))).</formula><p>Since evaluating any causal effect model requires counterfactual outcomes that are inaccessible in real-world data, we use a semi-synthetic setting, where the covariates are real-world data and the labels are generated according to patterns in the data, albeit synthetically. We demonstrate the correlation between title buzziness and the text in Appendix D.</p><p>Following the original experimental design, we report the Average Treatment Effect on the Treated (ATT),</p><formula xml:id="formula_20">ATT := p(Y = 1 | do(A = 1), A = 1) -p(Y = 1 | do(A = 0), A = 1),</formula><p>across three confounding levels: low, medium, and high. A positive ATT indicates that including a theorem increases a paper's chance of acceptance. For larger values of β, the outcome becomes more correlated with title buzziness Z rather than the action A, so the ground truth ATT is smaller.</p><p>We compare our proposed approach to a non-autoregressive MLP baseline and Causal-BERT (C-BERT) from <ref type="bibr" target="#b39">Veitch et al. (2020)</ref>.<ref type="foot" target="#foot_4">foot_4</ref> Like C-BERT, we fine-tune a pre-trained BERT model on our sequencified representations for a fair comparison. Additionally, we evaluate GPT-2 (referred to as GPT), another pretrained LLM with a comparable parameter size to BERT <ref type="bibr" target="#b29">(Radford et al., 2019)</ref>.</p><p>BERT is trained using masked language modeling (MLM) and next-sentence prediction objectives. MLM randomly masks a fraction of input tokens and trains the model to predict them. GPT is trained with a next-token prediction objective. To adapt BERT for this setting, we randomly sample subsection of the abstract during training and mask the final token to fine-tune it as a next-token prediction model. As shown in Table <ref type="table" target="#tab_0">1</ref>, our approach outperforms C-BERT and other benchmarks. The primary reason for the improvement is that we jointly learn representations and outcome predictions within a single model, whereas C-BERT uses additional architectural layers for multiple objective functions. To quantify the variance in effect estimation for our proposed models, we compute the mean and standard error of the ATT estimates across three trials. Note that most language models tend to have high variance due to the heavy-tailed nature of next-token prediction. <ref type="bibr" target="#b39">Veitch et al. (2020)</ref> do not report uncertainties in their experiments.</p><p>Our proposed framework leverages the existing knowledge in pre-trained LLMs to accurately estimate causal quantities. While fine-tuning GPT yields successful results, training the model from scratch fails to identify causal effects because the model lacks prior understanding of text. We also demonstrate that our results are robust to the size of the pre-trained language model in Appendix D. By using LLMs, our approach outperforms non-autoregressive causal methods and proves more effective for a wider range of CI tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this work, we introduce an AR framework for CI that handles high-dimensional confounders and combinatorially large action spaces. Our proposed method, called sequencification, transforms data into a linear sequence of tokens based on a known causal diagram. By training a single AR model on sequencified data, we learn conditional distributions between variables in the graph. The framework enables efficient sampling and approximation of several interventional distributions in a unified manner.</p><p>We validate the effectiveness of our method for inferring causal effects across three diverse settings: maze navigation, chess endgames, and academic papers. By handling high-dimensional confounders and combinatorially large action sequences, our work extends the capabilities of CI for a wider range of applications.</p><p>Our approach has two main limitations. First, it requires the full causal graph to be known exactly, with all variables observed. A possible solution for handling unobserved values is to impute unconfounded missing data using a mask token. Second, our method supports conditioning or intervening only on variable prefixes. We leave the investigation of solutions to these limitations for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training details</head><p>The maze experiments were conducted on a single NVIDIA Tesla T4. All models for the chess and PeerRead experiments were trained on a single NVIDIA GeForce RTX 3090 in four and eight hours respectively.</p><p>Maze experiments. The maze dataset comprises 10,000 sequencified data points. We use a vanilla transformer with 3 layers, 8 attention heads, and a hidden dimension of 64. For training, we use the Adam optimizer with a batch size of 64. The CI model is trained for 6,250 iterations, while the offline RL model is trained for 5,000 iterations.</p><p>Chess endgame experiments. We use a 512-dimensional vanilla transformer with 6 layers and 8 attention heads. The model is trained on a next-token prediction task using the sequencified representation. Training runs for 200 epochs with the Adam optimizer, a batch size of 4096, and a learning rate chosen to be as large as possible without overfitting.</p><p>For the training dataset, we sample 500,000 two-move chess games per dataset based on Black's policy function. The test dataset includes every game from all 223,660 legal starting positions and all four possible Black actions (king-king, king-rook, rook-king, rook-rook). We sequencify the data by assigning a unique token to each square, legal king and rook move, and outcome.</p><p>PeerRead experiments. We fine-tuned our models using pre-trained BERT and GPT base model checkpoints. <ref type="foot" target="#foot_5">6</ref> For BERT, we employed a two-phase training process similar to C-BERT. In the first phase, we trained BERT to generate abstracts, followed by a second phase where it learned to generate full sequences, including both actions and outcomes. GPT, having been pre-trained on next-token prediction, required only a single training phase. This approach ensures a gradual refinement of the generative capabilities specifically tailored to the PeerRead corpus. For all training phases, we trained for 100 epochs using the Adam optimizer with a batch size of 16. The learning rate was set as high as possible without overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Maze extra experiments</head><p>We investigate whether the outcomes produced by our model have some interpretability. To study the predictions of our model, we reuse the synthetic maze setup in Section 6.1 with slightly modified obstacle positions. The configuration of the maze is shown in Figure <ref type="figure" target="#fig_6">6</ref>.  Following the original experimental design, the objective is to determine the distance to the exit after following a path. The confounding variable X is the start and end positions, the action A is the sequence of moves in a path, and the outcome Y is the distance from the final position to the exit.</p><p>We consider the question: for a fixed starting state, is it better to go right or down? To answer this, we compute the potential outcome of moving right or down initially. This task is prohibitive for most nonautoregressive CI models as they treat the path as a singular variable. Our model is capable of intervening on any subsequence of actions because the conditional probability given its parents is tractable.</p><p>To compute the potential outcome, we marginalize over subsequent actions as shown in Equation <ref type="formula">4</ref>. Since the paths may be intractable without limiting the maximum length, we cap the longest path to 16 moves as there are a total of 16 positions in the maze. To compare the exact estimates with the Monte Carlo approximations, we report both quantities derived from Equation 4 and 5, and denote them as exact model estimate and approximate model estimate respectively.</p><p>Figure <ref type="figure" target="#fig_7">7</ref> shows the potential outcome estimate of moving right or down initially. The distribution is more concentrated towards smaller distances for moving down and more uniform for moving right. Thus, going down is a better choice for the first move, which matches our intuition based on the maze configuration.</p><p>To demonstrate the scalability of our methodology with respect to the number of variables, we extend the maze experiments using the same setup described in Section 6.1. Specifically, we adjust the maze dimensionality and path length for fine-grained control over the covariates X and actions A. We increase the maze from 2D (i.e., 4 × 4) up to 5D (i.e., 4 × 4 × 4 × 4 × 4), while keeping the path length fixed at six. Since the starting position in d dimensions is defined by d coordinates, this directly controls the dimensionality of X. To vary the number of actions, we modify the path length from four to ten while holding the maze structure fixed at 2D. All model and training details (e.g. number of samples and number of optimization epochs) are identical to the original maze experiments.</p><p>We evaluate our model by computing the absolute error in estimating the effect of intervening on every possible path of a specified length. Figure <ref type="figure" target="#fig_8">8</ref> shows the distribution of these errors as we vary the maze dimensionality and path length. The average estimation error increases with both maze dimensionality and path length due to growing data complexity. The variance also increases significantly with longer paths and more gradually with higher-dimensional mazes. Nonetheless, the overall estimation accuracy remains high, with the majority of errors within 0.5 of the true effect across all configurations.   In Figure <ref type="figure" target="#fig_10">9</ref>, we present the potential outcome graphs for the remaining three actions: king-king, king-rook, and rook-rook. The model behavior on these actions closely aligns with the observations for rook-king in Figure <ref type="figure" target="#fig_4">5</ref>. Across multiple interventions, Monte Carlo sampling improves potential outcome estimates when only a subset of the test data is available. Thus, our approach not only effectively models outcomes but also leverages Monte Carlo sampling to enhance predictions in limited data scenarios.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Chess endgame potential outcome estimates</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D PeerRead extra experiments</head><p>We examine the rate at which the ATT error converges to study causal effect prediction in small data cases. Using the PeerRead experimental setup, we vary the training set size from a few hundred papers to the full dataset (9305 samples). We repeat each estimation across three trials and report the mean and standard error of the relative ATT error in Figure <ref type="figure" target="#fig_11">10</ref>. For our BERT and GPT models, the error decays gradually with the number of training samples. We also study the impact of pre-trained language model size on effect estimation accuracy using three versions of GPT. Table <ref type="table" target="#tab_3">3</ref> indicates that larger models generally yield more accurate estimates. Furthermore, we demonstrate why our model performs well when the outcome is generated from Z and A while the input is derived from X and A. To quantify the correlation between title buzziness and the abstract, we train a logistic regression model to predict Z from X. For each model, we extract the final hidden layer output as a dense vectorized representation of the abstract. As a baseline, we train a separate logistic regression model using the bag-of-words (BoW) representation of X. Table <ref type="table" target="#tab_4">4</ref> shows a strong correlation between X and Z, explaining the high accuracy of our potential outcome estimations.  To illustrate the positive predicted ATT on the PeerRead dataset, we compare p θ (Y = 1 | A = 1, X) and p θ (Y = 1 | A = 0, X) predicted by GPT in Figure <ref type="figure" target="#fig_0">11</ref>. Our model consistently favors papers containing theorems regardless of title buzziness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Ablation studies on IHDP</head><p>Although the experiments in Section 6 are designed to demonstrate the effectiveness of our AR model in scenarios involving variable-length action sequences and high-dimensional covariates, it is also competitive with existing methods on benchmark causal datasets. To illustrate this, we evaluate our model on a semisynthetic baseline using the Infant Health and Development Program (IHDP) data. The dataset consists of a 25-dimensional covariate X (6 of which are continuous features), a binary treatment A, and a continuous outcome Y . The evaluation metric is ATE prediction error.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Causal diagrams illustrating interventions on the action (a), partial action (b), and when conditioning on a prefix of the confounders (c), where X, A, and Y denote the confounders, actions, and outcome respectively. Bold red arrows indicate the pathways blocked by the corresponding intervention. Potential outcomes can be computed using the backdoor adjustment formula for each scenario.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustrations of the maze and chess experimental settings. In the maze experiment, we address two questions: what is the potential outcome given (a) a complete path, and (b) a partial path? The blue path represents the intervention, gray indicates a potential remaining path after a partial intervention, and orange denotes the distance to the end. The chess experiment aims to determine which pieces Black should move to checkmate White the quickest. In the example position shown in (c), the probability of moving the Black king is 0.5, 0.25, and 0.8 with the RCT, non-RCT1, and non-RCT2 policies respectively.</figDesc><graphic coords="7,76.80,81.86,140.41,140.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Error distribution of potential outcome estimates for our AR model (blue) and the offline RL baseline(red). We compute the effect of intervening on the complete path with and without conditioning on the starting row X1. The plot depicts the distribution of errors across all 4096 possible paths of length six, while the black dashed line represents the mean error. The AR and RL models exhibit comparable performance across all settings, with our AR model performing marginally better.</figDesc><graphic coords="8,72.00,81.86,468.01,217.17" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Heatmap illustrating the error distribution of potential outcome estimates when intervening on the first four moves in the path. Each row represents all possible actions for the first two moves, while each column represents all possible subsequent two moves. Our AR model accurately estimates potential outcomes for all four-move sequences by learning p(a2 | a1, x). The offline RL baseline exhibits significant errors across nearly all interventions.</figDesc><graphic coords="9,95.40,81.86,421.21,199.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Potential outcome estimates for rook-king. The exact model estimate uses all 223,660 valid starting positions as test samples, while the approximate and Monte Carlo estimates use 1,000 randomly selected samples. Each Monte Carlo estimate was repeated 1,000 times, with error bars representing one standard deviation. By sampling from p θ (X), the AR Monte Carlo estimate approaches the AR exact estimate. In contrast, the MLP model cannot perform sampling on p θ (X).</figDesc><graphic coords="10,72.00,81.86,468.02,152.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>E</head><label></label><figDesc>Y [Y | do(a 2 , a 4 )] = arg min a2,a4∈{king,rook} x,y y • p(Y = y | x, a 2 , a 4 )p(x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Illustration of the maze setup. We answer a causal question involving intervening on a partial path: is it better to go right or down?</figDesc><graphic coords="16,207.72,473.50,196.57,196.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Potential outcome MSE between ground truth and model estimates for moving right vs. down first. Both the exact model estimate (a) and approximate model estimate (b) are shown.</figDesc><graphic coords="17,75.02,81.86,224.74,113.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Distribution of effect estimation errors for all possible interventions of the given path length. The inner box indicates the lower and upper quartiles of the distribution, while the point represents the mean. The overall error increases with the input complexity (i.e. higher-dimensional mazes and longer path sequences).</figDesc><graphic coords="18,72.00,81.86,467.99,297.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a) King-king potential outcome estimates. (b) King-rook potential outcome estimates. (c) Rook-rook potential outcome estimates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Potential outcome estimates for (a) king-king, (b) king-rook, and (c) rook-rook actions. Similar to the rook-king intervention, sampling from p θ (X) enables the AR Monte Carlo estimate to approach the AR exact estimate.</figDesc><graphic coords="19,72.00,425.66,468.00,153.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Mean and standard deviation of the relative ATT error while varying the training set size. The training data increases exponentially from one hundred points to the entire dataset of 9305 samples.</figDesc><graphic coords="20,153.90,81.86,304.20,197.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="21,177.30,81.86,257.41,198.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>PeerRead ATT performance across low, medium, and high confounding levels, with relative error indicated in parentheses. For our Deep Autoregressive Causal Inference Engine (DARCIE) BERT and GPT models, we quantify the uncertainty in our estimates by reporting the mean and standard error of the ATT across three trials. Entries in bold and underlined indicate best performing models for each confounding level. Overall, our DARCIE-GPT model achieves the lowest relative error, and both of our models show improvement over other methods. Training DARCIE-GPT from scratch fails to identify causal effects due to its lack of understanding of the text.</figDesc><table><row><cell>Confounding level</cell><cell>Low (β = 1)</cell><cell>Medium (β = 5)</cell><cell>High (β = 25)</cell></row><row><cell>Ground truth</cell><cell>0.062</cell><cell>0.059</cell><cell>0.028</cell></row><row><cell>Computed biased</cell><cell>0.065 (4.8%)</cell><cell>0.097 (68%)</cell><cell>0.160 (470%)</cell></row><row><cell>Reported biased (Veitch et al., 2020)</cell><cell>0.08 (30%)</cell><cell>0.15 (150%)</cell><cell>0.16 (471%)</cell></row><row><cell>MLP ψQ</cell><cell>0.05 (20%)</cell><cell>0.10 (70%)</cell><cell>0.30 (970%)</cell></row><row><cell>C-BERT ψQ</cell><cell>0.09 (45%)</cell><cell>0.07 (19%)</cell><cell>0.04 (42%)</cell></row><row><cell>C-BERT ψplugin</cell><cell>0.10 (61%)</cell><cell>0.09 (53%)</cell><cell>0.05 (78%)</cell></row><row><cell>DARCIE-GPT (No pre-train)</cell><cell>0.001 (98%)</cell><cell>0.002 (97%)</cell><cell>0.001 (96%)</cell></row><row><cell>DARCIE-BERT (Ours)</cell><cell>0.039 (37%) ± 0.007</cell><cell>0.039 (34%) ± 0.005</cell><cell>0.016 (43%) ± 0.003</cell></row><row><cell>DARCIE-GPT (Ours)</cell><cell cols="3">0.041 (34%) ± 0.004 0.048 (19%) ± 0.002 0.025 (10%) ± 0.002</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table /><note><p>compares the potential outcome values for all actions, presenting both exact model estimates and approximate model estimates. Our AR model performs similarly to the baseline across both metrics. Predictions from the model aligns with the ground truth answer to our counterfactual query: on average, moving the rook twice leads to the fastest checkmate.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Chess</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Potential outcome (Error %)</cell><cell></cell></row><row><cell></cell><cell>king-king</cell><cell>king-rook</cell><cell>rook-king</cell><cell>rook-rook</cell></row><row><cell>Ground truth</cell><cell>22.76</cell><cell>20.18</cell><cell>20.48</cell><cell>17.27</cell></row><row><cell>RCT</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>endgame potential outcome estimates for all actions. The outcome represents the number of additional moves required for checkmate. Since Black aims to achieve checkmate as quickly as possible, lower values are desired.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>PeerRead ATT estimates for GPT small, medium, and large, with relative error shown in parentheses.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Confounding level</cell><cell></cell></row><row><cell></cell><cell># params</cell><cell>Low</cell><cell>Medium</cell><cell>High</cell></row><row><cell>Ground truth</cell><cell></cell><cell>0.062</cell><cell>0.059</cell><cell>0.028</cell></row><row><cell>GPT-small</cell><cell>117M</cell><cell>0.050 (20%)</cell><cell>0.044 (25%)</cell><cell>0.020 (29%)</cell></row><row><cell>GPT-medium</cell><cell>345M</cell><cell>0.052 (16%)</cell><cell>0.053 (10%)</cell><cell>0.038 (36%)</cell></row><row><cell>GPT-large</cell><cell>774M</cell><cell>0.051 (18%)</cell><cell>0.054 (8%)</cell><cell>0.021 (25%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Accuracy and balanced accuracy of title buzziness prediction from the abstract using logistic regression.</figDesc><table><row><cell></cell><cell>Acc.</cell><cell>Balanced acc.</cell></row><row><cell>BoW</cell><cell>87.95%</cell><cell>73.27%</cell></row><row><cell>BERT</cell><cell>88.57%</cell><cell>77.91%</cell></row><row><cell>GPT2</cell><cell>89.18%</cell><cell>81.00%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Code is available at https://github.com/jiwoongim/Deep-Autoregressive-Models-as-Causal-Inference-Engines.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>Y is the shortest possible distance in the maze while avoiding obstacles, not necessarily the Hamming distance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>In the event of a draw, the outcome is set to 50 due to the 50-move rule.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Stockfish is available at https://github.com/official-stockfish/Stockfish.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>C-BERT learns causally sufficient embeddings: low-dimensional document representations that preserve sufficient information for causal identification and enable efficient causal effect estimation.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>BERT-Base is available at https://huggingface.co/google/bert_uncased_L-12_H-768_A-12, and GPT is available at https://huggingface.co/openai-community/gpt2.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by the <rs type="institution">Institute of Information &amp; Communications Technology Planning &amp; Evaluation (IITP)</rs> with a grant funded by the <rs type="funder">Ministry of Science and ICT (MSIT) of the Republic of Korea</rs> in connection with the <rs type="institution">Global AI Frontier Lab International Collaborative Research</rs>. This work was also supported by the <rs type="funder">Samsung Advanced Institute of Technology</rs> (under the project <rs type="projectName">Next Generation Deep Learning</rs>: <rs type="grantName">From Pattern Recognition</rs> to AI) and the <rs type="funder">National Science Foundation</rs> (under <rs type="funder">NSF</rs> Award <rs type="grantNumber">1922658</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_yz98nF8">
					<orgName type="grant-name">From Pattern Recognition</orgName>
					<orgName type="project" subtype="full">Next Generation Deep Learning</orgName>
				</org>
				<org type="funding" xml:id="_dHJFpgJ">
					<idno type="grant-number">1922658</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We compare performance with four other baseline models: a neural network (NN), random forest (RF), causal forest (CF), and CRNET <ref type="bibr" target="#b46">(Zhu et al., 2024)</ref>. For the AR model, we use a feedforward network embedding layer to handle continuous numerical values. We report the mean and standard error of the ATE error on the test set across 30 different random train-test splits in Table <ref type="table">5</ref>. Our method is competitive with common existing methods and outperforms CRNET while having lower variance. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Estimating the effects of continuous-valued interventions using generative adversarial networks</title>
		<author>
			<persName><forename type="first">Ioana</forename><surname>Bica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Jordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihaela</forename><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="16434" to="16445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Decision transformer: Reinforcement learning via sequence modeling</title>
		<author>
			<persName><forename type="first">Lili</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Laskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="15084" to="15097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Controlling bias in observational studies: A review</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">G</forename><surname>Cochran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Indian Journal of Statistics, Series A</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="417" to="446" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter</title>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Overlap in observational studies with high-dimensional covariates</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Alexander D'amour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Avi</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lihua</forename><surname>Feller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jasjeet</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><surname>Sekhon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Econometrics</title>
		<imprint>
			<biblScope unit="volume">221</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="644" to="654" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How to make causal inferences using texts</title>
		<author>
			<persName><forename type="first">Naoki</forename><surname>Egami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><forename type="middle">J</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Causal inference in natural language processing: Estimation, prediction, interpretation and beyond</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emaad</forename><forename type="middle">A</forename><surname>Manzoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reid</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zach</forename><surname>Wood-Doughty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1138" to="1158" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learners for estimating heterogeneous treatment effects over time</title>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Frauen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Feuerriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Estimating causal effects with the neural autoregressive density estimator</title>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislav</forename><surname>Borysov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeppe</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="211" to="228" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Causal estimation for text data with (apparent) overlap violations</title>
		<author>
			<persName><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 11th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Continual pre-training of large language models: How to (re)warm your model?</title>
		<author>
			<persName><forename type="first">Kshitij</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Th'erien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><forename type="middle">G</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Irina</forename><surname>Belilovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Rish</surname></persName>
		</author>
		<author>
			<persName><surname>Lesort</surname></persName>
		</author>
		<idno>CoRR, abs/2308.04014</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistics and causal inference</title>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">396</biblScope>
			<biblScope unit="page" from="945" to="960" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Causal effect variational autoencoder with uniform treatment for overcoming covariate shifts</title>
		<author>
			<persName><forename type="first">Jiwoong</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narges</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><surname>Razavian</surname></persName>
		</author>
		<idno>CoRR, abs/2111.08656</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Offline reinforcement learning as one big sequence modeling problem</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Janner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Liang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1273" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning weighted representations for generalization across designs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fredrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Kallus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><surname>Sontag</surname></persName>
		</author>
		<idno>CoRR, abs/1802.08598</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A dataset of peer reviews (PeerRead): Collection, insights and NLP applications</title>
		<author>
			<persName><forename type="first">Dongyeop</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhavana</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Kohlmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter</title>
		<editor>
			<persName><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</editor>
		<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1647" to="1661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Text and causal inference: A review of using text to remove confounding from causal estimates</title>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brendan O'</forename><surname>Connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joyce</forename><surname>Chai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Natalie</forename><surname>Schluter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="5332" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Experimental design for learning causal graphs with latent variables</title>
		<author>
			<persName><forename type="first">Murat</forename><surname>Kocaoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthikeyan</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Brunskill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno>PMLR</idno>
		<title level="m">Normalizing Flows for Interventional Density Estimation</title>
		<editor>
			<persName><forename type="first">Barbara</forename><surname>Engelhardt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sivan</forename><surname>Sabato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jonathan</forename><surname>Scarlett</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2023-07">Jul 2023</date>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page" from="23" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequential causal imitation learning with unobserved confounders</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kumor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="14669" to="14680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Artificial Intelligence and Statistics</title>
		<editor>
			<persName><forename type="first">Geoffrey</forename><surname>Gordon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><surname>Dunson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Miroslav</forename><surname>Dudík</surname></persName>
		</editor>
		<meeting>the 14th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011-04">Apr 2011</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="11" to="13" />
		</imprint>
	</monogr>
	<note>PMLR</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Autoregressive structured prediction with language models</title>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuchen</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Eleanor</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Monath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2022</title>
		<editor>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="993" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Causal effect inference with deep latent-variable models</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joris</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Causal effect estimation using variational information bottleneck</title>
		<author>
			<persName><forename type="first">Zhenyu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yurong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Stoian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ye</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoren</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Information Systems and Applications</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="288" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Autoregressive flow-based causal discovery and inference</title>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Pio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Monti</forename></persName>
		</author>
		<idno>CoRR, abs/2007.09390</idno>
	</analytic>
	<monogr>
		<title level="m">Ilyes Khemakhem, and Aapo Hyvarinen</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Matching with text data: An experimental evaluation of methods for matching documents and of measuring match quality</title>
		<author>
			<persName><forename type="first">Reagan</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Miratrix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Russell Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Anastasopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="445" to="468" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">VCNet and functional targeted regularization for learning causal effects of continuous treatments</title>
		<author>
			<persName><forename type="first">Lizhen</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><forename type="middle">L</forename><surname>Nicolae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 9th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Causality: Models, Reasoning and Inference</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An introduction to causal inference</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Biostatistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1557" to="4679" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>OpenAI</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Modular learning of deep causal generative models for highdimensional causal inference</title>
		<author>
			<persName><forename type="first">Md</forename><surname>Musfiqur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahman</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Murat</forename><surname>Kocaoglu</surname></persName>
		</author>
		<idno>CoRR, abs/2401.01426</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adjusting for confounding with text matching</title>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Political Science</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="887" to="903" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Estimating individual treatment effect: Generalization bounds and algorithms</title>
		<author>
			<persName><forename type="first">Uri</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fredrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 33rd International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A unified framework for synaesthesia analysis</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingqing</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2023</title>
		<editor>
			<persName><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="6038" to="6048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Estimating causal effects of tone in online debates</title>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A general identification condition for causal effects</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th National Conference on Artificial Intelligence</title>
		<meeting>the 18th National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">LLaMA: Open and efficient foundation language models</title>
		<author>
			<persName><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thibaut</forename><surname>Lavril</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Martinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothée</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baptiste</forename><surname>Rozière</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hambro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Azhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelien</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<idno>CoRR, abs/2302.13971</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">An overview on controllable text generation via variational auto-encoders</title>
		<author>
			<persName><forename type="first">Haoqin</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yitong</forename><surname>Li</surname></persName>
		</author>
		<idno>CoRR, abs/2211.07954</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adapting text embeddings for causal inference</title>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence</title>
		<editor>
			<persName><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">David</forename><surname>Sontag</surname></persName>
		</editor>
		<meeting>the 36th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020-08">Aug 2020</date>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="3" to="06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Desiderata for representation learning: A causal perspective</title>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">275</biblScope>
			<biblScope unit="page" from="1" to="65" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neural causal models for counterfactual identification and estimation</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Muyuan Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">A survey of resource-efficient LLM and multimodal foundation models</title>
		<author>
			<persName><forename type="first">Mengwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wangsong</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongqi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rongjie</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daliang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qipeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingyang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yihao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shihe</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/2401.08092</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">TinyLlama: An open-source small language model</title>
		<author>
			<persName><forename type="first">Peiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangtao</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianduo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno>CoRR, abs/2401.02385</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">DESCN: Deep entire space cross networks for individual treatment effect estimation</title>
		<author>
			<persName><forename type="first">Kailiang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengtong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaorong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenqing</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ling</forename><surname>Cen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Contrastive balancing representation learning for heterogeneous dose-response curves estimation</title>
		<author>
			<persName><forename type="first">Minqin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anpeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoxuan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiecheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Kuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
