<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimating the Causal Effects of Natural Logic Features in Transformer-Based NLI Models</title>
				<funder>
					<orgName type="full">CRUK National Biomarker Centre</orgName>
				</funder>
				<funder ref="#_aeyaamY">
					<orgName type="full">Swiss National Science Foundation</orgName>
					<orgName type="abbreviated">SNSF</orgName>
				</funder>
				<funder ref="#_cxg7RFE">
					<orgName type="full">EPSRC</orgName>
				</funder>
				<funder ref="#_jhaNN8H">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_6u5mqar">
					<orgName type="full">Manchester Experimental Cancer Medicine Centre. Erik Arakelyan</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Julia</forename><surname>Rozanova</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marco</forename><surname>Valentino</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">André</forename><surname>Freitas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">National Biomarker Centre</orgName>
								<orgName type="institution" key="instit2">CRUK-MI</orgName>
								<orgName type="institution" key="instit3">University of Manchester</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Estimating the Causal Effects of Natural Logic Features in Transformer-Based NLI Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rigorous evaluation of the causal effects of semantic features on language model predictions can be hard to achieve for natural language reasoning problems. However, this is such a desirable form of analysis from both an interpretability and model evaluation perspective, that it is valuable to investigate specific patterns of reasoning with enough structure and regularity to identify and quantify systematic reasoning failures in widely-used models. In this vein, we pick a portion of the NLI task for which an explicit causal diagram can be systematically constructed: the case where across two sentences (the premise and hypothesis), two related words/terms occur in a shared context. In this work, we apply causal effect estimation strategies to measure the effect of context interventions (whose effect on the entailment label is mediated by the semantic monotonicity characteristic) and interventions on the inserted word-pair (whose effect on the entailment label is mediated by the relation between these words). Extending related work on causal analysis of NLP models in different settings, we perform an extensive interventional study on the NLI task to investigate robustness to irrelevant changes and sensitivity to impactful changes of Transformers. The results strongly bolster the fact that similar benchmark accuracy scores may be observed for models that exhibit very different behaviour. Moreover, our methodology reinforces previously suspected biases from a causal perspective, including biases in favour of upward-monotone contexts and ignoring the effects of negation markers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There is an abundance of reported cases where high accuracies in NLP tasks can be attributed to simple heuristics and dataset artifacts <ref type="bibr">(McCoy et al., 2019a)</ref>. As such, when we expect a language model to capture a specific reasoning strategy or correctly use certain semantic features, it has become good practice to perform evaluations that provide a more granular and qualitative view into model behaviour and efficacy. In particular, there is a trend in recent work to incorporate causal measures and interventional experimental setups in order to better understand the captured features and reasoning mechanisms of NLP models <ref type="bibr" target="#b23">(Vig et al., 2020;</ref><ref type="bibr" target="#b1">Finlayson et al., 2021;</ref><ref type="bibr" target="#b22">Stolfo et al., 2023;</ref><ref type="bibr" target="#b3">Geiger et al., 2021;</ref><ref type="bibr" target="#b20">Rozanova et al., 2023;</ref><ref type="bibr">Arakelyan et al., 2024)</ref>.</p><p>In general, it can be hard to pinpoint all the intermediate features and critical representation elements which are guiding the inference behind an NLP task. However, in many cases there are subtasks which have enough semantic/logical regularity to perform stronger analyses and diagnose clear points of failure within larger tasks such as NLI and QA (Question Answering). As soon as we are able to draw a causal diagram which captures a portion of the model's expected reasoning capabillities, we may be guided in the design of interventional experiments which allow us to estimate causal quantities of interest, giving insight into how different aspects of the inputs are used by models.</p><p>In this work, we investigate a structured subset of the NLI task <ref type="bibr" target="#b18">(Rozanova et al., 2022)</ref> to better understand the use of two semantic inference features by NLI models: concept relations and logical monotonicity. We use these intermediate abstracted semantic feature labels to construct intervention sets out of NLI examples which allow us to measure certain causal effects. Building upon recent work on causal analysis of NLP models <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref>, we use the intervention sets to systematically and quantitatively characterise models' sensitivity to relevant changes in these semantic features and robustness to irrelevant changes.</p><p>Our contributions may be summarised as follows:</p><p>• Extending previous work on causal analysis of NLP models, we investigate a structured subproblem in NLI (in our case, a subtask based on natural logic <ref type="bibr" target="#b9">(MacCartney and Manning, 2007)</ref>) and present a causal diagram which captures both desired and undesired potential reasoning routes which may describe model behaviour.</p><p>• We adapt the NLI-XY dataset of <ref type="bibr" target="#b18">Rozanova et al. (2022)</ref> to a meaningful collection of intervention sets which enable the computation of certain causal effects.</p><p>• We calculate estimates for undesired direct arXiv:2404.02622v1 [cs.CL] 3 Apr 2024 causal effects and desired total causal effects, which also serve as a quantification of model robustness and sensitivity to our intermediate semantic features of interest.</p><p>• We compare a suite of BERT-like NLI models, identifying behavioural weaknesses in highperforming models and behavioural advantages in some worse-performing ones.</p><p>To the best of our knowledge, we are the first to complement previous observations of models' brittleness with respect to context monotonicity with the evidence of causal effect measures 1 , as well as presenting new insights that over-reliance on lexical relations is consequently also tempered by the same improvement strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Formulation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">A Structured NLI Subtask</head><p>As soon as we have a concrete description of how a reasoning problem should be treated, we can begin to evaluate how well a model emulates the expected behaviour and whether it is capturing the semantic abstractions at play.</p><p>In this work, we consider an NLI subtask which comes from the broader setting of Natural Logic <ref type="bibr" target="#b9">(MacCartney and Manning, 2007;</ref><ref type="bibr" target="#b6">Hu and Moss, 2018;</ref><ref type="bibr" target="#b21">Sánchez, 1991)</ref>. As it has a rigid and well-understood structure, it is often used in interpretability and explainability studies for NLI models <ref type="bibr" target="#b3">(Geiger et al., 2021;</ref><ref type="bibr">Richardson et al., 2019a;</ref><ref type="bibr" target="#b5">Geiger et al., 2022;</ref><ref type="bibr" target="#b18">Rozanova et al., 2022</ref><ref type="bibr" target="#b19">Rozanova et al., , 2021))</ref>. We begin with the format described in <ref type="bibr" target="#b18">(Rozanova et al., 2022)</ref>  A semantic property of the natural language context called monotonicity determines whether there 1 Our code is available at <ref type="url" target="https://github.com/juliarozanova/counterfact_nli">https://github.com/julia rozanova/counterfact_nli</ref>.  Variable Description</p><formula xml:id="formula_0">G Gold Label C Context M Context Monotonicity W Inserted Word Pair R Word-Pair Relation C M W R G Figure 1: Causal Diagram for the Natural Logic Subtask</formula><p>is an entailment relation between the sentences generated upon substitution/insertion of given related terms (formally, this is monotonicity in the sense of preserving the "order" between the inserted terms to an equally-directed entailment relation between the sentences.) The context monotonicity may either be upward (↑) or downward (↓, as in the example above) or neither.</p><p>The effect of the context's monotonicity in conjunction with the relation between the inserted words on the gold entailment label is summarised in table 1. The authors of <ref type="bibr" target="#b18">Rozanova et al. (2022)</ref> provide a thus-formatted dataset called NLI-XY, which we use as the basis for our causal effect estimation experiments.</p><p>Throughout the remainder of this paper, we will represent an NLI-XY example n as a tuple n = (c, m, w, r, g) in which c is the shared natural language context, m is its monotonicity label, w is a pair (w 1 , w 2 ) of nouns/noun phrases which will be inserted into the context (we refer to these as the inserted word pair for brevity), r is the concept inclusion relation label for w and g is the entailment gold label arising from m and r as per table 1. We denote by P (Y | C = c, W = w) the probabilistic output of a trained NLI model with the example n as the NLI input (in particular, the input is the premise-hypothesis pair (c(w 1 ), c(w 2 ))).</p><p>As we have chosen a coarse segmentation of the monotonicity reasoning problem, we can present a simple causal diagram which illustrates our expectations for the correct reasoning scheme for a fixed class of NLI problems. The diagram in figure <ref type="figure">1</ref> shows the features on which the gold label is dependent on in the NLI-XY dataset: only the context monotonicity M and the concept pair relation R, which are respectively dependent on the content of the natural language context C and the concept pair / word pair W which is substituted into it. The exact values of the gold label with respect to these features may be referenced in table <ref type="table" target="#tab_2">1</ref>.</p><p>Naturally, it is always likely that models may fail to follow the described reasoning scheme for these NLI problems. In the next section (2.2), we propose a causal diagram which also captures the reasoning possibilities an NLI model may follow, accounting for possible confounding heuristics via unwanted direct effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">The Causal Structure of Model Decision-Making</head><p>In an ideal situation, a strong NLI model would identify the word-pair relation and the context monotonicity as the abstract variables relevant to the final entailment label. In this case, these features would causally affect the model prediction in the same way they affect the gold label. Realistically, as shown in illuminating studies such as <ref type="bibr">McCoy et al. (2019b)</ref>, models identify unexpected biases in the dataset and may end up using accidental correlations output labels, such as the frequency of certain words in a corpus. For example, Richard T. <ref type="bibr" target="#b15">McCoy (2019)</ref> demonstrate how models can successfully exploit the presence of negation markers to anticipate non-entailment, even when it is not semantically relevant to the output label.</p><p>To ensure that the semantic features themselves are taken account into the model's output and not other surface-level confounding variables, one would like to perform interventional studies which alter the value of the target feature but not other confounding variables. This is, in many cases, not feasible (although attempts are sometimes made to at least perform interventions that only make minimal changes to the textual surface form, as in <ref type="bibr" target="#b8">Kaushik et al. (2020)</ref>.) <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref> argue that it is useful to quantify instead the direct impact of irrelevant surface changes (controlling for values of semantic variables of interest) and compare them to total causal effects of input-level changes: doing so, we may posit deductions about the flow of information via the semantic variables (or lack thereof). For analyses where there is an attempt to align intermediate variables with explicit internals, see <ref type="bibr" target="#b23">Vig et al. (2020)</ref> and <ref type="bibr" target="#b1">Finlayson et al. (2021)</ref> for a mediation analysis approach, or <ref type="bibr" target="#b3">Geiger et al. (2021)</ref> for an alignment strategy based on causal abstraction theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variable</head><p>Description Diagram Specification We follow <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref> in the strategy of explicitly modeling the "irrelevant surface form" of the input text portions as variables in the causal diagram. Their setting of math word problems is decomposed into two compositional inputs: a question template and two integer arguments. Our setting follows much the same structure: our natural language "context" plays the same role as their "template", but our arguments (an inserted word pair) have an additional layer of complexity as we also model the relation between the arguments as an intermediate reasoning variable rather than the values themselves (as such, the structure of their template modeling in their causal diagram is more applicable than the direct way they treat their numerical arguments.) We present our own causal diagram in figure 2. We introduce the textual context C as an input variable, which is further decomposed into more abstract variables: its monotonicity M (which directly affects the gold truth G) and the textual surface form S of the context . The other input variable is the word-pair insertion which we will summarise as a single variable W . Once again, W has a potential effect on the model decision through its textual surface form T and via the relation R between the words. The gold truth G is dependent on M and R only. Finally, the outcome variable is the model prediction Y . The paths for which we would like to observe the highest causal effect are the paths to Y from the inputs via M, R and through the gold truth variable G. However, each of S, T, M and R have direct links to the model output Y as well (indicated in red): these are potential direct effects which are unwanted. For example, we would not want a model to learn a prediction heuristic based directly on the variable M , such as consistently predicting non-entailment any time a downward monotone context is recognised. Similarly, a direct effect of S or T would look like a heuristic which predicts the entailment label purely based on the presence of words which happened to co-occur with that label in the training data. The key goal of this study is to compare the extent to which models exhibit the high causal effects for the desired diagram routes and lower causal effects for the undesired routes.</p><formula xml:id="formula_1">Y Model Prediction G Gold Label C Context M Context Monotonicity S Context Textual Surface Form W Inserted Word Pair R Word-Pair Relation T Word-Pair Textual Surface Form C S M W T R G Y</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Estimating the Causal Effects</head><p>Given a fixed set N of NLI-XY examples, we define an intervention I on N as a set of pairs (n, n ′ ) of NLI-XY examples for (one for each n ∈ N ), where n ′ = (c ′ , m ′ , w ′ , r ′ , g ′ ) is a second NLI-XY example which represents a modified version of n (in practice, a modification of either c or w). We denote by N ′ the set of modified NLI-XY examples, so that I ⊆ N × N ′ .</p><p>For any pair (n, n ′ ) ∈ I , we define the changeof-prediction indicator</p><formula xml:id="formula_2">CP (n, n ′ ) = 1 if y ̸ = y ′ 0 if y = y ′ ,</formula><p>where</p><formula xml:id="formula_3">y = arg max i∈{0,1} P (Y = i | C = c, W = w)</formula><p>(namely, the model prediction which assigns the entailment label with the highest predicted probability) and</p><formula xml:id="formula_4">y ′ = arg max i∈{0,1} P (Y = i | C = c ′ , W = w ′ ).</formula><p>Stolfo et al. ( <ref type="formula">2023</ref>) refer to the average change-ofprediction quantity for a given intervention I as a causal effect. This causal effect quantity is named and interpreted differently depending on the conditions of the intervention: in particular, which variables are changed and which are kept constant throughout the intervention set over which we will take the average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Interventions for Calculating TCE and DCE</head><p>The quantities of interest in <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref> are the total causal effect (TCE) of interventions on the variables which we would like to see having an effect on the prediction (in our case, C and W ) and the direct causal effect (DCE) of interventions on the variables which we do not wish to unnecessarily impact the model prediction (in our case, T and S).</p><p>For a given source variable and target variable, whether we are measuring a DCE or TCE differs only in the design of the intervention set, which in turn depends on the structure of the causal diagram. For the design of the relevant intervention sets, we follow the strategy in <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref>, as the upper portion of their causal diagram (concerning the natural language question template, its textual surface form and the implicit math operation) is equivalent to both the upper and lower half of our diagram in figure <ref type="figure" target="#fig_0">2</ref>.</p><p>In this work, we provide four intervention sets: </p><formula xml:id="formula_5">I 0 , I 1 , I 2 , I 3 ,</formula><formula xml:id="formula_6">(c ̸ = c ′ , m ̸ = m ′ , w = w ′ , r = r ′ , g ̸ = g ′ ).</formula><p>We then calculate:</p><formula xml:id="formula_7">TCE(C on Y ) = 1 |I 0 | (n,n ′ )∈I0 CP (n, n ′ )</formula><p>Secondly, we estimate the total causal effect of the inserted word pair W on the model prediction Y by constructing an intervention set I 1 as follows: starting with a randomly sampled set N of NLI-XY examples, we intervene on each n ∈ N by sampling a different inserted word pair w ′ from the NLI-XY dataset which should result in a changed prediction, while keeping the shared context c constant. In summary, every (n, n ′ ) ∈ I 1 satisfies</p><formula xml:id="formula_8">(c = c ′ , m = m ′ , w ̸ = w ′ , r ̸ = r ′ , g ̸ = g ′ ).</formula><p>We then calculate:</p><formula xml:id="formula_9">TCE(W on Y ) = 1 |I 1 | (n,n ′ )∈I1 CP (n, n ′ )</formula><p>Following <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref>, we interpret this quantity as a measure of model sensitivity to relevant context (respectively, inserted word pair) changes. As it quantifies how often the prediction changes when it should, we would like to see this value being as close to 1 as possible.</p><p>(Undesired) Direct Causal Effects The total causal effect does not distinguish whether this effect is mediated through the preferred causal route (for example, via context's monotonicity) or through a model heuristic based on the textual surface form: it is taking into account all possible routes of influence. The key suggestion in <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref> is that even though we have no feasible intervention strategies which allow us to calculate the causal effect of the intermediate variables M and R on Y as mediated through the gold label G (the effect of greatest interest to us), we may yield some insight into their causal influence by comparing the relevant TCE to the unwanted direct causal effect DCE (S → Y ) ( respectively, DCE (T → Y )).</p><p>To estimate the direct causal effect of the textual surface form S of the context C which is irrelevant to the context monotonicity M , we construct an intervention set I 2 as follows: starting with a randomly sampled set N of NLI-XY examples, we intervene on each n ∈ N by sampling a different context c ′ from the NLI-XY dataset while conditioning on the monotonicity (specifically, c ′ is chosen so that its monotonicity attribute m ′ is the same as that of c). The word pair w ′ (and therefore its relation r ′ ) are kept the same as in n, so the prediction is expected not to change. In summary, every</p><formula xml:id="formula_10">(n, n ′ ) ∈ I 2 satisfies (c ̸ = c ′ , m = m ′ , w = w ′ , r = r ′ , g = g ′ ).</formula><p>We then calculate:</p><formula xml:id="formula_11">DCE(S → Y ) = 1 |I 2 | (n,n ′ )∈I2 CP (n, n ′ )</formula><p>To estimate the direct causal effect of the textual surface form T of the inserted word pair W which is irrelevant to the word pair relation R, we construct an intervention set I 3 as follows: starting with a randomly sampled set N of NLI-XY examples, we intervene on each n ∈ N by sampling a different inserted word pair w ′ from the NLI-XY dataset while conditioning on the word pair relation (specifically, w ′ is chosen so that its relation attribute r ′ is the same as that of w). The context c ′ (and therefore its monotonicity m ′ ) are kept the same as in n, so the prediction is expected not to change. In summary, every (n, n ′ ) ∈ I 3 satisfies</p><formula xml:id="formula_12">(c = c ′ , m = m ′ , w ̸ = w ′ , r = r ′ , g = g ′ ).</formula><p>We then calculate:</p><formula xml:id="formula_13">DCE(T → Y ) = 1 |I 3 | (n,n ′ )∈I3 CP (n, n ′ )</formula><p>Once again following <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref>, we interpret this quantity as a measure of model robustness to irrelevant context (respectively, inserted word pair) changes. As it quantifies how often the prediction changes in cases when it shouldn't, we would like to see this value being as close to 0 as possible. We present examples and dataset statistics for the intervention sets in the next section, along with the summary of the intervention schema in table 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data and Interventions</head><p>We use the NLI-XY evaluation dataset to construct intervention pairs (n, n ′ ) by using a sampling/filtering strategy as in <ref type="bibr" target="#b22">(Stolfo et al., 2023)</ref> according to the intervention schema in table 4. In particular, for constructing context interventions, we sample a seed set of 400 NLI-XY premise/hypothesis pairs. This is the preintervention NLI example. For each, we fix the insertion pair and filter through the NLI-XY dataset for all examples with the shared insertion pair but different context, conditioned as necessary on the properties of the other variables as in the intervention schema. For insertion pairs, we do the opposite. The number of interventions we produce in this way for our experiments are reflected in the last column of table 4. In summary, the changes are context replacements and related word-pair replacements; we provide text-level examples in tables 2 and 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model Choice and Benchmark Comparison</head><p>We include the following models<ref type="foot" target="#foot_1">foot_1</ref> in our study: firstly, the models evaluated in NLI-XY pa- </p><formula xml:id="formula_14">Intervention Set Target Measure C W M R G Interventions in Dataset I0 TCE (C → Y ) ̸ = = ̸ = = ̸ = 14270 I1 TCE (W → Y ) = ̸ = = ̸ = ̸ = 22640 I2 DCE (S → Y ) ̸ = = = = = 20910 I3 DCE (T → Y ) = ̸ = = = = 25960</formula><p>Table <ref type="table">4</ref>: Intervention schema and dataset statistics: which variables are held constant and which are changed in the construction of intervention sets for the calculation of the indicated effects.</p><p>per <ref type="bibr" target="#b18">(Rozanova et al., 2022)</ref>, namely roberta-largemnli, facebook/bart-large-mnli, bert-base-uncasedsnli and their counterparts fine-tuned on the HELP dataset <ref type="bibr">(Yanaka et al., 2019b)</ref> Next, the infobert model, which is trained on three benchmark training sets of interest: MNLI <ref type="bibr">(Williams et al., 2018)</ref>, <ref type="bibr">SNLI (Bowman et al., 2015)</ref> and ANLI <ref type="bibr" target="#b13">(Nie et al., 2020</ref>) (currently at the top of the leaderboard for the adversarial ANLI test set, as of January 2023) Lastly, another roberta-large checkpoint, also trained on all three benchmark NLI training training sets (as well as FEVER-NLI <ref type="bibr" target="#b12">(Nie et al., 2019)</ref>). We report their scores on the mentioned benchmark datasets alongside the relevant total and direct causal effects we are interested in.</p><p>Note that as the HELP dataset is a two-class entailment dataset (as opposed to datasets like MNLI, which are three-class), we cannot directly compare existing reported scores. As such, we adapt the three-class scores to a two-class score by grouping two of the three-class labels ("contradiction" and "neutral") into the two-class umbrella label "non-entailment".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussion</head><p>We examine and compare the results for the models listed in 4.2. We first observe the word-pair insertion intervention experiments in 5.1, then the context intervention experiments in 5.2 and finally present a categorical overview of these results in section 5.3, contextualised by benchmark scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Causal Effect of Inserted Word Pairs</head><p>The results for the substituted word-pair intervention experiment are reported in figure <ref type="figure" target="#fig_2">3</ref>. The most desireable outcome is a DCE(T → Y ) which is as low as possible in combination with a TCE(W on Y ) which is as high as possible. The lower this DCE, the higher the model robustness to irrelevant word pair surface form changes. On the other hand, the higher the specified TCE, the greater the model's sensitivity to word pair insertion changes affecting the gold label.</p><p>The largest delta between these two quantities can be seen in the roberta-large-mnli-help and facebook-bart-large-mnli-help models. This is important to note: the HELP dataset <ref type="bibr">(Yanaka et al., 2019b)</ref> is explicitly designed to bolster model success on natural logic problems, but until now there has been little to no evidence that it improves the treatment of word-pair relations. In particular, the internal probing results in <ref type="bibr" target="#b18">Rozanova et al. (2022)</ref> show that probing performance for the intermediate word-pair relation label decreases slightly for roberta-large-mnli after fine-tuning on HELP; as such, it was thought that the HELP improvements on natural logic could solely be attributed to improved context monotonicity treatment. Now, however, we observe distinct improvements in ro-   <ref type="formula">2022</ref>) does indicate that the large MNLI-based models are already very successful in distinguishing the relation between substituted words. The word-pair relation label has a high probing result for all of these models, as well as strong signs of systematicity in their error analysis. This is in line with our observations of relatively large deltas between the DCE and TCE here, compared to the smaller BERT-based models.</p><formula xml:id="formula_15">DCE (T → Y) TCE (W on Y) Model DCE(T → Y ) TCE(W on Y ) TCE/DCE</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Causal Effect of Contexts</head><p>The results for the context intervention experiments are reported in figure <ref type="figure" target="#fig_3">4</ref>. The most desireable outcome is a DCE(S → Y ) which is as low as possible in combination with a TCE(C on Y ) which is as high as possible. For context interventions, we start to see major distinctions in the sensitivity of models to important context changes -especially the effect of the HELP fine-tuning dataset in increasing model reasoning with respect to context structure. In line with previous behavioural findings in <ref type="bibr">Richardson et al. (2019a)</ref>; <ref type="bibr">Yanaka et al. (2019b,a)</ref>; <ref type="bibr" target="#b4">Geiger et al. (2020)</ref>; <ref type="bibr" target="#b18">Rozanova et al. (2022)</ref> and all the way back to <ref type="bibr" target="#b24">Wang et al. (2018)</ref>, which observe systematic failure of large language models in downward monotone contexts, we notice that all of the models trained only on the large benchmarks sets fail to correctly change their prediction when a context change requires it to do so (as indicated by the low TCE score). In <ref type="bibr">Yanaka et al. (2019b)</ref>, <ref type="bibr" target="#b18">Rozanova et al. (2022)</ref> and <ref type="bibr" target="#b19">Rozanova et al. (2021)</ref>, the posi-  tive effect of the HELP dataset is already evident, but here we may also compare it to roberta-largemnli tuned on many additional training sets, precluding the possibility that its helpfulness can be attributed only to a larger amount of training data. We note that although the situation of the TCE/DCE ratio for roberta-large-mnli being less than one may seem peculiar, it is important to keep in mind that the intervention sets used for estimating these quantities are sampled independently so some margin of error is warranted. As in <ref type="bibr" target="#b22">Stolfo et al. (2023)</ref>, we interpret this result to simply mean that the causal influence is comparable whether we are affecting the ground truth result (as in the TCE(C on Y ) case) or not (as in the DCE(S → Y ) case).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Benchmark Scores and Causal Effects</head><p>A summary of the performance of all models on popular benchmarks alongside a categorical breakdown of robustness and sensitivity is presented in table <ref type="table" target="#tab_8">5</ref>. The robustness/sensitivity categories are a qualitative assessment, identifying the lowest and highest scores within a category, and categorising other models correspondingly as low, mid or high performers for the given categories. The sensitivity property is tied to the desired total causal effect, while the robustness property is tied to the undesired direct causal effect (note in particular that the latter is judged as inversely proportional: the model with the lowest given DCE is judged the "highest" in terms of robustness).</p><p>The key observation is that the models which  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related Work</head><p>Natural Logic Handling in NLI Models It has been known for some time that large NLI models are frequently tripped up by downward-monotone reasoning <ref type="bibr">(Richardson et al., 2019b;</ref><ref type="bibr" target="#b24">Wang et al., 2018;</ref><ref type="bibr">Yanaka et al., 2019b;</ref><ref type="bibr" target="#b18">Rozanova et al., 2022;</ref><ref type="bibr" target="#b4">Geiger et al., 2020)</ref>. Various datasets have been created to evaluate and improve this behaviour, such as HELP <ref type="bibr">(Yanaka et al., 2019b)</ref>, MoNLI <ref type="bibr" target="#b4">(Geiger et al., 2020)</ref>, MQNLI <ref type="bibr" target="#b2">(Geiger et al., 2019)</ref>, MED <ref type="bibr">(Yanaka et al., 2019a)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>The results strongly bolster the fact that similar benchmark accuracy scores may be observed for models that exhibit very different behaviour, especially concerning specific semantic reasoning patterns and higher-level properties such as robustness/sensitivity to target features. In this work, we have been able to causally investigate previously suspected biases in NLI models. For example, previous observations <ref type="bibr" target="#b18">(Rozanova et al., 2022;</ref><ref type="bibr">Yanaka et al., 2019a</ref>) that roberta-large-mnli is biased in favour of assuming upward-monotone contexts, ignoring the effects of things like negation markers, agrees with our observations that it exhibits poor context sensitivity. Furthermore, the causal flavour of the study adds a complimentary narrative to works that investigate model internals via probing <ref type="bibr" target="#b18">(Rozanova et al., 2022)</ref> and observe the presence/absence of intermediate semantic features in the models' representation. Instead of merely suggesting that these features are captured, we can gain insight into their causal influence via connected causal effect estimates. The causal measures presented here show us that even the highest-performing models can systematically fail to adapt their predictions to changing context structure, suggesting an over-reliance on word relations across the premise and hypothesis. Finally, we have also added the observation that existing strategies to improve responsiveness to context changes also increase the robustness word-pair insertion changes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Specification of the causal diagram for possible routes of model reasoning for NLI-XY problems. Green edges indicate desired causal influence, while red edges indicate undesired paths of causal influence via surface-level heuristics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>each corresponding to the quantities TCE (C on Y ), TCE (W on Y ), DCE (T → Y ) and DCE (S → Y ) respectively. 2 We stick to their nomenclature of total causal effect (TCE) and direct causal effect (DCE), but define the quantities in the way that they are concretely calculated (in both our experiments and in Stolfo et al. (2023)): as an estimate of the causal effect quantity, which they present as an expected value of the changeof-prediction indicator. (Desired) Total Causal Effects We estimate the total causal effect of the context C on the model prediction Y by constructing an intervention set I 0 as follows: starting with a randomly sampled set N of NLI-XY examples, we intervene on each n ∈ N by sampling a different context c ′ from the NLI-XY dataset which should result in a changed prediction, while keeping the inserted word pair w constant. In summary, every (n, n ′ ) ∈ I 0 satisfies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Results for Insertion Interventions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Results for Context Interventions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>(we refer to this work for more detailed description and full definitions).</figDesc><table><row><cell cols="4">Consider two terms/concepts with a known relation</cell></row><row><cell cols="3">label, such as one of the pairs:</cell></row><row><cell cols="4">Word/Term x Word/Term y Relation</cell></row><row><cell cols="2">brown sugar</cell><cell>sugar</cell><cell>x ⊑ y</cell></row><row><cell>mammal</cell><cell></cell><cell>lion</cell><cell>x ⊒ y</cell></row><row><cell cols="2">computer</cell><cell>pomegranate</cell><cell>x#y</cell></row><row><cell cols="4">Suppose the two terms occur in an identical context</cell></row><row><cell cols="4">(comprising of a natural language sentence, like a</cell></row><row><cell cols="3">template), for example:</cell></row><row><cell>Premise</cell><cell cols="3">I do not have any sugar.</cell></row><row><cell cols="4">Hypothesis I do not have any brown sugar.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The entailment gold labels as a function of two semantic features: the context montonicity (M) and the relation (R) of the inserted word pair.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Example word-pair insertion interventions for determining the total causal effect of label-relevant word-pair changes and the direct causal effect of label-irrelevant word-pair changes.</figDesc><table><row><cell>Intervention</cell><cell cols="2">Target Quantity Intervention</cell><cell>Premise</cell><cell>Hypothesis</cell><cell cols="2">M R G</cell></row><row><cell>Set</cell><cell></cell><cell>Step</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>I 1</cell><cell>TCE(W on Y )</cell><cell>Before After</cell><cell>There's a cat on the pc. There's a cat on the tree.</cell><cell>There's a cat on the machine. There's a cat on the fruit tree.</cell><cell>↑ ↑</cell><cell>⊑ Entailment ⊒ Non-Entailment</cell></row><row><cell>I 3</cell><cell>DCE(T → Y )</cell><cell>Before</cell><cell>There are no students yet.</cell><cell>yet. There are no first-year students</cell><cell>↓</cell><cell>⊒ Entailment</cell></row><row><cell></cell><cell></cell><cell>After</cell><cell>There are no people yet.</cell><cell>There are no women yet.</cell><cell>↓</cell><cell>⊒ Entailment</cell></row><row><cell>Intervention</cell><cell cols="2">Target Quantity Intervention</cell><cell>Premise</cell><cell>Hypothesis</cell><cell cols="2">M R G</cell></row><row><cell>Set</cell><cell></cell><cell>Step</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>I 0</cell><cell>TCE(C on Y )</cell><cell>Before</cell><cell>You can't live without fruit .</cell><cell>ries . You can't live without strawber-</cell><cell>↑</cell><cell>⊒ Non-Entailment</cell></row><row><cell></cell><cell></cell><cell>After</cell><cell>All fruit study English.</cell><cell>All strawberries study English.</cell><cell>↓</cell><cell>⊒ Entailment</cell></row><row><cell>I 2</cell><cell>DCE(S → Y )</cell><cell>Before After</cell><cell>He has no interest in seafood . I don't want to argue about this</cell><cell>He has no interest in oysters . I don't want to argue about this</cell><cell>↓ ↓</cell><cell>⊒ Entailment ⊒ Entailment</cell></row><row><cell></cell><cell></cell><cell></cell><cell>in front of seafood .</cell><cell>in front of oysters .</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Example context interventions for determining the total causal effect of label-relevant context changes and the direct causal effect of label-irrelevant context changes.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Overall 2 class accuracy on original NLI benchmarks and qualitative comparison against the performed causal intervention analysis. The accuracy is not necessarily predictive of the performances achieved using a systematic causal inspection.</figDesc><table><row><cell>achieve the highest performance on benchmarks</cell></row><row><cell>may be far from the best performers with respect</cell></row><row><cell>to our quantitative markers of strong reliance of im-</cell></row><row><cell>portant causal features. In particular, models such</cell></row><row><cell>as infobert are outperformed in our behavioural</cell></row><row><cell>causal effect analyses by weaker models that are</cell></row><row><cell>fine-tuned on a relatively small helper dataset such</cell></row><row><cell>as HELP. It is important to note that such changes</cell></row><row><cell>coincide with drops in benchmarks performance</cell></row><row><cell>too, but any model interventions that discourage</cell></row><row><cell>the exploitation of heuristics (evident from a lower</cell></row><row><cell>DCE for surface form features) may have that ef-</cell></row><row><cell>fect.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Causal Analysis in NLP Causal modelling has appeared in NLP works in various forms, such as the investigations of the causal influence of data statistics(Elazar et al., 2022)  and mediation analyses<ref type="bibr" target="#b23">(Vig et al., 2020;</ref><ref type="bibr" target="#b1">Finlayson et al., 2021)</ref> which link intermediate linguistic/semantic features to model internals.<ref type="bibr" target="#b22">Stolfo et al. (2023)</ref>, our core reference, appears to be the first to use explicitly causal effect measures as indicators of sensitivity and robustness (for some non-causal approaches to measuring model robustness in NLP, we point to<ref type="bibr" target="#b7">Jin et al. (2019)</ref> and Ribeiro et al. (2020)). For a fuller summary of the use of causality in NLP, please see the survey by<ref type="bibr" target="#b0">Feder et al. (2022)</ref>. Specific to natural logic, works with causal approaches include<ref type="bibr" target="#b4">Geiger et al. (2020)</ref> (which perform interchange interventions at a token representation level),<ref type="bibr" target="#b3">Geiger et al. (2021)</ref> (where an ambitious causal abstraction experiment attempts to align model internals with candidate causal models) and the works of<ref type="bibr" target="#b4">Geiger et al. (2020)</ref> and<ref type="bibr" target="#b27">Wu et al. (2022)</ref>, (where attempts are made to build a prescribed causal structure into models themselves). In particular,<ref type="bibr" target="#b27">Wu et al. (2022)</ref> create a "causal proxy model" which becomes the basis for a new explainable predictor designed to replace the original neural network.</figDesc><table><row><cell>. Rozanova</cell></row><row><cell>et al. (2022) introduced NLI-XY, secondary compo-</cell></row><row><cell>sitional dataset built from portions of MED, where</cell></row><row><cell>the intermediate features of context monotonicity</cell></row><row><cell>and concept relations are explicitly labelled: this</cell></row><row><cell>is the dataset we use in this work. Non-causal</cell></row><row><cell>structural analyses of model internals with respect</cell></row><row><cell>to natural logic features include Rozanova et al.</cell></row><row><cell>(2022) (a probing study), but we leave to the next</cell></row><row><cell>section some existing works where natural logic</cell></row><row><cell>intersects with the world of causal approaches to</cell></row><row><cell>NLP.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>To be consistent with the notation in<ref type="bibr" target="#b22">Stolfo et al. (2023)</ref>, we will stylize these quantities as (for example) TCE(C on Y ) and DCE(S → Y ), where the arrow emphasizes that the quantity is specific to a direct path in the causal diagram (passing through no intermediate variables).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1"><p>All pretrained models are from the Huggingface transformers library<ref type="bibr" target="#b26">(Wolf et al., 2020)</ref>, except for infobert and the pretrained model counterparts fine-tuned on HELP: their sources are linked in the README of the accompanying code.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was partially funded by the <rs type="funder">Swiss National Science Foundation (SNSF)</rs> project <rs type="projectName">Neu-Math</rs> (<rs type="grantNumber">200021_204617</rs>), by the <rs type="funder">EPSRC</rs> grant <rs type="grantNumber">EP/T026995/1</rs> entitled "<rs type="projectName">EnnCore: End-to-End Conceptual Guarding of Neural Architectures</rs>" under Security for all in an AI enabled society, by the <rs type="funder">CRUK National Biomarker Centre</rs>, and supported by the <rs type="funder">Manchester Experimental Cancer Medicine Centre. Erik Arakelyan</rs>, <rs type="person">Zhaoqi Liu</rs>, and <rs type="person">Isabelle Augenstein</rs>. 2024. Semantic sensitivities and inconsistent predictions: Measuring the fragility of NLI models. In Proceedings of the 18th Conference of the European Chapter of the <rs type="programName">Association for Computational Linguistics (Volume 1: Long Papers</rs>), pages <rs type="grantNumber">432-444</rs>, <rs type="institution">St. Julian's, Malta. Association for Computational Linguistics</rs>. <rs type="person">Samuel R Bowman</rs>, <rs type="person">Gabor Angeli</rs>, <rs type="person">Christopher Potts</rs>, and <rs type="person">Christopher D Manning</rs>. 2015. A large annotated corpus for learning natural language inference. In EMNLP. <rs type="person">Yanai Elazar</rs>, <rs type="person">Nora Kassner</rs>, <rs type="person">Shauli Ravfogel</rs>, <rs type="person">Amir Feder</rs>, <rs type="person">Abhilasha Ravichander</rs>, <rs type="person">Marius Mosbach</rs>, <rs type="person">Yonatan Belinkov</rs>, <rs type="person">Hinrich Schütze</rs>, and <rs type="person">Yoav Goldberg</rs>. <rs type="grantNumber">2022</rs>. <rs type="projectName">Measuring causal effects of data statistics on language model</rs>'s 'factual' predictions.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_aeyaamY">
					<idno type="grant-number">200021_204617</idno>
					<orgName type="project" subtype="full">Neu-Math</orgName>
				</org>
				<org type="funded-project" xml:id="_cxg7RFE">
					<idno type="grant-number">EP/T026995/1</idno>
					<orgName type="project" subtype="full">EnnCore: End-to-End Conceptual Guarding of Neural Architectures</orgName>
				</org>
				<org type="funding" xml:id="_6u5mqar">
					<idno type="grant-number">432-444</idno>
					<orgName type="program" subtype="full">Association for Computational Linguistics (Volume 1: Long Papers</orgName>
				</org>
				<org type="funded-project" xml:id="_jhaNN8H">
					<idno type="grant-number">2022</idno>
					<orgName type="project" subtype="full">Measuring causal effects of data statistics on language model</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Causal inference in natural language processing: Estimation, prediction, interpretation and beyond</title>
		<author>
			<persName><forename type="first">Amir</forename><surname>Feder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emaad</forename><surname>Manzoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reid</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dhanya</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zach</forename><surname>Wood-Doughty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Grimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Veitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00511</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1138" to="1158" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Causal analysis of syntactic agreement mechanisms in neural language models</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.144</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1828" to="1843" />
		</imprint>
	</monogr>
	<note>Long Papers). Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Posing fair generalization tasks for natural language inference</title>
		<author>
			<persName><forename type="first">Atticus</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ignacio</forename><surname>Cases</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lauri</forename><surname>Karttunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1456</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4485" to="4495" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Causal abstractions of neural networks</title>
		<author>
			<persName><forename type="first">Atticus</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanson</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9574" to="9586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural natural language inference models partially embed theories of lexical entailment and negation</title>
		<author>
			<persName><forename type="first">Atticus</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.blackboxnlp-1.16</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="163" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inducing causal structure for interpretable neural networks</title>
		<author>
			<persName><forename type="first">Atticus</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanson</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josh</forename><surname>Rozner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisa</forename><surname>Kreiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="7324" to="7338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Polarity computations in flexible categorial grammar</title>
		<author>
			<persName><forename type="first">Hai</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Larry</forename><surname>Moss</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S18-2015</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the Seventh Joint Conference on Lexical and Computational Semantics<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="124" to="129" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Di</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Szolovits</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11932</idno>
		<title level="m">Is bert really robust? natural language attack on text classification and entailment</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning the difference that makes a difference with counterfactually augmented data</title>
		<author>
			<persName><forename type="first">Divyansh</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Natural logic for textul inference</title>
		<author>
			<persName><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</title>
		<meeting>the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</meeting>
		<imprint>
			<publisher>Prague. Association for Computational Linguistics</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">2019a. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1334</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="3428" to="3448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">2019b. Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1334</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="3428" to="3448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining fact extraction and verification with neural semantic matching networks</title>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haonan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adversarial nli: A new benchmark for natural language understanding</title>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Beyond accuracy: Behavioral testing of NLP models with CheckList</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tongshuang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.442</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Non-entailed subsequences as a challenge for natural language inference</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">T</forename><surname>Tal Linzen</surname></persName>
		</author>
		<author>
			<persName><surname>Mccoy</surname></persName>
		</author>
		<idno type="DOI">10.7275/9hfp-2974</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="358" to="360" />
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts Amherst Libraries</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Probing natural language inference models through semantic fragments</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">S</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Probing natural language inference models through semantic fragments</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><forename type="middle">S</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno>CoRR, abs/1909.07521</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decomposing natural logic inferences for neural NLI</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Rozanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mokanarangan</forename><surname>Thayaparan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Valentino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Freitas</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.blackboxnlp-1.33</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Black-boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the Fifth Black-boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Abu Dhabi</addrLine></address></meeting>
		<imprint>
			<publisher>United Arab Emirates (Hybrid). Association for Computational Linguistics</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="394" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Julia</forename><surname>Rozanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mokanarangan</forename><surname>Thayaparan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Valentino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André</forename><surname>Freitas</surname></persName>
		</author>
		<title level="m">Supporting context monotonicity abstractions in neural nli models</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interventional probing in high dimensions: An NLI case study</title>
		<author>
			<persName><forename type="first">Julia</forename><surname>Rozanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Valentino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Cordeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André</forename><surname>Freitas</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.findings-eacl.188</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EACL 2023</title>
		<meeting><address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2489" to="2500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Studies on natural logic and categorial grammar</title>
		<author>
			<persName><forename type="first">Cabezas</forename><surname>Víctor</surname></persName>
		</author>
		<author>
			<persName><surname>Sánchez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A causal framework to quantify the robustness of mathematical reasoning with language models</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Stolfo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kumar</forename><surname>Shridhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernhard</forename><surname>Schoelkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2023.acl-long.32</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="545" to="561" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Investigating gender bias in language models using causal mediation analysis</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharon</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Nevo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaron</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="12388" to="12401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5446</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2018 EMNLP Workshop Black-boxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter</title>
		<title level="s">Long Papers</title>
		<editor>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</editor>
		<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>the Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Transformers: State-of-theart natural language processing</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teven</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvain</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Causal proxy models for concept-based model explanations</title>
		<author>
			<persName><forename type="first">Zhengxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Karel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atticus</forename><surname>Oosterlinck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Zur</surname></persName>
		</author>
		<author>
			<persName><surname>Potts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Can neural networks understand monotonicity reasoning?</title>
		<author>
			<persName><forename type="first">Hitomi</forename><surname>Yanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koji</forename><surname>Mineshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daisuke</forename><surname>Bekki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasha</forename><surname>Abzianidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-4804</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">HELP: A dataset for identifying shortcomings of neural models in monotonicity reasoning</title>
		<author>
			<persName><forename type="first">Hitomi</forename><surname>Yanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koji</forename><surname>Mineshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daisuke</forename><surname>Bekki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasha</forename><surname>Abzianidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-1027</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</title>
		<meeting>the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</meeting>
		<imprint>
			<publisher>Minnesota. Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="250" to="255" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
