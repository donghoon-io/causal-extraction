<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mitigating Frequency Bias in Next-Basket Recommendation via Deconfounders</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-11-16">16 Nov 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiaohan</forename><surname>Li</surname></persName>
							<email>xiaohan.li@walmart.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Walmart Global Tech</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zheng</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Luyi</forename><surname>Ma</surname></persName>
							<email>luyi.ma@walmart.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Walmart Global Tech</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kaushiki</forename><surname>Nag</surname></persName>
							<email>kaushiki.nag@walmart.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Walmart Global Tech</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><surname>Guo</surname></persName>
							<email>stephen.guo@walmart.com</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Indeed</orgName>
								<address>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
							<email>psyu@uic.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kannan</forename><surname>Achan</surname></persName>
							<email>kannan.achan@walmart.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Walmart Global Tech</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mitigating Frequency Bias in Next-Basket Recommendation via Deconfounders</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-11-16">16 Nov 2022</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2211.09072v1[cs.IR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>next-basket recommendation</term>
					<term>frequency bias</term>
					<term>deconfounder</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent studies on Next-basket Recommendation (NBR) have achieved much progress by leveraging Personalized Item Frequency (PIF) as one of the main features, which measures the frequency of the user's interactions with the item. However, taking the PIF as an explicit feature incurs bias towards frequent items. Items that a user purchases frequently are assigned higher weights in PIF-based recommender system and appear more frequently in the personalized recommendation list. As a result, the system will lose the fairness and balance between items that the user frequently purchases and items that the user never purchases. We refer to this systematic bias on personalized recommendation lists as frequency bias, which narrows users' browsing scope and reduces the system utility. We adopt causal inference theory to address this issue. Considering the influence of historical purchases on users' future interests, the user and item representations can be viewed as unobserved confounders in the causal diagram. In this paper, we propose a deconfounder model named FENDER (Frequency-aware Deconfounder for Nextbasket Recommendation) to mitigate the frequency bias. With the deconfounder theory and the causal diagram we propose, FENDER decomposes PIF with a neural tensor layer to obtain substitute confounders for users and items. Then, FENDER performs unbiased recommendations considering the effect of these substitute confounders. Experimental results demonstrate that FENDER has derived diverse and fair results compared to ten baseline models on three datasets while achieving competitive performance. Further experiments illustrate how FENDER balances users' historical purchases and potential interests.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Next-basket Recommendation (NBR) <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b4">[5]</ref> means to recommend a list of items (the next basket) that a user may be interested using the content of previous baskets. Unlike other recommendation scenario, a unique characteristics of NBR is its repetitive purchase pattern, which means the same item may appear multiple times in baskets that are close together in time. For example, a user may purchase his favorite potato chips frequently during a short period of time. In contrast, user usually does not interact with the same item very often in other recommendation scenarios, such as movie and book recommendation.</p><p>To capture the pattern of repetitive purchase in NBR, previous models strongly rely on Personalized Item Frequency (PIF) in their decision-making processes <ref type="bibr" target="#b4">[5]</ref>. PIF denotes the appearance times of the item in the user's purchased baskets divided by the number of baskets. For example, Mary has made five purchased baskets on the platform, three containing toilet paper. Then, the PIF of toilet paper with respect to Mary is 0.6. PIF measures the frequency of the user's interactions with the product, and the higher PIF is, the more likely the user would buy it next time. <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b6">[7]</ref> claim that a high PIF of an item to a user indicates the user's high preference for the item. Hu et al. <ref type="bibr" target="#b4">[5]</ref> propose a KNN-based model regarding PIF as the main feature which achieves the state-of-the-art performance on NBR.</p><p>However, the reliance on PIF can be pernicious, especially when the weight of PIF in the model is high. Suppose a recommendation model relies solely on PIF to make decisions. It will only recommend items the user has purchased before. In this case, though the model can achieve high performance due to repetitive purchase pattern, it does not derive any new knowledge for users. Based on this example, we conclude that the improper use of PIF can cause systematic bias in NBR. Here we illustrate where the systematic bias comes from. PIF-based methods assume that a higher PIF indicates a higher preference of a user for an item and leads to a higher probability of the next purchase. Thus the model takes PIF as a crucial feature in prediction. However, high PIF, which means the existence of previous purchases, has reversely been caused by the user's preference before. Therefore, if the model simply takes PIF as a feature, the model will erroneously take historical information directly as predictive output, reinforcing the system's bias and users' stereotype. In this paper, we name this systematic bias caused by the misuse of PIF frequency bias. Frequency bias can also be viewed as "personalized popularity bias", expressing a false tendency of RS to recommend previous purchased items of the user too often.</p><p>Many studies have discussed the unbiasedness or fairness issue on recommender systems recently <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b12">[13]</ref>. Although most of these approaches are not designed for NBR and inapplicable to our problem directly, they inspired us to address frequency bias from a causal inference perspective. Here we illustrate the causal diagram we use. First, we claim that PIF can directly affect a user's next-basket purchase due to some mechanism such as Mere Exposure Effect <ref type="bibr" target="#b13">[14]</ref> or feedback loop <ref type="bibr" target="#b14">[15]</ref>. Moreover, we argue that many other factors of users or items, such as user's personality and item's characteristic, can affect both the PIF and the next-basket purchase simultaneously, and thus are confounders in the causal diagram. For example, suppose the user's personality (adventurous or prudent) is a confounder. Since it can affect both the PIF (cause) and the next-basket purchase (effect). An adventurous user would like to try new items that (s)he hasn't bought before, but a prudent user would only purchase what (s)he has bought before. Therefore, the causality between PIF and next-basket purchase depends on the user's personality and cannot be identified without observing the confounder.</p><p>In this paper, we propose a novel framework named FENDER (Frequency-aware Deconfounder for Next-basket Recommendation) based on the deconfounder theory to mitigate the frequency bias in NBR. Inspired by the deconfounder <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> theory, FENDER addresses the unobserved confounders of PIF by leveraging a two-stage training schema. In the first stage, we use a latent factor model (i.e., Neural Tensor Layer <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>) to model the PIF for each user-item pair. In the second stage, we use embeddings learned from the first model to predict the next basket, and jointly learn user and item embeddings. In the inference step, we can adopt flexible weight to balance the influence of PIF on the next-basket purchase. We can also adjust FENDER's recommendation style from conservative (prefer high PIF items) to diverse (prefer low PIF items) by adjusting the weight in the inference step.</p><p>In summary, here are the contributions of this paper:</p><p>• To the best of our knowledge, this is the first study that analyzes the repetitive purchase pattern of NBR from the causal inference perspective. We propose the concept frequency bias, describing the preferences of the products having been purchased by users in the personalized recommender system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Frequency Bias</head><p>In this section, we demonstrate the manifestation of frequency bias. Frequency bias describes the bias of an NBR model on items purchased by the user before. Figure <ref type="figure">1</ref> shows the percentage of items that have been purchased in previous baskets based on the Instacart Dataset <ref type="bibr" target="#b19">[20]</ref> and the prediction results of the state-of-the-art NBR model TIFU-KNN <ref type="bibr" target="#b4">[5]</ref>. To obtain this figure, we select users with more than five baskets and calculate the ratio of items existing in previous baskets. For example, the percentage is zero for the first basket since there is no previous basket. Next, for the second basket, we calculate how many items in it are also in the first basket. Then, for the third basket, we calculate the percentage of items in it that are also in the first and second baskets. We plot the blue line in Figure <ref type="figure">1</ref> to show this for each basket in the Instacart dataset. To obtain the orange line in the figure, we adopt the results of TIFU-KNN to substitute the Instacart data in the blue line. We train a recommendation model for each basket based on its previous baskets and calculate this percentage based on the recommendation results.</p><p>From Figure <ref type="figure">1</ref>, we observe that the result of TIFU-KNN (orange line) is always higher than the ground-truth data (blue line), especially when the basket number is high. This observation also fits our intuition: recommendation algorithms tend to provide a higher ranking to items the user has purchased before. These items are also more likely to be included in the next-basket recommendation. However, though these algorithms may achieve good performance on the first several baskets, they are biased since their prediction distribution differs from the ground truth. Furthermore, these methods will deteriorate the long-term benefits of the accuracy and diversity of the recommendation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Fairness and Debiasing on Recommender Systems</head><p>As a crucial part of large-scale online platforms, the fairness and debiasing issue on Recommender Systems is essential to improve the user experience and system utility. However, conventional recommendation algorithms mainly focus on improving prediction accuracy, especially improving evaluation metrics' value. Most studies do not dissect the recommendation results they derive and thus neglect the difference between their recommendation results and the ground truth in data distribution.</p><p>Recently, many studies have focused on mitigating systematic biases and maintaining fairness of Recommender Systems. According to their literature, many factors, such as feedback loop <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, missing-not-at-random nature <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, and exposure/popularity/position biases <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b24">[25]</ref>, can affect the observational collaborative information and further deteriorate the whole system. Though focusing on different problems, these studies inspired our work dealing with frequency bias.</p><p>In this paper, we have introduced the frequency bias and its outcomes in NBR, and will address this issue via causal inference theories. From the causal inference perspective <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, recommendation is naturally a causal inference problem with unobserved factors. A purchase is a combined result of the user's preferences together with item characteristics, while both the user's preferences and item characteristics are unobservable to us. In other to deal with these latent factors, we adopt the deconfounder framework to address frequency bias.</p><p>Wang and Blei <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b27">[28]</ref> propose the deconfounder theory to deal with the effect of multiple causes. A deconfounder is constructed based on the belief that the distribution of multiple causes contains information about the confounders. Hence, it resorts to a factor model to capture the causes' distribution and use this model to correct the confounding bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRELIMINARIES A. Notations &amp; Problem Definition</head><p>Consider there is a set of user U and a set of item I in NBR and each user consists of T baskets</p><formula xml:id="formula_0">B u T = {B u 1 , B u 2 , • • • , B u T }. Each basket B contains a set of items {i 1 , i 2 , • • • , i |B| }</formula><p>without duplicates, denoting the items that the user purchased in this basket. In this paper, we use letter r to denote the probability of purchase in the dataset. r (u,i,t) = 1 if the user u purchase item i in the t-th basket and vice versa.</p><p>The goal of next-basket recommendation can be viewed as the prediction of next basket B u t with B u t-1 given. In other words, the model needs to predict r(u,i,t) for user u and item i using the records of previous t -1 baskets.</p><p>a) Personalized Item Frequency (PIF): As a crucial feature in recent next-basket recommendation models <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, PIF is the number of times that the item was purchased by the user divided by the number of baskets. Formally, for each pair of user u and item i, the PIF at the t-th basket can be defined as</p><formula xml:id="formula_1">P IF (u,i,t) = t-1 t =1 r (u,i,t ) t -1 .<label>(1)</label></formula><p>For example, a user u has made three purchases at a grocery store, and two of those records contain milk. Then, the PIF of milk at the fourth basket is p (u,'milk ,4) = 2/3. It is obvious that the PIF of each (u, i, t) triplet can be easily calculated with linear complexity. Intuitively, a higher PIF indicates a higher preference of the product and can lead to higher probability of purchase in the next basket.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Basic Causal Graphs in NBR</head><p>Given historical purchase records, one can build effective next-basket recommender systems based on various causal diagrams and each causal diagram is a unique assumption of data latent structure. Here we first introduce two straightforward recommendation methods together with their corresponding causal graphs to show the connection between the recommendation algorithm and the corresponding causal diagram.</p><p>1) Simple PIF-based Recommendation: A straightforward assumption of PIF is that the higher the PIF is, the more likely the user is to purchase the item in the next basket. This assumption is related to the causal diagram Figure <ref type="figure" target="#fig_0">2(a)</ref>, meaning that the probability of a purchase merely depends on the frequency of historical purchases. Therefore, we can build a recommender system based on this causal diagram, merely ranking the PIF for each item:</p><formula xml:id="formula_2">r(u,i,t) = P IF (u,i,t) .<label>(2)</label></formula><p>Such a system is easy to implement and can even achieve comparable results in offline evaluation <ref type="bibr" target="#b4">[5]</ref>. However, since it never recommends new items for users, this system is actually with low utility and deteriorates users' experience.</p><p>2) Conventional Recommender Systems: Most conventional recommendation methods (e.g., Matrix Factorization (MF) <ref type="bibr" target="#b28">[29]</ref>) are based on the causal diagram shown in Figure <ref type="figure" target="#fig_0">2(b)</ref>. In this diagram, there are unobserved user and item nodes that can represent their features. Both the probability of purchase at the t-th basket (denoted by R t ) and the PIF at the t-th basket (denoted by P t ) are both sampled based on the interaction between user and item nodes. Here we take MF as an example <ref type="bibr" target="#b29">[30]</ref>:</p><formula xml:id="formula_3">L BP R = (u,i,j)∈Ot -log σ( e u •e i -e u •e j )+λ M F Θ M F 2 .</formula><p>(3) Above is the loss function to deploy MF with BPR loss and</p><formula xml:id="formula_4">L 2 regularizor Θ M F 2 to predict next basket at timestep t. In this function, O t = {(u, i, j)|P IF (u,i,t) &gt; 0, P IF (u,j,t) = 0}</formula><p>is a set of (u, i, j) triplet where u is a user and i, j are positive and negative samples, respectively. Formally, In this objective, the probability of purchase r(u,i,t) = e u •e i is represented as the inner product of user embedding e u and item embedding e i . In this case, the user and item nodes in the causal diagram represents the corresponding embedding vectors in the BPR-MF model. Both of above two methods can derive predictions on NBR. However, our experiments on TIFU-KNN and BPR-MF demonstrate that they do not perform very well in fairness, indicating their causal diagrams may be defective. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. METHOD</head><p>In this paper, we propose a novel framework FENDER based on deconfounder theory to address frequency bias in NBR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Causal Graph</head><p>The causal diagram in Figure <ref type="figure" target="#fig_0">2</ref>(c) illustrates the cause of frequency bias. Most NBR model assumes an intuitive assumption: higher PIF, representing a higher purchase frequency, can lead to a higher probability of future purchases. However, we argue that this assumption is not comprehensive. On the one hand, a user's purchase behavior is caused by the user and item attributes; on the other hand, these attributes can also lead to high PIFs, since the user's interest and item's characteristics are not likely to change quickly. Moreover, some unobserved mechanisms, such as the Mere Exposure Effect <ref type="bibr" target="#b13">[14]</ref>, and the feedback loop <ref type="bibr" target="#b14">[15]</ref> lead to a direct causal relationship between high PIF and users' purchases. To describe the causality between these factors, the causal diagram in Figure <ref type="figure" target="#fig_0">2</ref>(c) adopts four nodes in total: the user's interest (denoted by U ), the item's characteristics (denoted by I ), PIF indicating historical purchases (denoted by P t ) and the next-basket purchase (denoted by R t ). In this graph, the user node U and item node I point to P t and R t simultaneously, which means the user and item's characteristics affect both historical and next-basket purchases. Moreover, a direct arrow from PIF P t to next-basket purchase R t represents the direct influence of previous user choice on the next-basket purchase.</p><p>From this causal diagram, we can observe the frequency bias comes from the confounding bias between P t and R t . In causal inference theory, confounders are factors that can affect both the cause and effect. In this case, U and I are unobserved confounders that affect both the cause P t and the effect R t , which cause confounding bias. Confounders in the causal graph can affect both the cause and effect and further control their association. In our case, for example, suppose the user's personality can be categorized into adventurous or prudent. Then, an adventurous user prefers to try new items that (s)he hasn't bought before, and the association between P t and R t for (s)he is lower. Reversely, the association between them for a prudent user can be higher. Therefore, without addressing the confounding issue, even if we measure the correlation between P t and R t from the observational dataset, it can represent neither group of users and is unreliable when data distribution shifts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Deconfounder</head><p>In order to deal with the unobserved confounders, our method is motivated by the theory of deconfounder <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b27">[28]</ref>.</p><p>Here we list the assumptions that the deconfounder requires in the following.</p><p>a) Stable unit treatment value assumption (SUTVA): The SUTVA assumption assumes that the potential outcomes for a particular unit only depend on the treatment to which the unit itself was received <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b30">[31]</ref>. In NBR, it means whether a user buys an item only related to the user and the item themselves, and is irrelevant to all other users or items.</p><p>b) Overlap (Positivity): Overlap asserts that, given the unobserved confounder, the conditional probability of any possible value of treatments is positive. In NBR, this means we assume</p><formula xml:id="formula_5">0 &lt; r (u,i,t) &lt; 1, ∀u, i, t,<label>(4)</label></formula><p>which means the probability of a user purchasing any item is ranging from 0 to 1. c) Single ignorability: Unlike the traditional unconfoundedness assumption requires "All confounders observed", the deconfounder requires "No unobserved single-cause confounders" assumption <ref type="bibr" target="#b15">[16]</ref>, which means we observe any confounders that affect only one of the causes. In NBR, apart from the collaborative information, the model does not have to observe any user or item features. Therefore, we assume that if a factor (of user u or item i) can affect the purchase of u on i, it must either affect u purchasing other items or affect other users purchasing item i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. FENDER</head><p>Based on the three assumptions, we propose an novel unbiased framework FENDER to mitigate the frequency bias in NBR. FENDER adopts a two-stage architecture to model the frequency bias before making a recommendation.</p><p>In the first step, FENDER models frequency bias by factorizing PIF. It learns the user and item embeddings e p u,t , e p i with MF model with a neural tensor layer to factorize PIF, which is to learn not only the feature PIF itself, but also derive new knowledge about latent features that cause the PIF. In the second step, FENDER predicts the probability of items in the next basket. The learned embeddings of the first step are used to balance the current state and the previous state. We disentangle the user's previous interest e p u,t and current interest e r u,t , and use them to derive unbiased recommendations in the inference step.</p><p>1) First Stage Model: In the first stage of the model, FENDER models the previous baskets by factorizing PIF at time step t. Since P IF (u,i,t) is calculated based on all previous baskets, it contains information about the historical preference of an item and can be used to correct frequency bias. For each triplet in I = {(u, i, t)|u ∈ U, i ∈ I, 1 &lt; t ≤ T }, we can calculate P IF (u,i,t) from the original dataset {B u }. In the first stage model, we decompose the PIF into two latent user and item representations. Motivated by <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, a Neural Tensor Layer (NTL) is applied to generate the predicted PIF value from the latent embeddings. With Mean Squared Error (MSE) loss, the distance between the predicted PIF and the actual PIF will be minimized. Specifically, the process is as follows:</p><formula xml:id="formula_6">p (u,i,t) = σ h (e p u,t W [1:k] 1 e p i ) + W 2 e p u,t e p i + b ,<label>(5)</label></formula><formula xml:id="formula_7">L 1 = 1 |I| (u,i,t)∈I (p (u,i,t) -P IF (u,i,t) ) 2 + λ p Θ p 2 ,<label>(6)</label></formula><p>where e p u,t denoted the user embedding for user u at the t-th basket, and e p i is the item embedding for item i which is consistent to time. Θ p = {W 1 , W 2 , b, h} is the parameter set of this model and λ p is its weight. I = {(u, i, t)|u ∈ U, i ∈ I, 1 &lt; t ≤ T } denotes the sample set, and W ∈ R d×d×k and W 2 ∈ R k×2d are 3d and 2d weight tensors, respectively. These embeddings represent the feature PIF as well as other latent features that cause the PIF. The latent features help us know extra knowledge in addition to PIF to mitigate the frequency bias. In the next step, we will use this information to correct frequency bias when predicting the current basket purchase.</p><p>2) Second Stage Model: After we obtain e p u,t and e p i from the PIF decomposition stage, they are used in the second stage to predict the probability of next-basket purchase. The rationale of the second stage model is to balance the PIF and confounders in the model. In the second stage model, we learn another pair of user and item embeddings e r u,t and e r i to represent confounders. Here is the forward propagation formula to predict the probability of purchase r(u,i,t) based on the causal graph shown in Figure <ref type="figure" target="#fig_0">2(d):</ref> p (u,i,t) = NTL(e p u,t , e p i ), (7) c (u,i,t) = NTL(e r u,t , e r i ),</p><formula xml:id="formula_8">(u,i,t) = ω • c (u,i,t) + (1 -ω) • p (u,i,t) , (<label>(8) r</label></formula><formula xml:id="formula_9">)<label>9</label></formula><p>where NTL is the Neural Tensor Layer and ω is the weight of the first factor. p (u,i,t) and c (u,i,t) are the embeddings of PIF and confounders. ω illustrates the inclination of PIF and confounders in the model training. In this formula, e p u,t and e p i stay fixed while other parameters and embeddings are trained with BPR <ref type="bibr" target="#b28">[29]</ref> loss, which is </p><formula xml:id="formula_10">L 2 = (u,i,j)∈Ot -log σ(r (u,i,t) -r(u,j,t) ) + λ r Θ r 2 , (<label>10</label></formula><formula xml:id="formula_11">)</formula><p>where O t = {(u, i, j)|r (u,i,t) = 1, r (u,j,t) = 0} is a set containing positive and negative items at the t-th basket. Θ r is the parameter set of the second stage. The positive items are the items purchased in the t-th basket and we take it as the ground truth to train our model. In the inference step, we can easily change the recommendation style by tuning the value of weight ω. The higher ω we set, the more FENDER relies on PIF to make recommendation, and thus there will be more repeat items in the recommendation list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>This section evaluates our proposed FENDER on real and manually interfered datasets. The experimental results demonstrate that FENDER can better model user behavior and have more accurate and diverse recommendation results.</p><p>A. Experiment Settings 1) Datasets: We use three real-world next-basket recommendation datasets to measure FENDER's performance.</p><p>• Instacart<ref type="foot" target="#foot_0">foot_0</ref> . This dataset was published by instacart.com, an online grocery delivery and pick-up service platform in North America. It contains over 3 million orders and 200 thousand users. • Dunnhumby<ref type="foot" target="#foot_1">foot_1</ref> . We use the Let's Get Sort-of-Real dataset from Dunnhumby.com. It is real in-store data, including the basket records for each user. • Walmart Grocery<ref type="foot" target="#foot_2">foot_2</ref> . This dataset is from Walmart Inc, one of the largest online grocery platforms. Walmart Grocery has over 100 million monthly active users who buy more than one hundred thousand products. We collect a portion of the dataset to test our model.</p><p>All three datasets contain the transactions about the interactions of users and items for each order. The items purchased in the same order are considered as a basket. As FENDER focuses on mitigating the long-term bias, we select the users with more than five baskets in the dataset. The statistics of the datasets are shown in Table <ref type="table">I</ref>.</p><p>2) Measurement metrics: We utilize three metrics to measure the accuracy and diversity of FENDER's recommended list. Hit rate and NDCG are two widely used metrics in NBR. These two metrics measure FENDER's ability to learn the unbiased distribution improves accuracy. We also propose a novel negative Top-Frequency Ratio (nTFR), which measures the percentage of top-k frequent items in the recommended list. Fewer frequent items in the recommended list mean there is more diversity. We define the nTFR as</p><formula xml:id="formula_12">nT F R = 1 - N top f re N rec item ,<label>(11)</label></formula><p>where N top f re and N rec item are the numbers of top frequent items and all items in the recommended list. In this paper, we choose k as 20 based on the statistics of the datasets.</p><p>3) Implementation: The code is implemented by Tensorflow 1.12 and also compatible with Tensorflow version &gt; 2.0. The source codes and datasets are open-sourced 4 . We take the basket t as testing set, basket t-1 as validation set and baskets 0 to t -2 as training sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison Experiments</head><p>This section compares our proposed FENDER with ten state-of-the-art baseline models. We measure our model on both accuracy and diversity. The detailed experiment results are shown in Table <ref type="table" target="#tab_3">II</ref>.</p><p>1) Baseline models: We compare our method FENDER with ten state-of-the-art NBR algorithms.</p><p>• PIF. We rank the most frequently purchased items in all purchased items for the user and take them as the recommended items for the next basket. • BPR-MF <ref type="bibr" target="#b28">[29]</ref>. It is one of the most widely used baseline methods in recommender systems. We use all interactions of users and items as inputs to train the user and item embeddings.</p><p>• propensity-MF. It is an unbiased version of MF. In this model, we regard PIF as the propensity score and penalize it over different datapoints to derive an unbiased result. 2) Experiment analysis: Based on Table <ref type="table" target="#tab_3">II</ref>, we can compare the performance of all models on three datasets. Our observations of the experiment results are as follows:</p><p>• In the comparison of recommendation accuracy, FENDER outperforms all baselines on all three datasets in NDCG@20. In comparing diversity, FENDER can defeat all baselines on the Walmart Grocery and Dunnhumby datasets and achieves the second-best in the Instacart dataset. At the same time, the best performing BPR-MF has very low NDCG@20. Therefore, we conclude that FENDER consistently outperforms all other baselines in accuracy and diversity on most datasets. Apart from FENDER, models considering frequency patterns in baskets (Sets2Sets, MIT-GNN, TIFU-KNN) achieve competitive accuracy compared to other baselines. However, the diversity of these models is relatively low, indicating the item frequency biases them.</p><p>The unbiased model (propensity-MF) achieves high nTFR@20 but low HR@20 and NDCG@20, indicating that it tends to produce diverse results but loses its recommendation effectiveness. • We can also infer the distribution of the datasets from the table. In Instacart and Walmart Grocery, we can observe a high impact of PIF on recommendation results since the model PIF surpasses six other baselines on these datasets. This may be because the grocery scenario contains many perishable items that need to be purchased more frequently. However, the diversity of model PIF is the lowest, which means only focusing on PIF may deteriorate the diversity of the recommendation results. As for Dunnhumby, the performance of model PIF is relatively lower, indicating the PIF has a moderate impact on it. • Compared with the second-best results on the three datasets we use, our model has a better performance on NDCG than on Hit rate. The average improvement on NDCG is 10.20%, while on Hit Rate, it is only 1.14%. It shows that FENDER can find a better ranking of items than other baseline models. The improvement in NDCG may result from the parameter ω, which illustrates the inclination of PIF and confounders in the model training. In Section 5.5, we have a more detailed analysis of this parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Robustness Experiment</head><p>We conduct the robustness experiment by manually adding noise to the datasets. Specifically, we randomly choose an unrelated item for each user and insert it into all their purchased baskets. This way, we can make the unrelated items have the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets Instacart Walmart Grocery Dunnhumby</head><p>Models HR@20 NDCG@20 nTFR@20 HR@20 NDCG@20 nTFR@20 HR@20 NDCG@20 nTFR@  highest PIF compared to other items in the user's historical records. We conduct this experiment on Instacart and Walmart Grocery, as these datasets exhibit stronger repetitive purchase pattern and are easily influenced by PIF. To demonstrate the robustness of the models, we expect the model to identify the user's actual interest, and doesn't recommend the inserted item on the top ranking.</p><p>From the recommended lists of each model, we calculate the average rank of the inserted items among all users to represent the robustness of the model. A higher average rank of the inserted items means the model is more robust to the influence of PIF. As shown in Figure <ref type="figure" target="#fig_2">3</ref>, we observe that FENDER ranks the inserted items highest among the baselines on both datasets. Both Models PIF and TIFU-KNN rank the inserted items near top-1, which are the lowest among all baseline models. This phenomenon indicates that FENDER can find some other features apart from PIF to generate recommendations with the deconfounder. Models PIF and TIFU-KNN rely on PIF as the main feature, so they rank the inserted items near the top of the recommended lists. Besides, models Sets2Sets and MIT-GNN all rank the inserted items higher than the top 1 because they consider other features (graph structure, item attention).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Case Study</head><p>We conducted the case study on the Walmart Grocery dataset to compare the diversity of the recommended lists. We randomly select a user for this dataset and compare the recommended lists of TIFU-KNN <ref type="bibr" target="#b4">[5]</ref> and our proposed FENDER. TIFU-KNN is the most representative PIF-based model and performs well on the Walmart Grocery dataset according to Table <ref type="table" target="#tab_3">II</ref>. The comparison of these two models is listed in Table <ref type="table" target="#tab_6">III</ref>. This table lists the top 10 items provided by the two models. The first five baskets are used as training data, and we compare the next five predicted baskets of the two models.</p><p>Based on Table <ref type="table" target="#tab_6">III</ref>, we have the following observations:</p><p>• The predicted lists of TIFU-KNN exhibit a homogenization pattern across different baskets, while FENDER has different patterns for different baskets. It demonstrates that our proposed FENDER can provide diverse recommendations for various visits of users. The diversity of recommendations improves user experience by creating a feeling of freshness.   ferent items, 36.8% less than FENDER. This indicates that FENDER has a broader browsing scope for items than TIFU-KNN. Broader browsing scope assists users in finding the potential items that they may be interested in, but have not purchased before. • FENDER can still consider the repetitive purchasing pattern in the recommendation. According to Table <ref type="table" target="#tab_6">III</ref>, items 33 and 5 always appear in the top 2 of the recommended lists. These two items are purchased almost every time by the users in the dataset. This shows that FENDER can find the items with PIF, while maintaining a unique shopping experience simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Parameter Analysis</head><p>In this section, we investigate the selection of parameter ω in Eq. 6. ω illustrates the inclination of PIF and confounders in the model training. We demonstrate the variation trend during the training process for all three datasets. This experiment helps us understand the relations between confounders and PIF. Figure <ref type="figure" target="#fig_3">4</ref> depicts parameter changes ω during 100 training epochs. We set the starting ω as 0.1 and the learning rate as 0.0001.</p><p>Based on Figure <ref type="figure" target="#fig_3">4</ref>, we observe that parameter ω converges to around 1.6 for datasets Instacart and Walmart Grocery, while on Dunnhumby, it converges to about 1.2. This phenomenon may result from the difference in the repetitive purchase pattern of the datasets. As described in Eq. 6, the allocation of PIF and confounders is ω and (1 -ω). A higher ω denotes more differences between PIF and confounders as they are negatively correlated. According to Table <ref type="table" target="#tab_3">II</ref>, dataset Instacart and Walmart Grocery have a stronger repetitive purchase pattern than Dunnhumby, so the parameter ω is higher on Instacart and Walmart Grocery than on Dunnhumby.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RELATED WORKS A. Next-Basket Recommendation</head><p>Next Basket Recommendation (NBR) predicts what the user will buy the next time (s)he visits the online platform. Previous works mainly focus on two aspects: 1) modeling the complementary pattern among historical basket records. <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>; and 2) considering the frequency pattern for the purchased items [5]- <ref type="bibr" target="#b6">[7]</ref>. Complementary pattern is the complementary relationship between items and we can leverage it to know which items will be added next based on the existing items in the basket. Sceptre <ref type="bibr" target="#b33">[34]</ref> is proposed to model and predict relationships between items from the text of their reviews and the corresponding descriptions. DREAM <ref type="bibr" target="#b0">[1]</ref> proposes to use RNN structure to exploit the dynamics of user embeddings to complete BR. Triple2vec <ref type="bibr" target="#b2">[3]</ref> improves withinbasket recommendation via (user, item A, item B) triplets sampled from baskets. MIT-GNN <ref type="bibr" target="#b3">[4]</ref> uses heterogeneous graph embeddings to complete BR. All these works simply aggregate the information within the basket, while having no discussion regarding the complete feedback loop. Le et al. <ref type="bibr" target="#b31">[32]</ref> propose a hierarchical network to model the basket sequences based on the correlation of items in each basket. CLEA <ref type="bibr" target="#b32">[33]</ref> extracts items relevant to the target item for NBR with a Gumbel Softmax-based denoising generator. Wang et al. devise Intention2Basket <ref type="bibr" target="#b35">[36]</ref> including three modules: Intention Recognizer, Coupled Intention Chain Net, and Dynamic Basket Planner to model the heterogeneous intentions behind baskets. All the models above learn from the complementary pattern of baskets to model users in different innovative ways, but none of them consider the frequency pattern behind items.</p><p>Apart from the complementary pattern, the frequency pattern is also demonstrated to be useful in the NBR problem. Hu et al. <ref type="bibr" target="#b4">[5]</ref> leverage Personalized Item Frequency (PIF) as a key feature in the KNN model and achieved the state-of-theart performance. Faggioli et al. <ref type="bibr" target="#b5">[6]</ref> propose a recency-aware user-wise popularity in the collaborative filtering method to model the repetitiveness and loyalty of the user. Sets2Sets <ref type="bibr" target="#b6">[7]</ref> is an end-to-end learning approach based on an encoderdecoder framework to predict the subsequent sets of elements.</p><p>Sets2Sets also considers the repeated elements pattern in the model to improve performance. The frequency or repetitionbased models perform well in the offline setting, but this kind of strategy is detrimental to the users' experience in the long term. If a model relies on frequency pattern heavily, the scope of the item set in the recommendation list will be significantly narrowed. In this paper, we want to find a balance to increase the diversity of the items in the recommendation list while maintaining a satisfactory performance from the frequency pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Recommender System Debiasing</head><p>Recommender systems have achieved wide success in different tasks <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, but most of them are still suffering from the biases in the recommendation results. There is rich literature dealing with biases in recommender systems. While a few studies can take a holistic view of the debiasing task on recommender systems, the vast majority of studies are organized either from the probabilistic perspective or the system design perspective. From the probabilistic perspective, scientists try to analyze the distribution of the recommendation dataset or results. The item exposure is regarded as a crucial factor in the recommendation data generating process and is modeled explicitly in many studies <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>. Many studies believe that the bias in recommender systems is induced by the missing-not-at-random nature of the dataset, and focus on the following outcome of this selection bias <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b40">[41]</ref>- <ref type="bibr" target="#b42">[43]</ref>. From the system perspective, scientists address the biases resulting from the flaw of the system. Some studies discover that the recommendation result is biased toward a particular item or user group and try to address such as popularity bias <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b43">[44]</ref>- <ref type="bibr" target="#b46">[47]</ref> or conformity bias <ref type="bibr" target="#b47">[48]</ref>. <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b48">[49]</ref> introduce debiased estimators to correct the selection bias in the recommendation evaluation step. <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b50">[51]</ref> leverage a small volume of unbiased uniform data to calibrate the biased dataset. Furthermore, the studies of feedback loops regard the recommender system and users as a whole system and hope the recommender system can achieve a balance during its interactions with users <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b51">[52]</ref>. There are more related works regarding other biases, such as position bias in learning-to-rank systems <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b53">[54]</ref>.</p><p>Although the recommender system debiasing problem attracts much attention in academia and industry, this topic is still challenging due to the critical generality/variance tradeoff: if a method can handle multiple biases with minor modification, its variance must be high, making itself difficult to train. Moreover, because of the different sources of the biases, there is no panacea to deal with this problem in recommender systems. In different scenarios, the biases can come from different aspects, such as item popularity or unobserved confounders. In this paper, we discuss the frequency bias and devise a model only for NBR. We first propose a causal model to explain the cause of such bias. Then, we propose a flexible and scalable method to reduce the bias systematically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION &amp; FUTURE WORKS</head><p>This paper discusses the frequency bias issue in the NBR problem. Frequency bias results from the RS model relying heavily on the PIF feature. In the bias amplification loop, the frequency bias accumulates and increases the recommendation results' homogenization. Frequency bias gradually narrows a user's browsing scope on the online platform and eventually deteriorates the user's experience. We propose FENDER, a model based on the deconfounder architecture, to deal with frequency bias. FENDER factorizes the PIF into latent embeddings to eliminate the frequency bias. Experimental results show that FENDER can improve the accuracy of the recommendation results and the diversity of the recommended items.</p><p>From a method perspective, our model can be viewed as a variation of sequential deconfounder <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b55">[56]</ref> and is a sequential model. While conventional sequential model/deconfounder requires many mediate variables to learn the hidden state of the next timestep, our model only needs a pre-calculated feature (PIF) to summarize users' interests and thus speeds up the calculation process significantly. In the future, similar ideas can be used to design models. We can select representative features to substitute certain modules in complex machine learning models to improve the efficiency and effectiveness of models simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. ACKNOWLEDGEMENT</head><p>This work is supported in part by NSF under grants III-1763325, III-1909323, III-2106758, and SaTC-1930941.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Causal graphs depicting causalities between User U , item I, PIF Pt and purchase Rt. Dotted circles represent unobserved variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. The average rank of the manually inserted items. We compare FENDER with four frequency-aware baseline models, i.e., PIF, TIFU-KNN, Sets2Sets, and MIT-GNN.</figDesc><graphic coords="7,102.49,415.04,144.00,108.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. The variation trend of weight ω in datasets Instacart, Walmart Grocery, and Dunnhumby. We run 100 epochs to see the difference between the three curves.</figDesc><graphic coords="8,82.26,173.89,192.74,144.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>in the heterogeneous graph, and a translation-based model is utilized to learn the node embeddings. We take the PIF as the initial feature of the nodes.• TIFU-KNN<ref type="bibr" target="#b4">[5]</ref>. It is the state-of-the-art PIF-based model in NBR. PIF is a crucial feature in the proposed KNN model to model the user's interest.</figDesc><table><row><cell>• DREAM [1]. It is a Recurrent Neural Network (RNN)-</cell></row><row><cell>based NBR model. DREAM captures the dynamic repre-</cell></row><row><cell>sentations, as well as global sequential features, among</cell></row><row><cell>baskets.</cell></row><row><cell>• Triple2vec [3]. It utilizes complementarity, compatibility,</cell></row><row><cell>and loyalty to construct triplets for baskets and train user</cell></row><row><cell>and item embeddings.</cell></row><row><cell>• Beacon [32]. It is a hierarchical network to model basket</cell></row><row><cell>sequences. It considers the relative importance of items</cell></row><row><cell>and correlations among item pairs.</cell></row><row><cell>• CLEA [33]. It extracts items relevant to the target item</cell></row><row><cell>with contrastive learning to make denoising NBR.</cell></row><row><cell>• Sets2Sets [7]. It is an NBR model based on the RNN</cell></row><row><cell>and attention mechanism. A repetitive purchase pattern</cell></row><row><cell>is also considered in this model.</cell></row></table><note><p><p><p>• MIT-GNN</p><ref type="bibr" target="#b3">[4]</ref></p>. It is the state-of-the-art GNN-based NBR recommendation model. Users, items, and baskets are 4 https://github.com/shawnlxh/FENDER nodes</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II EXPERIMENTS</head><label>II</label><figDesc>ON THREE DATASETS COMPARING OUR PROPOSED FENDER FRAMEWORK WITH TEN BASELINE MODELS USING THE METRICS: HIT RATE (HR), NORMALIZED DISCOUNTED CUMULATIVE GAIN (NDCG), AND NEGATIVE TOP-FREQUENCY RATIO (NTFR). THE BOLD AND UNDERLINED NUMBERS INDICATE THE BEST AND SECOND-BEST RESULTS ON EACH DATASET AND METRIC, RESPECTIVELY.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE III CASE</head><label>III</label><figDesc>STUDY OF TIFU-KNN AND FENDER. THISTABLE LISTS THE TOP 10 RECOMMENDED ITEMS FOR THESE TWO MODELS. WE RE-INDEX THE ITEM IDS IN THE DATASET RANGING FROM 1 TO 45. THE FIRST FIVE BASKETS ARE USED AS TRAINING DATA, AND WE LIST THE NEXT FIVE PREDICTED BASKETS FOR COMPARISON.</figDesc><table><row><cell>Baskets</cell><cell>TIFU-KNN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FENDER</cell><cell></cell></row><row><cell>1</cell><cell>33 5 17 26 12 41</cell><cell>8</cell><cell cols="3">44 21 10</cell><cell cols="2">33 5 26 17 44</cell><cell>8</cell><cell cols="2">21 15 41 10</cell></row><row><cell>2</cell><cell cols="2">33 5 17 41 26 12 44</cell><cell>8</cell><cell>15</cell><cell>7</cell><cell>33 5 17 44</cell><cell>8</cell><cell cols="2">26 19</cell><cell>7</cell><cell>15 41</cell></row><row><cell>3</cell><cell cols="2">33 5 17 41 26 44 12</cell><cell>7</cell><cell>8</cell><cell>38</cell><cell cols="2">33 5 41 26 44</cell><cell>8</cell><cell cols="2">12 25 17 38</cell></row><row><cell>4</cell><cell cols="2">33 5 17 41 26 44 12</cell><cell>8</cell><cell>15</cell><cell>7</cell><cell>33 5 17 26</cell><cell>8</cell><cell cols="3">27 44 20 19 12</cell></row><row><cell>5</cell><cell cols="2">33 5 17 41 26 44 12</cell><cell>8</cell><cell cols="2">15 38</cell><cell>33 5 26 44</cell><cell>8</cell><cell cols="3">15 41 17 14</cell><cell>3</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://www.kaggle.com/c/instacart-market-basket-analysis</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.dunnhumby.com/source-files/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>walmart.com   </p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A dynamic recurrent model for next basket recommendation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="729" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Basket-sensitive personalized item recommendation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Lauw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Representing and recommending shopping baskets with complementarity, compatibility and loyalty</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1133" to="1142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Basket recommendation with multi-intent translation graph neural network</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Achan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="728" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling personalized item frequency information for next-basket recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1071" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recency aware collaborative filtering for next basket recommendation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Faggioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Polato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Aiolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization</title>
		<meeting>the 28th ACM Conference on User Modeling, Adaptation and Personalization</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="80" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sets2sets: Learning from sequential sets with neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1491" to="1499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recommendations as treatments: Debiasing learning and evaluation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1670" to="1679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Information theoretic counterfactual learning from missingnot-at-random feedback</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Kuruoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.02623</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A general knowledge distillation framework for counterfactual recommendation via uniform data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="831" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Causal inference for recommender systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="426" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deconfounded recommendation for alleviating bias amplification</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.10648</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unbiased sequential recommendation with latent confounders</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Web Conference 2022</title>
		<meeting>the ACM Web Conference 2022</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="2195" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stimulus recognition and the mere exposure effect</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Bornstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>D'agostino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">545</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How algorithmic confounding in recommendation systems increases homogeneity and decreases utility</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Chaney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Engelhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="224" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The blessings of multiple causes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">528</biblScope>
			<biblScope unit="page" from="1574" to="1596" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mitigating health disparities in ehr via deconfounder</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM International Conference on Bioinformatics</title>
		<meeting>the 13th ACM International Conference on Bioinformatics</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th international conference on world wide web</title>
		<meeting>the 26th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The instacart online grocery shopping dataset 2017</title>
		<ptr target="https://www.instacart.com/datasets/grocery-shopping-2017on2021-8-2" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unbiased offline recommender evaluation for missing-not-at-random implicit feedback</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems</title>
		<meeting>the 12th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unbiased recommender learning from missing-not-at-random implicit feedback</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yaginuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Nishino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sakata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nakata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="501" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modeling user exposure in recommendation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on World Wide Web</title>
		<meeting>the 25th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="951" to="961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Causal intervention for leveraging popularity bias in recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.06067</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unbiased learning-torank with biased feedback</title>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schnabel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="781" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Causal inference using potential outcomes: Design, modeling, decisions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">469</biblScope>
			<biblScope unit="page" from="322" to="331" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Towards clarifying the theory of the deconfounder</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04948</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1205.2618</idno>
		<title level="m">Bpr: Bayesian personalized ranking from implicit feedback</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Randomization analysis of experimental data: The fisher randomization test comment</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">371</biblScope>
			<biblScope unit="page" from="591" to="593" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Correlation-sensitive next-basket recommendation</title>
		<author>
			<persName><forename type="first">D.-T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Lauw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="2808" to="2814" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The world is binary: Contrastive learning for denoising next basket recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="859" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Inferring networks of substitutable and complementary products</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Knowledge-aware complementary product representation learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Körpeoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Achan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="681" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Intention2basket: A neural intention-driven approach for dynamic nextbasket planning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">Z</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Orgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="2333" to="2339" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamic graph collaborative filtering</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="322" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pretraining recommender systems via reinforced attentive multi-relational graph neural network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Achan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="457" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Causal inference for recommendation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Causation: Foundation to Application, Workshop at UAI. AUAI</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unbiased learning for the causal effect of recommendation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Takemori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ohkuma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="378" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deconfounding user satisfaction estimation from response rate bias</title>
		<author>
			<persName><forename type="first">K</forename><surname>Christakopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Traverse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Haulk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="450" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for debiasing missing-not-at-random explicit feedback</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Saito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mitigating confounding bias in recommendation via information bottleneck</title>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth ACM Conference on Recommender Systems</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="351" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Controlling popularity bias in learning-to-rank recommendation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Abdollahpouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mobasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh ACM conference on recommender systems</title>
		<meeting>the eleventh ACM conference on recommender systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="42" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Managing popularity bias in recommender systems with personalized re-ranking</title>
	</analytic>
	<monogr>
		<title level="m">The thirty-second international flairs conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Popularityopportunity bias in collaborative filtering</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="85" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">User-oriented fairness in recommendation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference</title>
		<meeting>the Web Conference</meeting>
		<imprint>
			<date type="published" when="2021">2021, 2021</date>
			<biblScope unit="page" from="624" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Disentangling user interest and conformity for recommendation with causal embedding</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Web Conference 2021</title>
		<meeting>the Web Conference 2021</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2980" to="2991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Offline evaluation to make decisions about playlistrecommendation algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gruson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Charbuillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tardieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carterette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="420" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Combating selection biases in recommender systems with a few unbiased ratings</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="427" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Causal transfer random forest: Combining logged data and randomized experiments for robust prediction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bayir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kiciman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="211" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Adversarial counterfactual learning and evaluation for recommender system</title>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Korpeoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Achan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.02295</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Counterfactual learningto-rank for additive metrics and deep models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Zaitsev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00065</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Correcting for selection bias in learning-to-rank systems</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ovaisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ahsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vasilaky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zheleva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference</title>
		<meeting>The Web Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1863" to="1873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Sequential deconfounding for causal inference with unobserved confounders</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feuerriegel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.09323</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Time series deconfounder: Estimating treatment effects over time in the presence of hidden confounders</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName><surname>Schaar</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="884" to="895" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
