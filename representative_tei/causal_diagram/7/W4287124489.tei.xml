<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Path-specific Effects Based on Information Accounts of Causality</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Gong</forename><surname>Heyang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics and Finance</orgName>
								<orgName type="department" key="dep2">Department of Statistics and Actuarial Science</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of HongKong</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhu</forename><surname>Ke</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics and Finance</orgName>
								<orgName type="department" key="dep2">Department of Statistics and Actuarial Science</orgName>
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">University of HongKong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Path-specific Effects Based on Information Accounts of Causality</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Path-specific effects in mediation analysis provide a useful tool for fairness analysis, which is mostly based on nested counterfactuals. However, the dictum "no causation without manipulation" implies that path-specific effects might be induced by certain interventions. This paper proposes a new path intervention inspired by information accounts of causality, and develops the corresponding intervention diagrams and π-formula. Compared with the interventionist approach of Robins et al. (2020) based on nested counterfactuals, our proposed path intervention method explicitly describes the manipulation in structural causal model with a simple information transferring interpretation, and does not require the non-existence of recanting witness to identify path-specific effects. Hence, it could serve useful communications and theoretical focuses for mediation analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Analyzing the relative strength of different pathways between a decision X and an outcome Y is an interesting topic for both scientists and practitioners across many disciplines over several decades. The path-specific effects in mediation analysis have been demonstrated as a useful tool to tackle this topic <ref type="bibr" target="#b2">(Baron &amp; Kenny, 1986;</ref><ref type="bibr" target="#b18">Robins &amp; Greenland, 1992;</ref><ref type="bibr" target="#b12">Pearl, 2001)</ref>. This is one of the seven tasks summarized by Judea Pearl in causal inferences <ref type="bibr">(Pearl, 2019b)</ref>. To capture the path-specific effects, the often used approaches are based on nested counterfactuals; see <ref type="bibr" target="#b0">Avin et al. (2005)</ref>, <ref type="bibr" target="#b21">Shpitser &amp; Tchetgen (2016)</ref>, <ref type="bibr" target="#b23">Zhang &amp; Bareinboim (2018)</ref>, and <ref type="bibr" target="#b10">Malinsky et al. (2019)</ref> for earlier references.</p><p>More recently, <ref type="bibr" target="#b19">Robins et al. (2020)</ref> provided an interventionist theory of mediation to study some path-specific effects (such as natural indirect/direct effects) in single world intervention graph (SWIG). However, their interventionist framework seems lack of a formally defined concept of intervention for the general path-specific effects, and it requires the recursive assumption to well define the nested counterfactuals. Also, their path specific counterfactuals are equal to interventional counterfactuals only when no recanting witness exists. Therefore, their method are restrictive in many situations. For example, to analyze the strength of path π : X → A → Y between a decision X and an outcome Y in Fig. <ref type="figure" target="#fig_0">1</ref>(a) or (b), their method is not applicable any more.</p><p>In this paper, we propose a path intervention based on the information accounts of causality. To understand causality as information transfer, which has been formally proposed and developed in philosophy since <ref type="bibr" target="#b4">Collier (1999)</ref>, we decompose causal mechanisms into two parts: information transfer mechanisms and information process mechanisms. Specifically, each causal mechanism f i in a structural causal model (SCM) decides how to process the collected information e pa(i),i from its input edges, where each e j,i decides the information transferred from its input node j through the edge j → i. Our novel path intervention is formally defined by explicitly manipulating mechanisms in the informational decomposition of SCM. Henceforth, the path specific effects can be well defined by using our path intervention, even for cyclic causal diagrams such as that in Fig. <ref type="figure" target="#fig_0">1</ref>(b), Moreover, we develop a π-formula for identifying our interventional counterfactuals. The use of the π-formula does not need the absence of recanting witness, and hence it can be applied to identify the path-specific effects in Fig. <ref type="figure" target="#fig_0">1</ref>(a). As a graphical tool to assist causal reasoning, we also propose the associated intervention diagram for different interventions under the informational decomposition of SCM. Our path-specific effects can be interpreted as simply making the decision information X = x exclusively pass through the causal path π while allowing all other information outside π to behave naturally. This interpretation is different from those in the existing graphical approaches based on nested counterfactuals.</p><p>The remaining paper is organized as follows. Section 2 gives the preliminaries and the formal definition of informational decomposition of SCM. Section 3 introduces our path intervention and intervention diagrams with some illustrating examples. Section 4 proposes the identification formula for path-specific effects by using our path intervention. Concluding remarks and discussions are offered in Section 5.</p><p>Notations. Our notations below are similar to those in <ref type="bibr" target="#b22">Shpitser et al. (2020)</ref>. Fix a set of indices V ≡ {1, ..., n}. For each index i ∈ V , associate a random variable X i with state space X i . Given A ⊆ V , we will denote subsets of random variables indexed by A as X A ∈ X A ≡ i∈A X i . For notational conciseness, we will sometimes use index sets to denote random variables themselves, that is, using V and A to denote X V and X A , respectively, and similarly using lower case x A to denote x A ∈ X A . Similarly, by extension, we will also use V A to denote X A and V i to denote X i . Finally, M is usually used as a mediator, and M is an SCM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries and Informational Decomposition of SCM</head><p>The centre of modern causal modeling theory lies the structural causal model (SCM) (also known as structural equation model) that makes graphical assumptions of the underlying data generating process.<ref type="foot" target="#foot_0">foot_0</ref> There are many different formulations of SCM in the literature (see, e.g., <ref type="bibr" target="#b3">Bongers et al. (2016)</ref>; <ref type="bibr" target="#b17">Pearl et al. (2009)</ref>; Pearl (2019a); Schölkopf (2019)), among which we use the definition in <ref type="bibr" target="#b1">Bareinboim et al. (2020)</ref> in this paper.</p><p>Definition 1 (SCM) A structural causal model (SCM) M is a 4-tuple (U, V, F, P (U)), where</p><p>• U is a set of background variables, also called exogenous variables, that are determined by factors outside the model;</p><p>• V is a set {V 1 , V 2 , ..., V n } of variables, called endogenous, that are determined by other variables in the models-that is, variables in U ∪ V;</p><p>• F is a set of functions {f 1 , f 2 , ..., f n } such that each f i is a mapping from(the respective domains of) U i ∪ P a i to V i , where U i ⊆ U, P a i ⊆ V \ V i , and the entire set F forms a mapping from U to V. That is, for i ∈ V = {1, ..., n}, each f i ∈ F is such that</p><formula xml:id="formula_0">v i ← f i (pa i , u i ),<label>(1)</label></formula><p>• P (U) is a probability function defined over the domain of U.</p><p>Mechanisms are activities and entities organized to produce some phenomena which are represented by structural equations in an SCM. A structural model is Markovian if the exogenous parent set U i , U j are independent whenever i = j, and the associated causal graph for a Markovian SCM M = (U, V, F, P (U)) can be defined as follows:</p><p>Definition 2 (Causal Diagrams) G(M) = (V, E) is said to be a causal diagram (of M) if constructed as follows:</p><p>• add a vertex for every endogenous variable in the set V ,</p><p>• add an edge (V j → V i ) for every i ∈ V if V j appears as an argument of f i ∈ F in the edge set E.</p><p>Various difference-making and production accounts in philosophy<ref type="foot" target="#foot_1">foot_1</ref> have been taken account by Judea Pearl for developing the structural causal modeling framework. However, the information accounts of causality, one of major approaches to study causality, has been comparatively neglected. The view of causality as information transfer was first proposed in <ref type="bibr" target="#b4">Collier (1999)</ref>, further developed by <ref type="bibr" target="#b8">Illari (2011)</ref> and <ref type="bibr" target="#b7">Illari &amp; Russo (2014)</ref>, and recently applied in neuroscience by <ref type="bibr" target="#b5">Feltz et al. (2019)</ref>. Inspired by this view of causality, we propose the informational decomposition of SCM in the following:</p><formula xml:id="formula_1">Definition 3 (Informational Decomposition of SCM) Consider an SCMM = (U, V, F, P (U)).</formula><p>The informational decomposition of M is defined as, for any i ∈ V ,</p><formula xml:id="formula_2">v i ← f i (e pa(i),i , u i ), e j,i ← v j ,<label>(2)</label></formula><p>where e j,i represents the information on edge (j, i) received from its input node V j .<ref type="foot" target="#foot_2">foot_2</ref> </p><p>Essentially, it can be interpreted as separating every causal mechanism f i into two part -information process and information transfer. Mechanisms could be seen as information channels which is one centre idea of the informational accounts <ref type="bibr" target="#b4">(Collier, 1999;</ref><ref type="bibr" target="#b7">Illari &amp; Russo, 2014)</ref>. Under this information transferring interpretation of SCM, both do intervention <ref type="bibr" target="#b11">(Pearl, 1995)</ref> and info intervention <ref type="bibr" target="#b6">(Gong &amp; Zhu, 2020)</ref> are defined as following:</p><p>Definition 4 (Do and info intervention) Given an SCM M = (U, V, F, P (U)) and any I ⊆ V, v I ∈ V I , the the do intervention do(v I ) can be defined as a modification of structural equations to</p><formula xml:id="formula_3">v i ← f i (e pa(i),i , u i ) if i / ∈ I else v i e j,i ← v j (3)</formula><p>while keeping everything else constant. And info intervention σ(V</p><formula xml:id="formula_4">I = v I ) (or, in short, σ(v I )) maps M to the info-intervention model M σ(v I )</formula><p>with a modified mechanism for every i ∈ V :</p><formula xml:id="formula_5">v i ← f i (e pa(i),i , u i ) e j,i ← v j if j / ∈ I else v j (4)</formula><p>while keeping everything else constant.</p><p>The informational decomposition of SCM reflect important epistemological distinctions about causality and lead to an alternative approach for mediation analysis. Comparing to the do intervention, the info intervention changes the information transferring instead of information processing mechanisms, which facilitates communication and theoretical focus as complementing causal modeling in terms of do operator. This motivates us to proposed a novel path intervention as modification of information transfer mechanisms. In the following section, we propose a path intervention for path-specific effect based on the above informational decomposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Path Intervention and Intervention Diagrams</head><p>Causal questions, such as what if we make something happen, can be formalized by using do intervention. However, the do intervention makes the intervention variable deterministic, by hypothetically forcing its value to a given constant. Henceforth, this causal notation is powerful but sometimes not enough for certain causal tasks, e.g., nature directed effects(NDE) defined by nested counterfactuals in mediation analysis. The dictum "no causation without manipulation" calls for an interventionist approach, recently addressed by <ref type="bibr" target="#b19">Robins et al. (2020)</ref> based on single world intervention graphs(SWIG) with certain limitation. Here, we are giving a explicit definition of path intervention based on informational decomposition of SCM.</p><p>Definition 5 (Path intervention) Consider a Makovian SCM M = (U, V, F, P (U)). Then, the path intervention π(A = a ) (or, in short, π(a )) along a causal path π from A to Y maps M to the path-intervention model M π(a ) with a modified causal mechanism for every i ∈ V :</p><formula xml:id="formula_6">         v i ← f i (e pa(i),i , u i ), e j,i ← v j , v π i ← f i (e pa(i),i , u i ), e j,i ← v j if (j, i) / ∈ π; else if V j is A , a ; else v π j ,<label>(5)</label></formula><p>while keep everything else constant. Here, v π i (standing for v π(a ) i</p><p>) and v i are in corresponding counterfactual and factual domains, respectively, u i is a realization of U i , and U i is the ith entry of U which is an independent and identically distributed (i.i.d.) copy of U.</p><p>In M π(a ) , we have a set of endogenous variables V ∪ V π(a ) , where</p><formula xml:id="formula_7">V π(a ) = {V π(a ) 1 , V π(a ) 2 , ..., V π(a ) n</formula><p>}, and all V π(a ) i (or, in short, V π i ) are referred as the effect variables of this path intervention π(a ). Hence, the path intervention in Def. 4 considers both factual and counterfactual worlds to capture the cross-world nature of path-specific effects. Moreover, since the information A = a is only transferred to the descendants of A along the path π in M π(a ) , it is easy to see that the effect variables</p><formula xml:id="formula_8">V π i d = V i for (j, i) / ∈ π.</formula><p>In view of this fact, we marginalize out the effect variables a ) . Intuitively, our path intervention creates the counterfactual variables V π to transfer the information A = a exclusively through the causal path π while allowing the information outside π to remain unchanged.</p><formula xml:id="formula_9">V π i for (j, i) / ∈ π in M π(</formula><p>We use use the NIE(natural indirect effect) as a toy example to show how our path intervention related to existing literatures.</p><p>Example 1 (Natural indirect effect) For an SCM with three endogenous variables, including treatment A, mediator M , Outcome Y , satisfies</p><formula xml:id="formula_10">   a ← f A (u A ) m ← f M (a, u M ) y ← f Y (a, m, u Y ) (6)</formula><p>The natural indirect effect(NIE) of Y on A through the mediator M depends on Y (a, M (a )) -a variable in which two different levels of a are nested within the counterfactual for Y .</p><p>For a causal path π : A → M → Y with transferred information A = a , the path intervention results in a set of modified equations</p><formula xml:id="formula_11">                   a ← f A (u A ) m ← f M (a, u M ) y ← f Y (a, m, u Y ) a π ← f A (u A ) m π ← f M (e AM , u M ); e AM ← a y π ← f Y (e AY , e M Y , u Y ); e AY ← a, e M Y ← m π (7)</formula><p>Since the causal mechanisms of a and a π coincide with the same input distribution information, the distributions of corresponding variables are the same. Henceforth, we marginalize A π out the model, results in a causal model of variables of (A, M, Y, M π , Y π ) with mechanisms:</p><formula xml:id="formula_12">             a ← f A (u A ) m ← f M (a, u M ) y ← f Y (a, m, u Y ) m π ← f M (e AM , u M ); e AM ← a y π ← f Y (e AY , e M Y , u Y ); e AY ← a, e M Y ← m π (8)</formula><p>We can derive a set of structural equations ruling out e •• : The recognition that there are mechanisms underlying the phenomena of interest, but we usually cannot determine them precisely, gives rise to the discipline of causal inference <ref type="bibr" target="#b16">Pearl et al. (2000)</ref>. Virtually every approach to causal inference works under the stringent condition that only partial knowledge of the underlying SCM is available, and usually the information of structural dependency(i.e. causal diagrams) might be sufficient for many causal effect estimation problems. Particularly, do-calculus is available for identification of causal queries when the causal structure is known, while its graphical criteria are placed on graphs which obtained by removing input/output edges on intervened variables from the original causal graph. Since every hypothetical intervention is creating a counterfactual world for domain variables, then we can define a causal graph corresponding to the modified mechanisms. We here introduce a novel graphical tool intervention diagram to further illustrate how the path intervention works.</p><formula xml:id="formula_13">             a ← f A (u A ) m ← f M (a, u M ) y ← f Y (a, m, u Y ) m π ← f M (a , u M ) y π ← f Y (a, m π , u Y )<label>(9</label></formula><p>Definition 6 (Intervention diagram) For an intervention, which can be do, info or path intervention, the causal diagram for the modified mechanisms induced by the intervention is called the intervention diagram (or graph). <ref type="foot" target="#foot_3">4</ref>To emphasis the informational accounts of causality and differences from previous causal graphs, our intervention diagrams, which is created based on the modified mechanisms by an intervention on    </p><formula xml:id="formula_14">   z ← f Z (u Z ), t ← f T (z, u T ), y ← f Y (t, z, u Y ).</formula><formula xml:id="formula_15">   z ← f Z (u Z ), t ← t , y ← f Y (e T Y ,</formula><formula xml:id="formula_16">   z ← f Z (u Z ), ← f T (e ZT , u T ); e ZT ← z, y ← f Y (e T Y , e ZY , u Y ); e T Y ← t , e ZY ← z.</formula><formula xml:id="formula_17">       z ← f Z (u Z ), t ← f T (e ZT , u T ); e ZT ← z, y ← f Y (e T Y , e ZY , u Y ); e T Y ← t, e ZY ← z, y π ← f Y (e T Y , e ZY , u Y ); e T Y ← t , e ZY ← z.</formula><p>For conciseness, we usually construct the (augmented) causal graph of those intervention SCMs without separating the variables in the counterfactual world created by the hypothetical intervention from the factual world, except for path intervention. In particular, the counterfactual variable Y do(t ) created by do intervention do(t ) is represented with notation y instead of y do (t ) . Henceforth, we are using y rather than y do(t ) or y σ(t ) in those structural equations in the formal definition of do intervention and info intervention. However, we find that the path intervention is quite different from info or do intervention in that it includes cross-world structural equation between two endogenous variable represented by z and y π . In fact, the cross-world counterfactuals involved in mediation analysis is exactly what makes it more complicated, and we need the counter-intuitive recanting witness criteria for identification with traditional methods. In contrast, our novel path specific effects exhibit intuitive interpretation and identification properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Identification of Path-specific Effects</head><p>Robins et al. ( <ref type="formula">2020</ref>) defines the potential outcome V i (π, a, a ) by setting A to a for path π that end in V i , and setting A to a for the purposes of proper causal paths from A to V i other than π. Formally, the definition is as follows, for any</p><formula xml:id="formula_18">V i ∈ V : V i (π, a, a ) ≡ a if V i is A, (<label>10</label></formula><formula xml:id="formula_19">) V i (π, a, a ) ≡ V i ({V j (π, a, a ) | V j ∈ pa π i }, {V j (a ) | V j ∈ pa π i })</formula><p>where V j (a ) ≡ a if V j is A, and given by recursive substitution otherwise, pa π i is the set of parents of V i along the path π, and pa π i is the set of all other parents of V i . Their path specific effects rely on the recursive assumption, and no recanting witness for identification. Although our path-specific effects can be defined for non-recursive SCMs, but we will not further address that problem in this paper considering the numerous complications for cyclic causal models.</p><p>Identification for path-specific effects based on nested counterfactuals for causal graphical models is governed by the criterion known as the recanting witness criterion <ref type="bibr" target="#b0">(Avin et al., 2005;</ref><ref type="bibr" target="#b21">Shpitser &amp; Tchetgen, 2016;</ref><ref type="bibr" target="#b22">Shpitser et al., 2020)</ref>. Here let's look into the causal diagrams Fig. <ref type="figure" target="#fig_0">1</ref>(a), a submodel of X, M, Y can be induced through marginalization with the causal graph X → M → Y and M → Y . This is the simplest case of mediation analysis, hence the path specific effect along π : X → Y can be identified. However, the corresponding path π : X → A → Y specific effect can not be identified because A is a recanting witness. This leads to a model with additional observational information of A to disable the identifiability of path-specific effect which conceptually contradicts the intuition that the more information the better.</p><p>In contrast, our novel path-specific effects induced by our path intervention can be identified regardless of whether it satisfies recanting witness criteria or not. In particular, for a path intervention π(a ), the joint distribution of counterfactual variables can always be identified by the π-formula. To formulate our result, we denote desc π (A) as descendants of A in the path π, i.e., all nodes in π with a parent node in causal path π.</p><p>Theorem 7 (π-formula) In a causal diagram G(of a Markovian SCMM) with a factorized probability p, for a causal path π :</p><formula xml:id="formula_20">A → • • • → Y , the joint counterfactual distribution over variables p(v π , v) for path intervention π(A = a ) is identified via a equation called the π-formula: p(v π desc π (A) , v) = k∈desc π (A) p(v π k |e π pa(k),k ) • i∈V p(v i |v pa(i) )<label>(11</label></formula><p>)</p><formula xml:id="formula_21">where e π j,k = v j if (j, k) / ∈ π; else if V j is A , a ; else v π j .</formula><p>Proof By definition of path intervention, the modified causal mechanisms for (V π , V) are, for any i ∈ V :</p><formula xml:id="formula_22">         v i ← f i (e pa(i),i , u i ) e j,i ← v j v π i ← f i (e pa(i),i , u i ) e j,i ← v j if (j, i) / ∈ π; else if V j is A , a ; else v π j</formula><p>The intervened SCM is also acyclic with independent errors, thus factorize with the following density:</p><formula xml:id="formula_23">p(v π , v) = k∈V p(v π k |e π pa(k),k ) • i∈V p(v i |v pa(i) )</formula><p>where e π j,k = v j if (j, k) / ∈ π; else if V j is A , a ; else v π j . Notice that for any counterfactual variable not in desc π (A), it receives the information directly from factual variables and the i.i.d. copy of exogenous variable. These counterfactual variables are leafs of the intervention diagram, hence marginalizing out them directly leads to the π-formula.</p><p>We then can formally identify the path specific effect for causal diagram Fig. <ref type="figure" target="#fig_0">1</ref> Note that we use latent projection onto variables of interest. In particular, we exclude the factual variable Y in the intervention graph for conciseness, which can be marginalized over the π-formula. However you cannot marginalize out factual variable M to identify the distribution of Y π . This way of constructing intervention diagram is somewhat similar to twin-network <ref type="bibr" target="#b17">(Pearl et al., 2009)</ref> for both including factual and counterfactual variables. However, there are completely different in several ways. First, the twin-SCM only have U V which connects factual and counterfactual variables, our intervention diagram includes an i.i.d. copy of U V for the corresponding intervened SCM. Second, there are no direct edges between factual and counterfactual variables in a twin-SCM. In contrast, there are no direct edges between two counterfacutal variables unless there exists an edge in π connecting them, which leads to counterfactual variables usually have no output edge in the intervention diagram. In other words, parents of counterfactual variables are usually factual variables, e.g. A, Z, W → Y π in Fig. <ref type="figure">4(b)</ref>. Third, Our intervention diagrams include probabilistic relations instead of deterministic relations, while the incompleteness of d-separation occurs in twin-SCM due to deterministic relations <ref type="bibr" target="#b22">(Shpitser et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Concluding remarks and Discussion</head><p>In this paper, by relating the informational account to SCM, we propose a novel path intervention framework to formalize path-specific effects aligned the dictum "no causation without manipulation". In the path intervention framework, the information account of causality has suggested of separating causal mechanisms into information transfer and process. Our path intervention explicitly manipulate the mechanisms, thus path-specific effects even can be well-defined for cyclic SCMs. Intuitively, our path-specific effect Y π(a ) is obtained by making the treatment information A = a exclusively pass through the causal path π while allowing all other information outside from the π to keep constant. Moreover, we address the identifiability of path-specific effects for causal diagrams and show that they can be identified even when recanting witness exists with the π-formula.</p><p>More discussions. Causality has been one of the basic topics of philosophy since the time of Aristotle. However during the last two decades or so, interest in causality has become very intense in the philosophy of science community, and a great variety of novel views on the subject have emerged and been developed. Among those novel views, it has been claimed that an informational account of causality, formally proposed and developed since <ref type="bibr" target="#b4">Collier (1999)</ref> in philosophy, might be useful to the scientific problem of how we think about, and ultimately trace, causal linking, and so to causal inference and reasoning. An informational account of causality can be useful to help us reconstruct how science builds up understanding of the causal structure of the world. Broadly, we find mechanisms that help us grasp causal linking in a coarse-grained way. Then we can think in terms of causal linking in a more fine-grained way by thinking informationally. An informational account of causality may also give us the prospect of saying what causality is, in a way that is not tailored to the description of reality provided by a given discipline. And it carries the advantage over other causal metaphysics that it fares well with the applicability problem for other accounts of production (processes and mechanism) <ref type="bibr" target="#b7">(Illari &amp; Russo, 2014)</ref>. But from an application perspective, what benefits we can gain in causal modeling? Or it is just a rhetorical flourish? Algorithmic information theory has been used in causal modeling(see e.g. <ref type="bibr" target="#b20">(Schölkopf, 2019)</ref>).It is also worth to mention that, broadly speaking, the information accounts of causality can also facilitate interpretation of existing widely used causal propositions. For example, regarding backdoor/front-door criteria, the goal of which can be consistently considered as whether the observational information of a set of variables is enough or not to answer causal-effect estimation question, instead of conventional understanding such as controlling variables. Moreover, in general sense of information accounts, Pearl points out that questions in one layer of the causal hierarchy can only be answered when corresponding layer information are available <ref type="bibr">(Pearl, 2019b;</ref><ref type="bibr" target="#b1">Bareinboim et al., 2020)</ref>, and Scholköpf believes causal science will enable us act and decision with information from Lorenzian imagined space <ref type="bibr" target="#b20">(Schölkopf, 2019)</ref>. The recently proposed Mini-Turing test for AI -How can machines represent causal knowledge in a way that would enable them to access the necessary information swiftly, answer questions correctly, and do it with ease, as a human can? <ref type="bibr" target="#b15">(Pearl &amp; Mackenzie, 2018)</ref>. In summary, to build true intelligent machines, climb the ladder of data, information, knowledge and wisdom, we might need to incorporate the information accounts of causality into causal tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>35thFigure 1 :</head><label>1</label><figDesc>Figure 1: (a) A causal diagram with a recanting witness A for the path π : X → A → Y ; (b) A cyclic causal diagram with a loop between A and Y .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>)</head><label></label><figDesc>In the above example, the path specific effect variable Y π are different from Y (a, M (a )) in two aspects. First, NIE usually considers the contrast of outcome under two given different levels a, a of the treatment, then mathematically Y (a, M (a )) = Y (A, M (a )) = Y π(a ) . Second, the interpretation is completely different for Y π , which is the effect of Y had the information A = a passed through the path π : A → M → Y while keeping other transferred information unchanged. Beyond this example, our path specific effects can even be well-defined for causal diagram with cycle, e.g. Fig 1(b), by the solution of an SCM with modified structural equations (5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Causal graphs of an SCM and three augmented intervention diagrams of its intervention SCMs.</figDesc><graphic coords="6,147.60,72.00,316.81,193.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Its do-intervention SCM M do(t ) with augmented intervention diagram Fig 2(b) has the following modified structural equations:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>e ZY , u Y ); e T Y ← t, e ZY ← z. Its info-intervention SCM M σ(t ) with the augmented intervention diagram Fig 2(c) has the following modified structural equations:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Its path-intervention SCM M π(t ) (for causal path π : T → Y with input information T = t ) with augmented intervention diagram Fig 2(d) 5 has the following modified structural equations:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Intervention diagram induced by path intervention π(x ) , where π : X → A → Y with input information X = x . Let's see a more complicated example in which M is a recanting witness. Example 4 For a causal diagram(of a Markovian SCMM) with a probability p that factorize, we consider the path intervention π(a ) for the causal path π : A → M → Y with input information A = a . Then according to intervention graph Fig. 4(b) with π-formula, we have p(y π , m π , z, m, a, w) = p(y π |m π , w, z)p(y π |w, a ) • p(z|m, a)p(m|a, w)p(a|w)p(w)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 4: (a) A causal diagram with recanting witness M ; (b) Intervention diagram.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Another popular causal modeling framework is the potential-outcome framework, and one can refer to Imbens (2020) for more details.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>See more details on<ref type="bibr" target="#b7">Illari &amp; Russo (2014)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>pai usually stands for functional parents of node i in an SCM, while pa(i) stands for parents in a causal diagram.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>Note that intervention diagrams are not restricted to path intervention. For some cases, we may also want to include exogenous variables to represent the causal mechanisms more detailed graphically, we call the causal graph of the intervention model with both exogenous and endogenous variables the augmented intervention diagram.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Since T π , Z π are not affected by the information T = t through the path π, then we marginalize out the mechanisms for them.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Identifiability of path-specific effects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Avin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On pearl&apos;s hierarchy and the foundations of causal inference</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ibeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Icard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Special</title>
		<editor>
			<persName><forename type="first">Honor</forename><surname>Of</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>provisional title</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Kenny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1173</biblScope>
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06221</idno>
		<title level="m">Theoretical aspects of cyclic structural causal models</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causation is the transfer of information</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Causation and laws of nature</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="215" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Feltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Missal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sims</surname></persName>
		</author>
		<author>
			<persName><surname>Free Will</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neuroscience</forename><surname>Causality</surname></persName>
		</author>
		<author>
			<persName><surname>Brill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11090</idno>
		<title level="m">Info intervention and its generalization</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Causality: Philosophical theory meets scientific practice</title>
		<author>
			<persName><forename type="first">P</forename><surname>Illari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Russo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>OUP</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Why theories of causality need production: An information transmission account</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Illari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="114" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Potential outcome and directed acyclic graph approaches to causality: Relevance for empirical practice in economics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Imbens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Literature</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1129" to="1179" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A potential outcomes calculus for identifying conditional path-specific effects</title>
		<author>
			<persName><forename type="first">D</forename><surname>Malinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of machine learning research</title>
		<meeting>machine learning research</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page">3080</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Direct and indirect effects</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Seventeenth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Causal and counterfactual inference. The Handbook of Rationality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The seven tools of causal inference, with reflections on machine learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="54" to="60" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The book of why: the new science of cause and effect</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mackenzie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Basic Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Models, reasoning and inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Causal inference in statistics: An overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics Surveys</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="96" to="146" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Identifiability and exchangeability for direct and indirect effects</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Epidemiology</title>
		<imprint>
			<biblScope unit="page" from="143" to="155" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shpitser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06019</idno>
		<title level="m">An interventionist approach to mediation analysis</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Causality for machine learning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10500</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Causal inference with a graphical hierarchy of interventions</title>
		<author>
			<persName><forename type="first">I</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Tchetgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2433</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Multivariate counterfactual systems and causal graphical models</title>
		<author>
			<persName><forename type="first">I</forename><surname>Shpitser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Robins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06017</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Non-parametric path analysis in structural causal models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 34th Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
