<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large-Scale Exploration of Cave Environments by Unmanned Aerial Vehicles</title>
				<funder ref="#_3DeNrBG">
					<orgName type="full">GA ČR)</orgName>
				</funder>
				<funder>
					<orgName type="full">Czech Science Foundation</orgName>
				</funder>
				<funder ref="#_48bQvQ8">
					<orgName type="full">Defense Advanced Research Projects Agency</orgName>
					<orgName type="abbreviated">DARPA</orgName>
				</funder>
				<funder ref="#_W2caphF">
					<orgName type="full">CTU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-03-06">6 Mar 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Pavel</forename><surname>Petráček</surname></persName>
							<idno type="ORCID">0000-0002-0887-9430</idno>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<postCode>166 36</postCode>
									<settlement>Prague Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vít</forename><surname>Krátký</surname></persName>
							<idno type="ORCID">0000-0002-1914-742X</idno>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<postCode>166 36</postCode>
									<settlement>Prague Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matěj</forename><surname>Petrlík</surname></persName>
							<idno type="ORCID">0000-0002-5337-9558</idno>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<postCode>166 36</postCode>
									<settlement>Prague Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tomáš</forename><surname>Báča</surname></persName>
							<idno type="ORCID">0000-0001-9649-8277</idno>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<postCode>166 36</postCode>
									<settlement>Prague Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Radim</forename><surname>Kratochvíl</surname></persName>
							<email>r_kratochvil@fce.vutbr.cz.</email>
							<idno type="ORCID">0000-0003-1884-4052</idno>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Faculty of Civil Engineering</orgName>
								<orgName type="department" key="dep2">Institute of Geodesy</orgName>
								<orgName type="institution">Brno University of Technology</orgName>
								<address>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Saska</surname></persName>
							<email>martin.saska@fel.cvut.cz</email>
							<idno type="ORCID">0000-0001-7106-3816</idno>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cybernetics</orgName>
								<orgName type="department" key="dep2">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<postCode>166 36</postCode>
									<settlement>Prague Prague 6</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">0000765 &quot;Research Center for Informatics&quot;</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Large-Scale Exploration of Cave Environments by Unmanned Aerial Vehicles</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-03-06">6 Mar 2023</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/LRA.2021.3098304</idno>
					<idno type="arXiv">arXiv:2303.02972v1[cs.RO]</idno>
					<note type="submission">received March 1, 2021; Revised May 6, 2021; Accepted July 8, 2021.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T01:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Aerial Systems: Applications</term>
					<term>Field Robots</term>
					<term>Aerial Systems: Perception and Autonomy</term>
					<term>Multi-Robot Systems</term>
					<term>Mapping</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a self-contained system for the robust utilization of aerial robots in the autonomous exploration of cave environments to help human explorers, first responders, and speleologists. The proposed system is generally applicable to an arbitrary exploration task within an unknown and unstructured subterranean environment and interconnects crucial robotic subsystems to provide full autonomy of the robots. Such subsystems primarily include mapping, path and trajectory planning, localization, control, and decision making. Due to the diversity, complexity, and structural uncertainty of natural cave environments, the proposed system allows for the possible use of any arbitrary exploration strategy for a single robot, as well as for a cooperating team. A multi-robot cooperation strategy that maximizes the limited flight time of each aerial robot is proposed for exploration and search &amp; rescue scenarios where the homing of all deployed robots back to an initial location is not required. The entire system is validated in a comprehensive experimental analysis comprising of hours of flight time in a real-world cave environment, as well as by hundreds of hours within a stateof-the-art virtual testbed that was developed for the DARPA Subterranean Challenge robotic competition. Among others, experimental results include multiple real-world exploration flights traveling over 470 m on a single battery in a demanding unknown cave environment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>drainages, and mines pose similar risks. These environments contain sediments such as debris, rocks, sand, clay, ice, decomposed organic matter, human waste, and even various forms of speleothems in limestone caves. Considering the absolute darkness, lack of GNSS signals, flowing and dripping water, humid air, and the possible presence of poisonous gases, wind gusts, hanging ropes, and wildlife, there is excessive risk to the lives of human explorers in the exploration of new environments, as well as in search &amp; rescue missions. Given the current state-of-the-art technology in robotics, many dangerous areas of subterranean systems are safely reachable using mobile robots, with the greatest focus being on vertical exploration using aerial vehicles. In contrast to human exploration, the use of such technology presents several advantages in the form of accessibility, safety, speed, instantaneous environment visualization, and precise quantification. On the other hand, challenges to the operation of mobile robots in such an environment lies in the uncertainty, lack of light, high humidity, and diversity of space in the form of narrow and/or low passages, canyons, large domes, high chimneys, and deep abysses.</p><p>The challenges to deployment of aerial vehicles in subterranean environments with respect to robot control, communication, sensor fusion, and positioning are described thoroughly in <ref type="bibr" target="#b0">[1]</ref>. These specific challenges continue to be relevant even after substantial progress in the field of mobile robotics. However, in contrast to <ref type="bibr" target="#b0">[1]</ref>, our motivation includes minimizing the need for communications required for operator control and instead focuses on the full autonomy of robots and autonomous cooperation among members of a robotic team. The restriction of communication in subterranean environments introduces challenges to the maximization of system robustness and the use of efficient decision making in the form of adaptable exploration strategies in harsh unknown environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Related work</head><p>In a non-robotic context, wild caves are explored by modernly termed cavers. However, the human surveying and mapping of caves is known to have existed for thousands of years for purposes ranging from dwelling to speleology. The significance of cave exploration and cave mapping to scientific research is a thoroughly studied inquiry in literature, e.g., in <ref type="bibr" target="#b1">[2]</ref>.</p><p>In the work presented here, we focus mainly on the robotic point of view within the scope of the application domain. One of the first cave-mapping approaches using robotic solutions was proposed in <ref type="bibr" target="#b2">[3]</ref>, where the authors employed hand-held laser scanners, which are limited in speed, accuracy, and safety. In the context of mobile robotics, topics like the automatic control of an unstable dynamic system such as an aerial multirotor vehicle <ref type="bibr" target="#b3">[4]</ref>, the fusion of inertial, visual, and laser information for localization and mapping <ref type="bibr" target="#b4">[5]</ref>, and path planning in dynamic environments <ref type="bibr" target="#b5">[6]</ref> have been addressed in order to achieve faster and safer methodology than mapping done with hand-held devices, as proposed in <ref type="bibr" target="#b2">[3]</ref>.</p><p>Within the scope of subterranean environments, the DARPA Subterranean Challenge competition has pushed the state of the art of autonomous exploration in human-made mines <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Although these systems have provided interesting solutions with great potential, the authors of <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b9">[10]</ref> rely on the predictable structure of underground mines, such as using the protraction of human-made tunnels to mark the furthest depth data as frontiers or predefining turns at junctions in <ref type="bibr" target="#b8">[9]</ref>. Since the complexity and diversity of natural caves is extensive, more robust solutions with a minimum number of environmental assumptions are required. This was tackled in <ref type="bibr" target="#b10">[11]</ref> where the authors introduced a possible way for applying autonomous drones as a technology to assist speleologists and archaeologists. Although an interesting read, the proposed methods only constitute a preliminary discussion that presents neither novel technology nor applied results. A similar discussion focusing on the state of robotic problems within the application of subterranean exploration with UAVs is presented in <ref type="bibr" target="#b11">[12]</ref>. In contrast to <ref type="bibr" target="#b10">[11]</ref>, the authors of <ref type="bibr" target="#b11">[12]</ref> present a set of preliminary experiments in laboratory conditions and two dimensional space. Unfortunately, the assumption of a planar world is highly restrictive within the scope of real-world deployment due to the complex character of natural subterranean environments.</p><p>The precise localization of mobile robots is crucial to autonomous navigation in such complex environments. Among existing state-of-the-art literature, the LOCUS algorithm <ref type="bibr" target="#b12">[13]</ref> achieves the lowest localization error at the cost of high computational demands. Unlike with ground robots, this method might be unsuitable for aerial robots as the computational resources on lightweight UAVs are scarce due to their limited payload. In <ref type="bibr" target="#b13">[14]</ref>, the authors demonstrated that localization performance can be further improved by dropping range beacons. This is a viable strategy for heterogeneous robotic teams, but unfeasible for teams of only lightweight UAVs.</p><p>The use of robotic teams for cooperative exploration has been addressed mostly in planar worlds with recurrent connectivity constraints <ref type="bibr" target="#b14">[15]</ref> or with the requirement of a centralized element <ref type="bibr" target="#b15">[16]</ref>. A similarly defined task to our problem of team homing -respecting intermittent communication, need for decentralization, and limited operation time of aerial robots -is proposed in <ref type="bibr" target="#b16">[17]</ref>, where the robots gather and share data during the mission and return all the way back to the base before their operation times out. In contrast to <ref type="bibr" target="#b16">[17]</ref>, we propose homing coordination that lands each aerial robot at a position expanding a communication relay graph, thereby increasing the time for mere exploration in tasks where return to the starting position is not required. Related to the scope of search &amp; rescue, the authors in <ref type="bibr" target="#b17">[18]</ref> propose to re-position robots in a relay-chain formation to enable data transmission over longer distances once an object of interest is found. Our solution reports the position of the objects once the explorer robot connects to the relay graph during homing. The recently developed fast exploration technique in <ref type="bibr" target="#b18">[19]</ref> maximizes explored volume over battery-limited flight time. The method is based on data only from an RGBD camera with a limited field of view (FoV). In comparison to LiDARbased methods, we have experimentally verified that RGBD cameras are sub-optimal sensors for the exploration of largescale caves due to their limited range and FoV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contributions</head><p>First, we propose a fully autonomous system enabling multimodal mapping, fast and efficient planning with sensoric fieldof-view constraints for safe movement in 3D, robust localization, and adaptable decision making. Second, a multi-robot cooperation for the efficient homing of a team of autonomous explorer robots is proposed. Third, the system has been validated through hundreds of hours of testing in a state-of-theart virtual testbed developed for the DARPA Subterranean Challenge robotic competition, as well as through hours of flight time in the real world. To the best of our knowledge, the presented large-scale experimental deployment of autonomous aerial robots in a natural cave environment goes beyond the current state of the art in autonomous robotics. Lastly, we present and share the experience obtained during this comprehensive experimental deployment that was carried out in close cooperation with speleologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. EXPERIENCE GAINED</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Speleology motivation</head><p>From the speleological point of view, aerial systems are crucial for pushing exploratory state-of-the-art methods to provide assistance in efficient scouting of difficult-to-access areas in vertical environments, as well as for the quick inspection of known areas using onboard sensors only. These systems minimize risks for humans by reducing the need to climb or to swim in cold water reservoirs, and also through the detection of poisonous gases or even radioactive waste. Furthermore, this enables the preservation and protection of natural environments against human influence, including ancient sediment forms, floor dripstone formations, paleontological and archaeological sites, and sources of potable water.</p><p>In contrast to well-established methods of subterranean documentation (i.e., theodolite and level/distance meter, compass, and clinometer), modern technology employs stationary and mobile laser scanners to produce a dense 3D model of the environment. Due to the complexity of natural environments, the use of stationary scanners is time-consuming because of the necessity of eliminating occluded spaces. Although handheld mobile scanners are more time-efficient in this context, their use is limited to areas accessible to humans. This limitation opens the door for mobile robotics which is able to tackle this challenge and to provide optimized 3D mapping. State-ofthe-art mapping in such environments reaches decimeter level precision, which is less precise than stationary scanners, yet sufficient for the majority of speleological needs. Moreover, the common issue of mapping drift accumulation in longcorridor spaces can be minimized using reference measurements by precise stationary scanners or man-measured control points to obtain accurate results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. System requirements</head><p>The primary prerequisite of a team of aerial explorers that can be deployed in caves involves the ability to adapt to diverse, unknown environments lacking sources of light and access to GNSS. This general description requires the abilities to</p><p>• be deployed in constrained cavities, as well as in open caverns of natural caves, • map and visualize the environment in a fast, quantified manner in the form of dense point clouds and image streams, • seamlessly infuse an arbitrary exploration strategy for more efficient mission operation within the scope of individual environments (policy selection is discussed in Sec. IV), • return to the mission operator and promptly visualize the environment for human supervision, and • maximize operation capabilities in terms of coverage when a team of robots is employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Depth estimation in high humidity</head><p>The performance of the PMD pico flexx time-of-flight (ToF) camera and the Intel Realsense D435 stereo camera have been analyzed as complementary sensors to the primary LiDAR for the purpose of improving the sensory FoV coverage. Although ToF cameras generally outperform stereo cameras in terms of distance measurement precision and density of measurement points <ref type="bibr" target="#b19">[20]</ref>, the high humidity typically present in natural caves causes dispersion of light emitted from ToF cameras by small water droplets. This effect significantly degrades the acquired measurements. As was verified empirically, ToF cameras can produce false-negative measurements of obstacles situated behind clouds of water droplets. The use of stereo cameras (e.g., Realsense) is recommended for its robustness to environmental conditions within natural caves. Nevertheless for large cave systems, such a sensor needs to be combined with 3D LiDARs in order to comply with the requirements of speleologists and first responders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SYSTEM ARCHITECTURE</head><p>The system of the proposed autonomous explorer robot is divided into multiple groups of individual interconnected modules to be described in this section. All components and their relations are visualized in Fig. <ref type="figure" target="#fig_1">2</ref>. </p><formula xml:id="formula_0">T d x d ω d ω IMU , R IMU R LOAM r LOAM r, ω, R<label>High</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Perception</head><p>The perception of the proposed system is based on a multichannel LiDAR sensor that is used for both building the spatial representation of the surrounding environment in the Mapping module, as well as for the motion estimation in the LOAM module. Obtaining the full-state estimate is realized within the State estimation module, where multiple sources of incomplete state measurements are fused together using a bank-offilters estimator.</p><p>The vertical navigation capabilities of the system can be greatly improved by equipping the robot with vertically-facing RGBD cameras that are able to fill in the blind spots in the limited vertical FoV of the LiDAR. Apart from navigation, these optional sensors may be used for detecting objects of interest in caves in search &amp; rescue scenarios or for visual documentation of newly explored cave systems.</p><p>1) LiDAR: Even though our system is not tied to a specific LiDAR model, there are certain important parameters that can affect the performance and capabilities of the platform.</p><p>To reliably stabilize the UAV, the time delay of the estimated state must stay below the threshold of a certain critical value depending on the type of controller and gains. When this threshold is exceeded, the UAV begins oscillating and eventually automatically lands when the control error is too large to continue the mission safely. We have found experimentally that for most combinations of localization methods and controllers, the critical value ranges from 100 ms to 200 ms. Thus, 10 Hz is the lowest rotation frequency that can be used without employing methods of delay compensation.</p><p>The typical values of a vertical field of view (VFoV) of 3D LiDARs are in the 30°to 90°range. The higher VFoV values improve vertical mobility in constrained spaces, however with a low VFoV, it is impossible to safely navigate narrow vertical shafts as it is not known whether the space above the UAV is free and safe to fly through, or whether it contains an obstacle.</p><p>2) RGBD: The regions above and below the UAV that are not covered by the LiDAR can be captured using a depth camera or by spinning the LiDAR sensor around a vector that is orthogonal to the axis of scanning, as seen in <ref type="bibr" target="#b20">[21]</ref>. However, such a solution adds additional weight to the sensor, which decreases the available flight time. A blind spot also still remains as part of the laser rays is blocked by the frame of the UAV. Alternatively, lightweight depth cameras can be mounted on opposite sides of the body frame in order to cover most blind spots of the LiDAR. Additional sensing modality is gained by combining an RGB and depth camera in a single sensor (RGBD) with a slight weight increase.</p><p>3) Localization: For localization of the UAV, we have adapted the LOAM algorithm <ref type="bibr" target="#b21">[22]</ref>. This state-of-the-art method is very precise (0.55 % translation error <ref type="bibr" target="#b22">[23]</ref>) while attaining real-time performance. In our adapted version of the open-source implementation, the algorithm is optimized on CPU and employs parallel computing, which enables us to deploy and use the localization in the real-time position control feedback loop onboard fast-moving aerial vehicles.</p><p>4) Mapping: The LOAM-based algorithm builds a sparse internal representation of the environment consisting of edge and planar features. However, this sparse map is unsuitable for navigation purposes. Additionally, the LOAM map does not consider the probabilistic nature of the sensor, nor does it distinguish free and unknown space. Both of these factors are necessary in exploration techniques for reliable navigation and consistent frontier selection.</p><p>In the proposed system, the environment is represented by a dense probabilistic volumetric map, which consists of cubic cells with one of 3 states: free, occupied, or unknown. The map is kept in the octree structure to facilitate the Bayesian integration of new measurements and efficient access to individual cells of the probabilistic map. The high-level systems, such as grid-based path planning or inter-robot map registration, also benefit from quick access to the dense environment representation. This approach is capable of multi-modal fusion by integrating the data from all available onboard sensors and outputting point-cloud measurements. If high-level path planning is constrained by the field of view of onboard sensors (tackled in <ref type="bibr" target="#b23">[24]</ref> and also in Sec. III-C), the multi-modality of mapping enables arbitrary movement in 3D.</p><p>5) Sensor processing: The targeted subterranean environments may have high humidity or may contain large clouds of whirling dust. The water and dust particles can then produce erroneous measurements for the LiDAR-based sensors. Assuming a partial reflection from water or dust particles and a large energy dissipation of distant reflections, these erroneous measurements can be filtered with respect to the measured intensity of returning light rays. As has been empirically verified, a simple threshold-based filtration over the intensity channel within the local neighborhood of the sensor is sufficient for filtering out false-positive measurements. The idea of the local filtration is to filter out particles gusting through the surrounding air due to the aerodynamic influence of the propellers. Although the cutoff threshold of the intensity magnitude is environment-specific, filtering out measurements below the 10 th percentile of the intensity distribution per each laser scan proved to be a reliable solution, even in the dustiest real-world environments. Such processing is unavailable for camerabased systems that may require thorough, computationallyexpensive solutions to overcome these challenges.</p><p>6) State estimation: The reference controller (see Sec. III-B2) requires a position estimate of the UAV body frame in the world frame r = (x, y, z), the velocity of the body frame ṙ, rotation R from the UAV body frame to the world frame, and angular velocity ω in the body frame in order to close the feedback loop. The LOAM localization method provides 6-DoF pose estimate, i.e., r LOAM , R LOAM , which are fused in the State estimation block with interoceptive measurements from the IMU of the Autopilot to obtain the rest of the state variables.</p><p>The details about the estimation process are described in <ref type="bibr" target="#b24">[25]</ref>. Nevertheless, it is worth highlighting the importance of the fusion of orientation R IMU and R LOAM in cave environments. While R IMU is very precise and without delay, the heading of the UAV (i.e., the measured direction of the bodyfixed, forward-facing axis) is unreliable due to the presence of ferromagnetic ores in the cave rocks that cause deviations in the magnetometer measurements. By correcting these errors with the heading from R LOAM in the estimation process, the resulting orientation R is robust to changes in the erratic magnetic field in subterranean environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Tracking &amp; control</head><p>The safe navigation of constrained environments with low obstacle clearance imposes the requirements of precise trajectory tracking with minimal control error, as any deviation from the desired state could potentially result in a collision. The Reference controller is responsible for minimizing the control error around the desired control reference that is provided by the Reference tracker. The controller outputs an attitude rate reference for the low-level Attitude rate controller in the Autopilot.</p><p>1) Reference tracker: The Reference tracker is essential in providing the Reference controller with smooth and feasible references to ensure a safe flight. The tracker based on the model predictive control (MPC) simulates an ideal virtual model of the UAV with constrained translational states up to jerk, together with heading and heading rate. The input can be either a single pair of desired 3D position p d and heading η d , or a trajectory T d in the form of a sequence of such pairs with a specified sampling rate. The full state of the virtual model is then sampled at 100 Hz, and r d , ṙd , rd , ṙd , η d , ηd are passed to the Reference controller as reference x d .</p><p>2) Reference controller: The agile SE(3) geometric state feedback controller <ref type="bibr" target="#b25">[26]</ref> minimizes the position and velocity errors. To compensate imperfect calibration and external forces acting upon the UAV, the controller is extended with the body and world disturbance terms described in <ref type="bibr" target="#b24">[25]</ref>. The output attitude rate reference ω d is tracked by the Autopilot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Path planning</head><p>The planning approach used to safely navigate through apriori unknown environments must fulfill requirements of realtime responsiveness and efficient global planning in order to fully exploit the limited flight time of UAVs. For this purpose, fast iterative post-processing is applied to the output of an optimal grid-based planner in order to increase the UAVobstacle distance above a minimum threshold <ref type="bibr" target="#b26">[27]</ref>. The gridbased planner and the iterative post-processing do not apply an optimistic assumption that the unknown space is collisionfree. Although this visibility-constrained precondition requires high sensory coverage around the robot to allow for arbitrary movement in 3D, it consequently prevents collisions of the trajectory being followed, even if replanning would fail. This methodology improves safety and robustness of the overall flight, allows for deployment in completely unknown environments without any apriori information, and permits seamless navigation in open spaces, as well as safe movement through narrow passages.</p><p>Common grid-based planning methods require preprocessing of an employed map representation, such as determining and applying the 3D distance transform for obstacle growing. This may introduce significant computational overhead by bottle-necking system performance, as the map must then be processed in every planning step. Such a computationally expensive task contradicts the requirements for responsiveness within evolving dynamic environments. To minimize the overall time required for a single planning iteration, a local KD-tree representation of the environment is used to decide the feasibility of particular cells within a voxel grid. This approach shifts the largest load from the pre-processing phase to the planning phase, which is beneficial especially to shorter plans that require searching only a small part of the environment. The low computational demands of the applied planning approach enable frequent replanning the global plan, which is also crucial for the efficient use of newly-discovered collision-free space.</p><p>To effectively exploit the limited flight time of aerial explorers, all mid-flight stops are eliminated by computing in parallel the next exploration goal during path following. The path to the next goal is efficiently appended to the rest of the current reference trajectory T d using the prediction horizon of the MPC (see Sec. III-B). The need for precise locomotion control in complex natural caves makes uniform path-sampling unfeasible with respect to the dynamic constraints of a UAV and fast, collision-free trajectory tracking. Therefore, the reference trajectory T d provided by the Navigation &amp; planning module to the Reference tracker is computed based on the following process.</p><p>Given the dynamical constraints of the robot, the generated path is uniformly sampled with a sampling distance adapted to the maximum velocity magnitude v max of the UAV. Based on this initial trajectory T i , the required acceleration magnitudes a n between consequent transition points are computed by velocity differentiation as</p><formula xml:id="formula_1">a n (k) = ||v i (k + 1) -v i (k)|| 2 t s ,<label>(1)</label></formula><p>where v i (k) is the required velocity vector for transition from a transition point t i (k) to t i (k + 1) on the initial trajectory T i and t s is a constant sampling period. The new velocity for a k-th segment is then given by</p><formula xml:id="formula_2">v k = max v max amax an , v min if a n (k) &gt; a max , v max if a n (k) ≤ a max ,<label>(2)</label></formula><p>where the minimum velocity v min serves as a parameter balancing the precision and the time needed for trajectory tracking. By this step, the velocities for particular segments are set so that the maximum velocity is applied in straight segments, while lower velocities are applied in curved segments of any given path.</p><p>To further improve trajectory sampling and to achieve smoother changes in velocities, the sampling distance on particular segments is computed so that the motion along each segment has the constant acceleration</p><formula xml:id="formula_3">a k = |v k+1 -v k | t acc,k ,<label>(3)</label></formula><p>where t acc,k is the time available for acceleration on the k-th segment. The time t acc,k is obtained from the length l k of the segment k and the required change of the velocity. The number of transition points N k on the k-th segment of the initial trajectory T i is given as</p><formula xml:id="formula_4">N k =      l k v k ts if a k = 0, tacc ts if a k &gt; 0,<label>(4)</label></formula><p>where the desired constant acceleration is adapted to meet the velocity v k+1 at the end of each segment as</p><formula xml:id="formula_5">a k = a k N k t s . (<label>5</label></formula><formula xml:id="formula_6">)</formula><p>The sequence of sampling distances for the k-th segment of T i is then given by</p><formula xml:id="formula_7">d k,i = v k t s + ia k t s 2 , i ∈ {1, • • • , N k }.<label>(6)</label></formula><p>The trajectory sampled with sampling distances defined by ( <ref type="formula" target="#formula_7">6</ref>) is passed to the Reference tracker <ref type="bibr" target="#b24">[25]</ref> as a reference trajectory T d in order to generate a feasible reference x d for the Reference controller. Despite its simplicity, the described sampling method achieves better results within the scope of the proposed application than the optimization-based trajectory generation methods proposed in <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>. In contrast to the proposed method, the problem in <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref> is defined in such a way that the exact positions of all the path waypoints must be visited, generating significantly slower trajectories.</p><p>IV. EXPLORATION POLICY Cave environments are naturally diverse and require various different mission strategies suitable for specific environments. Deriving the optimal policy is thereby dependent on various factors, such as the expected mission output, mission-specific constraints, the complexity and the specifics of the environment, and the number of available robots. For this reason, our system is designed so that any arbitrary policy can be utilized within the scope of an autonomous mission.</p><p>Nevertheless, two exploratory mission types are of the most use in practice: deep cave exploration and full-coverage exploration. These missions are used for scouting previously uncovered areas in order to obtain a general overview of the environment, monitor environmental changes such as gas leaks, detect natural water reservoirs, discover new possible passages, or assess the structural state of cavern walls and other objects of interest. The former approach maximizes the explored volume of space in the entire environment, while the latter minimizes the blind spots missed by onboard cameras with a constrained FoV.</p><p>The capabilities of a robotic mission are furthered with the use of multiple cooperating robots. To show an example of such improvement using a team of agents as opposed to a single agent, a homing strategy that maximizes the flight time of aerial robots during a multi-robotic mission is proposed in the following subsection. During the proposed coordination, continuous exploration is not assumed and distance-constrained ad-hoc communication is used. The robots are homogeneous and generate their behaviors in a decentralized manner based on their current state and the available information from other robots (only positions in a shared frame are required).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multi-robot homing strategy</head><p>A cooperative operation maximizing the flight time of a multi-robot team is proposed for applications where homing all the deployed robots to an initial location is not required. This strategy is suitable for tasks where the possible gained information is superior to the cost of the robots, such as in search &amp; rescue scenarios. This method assumes there is access to a low-bandwidth communication link among any two robots within an omnidirectional communication radius.</p><p>To maximize the flight time, the robots utilize local communication to plan the homing path such that a group of robots is able to build up a communication tree with the base station as the root communication node. This allows the robots to optimize their flight time by navigating back to a location in the proximity of another communication node (a landed robot, base station, or self-sustaining communication node deployed by other robots) when the battery capacity becomes drained. This entire homing strategy is showcased in an example scenario for two independent robots in Fig. <ref type="figure">3</ref>.</p><p>In the proposed strategy, each robot constructs a navigation homing tree using nodes created from the set of past poses of the robot. This online-built tree has edges valued by the required flight time between two nodes and is used to estimate required homing time to the proximity of a communication node. The pose nodes are connected such that each path leafto-communication is the shortest (see Fig. <ref type="figure">3a</ref>). A homing path is constructed recursively as a sequence of tree nodes from the current robot position (a leaf) to the nearest communication node, with the landing position being within communication range of the nearest communication node (see Fig. <ref type="figure">3b</ref>). The tree is shared among the robots deployed in the same mission. The knowledge from the previous explorers is integrated to prolong their flight time (see Fig. <ref type="figure">3c</ref>), thus causally maximizing the time capacity for the exploration task. When a communication node (e.g., a robot landing pose) is integrated into the homing tree, it is linked exclusively to another communication node to join the retranslation chain (see Fig. <ref type="figure">3d</ref>). Consequently, the parents of neighboring pose nodes are updated so that each pose node has a parent with the minimal accumulated cost to any communication node (see Fig. <ref type="figure">3b</ref> and Fig. <ref type="figure">3d</ref>). The process of inserting pose nodes as well as communication nodes into the homing tree is described in Alg. 1.</p><p>V. EXPERIMENTAL ANALYSIS The entire proposed system has been validated through hours of flight time in the real world, as well as in hundreds of hours in various virtual subterranean environments. The results of these experimental analyses are presented hereafter. 18:</p><formula xml:id="formula_8">P ← P ∪ N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Real-world environment</head><p>To analyze the properties of the system, a fully autonomous aerial robot (see Fig. <ref type="figure" target="#fig_4">4</ref>) was deployed for several hours of flight time in the Bull Rock Cave located in the central Moravian Karst of the Czech Republic (see Fig. <ref type="figure" target="#fig_0">1</ref> and the attached multimedia materials).</p><p>During multiple autonomous exploratory missions, a single explorer (see the hardware components of the robot in Fig. <ref type="figure" target="#fig_4">4</ref>) was deployed to validate the proposed system in various exploratory scenarios. The flight trajectories from all missions are visualized in Fig. <ref type="figure" target="#fig_6">5a</ref> and the mission statistics and performance metrics of the mapping module are summarized in Table I. A greedy frontier-navigation policy was employed such that the frontier closest to the lateral direction of flight (A, B), the highest frontier (C), and frontier with the largest ratio of unknown to free cells in a bounded area (D) was selected as the next goal. With respect to these experiments in a harsh subterranean environment, we have</p><p>• validated the performance of the system by flying in large cave domes, as well as in narrow corridors just 70 cm wider than the dimensions of the robot,  I: Quantitative evaluation on multiple autonomous exploratory missions within the Bull Rock Cave system. The flight trajectories and qualitative analysis of the mapping accuracy are shown in Fig. <ref type="figure" target="#fig_6">5</ref>.</p><p>• validated the real-time performance and robustness of the system in multiple autonomous horizontally-deep flights longer than 470 m using just a single battery and reaching a maximal velocity up to 2 m s -1 , • validated the ability to autonomously explore natural domes in terms of vertical depth, • verified the ability to perform a full mission and return to an initial location with the obtained information, • quantified the accuracy of the onboard-built maps with respect to a ground truth map of the environment, and • obtained feedback from speleologists in order to design the system following their requirements. The dense onboard-built maps (20 cm resolution) from all the experiments were merged (manual global registration with local ICP refinement) during post-processing to obtain the map of the environment M. The reference ground truth map M gt was built by registering over 100 largely overlapping scans taken by a Leica BLK360 terrestrial 3D scanner. The mapping accuracy over all the experiments reached mean µ = 0.37 m and standard deviation σ = 0.46 m using the point-to-point Euclidean error metric between each point in M and the corresponding closest point in M gt . The distribution of the mapping errors throughout all flights is visualized in Fig. <ref type="figure" target="#fig_6">5b</ref>. As specified by the end-users, the decimeter-level mapping precision achieved over the course of these exceptionally fast and extensive flights is sufficient for the majority of speleological needs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Virtual environment</head><p>To validate the proposed methodology for multi-robot coordination using a local low-bandwidth communication network, a team of aerial robots was deployed for hundreds of hours of flight in a virtual environment using a virtual testbed developed for the DARPA Subterranean Challenge competition.  This state-of-the-art testbed consists of several large-scale cave environments containing dynamic obstacles and models of real-world interference, such as sensor discrepancies, communication schemes, and battery longevity.</p><p>In contrast to real-world experiments, the virtual environment is larger and allows for the seamless verification of multirobotic cooperation. To demonstrate the performance of the proposed homing strategy, a selected example scenario of such an operation is presented in Fig. <ref type="figure" target="#fig_7">6</ref>. This experiment highlights the positive influence of the homing strategy in a search &amp; rescue scenario where the three explorers were able to exploit the increased flight time. With a 50 m communication range and 1.2 m s -1 average velocity for each robot, the homing cooperation increased the available flight time for exploration by 40 s and 80 s, respectively. Moreover, the experiment shows the influence of multi-sensor mapping, which allowed the black robot to single-handedly explore the upper floor of the virtual environment. The final exploratory trajectories of the cooperating robots during the presented mission reached lengths of 715 m, 1349 m, and 1405 m.</p><p>The influence of the homing strategy on the time available for mere exploration is also quantitatively analyzed in Table <ref type="table">II</ref>. The results were averaged over six separate deployments, each with five cooperating robots. Identical mission parameters were set to all the robots for the baseline <ref type="bibr" target="#b16">[17]</ref>, as well as for the proposed method. The data show an increasing trend in the available mission time for belated explorers for which the effective exploration phase is consequently prolonged during their entire operation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>This letter presents a comprehensive study on the use of autonomous aerial explorers as an assisting technology for the exploration of natural cave environments. This study also  shares the experience acquired during the technology's development in close cooperation with a team of speleologists, cavers, and first responders.</p><p>The proposed self-sustaining system interconnects solutions for all crucial robotic tasks in order to enable full autonomy in complex unknown subterranean environments without access to GNSS. Among others, this includes laser-data processing which copes with high humidity and dustiness within subterranean environments and robust path-planning for unknown dynamic environments to allow for flights in constrained cavities, as well as in open caverns of natural caves. Moreover, a multi-robot cooperation is proposed for the efficient homing of a team of robots for applications where the possible information gain is superior to the costs of the robots, such as search &amp; rescue scenarios in cave systems. The performance of the entire applicable system was validated in one of the most large-scale experimental analyses ever conducted, consisting of hours of flight time in Bull Rock Cave (Czech Republic, Moravian Karst) and in hundreds of hours in the state-ofthe-art virtual testbed developed for the DARPA Subterranean Challenge. This presented analysis of the entire system proves that it is a robust solution capable of reliable planning with sensoric field-of-view constraints and accurate mapping. The accuracy of localization and mapping was evaluated with respect to a ground-truth map of the cave environment and reached mean precision below 40 cm in real-world conditions. This performance has satisfied the requirements of speleologists and first responders.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Robotic exploration of the Bull Rock Cave (central Moravian Karst, Czech Republic) by a fully autonomous aerial vehicle.</figDesc><graphic coords="2,311.98,174.54,251.04,124.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2: Individual interconnected modules form the system architecture of the autonomous explorer robot. The High-level planning modules focus on achieving the mission objectives by generating references for the Tracking &amp; control modules based on the map built by the Perception modules. This also provides a state estimate for closing the control feedback loop. All modules except the Autopilot group are handled by the main onboard computer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>BFig. 3 :Algorithm 1 : 8 : 9 : 14 :</head><label>318914</label><figDesc>Fig. 3: An example scenario of the homing strategy for two robots (red and blue) that maximizes flight time by landing at feasible positions while building a communication chain to a base station. Algorithm 1: Insertion of a node into the onboard-built homing tree. Function cost(na, n b ) returns an estimate of flight time among nodes na and n b , function accumulatedCost(na) returns the required flight time from node na to the nearest communication node, and function freeRay(na, n b ) returns true if a linear path between nodes na and n b is collision-free in 3D. 1: procedure INSERTNODETOHOMINGTREE 2:Input:</figDesc><graphic coords="7,334.40,155.97,109.39,88.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: General hardware components of an autonomous explorer robot. All data are processed and reasoned over with an onboard processing unit. The main source of data comes from the top-mounted LiDAR.</figDesc><graphic coords="8,48.96,538.68,251.05,101.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Overview of the cave environment with the trajectories of all exploration missions (see TableI) performed within Bull Rock Cave. The figure shows deep cave missions (A, B), vertical flight (C), and the thorough exploration of a bounded area (D). Visual analysis on the mapping accuracy -the distribution of mapping errors during all autonomous exploration tasks as summarized in TableI. The color bar legend represents the mapping error in meters using the point-to-point euclidean error metric.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Full-coverage exploration of the Bull Rock Cave system (located in the central Moravian Karst, Czech Republic) with autonomous aerial explorers. Full resolution figure is available within the attached multimedia.</figDesc><graphic coords="8,326.18,191.10,238.50,68.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Three autonomous explorers deployed in a virtual cave world within the DARPA simulation testbed. The robots finished their missions by building a communication tree with maximal edge length of dc = 50 m.</figDesc><graphic coords="9,59.85,56.06,238.50,212.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Influence of the homing strategy on the flight time available for mere exploration. Comparison with a baseline time of 321 s (averaged over 10 flights) where a robot returned to base before its operation timed out.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE</head><label></label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="funding">
<div><p>This paper was recommended for publication by Editor <rs type="person">Pauline Pounds</rs> upon evaluation of the Associate Editor and Reviewers' comments. The work was supported by the <rs type="funder">Czech Science Foundation</rs> (<rs type="funder">GA ČR)</rs> under research project no. <rs type="grantNumber">20-29531S</rs>, by <rs type="funder">CTU</rs> grant no. <rs type="grantNumber">SGS20/174/OHK3/3T/13</rs>, by the <rs type="funder">Defense Advanced Research Projects Agency (DARPA)</rs>, and by <rs type="projectName">OP VVV</rs> funded project CZ.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_3DeNrBG">
					<idno type="grant-number">20-29531S</idno>
				</org>
				<org type="funding" xml:id="_W2caphF">
					<idno type="grant-number">SGS20/174/OHK3/3T/13</idno>
				</org>
				<org type="funded-project" xml:id="_48bQvQ8">
					<orgName type="project" subtype="full">OP VVV</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Opportunities for autonomous UAV in harsh environments</title>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName><forename type="first">La</forename><surname>Scalea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ISWCS</title>
		<imprint>
			<biblScope unit="page" from="227" to="232" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The importance of cave exploration to scientific research</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kambesis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cave and Karst Studies</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">2007</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Three-Dimensional Mobile Mapping of Caves</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zlot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cave and Karst Studies</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="191" to="206" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Position and attitude control of multirotor aerial vehicles: A survey</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Saska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Reviews in Control</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Review of Visual-LiDAR Fusion based Simultaneous Localization and Mapping</title>
		<author>
			<persName><forename type="first">C</forename><surname>Debeunne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vivet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">2068</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Survey on computational-intelligence-based UAV path planning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="54" to="64" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LAMP: Large-Scale Autonomous Mapping and Positioning for Exploration of Perceptually-Degraded Subterranean Environments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ebadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ICRA</title>
		<imprint>
			<biblScope unit="page" from="80" to="86" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Explore Locally, Plan Globally: A Path Planning Framework for Autonomous Robotic Exploration in Subterranean Environments</title>
		<author>
			<persName><forename type="first">T</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ICAR</title>
		<imprint>
			<biblScope unit="page" from="9" to="16" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mine Tunnel Exploration Using Multiple Quadrupedal Robots</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA-L</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2840" to="2847" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Robust UAV System for Operations in a Constrained Environment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Petrlík</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA-L</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2169" to="2176" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SmartCaveDrone: 3D cave mapping using UAVs as robotic co-archaeologists</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ICUAS</title>
		<imprint>
			<biblScope unit="page" from="1052" to="1057" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed subterranean exploration and mapping with teams of UAVs</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G R</forename><surname>Iii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR VIII</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10190</biblScope>
			<biblScope unit="page" from="285" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LOCUS: A Multi-Sensor Lidar-Centric Solution for High-Precision Odometry and 3D Mapping in Real-Time</title>
		<author>
			<persName><forename type="first">M</forename><surname>Palieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA-L</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="421" to="428" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Range-Aided Pose-Graph-Based SLAM: Applications of Deployable Ranging Beacons for Unknown Environment Exploration</title>
		<author>
			<persName><forename type="first">N</forename><surname>Funabiki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA-L</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="55" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Coordinated Multi-Robot Real-Time Exploration with Connectivity and Bandwidth Awareness</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Pei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ICRA</title>
		<imprint>
			<biblScope unit="page" from="5460" to="5465" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Coordinated Multi-Robot Exploration</title>
		<author>
			<persName><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="376" to="386" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-UAV Exploration with Limited Communication and Battery</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cesare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="2230" to="2235" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An Autonomous Multi-UAV System for Search and Rescue</title>
		<author>
			<persName><forename type="first">J</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DroNet</title>
		<imprint>
			<biblScope unit="page" from="33" to="38" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">FUEL: Fast UAV Exploration Using Incremental Frontier Structure and Hierarchical Planning</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA-L</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="779" to="786" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Three depth-camera technologies compared</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pece</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First BEAMING Workshop</title>
		<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Online 3D Frontier-Based UGV and UAV Exploration Using Direct Point Cloud Visibility</title>
		<author>
			<persName><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE MFI</title>
		<imprint>
			<biblScope unit="page" from="263" to="270" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Low-drift and real-time lidar odometry and mapping</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="401" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite</title>
		<author>
			<persName><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR, 05</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fast Autonomous Flight in Warehouses for Inventory Applications</title>
		<author>
			<persName><forename type="first">M</forename><surname>Beul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA-L</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3121" to="3128" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The MRS UAV System: Pushing the Frontiers of Reproducible Research, Real-world Deployment, and Education with Autonomous Unmanned Aerial Vehicles</title>
		<author>
			<persName><forename type="first">T</forename><surname>Baca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Intell Robot Syst</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">26</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Geometric tracking control of a quadrotor UAV on SE(3)</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CDC</title>
		<imprint>
			<biblScope unit="page" from="5420" to="5425" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An Autonomous Unmanned Aerial Vehicle System for Fast Exploration of Large Complex Indoor Environments</title>
		<author>
			<persName><forename type="first">V</forename><surname>Krátký</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JFR</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Polynomial trajectory planning for aggressive quadrotor flight in dense indoor environments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Richter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics Research</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Real-Time Visual-Inertial Mapping, Re-localization and Planning Onboard MAVs in Unknown Environments</title>
		<author>
			<persName><forename type="first">M</forename><surname>Burri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE IROS</title>
		<imprint>
			<biblScope unit="page" from="1872" to="1878" />
			<date type="published" when="2015-09">Sept 2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
