<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Non-Probability Sampling Network for Stochastic Human Trajectory Prediction</title>
				<funder>
					<orgName type="full">National IT Industry Promotion Agency of Korea</orgName>
					<orgName type="abbreviated">NIPA</orgName>
				</funder>
				<funder>
					<orgName type="full">GIST</orgName>
				</funder>
				<funder ref="#_PGQtrkU">
					<orgName type="full">Artificial Intelligence Graduate School Program (GIST)</orgName>
				</funder>
				<funder>
					<orgName type="full">Vehicles AI Convergence Research &amp; Development Program</orgName>
				</funder>
				<funder>
					<orgName type="full">GIST-MIT Collaboration</orgName>
				</funder>
				<funder>
					<orgName type="full">National Research Foundation of Korea</orgName>
					<orgName type="abbreviated">NRF</orgName>
				</funder>
				<funder>
					<orgName type="full">Institute of Information &amp; communications Technology Planning &amp; Evaluation</orgName>
					<orgName type="abbreviated">IITP</orgName>
				</funder>
				<funder ref="#_Gehdw4h #_9Kfck6X">
					<orgName type="full">Korea government (MSIT)</orgName>
				</funder>
				<funder ref="#_evK64RU">
					<orgName type="full">Ministry of Science and ICT</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Inhwan</forename><surname>Bae</surname></persName>
							<email>inhwanbae@gm.gist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Graduate School</orgName>
								<orgName type="institution" key="instit2">GIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jin-Hwi</forename><surname>Park</surname></persName>
							<email>jinhwipark@gm.gist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Graduate School</orgName>
								<orgName type="institution" key="instit2">GIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hae-Gon</forename><surname>Jeon</surname></persName>
							<email>haegonj@gist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Graduate School</orgName>
								<orgName type="institution" key="instit2">GIST</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Non-Probability Sampling Network for Stochastic Human Trajectory Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T01:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Capturing multimodal natures is essential for stochastic pedestrian trajectory prediction, to infer a finite set of future trajectories. The inferred trajectories are based on observation paths and the latent vectors of potential decisions of pedestrians in the inference step. However, stochastic approaches provide varying results for the same data and parameter settings, due to the random sampling of the latent vector. In this paper, we analyze the problem by reconstructing and comparing probabilistic distributions from prediction samples and socially-acceptable paths, respectively. Through this analysis, we observe that the inferences of all stochastic models are biased toward the random sampling, and fail to generate a set of realistic paths from finite samples. The problem cannot be resolved unless an infinite number of samples is available, which is infeasible in practice. We introduce that the Quasi-Monte Carlo (QMC) method, ensuring uniform coverage on the sampling space, as an alternative to the conventional random sampling. With the same finite number of samples, the QMC improves all the multimodal prediction results. We take an additional step ahead by incorporating a learnable sampling network into the existing networks for trajectory prediction. For this purpose, we propose the Non-Probability Sampling Network (NPSN), a very small network (∼5K parameters) that generates purposive sample sequences using the past paths of pedestrians and their social interactions. Extensive experiments confirm that NPSN can significantly improve both the prediction accuracy (up to 60%) and reliability of the public pedestrian trajectory prediction benchmark. Code is publicly available at <ref type="url" target="https://github.com/inhwanbae/NPSN">https://github.com/inhwanbae/NPSN</ref> .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The goal of predicting pedestrian trajectories is to infer socially-acceptable paths based on previous steps while considering the social norms of other moving agents. Many earlier works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b57">58]</ref> on human trajectory prediction are based on deterministic approaches which yield the * Corresponding author Figure <ref type="figure">1</ref>. An illustration of a probability distribution of stochastic trajectory prediction and selected paths from each sampling method. While the trajectories from the random sampling are biased in that they do not consider space of all possible distributions, our NPSN purposively generates the accurate route, turning to SHOP, even with its low probability. most likely single path. One of the earliest works in <ref type="bibr" target="#b14">[15]</ref> models a social force using attractive and repulsive forces between pedestrians. Since then, motion time-series and agent interactions have been applied to trajectory forecasting. With the development of recurrent neural networks (RNNs), pioneering works such as, Social-LSTM <ref type="bibr" target="#b0">[1]</ref> and Social-Attention <ref type="bibr" target="#b54">[55]</ref>, have adopted a social pooling and attention mechanisms between spatial neighbors. These approaches have become baseline models in areas such as spatial relation aggregation <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b51">52]</ref> and temporal future prediction <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63]</ref>.</p><p>Recently, generative models, which infer the distribution of potential future trajectories, are likely to inspire a major paradigm shift away from the single best prediction methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b63">64]</ref>. The generative models represent all possible paths, such that pedestrians may go straight, turn left/right at an intersection or take a roundabout way to avoid obstacles. To efficiently establish this multi-modality, a stochastic process is introduced to the trajectory prediction <ref type="bibr" target="#b12">[13]</ref>, which models the inferred uncertainty of pedestrians' movements in every time frame. Stochastic trajectory prediction models start by generating a random hypothesis. Due to the non-deterministic nature of random sampling, the quality of the hypotheses depends on the number of samples. Ideally, an infinite number of hypotheses would be able to characterize all possible movements of pedestrians, but this is infeasible. In prac- tice, a fixed number of multiple trajectories are randomly sampled using the Monte Carlo (MC) method, and all existing stochastic models follow this random sampling strategy. However, the number of samples is typically too small to represent socially-acceptable pedestrian trajectories because they are biased toward the random sampling, as illustrated in Fig. <ref type="figure">1</ref>.</p><p>In this paper, we revisit the state-of-the-art works which employ the stochastic process for multimodal prediction (Fig. <ref type="figure" target="#fig_0">2-(a)∼(c)</ref>). We prove that all of the expected values in the generated trajectory distributions with Generative Adversarial Networks (GANs) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17]</ref>, Conditional Variational Auto-Encoders (CVAEs) <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b46">47]</ref>, and Gaussian methods <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b48">49]</ref> are biased. Afterward, we introduce a Quasi-Monte Carlo (QMC) sampling method that effectively alleviates this problem using a low-discrepancy sequence, instead of random sampling. Lastly, we push the random sampling forward with a learnable method: Non-Probability Sampling Network (NPSN), a very small network that generates purposive sample sequences using observations and agent interactions in Fig. <ref type="figure" target="#fig_0">2-(d</ref>). Without structurally modifying the existing models in any way, we achieve significant improvements in the performance of pedestrian trajectory prediction. This is accomplished by replacing one line of code on random sampling with our NPSN. Interestingly, one of the existing models using our NPSN as an auxiliary module achieves the best performance in all evaluation metrics.</p><p>Unlike previous methods, the proposed approach focuses on the sampling method to generate a set of random latent vectors. To the best of our knowledge, our work is the first attempt to adopt QMC sampling and to propose a learnable method for purposive sampling in trajectory forecasting in Fig. <ref type="figure">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Stochastic trajectory prediction</head><p>Convolutional neural network (CNN)-based approaches using Gaussian distribution have improved the efficiency of pedestrian trajectory prediction. Social-LSTM <ref type="bibr" target="#b0">[1]</ref>, a pioneering model in this field, predicts a bivariate Gaussian distribution consisting of five parameters for the observed trajectories of pedestrians. However, it has a limitation when inferring single paths, since it only selects the best one sample from the distribution in inference time. Followup works <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b54">55]</ref> predict multiple paths by sampling multiple next coordinates based on predicted distributions.</p><p>As another methodology, a generative model is introduced to predict realistic future paths. Social-GAN <ref type="bibr" target="#b12">[13]</ref> firstly uses a generative framework that recursively infers future trajectory. The benefit of GAN is that it generates various outputs according to latent vectors. As a result, inter-personal, socially acceptable and multimodal human behaviors are accounted for in the pedestrian trajectory prediction. Such a research stream encourages to define a variety loss which calculates for the best prediction among multiple samples for diverse sample generation. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>Similarly, there have been attempts to predict diverse future generations using CVAE frameworks. DESIRE <ref type="bibr" target="#b22">[23]</ref> uses a latent variable to account for the ambiguity of future paths and learns a sampling model to produce multiple hypotheses of future trajectories from given observations. This approach provides a diverse set of plausible predictions without the variety loss, and shares inspiration to objectives in many CVAE-based models <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b59">60]</ref>.</p><p>All of these methods include a random sampling process and are sensitive to bias, due to the fixed number of samples, as above mentioned. In addition, current state-ofthe-art models with CVAE frameworks outperform Gaussian distribution-based methods <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b48">49]</ref>. In this study, we analyze these phenomena with respect to the bias of stochastic trajectory prediction, and show that the Gaussian distributionbased approaches achieve noticeable performance improvements by minimizing the bias, even better than the CVAEbased methods. Lastly, we mention a recent deterministic approach <ref type="bibr" target="#b62">[63]</ref> that predicts multiple trajectories, which is beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Learning latent variables</head><p>Some works account for the transformation of latent spaces by using prior trajectory information. PECNet <ref type="bibr" target="#b33">[34]</ref> for example uses a truncation trick in latent space to adjust the trade-off between the fidelity and the variety of samples. In their learning approach, both IDL <ref type="bibr" target="#b27">[28]</ref> and Tra-jectron++ <ref type="bibr" target="#b46">[47]</ref> predict the mean and standard deviation of a latent distribution in an inference step. Rather than directly predicting the distribution parameters, AgentFormer <ref type="bibr" target="#b60">[61]</ref> uses a linear transform of Gaussian noise to produce the latent vector. These methodologies still run the risk of bias because of the random sampling of the latent vectors. In the present work, we aim to reduce the bias using a discrepancy loss of a set of sampled latent vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Graph-based approaches</head><p>Pioneering works have introduced the concepts of socialpooling <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b50">51]</ref> and social-attention mechanisms <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b61">62]</ref> to capture the social interactions among pedestrians in scenes. Recently, Graph Neural Network (GNN)-based approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref> have been introduced to model agent-agent interactions with graph-based policies.</p><p>In the GNN-based works, pedestrians are regarded as nodes of the graph, and their social relations are represented as edge weights. Social-STGCNN <ref type="bibr" target="#b38">[39]</ref> presents a Graph Convolutional Network (GCN) <ref type="bibr" target="#b20">[21]</ref>-based trajectory prediction which aggregates the spatial information of distances among pedestrians. Graph Attention Networks (GATs) <ref type="bibr" target="#b53">[54]</ref> implicitly assign more weighting to edges with high social affinity on the pedestrian graph <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b59">60]</ref>. Multiverse <ref type="bibr" target="#b29">[30]</ref> and SimAug <ref type="bibr" target="#b28">[29]</ref> utilize GATs on 2D grids to infer feasible trajectories. Unlike these previous works, where GATs are used in the encoding process, we apply a GAT framework to a sampling process on the latent space to make a decoder predict future paths more accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Monte Carlo Sampling Method</head><p>(Quasi-) Monte Carlo is a computational technique for numerical experiment using random numbers. Exploiting the random numbers allows one to approximate integrals, but this is highly error prone. The error directly depends on the random sampling methods from probability distributions. QMC sampling is developed with quasi-random sequences, known as low-discrepancy sequences <ref type="bibr" target="#b39">[40]</ref> and is generated in a deterministic manner. It is widely utilized for many computer vision tasks, such as depth completion <ref type="bibr" target="#b55">[56]</ref>, 3D reconstruction <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b56">57]</ref>, motion tracking <ref type="bibr" target="#b64">[65]</ref> and neural architecture search <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. We firstly apply QMC sampling to ensure uniform coverage of the sampling spaces for pedestrian trajectory prediction. Note that the sequence is uniformly distributed if the discrepancy tends to be zero, as the number of samples goes to infinity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Generated Trajectories Are Biased</head><p>In this section, we start with the problem definition for pedestrian trajectory prediction in Sec. 3.1. We then theoretically demonstrate that generated trajectories from stochastic trajectory prediction models are biased toward random sampling in Sec. 3.2. We also introduce a way to alleviate the bias with a low-discrepancy sequence for stochastic prediction in Sec. 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Definition</head><p>We formulate the pedestrian trajectory prediction task as a multi-agent future trajectory generation problem conditioned on their past trajectories. To be specific, during the observation time frames 1 ≤ t ≤ T obs , there are L pedestrians in a scene. The observed trajectory sequence is represented as X 1:T obs l = {X t l |t ∈ [1, ..., T obs ]} for ∀l ∈ [1, ..., L], where x t l is the spatial coordinate of each pedestrian l at time frame t. With the given observed sequence, the goal of the trajectory prediction is to learn potential distributions to generate N plausible future sequences</p><formula xml:id="formula_0">Ŷ 1:T pred l = { Ŷ t l,n |t ∈ [1, ..., T pred ], n ∈ [1, ..., N ]} for all L pedestrians.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Stochastic Trajectory Prediction is Biased.</head><p>The generated trajectory Ŷ 1:T pred l comes from a distribution of possible trajectories which are constructed by pedestrians' movements based on social forces (Fig. <ref type="figure" target="#fig_1">3</ref>). T truth is an expectation value computed with a plausible trajectory distribution, and T gen is calculated with Ŷ 1:T pred l of N which are independent and identically distributed (IID) random samples, i.e. the term is random if one uses different samples to generate trajectories. The expectation T gen is a Monte Carlo estimate of integral, i.e. relevant expectation.</p><p>Suppose that the expectation we want to compute from the trajectory distribution is I(τ ) = [0,1] s τ (x)q(x)dx which is the expected value of τ (x) for random variable x with a density q on s-dimensional unit cube [0, 1] s . Then, the Monte Carlo estimator for the generated trajectory distribution with N samples can be formulated as below:</p><formula xml:id="formula_1">Î(τ ) = ÎN,s (τ ) = 1 N N i=1 τ (x i ),<label>(1)</label></formula><p>P r(</p><formula xml:id="formula_2">lim n→∞ Î(τ ) = I(τ )) = 1,<label>(2)</label></formula><p>where P r(•) denotes a probability. By the Strong Law of large numbers <ref type="bibr" target="#b11">[12]</ref>, the MC estimate converges to I(τ ) as the number of samples N increases without bound. Now, we assume that τ (x) has a finite variance K(τ ) and define the error α as below:</p><formula xml:id="formula_3">α = ÎN,s (τ ) -I(τ ),<label>(3)</label></formula><formula xml:id="formula_4">E[α] = 0, var(α) = K(τ ) N ,<label>(4)</label></formula><p>where E is an expectation and K(t) is (τ (x) -I(τ )) 2 q(x)dx. Note that the K(τ ) is non-negative and depends on the function being integrated. The algorithmic goal is to specify the procedure that results in lower variance estimates of the integral. Now consider a function of the generator F , which is sufficiently smooth, in a Monte Carlo integral I(τ ). We apply the Taylor series expansion of F (I(τ )+α) as follows:</p><formula xml:id="formula_5">F ( ÎN,s (τ )) = F (I(τ )+α) (5) ≈ F (I(τ ))+αF ′ (I(τ ))+α 2 F ′′ (I(τ )) 2 +O(α 3 ).</formula><p>Therefore, the expectation value of F ( ÎN,s (τ )) can be formulated as below:</p><formula xml:id="formula_6">E[F ( ÎN,s (τ ))] = F (I(τ )) + M N + O( 1 N 2 ),<label>(6)</label></formula><p>where M = K(τ )(F ′′ (I(τ ))/2) and the M N is a bias. Since the term T gen is estimated with an MC integration, the estimate must have a bias of M N + O( 1 N 2 ). Note that the bias in the generated trajectories vanishes for N → ∞, however, it is infeasible to utilize all infinite possible paths in practice. Since M depends on the generator, the generated trajectories are differently biased depending on the number of generated samples as well as the generators, which is validated in Sec. 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Quasi-Monte Carlo for Trajectory Prediction</head><p>The QMC method utilizes a low discrepancy sequence including the Halton sequence <ref type="bibr" target="#b13">[14]</ref> and the Sobol sequence <ref type="bibr" target="#b18">[19]</ref>. Inspired by <ref type="bibr" target="#b41">[42]</ref>, we select a Sobol sequence which not only shows consistently better performances than the Halton sequence, but also is up to 5 times faster than the MC method, even with lower error rates.</p><p>From the view of numerical analysis, an inequality in <ref type="bibr" target="#b40">[41]</ref> proves that low-discrepancy sequences guarantees more advanced sampling in Eq. ( <ref type="formula" target="#formula_2">2</ref>) with fewer integration errors as below:</p><formula xml:id="formula_7">|α| ≦ V (τ ) D * N ,<label>(7)</label></formula><p>where V (τ ) is a total variation of function τ which is bounded variation, and D * N is the discrepancy of a sequence for the number of samples N . The inequality shows that a deterministic low-discrepancy sequence can be much better than the random one, for a function with finite variation. In the mathematics community, it has been proven that the Sobol sequences have a rate of convergence close to O((logN ) s /N ); for a random sequence it is O( log(logN )/N ) in <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>. For faster convergence, s needs to be small and N large (e.g., N &gt; 2 s ). As a result, the low discrepancy sequences have lower errors for the same number of points (N = 20) as shown in Tab. 1.</p><p>As an example, since x i are IID samples from a uniformly distributed unit box for MC estimates, the samples tend to be irregularly spaced. For QMC, as x i comes from a deterministic quasi-random sequence whose point samples are independent, they can be uniformly spaced. This guarantees a suitable distribution for pedestrian trajectory prediction by successively constructing finer uniform partitions. Fig. <ref type="figure" target="#fig_2">4</ref> displays a plot of a moderate number of pseudo-random points in 2-dimensional space. We observe regions of empty space where there are no points generated from the uniform distribution, which produce results skewed towards the specific destinations. However, the Sobol sequence yields evenly distributed points to enforce prediction results close to socially-acceptable paths. Unfortunately, low-discrepancy sequences such as the Sobol sequence are deterministically generated and make the trajectory prediction intractable when representing an uncertainty of pedestrians' movements with various social interactions. Adding randomness into the Sobol sequence by scrambling the sequence's base digits <ref type="bibr" target="#b2">[3]</ref> is a solution to this problem. The resultant sequence retains the advantage of QMC method, even with the same expected value. Accordingly, we utilize the scrambled Sobol sequence to generate pedestrian trajectories to account for the feasibility, the diversity, and the randomness of human behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Non-Probability Sampling Network</head><p>In this section, we propose NPSN, which extends the sampling technique for pedestrian trajectory prediction based on observed trajectory. Unlike the previous methods, which sample N paths in a stochastic manner, we construct a model that effectively chooses target samples using a nonprobabilistic sampling technique illustrated in Fig. <ref type="figure" target="#fig_0">2-(d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Non-Probability Sampling on Multimodal Trajectory Prediction</head><p>In contrast to stochastic sampling, purposive sampling, one of the most common non-probability sampling techniques <ref type="bibr" target="#b3">[4]</ref>, relies on the subjective judgment of an expert to select the most productive samples rather than random selection. This approach is advantageous when studying complicated phenomena in in-depth qualitative research <ref type="bibr" target="#b36">[37]</ref>.</p><p>Since most people walk to their destinations using the shortest path, a large portion of labeled attributes in public datasets <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b42">43]</ref> are straight paths. Generative attribute models learn the probabilistic distributions of social affinity features for the attribute of straight paths. However, due to the multimodal nature of human paths, the models must generate as many diverse and feasible paths as possible, using only a fixed number of samples. As a possible solution, we can purposively include a variety of samples on turning left/right and detouring around obstacles. In purposive sampling, a maximum variation is beneficial for multimodal trajectory prediction, when examining the diverse ranges of pedestrians' movements. We make this process a learnable method, aiming to generate N heterogeneous trajectory samples with prior knowledge of past trajectories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">NPSN Architecture</head><p>We propose NPSN which substitutes the random sampling process of existing models with a learnable method. NPSN works as purposive sampling, which relies on the past trajectories of pedestrians when selecting samples in the distribution. As a result, when predicting a feasible future trajectory, a past trajectory can be used for the sampling process while also embedding informative features as a guidance. Unlike existing works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b60">61]</ref> that impose a restriction in the sampling space by limiting a distribution, we design all of the processes in a learnable manner. Pedestrian graph representation. NPSN first captures the social relations using a GAT to generate sociallyacceptable samples. For input trajectory X 1:T obs l , a pedestrian graph G = (V, E) is defined as a set of pedestrian nodes V = {v l | l ∈ [1, ..., L]} and their relation edges</p><formula xml:id="formula_8">E = {e i,j | i, j ∈ [1, ..., L]}. With the node features H = {h l |l ∈ [1, ..., L</formula><p>]}, learned feature maps for the social relation are shared across different pedestrian nodes in a scene. We utilize an attention mechanism for modeling the social interaction, whose effectiveness is demonstrated in previous works <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b48">49]</ref>. The GAT allows NPSN to aggregate the features for neighbors by assigning different importance to their edge e i,j . Here, the importance value is calculated using the attention score between two node features (h i , h j ). Purposive sampling. With the interaction-aware node features, we predict N samples for each pedestrian. In particular, we use three MLP layers after the GAT layer for NPSN. By learning more prior information about samples of interest, prediction models using NPSN generate better samples. Each trajectory prediction model additionally receives an s-dimensional random latent vector along with the observed trajectory. Therefore, the NPSN must predict a set of output S l = [S l,1 , ..., S l,N ]. The output passes through a prediction model to generate N final trajectories for each pedestrian. For temporal consistency, we use the same set of purposive samples for all prediction time frames [1, ..., T pred ] of each pedestrian node. This process is repeated for all pedestrian nodes, and the output shape of the NPSN is S = R L×s×N . Loss function. To optimize trajectory prediction models with our NPSN, we use two loss functions to generate welldistributed purposive samples. First, a winner-takes-all process <ref type="bibr" target="#b44">[45]</ref>, which generates a path closest to its ground truth, is trained to regress the accurate positions of pedestrians. Similar to <ref type="bibr" target="#b12">[13]</ref>, we measure a L 2 distance between the N prediction paths and the ground-truth, and use only one path with the smallest error for training:</p><formula xml:id="formula_9">L dist = 1 L L l=1 min n∈[1,...,N ] || Ŷ 1:T pred l,n -Y 1:T pred l ||. (8)</formula><p>However, we observe that all N sample points are sometimes closely located near its ground-truth as learning progresses. This is a common problem in purposive sampling, because certain samples can be over-biased due to data imbalance, i.e. a large portion of the trajectory moving along one direction of the walkway. For this reason, we introduce a novel discrepancy loss to keep the N sample points with low-discrepancy, as below:</p><formula xml:id="formula_10">L disc = 1 LN L l=1 N i=1 -log min j∈[1,...,N ] j̸ =i ||S l,i -S l,j ||. (<label>9</label></formula><formula xml:id="formula_11">)</formula><p>The objective of discrepancy loss is to maximize distances among the closest neighbors of N samples. If the distance is closer, the loss imposes a higher penalty to ensure their uniform coverage of the sampling space.</p><p>The final loss function is a linear combination of both the distance and the discrepancy loss L = L dist + λL disc . We set λ = 1e-2 to balance the scale of both terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Implementation Details</head><p>Transformation of one distribution to another. While most human trajectory prediction models use a normal distribution, the Sobol sequence and our NPSN are designed to produce a uniform distribution. We bridge the gap by transforming between the uniform distribution and the normal distribution. There are some representative methods including Ziggurat method <ref type="bibr" target="#b35">[36]</ref>, Inverse Cumulative Distribution Function (ICDF), and Box-Muller Transform <ref type="bibr" target="#b4">[5]</ref>. In this work, we utilize the Box-Muller transform which is differentiable and enables an efficient execution on a GPU with the lowest QMC error, as demonstrated in <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b65">66]</ref>. The formula of the Box-muller transform is as follows:</p><formula xml:id="formula_12">Z odd = -2 ln(U even ) cos(2πU odd ),</formula><p>Z even = -2 ln(U even ) sin(2πU odd ), <ref type="bibr" target="#b9">(10)</ref> where U is an independent sample set from a uniform distribution and Z is an independent random variable from a standard normal distribution. Training Procedure. Our NPSN is embedded into the state-of-the-art pedestrian trajectory prediction models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49]</ref> by simply replacing their random sampling part. The parameters of the models are initialized using the weights provided by the authors, except for four models <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b46">47]</ref> which use weights reproduced from the authors' source codes. Our NPSN has only 5,128 learnable parameters on s = 2 and N = 20. We train the prediction models with NPSN using an AdamW optimizer <ref type="bibr" target="#b32">[33]</ref> with a batch size of 128 and a learning rate of 1e-3 for 128 epochs. We step down the learning rate with a gain of 0.5 at every 32 epochs. Training time takes about three hours on a machine with an NVIDIA 2080TI GPU. Social-STGCNN <ref type="bibr" target="#b38">[39]</ref> (s = 2)    <ref type="bibr" target="#b38">[39]</ref>, SGCN <ref type="bibr" target="#b48">[49]</ref>, SGAN <ref type="bibr" target="#b12">[13]</ref>, STGAT <ref type="bibr" target="#b16">[17]</ref>, Trajectron++ <ref type="bibr" target="#b46">[47]</ref>,</p><formula xml:id="formula_13">SGCN [49] (s = 2) MC (Baseline) QMC NPSN MC (Baseline) QMC NPSN ADE ↓ FDE ↓ TCC ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ETH 0.</formula><formula xml:id="formula_14">MC (Baseline) QMC NPSN MC (Baseline) QMC NPSN ADE ↓ FDE ↓ TCC ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ETH 0.</formula><formula xml:id="formula_15">MC (Baseline) QMC NPSN MC (Baseline) QMC NPSN ADE ↓ FDE ↓ TCC ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ADE ↓ FDE ↓ TCC ↑ Gain ↑ ETH 0.</formula><p>and PECNet <ref type="bibr" target="#b33">[34]</ref> in N = 20. Models are evaluated on the ETH <ref type="bibr" target="#b42">[43]</ref>, UCY <ref type="bibr" target="#b24">[25]</ref>, SDD <ref type="bibr" target="#b43">[44]</ref>, and GCS <ref type="bibr" target="#b58">[59]</ref> datasets. (Gain: performance improvement w.r.t. FDE over the baseline models, Unit for ADE and FDE: meter, Bold:Best, Underline:Second best)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we conduct comprehensive experiments on public benchmark datasets to verify how the sampling strategy contributes to pedestrian trajectory prediction. We first briefly describe our experimental setup (Sec. 5.1), and then provide comparison results with various baselines and state-of-the-art models (Sec. 5.2). Moreover, we run an extensive ablation study to demonstrate the effect of each component of our method (Sec. 5.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>Dataset. We evaluate the effectiveness of the QMC method and our NPSN on various benchmark datasets <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b58">59</ref>] over state-of-the-art methods. ETH <ref type="bibr" target="#b42">[43]</ref> and UCY dataset <ref type="bibr" target="#b24">[25]</ref> include ETH and HOTEL, and UNIV, ZARA1 and ZARA2 scenes, respectively. Both datasets consist of various movements of pedestrians with complicated social interactions. The Stanford Drone Dataset (SDD) <ref type="bibr" target="#b43">[44]</ref> contains secluded scenes with various object types (e.g. pedestrian, biker, skater, and cart), and the Grand Central Station (GCS) <ref type="bibr" target="#b58">[59]</ref> dataset consists of highly congested scenes where pedestrians walk. We observe a trajectory for 3.2 seconds (T obs = 8), and then predict future paths for the next 4.8 seconds (T pred = 12). We follow a leave-one-out cross-validation evaluation strategy, which is the standard evaluation protocol used in many works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49]</ref>. Evaluation metric. We measure the performance of the trajectory prediction models using three metrics: 1) Aver-age Displacement Error (ADE) -average Euclidean distance between a prediction and ground-truth trajectory; 2) Final Displacement Error (FDE) -Euclidean distance between a prediction and ground-truth final destination; 3) Temporal Correlation Coefficient (TCC) <ref type="bibr" target="#b52">[53]</ref> -Pearson correlation coefficient of motion patterns between a prediction and ground-truth trajectory. These metrics assess the best one of N = 20 trajectory outputs, and we report average values for all agents in each scene. In addition, to reduce the variance in the prediction results of stochastic models, we repeat the evaluation 100 times and then average them for each metric. Baseline. We evaluate QMC and NPSN sampling methods with representative stochastic pedestrian trajectory prediction models: 1) Gaussian distribution-based model -Social-STGCNN <ref type="bibr" target="#b38">[39]</ref>, SGCN <ref type="bibr" target="#b48">[49]</ref>; 2) GAN-based model -Social-GAN <ref type="bibr" target="#b12">[13]</ref>, STGAT <ref type="bibr" target="#b16">[17]</ref>, Causal-STGAT <ref type="bibr" target="#b5">[6]</ref>; 3) CVAEbased model -Trajectron++ <ref type="bibr" target="#b46">[47]</ref>, PECNet <ref type="bibr" target="#b33">[34]</ref>, and NCE-Trajectron++ <ref type="bibr" target="#b31">[32]</ref>. To validate the effectiveness of QMC and NPSN, we replace their random sampling parts in the authors' provided codes with our QMC and NPSN sampling method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results from QMC and NPSN method</head><p>Comparison of MC and QMC. We compare MC with the QMC method by incorporating them into the sampling part of the baseline models. As shown in Tab. 1 and Fig. <ref type="figure" target="#fig_3">5</ref>, the QMC method significantly outperforms the MC method on all the evaluation metrics. In Fig. <ref type="figure" target="#fig_3">5</ref>, we report the error  <ref type="bibr" target="#b38">[39]</ref>, (b) SGCN <ref type="bibr" target="#b48">[49]</ref>, (c) SGAN <ref type="bibr" target="#b12">[13]</ref>, (d) STGAT <ref type="bibr" target="#b16">[17]</ref>, (e) Trajectron++ <ref type="bibr" target="#b46">[47]</ref>, and (f) PECNet <ref type="bibr" target="#b33">[34]</ref>. Figure <ref type="figure">6</ref>. Visualization of probabilistic distributions and the best predictions among sampled trajectories with MC, QMC, and NPSN in SGCN <ref type="bibr" target="#b48">[49]</ref>.</p><p>distributions of the baseline models in the test phase. The QMC method achieves consistently lower errors and variations by alleviating the bias problem mentioned in Sec. 3.2.</p><p>We also observe that the Gaussian-based models show a large performance gain over the GAN-and CVAE-based models. There are two reasons for the performance gains induced by the QMC method: 1) The dimension of the sampling space (s = 2) in the Gaussian-based models is relatively smaller than other models (i.e. s = 8, 16 or 25). According to <ref type="bibr" target="#b23">[24]</ref>, for large dimensions s and a small number of samples N , the sampling results from a low-discrepancy generator may not be good enough over randomly generated samples. The Gaussian-based model thus yields promising results compared to one which has larger sampling dimensions. 2) The performance improvements depend on the number of layers in networks (shallower is better): The CVAE and GAN-based models are composed of multiple layers. By contrast, the Gaussian-based models have only one layer which acts as a linear transformation between the predicted trajectory coordinates and final coordinates. To be specific, in the transformation, sampled independent 2D points are multiplied with the Cholesky decomposed covariance matrix and shifted by the mean matrix. Here, the shallow layer of the Gaussian-based models directly reflects the goodness of the QMC sampling method, rather than deeper layers which can barely be influenced by the random latent vector in the inference step. Evaluation of NPSN. We apply NPSN to all three types of stochastic trajectory prediction models. As shown in Tab. 1, there are different performance gains according to the types. Particularly, the Gaussian distribution approaches (Social- STGCNN <ref type="bibr" target="#b38">[39]</ref>, SGCN <ref type="bibr" target="#b48">[49]</ref>) show the highest performance improvement (up to 60%), which can be analyzed by the advantages of the QMC method when s = 2. So far, the performance of the Gaussian distribution approaches has been underestimated due to the disadvantage of being easily affected by the sampling bias. Our NPSN maximizes the capability of the Gaussian distribution approaches through a purposive sampling technique.</p><p>In the CVAE based approaches, PECNet <ref type="bibr" target="#b33">[34]</ref> shows a larger performance improvement (up to 41%) than that of Trajectron++ <ref type="bibr" target="#b46">[47]</ref>. Since PECNet directly predicts a set of destinations through the latent vector, NPSN is compatible with its inference step. On the other hand, NPSN seems to produce less benefit with the inference step of Trajectron++ because it predicts the next step recurrently and its sample dimension is relatively large (s = 25).</p><p>The generative models with variety loss, Social-GAN and STGAT, show relatively small performance improvements, compared to the others. For some datasets, the FDE values of STGAT are lower than those of MC and QMC when using our NPSN. This seems to suggest that NPSN fails to learn samples close to ground-truth trajectories due to the common entanglement problem of latent space <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20]</ref>. Qualitative results. Fig. <ref type="figure">6</ref> shows several cases where there are differences between the predictions of NPSN and other methods. Since NPSN takes an observation trajectory along with the low-discrepancy characteristics of the QMC method, the predicted paths from NPSN are closer to socially-acceptable paths compared to other methods.</p><p>As we described in the Fig. <ref type="figure" target="#fig_2">4</ref>, the QMC method generates a more realistic trajectory distribution than the MC method. However, due to the limitations of the dataset, the generated trajectories of the baseline network are biased toward a straight path. On the other hand, NPSN sampling method alleviates the problem by selecting the point near the groundtruth in the latent space. As a result, the human trajectory model with NPSN not only generates well-distributed samples with finite sampling pathways, but also represents the feasible range of human's movements.  <ref type="bibr" target="#b48">[49]</ref> (Gaussian distribution approach), STGAT <ref type="bibr" target="#b16">[17]</ref> (GAN-based approach) and PECNet <ref type="bibr" target="#b33">[34]</ref> (CVAE-based approach). We quantify the performance change w.r.t. the sampling methods including MC, QMC and NSPN. We also report the results of deterministic trajectory prediction when N = 1 in gray colored regions.</p><p>Comparison with the state-of-the-art models. We push the state-of-the-art models with our NPSN, a purposive sampling technique. As shown in Tab. 1, our NPSN shows a significant performance improvement on all the baseline networks. NPSN provides better overall accuracy by taking fully advantage of the low-discrepancy characteristics of the QMC method.</p><p>In addition, we report a benchmark result on ETH/UCY dataset in Tab. 2. It is noticeable that all the baseline models exhibit better performances with our NPSN. In particular, when NPSN is incorporated into the combinational approach of Trajectron++ <ref type="bibr" target="#b46">[47]</ref> and NCE <ref type="bibr" target="#b31">[32]</ref>, it achieves the best performances on the benchmark. Our NPSN is trained to only control the latent vector samples for the baseline models, and synergizes well with the inference step that comes after both the initial prediction of Trajectron++ and the collision avoidance of NCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation Studies</head><p>Evaluation of different number of samples. To check the effectiveness of the density of sampled paths in human trajectory prediction, we randomly generate trajectories by changing the number of samples N . As shown in Fig. <ref type="figure" target="#fig_4">7</ref>, the performance gap between the MC and the QMC method is marginal when the number of samples goes to infinity. As mentioned above, it follows the Strong Law of large numbers in the MC integration. The Gaussian-based model, SGCN <ref type="bibr" target="#b48">[49]</ref>, achieves superior performance and improves more than 30% performance gain over the classic policy (N = 20). Since the sample dimension is small, the effectiveness and convergence of our NPSN are enlarged. Note that a performance drop over sparse conditions due to the discrepancy property: For small N and a comparably large sample space dimension (i.e., N &lt; 2 s ), the discrepancy of the QMC method may not be less than that of a random sequence. We overcome these limitations with a learnable sampling method by sampling a feasible latent vector with low-discrepancy characteristics. Deterministic trajectory prediction. Since the stochastic model is trained to predict multi-modal future paths, it outputs diverse paths at each execution, which is undesirable for deterministic human trajectory prediction, which infers only one feasible pathway (N = 1). By replacing the conventional probability process with a learnable sampling, NPSN allows the stochastic models to infer the most feasible trajectory in a deterministic manner. As shown in Fig. <ref type="figure" target="#fig_4">7</ref> (gray colored regions), NPSN outperforms QMC and the conventional methods on all the metrics at N = 1.</p><p>Effectiveness of each component. Lastly, we examine the effectiveness of each component in our NPSN, whose result is reported in Tab. 3. Here, SGCN <ref type="bibr" target="#b48">[49]</ref> is selected as the baseline model because it shows the most significant performance improvements with NPSN. First, our two loss functions work well. Particularly, the discrepancy loss guarantees sample diversity by generating low-discrepancy samples, and the distance loss enforces generating samples close to the ground-truth trajectory. The GAT captures the agent-aware interaction for socially-acceptable trajectory prediction, except for the secluded ETH scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we numerically analyze the limitations of the conventional sampling process in stochastic pedestrian trajectory prediction, by using the concept of discrepancy as a measure of the sampling quality. To overcome this limitation, we then introduce a novel, light-weight and learnable sampling strategy, inspired by the Quasi-Monte Carlo method. Unlike conventional random sampling, our learnable method considers both observations and the social norms of pedestrians in scenes. In addition, our method can be inserted into stochastic pedestrian trajectory predictions as a plug-andplay module. With the proposed learnable method, all of the state-of-art models achieve performance improvements. In particular, the Gaussian-based models show the best results on the benchmark.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Illustrations of stochastic human trajectory prediction and our NPSN method. The red box indicates the latent vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. An example of the probability map of the truth plausible trajectory distribution and the generated distributions with N = 20 samples Ŷ 1:T pred l</figDesc><graphic coords="3,180.60,87.67,93.52,57.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. (Top): 2D scatter plots of 1,000 points with MC, QMC and NPSN. Stars indicate coordinates of a GT destination in the sampling space. (Bottom): Stochastic trajectory prediction results with the first 20 samples of the 1,000 points from each method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Box plots of average ADE, FDE and TCC measured for each stochastic model on both MC and QMC. (a) STGCNN<ref type="bibr" target="#b38">[39]</ref>, (b) SGCN<ref type="bibr" target="#b48">[49]</ref>, (c) SGAN<ref type="bibr" target="#b12">[13]</ref>, (d) STGAT<ref type="bibr" target="#b16">[17]</ref>, (e) Trajectron++<ref type="bibr" target="#b46">[47]</ref>, and (f) PECNet<ref type="bibr" target="#b33">[34]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Averaged ADE/FDE/TCC results on ETH/UCY datasets w.r.t. the number of samples for SGCN<ref type="bibr" target="#b48">[49]</ref> (Gaussian distribution approach), STGAT<ref type="bibr" target="#b16">[17]</ref> (GAN-based approach) and PECNet<ref type="bibr" target="#b33">[34]</ref> (CVAE-based approach). We quantify the performance change w.r.t. the sampling methods including MC, QMC and NSPN. We also report the results of deterministic trajectory prediction when N = 1 in gray colored regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Comparison results of MC, QMC and NPSN w.r.t. STGCNN</figDesc><table><row><cell></cell><cell cols="2">610 1.028 0.495 0.591 0.995 0.503</cell><cell>3.2%</cell><cell cols="2">0.518 0.780 0.499 24.1%</cell><cell cols="4">0.610 1.073 0.596 0.601 1.036 0.602</cell><cell>3.5%</cell><cell cols="2">0.550 0.882 0.618 17.8%</cell></row><row><cell>HOTEL</cell><cell>0.196 0.284 0.323</cell><cell>0.193 0.277 0.319</cell><cell>2.5%</cell><cell>0.157 0.266 0.352</cell><cell>6.2%</cell><cell cols="4">0.222 0.390 0.335 0.214 0.369 0.336</cell><cell>5.3%</cell><cell cols="2">0.188 0.288 0.359 26.1%</cell></row><row><cell>UNIV</cell><cell>0.304 0.545 0.765</cell><cell>0.297 0.531 0.767</cell><cell>2.6%</cell><cell cols="2">0.266 0.443 0.765 18.8%</cell><cell cols="4">0.335 0.558 0.752 0.326 0.533 0.759</cell><cell>4.5%</cell><cell cols="2">0.289 0.439 0.765 21.4%</cell></row><row><cell>ZARA1</cell><cell>0.241 0.413 0.764</cell><cell>0.235 0.401 0.766</cell><cell>2.8%</cell><cell cols="2">0.191 0.358 0.844 13.4%</cell><cell cols="4">0.250 0.448 0.808 0.241 0.425 0.816</cell><cell>5.1%</cell><cell cols="2">0.209 0.333 0.839 25.8%</cell></row><row><cell>ZARA2</cell><cell>0.175 0.319 0.639</cell><cell>0.170 0.307 0.641</cell><cell>3.5%</cell><cell cols="2">0.161 0.278 0.684 12.6%</cell><cell cols="4">0.186 0.332 0.596 0.178 0.310 0.609</cell><cell>6.7%</cell><cell cols="2">0.159 0.252 0.641 24.0%</cell></row><row><cell>AVG</cell><cell cols="2">0.305 0.518 0.597 0.297 0.502 0.599</cell><cell>3.0%</cell><cell cols="2">0.258 0.425 0.629 17.9%</cell><cell cols="4">0.321 0.560 0.617 0.312 0.535 0.624</cell><cell>4.6%</cell><cell cols="2">0.279 0.439 0.644 21.7%</cell></row><row><cell>SDD</cell><cell cols="2">11.40 20.12 0.652 11.22 19.69 0.656</cell><cell>2.1%</cell><cell>11.12 18.95 0.653</cell><cell>5.8%</cell><cell>9.97</cell><cell>15.89 0.647</cell><cell>9.72</cell><cell>15.22 0.652</cell><cell>4.2%</cell><cell>8.56</cell><cell>11.85 0.665 25.4%</cell></row><row><cell>GCS</cell><cell>12.75 24.23 0.802</cell><cell>12.47 23.50 0.802</cell><cell>3.0%</cell><cell>12.36 22.98 0.805</cell><cell>5.2%</cell><cell cols="4">17.08 29.30 0.708 17.09 29.23 0.711</cell><cell>0.2%</cell><cell cols="2">10.13 17.36 0.717 40.8%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>/ 1.62 0.67 / 1.37 0.76 / 1.52 0.35 / 0.68 0.42 / 0.84 0.61 / 1.21 STGAT<ref type="bibr" target="#b16">[17]</ref> 0.65 / 1.12 0.35 / 0.66 0.52 / 1.10 0.34 / 0.69 0.29 / 0.60 0.43 / 0.83 Causal-STGAT [6] 0.60 / 0.98 0.30 / 0.54 0.52 / 1.10 0.32 / 0.64 0.28 / 0.58 0.40 / 0.77 Social-STGCNN [39] 0.64 / 1.11 0.49 / 0.85 0.44 / 0.79 0.34 / 0.53 0.30 / 0.48 0.44 / 0.75 PECNet [34] 0.61 / 1.07 0.22 / 0.39 0.34 / 0.56 0.25 / 0.45 0.19 / 0.33 0.32 / 0.56 Trajectron++ [47] 0.61 / 1.03 0.20 / 0.28 0.30 / 0.55 0.24 / 0.41 0.18 / 0.32 0.31 / 0.52 NCE-Trajectron++ [32] 0.56 / 1.02 0.17 / 0.27 0.28 / 0.54 0.22 / 0.41 0.16 / 0.31 0.28 / 0.51 SGCN [49] 0.57 / 1.00 0.31 / 0.53 0.37 / 0.67 0.29 / 0.51 0.22 / 0.42 0.35 / 0.63 Trajectron++ 0.40 / 0.62 0.15 / 0.24 0.23 / 0.41 0.19 / 0.35 0.14 / 0.25 0.22 / 0.37 NPSN-SGCN 0.36 / 0.59 0.16 / 0.25 0.23 / 0.39 0.18 / 0.32 0.14 / 0.25 0.21 / 0.36 Comparison of NPSN with other state-of-the-art stochastic model (ADE/FDE, Unit: meter). The evaluation results are directly referred from [6]. Bold:Best, Underline:Second Best.</figDesc><table><row><cell></cell><cell>ETH</cell><cell>HOTEL</cell><cell>UNIV</cell><cell>ZARA1</cell><cell>ZARA2</cell><cell>AVG</cell></row><row><cell cols="7">Social-GAN [13] 0.87 NPSN-SGAN 0.72 / 1.26 0.38 / 0.72 0.71 / 1.43 0.34 / 0.68 0.34 / 0.70 0.50 / 0.96</cell></row><row><cell>NPSN-STGAT</cell><cell cols="6">0.61 / 1.02 0.31 / 0.57 0.53 / 1.13 0.34 / 0.68 0.30 / 0.62 0.42 / 0.80</cell></row><row><cell>NPSN-Causal-STGAT</cell><cell cols="6">0.56 / 0.90 0.25 / 0.40 0.51 / 1.09 0.32 / 0.65 0.27 / 0.56 0.38 / 0.72</cell></row><row><cell>NPSN-STGCNN</cell><cell cols="6">0.44 / 0.65 0.21 / 0.34 0.28 / 0.44 0.25 / 0.43 0.22 / 0.38 0.28 / 0.45</cell></row><row><cell>NPSN-PECNet</cell><cell cols="6">0.55 / 0.88 0.19 / 0.29 0.29 / 0.44 0.21 / 0.33 0.16 / 0.25 0.28 / 0.44</cell></row><row><cell>NPSN-Trajectron++</cell><cell cols="6">0.52 / 0.78 0.16 / 0.27 0.27 / 0.44 0.19 / 0.36 0.16 / 0.28 0.26 / 0.42</cell></row><row><cell>NPSN-NCE-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>/ 1.00 0.31 / 0.53 0.37 / 0.67 0.29 / 0.51 0.22 / 0.42 0.35 / 0.63 w/o Ldist 0.39 / 0.61 0.23 / 0.45 0.26 / 0.47 0.20 / 0.36 0.16 / 0.31 0.25 / 0.44 w/o Ldisc 0.38 / 0.61 0.16 / 0.25 0.23 / 0.39 0.18 / 0.32 0.14 / 0.25 0.22 / 0.37 w/o GAT 0.36 / 0.57 0.17 / 0.28 0.23 / 0.39 0.18 / 0.32 0.14 / 0.26 0.22 / 0.37 +NPSN 0.36 / 0.59 0.16 / 0.25 0.23 / 0.39 0.18 / 0.32 0.14 / 0.25 0.21 / 0.36 Ablation study on each component of NPSN in SGCN.</figDesc><table><row><cell></cell><cell>ETH</cell><cell>HOTEL</cell><cell>UNIV</cell><cell>ZARA1</cell><cell>ZARA2</cell><cell>AVG</cell></row><row><cell>Baseline</cell><cell>0.57</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement This work is in part supported by the <rs type="funder">Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP)</rs> grant funded by the <rs type="funder">Korea government (MSIT)</rs> (No.<rs type="grantNumber">2019-0-01842</rs>, <rs type="funder">Artificial Intelligence Graduate School Program (GIST)</rs>, No.<rs type="grantNumber">2021-0-02068</rs>, <rs type="projectName">Artificial Intelligence Innovation Hub</rs>), <rs type="funder">Vehicles AI Convergence Research &amp; Development Program</rs> through the <rs type="funder">National IT Industry Promotion Agency of Korea (NIPA)</rs> funded by the <rs type="funder">Ministry of Science and ICT</rs>(No.<rs type="grantNumber">S1602-20-1001</rs>), the <rs type="funder">National Research Foundation of Korea (NRF)</rs> grant funded by the <rs type="funder">Korea government (MSIT)</rs> (No.<rs type="grantNumber">2020R1C1C1012635</rs>), and the <rs type="funder">GIST-MIT Collaboration</rs> grant funded by the <rs type="funder">GIST</rs> in 2022.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Gehdw4h">
					<idno type="grant-number">2019-0-01842</idno>
				</org>
				<org type="funded-project" xml:id="_PGQtrkU">
					<idno type="grant-number">2021-0-02068</idno>
					<orgName type="project" subtype="full">Artificial Intelligence Innovation Hub</orgName>
				</org>
				<org type="funding" xml:id="_evK64RU">
					<idno type="grant-number">S1602-20-1001</idno>
				</org>
				<org type="funding" xml:id="_9Kfck6X">
					<idno type="grant-number">2020R1C1C1012635</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016. 1, 2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Disentangled multi-relational graph convolutional network for pedestrian trajectory prediction</title>
		<author>
			<persName><forename type="first">Inhwan</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hae-Gon</forename><surname>Jeon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fifth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the scrambled sobol sequence</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Beerli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deidre</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Mascagni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Business statistics: for contemporary decision making</title>
		<author>
			<persName><forename type="first">Ken</forename><surname>Black</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A note on the generation of random normal deviates</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mervin</forename><forename type="middle">E</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Human trajectory prediction via counterfactual analysis</title>
		<author>
			<persName><forename type="first">Guangyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junlong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2007">2021. 1, 2, 5, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fbnetv3: Joint architecturerecipe search using predictor pretraining</title>
		<author>
			<persName><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<idno>2021. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Chamnet: Towards efficient network design through platform-aware model adaptation</title>
		<author>
			<persName><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxu</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marat</forename><surname>Dukhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Uyttendaele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niraj</forename><forename type="middle">K</forename><surname>Jha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mggan: A multi-generator model preventing out-of-distribution samples in pedestrian trajectory prediction</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sven</forename><surname>Elflein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Leal-Taixé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV), 2021</title>
		<meeting>International Conference on Computer Vision (ICCV), 2021</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A robust loss for point cloud registration</title>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bailin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juyong</forename><surname>Zhang</surname></persName>
		</author>
		<idno>2021. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An introduction to probability theory and its applications</title>
		<author>
			<persName><forename type="first">William</forename><surname>Feller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<publisher>John Wiley &amp; Sons Inc</publisher>
			<biblScope unit="volume">II</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007">2018. 1, 2, 5, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithm 247: Radical-inverse quasi-random point sequence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Halton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">GPU Gems 3 -Efficient Random Number Generation and Application Using CUDA</title>
		<author>
			<persName><forename type="first">Lee</forename><surname>Howes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Pearson Education, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stgat: Modeling spatial-temporal interactions for human trajectory prediction</title>
		<author>
			<persName><forename type="first">Yingfan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huikun</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianlu</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoqi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2008">2019. 1, 2, 3, 5, 6, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName><forename type="first">Boris</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019">2019. 1, 2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Constructing sobol sequences with better two-dimensional projections</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Joe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frances</forename><forename type="middle">Y</forename><surname>Kuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM Journal on Scientific Computing</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Socialbigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Martín-Martín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2019">2019. 1, 2, 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName><forename type="first">Namhoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manmohan</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Monte Carlo and Quasi-Monte Carlo Sampling</title>
		<author>
			<persName><forename type="first">Christiane</forename><surname>Lemieux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Springer</publisher>
			<pubPlace>Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiorgos</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Conditional generative neural system for probabilistic trajectory prediction</title>
		<author>
			<persName><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hengbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Intelligent Robots and Systems (IROS)</title>
		<meeting>IEEE International Conference on Intelligent Robots and Systems (IROS)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evolvegraph: Multi-agent trajectory prediction with dynamic relational reasoning</title>
		<author>
			<persName><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiho</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2020">2020. 1, 2, 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Which way are you going? imitative decision learning for path forecasting in dynamic scenes</title>
		<author>
			<persName><forename type="first">Yuke</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005">2019. 2, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Simaug: Learning robust representations from simulation for trajectory prediction</title>
		<author>
			<persName><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The garden of forking paths: Towards multifuture trajectory prediction</title>
		<author>
			<persName><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Peeking into the future: Predicting future person activities and locations in videos</title>
		<author>
			<persName><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Social nce: Contrastive learning of socially-aware motion representations</title>
		<author>
			<persName><forename type="first">Yuejiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2008">2021. 1, 2, 5, 6, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">It is not the journey but the destination: Endpoint conditioned trajectory prediction</title>
		<author>
			<persName><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harshayu</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shreyas</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuan-Hui</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2008">2020. 1, 2, 3, 5, 6, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mantra: Memory augmented networks for multiple trajectory prediction</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Becattini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><forename type="middle">Del</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The ziggurat method for generating random variables</title>
		<author>
			<persName><forename type="first">George</forename><surname>Marsaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><forename type="middle">Wan</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sampling for qualitative research</title>
		<author>
			<persName><forename type="first">N</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Family Practice</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName><forename type="first">Ramin</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Social-stgcnn: A social spatio-temporal graph convolutional neural network for human trajectory prediction</title>
		<author>
			<persName><forename type="first">Abduallah</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Claudel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007">2020. 1, 2, 3, 5, 6, 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Random Number Generation and Quasi-Monte Carlo Methods</title>
		<author>
			<persName><forename type="first">Harald</forename><surname>Niederreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Society for Industrial and Applied Mathematics</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1992">1992</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Quasi-monte carlo sampling</title>
		<author>
			<persName><forename type="first">Art</forename><forename type="middle">B</forename><surname>Owen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Faster valuation of financial derivatives</title>
		<author>
			<persName><forename type="first">H</forename><surname>Spassimir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">F</forename><surname>Paskov</surname></persName>
		</author>
		<author>
			<persName><surname>Traub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Portfolio Management</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konrad</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2006">2009. 1, 4, 6</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning social etiquette: Human trajectory understanding in crowded scenes</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning in an uncertain world: Representing ambiguity through multiple hypotheses</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iro</forename><surname>Laina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Dipietro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Baust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName><forename type="first">Vineet</forename><surname>Amir Sadeghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noriaki</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamid</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvio</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019">2019. 1, 2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boris</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Punarjay</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2008">2020. 1, 2, 5, 6, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Introvert: Human trajectory prediction via conditional 3d attention</title>
		<author>
			<persName><forename type="first">Nasim</forename><surname>Shafiee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taskin</forename><surname>Padir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ehsan</forename><surname>Elhamifar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Sgcn: Sparse graph convolution network for pedestrian trajectory prediction</title>
		<author>
			<persName><forename type="first">Liushuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjiang</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenxing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008">2021. 1, 2, 3, 5, 6, 7, 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multimodal interaction-aware trajectory prediction in crowded space</title>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaowei</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zipei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renhe</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiling</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryosuke</forename><surname>Shibasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fourth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Reciprocal learning networks for human trajectory prediction</title>
		<author>
			<persName><forename type="first">Zhiqun</forename><surname>Hao Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Recursive social behavior graph for trajectory prediction</title>
		<author>
			<persName><forename type="first">Jianhua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinhong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Dynamic and static context-aware lstm for multi-agent motion prediction</title>
		<author>
			<persName><forename type="first">Chaofan</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinhong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lixin</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Social attention: Modeling attention in human crowds</title>
		<author>
			<persName><forename type="first">Anirudh</forename><surname>Vemula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katharina</forename><surname>Muelling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Robotics and Automation (ICRA)</title>
		<meeting>IEEE International Conference on Robotics and Automation (ICRA)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sparse-to-dense depth completion revisited: Sampling strategy and graph construction</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haipeng</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Ladybird: Quasi-monte carlo sampling for deep implicit field based 3d reconstruction with symmetry</title>
		<author>
			<persName><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gurprit</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Who are you with and where are you going?</title>
		<author>
			<persName><forename type="first">Kota</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><forename type="middle">E</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Understanding pedestrian behaviors from stationary crowd groups</title>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph transformer networks for pedestrian trajectory prediction</title>
		<author>
			<persName><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020">2020. 1, 2, 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Agentformer: Agent-aware transformers for socio-temporal multiagent forecasting</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanglan</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2005">2021. 2, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Sr-lstm: State refinement for lstm towards pedestrian trajectory prediction</title>
		<author>
			<persName><forename type="first">Pu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianru</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanning</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019">2019. 1, 2</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Tnt: Target-driven trajectory prediction</title>
		<author>
			<persName><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tian</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balakrishnan</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Congcong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning (CoRL)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Multi-agent tensor fusion for contextual trajectory prediction</title>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yifei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathew</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yibiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><forename type="middle">Nian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Abrupt motion tracking via adaptive stochastic approximation monte carlo sampling</title>
		<author>
			<persName><forename type="first">Xiuzhuang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Generating low-discrepancy sequences from the normal distribution: Box-muller or inverse transform?</title>
		<author>
			<persName><forename type="first">Giray</forename><surname>Ökten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmet</forename><surname>Göncü</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical and Computer Modelling</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
