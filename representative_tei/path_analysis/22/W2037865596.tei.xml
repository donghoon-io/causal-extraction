<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Trajectory Analysis and Semantic Region Modeling Using A Nonparametric Bayesian Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2008-06-24">June 24, 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
							<email>xgwang@csail.mit.edu</email>
							<affiliation key="aff1">
								<orgName type="department">CS and AI Lab</orgName>
								<orgName type="institution">MIT Cambridge</orgName>
								<address>
									<postCode>02139</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Keng</forename><forename type="middle">Teck</forename><surname>Ma</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">DSO National Laboratories</orgName>
								<address>
									<addrLine>20 Science Park Drive</addrLine>
									<postCode>118230</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gee-Wah</forename><surname>Ng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eric</forename><surname>Grimson</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">CS and AI Lab</orgName>
								<orgName type="institution">MIT Cambridge</orgName>
								<address>
									<postCode>02139</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DSO National Laboratories</orgName>
								<address>
									<addrLine>20 Science Park Drive</addrLine>
									<postCode>118230</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science</orgName>
								<orgName type="laboratory">Artificial Intelligence Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Trajectory Analysis and Semantic Region Modeling Using A Nonparametric Bayesian Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-06-24">June 24, 2008</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T21:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel nonparametric Bayesian model, Dual Hierarchical Dirichlet Processes (Dual-HDP), for trajectory analysis and semantic region modeling in surveillance settings, in an unsupervised way. In our approach, trajectories are treated as documents and observations of an object on a trajectory are treated as words in a document. Trajectories are clustered into different activities. Abnormal trajectories are detected as samples with low likelihoods. The semantic regions, which are intersections of paths commonly taken by objects, related to activities in the scene are also modeled. Dual-HDP advances the existing Hierarchical Dirichlet Processes (HDP) language model. HDP only clusters co-occurring words from documents into topics and automatically decides the number of topics. Dual-HDP co-clusters both words and documents. It learns both the numbers of word topics and document clusters from data. Under our problem settings, HDP only clusters observations of objects, while Dual-HDP clusters both observations and trajectories. Experiments are evaluated on two data sets, radar tracks collected from a maritime port and visual tracks collected from a parking lot.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Activity analysis has always been one of the foci of research in surveillance. Over the past decade significant work has been reported on this topic. Although some approaches <ref type="bibr" target="#b21">[18,</ref><ref type="bibr" target="#b14">11,</ref><ref type="bibr" target="#b17">14]</ref> modeled activities by directly extracting motion and appearance features from the videos without relying on tracking, most approaches <ref type="bibr" target="#b15">[12,</ref><ref type="bibr">3,</ref><ref type="bibr" target="#b12">9,</ref><ref type="bibr" target="#b19">16,</ref><ref type="bibr" target="#b18">15,</ref><ref type="bibr" target="#b20">17]</ref> assumed that objects and/or their constituents were first detected and tracked throughout the scene and activities were modeled as sequences of movements of objects. Through tracking, an activity executed by a single object can be separated from other co-occurring activities, and features related to the activity can be integrated as a track. In many far-field surveillance settings, the captured videos are of low resolution and poor quality or even no videos are available (e.g. in some maritime surveillance, only radar signals are available). In these scenarios, it is difficult to compute more complicated features, such as gestures, local motions, or appearance of objects within the tracks. Usually only positions of objects are recorded along the tracks, which are called trajectories. Although quite simple, the information encoded by trajectories can distinguish many different activity patterns, especially in far-field settings. The goal of this work is to model activities by trajectory analysis: clustering trajectories into different activities, detecting abnormal trajectories, and modeling semantic regions.</p><p>We propose a framework using a nonparametric Bayesian model, Dual Hierarchical Dirichlet Processes (Dual-HDP), for trajectory analysis. Dual-HDP advances the existing Hierarchical Dirichlet Processes (HDP) <ref type="bibr" target="#b16">[13]</ref> language model. HDP is a nonparametric Bayesian model. It clusters words often co-occurring in the same documents into one topic and automatically decides the number of topics. Wang et al. <ref type="bibr" target="#b17">[14]</ref>, proposed an HDP mixture model to co-cluster both words and documents. However, it required one to manually specify the number of document clusters. Our Dual-HDP also co-clusters words and documents, but it automatically decides the numbers of both word topics and document clusters. Under our framework, trajectories are treated as documents and the observations (positions and moving directions of objects) on the trajectories are treated as words. Topics model the semantic regions, which are intersections of paths commonly taken by objects, in the scene, and trajectories are clustered into different activities. We evaluate our approach on two data sets (see Figure <ref type="figure" target="#fig_0">1</ref>): 577 radar tracks collected from a port in maritime surveillance and 45, 453 video tracks collected from a parking lot scene. In maritime surveillance, trajectory analysis is a natural way to analyze activities especially when only radar signals are available. Without expert knowledge, it is very difficult for humans to discover transportation structures on the sea, such as shipping fairways, since the appearance of the scene does not help. The tracks from the parking lot scene are obtained from far-field videos recorded by a fixed camera. We use the Stauffer-Grimson tracker <ref type="bibr" target="#b15">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Most of the existing trajectory analysis approaches cluster trajectories and detect abnormal trajectories by defining the pairwise similarities between trajectories. The proposed trajectory similarities or distances include Euclidean distance <ref type="bibr" target="#b7">[4]</ref>, Hausdorff distance and its different variations <ref type="bibr" target="#b8">[5,</ref><ref type="bibr" target="#b18">15]</ref>, and Dynamic Time Warping (DTW) <ref type="bibr" target="#b10">[7]</ref> etc. These similarity-based approaches have several drawbacks. First, there is no global probabilistic framework to model activities happening in the scene. They have an ad hoc nature especially on the definitions of distance measures. Abnormal trajectories are usually detected as those with larger distance to other trajectories. The abnormality detection lacks a probabilistic explanation. Second, they do not provide a solution to the number of clusters. They require that the cluster number is known in advance. Third, they measure the spatial distance between observations on two trajectories. However, spatial distance do not reflect the statistical nature of activities. For example, vehicles moving on two side by side lanes may be close in space, but their trajectories represent different activities. Spatial distance is also sensitive to projective distortion. Fourth, calculating the similarities between all pairs of samples is computationally inefficient, with a complexity of O(N 2 ) in both time and space, where N is the number of trajectories.</p><p>Trajectory clustering is also related to the problem of modeling semantic regions in the scene. The knowledge of the structures of the scene (e.g. roads, paths, entry and exit points) can help not only the high-level description of activities <ref type="bibr" target="#b18">[15]</ref>, but also low-level tracking and classification <ref type="bibr" target="#b9">[6]</ref>. It takes a lot of effort to manually input these structures. They cannot be reliably detected based on the appearance of the scene either. In some cases, e.g. detecting shipping fairways on the sea, there is no appearance cue available at all. It is of interest to detect these structures by trajectory analysis. Usually paths are detected by modeling the spatial extents of trajectory clusters <ref type="bibr">[3,</ref><ref type="bibr" target="#b12">9,</ref><ref type="bibr" target="#b18">15]</ref>. Semantic regions are detected as intersections of paths <ref type="bibr" target="#b12">[9]</ref>. Entry and exit points are detected at the ends of paths <ref type="bibr" target="#b18">[15]</ref>. Our framework differs from previous trajectory analysis approaches in several aspects:</p><p>• Different from prior similarity-based clustering approaches, it clusters trajectories using a generative model. There is a natural probabilistic explanation for the detection of abnormal trajectories.</p><p>• Previous approaches first clustered trajectories into activities and then segmented semantic regions. Our approach simultaneously learns activities and semantic regions, which are jointly modeled in Dual-HDP.</p><p>• Using Dirichlet Processes, the number of activity categories and semantic regions are automatically learnt from data instead of requiring manual definition.</p><p>• Instead of using a spatial distance measure uniformly over the scene, it models the spatial distributions of activities. It separates activity-related structures close in space. It is more robust to projective distortion.</p><p>• The space complexity of our algorithm is O(N ) instead of O(N 2 ) in the number of trajectories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Modeling Trajectories</head><p>We treat a trajectory as a document and the observations on the trajectory as words. The positions and moving directions of observations are computed as features which are quantized according to a codebook. The codebook uniformly quantizes the space of the scene into small cells and the velocity of objects into several directions. A trajectory is modeled as a bag of quantized observations without temporal order. In language processing, some topic models, such as HDP, cluster co-occurring words into one topic. Each topic has a multinomial distribution over the codebook. A document is modeled as a mixture of topics and documents share topics. If some words, such as "professor" and "education", often but not necessarily always occur in the same documents, a topic related to "education" will be learnt and its multinomial distribution has large weights on these words. When these models are used to model trajectories, topics reveal semantic regions shared by trajectories, i.e. many trajectories pass through one semantic region with common directions of motion. Semantic regions are intersections of paths. Two paths may partially share one semantic region. A semantic region is modeled as a multinomial distribution over the space of the scene and moving directions. If two trajectories pass through the same set of semantic regions, they belong to the same activity. In our Dual-HDP model, each activity cluster has a prior distribution over topics (semantic regions). It is learnt in an unsupervised way. All the trajectories clustered into the same activity share the same prior distribution. Using Dirichlet Processes, Dual-HDP can learn the number of semantic regions and the number of activities from data.</p><p>In Figure <ref type="figure" target="#fig_1">2</ref>, an example is shown to explain the modeling. There are three semantic regions (indicated by different colors) which form two paths. Both trajectories A and C pass through regions 1 and 2, so they are clustered into the same activity. Trajectory B passes through regions 1 and 3, so it is clustered into a different activity.</p><p>Although with the "bag-of-words" assumption, our approach does model the first order temporal information among observations since the codebook encodes the moving directions. It can distinguish some activities related to temporal features. For example, if objects visit several regions in opposite temporal order, they must pass through the same region in opposite directions. In our model, that region splits into two topics because of the velocity difference. So these two activities can be distinguished by our model, since they have different topics.</p><p>In Section 5 and 6, we will explain the HDP model proposed by Teh et al. <ref type="bibr" target="#b16">[13]</ref> and our Dual-HDP model, which is actually used for trajectory analysis. We will describe them as language models. However, remember that in our problem documents are trajectories, words are observations, and topics are semantic regions. Clusters of trajectories (activities) are explicitly modeled in Dual-HDP but not in HDP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Dirichlet Process</head><p>A Dirichlet Process (DP) <ref type="bibr">[2]</ref> is a nonparametric distribution whose domain is a set of probability distributions. A DP is defined by a concentration parameter α, which is a positive scalar, and a base probability measure H (for example H is a Dirichlet distribution in our case). A probability measure G randomly drawn from DP (α, H) is always a discrete distribution and it can be obtained from a stick-breaking reconstruction <ref type="bibr" target="#b13">[10]</ref>,</p><formula xml:id="formula_0">G = ∞ k=1 π k δ φ k ,<label>(1)</label></formula><p>where δ φ k is a Dirac delta function centered at φ k , φ k is a multinomial parameter vector sampled from Dirichlet distribution H, φ k ∼ H, and π k is a non-negative scalar satisfying</p><formula xml:id="formula_1">∞ k=1 π k = 1, π k = π k k-1 l=1 (1 -π l ), π k ∼ Beta(1, α)</formula><p>. G is often used as a prior for infinite mixture models. When data points are sampled from G, there is no limit to the number of distinct components which may be generated. Given a set of data points θ 1 , . . . , θ N sampled from G, it turns out that the posterior of sampling a new data point can be obtained by integrating out G,</p><formula xml:id="formula_2">θ N +1 |θ 1 , . . . , θ N , α, H ∼ K k=1 n k N + α δ θ * k + α N + α H<label>(2)</label></formula><p>There are K distinct values {θ * k } K k=1 (identifying K components) among the N data points. n k is the number of points with value θ * k . The new data point θ N +1 can be assigned to one of the existing components or can sample a new component from H. These properties make DP ideal for modeling data clustering problems where the number of mixture components is not well-defined in advance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">HDP</head><p>HDP proposed by Teh et al. <ref type="bibr" target="#b16">[13]</ref> is a nonparametric hierarchical Bayesian model used to cluster co-occurring words in documents into topics (in our problem it clusters observations on the trajectories into semantic regions). The graphical model of HDP is shown in Figure <ref type="figure">3</ref>. There are M documents (trajectories) in the corpus. Each document j has N j words (quantized observations of positions and moving directions of objects). In HDP, a prior distribution G 0 over the whole corpus is sampled from a Dirichlet process, G 0 ∼ DP (γ, H). G 0 = ∞ k=1 π 0k δ φ k . φ k is the parameter of a topic, which is modeled as a multinomial distribution over the codebook. φ k is sampled from Dirichlet prior H. All the words in the corpus will be sampled from some topics {φ k }. For each document j, a prior distribution G j over all the words in that document is sampled from Dirichlet process, G j ∼ DP (α, G 0 ). G j = ∞ k=1 π jk δ φ k share the same components φ k as G 0 , i.e. all the documents share the same set of topics. For each word i in document j, a topic θ ji , which is one of the φ k 's, is sampled from G j . The word value w ji is sampled from the topic θ ji , w ji ∼ Discrete(θ ji ). The concentration parameters are sampled from some gamma priors, γ ∼ Gamma(a 1 , b 1 ), α ∼ Gamma(a 2 , b 2 ). In HDP, all the documents share topics and the number of topics, i.e. the number of non-zero elements of {π k } is learnt from data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Dual-HDP</head><p>Unfortunately, HDP does not cluster documents (trajectories in our problem). We propose a Dual-HDP model to cocluster both words and documents. A document is modeled as a distribution over topics. Thus documents with similar distributions over topics can be grouped into one cluster. There are two hierarchical Dirichlet processes modeling topics of words and clusters of documents. The graphical model of Dual-HDP is shown in Figure <ref type="figure">4</ref>.</p><p>In Dual-HDP, each document j is from one of the document clusters. All the documents in cluster c have the same prior distribution G c . G c = ∞ k=1 π ck δ φ ck is an infinite mixture of topics. Since the number of document clusters is not known in advance, we model the clusters of documents as an infinite mixture, When a DP was first developed by Ferguson <ref type="bibr">[2]</ref>, the components (such as φ k in Eq 1) could only be scalars or vectors.</p><formula xml:id="formula_3">Q = ∞ c=1 c δ Gc<label>(3)</label></formula><p>MacEachern <ref type="bibr" target="#b11">[8]</ref> generalized this to Dependent Dirichlet Process (DDP). In DDP, components could be stochastic processes.</p><p>In our model, the parameters {( π ck , φ ck )} ∞ k=1 of G c can be treated as a stochastic process with index k. As shown in Figure <ref type="figure">4</ref>, Q is generated from DDP (µ, ρ, G 0 ). In Eq 3, c = c c-1 l=1 (1l ), c ∼ Beta(1, µ), G c ∼ DP (ρ, G 0 ). As explained in Section 5, G 0 ∼ DP (γ, H) is the prior distribution over the whole corpus. { G c } ∞ c=1 all have the same topics in G 0 . i.e. φ ck = φ k . However they have different mixtures { π ck } over these topics. Each document j samples a probability measure G cj from Q as its prior. Different documents may choose the same prior G c , thus they form one cluster c. Then document j generates its own probability measure G j from G j ∼ DP (α, G cj ) where the base measure is provided by cluster c j instead of the corpus prior G 0 (as HDP did). The following generative procedure is the same as HDP. Word i in document j samples its topic θ ji from G j and samples its word value w ji from Discrete(θ ji ). The concentration parameters are also sampled from gamma priors.</p><p>Gibbs sampling is used to do inference in three steps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results on radar tracks</head><p>There are 577 radar tracks in our maritime port data set. They were acquired by multiple collaborating radars along the shore and recorded the locations of ships on the sea. 23 semantic regions are discovered by our model. In Figure <ref type="figure" target="#fig_3">5</ref>, we display the distributions of the first 16 semantic regions (sorted by the number of observations assigned to semantic regions) over space and moving directions. As shown in Figure <ref type="figure" target="#fig_3">5</ref>, the 1st, 4th, 6th, 8th and 15th semantic regions are five side by side shipping fairways, where ships move in two opposite directions. For comparison, we segment the five fairways using a threshold on the density, and overlay them in Figure <ref type="figure" target="#fig_3">5</ref> (c) in different colors, green (1st), red (4th), black (6th), yellow (8th), and blue (15th). Since they are so close in space, they cannot be separated using spatial distance based trajectory clustering approaches. In Figure <ref type="figure" target="#fig_3">5 (d)</ref>, we compare the 7th, 11th, and 13th semantic regions also by overlaying the segmented regions in red, green, and black colors. This explains the fact that ships first move along the 7th semantic region and then diverge along the 11th and 13th semantic regions.</p><p>Our approach groups trajectories into 16 clusters. In Figure <ref type="figure">6</ref>, we plot the eight largest clusters and some smaller clusters. Clusters 1, 4, 6 and 7 are close in space but occupy different regions. Clusters 3 and 5 occupy the same region, but ships in the two clusters moves in opposite directions. Clusters 2 and 5 partially overlap in space. As shown in Figure <ref type="figure" target="#fig_3">5</ref>(d), ships first  move along the same way and then diverge in different directions. For comparison, in the last two sub-figures of Figure <ref type="figure">6</ref> we also show two clusters of the result using Euclidean distance and sepctral clustering <ref type="bibr" target="#b7">[4]</ref> and setting the number of clusters as 16. Some fine structures of shipping faiways cannot be separated using a spaitial distance based clustering method. One of the advantages of our approach is that it learns the number of clusters from data. When spatial distance based clustering methods are evaluated on this dat set, choosing an improper cluster number, say 8 or 25, the clustering performance sincerely deteriorates. In Figure <ref type="figure" target="#fig_5">7</ref>, we display the top 20 abnormal trajectories based on their normalized log-likelihoods log(p(w j |w -j ))/N j . There are two possible reasons for the abnormality. (1) The trajectory does not fit any major semantic regions. Many examples can be found in Figure <ref type="figure" target="#fig_5">7</ref>. (2) The trajectory fits more than one semantic region, but the combination of the semantic regions is uncommon. The red trajectory in Figure <ref type="figure" target="#fig_5">7</ref> (a), and the red and green trajectories in Figure <ref type="figure" target="#fig_5">7</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Results on tracks from a parking lot</head><p>There are N = 40, 453 trajectories in the parking lot data set collected over one week. Figure <ref type="figure" target="#fig_0">1 plots 4</ref>, 404 trajectories from one day. Because of the large number of samples, similarity based clustering methods require both large amounts of space (6GB) to store the 40, 453×40, 453 similarity matrix and high computational cost to compute the similarities of around 800, 000, 000 pairs of trajectories. If spectral clustering is used, it is quite challenging to compute the eigenvectors of such a huge matrix. It is difficult for them to work on this large data set. The space complexity of our nonparametric Bayesian approach is O(N ) instead of O(N 2 ). The time complexity of each Gibbs sampling iteration is O(N ). It is difficult to provide theoretical analysis on the convergence of Gibbs sampling. However, there is some empirical observations by plotting the likelihoods of data sets over Gibbs sampling iterations. On the smaller radar data set, the likelihood curve converges after 1, 000 iterations. This takes around 1.5 minutes running on a computer with 3GHz CPU. On the parking lot data set, which is 70 times large than the radar data set in the number of trajectories, the likelihood curve converges after 6, 000 iterations. It takes around 6 hours. In our experiments, the time complexity of our approach is much smaller that O(N 2 ) 30 semantic regions and 22 clusters of trajectories are learnt from this data set. Some of them are shown in Figure <ref type="figure" target="#fig_6">8</ref> and<ref type="figure">9</ref>. The first and third semantic regions explain vehicles entering and exiting the parking lot. Most other semantic regions are related to pedestrian activities. Because of opposite moving directions, some region splits into two semantic regions, such as semantic regions 2 and 7, 9 and 12, 5 and 14. Similarly objects on trajectories (see Figure <ref type="figure">9</ref>) in clusters 2 and 3, 5 and 11 are moving in opposite directions. Many outlier trajectories are in small clusters, such as clusters 20, 21 and 22. The top 100 abnormal trajectories are shown in Figure <ref type="figure" target="#fig_0">10</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion</head><p>We propose a nonparametric Bayesian framework to cluster trajectories, learn the models of semantic regions, and detect trajectories related to abnormal activities. Different from most of the existing spatial distance based trajectory clustering approaches with ad hoc nature, we formulate these problem in a transparent probabilistic way. The number of semantic regions and clusters of trajectories are learnt through the hierarchical Dirichlet processes. The space complexity of our algorithm is O(N ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Acknowledgment</head><p>The authors wish to acknowledge DSO National Laboratory of Singapore for partially supporting this research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.1.">Gibbs sampling under the Dual-HDP model</head><p>We will explain how to do Gibbs sampling in the Dual-HDP model as described in Section 6 in our paper. The sampling procedure is implemented in three steps. In the first step, given the cluster assignment {c j } of documents fixed, we sample the word topic assignment z, mixtures π 0 and π c on topics. It follows the Chinese Restaurant Process (CRP) Gibbs sampling scheme as described in <ref type="bibr" target="#b16">[13]</ref>, but adding more hierarchical levels. In CPR, restaurants are documents, customers are words and dishes are topics. All the restaurants share a common menu. The process can be briefly described as following (see more details in <ref type="bibr" target="#b16">[13]</ref>).</p><p>• When a customer i comes to restaurant j, he sits at one of the existing tables t and eat the dishes served on table t, or take a new table t new .</p><p>• If a new table t new is added to restaurant j, it orders a dish from the menu.</p><p>Since we are modeling clusters of documents, we introduce "big restaurants", which are clusters of documents. The label of document cluster c j associates restaurant j to big restaurant c j . The CRP is modified as following.</p><p>• If a new table t new needs to be added in restaurant j, we go to the big restaurant c j and choose one of the existing big tables r in c j . t new is associated with r, and serve the same dish as r.</p><p>• Alternatively, the new table t new may take a new big table r new in the big restaurant c j . If that happens, r new orders a dish from the menu. This dish will be served on both r new and t new .</p><p>Following this modified CRP , given {c j }, k, π 0 and { π c } can be sampled. It is a straightforward extension of the sampling scheme in <ref type="bibr" target="#b16">[13]</ref> to more hierarchical levels.</p><p>In the second step, in order to sample {c j } and generate the clusters of documents, given z, π 0 , and { π c }, we add an extra process.</p><p>• When a new restaurant j is built, it needs to be associated with one of the existing big restaurants or a new big restaurant needs to be built and associated with j. It is assumed that we already know how many tables in restaurant j and dishes served at every table.</p><p>Let m t jk be the number of tables in restaurant j serving dish k and m t j• be the number of tables in restaurant j. To sample c j , we need to compute the posterior,</p><formula xml:id="formula_4">p(c j |{m t jk }, c -j , { π c }, π 0 ) ∝ p({m t jk }|c j , c -j , { π c }, π 0 )p(c j |c -j , { π c }, π 0 )<label>(4)</label></formula><p>where c -j is the cluster labels of documents excluding document j. c j could be one of the existing clusters generated at the current stage, i.e. c j ∈ c old . In this case,</p><formula xml:id="formula_5">p(m t jk |c j , c -j , { π c }, π 0 ) = p(m t jk | π cj ) =   m t j• m t j1 • • • m t jK   K k=1 π m t jk cj k<label>(5)</label></formula><p>where K is the number of word topics allocated at the current stage. And,</p><formula xml:id="formula_6">p(c j |{ π c }, c -j , π 0 ) = n cj M -1 + µ (6)</formula><p>where n cj is the number of documents assigned to cluster c j . c j could also be a new cluster, i.e. c j = c new . In this case, </p><p>So we have, p(c j = c|{m t jk }, c -j , { π l }, π 0 )</p><formula xml:id="formula_8">∝ u c u • + µ K k=1 π m t jk ck , c ∈ c old µ u • + µ Γ(α) K k=1 Γ(α • π 0k ) • K k=1 Γ(α • π 0k + m t jk ) Γ(α + m t j• ) , c = c new<label>(9)</label></formula><p>In the third step, the concentration parameters are sampled given other random variables fixed. The same sampling scheme proposed in <ref type="bibr" target="#b16">[13]</ref> can be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.2.">Compute the likelihood of a document</head><p>In order to detect abnormal documents (trajectories), we need to compute the likelihood of a document j given other documents, p(w j |w -j ), where w j = {w ji } Nj i=1 is the set words in document j and w -j represents the remaining documents exclusing j. During the Gibbs sampling procedure, there are N samples {z -j(n) , {</p><formula xml:id="formula_9">(n) c }, { π (n) c }, π (n) 0 , α (n) } N</formula><p>n=1 drawn from distribution p(z -j , { c }, { π c }, {π 0 }, α|w) which is very close to p(z -j , { c }, { π c }, {π 0 }, α, |x -j ), We approximate p(w j |w -j ) as p(w j |w -j ) = 1 N n cj πj zj i</p><formula xml:id="formula_10">(n) cj p(π j |α (n) • π (n) cj )</formula><p>p(z j |π j )p(w ji |z ji , z -j(m) , w -j )dπ j <ref type="bibr" target="#b13">(10)</ref> p(π j |α (n) • π </p><p>is a multinomial distribution, where n t,zji is the number of words in w -j with value t and being assigned to topic z ji (see <ref type="bibr" target="#b16">[13]</ref>). The computation of πj zj p(π j |α (n) • π</p><p>(n) cj )p(z j |π j )p(w ji |z ji , z -j(m) , w -j ) is intractable, but can be approximated by a variatoinal method as in <ref type="bibr">[1]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Trajectories in the our two data sets. (a) Radar tracks collected from a port. (b) The background image of a parking lot. (c) Tracks collected from a parking lot scene (only 4, 404 out of 40, 453 tracks are shown here).</figDesc><graphic coords="3,346.91,211.39,144.07,108.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. An example to explain the modeling of semantic regions and activities. See details in text.</figDesc><graphic coords="4,199.12,71.85,194.49,124.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .Figure 4 .</head><label>34</label><figDesc>Figure 3. The graphical model of HDP</figDesc><graphic coords="6,203.96,71.85,187.29,122.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Semantic regions at a maritime port learnt from the radar tracks. Distributions of the first 16 semantic regions over space and moving directions are shown (for easier comparison, they are not shown in order). Colors represent different moving directions: → (red), ← (cyan), ↑ (magenta), and ↓ (blue),. (a) Histogram of observations assigned to different semantic regions. (b) All of the radar tracks. (c) Compare the 1st, 4th, 6th, 8th, and 15th semantic regions. (d) Compare the 7th, 11th, and 13th semantic regions (see details in text).</figDesc><graphic coords="7,175.03,392.08,122.45,66.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 (Figure 6 .</head><label>16</label><figDesc>Figure 6. Clusters of trajectories. Random colors are used to distinguish individual trajectories. For comparison the last two sub-figures show some trajectory clusters of the result using Euclidean distance and spectral clustering [4].</figDesc><graphic coords="8,200.36,360.28,194.48,105.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Top 20 abnormal trajectories are plotted in different colors. Other trajectories are plotted in cyan color.</figDesc><graphic coords="8,200.36,480.46,194.48,107.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Some semantic regions learnt from the parking lot data set. The meaning of colors is the same as Figure 5.</figDesc><graphic coords="9,49.99,252.89,97.25,73.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(b) are such examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .Figure 10 .</head><label>910</label><figDesc>Figure 9. Some clusters of trajectories from the parking lot data set.</figDesc><graphic coords="10,150.25,368.44,97.24,73.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>p</head><label></label><figDesc>({m t jk }|c j = c new , c -j , { π c }, π 0 ) = p({m t jk }|π new )p(π new |π 0 )dπ πnew j = c new |{ π c }, c -j , π 0 ) = µ M -1 + µ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>cj ) is Dirichlet distribution. If H = Dirichlet(•; (u 1 , . . . , u T )), where T is the size of the codebook,p(w ji |z ji , z -j(n) , w -j ) = u wji + n wji,zji T t=1 (u t + n t,zji )</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Given the cluster assignment {c j } of documents, sample the word topic assignment {z ji } (z ji = k indicates θ ji = φ k ), topic mixtures {π 0k } and { π ck }. Given {c j }, Dual-HDP is simplified as HDP, and thus the sampling scheme proposed by Teh et al. [13] can be used. They showed that {φ k } and {π jk } can be integrated out without being sampled</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Given {z ji }, {π 0k } and { π ck }, sample</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Given other variables, sample the concentration parameters using the sampling scheme proposed in</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">we need to compute the likelihood of document j given other documents, p(w j |w -j ), where w j = {w ji } Nj i=1 is the set words in document j and w -j represents the remaining documents excluding j. It can be approximated using the samples obtained during Gibbs sampling and a variational method</title>
		<imprint/>
	</monogr>
	<note>In order to detect abnormal documents (trajectories. See details in the appendix</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A bayesian analysis of some nonparametric problems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Ferguson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="209" to="230" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generation of semantic regions from image sequences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fernyhough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ECCV</title>
		<meeting>of ECCV</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Similarity based vehicle trajectory clustering and anomaly detection</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICIP</title>
		<meeting>of ICIP</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi feature path modeling for video surveillance</title>
		<author>
			<persName><forename type="first">I</forename><surname>Junejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICPR</title>
		<meeting>of ICPR</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A unified framework for tracking through occlusions and across sensor gaps</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kaucic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brooksby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaufhold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hoogs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scaling up dynamic time scaling up dynamic time</title>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGKDD</title>
		<meeting>of ACM SIGKDD</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Spatial nonparametric bayesian models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Maceachern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kottas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelfand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Institute of Statistics and Decision Sciences, Duke University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic learning of an activity-based semantic scene model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Makris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AVSBS</title>
		<meeting>of AVSBS</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A constructive definition of dirichlet priors</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sethuraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="639" to="650" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Temporalboost for event recognition</title>
		<author>
			<persName><forename type="first">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICCV</title>
		<meeting>of ICCV</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning patterns of activity using real-time tracking</title>
		<author>
			<persName><forename type="first">C</forename><surname>Stauffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. on PAMI</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hierarchical dirichlet process</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised activity perception by hierarchical bayesian models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning semantic scene models by trajectory analysis</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Tieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ECCV</title>
		<meeting>of ECCV</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Beyond tracking: Modelling activity and understanding behaviour</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="21" to="51" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Trajectory series analysis based event rule induction for visual surveillance</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Detecting unusual activity</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Visontai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
