<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Integrating Statistical Methods for Characterizing Causal In uences on Planner Behavior over Time</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="1994-06-27">June 27, 1994</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Adele</forename><forename type="middle">E</forename><surname>Howe</surname></persName>
							<email>howe@cs.colostate.edu</email>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">St</forename><surname>Amant</surname></persName>
							<email>stamant@cs.umass.edu</email>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
							<email>cohen@cs.umass.edu</email>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>St</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><forename type="middle">R</forename><surname>Amant</surname></persName>
						</author>
						<author>
							<persName><surname>Cohen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Dept</orgName>
								<orgName type="institution" key="instit1">Colorado State University</orgName>
								<orgName type="institution" key="instit2">Colorado State University Ft Collins</orgName>
								<address>
									<postCode>80523</postCode>
									<region>CO</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01003</postCode>
									<settlement>Amherst</settlement>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Integrating Statistical Methods for Characterizing Causal In uences on Planner Behavior over Time</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="1994-06-27">June 27, 1994</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T00:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given a complex planner and or environment, it can be di cult to determine why it behaves as it does. Statistical causal modeling techniques allow u s t o d e v elop models of behavior, but they tend to be limited in what they can model: either continuing, repetitive in uences or causal in uences without cycles, but not both as appear in most planning environments. This paper describes how t w o statistical modelling techniques can be combined to suggest speci c hypotheses about how the environment and the planner's design causally in uence the planner's behavior over many examples of interacting in its environment and to construct models of those in uences. One technique, dependency detection, is designed to identify relationships dependencies between particular failures, the methods that repair them and the occurrence of failures downstream. Another method, path analysis, builds causal models of correlational data. Dependency detection operates over a series of events, and path analysis models within a temporal snapshot. We explain the integration of the techniques and demonstrate it on data from the Phoenix planner.</p><p>This research w as supported by ARPA-AFOSR contract F30602-93-C-0100. The US Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright notation hereon.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Modelling Planner Behavior After many y ears of research, the planning community has developed many algorithms, techniques and strategies for planning. Unfortunately, for those trying to build a planner for a speci c environment, we do not know w h y and how our planning techniques work in particular environments. We do not have models of a planners operating in its environment, but rather, we need tools and techniques to help us construct them.</p><p>Because environments and planners do, these models will need to include continuous, numerical factors and discrete, categorical events. They will need to be developed, at least in part, from empirical data, and they will need to use data gathered over time as the planner operates in its environment.</p><p>Our models are statistical, that is, they relate behavior to in uences over many conditions.</p><p>With careful consideration of what is likely to in uence behavior and how the in uences and behaviors can be measured and related, we can construct models that are su cient to answer speci c questions about what makes a planner behave in particular ways. For example, we may ask: What is the relationship between possible decision strategies and the amount of time required to complete a plan? Does the in uence, as measured in terms of the resources used by the plan, of the e ect of the agent's actions depend on the rate of environment c hange? Are particular plan failures likely to be preceded by particular planner actions? These are the kinds of questions that we ask routinely when we design and implement planners for speci c environments and when we try to generalize planner designs across environments. Thus, these are the kinds of questions that we should routinely be answering with methods of model construction.</p><p>This paper describes how t w o statistical modeling techniques can be combined to answer questions about the in uence of numerical and categorical factors over periods of time in which situations and decisions are repeated. Each of the techniques are automated, generating models from empirical data without intervention. However, the two techniques, like other statistical techniques, are designed to answer questions about either numerical factors without feedback e.g., from repetition or categorical factors over many repetitions. Together, they are shown to characterize behavior involving both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Statistical Methods for Identifying In uences on Behavior</head><p>Statistical methods are a promising approach to answering questions about in uences on behavior. These questions are frequently hypotheses about the interaction of independent factors in uences on dependent factors. We rarely have recourse to complete, well-de ned models of environment or planner and so rely on observations and experiments to build such models. Additionally, e n vironments often are characterized by pseudo-random events the environment m a y not be random, but the factors that produce changes may be too di cult or numerous to measure and indeed sometimes the planners make random decisions, leading to descriptive models based on summaries or classi cations.</p><p>Statistical methods are designed to answer particular questions. In the course of our explorations with the Phoenix planner, we h a v e developed two methods, one for characterizing trends in a time series and the other for modelling a temporal snapshot. This section explains how the two methods can be combined to answer questions about in uences over varying time spans as well as constructing models of increasing detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Combining Two Statistical Methods</head><p>It is relatively easy to detect speci c, simple e ects of one thing on another, but not e ects of combinations of factors. Both Dependency Detection and Path Analysis are techniques for examining combinations.</p><p>Dependency Detection DD identi es relationships between discrete events in a time series, execution traces of a planner operating in an environment 12 . DD tests whether the occurrence of one event depends on the occurrence of other events prior to it i.e., whether one set of events appears to cause another event. For example, we h a v e used DD to search for dependencies between combinations of actions of a planner and plan failure.</p><p>Path Analysis PA is a technique for building causal models based on multiple linear regression 10,14,17,19,5 , which is related to techniques for causal induction 15,9 . Our algorithm for PA builds detailed models of the interaction of various causal factors on the value of an ordinal variable. For example, we h a v e constructed path models of environment and planner factors that directly or indirectly in uence the amount of time required to nish a plan. The primary strengths of dependency detection are capturing transitions through states and the behavior of the system over long periods of time, and discovering hypotheses about behavior. The primary strengths of path analysis are modelling the interaction of multiple continuous in uences at a particular point or within a short interval of time, and constructing detailed models of interactions of in uences. These strengths complement each other naturally in the framework of building causal models. Three requirements are commonly posited for x to cause y 18 : x must precede y in time; x and y must covary; and causes of y other than x must be controlled. By nding in uences between events, DD concentrates on precedence and control. Through application of regression, PA captures covariance and control. In combination, the two approaches cover all three requirements. We apply dependency detection and path analysis sequentially to answer speci c questions about behavior such as What previous events and environment factors cause a particular failure to occur?". Dependency detection can suggest a hypothesis about a speci c interval of interest, the interval between particular precursor events and a particular target event. Path analysis can then characterize in detail how the one event in conjunction with other factors in uences the occurrence of the second. Combining the two methods creates a natural progression from a descriptive to a predictive and possibly explanatory model<ref type="foot" target="#foot_0">foot_0</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Over a Time Series: Dependency Detection</head><p>Dependencies are detected statistically by analyzing execution traces. An execution trace is simply a sequence of interesting events that occurred during some period of observing the planner. Execution traces can be viewed as transitions between events, which can be analyzed for dependencies. Some of the events are designated as in uences called precursors in dependency detection and others as the behaviors of interest called target events. One event, T t , is said to be dependent on another, P a , i f T t is observed to occur more often following P a than after any other event. In its simplest form, the observed execution traces include precursor events interleaved with target events, as illustrated in the following example: P a ! T t ! P b ! T u ! P a ! T t where ! indicates temporal order. The statistical analysis requires two steps. Combinations of in uencing events are rst tested for whether they are more or less likely to be followed by each of the target events. Then the signi cant combinations are compared to remove o v erlapping combinations.</p><p>To determine whether particular target events are more or less likely after particular precursors, we construct contingency tables of the incidence of the target T t after the precursor P a by counting: 1 instances of T t that follow instances of P a , 2 instances of T t that follow instances of all precursors other than P a abbreviated P a , 3 target events other than T t abbreviated T t that follow P a and 4 target events T t that follow P a . These four frequencies are arranged in a 2x2 contingency table : 
T t T t P a 15 10 P a 30 50 For this table, we see a strong dependence between the precursor, P a , and the target event, T t : 15 cases of T t following P a out of 25 cases of P a . But while P a leads most frequently to target event T t , precursors other than P a lead to T t relatively infrequently 30 instances in 80. A G-Test on this table will detect a dependency between the target event and its precursor 17 ; in this case, G = 5 : 174; p : 023, which means that the two e v ents are unlikely to be independent and conclude that T t depends on P a abbreviated as P a ; T t .</p><p>The precursors can be single events or combinations of events. For example, we m a y wish some events to be counted both as in uences and as target events and so ask whether one target event in uences the occurrence of others. Given the above notation, we then build contingency tables for three classes of precursors: in uences that are not also targets, targets that are also in uences, and combinations of targets and in uences. A statistical technique based on the G-Test di erentiates the three types of precursors by comparing the sum of the e ects due to the combinations e.g., T u P a for all possible T t s to the e ect due to just the grouped e ect e.g., T u or P a . The intuition behind the test is that if the combinations do not add much information about the e ect then they can be disregarded; conversely, i f t h e grouped e ect, T u or P a , masks di erences between the pairs, then the grouped e ect should be disregarded as misleading. For example, by comparing the example dependency, P a ; T t t o ones that name the target that preceded P a as well e.g., T u P a ; T t , T v P a ; T t , etc, we m a y nd that T u P a ; T t adds little information over knowing P a ; T t , so the precursor that includes the preceding target can be disregarded. Similar comparisons can be done for longer combinations of in uences as well.</p><p>The output of dependency detection is a list of dependencies found to be signi cant in the execution traces and that describe the in uences without redundancy. The interpretation of this output depends entirely on what events were being monitored. Dependency detection was designed to detect sources of plan failure in the Phoenix planner 11 . For that application, the events of interest are failures and recovery actions, and it discovers dependencies between particular failures, the recovery methods that repair them and the occurrence of other failures downstream. We designed it to answer the question: Does a failure depend on some action or event that preceded it?" with the intent that we w ould use the information to identify bugs in the planner. For our explorations with the Phoenix planner, we h a v e collected almost 1000 execution traces 50-120 traces in each of nine di erent experiment scenarios in which w e h a v e detected hundreds of dependencies with precursors of many lengths. These dependency sets have been used in isolation to motivate debugging e orts and in comparisons to determine the sensitivity of particular dependencies to the planner's implementation and to the environment's rate of change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Snapshots of In uences: Path Analysis</head><p>Historically, path analysis was a method for estimating the strengths of causal in uence, given a causal model and correlational data. It was up to the data analyst to propose a causal model in the rst place. Recently, researchers have developed algorithms to propose causal models, given conditional information relationships in data, but these algorithms don't handle estimation, relying instead on statistical packages notably EQS or LISREL 1,13 to estimate strengths of causal in uence. We h a v e recently developed an algorithm that uses these strengths to guide its search in the space of causal models; in other words, it infers causal models and estimates their parameters at the same time. We h a v e used our algorithm, called FBD, to estimate the causal in uence of aspects of the Phoenix environment, such as wind speed and re perimeter, on variables such as the time until the next plan failure.</p><p>FBD is described in detail in 4 ; we will just sketch it here. Before analysis begins, we assume that our data are standardized to eliminate the e ect of di erences due to measurement scale.</p><p>Standardization transforms a distribution of data, such as the distribution of re perimeters, so its mean is zero and its standard deviation is one. Standardized variables are denoted by uppercase letters and created by the transformation X i = x i , x =s. Ordinary multiple linear regression builds causal models that predict the value of a performance variable Y given predictors X 1 ; X 2 ; : : : X k . In standardized form, a regression model looks like this:</p><formula xml:id="formula_0">Å¶i = X 1 X 1 i + X 2 X 2 i + + X k X k i</formula><p>If one were to draw a picture of this model, it would have each predictor variable pointing directly to the performance variable and correlated with every other predictor variable. coe cients have a causal interpretation. This is possible because they are partial: each represents the in uence of one predictor variable on Y when the in uences of all the other predictor variables are held constant. As such, these coe cients o er a statistical version of the experimental control that we need to assert cause. To show that X 1 , s a y , causes Y we h a v e t o show that its correlation with Y is not due to some shared relationship with another variable, say, X 2 . Most causal induction algorithms do this by showing that the relationship between X 1 and Y does not disappear when X 2 is held constant. Partial correlation coe cients are used for the purpose, but partial regression coe cients| coe cients|will serve a s w ell. Thus, if X 1 and Y have a high correlation but X 1 is close to zero, we suspect that X 1 's in uence on Y is actually due to another variable. Moreover, because coe cients are in the same units, if X 1 = k X 3 we can say predictor X 1 has k times the causal in uence of X 3 .</p><p>Unfortunately, m ultiple regression models are just one level" deep, which means that all in uences are modelled as exerting a direct in uence on the dependent v ariable. The FBD algorithm solves this problem as follows: it nds good predictors of the performance variable Y and then, recursively, treats each predictor as a performance variable and nds good predictors for it. The trick is to decide which predictors to use at a particular level, and which to hold back. FBD applies four tests to select a set of predictors at each level. First, it won't allow a v ariable to be a predictor if doing so creates a cycle in the resulting causal model e.g., A causes B and B causes A. Second, it calculates the score ! i = r Y;X i , X i r Y;X i and throws out any predictor for which ! i T ! , a threshold. ! i represents the proportion of X i 's total in uence on Y , measured by the correlation r Y;X i that is not due to its direct in uence on Y , measured by X i . Said di erently, ! i represents the proportion of X i 's in uence on Y that is due to its relationships with other predictors. It should be as low as possible. The third test is that X i T , because a predictor can pass the second test but still have v ery little direct in uence on Y . The fourth test is more complex and is stated here without elaboration:</p><p>FBD will select from the predictors that passed the rst tests those that form the largest set of predictors such that none is conditionally independent of the performance variable given the others see 4 for explanation.</p><p>At e v ery stage of the development of a model, the candidate predictors for a performance variable are all those but the original performance variable and the current one, but the candidates are quickly whittled down to a smaller set, typically less than ve or six. Each of these predictors then becomes a performance variable and the process repeats until we run out of variables that need to be predicted.</p><p>FBD has been thoroughly tested and its performance compared with Pearl and Verma's IC algorithm 15 . As expected, the algorithm performed well using measures such a s R 2 and di erences in estimated correlation. Additionally, it compared favorably using conditional independence measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">An Example with Phoenix</head><p>The Phoenix reboss planner coordinates the e orts of other agents to contain forest res within a simulation of res in Yellowstone National Park 6 . Within the simulation, res burn somewhat unpredictably, and the weather can be controlled during experimentation to change at variable intervals and by v ariable amounts. The reboss is forced to deal with challenging conditions: limited resources and a changing environment. As a consequence, the reboss's plans often fail.</p><p>Failure due to environment m a y be unavoidable; failure due to poor decisions on the part of the planner is unacceptable. In this example, we wish to combine dependency detection with path analysis to identify factors relevant to a major decision the planner must make: which o f several possible skeletal plans to use to ght a particular re.</p><p>First, we collected 102 execution traces of the Phoenix reboss planner in a scenario in which three res were started at intervals of about 12 hours and the wind speed was allowed to vary by 3 kph and the wind direction by 15 degrees every 30 minutes. Wind speed and wind direction strongly in uence the spread of the re.</p><p>The execution traces included failures and the recovery methods applied to repair them. For example, the following is a fragment of a trace from the set: F cfp ! R rm ! F ner ! R spa ! F ip ! R aab . F X denotes the occurrence of a plan failure of type X; R Y denotes the successful use of a recovery method of type Y . The data includes 10 types of plan failure and 8 types of recovery methods. It is impossible to tell much from just this fragment; for example, F ner may depend on R rm but we h a v e only one example of it. We analyzed the traces with dependency detection and identi ed 23 dependencies: 3 with precursors of FR , 7 with precursors of F, and 13 with precursors of R. The target events were failures.</p><p>At the conclusion of the DD phase, the experimenter must select a dependency for further modeling with PA. The output of DD is a set of dependencies; the starting point for PA should be a single dependency that demarcates an interval. Many criteria can be used to select a dependency for attention. We picked a dependency that was highly signi cant, was based on a fair amount of data no cell in the contingency table was less than 5, and included as a target event a failure with costly recovery. The dependency R rm ; F ner ranked best on these criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Its contingency table is:</head><p>F ner F ner R rm 18 62 R rm 20 314 A G-test on this table yields G = 2 3 : 7 ; p : 0001, which is highly signi cant. Now, we wish to know why R rm seems to cause F ner . R rm is an expensive replanning method that results in recalculation of the entire plan to ght a re. The F ner failure results when not enough resources are available to complete the plan that was selected. We used dependency detection to identify this relationship; we n o w apply path analysis to explore the relationship in more detail.</p><p>What we need from path analysis is a model of the factors that in uence the occurrence of the F ner failure. Once we understand these factors, we can redesign the decision procedure about which plan to use during replanning. Based on some knowledge of how the environment in uences re spread and how other plans in uence available resources, we identi ed a candidate set of variables to be collected during another experiment and considered as part of a path model. It is unrealistic to monitor everything in a planner and environment, and so collecting additional data requires some knowledge on the part of the experimenter as to which factors are likely to be salient. Those in uences are collected at the time of replanning and are: wind speed, re size, number of active bulldozers working on other res or waiting for assignment, number of res being fought, distance from center of re to base, wind speed changes over last two hours, wind direction changes over last two hours.</p><p>Because the dependent factor for PA should be a continuous variable, we replaced the event F ner with the variable Interval, a measure of the time between the start of the replan and the conclusion of the new plan either by successful completion or by occurrence of a failure.</p><p>We seek to maximize the delay b e t w een plan start and plan failure because the longer the plan executes, the more likely it is to have passed the critical point of producing a F ner failure which occurs, if at all, relatively early in a re ghting plan.</p><p>We ran 60 trials of the same scenario in which w e collected the above information. We used path analysis to generate the model shown in Figure <ref type="figure" target="#fig_0">1</ref>. The model accurately identi es change in wind speed and wind direction as independent v ariables, and captures several expected relationships: as variability in wind direction increases, the size of the re grows; a greater number of res causes replanning to happen sooner, reducing Interval. The strongest factor a ecting Interval is Fires, and then Wind Speed and Fire Size. The greater the number of res, the shorter Interval is likely to be, and thus the more likely F ner is to occur.</p><p>Using the model we can then approach the task of improving R rm . One bene t of the model is that it helps us distinguish between many possible in uences on a variable and concentrate on the ones that have the strongest in uence in terms of individual contribution and predictive power. The replanning method can make a better informed decision by rst considering the number of res, then re size and wind speed. At present, it considers only the number of bulldozers available and the wind speed. Indirect in uences, such a s c hange in wind direction, are of secondary interest. The particular plan selected by R rm , of which there are several The path analysis model can thus provide detailed solutions to questions" posed by dependency detection. The reverse is also true. One di cult area for path analysis modeling is the general problem of distinguishing cause from e ect based on predictive criteria. As mentioned, the model built by P A is not perfect; for example, if number of res is a good predictor of the number of bulldozers, then the reverse is likely to hold as well and, in fact, does hold in our model.</p><p>To handle this di culty, w e might allow the user to specify variables as independent. This simple approach has limitations. In non-experimental studies, in which v ariables are not manipulated explicitly, it is not always apparent whether a variable is independent. A potentially better approach is to use dependency detection to nd the proper causal direction between two variables. In our model, for example, the relationship Bulldozers ! Fires is plausible, given the data, but we believe that the causality could be reversed. We can explore this question by associating the continuous variable Bulldozers with the discrete event BulldozerDeath and the variable Fires with the event FireSet. If a dependency is detected from FireSet to Bulldoz-erDeath, w e take this as evidence that the causal in uence is from Fires to Bulldozers in the path analysis model as well. Not all relationships can be examined in this way, but there are many natural candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The results of combining DD and PA are a dependency and a path model of the in uences related to that dependency. The next step is interpretation, which requires domain knowledge.</p><p>We use the path model and the dependency to identify factors that produce early plan failure, and we use domain knowledge to prune out implausible candidates and to determine how those factors might be considered by the planner during replanning.</p><p>The model may uncover relationships that are expected but needed to be con rmed, unexpected but plausible, or implausible and likely due to sampling bias. For example, we expected that Wind Speed in uenced Interval but not to what degree; we did not expect Bulldozers to indirectly in uence Interval but upon re ection and some checking, we can construct a domain explanation of why; and we experimentally varied the Fires and know it is not possible that the number of bulldozers can have a strong negative e ect on it <ref type="bibr" target="#b1">2</ref> .</p><p>Together these results of DD and PA answer the question of how a previous event a recovery action and environment factors such as wind speed and number of res in uence how and when a particular failure occurs. For now, by combining DD and PA, we can answer questions about what events and in uences cause subsequent e v ents, as well as how short horizon factors in uence performance at the target event. For the future, we are designing methods to answer other questions about planner behavior and to interpret the results of those methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Path analysis model of factors in uencing Interval</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>While a PA model can be explanatory as well, in our combination of the methods, the explanatory model is developed by a knowledge based, as opposed to statistical, technique called Failure R e c overy Analysis 11 .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>We collect data only when Rrm occurs. As bulldozers are destroyed by re, replanning increases. As more res are set, replanning increases as well. Each instance of replanning makes the occurrence of Rrm more probable; thus, our data are biased towards situations with a high correlation between the number of bulldozers and the number of res.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Theory and Implementation of EQS: A Strutural Equations Program</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bentler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>BMDP Statistical Software, Inc</publisher>
			<pubPlace>Los Angeles</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Intelligence without reason</title>
		<author>
			<persName><forename type="first">Rodney</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Joint Conference o n A rti cial Intelligence</title>
		<meeting>the Twelfth International Joint Conference o n A rti cial Intelligence<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1991-08">August 1991</date>
			<biblScope unit="volume">569</biblScope>
			<biblScope unit="page">595</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Penguins can make cake</title>
		<author>
			<persName><forename type="first">David</forename><surname>Chapman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="1989">1989</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Experiments with a regression-based causal induction algorithm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName><surname>St</surname></persName>
		</author>
		<author>
			<persName><surname>Amant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automating path analysis for building causal models from data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><surname>St</surname></persName>
		</author>
		<author>
			<persName><surname>Amant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Machine Learning</title>
		<meeting>the Tenth International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Trial by re: Understanding the design requirements for agents in complex environments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adele</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><surname>Howe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="page">103</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Intelligence without robots: A reply to Brooks</title>
		<author>
			<persName><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">7 13</biblScope>
			<date type="published" when="1993">1993</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Universal planning: An almost universally bad idea</title>
		<author>
			<persName><forename type="first">L</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName><surname>Ginsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">44</biblScope>
			<date type="published" when="1989">1989</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Discovering Causal Structure</title>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kelly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Predicting and explaining success and task duration in the Phoenix planner</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Arti cial Intelligence Planning Systems: Proceedings of the First International Conference AIPS92</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Hendler</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers, Inc</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Accepting the Inevitable: The Role of Failure R e c overy in the Design of Planners</title>
		<author>
			<persName><forename type="first">Adele</forename><forename type="middle">E</forename><surname>Howe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993-02">February 1993</date>
			<pubPlace>Amherst, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts, Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Isolating dependencies on failure by analyzing execution traces</title>
		<author>
			<persName><forename type="first">Adele</forename><forename type="middle">E</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">R</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Arti cial Intelligence Planning Systems: Proceedings of the First International Conference</title>
		<meeting><address><addrLine>College Park, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">LISREL VI User&apos;s Guide</title>
		<author>
			<persName><forename type="first">K</forename><surname>Joreskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sorbom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984">1984</date>
			<publisher>Scienti c Software, Inc</publisher>
			<pubPlace>Mooresville, IN</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Path Analysis A Primer</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975">1975</date>
			<publisher>B o xwood Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A theory of inferred causation</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Allen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fikes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Sandewall</surname></persName>
		</editor>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1991-04">April 1991</date>
			<biblScope unit="volume">441</biblScope>
			<biblScope unit="page">452</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">In defense of reaction plans as caches</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Schoppers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">60</biblScope>
			<date type="published" when="1989">1989</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Biometry: The Principles and Practice of Statistics in Biological Research</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">R</forename><surname>Sokal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">James</forename><surname>Rohlf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>W.H. Freeman and Co</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A P r obabilistic Theory of Causality</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Suppes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<pubPlace>North Holland, Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Correlation and causation</title>
		<author>
			<persName><forename type="first">Sewal</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Agricultural Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="557" to="585" />
			<date type="published" when="1921">1921</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
