<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Analytical power calculations for structural equation modeling: A tutorial and Shiny app</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-11-02">2 November 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Suzanne</forename><surname>Jak</surname></persName>
							<email>s.jak@uva.nl</email>
							<idno type="ORCID">0000-0002-2223-5594</idno>
							<affiliation key="aff0">
								<orgName type="department">Methods and Statistics, Research Institute of Child Development and Education</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>Nieuwe Achtergracht 127</addrLine>
									<postCode>1018</postCode>
									<settlement>Amsterdam</settlement>
									<region>WS</region>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Terrence</forename><forename type="middle">D</forename><surname>Jorgensen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Methods and Statistics, Research Institute of Child Development and Education</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>Nieuwe Achtergracht 127</addrLine>
									<postCode>1018</postCode>
									<settlement>Amsterdam</settlement>
									<region>WS</region>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mathilde</forename><forename type="middle">G E</forename><surname>Verdam</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Methodology and Statistics</orgName>
								<orgName type="department" key="dep2">Institute of Psychology</orgName>
								<orgName type="institution">Leiden University</orgName>
								<address>
									<settlement>Leiden</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Frans</forename><forename type="middle">J</forename><surname>Oort</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Methods and Statistics, Research Institute of Child Development and Education</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>Nieuwe Achtergracht 127</addrLine>
									<postCode>1018</postCode>
									<settlement>Amsterdam</settlement>
									<region>WS</region>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Louise</forename><surname>Elffers</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Educational Sciences</orgName>
								<orgName type="department" key="dep2">Child Development and Education</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Analytical power calculations for structural equation modeling: A tutorial and Shiny app</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-02">2 November 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3758/s13428-020-01479-0</idno>
					<note type="submission">Accepted: 3 September 2020 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T21:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conducting a power analysis can be challenging for researchers who plan to analyze their data using structural equation models (SEMs), particularly when Monte Carlo methods are used to obtain power. In this tutorial, we explain how power calculations without Monte Carlo methods for the œá 2 test and the RMSEA tests of (not-)close fit can be conducted using the Shiny app "power4SEM". power4SEM facilitates power calculations for SEM using two methods that are not computationally intensive and that focus on model fit instead of the statistical significance of (functions of) parameters. These are the method proposed by Satorra and Saris (Psychometrika 50(1), [83][84][85][86][87][88][89][90] 1985)  for power calculations of the likelihood ratio test, and that described by MacCallum, Browne, and Sugawara (Psychol Methods 1(2) [130][131][132][133][134][135][136][137][138][139][140][141][142][143][144][145][146][147][148][149] 1996)  for RMSEA-based power calculations. We illustrate the use of power4SEM with examples of power analyses for path models, factor models, and a latent growth model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Before any quantitative study is conducted, one should evaluate how large the sample should be for the study to be adequately powered <ref type="bibr" target="#b7">(Cohen, 1992)</ref>. That is, there should be a fair chance to reject the null hypothesis (H 0 ) if it is indeed false. When statistical power is too low to detect a meaningful effect, a study would essentially waste data on type II errors. When the power is approximately 100%, a researcher may be wasting often expensive resources because the effect of interest could have been detected with a smaller sample size. To prevent under-or overpowered studies, researchers need to calculate the minimum sample size required to sufficiently minimize the chance of type II errors before they start collecting data. For simple analyses such as t tests or simple regression models, there are user-friendly tools to calculate statistical power, such as G*Power <ref type="bibr" target="#b10">(Erdfelder, Faul &amp; Buchner, 1996)</ref> or the R (R Core Team, 2019) package pwr <ref type="bibr" target="#b4">(Champely, 2018)</ref>. However, for researchers who intend to apply structural equation modeling to test their hypotheses, conducting a power analysis is more challenging.</p><p>There are three ways to calculate power for structural equation models (SEMs). One is by performing a Monte Carlo simulation study <ref type="bibr" target="#b19">(Muth√©n &amp; Muth√©n, 2002)</ref>. This is a computationally intensive method in which a researcher generates a large number of data sets from a population model corresponding to an alternative hypothesis (H 1 ), fits the model corresponding to the null hypothesis (H 0 ) to all generated data sets, and calculates the proportion of data sets for which the statistic or parameter of interest (e.g. œá 2 value, regression coefficient, or indirect effect) is statistically significant. This method provides an empirical estimate of power. For instructions on how to conduct such a study, see the articles by <ref type="bibr" target="#b19">Muth√©n and Muth√©n (2002)</ref>, <ref type="bibr" target="#b25">Schoemann, Boulton, and Short (2017)</ref>, or <ref type="bibr" target="#b27">Wang and Rhemtulla (2020)</ref>. In this tutorial we focus on two methods that are not computationally intensive and that focus on model fit instead of the statistical significance of (functions of) parameters: the method introduced by Satorra and <ref type="bibr" target="#b24">Saris (1985)</ref> for power calculations of the likelihood ratio test (LRT), and that by MacCallum, <ref type="bibr" target="#b16">Browne, and Sugawara (1996)</ref> for the calculation of root mean square error</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical power</head><p>A statistical test can be applied to obtain the probability (the p value) of finding a test statistic at least as extreme as the one from the given sample, given that the H 0 about the population value is true. When the p value is smaller than the chosen significance level (e.g., Œ± = .05), then H 0 will be rejected in favor of the alternative hypothesis (H 1 ). When the H 0 is not rejected while H 0 is actually false (so H 1 is true), one is making a type II error, and the probability of doing so is denoted by Œ≤. It is therefore important to know the probability of rejecting a false H 0 , which is the power (1 -Œ≤) of a statistical test. Table <ref type="table" target="#tab_0">1</ref> presents an overview of the relations between truth/falseness of the null hypothesis and outcomes of the test.</p><p>In applied hypothesis testing, H 1 represents a range of values. For example, H 1 may be that two means are unequal, or that a regression coefficient is larger than zero. However, to evaluate the power of a statistical test, researchers have to determine a specific value for H 1 . In the simple example of a t test, one may calculate the power to reject the H 0 of zero difference between two group means, given that in the population there is a mean difference of 0.5 standard deviations between groups (i.e., the standardized effect size; Cohen's d = 0.50, representing a "medium-sized" effect 3 ). For a given sample size (N) and significance level, the larger the difference between the null-hypothesized effect size and the effect size under H 1 , the larger the statistical power. So, for example, the statistical power to detect an effect size of d = 0.80 (representing a "large" effect) will be larger than the statistical power to detect an effect size of d = 0.50. The statistical power also increases with increasing sample size and with increasing significance level (but the latter also increases the probability of making a type I error). Note that in this example, the hypotheses refer to only one parameter: the difference between two group means. In SEM, many parameters are involved (e.g. direct effects, factor loadings, residual variances), making power calculations more complex. œá<ref type="foot" target="#foot_1">foot_1</ref> -based power <ref type="bibr" target="#b24">Satorra and Saris (1985)</ref> developed a method for estimating the power of the LRT (i.e., a SEM's œá 2 fit statistic) in SEM.</p><p>This method can be used to estimate the power to detect overall misspecification of SEMs, and to estimate the power to detect misspecification due to specific parameters. We will first discuss the power related to overall fit of the model, and then explain how the same procedure can be used for power calculations related to specific parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical background: Power to reject overall exact model fit</head><p>At the population level, the variables in a SEM may be related to each other. The population covariance matrix between the variables is denoted by Œ£ population . A researcher who plans to use SEM specifies a model that presumably explains the variances and covariances between the variables. The parameters in that model (for example, factor loadings, factor (co)variances, and residual variances in a factor model) lead to a so-called model-implied covariance matrix, denoted by Œ£ model . If the researcher specified the correct model, then the specified model indeed gives rise to the population covariance matrix, and Œ£ population = Œ£ model . If the specified model is not exactly correct, there is another model leading to Œ£ population , resulting in a discrepancy between Œ£ model and Œ£ population , so that Œ£ population ‚â† Œ£ model . The discrepancy between Œ£ population and Œ£ model is denoted by F 0 .</p><p>The œá 2 test of overall fit in SEM tests whether the hypothesized model fits exactly in the population-that is, the H 0 that the population discrepancy F 0 is zero. When H 0 is true, the expected value of the œá 2 statistic equals the expected sampling error, which is equal to the degrees of freedom (df) of a model. The df of a model can be calculated by counting the number of observed statistics p (the number of unique elements in the observed covariance matrix and mean vector of the variables) and the number of model parameters to be estimated, q. The model's df is then equal to df = pq. Calculation of a model's degrees of freedom will be illustrated in the example analysis in the next section.</p><p>Fitting the hypothesized model to data leads to an observed œá 2 statistic. The p value associated with the observed œá 2 statistic and the model's df gives the probability of observing a sample discrepancy at least as large as the observed one, when any discrepancy is solely due to random sampling error. When this probability is smaller than the nominal Œ± level, H 0 is rejected, implying that the model does not hold exactly in the population. In other words, we conclude that the model is misspecified.</p><p>The H 0 thus represents the case that the model fits the data exactly. When this is true, the expected œá 2 value will be equal to the expected sampling error, i.e. with E() denoting the expected value: E(œá 2 ) = E(sampling error) = df. The H 1 is that the model does not fit the data exactly. When H 1 is true but the (misspecified) H 0 model is fit to the data, the test statistic also asymptotically follows a œá 2 distribution (assuming multivariate normality and limited misfit), but with a larger mean and larger sampling variance. As a result, the distribution of the œá 2 statistic under H 1 lies more to the right, and is more spread out, than the distribution of the œá 2 statistic under H 0 . The expected œá 2 value under H 1 consists not only of discrepancies due to sampling error, but also discrepancies due to misspecification, i.e., E(œá 2 ) = E(sampling error) + E(misspecification error). The expected misspecification error is called the noncentrality parameter, denoted by Œª. Therefore, under H 1 , the expected œá 2 statistic equals df + Œª. The exact size of Œª depends on the population discrepancy F 0 and the sample size (see <ref type="bibr" target="#b18">Moshagen &amp; Erdfelder, 2016)</ref>:</p><p>where n = N under normal-theory<ref type="foot" target="#foot_3">foot_3</ref> maximum likelihood estimation.</p><p>To summarize, under H 0 the test statistic follows a central œá 2 distribution, with an expected value (i.e., mean) equal to its df parameter, and sampling variance equal to 2 √ó df. Under H 1 , the test statistic follows a œá 2 distribution that is noncentral, with a mean equal to its df plus its noncentrality parameter Œª-a nonnegative number that quantifies the degree of misspecification error-and sampling variance equal to 2df + 4Œª (i.e., greater misspecification leads to more variability between replications of a study). Table <ref type="table" target="#tab_1">2</ref> provides an overview of the hypotheses, models, and distributions associated with H 0 and H 1 .</p><p>Figure <ref type="figure">1</ref> shows a central œá 2 distribution with df = 5 in red, and a noncentral œá 2 distribution with df = 5 and Œª = 10 in blue. The noncentral œá 2 distribution is the œá 2 distribution associated with H 1 . The vertical line indicates the critical œá 2 value under the central œá 2 distribution that is associated with the H 0 with Œ± = .05. The H 0 will only be rejected if the observed œá 2 value is larger than the critical value. The blue area under the H 1 curve then shows the statistical power: the probability of rejecting  <ref type="bibr" target="#b24">Satorra and Saris (1985)</ref> showed that in order to obtain the noncentrality parameter for the œá 2 test in SEM, one can fit the H 0 model to covariances (and means) implied by the population model under H 1 . Because the model is fit to population moments, the sampling error is eliminated from the model (E(sampling error) = 0). All resulting discrepancies therefore arise from misspecification error, so that The œá 2 value obtained in this way is therefore the noncentrality parameter Œª under H 1 .</p><formula xml:id="formula_0">(1) Œª = n √ó F 0 ,</formula><p>Practically, a researcher performing a SEM power analysis first has to formulate the H 0 model. This is the model that the researcher thinks is the correct model. Next, the researcher has to think about a situation in which the H 0 model should be rejected. That is, they have to define what H 1 actually represents, by formulating a model with one or more additional parameters that are not zero. They then calculate the statistical (2) E œá 2 = 0 + E(misspecif ication error) = 0 + Œª.</p><p>power to reject the H 0 model when H 1 is true. Although conceptually it is easier to think about the H 0 model first, and then define how the H 0 model might be wrong (or what misspecification one wants to be able to detect with sufficient power), in order to perform power calculations, one has to specify the H 1 model first, followed by the H 0 model.</p><p>The following steps are used to obtain the statistical power <ref type="bibr" target="#b23">(Saris &amp; Satorra, 1993)</ref>:</p><p>Step 1: Calculate the model-implied population covariance matrix under the alternative-hypothesized model (Model H 1 ). The calculated covariance matrix is treated as population data in Step 2.</p><p>Step 2: Fit the null-hypothesized model (Model H 0 ) to the model-implied covariance matrix from Step 1.</p><p>Step 3: Use the œá 2 value from Step 2 as the noncentrality parameter Œª to calculate the statistical power.</p><p>We will illustrate these three steps with power analyses for the overall fit of a path model.</p><p>Example 1: Calculating the power of the œá 2 test for overall fit of a path model</p><p>As an example, we use the path model that was analyzed by <ref type="bibr" target="#b13">Ma et al. (2020)</ref>. It evaluates the effects of role conflict, role ambiguity, coworker support, and family support on three outcomes: emotional exhaustion (EE), depersonalization (DP), and decreased personal accomplishment (DPA). This path model is shown in Fig. <ref type="figure" target="#fig_0">2</ref>, using the thinner black lines (so the thicker gray lines should be ignored for now). The model contains seven variances, four covariances, and 10 regression coefficients to be estimated, leading to a total of 21 parameters. The number of unique elements in the observed covariance matrix equals (7 √ó 8)/2 = 28. Thus, df = 28 -21 = 7. With a significance level of Œ± = .05, exact fit of this model would be rejected if the œá 2 value obtained were larger than the Fig. <ref type="figure">1</ref> A central œá 2 distribution with df = 5 (dashed red line), and a noncentral œá 2 distribution with df = 5 and Œª = 10 (blue solid line). The shaded area corresponds to the statistical power with Œ± = 0.05 critical value of a œá 2 distribution with df = 7 and Œ± = .05, which equals œá 2 = 14.067. In order to calculate the power of the overall œá 2 test, we follow the three steps as outlined above.</p><p>Step 1 -We have to specify an H 1 model that contains more parameters than the model to be tested (H 0 ). We have to specify the population values for all parameters in the model, including the parameters that are also included in the model under H 0 . For this example we use the standardized parameter estimates obtained by <ref type="bibr">Ma et al. (2019)</ref> as population values for the parameters that are also included in the H 0 model. Figure <ref type="figure" target="#fig_0">2</ref> shows the path model with the smaller black lines representing these population parameters. In general, it may be convenient to specify the parameter values in standardized form, so one can base values on the guidelines regarding small, medium, and large effects in the appropriate research domain. Next, we have to specify the parameters that are present under H 1 , but not under H 0 . These parameters define exactly how the model under H 0 is misspecified. As there are many options for defining H 1 , it may require quite some deliberation to decide what the exact misspecification should entail. In principle, we would advise researchers to think about the parameters that should really lead to rejection of H 0 if they are not zero. Regarding the value of these parameters, our recommendation would be to choose the minimum value that would be of interest. In our example, we added two small effects to the model associated with H 1 : an effect of .10 for role ambiguity on EE, and an effect of .10 for family support on EE. In addition, we added a covariance between the residuals of family support and coworker support of .30. Note that specifying only these three extra parameters implies that we chose population values of zero for the rest of the parameters, such as the effect of role conflict on DPA. Figure <ref type="figure" target="#fig_0">2</ref> shows the population values of all parameters under H 1 , with the extra parameters indicated in thicker gray lines. The goal of step 1 of the procedure is to generate population data based on H 1 . If one wants to generate data in R, one can for example specify the population values in designated matrices and use matrix algebra to do so.</p><p>Appendix 1 provides the R code to calculate the modelimplied covariance matrix with matrix algebra for this example. However, the power4SEM app lets users specify the model in lavaan syntax with all fixed parameters, and will do these calculations behind the scenes using functions from the semTools package <ref type="bibr" target="#b11">(Jorgensen, Pornprasertmanit, Schoemann &amp; Rosseel, 2020)</ref>. Below, we show the lavaan syntax that specifies our example model under H 1 . 1 CoSup: .936, FamSup: .853, EE: .887, DP: .812, DPA: .789</p><p>All parameters are fixed at the (chosen) population values using the multiplication operator. For example, the population direct effect of RoleAmbi on CoSup is specified as being -.253 using "CoSup ~ -.253*RoleAmbi." In the app, a graphical display of the model will appear at the right side of the dialog box. This figure is created using the semPlot package <ref type="bibr" target="#b9">(Epskamp, 2019)</ref>. Although the outline of these figures may not always be optimal, especially with larger models, this graphical display can be used to check whether all population values are indeed specified as fixed parameters. If the model syntax still contains unspecified/free direct effects or (co)variances, these will be displayed in red.</p><p>Note that we started by using the standardized parameter values as reported by Ma et al., to ensure meaningful interpretation of the size of parameters However, by adding the extra parameters in the H 1 model, we also changed two population variances of the variables. As a result, the standardized values of the parameters may also change, compromising the interpretation of specified parameter values according to a standardized metric. If one clicks the button that says "View H1 values" in the app, a pop-up window appears that contains the model-implied covariance matrix of the H 1 model. The variances of the variables are on the diagonal of the covariance matrix. In a path model where all variances equal 1, all parameters are in the standardized metric. In a factor model, the same is true when the common factors are scaled by fixing the factor variances to 1. If the model-implied variances are not equal to 1, users may want to change some population values (for example by increasing or decreasing residual variances) such that the model-implied variances are 1. Users can inspect the table containing the values of the H 1 parameters in the standardized metric in the pop-up window. In our example, the model-implied variances of EE and DP are no longer exactly 1, but are close enough to ensure that the difference between the standardized values of the added direct effects and the specified values are within rounding error.</p><p>Step 2 -The next step is to specify the model under H 0 . In our app, the lower input box on the left can be used to add the lavaan syntax specifying the model to be tested. A graphical display of the model to be analyzed is shown next to the input box. Since this model contains free parameters, this figure contains red parameters. Figures 3 and 4 show a screenshot of the app with the input boxes and the graphical displays of our example model. If we hit the green button that says "Calculate NCP," Fig. <ref type="figure">3</ref> Screenshot of the calculation of the noncentrality parameter in power4SEM power4SEM will fit the H 0 model to the population data generated under H 1 , with the specified intended sample size, using the function SSpower() from the sem-Tools package <ref type="bibr" target="#b11">(Jorgensen et al., 2020)</ref>. The resulting œá 2 value is the noncentrality parameter that we need to calculate the power. In our example, the noncentrality parameter equals 26.638.</p><p>Step 3 -In the second tab of the app, we can calculate the power of the œá 2 test using the obtained noncentrality parameter. By filling in the noncentrality parameter (Œª = 26.638), df = 7, and Œ± = .05, the two associated œá 2 distributions and the calculated power will appear at the right side. In this example, we see that the power to reject the overall fit of the path model, given the chosen H 1 model, equals .982. At the lower left part of this tab, the minimum sample size that would be needed to obtain a specific power level can be calculated. In this example, a sample of 109 would be needed to obtain a power of .80.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical background: Power of the œá 2 difference test</head><p>The œá 2 statistic can be used to evaluate the overall fit of a model, but it can also be used to test the difference between two nested models with the œá 2 difference (Œîœá 2 ) test. For example, one may use the œá 2 difference test to test whether removing a certain direct effect in a path model leads to significantly worse model fit. A specific model (Model A) is said to be nested within a less restricted model (Model B) with more parameters (i.e., fewer df) than Model A, if Model A can be derived from Model B by introducing restrictions only. For example, path model A is nested within path model B by fixing one of the path coefficients in Model B to zero, or by constraining two path coefficients in path model B to be equal to each other. This is known as parameter nesting: any two models are nested when the free parameters in the more restrictive model are a subset of the free parameters in the less restrictive model.</p><p>The H 0 for the œá 2 difference test is that the difference between the population discrepancy values for the two models (Model A and Model B) is zero: ŒîF 0 = F 0_A -F 0_B = 0, or in other words that the two models fit equally well. The H 1 is that the models do not fit equally well, or specifically, that the more restricted Model A fits worse than Model B, so that F 0_A -F 0_B &gt; 0, or equivalently, ŒîF 0 &gt; 0.</p><p>As the test statistic of each of the nested models follows a œá 2 distribution, the difference in œá 2 values between two nested models is also œá 2 distributed: with degrees of freedom for the difference equal to the difference in degrees of freedom for the two models:</p><p>When Model A and Model B fit equally well in the population (so H 0 is true), then the models have the same F 0 , leading to the same noncentrality parameter Œª, such that ŒîŒª = Œª A -Œª B = 0. In this case, the Œîœá 2 between the models asymptotically follows a central œá 2 distribution. Under H 1 , so when the two models do not fit equally well, the noncentrality parameter of the most restricted model will be larger, such that ŒîŒª = Œª A -Œª B &gt; 0. In this case, under the assumption that neither Model A (3) nor Model B is badly misspecified, the Œîœá 2 between the models asymptotically follows a noncentral œá 2 distribution with noncentrality parameter ŒîŒª <ref type="bibr" target="#b26">(Steiger et al. 1985)</ref>. See Table <ref type="table" target="#tab_2">3</ref> for an overview of the hypotheses, models, and distributions associated with H 0 and H 1 of the œá 2 difference test.</p><formula xml:id="formula_1">Œîœá 2 = œá A 2 -œá B 2 , (4) Œîdf = df A -df B .</formula><p>The difference in model fit thus can be tested by comparing Œîœá 2 to a œá 2 distribution with Œîdf, which is called the œá 2 difference test. If Œîœá 2 is significant, the H 0 of equal fit for both models is rejected, so the less restrictive Model B should be retained. If Œîœá 2 is not significant, the fit of the restricted model (Model A) is not significantly worse than the fit of the unrestricted model (Model B), so the H 0 of equal fit cannot be rejected. In this case, the more restricted model (Model A) may be preferred based on the parsimony principle.</p><p>Note that because all overidentified models (so all models with df &gt; 0) are nested in the saturated model (the model with df = 0), the overall (œá 2 ) test is actually a special case of the Œîœá 2 test. That is, when Model B is the saturated model, œá B 2 and df B are zero, so that Œîœá 2 and Œîdf are the same as the overall œá 2 and df for Model A.</p><p>Power calculations for the œá 2 difference test are straightforward once the noncentrality parameter ŒîŒª is obtained. Obtaining ŒîŒª involves generating population data from the less restricted Model B. When the more restricted Model A is fitted to these data, the model will not fit perfectly and will yield a nonzero discrepancy value F 0_A . Fitting Model B to the population data will lead to a perfect fit, so F 0_B = 0 and Œª B = 0. Therefore, the noncentrality parameter for the œá 2 difference test equals the noncentrality parameter from Model A: ŒîŒª = Œª A -0 = Œª A (MacCallum, <ref type="bibr" target="#b15">Browne &amp; Cai, 2006)</ref>. In practice, we do not need to fit Model B to the data to verify that it will fit perfectly. Therefore, power calculations for the œá 2 difference test involve the same three steps as before, with the H 1 model (used to generate population data) being the Model B with the parameter(s) to be tested, and the H 0 model (model to be fitted to the population data) being the more restricted Model A.</p><p>Example 2: Calculating the power of the Œîœá 2 test Suppose that a researcher wants to know the statistical power of the Œîœá 2 test to detect a direct effect of Y1 on Y5 in the model from Fig. <ref type="figure" target="#fig_2">5</ref>. The two nested models that would be compared with a Œîœá 2 test in this case are models with and without estimating the direct effect.</p><p>Step 1 -The first step is to calculate the model-implied covariance matrix from the model with the direct effect, i.e. the model under H 1 . Similar to the earlier examples, one has to choose population values for each parameter in the model. In this example we chose medium-sized standardized values for the direct effects that are also included in the model under H 0 . We will calculate the power to detect a small standardized effect of .10 of Y1 on Y5. The (residual) variances are chosen in such a way that the total variances of all variables are 1, so that the specified effects are equal to the standardized effects.</p><p>Step 1 consists of calculating the model-implied covariance matrix based on this model. We entered the  value, which equals the noncentrality parameter.</p><p>In this example, the app fits the H 0 model with N = 200, which results in a noncentrality parameter of Œª = 4.007. The noncentrality parameter is the misfit that arises because the direct effect of Y1 on Y5 is .10 in the population, but it is not included in model H 0 .</p><p>Step 3 -The power of the Œîœá 2 test is calculated by inserting the values of the noncentrality parameter (4.007), the degrees of freedom of the test (1; the difference in the number of parameters between model H 0 and model H 1 ) and the sample size (200) in the second tab of the app. The result then shows that under the specified conditions, the power to detect the effect of Y1 on Y5 equals 52%, which is quite low. With the button at the lower left of this page in the app, one can calculate how large the sample should be to reach different power levels. In this example, one would need a sample size of 391 to obtain 80% power for the Œîœá 2 test.</p><p>By calculating the power of the Œî œá 2 test, we anticipated a situation in which one has an a priori hypothesis about this specific effect, and therefore would test the significance of this specific effect with the Œî œá 2 test with df = 1. Note that the same noncentrality parameter can be used to calculate the power to reject the overall œá 2 test for exact fit of model H 0 , because the overall œá 2 test is actually a Œîœá 2 test against the saturated model. In this example the H 0 model is correctly specified except for one direct effect, because the other parameters that are assumed to be zero in H 0 are indeed zero in the population. Still, the overall œá 2 test would have df = 5, because it is a test relating to all parameters that are not included in the model, regardless of how many of those parameters are nonzero in the population. In this example, the overall œá 2 test with df = 5 would have 29.2% power to reject exact fit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RMSEA-based power</head><p>In addition to the œá 2 statistic, researchers often use the RMSEA to evaluate overall model fit. The RMSEA assumes that the specified model will only be an approximation to reality, and thus some specification error should be allowed. An advantage of using RMSEA-based power calculations is that instead of choosing specific values for all parameters in the H 1 model, one only needs to choose the RMSEA values related to H 0 and H 1 . Before introducing power calculations with the RMSEA, we briefly explain how the RMSEA is used in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical background: RMSEA-based power</head><p>The RMSEA and tests of (not-)close fit The rationale behind the RMSEA measure of fit is that the H 0 of exact fit (i.e., Œ£ population = Œ£ model ) is invariably false in practical situations. 5 To limit the number of figures, we do not provide screenshots of the app for all examples in the article itself, but screenshots for Examples 2-4 can be found in Appendix C. The appendix also contains an additional example of a power calculation for a latent growth model.</p><p>Step 2 -Next, the model under H 0 , which is the model without the direct effect, is fitted to the covariance matrix from Step 1. In the app, the H 0 model can be specified in the textbox at the lower left side using lavaan syntax 5 . The H 0 model is the model that does not contain the parameter(s) of interest. So, in our example, the effect of Y1 on Y5 is fixed at zero. Fitting this model to the population data with a certain sample size provides a œá 2 Therefore, the hypothesis of exact fit is replaced by the hypothesis of approximate fit:</p><p>where it is assumed that the specified model will only be an approximation to reality, and thus some specification error should be allowed such that Œ£ model will never be exactly equal to Œ£ population . The RMSEA is a measure of approximate fit, and is computed based on the sample size, the noncentrality parameter (œá 2df), and the df of the model. In the formula for the RMSEA, the noncentrality parameter is divided by df √ó n, which makes it less sensitive to changes in sample size, and produces a measure of misspecification per df. It therefore also takes model parsimony into account. The point estimate of the RMSEA is calculated as follows:</p><p>Note that if œá 2 &lt; df, then the RMSEA is set to zero. An RMSEA of zero indicates that the model fits at least as well as would be expected if the H 0 of exact fit were true. However, in evaluating the value of the RMSEA, we accept some error of approximation. <ref type="bibr" target="#b3">Browne and Cudeck (1992)</ref> suggested that an RMSEA &lt; .05 indicates "close fit," an RMSEA between .05 and .08 is thought to indicate a "reasonable error of approximation," and models with an RMSEA above .10 have poor fit. MacCallum, <ref type="bibr" target="#b16">Browne, and Sugawara (1996)</ref> suggested that an RMSEA between .08 and .10 indicates mediocre fit.</p><p>A confidence interval (CI) can be computed for RMSEA. Ideally, the lower value of the 90% CI includes or is very near zero and the upper value is not very large, i.e., less than .08. <ref type="bibr" target="#b3">Browne and Cudeck (1992)</ref> proposed the "test of close fit" where it is tested whether RMSEA is significantly greater than .05 (i.e., the H 0 is that if we fit our model to the population covariance matrix, RMSEA ‚â§ .05). We conduct the test by constructing a CI, using a confidence level that is 2 √ó Œ± (so that we can conduct a one-sided test of our directional hypothesis using the CI). When the lower confidence limit is larger than .05, we can reject the H 0 of close fit (because the entire CI is above the .05 threshold). <ref type="bibr" target="#b16">MacCallum et al. (1996)</ref> extended this idea by "flipping" H 0 (i.e., that the population RMSEA ‚â• .05), which they called a "test of not-close fit." When the upper confidence limit of the RMSEA is smaller than .05, we can reject the H 0 of not-close fit (because the entire CI is below the .05 threshold). The reason that testing not-close fit may be more intuitive is explained by MacCallum et al.:</p><p>The test of not-close fit provides for more appropriate roles for the null and alternative hypotheses in the context of model evaluation. When specifying and evaluating a  <ref type="bibr">et al., 1996, p. 136)</ref> Figure <ref type="figure" target="#fig_4">6</ref> shows an overview of the RMSEA values and associated interpretations, with some example confidence intervals. The first confidence interval lies completely outside the gray area associated with "close fit," and therefore the hypothesis of close fit will be rejected. The hypothesis of not-close fit will not be rejected, because the confidence interval contains values associated with not-close fit. The second confidence interval falls completely in the area associated with "close fit." Therefore, the hypothesis of not-close fit would be rejected, and the hypothesis of close fit would not be rejected. The last confidence interval contains values associated with close fit as well as values associated with not-close fit, so neither hypothesis would be rejected.</p><formula xml:id="formula_2">Œ£ population ‚âà Œ£ model , (5) RMSEA = ‚àö max ùúí 2 -df , 0 df (n) = ‚àö ‚àö ‚àö ‚àö max ÃÇŒª, 0 df (n) model,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Power analysis for the RMSEA test of close fit</head><p>MacCallum, <ref type="bibr" target="#b16">Browne, and Sugawara (1996)</ref> describe a method to calculate power for SEM, based on the RMSEA. The RMSEA index follows a noncentral œá 2 distribution. The advantage of power calculations using the RMSEA is that the noncentrality parameter (Œª) of the œá 2 distribution can be derived from the RMSEA by rewriting Eq. 5:</p><p>Therefore, the noncentral œá 2 distributions for H 0 and H 1 can be easily derived when we use the RMSEA values associated with "close approximate fit" or "reasonable approximate fit," making power calculations based on the RMSEA relatively simple. MacCallum et al. suggested calculating the power to reject close fit (H 0 : RMSEA ‚â§ .05) when in the population there is not close fit (H 1 : RMSEA = .08). Figure <ref type="figure">7</ref> shows the noncentral œá 2 distributions related to these two RMSEA values with df = 10 and N = 200. The vertical dotted line shows the point for which larger observed RMSEA values are associated with œá 2 values that would lead to rejection of the hypothesis of close fit. The shaded area then shows the area under H 1 , which represents the statistical power. We can use the third tab in the app to calculate the power to reject close fit if in the population there is not-close fit (see the screenshots in Appendix 3). In the left panel we insert the RMSEA value associated with H 0 (RMSEA = 0.05) and the RMSEA value associated with H 1 (RMSEA = 0.08). We also fill in the degrees of freedom of the model ( <ref type="formula">15</ref>), the intended sample size (N = 200), and the Œ± level (0.05).</p><p>Then, to the right side of the panel we see the two distributions related to H 0 and H 1 , and the associated power. In this example, the power to reject close fit when in reality there is not-close fit equals 0.378. A power of .378 is generally unacceptable, so based on this result researchers would try to increase the sample to obtain more power. The app indicates that for 0.80 power, one would need a sample size of 551.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Power analysis for the RMSEA test of not-close fit</head><p>In SEM analysis, we hope that the entire confidence interval is below the RMSEA = .05 threshold. It would therefore make more sense to calculate the power to reject a hypothesis of not-close fit in favor of a hypothesis of close fit. When calculating the power of a test of not-close fit, the H 0 will be that the model does not fit closely (RMSEA ‚â• 0.05), and the H 1 model will be closely fit (for which MacCallum et al. suggest using an RMSEA value of .01). Figure <ref type="figure">9</ref> shows the noncentral œá 2 distributions related to these two RMSEA values with df = 10 and N = 200. Note that the distribution associated with H 0 is identical to Fig. <ref type="figure">7</ref>, but for this test the distribution associated with H 1 , and the area associated with the statistical power, lies on the left side of the H 0 distribution. The interpretation of the power of 0.124 is as follows: if in the population the RMSEA is .01, then the probability of correctly rejecting an H 0 of RMSEA ‚â• .05 equals .124.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 4: Power to reject not-close fit of a full SEM model</head><p>Suppose that one wants to evaluate the power to reject notclose fit of the full SEM model (without means) in Fig. <ref type="figure" target="#fig_6">10</ref>. With 15 observed variables, there are 15 √ó 16/2 = 120 unique observed statistics. The model contains 25 freely estimated parameters, being 15 residual variances of indicators, 10 factor loadings (one factor loading per factor will be fixed for scaling), five (residual) factor variances, one factor covariance, and four direct effects. Therefore, this model has 120 -35 = 85 df.</p><p>For the test of not-close fit, we assume a population RMSEA of .01, and we test the H 0 of RMSEA ‚â• .05 with an intended sample size of 200 and an alpha level of .05. The resulting power to reject not-close fit equals 0.816. The app indicates that for a power of 0.80, we would need a sample size of 195.</p><p>œá 2 -based power with H 1 based on the RMSEA As explained before, the œá 2 test of exact fit assumes that the population value of the RMSEA is zero. This means that one can also calculate the power to reject exact fit using the tab for RMSEA-based power, by setting the RMSEA for H 0 to zero. The RMSEA value for H 1 then defines the noncentrality parameter. An advantage of this procedure is that the power of the overall œá 2 test can be evaluated without specifying population The power to reject an H 0 RMSEA of zero when the H 1 RMSEA is .08 with df = 7 and N = 200 equals 0.555. For an RMSEA of .08, the noncentrality parameter Œª equals 8.9152, obtained by plugging in 0.08 in Eq. 6. Using this Œª in the second tab of the app (again using N = 200 and df = 7) shows a power of 0.555 to reject the œá 2 test of overall exact fit. So, for the null hypothesis of exact fit (i.e., RMSEA equals zero), power calculations using the œá 2 procedure or the RMSEA procedure actually coincide. The difference between the two procedures lies in the way the alternative hypothesis is defined: using an RMSEA value or by defining specific population values for the H 1 model.</p><p>The relation can also be shown the other way around. In Example 1, using a model with df = 7 and N = 200, the power to reject overall exact fit, obtained by defining the H 1 model explicitly, was .982. The noncentrality parameter (Œª) for this power analysis was 26.638. We can calculate the RMSEA value using this noncentrality parameter using the formula for the RMSEA provided in Eq. 4. The RMSEA value based on this noncentrality parameter is sqrt(26.638/(7 √ó 199)) = 0.138. Using H 0 = 0 and H 1 = 0.138 for the RMSEA-based power calculation again leads to statistical power of .982 to reject exact fit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this article we presented a tutorial and app to facilitate power analyses for researchers who plan to use SEM to analyze their data. When designing the app, we aimed at finding a good balance between providing enough functionality to be able to do power analyses, and keeping the app user-friendly and intuitive in use. There are situations in which researchers should use software other than power4SEM for power analyses. These situations are explained below. After that, we discuss some practical issues regarding power analysis for SEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features that are not implemented in power4SEM</head><p>Power4SEM only allows the evaluation of single group models. For power analyses with multi-group models, we advise researchers to use the SSpower() function in the package semTools directly. In this case the function needs a list of population means, a list of population covariances, and vector with sample sizes for each group, and fits the provided H 0 model to the provided moments for each group. The help page of the function (accessible using the command ?SSpower in R) shows an example of a multi-group SEM power analysis.</p><p>The Satorra-Saris method is not suitable for power calculations regarding specific indirect effects. If one wants to obtain the power to detect a nonzero indirect effect in SEM, one should use a Monte Carlo analysis <ref type="bibr" target="#b28">(Zhang, 2014)</ref>. Schoemann, Boulton, and Short (2017) created a Shiny app to facilitate power analyses for some specific mediation models. Alternatively, one can use WebPower <ref type="bibr" target="#b29">(Zhang &amp; Yuan, 2018)</ref> to conduct power analysis for any mediation model.</p><p>Our app does not facilitate power analyses for multilevel SEM. We are not aware of software that is specifically designed to do power calculations for multilevel SEM; therefore, to our knowledge, the only option for determining the necessary sample size in such a scenario would be to conduct a Monte Carlo simulation study. The article by <ref type="bibr" target="#b19">Muth√©n and Muth√©n (2002)</ref> may be useful for setting up such a study.</p><p>The R functions behind the app use normal theory maximum likelihood estimation, and therefore assume multivariate normality. If one expects to fit SEMs on non-normal data, one should also conduct a Monte Carlo analysis. WebPower <ref type="bibr" target="#b29">(Zhang &amp; Yuan, 2018)</ref> allows one to draw a path diagram for the H 0 model and the H 1 model, define the population levels of skewness and kurtosis, and run the Monte Carlo analysis to determine the power or necessary sample size.</p><p>The implemented method fits the null-hypothesized model to a covariance matrix to obtain the noncentrality parameter of the œá 2 distribution pertaining to H 1 . Fitting a model to a covariance matrix assumes a covariance matrix that is calculated from complete data. If researchers expect missing data, they should fit the model on the raw data. Therefore, in order to calculate the power for missing data scenarios, population raw data corresponding to H 1 are needed. Power calculations for the LRT with data missing completely at random (MCAR) are described by <ref type="bibr" target="#b8">Dolan, van der Sluis, and Grasman (2005)</ref>. Such population data can be obtained using transformation methods that are described by <ref type="bibr" target="#b0">Bollen and Stine (1993)</ref>. The difficulty with missing data is that population data need to be generated separately for each group of cases with a different missing data pattern. If there are five variables, there may be 2 5 = 32 patterns of missingness, each associated with a specific portion of the sample. The sample size of a specific group may be smaller than the number of variables, possibly leading to nonpositive definite covariance matrices in such groups. Moreover, this method is only applicable for data MCAR, which may not be realistic. Therefore, we chose not to implement this method in our app. Researchers who wish to evaluate power for specific missing data patterns may conduct a Monte Carlo simulation instead. Alternatively, a future analytical method might be developed based on similar methods used by <ref type="bibr" target="#b21">Rhemtulla, Savalei, and Little (2016)</ref>, which (like the Satorra-Saris method) would be less computationally demanding than a Monte Carlo simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Practical recommendations for power analysis using power4SEM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specifying sensible population values</head><p>Specifying the values for the population parameters in the H 1 model for power calculations of œá 2 tests is probably the hardest part of conducting such a power analysis. A researcher needs to have a feeling for what parameter values are typical for the model and variables under consideration, as well as a clear idea about the number and size of the parameters that should quantify the model misspecification. The general recommendation is that researchers should use all available relevant information to make informed estimates of the parameter values <ref type="bibr" target="#b15">(MacCallum et al., 2006)</ref>. The available relevant information can for example come from earlier research involving the same (or similar) variables and models, from the analysis of pilot data, or from strong theoretical hypotheses. This implies that œá 2 -based power analysis is most practical for research domains that include a large body of prior research on the topic. In situations where it is impossible to come up with sensible population values for the H 1 model, one could quantify the misspecification using an RMSEA value, as shown in the last example of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Determining which power analysis is needed</head><p>Naturally, we recommend conducting a power analysis on the analysis that one will use to answer the research question. To evaluate the exact fit of a hypothesized model, a power analysis concerning the overall œá 2 test is appropriate. Similarly, to test a hypothesis about the difference between two models, a power analysis for the œá 2 difference test will be informative. œá 2 -based power results based on explicit choices about parameter values associated with H 1 are attractive because interpretation of the resulting statistical power is quite intuitive. For example, the power estimate of .70 in Example 1 is directly related to the detection of two direct effects and a covariance that were specified as additional parameters in the H 1 model. In Example 2, we calculated the power to detect a standardized direct effect of .10 in a specific path model. When H 1 is not formulated explicitly, but the misfit is based on an RMSEA value, conducting power analyses is easier, but interpretation of the result is less intuitive because the specified misfit is less targeted. For example, obtaining 80% power to detect an overall misspecification as defined by an RMSEA of .08 is less intuitive than obtaining 80% power to detect a specific direct effect of .10.</p><p>A drawback of the œá 2 test of exact fit is that the H 0 of exact fit will invariably be false in practice, because no model is a perfect representation of reality <ref type="bibr" target="#b2">(Box, 1976)</ref>. With samples large enough to have large power, models that are only wrong to an irrelevant degree will be rejected by the œá 2 test. Therefore, many researchers focus on approximate fit indices.</p><p>We recommend that if a researcher intends to use the RMSEA to judge model fit, then RMSEA-based power calculation is needed. Given the relative simplicity of the procedure, we recommend power analyses for both the test for close fit and the test for not-close fit. When researchers intend to use different RMSEA values for the evaluation of model fit from those used in this tutorial, then the RMSEA values associated with H 0 and H 1 can be changed accordingly. For example, when a researcher is satisfied with the model when the RMSEA value is below .08 instead of .05, they could do a power analysis where the RMSEA for H 0 represents bad fit (say, RMSEA = .12), and RMSEA for H 1 equals .08. This leads to a power estimate of the rejection of bad fit when in reality there is mediocre fit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Conducting a power analysis for SEM is not easy. With this tutorial and with the Shiny app power4SEM, we try to facilitate the statistical part of conducting a power analysis. However, probably the most difficult aspect of doing a power analysis is that it requires careful thinking about the hypotheses to test, the parameter values one expects, and the questions that need to be answered. Although this may seem to be a drawback of power analysis, it is of course a good thing in itself if researchers think about their analysis plan carefully before collecting data. Moreover, a carefully conducted power analysis will prevent wasting expensive resources on under-or overpowered studies.</p><p>Example 4: Power to reject not-close fit of a full SEM model Extra example: Calculating the power of the œá 2 test for overall fit for a latent growth model Suppose one is interested in calculating the power of the overall œá 2 test for a linear growth curve model on four measurements. This model has five degrees of freedom, so with an Œ±-level of 0.05, exact fit of the H 0 model would be rejected if the observed œá 2 were larger than 11.071. The H 1 model is defined as a specific just-identified model, where one again has to choose values for all population parameters (but one can still assume population values of zero for parameters). In this example we specify small nonzero residual covariances between adjacent time points and zero covariance between nonadjacent time points. In addition, we specify nonzero intercepts at year 3 and year 4, leading to nonlinear growth instead of linear growth. The lavaan syntax for the H1 model is then:</p><p>Step 1 -The figure below shows the part of the Shiny app where we entered the lavaan syntax for the H 1 model in the upper left textbox. The app then provides a graphical display of the model next to the syntax. In the graphical display, all fixed parameters are represented in black, and all free parameters are in red. In the population model under H 1 , all parameters should be specified as fixed values, so all parameters in the graph should be black.</p><p>Step 2 -The textbox at the lower left part contains the syntax for the H 0 model, which contains free parameters. In this case, the estimated parameters are the growth factor means, variances, and covariance, and the residual variances of the indicators. The graphical display at the right side shows the freely estimated parameters in red. Note that the residual covariances that were specified to be present in the population (under H 1 ) are not estimated in the model under H 0 .</p><p>In this example the noncentrality parameter based on N = 200 is 11.52. Given this noncentrality parameter, we know that under H 1 , the test statistic follows a noncentral œá 2 distribution, with df = 5 and Œª = 11.52.</p><p>Step 3 -The power is found by determining the area under the H 1 distribution that lies to the right of the critical value under the H 0 distribution. For a central œá 2 distribution with df = 5 and Œ± = .05, the critical value is 11.07. In the second tab of the app, one can provide all necessary information on the left side, and then one will see the resulting power and the associated œá 2 distributions on the right side.</p><p>In this example, the power to reject exact fit is .749. The app also lets researchers calculate the minimum sample size needed to obtain a desired power level. In this example, we would need N = 223 obtain 0.80 power.</p><p>Open practices statement The R code needed to run the app locally is available from <ref type="url" target="https://osf">https:// osf</ref>. io/ 39gx8/ Funding Suzanne Jak was supported by the Dutch Research Council under Grant NWO-VENI-451-16-001. Terrence Jorgensen was supported by the Dutch Research Council under Grant 016. <ref type="bibr">Veni.195.457</ref>.</p><p>Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ref type="url" target="http://creat">http:// creat</ref> iveco mmons. org/ licen ses/ by/4. 0/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Path model for the example power calculations, with population values for H 0 based on empirical results and three extra parameters for H 1 . The variables and population values stem from Ma et al. (2020). RoleConf = role conflict, RoleAmbi = role ambiguity, CoSup = coworker</figDesc><graphic coords="5,141.76,57.76,311.76,140.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Screenshot of the calculation of the statistical power of the œá2 test in power4SEM</figDesc><graphic coords="7,53.32,57.76,488.64,220.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5 Path model with population values for power calculations in Example 2</figDesc><graphic coords="8,141.76,535.61,311.76,168.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>2 √ó df (n) Example 3: Power to reject close fit of a longitudinal factor model Suppose one wishes to evaluate the power to reject close fit of the longitudinal factor model without means from Fig. 8. This model consists of one factor with four indicators, measured at two time points. With eight observed variables, the number of observed unique variances and covariances is (8 √ó 9)/2 = 36. In a model without any constrained parameters over time, there will be 21 freely estimated parameters (when scaling by fixing the factor variances: eight residual variances, four residual covariances, eight factor loadings, and one factor covariance). Thus, for this model, df = 36 -21 = 15.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6</head><label>6</label><figDesc>Fig. 6 RMSEA values and associated interpretations, with some example confidence intervals and outcome of a test of close or not-close fit</figDesc><graphic coords="11,85.06,57.76,425.16,177.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 Fig. 9</head><label>89</label><figDesc>Fig. 8 The longitudinal factor model from Example 3</figDesc><graphic coords="12,141.76,57.76,311.76,175.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10</head><label>10</label><figDesc>Fig. 10 The full SEM model from Example 4</figDesc><graphic coords="13,141.76,57.76,311.76,185.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="6,51.46,330.89,492.36,370.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,51.05,201.97,238.08,313.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="15,51.17,321.62,237.96,325.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="15,306.02,131.16,237.96,265.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="16,51.02,184.41,492.72,331.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="17,51.28,80.57,492.72,256.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="17,51.28,424.44,492.72,245.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="18,51.46,120.33,492.36,249.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="19,51.04,281.47,238.08,326.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="20,51.28,57.76,492.72,347.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="21,51.28,57.76,492.72,257.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Overview of the relations between truth/falseness of the null hypothesis and outcomes of the test</figDesc><table><row><cell></cell><cell>True hypothesis</cell><cell></cell></row><row><cell></cell><cell>H 0</cell><cell>H 1</cell></row><row><cell>Outcome of statistical test</cell><cell>Type I error (Œ±) H 0 not rejected Correct inference H 0 rejected (1 -Œ±)</cell><cell>Power (1 -Œ≤) Type II error (Œ≤)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Overview of the hypotheses, models, and distributions associated with H 0 and H 1 of the overall œá 2 test</figDesc><table><row><cell></cell><cell>H 0</cell><cell>H 1</cell></row><row><cell>Hypothesis</cell><cell cols="2">Œ£ population = Œ£ model Œ£ population ‚â† Œ£ model</cell></row><row><cell>Model leading to Œ£ population</cell><cell>Model H 0</cell><cell>Model H 1</cell></row><row><cell>Value of population discrep-ancy F 0</cell><cell>F 0 = 0</cell><cell>F 0 &gt; 0</cell></row><row><cell>Distribution of test statistic</cell><cell>Central œá 2</cell><cell>Noncentral œá 2</cell></row><row><cell>Mean of test statistic</cell><cell>df</cell><cell>df + Œª</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Overview of the hypotheses, models, and distributions associated with H 0 and H 1 of the œá 2 difference test between two nested models Model A (most restrictive) and Model B (least restrictive)</figDesc><table><row><cell></cell><cell>H 0</cell><cell>H 1</cell></row><row><cell>Hypothesis</cell><cell>Œî F 0 = 0</cell><cell>Œî F 0 &gt; 0</cell></row><row><cell cols="2">Fit of Model A and Model B Model A = Model</cell><cell>Model A ‚â† Model</cell></row><row><cell></cell><cell>B</cell><cell>B</cell></row><row><cell>Value of noncentrality</cell><cell>ŒîŒª = 0</cell><cell>ŒîŒª &gt; 0</cell></row><row><cell>parameter</cell><cell></cell><cell></cell></row><row><cell>Distribution of test statistic</cell><cell>Central œá 2</cell><cell>Noncentral œá 2</cell></row><row><cell>Mean of test statistic</cell><cell>Œîdf</cell><cell>Œîdf + ŒîŒª</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>our research hypothesis would normally be that the model provides a good approximation to the realworld phenomena under study. As is often pointed out in introductory treatments of hypothesis testing (e.g., Champion 1981), the research hypothesis is most appropriately represented by the alternative hypothesis, so that rejection of the null hypothesis implies support for the research hypothesis. If the research hypothesis corresponds to the null hypothesis, then it becomes very difficult to support the research hypothesis, as is the case in usual tests of model fit in CSM[Covariance Structure Modeling]. (MacCallum</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>The R code needed to run the app locally is available from https:// osf. io/ 39gx8/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>For more information on how to specify models in lavaan see http:// lavaan. ugent. be/ tutor ial/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>We used the conventional values proposed by<ref type="bibr" target="#b6">Cohen (1988</ref><ref type="bibr" target="#b7">Cohen ( , 1992) )</ref> to represent small, medium, and large effect sizes throughout this tutorial. However, as Cohen also cautioned, values that should qualify as small, medium, or large effects depend on the research domain. For example, appropriate values are found to be smaller than Cohen's values in organizational psychology<ref type="bibr" target="#b1">(Bosco et al. 2015)</ref> and social psychology<ref type="bibr" target="#b12">(Lovakov &amp; Agadullina, 2017)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>In analyses without mean structure, it is also possible to use Wishart likelihood, in which case n = N -G, where G is the number of groups. Wishart likelihood is the default in older SEM software (LISREL and EQS), but not in lavaan, which our Shiny app uses.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bootstrapping goodness of fit measures in structural equation models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Testing structural equation models</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Long</surname></persName>
		</editor>
		<meeting><address><addrLine>Newbury Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="111" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Correlational effect size benchmarks</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Aguinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Pierce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="431" to="449" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Science and statistics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1976.10480949</idno>
		<ptr target="https://doi.org/10.1080/01621459" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">356</biblScope>
			<biblScope unit="page">949</biblScope>
			<date type="published" when="1976">1976. 1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Alternative ways of assessing model fit</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cudeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="230" to="258" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">pwr: Basic functions for power analysis [Computer software] (version 1.2-2)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Champely</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=pwr" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Basic statistics for social research</title>
		<author>
			<persName><forename type="first">D</forename><surname>Champion</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Macmillan</publisher>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Statistical power analysis for the behavioral sciences (2nd)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Erlbaum</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical power analysis. Current Directions in Psychological</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-8721.ep10768783</idno>
		<ptr target="https://doi.org/10.1111/1467-8721.ep" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">68783</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A note on normal theory power calculation in SEM with data missing completely at random</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Sluis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grasman</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15328007sem1202_4</idno>
		<ptr target="https://doi.org/10.1207/s" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="8007" to="1202" />
			<date type="published" when="1532">2005. 1532</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">semPlot: Path diagrams and visual analysis of various SEM packages&apos; output [Computer software] (version 1.1.1)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Epskamp</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=semPlot" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">GPOWER: A general power analysis program</title>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03203630</idno>
		<ptr target="https://doi.org/10.3758/BF032" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">semTools: Useful tools for structural equation modeling</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pornprasertmanit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Schoemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=semTools" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Computer software] (version 0.5-3</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Empirically derived guidelines for interpreting effect size in social psychology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lovakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Agadullina</surname></persName>
		</author>
		<ptr target="https://psyarxiv.com/2epc4/" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Role stress, social support and occupational burnout among physicians in China: a path analysis approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Health</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="157" to="163" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Behav Res</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1385" to="1406" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Testing differences between nested covariance structure models: Power analysis and null hypotheses</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="35" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Power analysis and determination of sample size for covariance structure modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Sugawara</surname></persName>
		</author>
		<idno type="DOI">10.1037/1082-989X.1.2.130</idno>
		<ptr target="https://doi.org/10.1037/1082-989X.1.2.130" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="130" to="149" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A framework for power analysis using a structural equation modelling procedure</title>
		<author>
			<persName><forename type="first">J</forename><surname>Miles</surname></persName>
		</author>
		<idno type="DOI">10.1186/1471-2288-3-27</idno>
		<ptr target="https://doi.org/10.1186/1471-2288-3-27" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Research Methodology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">semPower: Power analyses for SEM. R package version 1</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moshagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">packa ge= semPo wer Moshagen</title>
		<imprint>
			<date type="published" when="2016">2018. 2016</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="54" to="60" />
		</imprint>
	</monogr>
	<note>A new strategy for testing structural equation models</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How to use a Monte Carlo study to decide on sample size and determine power</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muth√©n</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muth√©n</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15328007SEM0904_8</idno>
		<idno>1207/ S1532 8007S EM0904_8</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="599" to="620" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing [Computer software] (version 3.6.1). R Foundation for Statistical Computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the asymptotic relative efficiency of planned missingness designs</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rhemtulla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Savalei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Little</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-014-9422-0</idno>
		<idno>11336-014-9422-0</idno>
		<ptr target="https://doi.org/10.1007/s" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="89" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">lavaan: An R package for structural equation modeling and more</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v048.i02</idno>
		<ptr target="https://doi.org/10.18637/jss.v048.i02" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Power evaluations in structural equation models</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Saris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Testing structural equation models</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Long</surname></persName>
		</editor>
		<meeting><address><addrLine>Newbury Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="181" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Power of the likelihood ratio test in covariance structure analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Saris</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294150</idno>
		<ptr target="https://doi.org/10.1007/BF022" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">94150</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Determining power and sample size for simple and complex mediation models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Schoemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Boulton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Short</surname></persName>
		</author>
		<idno type="DOI">10.1177/1948550617715068</idno>
		<ptr target="https://doi.org/10.1177/" />
	</analytic>
	<monogr>
		<title level="j">Social Psychological and Personality Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="379" to="386" />
			<date type="published" when="2017">2017. 19485 50617 715068</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the multivariate asymptotic distribution of sequential chi-square statistics</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Steiger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="263" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Power analysis for parameter estimation in structural equation modeling: A discussion and tutorial</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rhemtulla</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/pj67b</idno>
		<ptr target="https://doi.org/10.31234/osf.io/pj67b" />
	</analytic>
	<monogr>
		<title level="m">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Monte Carlo based statistical power analysis for mediation models: Methods and software</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1184" to="1198" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Practical Statistical Power Analysis Using</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-H</forename><surname>Yuan</surname></persName>
		</author>
		<editor>Webpower and R</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>ISDSA Press</publisher>
			<pubPlace>Granger, IN</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
