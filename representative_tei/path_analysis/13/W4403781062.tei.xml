<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CAMLOPA: A Hidden Wireless Camera Localization Framework via Signal Propagation Path Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-09-23">23 Sep 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jie</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zehua</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinyang</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Hefei University of Technology § Guizhou Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Meng</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Hefei University of Technology § Guizhou Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huan</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Peng</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Hefei University of Technology § Guizhou Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zijian</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Beijing Institute of Technology ∥ CFAR</orgName>
								<orgName type="institution" key="instit2">IHPC, A*STAR</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qing</forename><surname>Guo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tianwei</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Science and Technology of China</orgName>
								<orgName type="institution" key="instit2">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CAMLOPA: A Hidden Wireless Camera Localization Framework via Signal Propagation Path Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-09-23">23 Sep 2024</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2409.15169v1[cs.CR]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T21:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hidden wireless cameras pose significant privacy threats, necessitating effective detection and localization methods. However, existing solutions often require spacious activity areas, expensive specialized devices, or pre-collected training data, limiting their practical deployment. To address these limitations, we introduce CAMLOPA, a training-free wireless camera detection and localization framework that operates with minimal activity space constraints using low-cost commercial-off-the-shelf (COTS) devices. CAMLOPA can achieve detection and localization in just 45 seconds of user activities with a Raspberry Pi board. During this short period, it analyzes the causal relationship between the wireless traffic and user movement to detect the presence of a snooping camera. Upon detection, CAMLOPA employs a novel azimuth location model based on wireless signal propagation path analysis. Specifically, this model leverages the time ratio of user paths crossing the First Fresnel Zone (FFZ) to determine the azimuth angle of the camera. Then CAMLOPA refines the localization by identifying the camera's quadrant. We evaluate CAMLOPA across various devices and environments, demonstrating that it achieves 95.37% snooping camera detection accuracy and an average localization error of 17.46 o , under the significantly reduced activity space requirements. Our demo are available at <ref type="url" target="https://www.youtube.com/watch?v=GKam04FzeM4">https://www.youtube.com/watch?v=GKam04FzeM4</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In recent years, the proliferation of wireless camera devices for home and public security has grown significantly due to their convenience and flexibility in deployment. A study by Market Research Future in 2024 <ref type="bibr" target="#b0">[1]</ref> projected the global wireless video surveillance and monitoring market to grow at a compound annual growth rate of 16.8% from 2022 to 2030. However, the rapid adoption of wireless cameras has also raised substantial privacy concerns related to unauthorized video recording and dissemination <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Users increasingly find themselves being illegally recorded by hidden cameras in various locations, from hotel rooms to short-term rentals. For instance, a 2019 survey <ref type="bibr" target="#b4">[5]</ref> revealed that 58% of 2,023 Airbnb guests were concerned about the possibility of hidden cameras, with 11% reporting actual discoveries of such devices. In response to these privacy threats, various jurisdictions have proposed and enacted legislation. For example, Delaware's privacy laws now strictly prohibit the use of hidden cameras in private settings without the consent of the individuals being recorded, with violations leading to severe penalties including jail time and fines <ref type="bibr" target="#b5">[6]</ref>. These legal measures underscore the urgency of developing effective methods for detecting and localizing hidden wireless cameras.</p><p>Consequently, the problem of wireless camera detection  <ref type="bibr" target="#b6">[7]</ref> ✗ ✗ ✓ ✓ HeatDeCam <ref type="bibr" target="#b7">[8]</ref> ✗ ✓ ✗ ✓ Lumos <ref type="bibr" target="#b8">[9]</ref> ✓ ✗ ✗ ✗ SNOOPDOG <ref type="bibr" target="#b9">[10]</ref> ✓ ✗ ✓ ✗ MotionCompass <ref type="bibr" target="#b10">[11]</ref> ✓ ✓ ✓ ✗ SCamF <ref type="bibr" target="#b11">[12]</ref> ✓ ✗ ✓ ✗ LocCams <ref type="bibr" target="#b12">[13]</ref> ✓</p><formula xml:id="formula_0">✓ ✗ ✓ CAMLOPA ✓ ✓ ✓ ✓</formula><p>and localization has attracted considerable research attention <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. However, existing solutions often face significant limitations that hinder their practical deployment. Many approaches can detect wireless cameras but cannot locate them <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Those capable of localization often impose complex requirements. Specifically, methods relying on lens reflection <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref> or electromagnetic/thermal emissions <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b22">[23]</ref> are typically cumbersome, requiring user expertise and examination of every corner of the room, making them difficult to use. Moreover, electromagnetic/thermal-based methods often necessitate costly specialized equipment. To address these shortcomings, recent research has focused on analyzing the WiFi traffic and physical layer information to locate wireless cameras. These methods usually require users to move along the edges of the room <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b11">[12]</ref> or perform perturbations at different positions and orientations <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. The camera's location is determined by assessing the RSSI (Received Signal Strength Indicator) and traffic variations of target devices. These approaches typically necessitate the room to be nearly empty to allow user movement to different locations, which is not feasible in real-world scenarios. They are also time-consuming, requiring 10-30 minutes for camera localization and constant user movement or position adjustments. In a recent work <ref type="bibr" target="#b12">[13]</ref>, differences in WiFi Channel State Information (CSI) under Line-of-Sight (LOS) and None-Line-of-Sight (NLOS) conditions are utilized for the coarse localization of wireless cameras. This approach requires minimal user effort but its localization resolution is limited to 90 o , still taking a lot of time to search for devices. Additionally, it requires pre-collected training data, and the deep learning model used has poor robustness against changes in the environment and devices.</p><p>In this paper, we introduce CAMLOPA, a fast and robust wireless camera detection and localization framework using low-cost commercial-off-the-shelf (COTS) devices. As shown in Table <ref type="table" target="#tab_0">I</ref>, CAMLOPA requires less activity space and user effort compared to previous studies. Our framework is inspired by the relationship between obstructions in the propagation path of wireless signals and the resulting signal attenuation. Specifically, when a large obstacle is located within the First Fresnel Zone (FFZ) between a WiFi transmitter and receiver, the transmitted signal will experience significant attenuation due to diffraction, as defined by Huygen's principle <ref type="bibr" target="#b24">[25]</ref> and Fresnel-Kirchhoff diffraction parameters <ref type="bibr" target="#b25">[26]</ref>. As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, when a person crosses the FFZ, there is a drastic change in the wireless signal path loss, and the duration of this significant variation is related to the length of the path traversed through the FFZ. Since the FFZ forms an ellipse with the two devices as its foci, given a fixed distance between the two devices, the length of the path through the FFZ can be mapped to the angle of the walk relative to the LOS path (azimuth). CAMLOPA utilizes this relationship to achieve azimuth angle localization of the wireless cameras.</p><p>The technical crux of CAMLOPA is to address the overcomplexity and lack of robustness issues in previous approaches. However, there are two significant challenges:</p><p>1) Relationship Mapping Under Unknown User Speed: By analyzing the durations of significant wireless signal fluctuations, we can determine the time it takes for a user to traverse the FFZ. To ascertain the path length through the FFZ, we also need to know the user's speed (The issue of constant user speed is discussed in Section VII.). In real-world scenarios, considering cost and complexity, users typically do not have specialized equipment to measure walking speed or have robots to substitute for user to move. Thus, the user's speed remains unknown, and we cannot determine the path length.</p><p>Q1: How can we establish a mapping relationship between the traversal time and the azimuth angle of the hidden wireless camera without knowing the user's speed?</p><p>2) Errors Control Under Variable Distance and Body Size: In practical scenarios, the distance between the hidden wireless camera and the CAMLOPA device is also unknown, and the user's body size is variable. The user's body size significantly affects the duration of signal variations, as the signal is impacted from the moment the user enters the edge of the FFZ until he/she completely exits from it. Pre-defining these two values can introduce substantial errors in the aforementioned mapping relationship.</p><p>Q2: How can we minimize the impacts of biased parameters and keep the errors within an acceptable range? To overcome the above challenges, we propose a scheme called the orthogonal ratio. This scheme replaces the need to measure the distance of a single path through the FFZ with the time ratio of two orthogonal paths crossing the FFZ to establish a mapping relationship with the azimuth angle. Specifically, we set two orthogonal walking paths that both pass through the CAMLOPA device, which is typically easy to achieve in real-world environments. We then calculate the time taken for each path to traverse the FFZ. Since the path length is the product of the time and speed, using the time ratio of the two paths eliminates the influence of the speed. Next, we develop a mapping model between the orthogonal ratio and the angle between the first path and LOS (azimuth) by WiFi propagation path analysis. By obtaining the orthogonal ratio in real environments, the azimuth angle of the wireless camera can be derived from the model. Besides, the orthogonal ratio remarkably reduces the impact of biased parameters such as variable distances and body sizes due to the division operation.</p><p>CAMLOPA operates in three stages and requires only 45 seconds of user movement to detect and locate a hidden wireless camera. In the first stage (0-15s), the system analyzes the relationship between the data stream uploaded by the camera and user activity for snooping camera detection. The encoding method of the video stream causes an increase in data volume when there is movement within the monitored area. Therefore, CAMLOPA first prompts the user to leave the room and collects traffic data of 15 seconds. By examining the causal relationship between the user's exit and the data stream, the system identifies whether a wireless camera is monitoring the current area. In the next stage (15-35s), the user walks along two orthogonal paths that both pass through the CAMLOPA equipment. The system calculates the orthogonal ratio of these two paths and determines the azimuth of the wireless camera using the azimuth model. This model only provides an angle within the range of 0-90°(e.g., for 45°and 135°, CAMLOPA reports 45°for both cases). To address this, we further design a scheme to determine the quadrant in which the camera is located. In the final stage (35-45s), the system prompts the user to walk along a path that coincides with the first path but does not traverse the entire FFZ. By analyzing whether the user's initial position blocks the LOS, the quadrant determination scheme identifies the quadrant in which the wireless camera is located, achieving the final localization. We implement a prototype of CAMLOPA on a Raspberry Pi device, which users can connect to using SSH tools on their smartphone to receive system prompts and display the results.</p><p>In summary, we make the following key contributions: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>We first provide an overview of the state-of-the-art approaches for detecting and locating hidden cameras. Next, we introduce Channel State Information (CSI), which can be used to characterize signal attenuation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Detecting and Locating Hidden Wireless Cameras</head><p>Current wireless hidden camera detection schemes generally rely on information leaked from wireless channels or other side channels when the camera is in operation. For example, wireless communication can unintentionally leak information in certain out-of-band channels, which has recently been used to detect the presence of wireless devices, however, Sathyamoorthy et al. <ref type="bibr" target="#b26">[27]</ref> and Valeroset al. <ref type="bibr" target="#b27">[28]</ref> propose that the received power threshold needs to be carefully set to avoid false alarms or detection failures. LAPD <ref type="bibr" target="#b6">[7]</ref>, CamRadar <ref type="bibr" target="#b21">[22]</ref> and Heatdecam <ref type="bibr" target="#b7">[8]</ref> are based on thermal/electromagnetic emissions and lens reflection side channels when the camera is operating. These methods usually utilize relatively expensive specialized sensors to capture such information for detection. While they can locate devices within the LOS, they require the detection equipment to be close to the hidden camera to capture subtle changes in these side-channel signals, making them challenging for ordinary users and ineffective for detecting devices in unreachable areas. Some methods leverages WiFi packet sniffing to detect wireless cameras, as these cameras transmit data packets when in operation. Dewicam <ref type="bibr" target="#b13">[14]</ref>, Cheng et al. <ref type="bibr" target="#b16">[17]</ref>, Liu et al. <ref type="bibr" target="#b28">[29]</ref> and Miettinen et al. <ref type="bibr" target="#b29">[30]</ref> achieved detection by learning the traffic characteristics of wireless cameras, but machine learning-based approaches often suffered from robustness issues due to their reliance on large datasets. SNOOPDOG <ref type="bibr" target="#b9">[10]</ref> and ScamF <ref type="bibr" target="#b11">[12]</ref> relied on the causal relationship between wireless camera traffic and human activity, where significant movement within the monitored area led to increased encoded data. This semantic-rich relationship helped determine whether an area was under surveillance. Motioncompass <ref type="bibr" target="#b10">[11]</ref> and LocCams <ref type="bibr" target="#b12">[13]</ref> involved side-channel information collected from the internet, such as the Organizationally Unique Identifier (OUI) in the Media Access Control (MAC) address of WiFi packets, which often included information about the device's manufacturer. This information can be used to identify the type of device.</p><p>The localization of wireless hidden cameras also relies on the leakage of side-channel information, but not all sidechannel information can be used simultaneously for detection and localization. Schemes based on thermal/electromagnetic emissions <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b7">[8]</ref> and lens reflection <ref type="bibr" target="#b6">[7]</ref> side channels can detect and localize cameras by directly capturing the regions with abnormal signals. However, their limitations for localization are similar to those for detection: they are difficult to use and require proximity to the hidden camera <ref type="bibr" target="#b12">[13]</ref>. Detection schemes based on traffic analysis require additional effort to achieve localization. For example, they may rely on changes in RSSI strength or data flow as the user carrying the detection device moves around to infer the camera's location <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>. These schemes necessitate that the room be almost empty, which may not be feasible in everyday settings with furniture, as the user's movement space is limited and they might not be able to get close to the hidden wireless camera. Recently, LocCams <ref type="bibr" target="#b12">[13]</ref> has been proposed that uses CSI to determine whether the user is blocking the LOS path between the positioning equipment and the wireless camera, thus roughly estimating the hidden camera's location. However, this method has a localization resolution of only 90 degrees, and its deep learning-based approach suffers from poor robustness without the support of a large-scale dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Channel State Information (CSI)</head><p>WiFi CSI describes various effects that a WiFi signal undergoes during propagation, including multipath effects, attenuation, phase shift, and more. This process of influence can be represented as follows <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>:</p><formula xml:id="formula_1">Y = H • X + N,<label>(1)</label></formula><p>where Y and X are the received and transmitted signals, respectively. N is the additive white Gaussian noise, and H is a complex matrix representing CSI. And this complex matrix can be expressed as follows:</p><formula xml:id="formula_2">H(f ) = |H(f )|e jθ(f ) ,<label>(2)</label></formula><p>where H(f ) is the channel response at frequency f , |H(f )| is the magnitude of the CSI, representing the variation in signal strength, and θ(f ) is the phase shift of the CSI, representing the variation in signal phase. The magnitude of the CSI can be used to characterize signal attenuation. The received CSI is a superposition of signals of all the propagation paths, and its Channel Frequency Response (CFR) can be represented as <ref type="bibr" target="#b32">[33]</ref>:</p><formula xml:id="formula_3">H(f, t) = m∈Φ a m (f, t)e -j2π dm(t) λ ,<label>(3)</label></formula><p>where f and t represent center frequency and time stamp, respectively, and m is the multi-path component. a m (f, t) and d m (t) denote the complex attenuation and propagation length of the mth multi-path component, respectively. Φ denotes the set of multi-path components and λ is the signal wavelength. When there are changes in only one path, the CSI can be used to approximate the attenuation occurring on that path. Specifically, paths with no changes and those with changes can be categorized as static and dynamic paths as follows <ref type="bibr" target="#b33">[34]</ref>:</p><formula xml:id="formula_4">H(f, t) = H s (f, t) + H d (f, t) = ms∈Φs a ms (f, t)e -j2π dm s (t) λ + m d ∈Φ d a m d (f, t)e -j2π dm d (t) λ ,<label>(4)</label></formula><p>where H s (f, t) and H d (f, t) denote the static and dynamic components, respectively. Φ s represents the set of static paths, e.g., reflected off the walls and furniture and static body parts, while Φ d denotes the set of dynamic paths, e.g., reflected off the moving human. When there is only one person moving in the room, CSI can be used to characterize the signal attenuation and multipath effects caused by this person's movement.</p><p>Next, we briefly explain the Fresnel zone model, which is widely used to analyze the diffraction and reflection effects of wireless and light signals along their propagation path. This model helps in understanding how signal strength varies with distance and obstacles. The Fresnel zones can be described as a series of concentric ellipses with the wireless signal transmitter and receiver as the focal points <ref type="bibr" target="#b34">[35]</ref> (see Figure <ref type="figure" target="#fig_1">2</ref>):</p><formula xml:id="formula_5">|T xQ n | + |Q n Rx| -|T xRx| = nλ/2,<label>(5)</label></formula><p>where Q n is a point at the boundary of the nth Fresnel zone, and T x and Rx represent the transmitter and receiver, respectively. Since the phase difference of waves within the First Fresnel Zone (FFZ) is relatively small, most of the energy is concentrated in this region. In wireless communication and wave propagation, the energy within the FFZ typically accounts for about 60% to 70% of the total transmitted energy. Obstacles outside the FFZ primarily cause signal reflection <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>. The attenuation due to reflection is minimal, and the total signal energy affected by obstacles outside the FFZ is relatively small. As a result, when obstacles moves in the outside of the FFZ, the total received signal energy does not change significantly. Instead, the movement mainly causes multipath effects, leading to phase changes in the CSI. Conversely, obstacles within the FFZ mainly cause diffraction <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b34">[35]</ref>. The attenuation due to diffraction is substantial, and since a significant amount of signal energy is transmitted within the FFZ, the received signal experiences substantial attenuation, which can be clearly characterized by the magnitude of the CSI.</p><p>In practical systems, we can use open-source tools such as csitool <ref type="bibr" target="#b38">[39]</ref>, picosense <ref type="bibr" target="#b39">[40]</ref>, and nexmon csi <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref> to obtain CSI from various network cards, including Intel 5300, AX210/AX200, and bcm43455c0 (Raspberry Pi B3+/B4). The actual size of the extracted CSI matrix depends on the number of antennas and subcarriers <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>, and the obtained CSI is a 4-dimensional tensor H ∈ C N×M×K×T , and M, K, and T represent the number of receive antennas, transmit antennas, subcarriers, and packets, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. OVERVIEW</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Threat Model</head><p>Our work focuses on an attacker who places a hidden wireless camera in a room to monitor users. This aligns with current state-of-the-art methods <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b8">[9]</ref> for detecting and locating any hidden camera. This is also supported by several cases <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref> where attackers were live-streaming users in private spaces, a convenient and practical solution to gather users' private information. Therefore, we focus on the scenarios that the attacker uses COTS wireless cameras for privacy invasion. The adversary covertly deploys a camera in the room and communicates with it using encrypted wireless traffic. We focus on WiFi as the communication channel in this paper, as it is the most common method for remote monitoring with commercial and consumer devices. Below we introduce the real-world settings for both the attacker and user.</p><p>Attacker: The attacker could be the host or a previous guest intending to monitor users in the room.</p><p>• The attacker can fully control the room before the user checks in, such as changing the environment and installing the hidden wireless camera. • The attacker uses a COTS camera device to spy on users and can control the camera through an app. Similar to previous studies <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, we assume the attacker does not alter the firmware, network protocols or wireless transmission behaviors of the camera device, as these tasks generally require a high level of expertise.</p><p>• The attacker has complete control over the WiFi network to which the hidden wireless camera connect. He can configure the WiFi network's wireless channels, encryption methods, and access modes.</p><p>User: The user's requirement is to detect and locate the hidden wireless camera within the room.</p><p>• The user can access the physical space to search and move around. But in a real environment, his movement is limited and obstructed by the furniture, making it difficult to meet the activity space requirements of most previous studies <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b9">[10]</ref>. • The user does not have any knowledge of the hidden wireless camera. He is unaware of the WiFi network being used, the channel of the WiFi network, or the camera's location. However, the user has control over the CAMLOPA device, including its placement and the configuration of its network connection. • The user does not have control over the WiFi network to which the wireless camera are connected. However, he can use existing tools (e.g., tcpdump, Wireshark) to sniff WiFi 802.11 packets broadcast in the air. The user carries no additional measuring tools except for a Raspberry Pi equipped with CAMLOPA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Workflow of CAMLOPA</head><p>CAMLOPA requires the user to perform three walks (45 seconds) to detect and locate the hidden wireless camera according to the prompts of CAMLOPA. It then provides feedback with the estimated azimuth angle of the hidden wireless camera. The overall structure of CAMLOPA is shown in Figure <ref type="figure" target="#fig_2">3</ref> and it operates in two phases:</p><p>Hidden Wireless Camera Detection. CAMLOPA first scans the surrounding WiFi networks and captures packets on all active 802.11 wireless channels for analysis. If it detects a device that is continuously uploading data, it identifies this device as suspicious and forwards its MAC address and channel index to the snooping camera detection module. The snooping camera detection module will prompt the user to leave the room and sniff packets from this channel for 15 seconds. It then analyzes the upload traffic of the suspicious device according to the MAC address. If the traffic pattern matches the user's departure phase, the detection module will report that the device is monitoring the current area. Next, the module will forward the device's MAC address and channel index to the following localization phase.</p><p>Hidden Wireless Camera Localization. Upon receiving the MAC address of the snooping wireless camera and the WiFi channel of the connected Access Point (AP), CAMLOPA prompts the user to walk along two orthogonal paths (see Figure <ref type="figure" target="#fig_6">8</ref>) cross the CAMLOPA device, such as a Raspberry Pi board. Specifically, the device sniffs the WiFi packets transmitted from the target MAC on the specified channel over 10 seconds for each path, extracting CSI to calculate the orthogonal ratio and determine the azimuth angle using the proposed azimuth localization model. These paths intersect in a T-shape, with the intersection point being the location of the CAMLOPA device. After calculating the azimuth angle, CAMLOPA prompts the user to walk along a path coinciding with the first path but starting in front of the CAMLOPA device, collecting 10 seconds of CSI. Next, using the quadrant determination model, CAMLOPA calculates the quadrant in which the target device is located to obtain the final azimuth angle of the hidden wireless camera.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. WIRELESS CAMERA DETECTION</head><p>CAMLOPA detects the presence of snooping wireless cameras in the environment through wireless traffic analysis by: (i) searching for suspicious devices, and (ii) detecting snooping wireless cameras.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Searching for Suspicious Devices</head><p>In real-world environments, there are usually many wireless networks and devices connected to WiFi around the user. Analyzing all devices to detect cameras monitoring the area is highly inefficient. Therefore, CAMLOPA first identifies suspicious devices to narrow down the detection scope. Video stream packets are typically large and stable, and surveillance cameras continuously and frequently upload data. CAMLOPA starts by scanning the surrounding WiFi networks to detect all APs, even those with Hidden Service Set Identifiers (SSIDs).  According to <ref type="bibr" target="#b51">[52]</ref>, we list the Received Signal Strength Indication (RSSI) requirements for different applications. CAMLOPA excludes APs that do not meet the minimum RSSI requirements for video streaming, namely, below -67 dBm. It then sequentially scans the channels of the remaining APs, sniffing and capturing 802.11 packets for 5 seconds to determine if any devices are continuously uploading data.</p><p>For the captured 802.11 packets, CAMLOPA first classifies them by source MAC address into different end devices. Next, it filters out Management-Type and Control-Type frames, leaving only Data-Type frames for further analysis, as application layer data is encapsulated within Data-Type frames <ref type="bibr" target="#b52">[53]</ref>. The structure of an 802.11 wireless frame <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref> is shown in Figure <ref type="figure" target="#fig_3">4</ref>. It includes the plaintext header information and the encrypted data payload. The header contains unencrypted information such as addresses, while the payload is typically encrypted using WEP/WPA/WPA2. After protocol filtering, CAMLOPA aggregates all Data-Type frames corresponding to each device and calculates the average size of the payload portion. Finally, CAMLOPA determines the presence of any suspicious devices as follows:</p><formula xml:id="formula_6">S mac = true if smac &gt; T s &amp;l &gt; T l &amp;mac ̸ = m ap , false else .<label>(6)</label></formula><p>Here, S mac represents the determination of whether the device with MAC address mac is suspicious. smac , T s , l, m ap , and T l denote the average size of all packet payloads, the size threshold, the count of packets, the MAC address of APs, and the count threshold, respectively. This equation indicates that if a device sends a large number of packets within 5 seconds and the average packet length is long, it is likely uploading a video stream. After identifying suspicious devices, CAMLOPA forwards their MAC addresses and 802.11 channel index to the snooping camera detection module. This module then sequentially assesses the risk of each device to determine whether they are monitoring the current area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Detecting Snooping Cameras</head><p>Before uploading video streams, cameras typically apply encoding to compress the data and reduce the upload volume. Most video compression standards, such as H.264 <ref type="bibr" target="#b55">[56]</ref> and H.265 <ref type="bibr" target="#b56">[57]</ref>, achieve high compression rates through interframe prediction. Specifically, standard video compression algorithms use three types of frames to compress video: 1) I (Intra-coded picture) frames: these frames contain complete image information and can be decoded independently of other frames. 2) P (Predicted picture) frames: these frames encode residual information and require information from preceding I frames for decoding. 3) B (Bi-directionally predicted picture) frames: these frames can construct images using changes from preceding I or P frames, subsequent I or P frames, or interpolations between preceding and subsequent I/P frames. Among these frame types, B frames are the most compressible, followed by P frames, and finally, I frames.</p><p>Therefore, when there is any activity in the area monitored by the wireless camera, the camera traffic increases due to the higher number of P and B frames that need to be transmitted <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Conversely, if the scene transitions to a stationary one, the number of disturbed pixels decreases, reducing the camera traffic. If a person first moves and then remains still within the camera's monitored area, it will result in a unique camera traffic pattern (traffic decreasing) that corresponds to the user's motion. This causal effect can be used to detect whether a hidden wireless camera is snooping on the current area. CAMLOPA leverages this causal relationship to detect snooping cameras. Specifically, CAMLOPA prompts the user to leave the room within 15 seconds. It then calculates the data throughput of each suspicious device per second and checks for traffic patterns where the throughput is initially high and then decreases. If such a pattern is detected, the device is identified as a snooping camera, and its risk level is determined based on the ratio of the data throughput in the first half to that in the second half. A sample of the data throughputs during the user's exit from the room is shown in Figure <ref type="figure" target="#fig_4">5</ref>.</p><p>Upon detecting a snooping camera, CAMLOPA forwards the camera's MAC address and associated WiFi channel index to the wireless camera localization module. It then initiates the localization process for the detected snooping camera. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Diffraction Attenuation in Wireless Signal Propagation</head><p>Diffraction allows radio signals to propagate around the curved surface of the earth, beyond the horizon, and behind obstacles <ref type="bibr" target="#b34">[35]</ref>. This phenomenon can be explained using Huygen's principle, which states that all points on a wavefront can be considered as point sources generating secondary wavelets. These secondary wavelets are combined in the direction of propagation to form a new wavefront. Diffraction occurs due to the propagation of these secondary wavelets into shadowed regions. Empirical studies <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b57">[58]</ref>, <ref type="bibr" target="#b37">[38]</ref> suggest that when an obstacle is within the FFZ, it primarily causes the diffraction of wireless signals. Conversely, when the obstacle is outside the FFZ, it mainly causes the reflection of signals.</p><p>In Figure <ref type="figure" target="#fig_1">2</ref>, assuming the height of point Qn from the LOS path is h (see Figure <ref type="figure" target="#fig_5">6</ref>), and its projection onto the LOS path has distances d 1 and d 2 from T x and Rx, respectively, the path difference between the signal propagating through this point and the LOS path ∆d can be expressed as <ref type="bibr" target="#b34">[35]</ref>:</p><formula xml:id="formula_7">∆d ≈ h 2 2 d 1 + d 2 d 1 d 2 .<label>(7)</label></formula><p>The corresponding phase difference is:</p><formula xml:id="formula_8">ϕ = 2πd λ = πh 2 λ d 1 + d 2 d 1 d 2 . (<label>8</label></formula><formula xml:id="formula_9">)</formula><p>Equation 8 can typically be expressed using the Fresnel-Kirchoff diffraction parameter v as follows:</p><formula xml:id="formula_10">ϕ = π 2 v 2 . (<label>9</label></formula><formula xml:id="formula_11">)</formula><p>The Fresnel-Kirchoff diffraction parameter v can be represented as:</p><formula xml:id="formula_12">v = h 2(d 1 + d 2 ) λd 1 d 2 . (<label>10</label></formula><formula xml:id="formula_13">)</formula><p>The Fresnel-Kirchoff diffraction parameter originates from the combination of the Fresnel approximation and Kirchhoff's diffraction theory. This parameter is used to describe the diffraction effect that occurs when a wave encounters an obstacle or aperture. The magnitude of v is related to the significance of the diffraction effect. A smaller v indicates a smaller obstacle size or greater distance, resulting in a less significant diffraction effect. Conversely, a larger v indicates a more pronounced diffraction effect, where the wave experiences noticeable diffraction when encountering an obstacle and continues to propagate around it. The radius (The perpendicular distance from Q n to the LOS path.) of the FFZ can be expressed as <ref type="bibr" target="#b34">[35]</ref>:</p><formula xml:id="formula_14">r 1 = λd 1 d 2 d 1 + d 2 .<label>(11)</label></formula><p>Thus, the Fresnel-Kirchoff diffraction parameter can be represented as:</p><formula xml:id="formula_15">v = h 2(d 1 + d 2 ) λd 1 d 2 = h √ 2 r 1 .<label>(12)</label></formula><p>In wireless communication systems, only a portion of the signal's energy can diffract around an obstacle, allowing only part of the blocked energy to reach the receiver. Therefore, when an obstacle obstructs part of the Fresnel zone, the received energy is the vector sum of the contributions from all the unobstructed portions of the Fresnel zone. If an infinitely long object is positioned at a distance h from the LOS path, the ratio of the electric field strength E d affected by diffraction to the unobstructed electric field strength E o is given by:</p><formula xml:id="formula_16">E d E o = F (v) = 1 + j 2 ∞ v exp( -jπt 2 2 )dt,<label>(13)</label></formula><p>where F (v) is the complex Fresnel integral.</p><p>In practical scenarios, a human body can be approximated as a cylinder to analyze the signal attenuation caused by diffraction along the propagation path. As shown in Figure <ref type="figure" target="#fig_5">6</ref>, both ends of the cylinder induce diffraction effects, where h front and h back represent the distances from the front and back edges of the cylinder to the LOS path, respectively. The signal attenuation caused by diffraction at the front and back edges can be expressed as:</p><formula xml:id="formula_17">F (v f ront ) = 1 + j 2 ∞ v f ront exp( -jπt 2 2 )dt,<label>(14)</label></formula><formula xml:id="formula_18">F (v back ) = 1 + j 2 v back -∞ exp( -jπt 2 2 )dt. (<label>15</label></formula><formula xml:id="formula_19">)</formula><p>High Attenuation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Low Attenuation Low Attenuation</head><p>Fig. <ref type="figure">7</ref>. Diffraction gain variation corresponding to Figure <ref type="figure" target="#fig_5">6</ref>.</p><p>The diffraction gain due to the presence of a cylinder is given by:</p><formula xml:id="formula_20">G d (dB) = 20log|F (v f ront ) + F (v back )|. (<label>16</label></formula><formula xml:id="formula_21">)</formula><p>To intuitively demonstrate the diffraction attenuation caused by obstruction, we use the example of a cylinder with a radius equal to the FFZ radius. To simplify the setup, we assume the cylinder crosses the FFZ vertically (as shown in Figure <ref type="figure" target="#fig_5">6</ref>) and introduce Fresnel clearance u <ref type="bibr" target="#b57">[58]</ref> to indicate the percentage of crossing:</p><formula xml:id="formula_22">u = h r 1 ,<label>(17)</label></formula><formula xml:id="formula_23">v = h 2(d 1 + d 2 ) λd 1 d 2 = h √ 2 r 1 = √ 2u.<label>(18)</label></formula><p>The diffraction gain during the cylinder's traversal of the FFZ is shown in Figure <ref type="figure">7</ref>. It is obvious that the cylinder causes significant signal attenuation due to diffraction from the moment it touches the FFZ (u f ront = -1) until it completely exits the FFZ (u f ront = 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Azimuth Localization</head><p>Section V-A highlights that the period of significant wireless signal attenuation can be used to determine the time taken for an obstacle (the user) to cross the first Fresnel zone (FFZ). Below, we list several key points:</p><p>• The location of the CAMLOPA device is known.</p><p>• As discussed in Section II-B, Channel State Information (CSI) can represent the attenuation of WiFi signals.</p><p>• When the positions of transmitter (camera) and receiver (CAMLOPA) are fixed, and the obstacle (user) walks in a straight line past the receiver and through the FFZ, the length of the path traversing the FFZ is related to the angle between the walking path and LOS (azimuth).</p><p>Based on the above key points, it is evident that if the user's walking speed and the distance between the transmitter and receiver are known, the azimuth angle of the wireless camera can be calculated using the time of significant CSI attenuation. Furthermore, an important corollary is derived:</p><p>Corollary: In an indoor environment, for a camera to effectively monitor an area of interest, its LOS must remain unobstructed. Therefore, if the azimuth angle of the wireless camera is known, the camera is likely located at the first obstacle encountered along that angle.</p><p>From the corollary, we know that in an indoor environment, effective localization of a wireless camera can be achieved by knowing the azimuth angle information, even without distance information. However, some challenges arise in practice:</p><p>• Users' walking speeds are difficult to obtain.</p><p>• Some users may be unaware of their own sizes.</p><p>• The distance between the CAMLOPA device and the wireless camera is unknown.</p><p>CAMLOPA introduces the orthogonal ratio to address the challenge of obtaining crucial parameters (e.g., speed and distance). As shown in Figure <ref type="figure" target="#fig_6">8</ref>, CAMLOPA prompts the user to walk along two orthogonal paths, both of which pass by the CAMLOPA device. In real-world environments, finding such paths is usually feasible. CAMLOPA then calculates the time it takes to traverse the FFZ along each path (represented by the red lines) based on the periods of significant CSI attenuation and computes their ratio. The azimuth angle θ (the angle of the Path 1 relative to the LOS path) is estimated using a model that relates this ratio to the azimuth angle. The orthogonal ratio-based method eliminates the impact of walking speed and reduces errors due to unknown distances between devices and the user's size.</p><p>Next, we provide a detailed explanation of the azimuth localization model based on the orthogonal ratio. As explained in Section V-A, the duration of significant CSI attenuation corresponds to the time it takes for the user to traverse from entering to exiting the FFZ. Therefore, for Path 1, the walking distance that causes significant attenuation can be calculated as follows:</p><formula xml:id="formula_24">L 1 = B s + L f ,<label>(19)</label></formula><p>where B s and L f represent the user's body size and the length of Path 1 within the FFZ (red line in Figure <ref type="figure" target="#fig_6">8</ref>). L f can be further divided into L f 1 , the distance from the FFZ boundary to CAMLOPA, and L f 2 , the distance from CAMLOPA to the FFZ boundary. Combined with Equation <ref type="formula" target="#formula_5">5</ref>, we have the following equations:</p><formula xml:id="formula_25">L f 1 + d 2 + L 2 f 1 -2dL f 1 cos θ -d = λ 2 , (<label>20</label></formula><formula xml:id="formula_26">)</formula><formula xml:id="formula_27">L f 2 + d 2 + L 2 f 2 -2dL f 1 cos(π -θ) -d = λ 2 , (<label>21</label></formula><formula xml:id="formula_28">)</formula><p>where d is the distance between T x and R x . Treating L f 1 and L f 2 as unknown, they can be solved as follows:</p><formula xml:id="formula_29">L f 1 = λ 2 + 4dλ 4(2d + λ -2d cos θ) , (<label>22</label></formula><formula xml:id="formula_30">)</formula><formula xml:id="formula_31">L f 2 = λ 2 + 4dλ 4(2d + λ + 2d cos θ) . (<label>23</label></formula><formula xml:id="formula_32">)</formula><p>Path 2 does not cross the entire FFZ, and thus the length of its path that perturbs the CSI is only the distance from CAMLOPA to the FFZ boundary:</p><formula xml:id="formula_33">L 2 + d 2 + L 2 2 -2dL 2 cos( π 2 -θ) = λ 2 . (<label>24</label></formula><formula xml:id="formula_34">)</formula><p>Treating L 2 as unknown, it can be solved as follows:</p><formula xml:id="formula_35">L 2 = λ 2 + 4dλ 4(2d + λ -2d sin θ) . (<label>25</label></formula><formula xml:id="formula_36">)</formula><p>The orthogonal ratio is calculated as:</p><formula xml:id="formula_37">Ro = T1 T2 = T1vs T2vs = L1 L2 = 4Bs(2d + λ -2d sin θ) λ 2 + 4dλ + 4(2d + λ -2d sin θ) 4(2d + λ -2d cos θ) + 4(2d + λ -2d sin θ) 4(2d + λ -2d cos θ) = 4Bs(2d + λ -2d sin θ) λ 2 + 4dλ + 8(2d + λ)(2d + λ -2d sin θ) (2d + λ) 2 -(2d cos θ) 2 ,<label>(26)</label></formula><p>where T 1 and T 2 are the periods during which the user's movement along Paths 1 and 2 causes significant CSI attenuation, and v s is the user's walking speed. By taking the ratio, the influence of the speed can be eliminated. After obtaining R o , the Newton-Raphson method can be used to solve for θ.</p><p>Next, we analyze the errors introduced by setting fixed values of B s and d. We conducted an analysis of the L 1 -θ and R o -θ relationship models separately. Figure <ref type="figure" target="#fig_8">9</ref> shows the variations of L 1 and R o relative to the azimuth angle θ for B s = 0.15, 0.25, and 0.45, which are reasonable based on common sense. It can be observed that the error caused by B s is more pronounced near θ = 90 o . The error in the L 1based method due to changes in B s is significant, while the R o -based method effectively mitigates the error caused by the variations of B s . Figure <ref type="figure" target="#fig_9">10</ref> illustrates the variations of L 1 and R o relative to the azimuth angle θ for d = 1, 3, and 6, which are plausible ranges for indoor wireless camera deployment. It can be observed that the error caused by d is more significant around 0/180 o . Compared to the L 1 -based approach (with an theoretical maximum error approaching 20 o ), the theoretical maximum error of R o (15 o ) is more advantageous. Furthermore, the variations in the walking speed due to different users' habits can introduce greater errors in the L 1 -based scheme. It is clear that the orthogonal ratio-based scheme employed by CAMLOPA nearly eliminates the bias caused by unknown speeds and user body sizes while minimizing the errors due to the unknown distance between the transmitter and receiver. Even under the condition of maximum theoretical error, the localization results remain highly practical in real indoor environments due to the limited number of potential hiding spots for wireless cameras. Due to the superiority of the orthogonal ratio strategy, in this paper, CAMLOPA sets d = 3 and B s = 0.25 as fixed values according to realistic scenarios, and users walk for 10 seconds along each path.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Quadrant Determination</head><p>From Figures 9 and 10 (i.e., R o leading to two possible values of θ), we can also observe that the predicted θ using R o has two possible values, making it impossible to determine whether the camera is in the first or second quadrant. Therefore, further quadrant determination is necessary.</p><p>To achieve quadrant determination, CAMLOPA prompts the user to walk again in the same direction as Path 1 for 10 seconds, but starting from a position in front of the CAMLOPA device. The quadrant can then be determined based on changes in the CSI. The rationale is that if the wireless camera is located in the first quadrant, the user standing at the starting position will block the LOS signal between the two devices, causing significant signal variations due to the diffraction effect when the user moves. Conversely, if the wireless camera is behind the user, the user's movement will only cause signal fluctuations due to reflection. Specifically, CAMLOPA determines the quadrant as follows:</p><formula xml:id="formula_38">Q mac = 2 if max(CSI3) min(CSI3) &lt; T q * max(CSI1) min(CSI1) , 1 else . (<label>27</label></formula><formula xml:id="formula_39">)</formula><p>Equation 27 means that if the extent of the CSI fluctuation caused by Path 3 is less than T q times the extent of the CSI fluctuation caused by Path 1, the camera is determined to be in the second quadrant; otherwise, it is in the first quadrant.</p><p>Since movement within the range of 180-360 o does not cross the LOS, CAMLOPA can only locate devices within the range of 0-180 o . However, in real-world environments, the user's available space is usually near walls, thus a single measurement by CAMLOPA remains highly useful. If the condition of moving near walls is not met, CAMLOPA requires two measurements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. IMPLEMENTATION AND EVALUATION</head><p>We implemented CAMLOPA in multiple rooms and diverse hidden wireless cameras, and this section presents the implementation and evaluation details of CAMLOPA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Prototype</head><p>CAMLOPA needs to sniff 802.11 packets in the air and obtain CSI. Currently, most mobile devices require special permissions to perform sniffing. Otherwise, due to the closedsource nature of wireless network card manufacturers, extracting CSI is only possible with certain network cards. However, acquiring this data poses no technical challenge but only involves permission issues. To ensure system applicability, we  The prototype of CAMLOPA is shown in Figure <ref type="figure" target="#fig_10">11</ref>. The Raspberry Pi uses its built-in wireless NIC with the nexmon tool <ref type="bibr" target="#b40">[41]</ref> to modify the kernel for CSI extraction. However, the modified driver cannot sniff normal 802.11 packets, therefore we set up an external network card (NIC1) with monitoring capabilities to sniff 802.11 packets. NIC2 is a standard wireless network card used for communication between the CAMLOPA device and the user's smartphone. The user's smartphone can receive prompts and localization results from CAMLOPA via SSH tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Setup</head><p>We evaluated the performance of CAMLOPA on seven different wireless cameras, as listed in Table <ref type="table" target="#tab_3">III</ref>. All devices were purchased from shopping platforms, and the cameras were connected to a 2.4GHz WiFi network for data transmission. The experiments were conducted in three real-life rooms. Since the experiments were carried out in actual home environments and lasted for an extended period, only the residents participated to protect privacy. The validation experiments lasted for two months in total.</p><p>The layout of three rooms are shown in Figure <ref type="figure" target="#fig_11">12</ref>. Rooms 1 and 2 (Figures <ref type="figure" target="#fig_11">12(a</ref>) and 12(b)) are bedrooms, while room 3 is a living room (Figure <ref type="figure" target="#fig_11">12(c)</ref>). In real environments, private spaces like bedrooms and hotel rooms have limited activity space, restricting the feasibility of previous methods that rely on extensive indoor scanning. In each room, we select several potential locations suitable for monitoring the entire room to place the cameras for the experiments. The azimuths (path 1 as x-axis) of each point in room 1 are 28 As shown in Figure <ref type="figure" target="#fig_4">15</ref>, the cameras we used have an average QoS data packet length ranging from 369 to 1050 bytes during video stream uploads, with upload speeds ranging from 35 to 130 packets per second. Therefore, in our experiments, T s and T l are set to 300 bytes and 150 packets (30 packets * 5 seconds), respectively. The T q for quadrant localization is empirically set to 0.6. For camera detection, we use the success rate of detecting snooping cameras as the evaluation metric, while for localization, we use the azimuth angle error as the evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CSI Analysis and Algorithm Implementation</head><p>In this section, we analyze the mapping relationship between the CSI influenced by user activity and the angle of the wireless camera. Furthermore, we elaborate on the design of the algorithm for extracting attenuation time from the CSI.</p><p>The variation in CSI amplitude due to user activity when the wireless camera is positioned at different azimuth angles is shown in Figure <ref type="figure" target="#fig_2">13</ref>. It can be observed that the CSI amplitude variation is significantly influenced by the azimuth angle of the wireless camera relative to CAMLOPA. Generally, the larger the angle, the shorter the duration of significant fluctuations in CSI from Path 1 (CSI 1), while the duration of significant fluctuations in CSI from Path 2 (CSI 2) increases. These experimental results validate the feasibility of the azimuth localization scheme proposed by CAMLOPA. Additionally, we made several other observations:</p><p>• The fluctuation duration of CSI 2 may not accurately reflect the actual path length causing the fluctuation, as it takes time for the user to accelerate from a stationary state to walking. • When the angle is too small (0 degrees) or too large (90 degrees), the calculated R o significantly deviates from the theoretical R o . This is due to the limited indoor walking space usually causes the user to stop after a short distance due to obstacles, resulting in a fluctuation duration shorter than the theoretical value.</p><p>To obtain the duration of significant CSI fluctuations, we use different methods for CSI 1 and CSI 2. For CSI 1, we first identify the lowest point and then use the calculated inverse to find the start and end points of the fluctuation. For CSI 2, we first calculate the mean values of the initial and later segments, then we construct a piecewise waveform       Fig. <ref type="figure" target="#fig_2">13</ref>. The variation in CSI amplitude due to user activity when the wireless camera is positioned at different azimuth angles. The black dots represent the start and end points of significant CSI fluctuations for each path. By dividing the duration of significant attenuation of path 1 by that of path 2, we obtain Ro, which is then used to calculate θ according to Equation <ref type="formula" target="#formula_37">26</ref>. In (c) and (g), Ro is calculated as 0.8 0.66 = 1.21, and substituting this into Equation 26 yields θ = 72.18 • . The calculations for the others follow the same procedure.  where the values of the initial and later segments are equal to the calculated means. By adjusting the position of the segmentation, we find the point that best matches the waveform with CSI 2 to determine the midpoint of the fluctuation. We then calculate the inverse to identify the start and end points of the fluctuation. Additionally, based on our first observation, we scale the calculated fluctuation duration for CSI 2 to eliminate errors. For activities that cause fluctuations exceeding a certain duration, we increase the fluctuation time to mitigate the effect noted in the second observation. As shown in Figure <ref type="figure" target="#fig_20">14</ref> shows the variations in CSI 3 (corresponding to Path 3) when the wireless camera is located in different quadrants. It is obvious that the quadrant localization scheme proposed by CAMLOPA is also effective. Since CSI consists of many different subcarriers, and different subcarriers have varying sensitivities to user activity (with higher amplitudes indicating lower sensitivity), CAMLOPA focuses only on the periods of significant attenuation. Therefore, we select the five subcarriers with the highest amplitudes, average them after filtering, and use this average as the final input for CAMLOPA to calculate R o and the quadrant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Performance of Wireless Camera Detection</head><p>CAMLOPA detects wireless cameras monitoring the current area by first identifying suspicious devices, prompting the user to leave the room, and monitoring throughput changes to detect snooping hidden wireless cameras. CAMLOPA achieves an 84.35% success rate in identifying suspicious wireless cameras across all devices. The probability of identifying the 360 camera as a suspicious device is 0, while the accuracy of detecting other wireless cameras as suspicious devices reaches 98.41%. This discrepancy occurs because, during traffic sniffing, the 360 wireless camera only allows the capture of ACK Block and Request-to-Send packets, but not QoS data packets. This limitation may be due to the special data  transmission methods or protocols they use, which prevent its traffic from being intercepted, thus hindering detection and previous methods based on WiFi traffic all cannot work <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. However, the nexmon tool used by CAMLOPA can still capture the CSI for the 360 camera from WiFi traffic. The snooping camera detection results are shown in Figure <ref type="figure" target="#fig_4">15</ref>. CAMLOPA achieves a 95.37% success rate in detecting snooping cameras for six types of cameras across three rooms, except for the 360 wireless camera. For devices similar to the 360 camera, we believe that wireless camera detection can still be achieved by querying the OUI of the captured Request-to-Send packet's leaked MAC address. By constructing an OUI table of all available devices using device name information from shopping platforms and MAC address lookup websites, it is possible to identify the device type. However, CAMLOPA cannot determine whether the camera is monitoring the current area using this method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Performance of Wireless Camera Localization</head><p>The localization results for different deployment positions in three rooms are shown in Figure <ref type="figure" target="#fig_22">16</ref>, and CAMLOPA achieves an average azimuth localization error of 17.24 degrees for wireless hidden cameras. CAMLOPA demonstrates higher localization accuracy for cameras within the 40-90 o range, while the accuracy decreases for cameras in the second quadrant or close to 0 o . This discrepancy arises from errors introduced by the quadrant determination scheme and path length limitations. We further discuss the specific causes of these errors in Section VII. For cameras near 90 o , the algorithm described in Section VI-C causes CAMLOPA to tend to output predictions close to 90 o , resulting in lower errors. Overall, CAMLOPA achieves high localization accuracy than previous similar studies in a shorter time and with lower activity space requirements, and without the need for training. Although CAMLOPA's localization results are not perfectly precise in confined indoor spaces, it significantly improve the localization resolution and reduce the search area for users compare to previous studies. However, CAMLOPA still has some limitations and areas for improvement, which we will discuss further in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Sensitivity Analysis</head><p>CAMLOPA's performance in localizing different devices is shown in Figure <ref type="figure" target="#fig_0">17</ref>. Although the 360 camera's QoS data frames cannot be captured by common packet-sniffing tools, its CSI can still be monitored by the nexmon tool. Therefore, we also included the 360 camera in our localization experiments.  As shown in Figure <ref type="figure" target="#fig_0">17</ref>, CAMLOPA maintains consistent localization performance across different types of cameras, demonstrating its robustness to device variations. Figure <ref type="figure" target="#fig_23">18</ref> illustrates the differences in CAMLOPA's azimuth localization performance across three rooms, further highlighting its robustness to environmental changes. This robustness stems from CAMLOPA's localization algorithm, which is based on the analysis of wireless signal propagation paths. Consequently, unlike previous approaches <ref type="bibr" target="#b12">[13]</ref>, it does not require precollected data or deep learning models that need extensive data to ensure robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. DISSCUSSION</head><p>In this section, we discuss the limitations of CAMLOPA, the potential risks, and possible improvements.</p><p>Non-WiFi Cameras. The fundamental principle behind CAM-LOPA's detection and localization of wireless cameras limits its applicability to live streaming spy cameras on WiFi networks. It does not extend to cameras that use local storage, cellular networks, or Ethernet. However, most recent crime cases have involved WiFi spy cameras <ref type="bibr" target="#b11">[12]</ref> because they are easy to deploy and manage, and their prevalence is rapidly increasing in the commercial market. Therefore, CAMLOPA is suitable for many scenarios. To expand the detection range, infrared or optical methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref> would still be needed. Evading CAMLOPA. CAMLOPA aims to detect and locate wireless cameras deployed by typical attackers. However, we acknowledge that more powerful attackers may have ways to evade CAMLOPA. Attackers could modify the behavior of hidden cameras by customizing hardware or altering firmware to change the packet size or arrival intervals, thus avoiding detection. For example, they could have the wireless camera transmit unencoded raw video, add padding traffic to ensure a stable data stream, use randomly varying resolutions, or inject noise to disrupt the traffic model. These methods could prevent CAMLOPA from detecting whether a camera is monitoring the current area. However, such tactics require a high level of expertise from the attacker. The localization module, based on wireless signal propagation path analysis, can still function normally by using the device's MAC address and WiFi channel. Avoiding localization would require modifying the network card hardware to control the WiFi signal's transmission power, causing it to constantly change and disrupt the signal attenuation trend caused by user activity. This also requires attackers to have specialized knowledge, and modifying network card hardware is considerably challenging.</p><p>Failures Analysis. To analyze the sources of error in CAM-LOPA's localization process, we present the localization results for Room 1 in Figure <ref type="figure" target="#fig_8">19</ref>. It can be observed that most errors originate from cameras with smaller azimuth angles and outliers. For cameras with smaller azimuth angles, the user's starting position pf Path2 is in front of the CAMLOPA device, lacking the buffer distance similar to Path 1 (i.e., the user is already walking at a normal speed before entering the FFZ.) The differences in user acceleration and the limitation of leaving the FFZ right after starting to walk lead to a significant discrepancy between the actual and theoretical times for the user crossing the FFZ on Path 2. This discrepancy is difficult to correct with rules. Outliers mainly stem from the inaccuracy of the quadrant localization method. Due to the complexity of indoor multipath effects, the fluctuations in CSI 3 can be unstable, causing the algorithm to make incorrect judgments. This can result in a predicted angle that differs from the actual angle by 180 -θ. Therefore, in practical use, if the user does not find the hidden camera at the predicted location, they can also check the position at 180 -θ to find camera.</p><p>New Privacy Risks. While CAMLOPA can be used by users to detect wireless cameras, it could also be exploited by attackers to locate wireless devices in the user's environment through walls. Combined with traffic analysis and activity recognition methods based on WiFi CSI <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref>, <ref type="bibr" target="#b64">[65]</ref>, this could create new privacy risks. This is a direction we intend to explore in our future research.</p><p>Environment and User Effort Limitations. CAMLOPA can only localize wireless cameras within the 0-180 o range. However, in real-world environments, it is relatively easy to find a location near a wall to place the CAMLOPA device, and it can perform two rounds of positioning to achieve 360 o localization. Therefore, this localization range remains useful in practical settings. Another limitation is that CAMLOPA assumes users walk along two orthogonal straight paths at a constant speed, which can introduce errors in real-world scenarios. In actual environments, the layout of indoor furniture (such as floor stripes, walls, and furniture) can help guide users to maintain two straight walking paths. Additionally, users can easily control their walking speed within a certain range to minimize the biases. Our experiments have demonstrated the robustness of CAMLOPA in real-world settings with normal user walking. CAMLOPA can be easily extended to scenarios with multiple cameras. During the snooping camera detection phase, a single user walking can detect multiple cameras by clustering the MAC addresses of all sniffed packets. However, when capturing CSI, nexmon tool can only capture packets from one MAC address at a time. Therefore, to localize multiple cameras, the user must repeat the localization process for each camera, which increases the user's effort.</p><p>Future Work for Improvement. Next, we aim to further reduce user effort and eliminate localization errors caused by user activity. This will involve using low cost 3D-printed kits with metal obstructions as peripherals. By controlling the metal obstructions to rotate around the Raspberry Pi, we can perturb the CSI. Constructing a corresponding CSI-azimuth model will enable more precise localization with less user effort. Additionally, we plan to explore building indoor wireless device maps based on our localization technology. Combine this map with WiFi traffic and CSI will help us study new user behavior privacy risks and develop defensive measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we propose CAMLOPA, a framework for detecting and locating wireless hidden cameras based on wireless signal propagation path analysis, specifically focusing on diffraction attenuation. CAMLOPA establishes a relationship between the signal attenuation caused by user activity and the location of the wireless camera. Compared to current methods, CAMLOPA offers several advantages: it is costeffective, requires no training, demands less activity space, and involves minimal user effort. However, CAMLOPA still has some limitations. In future work, we aim to further reduce user effort and minimize localization errors through the use of peripherals. Additionally, we will analyze new privacy risks associated with CAMLOPA and develop countermeasures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Different wireless signal path losses when crossing the First Fresnel Zone (FFZ) with different path lengthes.</figDesc><graphic coords="2,67.87,54.00,214.30,97.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of Fresnel Zone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Overview of CAMLOPA. CAMLOPA is implemented using a low-cost Raspberry Pi, which can connect via SSH to the user's phone for prompts and notifications. The operation of CAMLOPA is divided into two phases: wireless camera detection and localization. The detection stage determines whether a wireless camera is monitoring the current area, while the localization stage precisely locates the identified camera.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. IEEE 802.11 wireless frame.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Throughput during the user's exit from the room. V. WIRELESS CAMERA LOCALIZATION CAMLOPA localizes snooping cameras in two stages: (i) azimuth localization and (ii) quadrant determination.</figDesc><graphic coords="6,325.69,45.83,239.10,139.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. A moving cylinder across the FFZ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. The illustration of azimuth localization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(a) The variations of L 1 . (b) The variations of Ro.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. The variations of L 1 and Ro relative to θ with Bs changes.</figDesc><graphic coords="9,104.09,48.07,208.51,125.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. The variations of L 1 and Ro relative to θ with d changes.</figDesc><graphic coords="9,92.68,201.77,208.51,125.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. The prototype of CAMLOPA.</figDesc><graphic coords="9,350.51,366.54,189.07,141.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. The layout of three rooms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>4.11 o , path1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>60.28 o , path1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>88.54 o , path1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>4.11 o , path2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>28.61 o , path2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>60.28 o , path2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>88.54 o , path2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>(a) 28 .</head><label>28</label><figDesc>61 o , path3. (b) 130.1 o , path3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 14 .</head><label>14</label><figDesc>Fig.<ref type="bibr" target="#b13">14</ref>. The variation in CSI amplitude due to user activity when the wireless camera is positioned at different quadrant. When the camera is located in the first quadrant (a), the user's starting position blocks the LOS, resulting in significant CSI fluctuations during movement. In contrast, when the camera is located in the second quadrant (b), the user does not block the LOS, leading to minor CSI fluctuations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig 13 ,Fig. 15 .</head><label>1315</label><figDesc>Fig. 15. Snooping camera detection performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Localization results of hidden cameras deployed at different positions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Azimuth localization results across different room.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I .</head><label>I</label><figDesc>QUALITATIVE COMPARISON WITH EXISTING APPROACHES.</figDesc><table><row><cell>Method</cell><cell>Low-Cost</cell><cell>Low</cell><cell>No Data Pre-</cell><cell>Low</cell></row><row><cell></cell><cell>Commercial</cell><cell>User</cell><cell>Collection</cell><cell>Empty Re-</cell></row><row><cell></cell><cell>Devices</cell><cell>Efforts</cell><cell>and Training</cell><cell>quirement</cell></row><row><cell>LAPD</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II .</head><label>II</label><figDesc>RECEIVED SIGNAL STRENGTH INDICATION (RSSI).</figDesc><table><row><cell>Signal</cell><cell cols="4">Conclusion Describe</cell><cell></cell><cell></cell><cell></cell><cell>Required for</cell></row><row><cell>Strength</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-30</cell><cell cols="2">Amazing</cell><cell cols="6">Max achievable signal strength. Not</cell><cell>N/A</cell></row><row><cell>dBm</cell><cell></cell><cell></cell><cell cols="6">typical or desirable in the real world.</cell></row><row><cell>-67</cell><cell>Very</cell><cell></cell><cell cols="6">Minimum signal strength for applica-</cell><cell>VoIP,</cell></row><row><cell>dBm</cell><cell>Good</cell><cell></cell><cell cols="6">tions that require very reliable, timely</cell><cell>streaming</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">delivery of data packets.</cell><cell></cell><cell>video</cell></row><row><cell>-70</cell><cell>Okay</cell><cell></cell><cell cols="6">Minimum signal strength for reliable</cell><cell>Email, web</cell></row><row><cell>dBm</cell><cell></cell><cell></cell><cell cols="2">packet delivery.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>-80</cell><cell cols="2">Not Good</cell><cell cols="6">Minimum signal strength for basic</cell><cell>N/A</cell></row><row><cell>dBm</cell><cell></cell><cell></cell><cell cols="6">connectivity. Packet delivery may be</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">unreliable.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>-90</cell><cell cols="2">Unusable</cell><cell cols="6">Approaching or drowning in the noise</cell><cell>N/A</cell></row><row><cell>dBm</cell><cell></cell><cell></cell><cell cols="6">floor. Any functionality is highly un-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>likely.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Duration/ID</cell><cell cols="2">Source</cell><cell></cell><cell cols="2">Sequence</cell><cell>Frame Check</cell></row><row><cell></cell><cell cols="2">(2B)</cell><cell cols="3">Address (6B)</cell><cell cols="2">Control (2B)</cell><cell>Sequence (4B)</cell></row><row><cell></cell><cell>FC</cell><cell>D/I</cell><cell>DA</cell><cell>SA</cell><cell>RA</cell><cell>SC</cell><cell></cell><cell>PL</cell><cell>FCS</cell></row><row><cell cols="2">Frame</cell><cell cols="2">Destination</cell><cell cols="3">Receiver</cell><cell cols="2">Payload</cell></row><row><cell cols="2">Control (2B)</cell><cell cols="2">Address (6B)</cell><cell cols="3">Address (6B)</cell><cell cols="2">(variable)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III</head><label>III</label><figDesc></figDesc><table><row><cell>.</cell><cell cols="3">CAMERAS USED IN EXPERIMENTS.</cell></row><row><cell>Camera</cell><cell></cell><cell>Abbreviation</cell><cell>Cost($)</cell></row><row><cell cols="2">XiaoMi Cloud Camera2</cell><cell>Mi</cell><cell>24.5</cell></row><row><cell cols="2">XiaoYi Smart Camera Y4</cell><cell>Yi</cell><cell>20.4</cell></row><row><cell cols="2">EZVIZ C2C</cell><cell>C2C</cell><cell>24.5</cell></row><row><cell cols="2">360 Cloud Camera 8Pro</cell><cell>360</cell><cell>24.5</cell></row><row><cell cols="2">V380 Camera</cell><cell>V380</cell><cell>13.6</cell></row><row><cell cols="2">Guangchun Mini Camera</cell><cell>Gc</cell><cell>31.4</cell></row><row><cell cols="2">HiLEME Mini Camera</cell><cell>Hi</cell><cell>18.4</cell></row><row><cell cols="4">did not implement CAMLOPA on specific phone or computer</cell></row><row><cell cols="4">platforms which can extract CSI. Instead, we chose the open-</cell></row><row><cell cols="4">source and low-cost COTS device, Raspberry Pi, as the plat-</cell></row><row><cell>form for CAMLOPA.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>.61 o , 42.27 o , 60.28 o , 88.54 o , 130.1 o , and 157.73 o , in room 2 are 4.86 o , 51.34 o , 69.44 o , and 103.52 o , and in room 3 are 110.94 o , 92.37 o , 61.34 o , 47.13 o , and 30.69 o .</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Non-VBR Devices. When CAMLOPA detects whether a camera is monitoring the current area, the device's traffic must be encoded using a Variable Bit Rate (VBR) algorithm. While this algorithm is used by the vast majority of wireless camera devices, if a camera is specifically designed to encode video/audio information at a constant bit rate (CBR), CAMLOPA may only be able to roughly detect its presence using the OUI table. However, CAMLOPA can still locate such devices through the proposed localization scheme.</figDesc><table><row><cell></cell><cell>28.61</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>42.27</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Azimuth</cell><cell>60.28 88.54</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>130.1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>157.73</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>-20</cell><cell>0</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80 100 120 140 160 180 200</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Estimation</cell></row><row><cell cols="4">Fig. 19. Failures analysis.</cell><cell></cell><cell></cell></row><row><cell cols="7">MAC Address Randomization. CAMLOPA uses MAC ad-</cell></row><row><cell cols="7">dresses to identify devices and treats them as unique IDs</cell></row><row><cell cols="7">throughout the localization process. Although some modern</cell></row><row><cell cols="7">devices employ MAC address randomization [59] to enhance</cell></row><row><cell cols="7">security, this does not affect CAMLOPA's detection and local-</cell></row><row><cell cols="7">ization capabilities. This is because devices, even with MAC</cell></row><row><cell cols="7">address randomization, use a consistent MAC address for</cell></row><row><cell cols="7">communication once a network connection is established.</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Gupta</surname></persName>
		</author>
		<ptr target="https://www.marketresearchfuture.com/reports/wireless-monitoring-surveillance-market-975" />
		<title level="m">Wireless monitoring and surveillance market, by component, type, connectivity, end-user -forecast till 2030</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wireless video surveillance: A survey</title>
		<author>
			<persName><forename type="first">Yun</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Ci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanwei</forename><surname>Aggelos K Katsaggelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="646" to="660" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Smart devices in airbnbs: Considering privacy and security for both guests and hosts</title>
		<author>
			<persName><forename type="first">Shrirang</forename><surname>Mare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franziska</forename><surname>Roesner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tadayoshi</forename><surname>Kohno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on Privacy Enhancing Technologies</title>
		<meeting>on Privacy Enhancing Technologies</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Many airbnbs have cameras installed, especially in the us, canada and singapore</title>
		<author>
			<persName><forename type="first">David</forename><surname>Janssen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">More than 1 in 10 airbnb guests have found hidden cameras: Survey</title>
		<author>
			<persName><forename type="first">Jim</forename><surname>Dalrymple</surname></persName>
		</author>
		<ptr target="https://www.inman.com/2019/06/07/morethan-1-in-10-airbnb-guest-have-found-cameras-in-rentals-survey/" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<ptr target="https://www.cambasket.com/the-security-camera-laws-in-delaware/" />
		<title level="m">The security camera laws in delaware</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lapd: Hidden spy camera detection using smartphone time-of-flight sensors</title>
		<author>
			<persName><forename type="first">Sriram</forename><surname>Sami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bangjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems</title>
		<meeting>the 19th ACM Conference on Embedded Networked Sensor Systems</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="288" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Heatdecam: detecting hidden spy cameras via thermal emissions</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhaur</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Skylar</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</title>
		<meeting>the 2022 ACM SIGSAC Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="3107" to="3120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Lumos: Identifying and localizing diverse hidden {IoT} devices in an unfamiliar environment</title>
		<author>
			<persName><forename type="first">Anand</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elahe</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Soltanaghaei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vyas</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><surname>Sekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st USENIX Security Symposium (USENIX Security 22)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1095" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">I always feel like somebody&apos;s sensing me! a framework to detect, identify, and localize clandestine wireless sensors</title>
		<author>
			<persName><forename type="first">Akash Deep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Noor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mani</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th USENIX Security Symposium (USENIX Security 21)</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1829" to="1846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Motioncompass: pinpointing wireless camera via motion-activated traffic</title>
		<author>
			<persName><forename type="first">Yan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiuye</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Song</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services</title>
		<meeting>the 19th Annual International Conference on Mobile Systems, Applications, and Services</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="215" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Are there wireless hidden cameras spying on me?</title>
		<author>
			<persName><forename type="first">Jeongyoon</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sangwon</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngman</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinmok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Donguk</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Woojin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongdae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Choong-Hoon</forename><surname>Kang G Shin</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Computer Security Applications Conference</title>
		<meeting>the 38th Annual Computer Security Applications Conference</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="714" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Loccams: An efficient and robust approach for detecting and localizing hidden wireless cameras via commodity devices</title>
		<author>
			<persName><forename type="first">Yangyang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziming</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiying</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dewicam: Detecting hidden wireless cameras via smartphones</title>
		<author>
			<persName><forename type="first">Yushi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyuan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 on Asia Conference on Computer and Communications Security</title>
		<meeting>the 2018 on Asia Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Do you see what i see? detecting hidden streaming cameras through similarity of simultaneous observation</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brent</forename><surname>Lagesse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Pervasive Computing and Communications (PerCom</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">User presence inference via encrypted traffic of wireless camera in smart homes. Security and Communication Networks</title>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinyan</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2018</biblScope>
			<biblScope unit="page">3980371</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On detecting hidden wireless cameras: A traffic pattern-based approach</title>
		<author>
			<persName><forename type="first">Yushi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyuan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="907" to="921" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Csi: Despy: enabling effortless spy camera detection via passive sensing of user activities and bitrate variations</title>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nguyen</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uichin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngtae</forename><surname>Noh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deepdespy: a deep learning-based wireless spy camera detection system</title>
		<author>
			<persName><forename type="first">Dinhnguyen</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youngtae</forename><surname>Noh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="145486" to="145497" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Spy hidden camera detector</title>
		<author>
			<persName><forename type="first">Jakobi</forename><surname>Teknik</surname></persName>
		</author>
		<ptr target="https://apps.apple.com/us/app/spy-hidden-cameradetector/id925967783?mt=8" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><surname>Llc Lsc</surname></persName>
		</author>
		<ptr target="https://apps.apple.com/us/app/hidden-camera-detector/id532882360" />
		<title level="m">Hidden camera detector</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Camradar: hidden camera detection leveraging amplitude-modulated sensor images embedded in electromagnetic emanations</title>
		<author>
			<persName><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijie</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongjie</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Li</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kui</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">See no evil: Discovering covert surveillance devices using thermal imaging</title>
		<author>
			<persName><forename type="first">Agustin</forename><surname>Zuniga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naser</forename><surname>Hossein Motlagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><forename type="middle">A</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasu</forename><surname>Tarkoma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huber</forename><surname>Flores</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petteri</forename><surname>Nurmi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Pervasive Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="33" to="42" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Lenser: A channel state information based indoor localization scheme for malicious devices</title>
		<author>
			<persName><forename type="first">Yongqiang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangyang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruixiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shaoyong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE 20th International Conference on Mobile Ad Hoc and Smart Systems (MASS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="461" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The mathematical theory of Huygens&apos; principle</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bevan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><surname>Thomas Copson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>American Mathematical Soc</publisher>
			<biblScope unit="volume">329</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Goldsmith</surname></persName>
		</author>
		<title level="m">Wireless communications</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Wireless spy devices: A review of technologies and detection methods</title>
		<author>
			<persName><forename type="first">Dinesh</forename><surname>Sathyamoorthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohd</forename><surname>Jalis Md</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shalini</forename><surname>Jelas</surname></persName>
		</author>
		<author>
			<persName><surname>Shafii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Editorial Board</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">130</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Spy vs. spy: A modern study of microphone bugs operation and detection</title>
		<author>
			<persName><forename type="first">Veronica</forename><surname>Valeros</surname></persName>
			<affiliation>
				<orgName type="collaboration">Chaos Computer Club eV</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Garcia</surname></persName>
			<affiliation>
				<orgName type="collaboration">Chaos Computer Club eV</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Detecting wireless spy cameras via stimulating and probing</title>
		<author>
			<persName><forename type="first">Tian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services</title>
		<meeting>the 16th Annual International Conference on Mobile Systems, Applications, and Services</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="243" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Iot sentinel: Automated devicetype identification for security enforcement in iot</title>
		<author>
			<persName><forename type="first">Markus</forename><surname>Miettinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Marchal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ibbad</forename><surname>Hafeez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Asokan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad-Reza</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sasu</forename><surname>Tarkoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 37th international conference on distributed computing systems (ICDCS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2177" to="2184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Phyfinatt: An undetectable attack framework against phy layer fingerprint-based wifi authentication</title>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenglin</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiancun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Wital: A cots wifi devices based vital signs monitoring system using nlos sensing model</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yantong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mianxiong</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaoru</forename><surname>Ota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuji</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusheng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Human-Machine Systems</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="629" to="641" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guohang</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Wiopen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.00822</idno>
		<title level="m">A robust wi-fi-based openset gesture recognition framework</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Wife: Wifi and vision based unobtrusive emotion recognition via gesture and facial expression</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mianxiong</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuji</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Wireless communications: principles and practice</title>
		<author>
			<persName><surname>Theodore S Rappaport</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards a diffraction-based sensing approach on human activity recognition</title>
		<author>
			<persName><forename type="first">Fusang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beihong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daqing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Wiprofile: Unlocking diffraction effects for subcentimeter target profiling using commodity wifi devices</title>
		<author>
			<persName><forename type="first">Zhiyun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daqing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th Annual International Conference on Mobile Computing and Networking</title>
		<meeting>the 30th Annual International Conference on Mobile Computing and Networking</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="185" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Understanding the diffraction model in static multipath-rich environments for wifi sensing system design</title>
		<author>
			<persName><forename type="first">Xuanzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anlan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiyan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daqing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tool release: Gathering 802.11 n traces with channel state information</title>
		<author>
			<persName><forename type="first">Wenjun</forename><surname>Daniel Halperin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anmol</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName><surname>Wetherall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGCOMM computer communication review</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="53" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Reshaping wi-fi isac with high-coherence hardware capabilities</title>
		<author>
			<persName><forename type="first">Rui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fangxin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hangbin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daiyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiping</forename><surname>Jiang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Free your csi: A channel state information extraction platform for modern wi-fi chipsets</title>
		<author>
			<persName><forename type="first">Francesco</forename><surname>Gringoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Link</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hollick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Wireless Network Testbeds</title>
		<meeting>the 13th International Workshop on Wireless Network Testbeds</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="21" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Nexmon: The c-based firmware patching framework</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Wegemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hollick</surname></persName>
		</author>
		<ptr target="https://nexmon.org" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Wifi sensing with channel state information: A survey</title>
		<author>
			<persName><forename type="first">Yongsen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuangquan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Wigrunt: Wifi-enabled gesture recognition using dual-attention network</title>
		<author>
			<persName><forename type="first">Yu</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yantong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianhua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mianxiong</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Human-Machine Systems</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="736" to="746" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Information leakage in encrypted ip video traffic</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Wampler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Selcuk</forename><surname>Uluagac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raheem</forename><surname>Beyah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Global Communications Conference (GLOBECOM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Drones&apos; cryptanalysis-smashing cryptography with a flicker</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Nassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raz</forename><surname>Ben-Netanel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adi</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuval</forename><surname>Elovici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1397" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Airbnb has a hidden-camera problem</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fussell</surname></persName>
		</author>
		<ptr target="https://www.theatlantic.com/technology/archive/2019/03/what-happens-when-youfind-cameras-your-airbnb/585007/" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Hundreds of south korean motel guests were secretly filmed and live-streamed online</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Griffiths</surname></persName>
		</author>
		<ptr target="https://www.cnn.com/2019/03/20/asia/southkorea-hotel-spy-cam-intl/index.html" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Keystrokesniffer: An off-the-shelf smartphone can eavesdrop on your privacy from anywhere</title>
		<author>
			<persName><forename type="first">Jinyang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia-Xuan</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhao</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianchun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mianxiong</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Devicemien: network device behavior modeling for identifying unknown iot devices</title>
		<author>
			<persName><forename type="first">Jorge</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franck</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Internet of Things Design and Implementation</title>
		<meeting>the International Conference on Internet of Things Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="106" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Classifying iot devices in smart environments using network traffic characteristics</title>
		<author>
			<persName><forename type="first">Arunan</forename><surname>Sivanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Habibi Gharakheili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franco</forename><surname>Loi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chamith</forename><surname>Wijenayake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijay</forename><surname>Sivaraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1745" to="1759" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><surname>Metageek</surname></persName>
		</author>
		<ptr target="https://www.metageek.com/training/resources/understanding-rssi/" />
		<title level="m">The basics: Understanding rssi</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Packet-level open-world app fingerprinting on wireless traffic</title>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiapu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobo</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2022 Network and Distributed System Security Symposium (NDSS&apos;22)</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">11 wireless networks: the definitive guide</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Gast</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>O&apos;Reilly Media, Inc</publisher>
			<biblScope unit="volume">802</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Ieee standard for information technology-telecommunications and information exchange between systems -local and metropolitan area networks-specific requirements -part 11: Wireless lan medium access control (mac) and physical layer (phy) specifications</title>
	</analytic>
	<monogr>
		<title level="j">Revision of IEEE Std</title>
		<imprint>
			<biblScope unit="volume">802</biblScope>
			<biblScope unit="page" from="1" to="4379" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>IEEE Std</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Traffic characteristics of h. 264/avc variable bit rate video</title>
		<author>
			<persName><forename type="first">Geert</forename><surname>Van Der Auwera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanth T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Reisslein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Magazine</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="164" to="174" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Fast motion estimation based on content property for lowcomplexity h. 265/hevc encoder</title>
		<author>
			<persName><forename type="first">Zhaoqing</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianjun</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Kwong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Broadcasting</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="675" to="684" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">From fresnel diffraction model to fine-grained human respiration sensing with commodity wi-fi devices</title>
		<author>
			<persName><forename type="first">Fusang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beihong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxiang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Interact. Mob. Wearable Ubiquitous Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018-03">mar 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Why mac address randomization is not enough: An analysis of wi-fi network discovery mechanisms</title>
		<author>
			<persName><forename type="first">Mathy</forename><surname>Vanhoef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Célestin</forename><surname>Matte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mathieu</forename><surname>Cunche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leonardo</forename><forename type="middle">S</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Piessens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th ACM on Asia conference on computer and communications security</title>
		<meeting>the 11th ACM on Asia conference on computer and communications security</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="413" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Cross-domain wifi sensing with channel state information: A survey</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Towards a dynamic fresnel zone model to wifi-based human activity recognition</title>
		<author>
			<persName><forename type="first">Jinyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruiyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fusang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daqing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">{BFMSense}:{WiFi} sensing using beamforming feedback matrix</title>
		<author>
			<persName><forename type="first">Enze</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fusang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daqing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24)</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1697" to="1712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Uwb-fi: Pushing wi-fi towards ultra-wideband for fine-granularity sensing</title>
		<author>
			<persName><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiping</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services</title>
		<meeting>the 22nd Annual International Conference on Mobile Systems, Applications and Services</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="42" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Muki-fi: Multi-person keystroke inference with bfi-enabled wi-fi sensing</title>
		<author>
			<persName><forename type="first">Hongbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyue</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingzhi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongbo</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanjin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Mobile Computing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">Daqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fusang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanzhi</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">Theories, applications and future directions. In Integrated Sensing and Communications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="387" to="417" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
