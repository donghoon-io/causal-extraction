<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach</title>
				<funder ref="#_pUjuXeQ #_Fj4JwN2">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_zqZYvTZ">
					<orgName type="full">Higher Education Authority</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="1145">1145/2530526</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Abu</forename><surname>Kamal</surname></persName>
						</author>
						<author role="corresp">
							<persName><roleName>Bleakley</roleName><forename type="first">M</forename><surname>Raihan</surname></persName>
							<email>raihan@ucdconnect.ie</email>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Dobson</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Raihan</forename><forename type="middle">M</forename><surname>Abu</surname></persName>
						</author>
						<author>
							<persName><surname>Kamal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Abu</forename><surname>Raihan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">M</forename><surname>Kamal</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Bleakley</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Simon</forename><surname>Dobson</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dublin SIMON DOBSON</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Informatics</orgName>
								<orgName type="laboratory">Complex and Adaptive Systems Laboratory</orgName>
								<orgName type="institution" key="instit1">University College Dublin CHRIS J. BLEAKLEY</orgName>
								<orgName type="institution" key="instit2">University College</orgName>
								<orgName type="institution" key="instit3">University of St Andrews</orgName>
								<orgName type="institution" key="instit4">University College Dublin</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Informatics</orgName>
								<orgName type="laboratory">Complex and Adaptive Systems Laboratory</orgName>
								<orgName type="institution">University College Dublin</orgName>
								<address>
									<addrLine>Simon Dobson</addrLine>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of St Andrews</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">from Publications Dept</orgName>
								<orgName type="institution">ACM, Inc</orgName>
								<address>
									<addrLine>Suite 701</addrLine>
									<settlement>Penn Plaza New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="1145">1145/2530526</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/2530526</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T21:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C.2.2 [Computer-Communication Networks]: Network Protocols Sensor Network</term>
					<term>Fault Detection</term>
					<term>Performance Wireless sensor networks</term>
					<term>sensor data</term>
					<term>senor faults</term>
					<term>data collection</term>
					<term>routing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Wireless Sensor Network (WSN) technology has recently moved out of controlled laboratory settings to realworld deployments. Many of these deployments experience high rates of failure. Common types of failure include Node Failure, Link Failure and Node Reboot. Due to the resource-constraints of sensor nodes, existing techniques for fault detection in enterprise networks are not applicable. Previously proposed WSN fault detection algorithms either rely on periodic transmission of node status data or inferring node status based on passive information collection. The former approach significantly reduces network lifetime, while the latter achieves poor accuracy in dynamic or large networks. Herein, we propose Sequence Based Fault Detection (SBFD), a novel framework for network fault detection in WSNs. The framework exploits in-network packet tagging using the Fletcher Checksum and server-side network path analysis to efficiently deduce the path of all packets sent to the Sink. The Sink monitors the extracted packet paths to detect Persistent Path Changes which are indicative of network failures. When a failure is suspected, the Sink uses control messages to check the status of the affected nodes. SBFD was implemented in TinyOS on TelosB motes and its performance was assessed in a testbed network and in TOSSIM simulation. The method was found to achieve a fault detection accuracy of 90.7% to 95.0% for networks of 25 to 400 nodes at the cost of 0.164% to 0.239% additional control packets and a 0.5% reduction in node lifetime due to in-network packet tagging. Finally, a comparative study was conducted with existing solutions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Wireless Sensor Networks (WSNs) have been used in many applications, including environmental monitoring, industrial plant monitoring and traffic monitoring. Typically, WSNs contain a large number of resource-constrained sensor nodes which are powered by non-rechargeable batteries. Nodes are often placed in hard-to-reach areas and are kept there for prolonged durations for the purpose of data reporting or event monitoring. Experience from real-world WSN deployments, such as <ref type="bibr" target="#b16">[Langendoen et al. 2006;</ref><ref type="bibr" target="#b2">Arora et al. 2004;</ref><ref type="bibr" target="#b3">Beckwith et al. 2004;</ref><ref type="bibr" target="#b15">Krishnamurthy et al. 2005;</ref><ref type="bibr" target="#b26">Szewczyk et al. 2004;</ref><ref type="bibr" target="#b4">Buonadonna et al. 2005;</ref><ref type="bibr" target="#b11">He et al. 2006]</ref>, indicates that Node Failure, Node Reboot and Link Failure are common occurrences <ref type="bibr" target="#b28">[Wachs et al. 2007]</ref>. For example, during the unwired wine deployment <ref type="bibr" target="#b3">[Beckwith et al. 2004]</ref>, researchers reported data delivery rates of over 90% in the laboratory but only 77% in the real deployment due to node and link failures. In a surveillance deployment <ref type="bibr" target="#b2">[Arora et al. 2004]</ref>, extreme environmental conditions caused node failures affecting the entire network. A WSN based industrial monitoring system deployed in the North Sea was subject to temporally correlated node failures <ref type="bibr" target="#b15">[Krishnamurthy et al. 2005</ref>]. The developers of the Great Duck Island experiment reported significant packet loss due to node failure <ref type="bibr" target="#b26">[Szewczyk et al. 2004]</ref>.</p><p>A number of researchers have proposed techniques for detecting failures in WSN deployments. Most existing solutions, such as, Sympathy <ref type="bibr" target="#b22">[Ramanathan et al. 2005]</ref>, Memento <ref type="bibr" target="#b24">[Rost and Balakrishnan 2006]</ref>, and Residual Energy Scan <ref type="bibr" target="#b29">[Zhao et al. 2002]</ref>, rely on a proactive approach whereby each node maintains a debugging agent which reports node and link status periodically. The proactive approach suffers from three drawbacks. Firstly, it incurs computational and communication costs at the nodes which significantly shorten network lifetime. Secondly, it suffers from significant latency since status information is only sent periodically. Thirdly, it relies on the assumption that node and link behavior are completely deterministic and can be controlled locally.</p><p>Recently, some researchers have proposed the use of passive information collection for the purpose of failure detection <ref type="bibr" target="#b18">[Liu et al. 2010;</ref><ref type="bibr" target="#b10">Guo et al. 2009;</ref><ref type="bibr" target="#b5">Chen et al. 2008</ref>]. These proposals are based on the idea that information useful for failure detection can be extracted from regular data packets sent to the Sink node. Unlike the proactive approach, the passive approach does not incur significant network overhead. However, it depends on the Sink node using non-deterministic means of inferring the operational status of nodes and links based on the data collected and a network model. As a result, the proposals suffer from poor accuracy and do not scale well with network size.</p><p>Herein, we propose a novel framework, named Sequence Based Failure Detection (SBFD), for detecting WSN failures. SBFD combines lightweight in-network packet tagging and server-side storage-intensive computation. Nodes piggyback path checksum tags onto all regular data packets going to the Sink node. Each node handling the packet updates the tag with its own node ID by means of the Fletcher checksum algorithm. The resultant path checksum is lightweight in terms of communication overhead and is efficient in terms of node computation. The path checksum is inspected on arrival at the Sink. A Network Database (NDB) is used to deterministically deduce the packet path from the path checksum. On detecting a Persistent Path Change, the Sink node injects a series of control messages into the network. Based on the received responses to these control messages, the Sink identifies, classifies and reports the failure.</p><p>To the best of the authors' knowledge, SBFD is the first work to propose lightweight in-network path checksum tagging with server-side path deduction and network failure detection. The approach has three major advantages. Firstly, it is lightweight in terms of communication and processing costs and so is suitable for implementation in resource-constrained WSN nodes. Secondly, because of the distributed nature of SBFD, it is highly accurate in terms of failure detection even for very large networks. Thirdly, it can detect faults with low latency.</p><p>We outline the overall contributions of this work as follows:</p><p>Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":3 -A framework (SBFD) for fault detection which operates on top of most greedy multihop routing protocols is proposed. By greedy we mean WSN routing protocols that always select the best path based on the routing metric, such as hop count or/and connectivity, for example CTP <ref type="bibr" target="#b9">[Gnawali et al. 2009]</ref> or Arbutus <ref type="bibr" target="#b21">[Puccinelli and Haenggi 2010]</ref>. The framework does not impose any special requirements or restrictions on the underlying network protocol. -An algorithm for recording a packet path, based on the Fletcher checksum algorithm, is described. The method generates a path checksum and can be efficiently implemented in resource-constrained sensor networks. -An algorithm for packet path deduction based on the path checksum is presented.</p><p>-Algorithms for accurate detection of Node Failure, Node Reboot and Link Failure based on analysis of packet path data are presented. -The accuracy of SBFD is evaluated with a small testbed deployment.</p><p>-The performance of SBFD, and its associated algorithms, is assessed in terms of communication and computation costs and their impact on node lifetime. -The scalability of SBFD is assessed in simulations of large networks of various types scenarios. -The performance of SBFD is compared with that of previous proposals.</p><p>The remainder of the paper is organized as follows. Section 2 summarizes the definitions and notation used throughout the paper. Section 3 contains the problem statement. The proposed system is presented in detail in section 4. Section 5 assesses the performance of the system both in a test-bed and in simulation. Related work is discussed in section 6 and section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">DEFINITIONS AND NOTATION</head><p>The following definitions are used in the paper:</p><p>-Source Node: A Source Node (SN) is a node within the network which sends its own sensed data to the Sink Node. </p><formula xml:id="formula_0">(i) = P new (i).</formula><p>-Suspect Link: The Suspect Link (SuL) is the link between the DN and the SuN, i.e.</p><p>the SuL is P old (i -1) → P old (i), where P old (i -1) is the DN and P old (i) is the SuN -Idle Node &amp; Link: Idle nodes or links are those which do not take part in data collection, either as SNs or RNs or DRNs, for prolonged periods of time. Figure <ref type="figure" target="#fig_0">1</ref> illustrates the above definitions. The nodes in the monitored area are SNs, the remainder are RNs and Node 0 is the Sink. The Network Size N is 16. The Mean Connectivity d µ is 1.53. Based on this, the network can be viewed as Sparse. The Network Length h is 7 as the farthest node (i.e. node 1) is 7 hops away from the sink. The original path for packets from Node 2 to the Sink was {2,4,9,10,12,14,16,0}. After Node 10 fails, the path becomes {2,4,9,11,13,14,15,0}. For this path change, Node 9 is the Divergent Node (DN) and Node 10 is the Suspect Node (SuN). The link between Nodes 9 and 10 is the Suspect Link (SuL).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROBLEM STATEMENT</head><p>Failures in WSN deployments can be broadly classified into the following two groups <ref type="bibr" target="#b10">[Guo et al. 2009</ref>]:</p><p>Data Failure: A network experiences a Data Failure whenever a Source Node performs the task of sensing erroneously. As a result, the system fails to accurately report the true underlying physical quantity being monitored. In-network data validation, Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":5 server-side outlier detection and model based methods are the main tools for dealing with such failures.</p><p>Network Failure: Network Failures can occur due the sudden death of a node, intermittent radio connectivity, packet-loss due to routing failure, and so on. More precisely, a Network Failure can be classified as either:</p><p>(1) Node Failure: Since nodes in WSNs are often unattended in remote locations, Node Failures may occur due to component failure, node destruction by an external event, or a sudden depletion of stored energy. (2) Link Failure: Links in WSNs are often failure-prone due to temporary blocking by moving external objects, abrupt changes in the radio environment, or temporary interference from other radio sources. Link Failure can cause network partition.</p><p>(3) Node Reboot: Apart from Node and Link Failure, a network may experience repeated Node Reboot due to energy depletion or software malfunction.</p><p>In order to effectively maintain and operate a deployed network it is important to detect network failures. Such failures might cause network partition if they are not detected, localized and corrected. Therefore, the problem addressed in this work is to detect and identify network failures, specifically Node Failures, Link Failures and Node Reboots, with high accuracy, low network overhead in terms of processing and communication costs at the nodes, and low latency. The solution should be scalable so that it is effective and efficient in large networks.</p><p>In this paper we assume that:</p><p>-The nodes send application data to the Sink regularly using a multi-hop routing protocol. -The timing of data transmissions to the Sink is not known in advance. For example, some nodes might send data regularly while others might not send data to the Sink for long periods. -A suitable routing protocol, for example CTP <ref type="bibr" target="#b9">[Gnawali et al. 2009]</ref> and Arbutus <ref type="bibr" target="#b21">[Puccinelli and Haenggi 2010]</ref>, that can handle multi-hop data forwarding in the face of unstable wireless connectivity is active. -The Sink Node is a high powered node, in terms of processing, storage and energy supply. -Each node in the network has a unique node ID.</p><p>-The network topology is known initially.</p><p>-Nodes can leave and join the network.</p><p>-Nodes are static. -There is no security threat from an external attacker which can cause node misbehavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PROPOSED SYSTEM</head><p>The following subsections describe the proposed system. Subsection 4.1 presents a system overview. The subsequent subsections are dedicated to in-depth descriptions of the main components of the framework. The special case of low data rate networks is dealt with in Section 4.6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Framework Overview</head><p>The SBFD framework is depicted in Figure <ref type="figure" target="#fig_2">2</ref>. The framework consists of four main components:</p><p>- IPT is performed by the nodes in the network. NPA and FDI are performed by, and the NDB is stored at, the Sink Node.</p><p>During normal network operation, IPT causes a path checksum to be added to all packets sent from SNs to the Sink. Nodes on the routing path of the packet update the path checksum using their node ID and the current path checksum as inputs to the Fletcher checksum algorithm. When a packet arrivals at the Sink, the path checksum is used to determine the packet path by means of look-up in the NDB. The NDB is pre-populated with the paths and path checksums for the network based on its known topology and NPA. The Sink updates the statistics for the packet path in the NDB. The FDI module inspects the NDB to determine if the network path statistics have changed. If they have, the FDI module reviews the NDB path information to determine if a fault is likely. If a fault is suspected, the FDI module sends control messages to the effected nodes. Based on the responses to these control messages, the Sink determines if a fault has occurred or not. If a fault is detected the location and type of the fault are reported. The types of faults detected are Node Failure, Link Failure and Node Reboot. Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">In-network Packet Tagging</head><p>IPT appends packet path information to all data packets sent from all SNs to the Sink. The goal of IPT is to allow the Sink to efficiently monitor activity in the network.</p><p>All SNs are required to append their node ID and a path checksum to all packets sent to the Sink. The path checksum consists of R K-bit data words (RK bits). The SN sets the initial path checksum to the value of its node ID, i.e., c(0) = x i , where c(i) is the value of the checksum at hop i. Later, on receipt of the packet, every RN recovers the current value of the path checksum c(i) and generates a new checksum value c(i + 1), using the Fletcher checksum algorithm, as follows:</p><formula xml:id="formula_1">c(i + 1)[0] = |c(i)[0] + x i | M (1) c(i + 1)[j] = |c(i)[j] + c(i + 1)[j -1]| M for j = 1 to R -1<label>(2)</label></formula><p>where c(i)[j] is word j of checksum c at hop i, x i is the ID of the RN, |.| M is the modulus operator and M is the checksum modulus.</p><p>The node replaces the current path checksum in the packet with the new checksum, the packet Cyclic Redundancy Check (CRC) (or Forward Error Correction information) is re-calculated and the packet is forwarded to the Sink, if necessary via a neighboring RN.</p><p>The Fletcher checksum algorithm was originally introduced for checking that blocks of stored or transmitted data were recovered or received correctly <ref type="bibr" target="#b8">[Fletcher 1982</ref>]. The Fletcher algorithm was chosen for this work since its value depends on the sequence of the IDs. Summation checksums only add node IDs together, which gives the same checksum for different paths. For example, the paths {3,0,1,2} and {3,1,0,2} have the same simple summation checksum but different Fletcher checksums. Detecting these changes in the routing path are important in the FDI step.</p><p>Herein, we use R = 2, K = 8 and M = 255, giving a 16-bit checksum. This ensures that the checksum is lightweight and is efficient to implement on a resourced constrained processor. The modulo 255 operation can be carried out simply by using a bit mask. A 16-bit checksum provides good disambiguation between paths. If the paths and node IDs are random, a 16-bit checksum gives a 0.001526% probability of two paths having the same checksum. Typically, in WSNs, node IDs are 16-bit allowing a network of 65,535 nodes with unique IDs. In this case, the checksum input is obtained by XORing the Most Signifiant Byte with the Least Significant Byte of the Node ID. The final algorithm is defined formally in Algorithm 1.</p><p>The Algorithm requires a fixed number of basic operations (i.e. 13). Every node computes the partial checksum based on two inputs: the previous checksum and its own Node ID. The process is independent of network parameters. Hence, the complexity of the Algorithm is O(1). In other words, it runs in constant time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Network DataBase</head><p>The NDB stores statistics on the paths used by packets arriving at the Sink and on the activity of the nodes. The Network DataBase consists of two tables -the Path Activity Table (PAT) and the Network Activity Table <ref type="bibr">(NAT)</ref>.</p><p>The PAT holds a record for all observed packet paths from all SNs to the Sink. Each record contains the following fields: sn_id, path_checksum, timestamp, freq, path_list where sn_id is the Source Node ID, path_checksum is the value of the Fletcher checksum when the packet arrives at the Sink, timestamp is the arrival time of the most recent packet that used the path, freq is the number of times that the path was used since network initialization and path_list is the list of the IDs of the nodes on the The NAT stores a single record for every node in the network. Each record contains the following fields:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>node_id, timestamp</head><p>where node_id is the Node ID and timestamp is the time that the node was alive either because of its SN or RN activity. The unique database key is node_id.</p><p>The information in the NAT can be extracted from the PAT but updating both the PAT and NAT as each packet arrives significantly reduces processing time at the Sink.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Network Path Analysis</head><p>The NPA works in association with NDB. Specifically, it is responsible for initializing and updating the NDB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1.">NDB Initialization.</head><p>The PAT is populated by generating records for the most probable packet paths in the network using Algorithm 2. For each SN, a set of possible packet paths from the SN to the Sink is generated based on the network topology. The paths are generated subject to the constraint that no generated path may be longer than the shortest path from the SN to the Sink plus r hops, where r is the search radius.</p><p>In general, the number of alternate paths (determined by r) that need to be considered is low since routing algorithms are specifically designed to use optimal paths based on the specific greedy routing protocols used. For each node a pre-defined number, r , of 1-hop nodes are selected. The search is expanded from each of these selected nodes to a maximum of r of their neighbor nodes and so on. The process continues until the Sink is reached. The number of all possible of paths from a specific SN to the Sink depends on two parameters: r, the number of neighbors to be selected and h, the network length. Thus the Algorithm has complexity O(r h ). For each path generated, a PAT record is created including the SN, path checksum and path list. The timestamp and frequency fields are set to zero. The NAT is also initialized based on the topology. The timestamp field is set to zero for all records. if T owardsSink(V N, x i , Sink) == 1 then 10:</p><formula xml:id="formula_2">P i = P i ||V N ||x i V N = x i N N [] = getNextNode(VN,r) 11: else 12: x i = getNode(NN[]) 13: end if 14: end while 15: until P i .Length() ≤ (h -1) 4.4.2. NDB Update.</formula><p>The NPA inspects the path checksums of all packets arriving at the Sink. Based on this, it updates the path statistics in the NDB. The goal is to maintain accurate, low latency information on the active packet paths in the network. The entire IPT and path deduction process is illustrated in Figure <ref type="figure" target="#fig_4">3</ref>.</p><p>When a packet is received at the Sink, and passes the CRC check, the sn_id and path_checksum tags are extracted from the packet and used to look up the corresponding record in the PAT. If a corresponding PAT record exists, the timestamp field is updated with the current time and the freq field is incremented. In addition, the timestamp fields are updated in the NAT records of the SN and all of the nodes in the path of the latest packet. If a corresponding PAT record does not exist, the SN, path checksum and time of arrival are stored in a temporary table on the basis that the information may be spurious. If the SN and path checksum recur, the NPA module performs an expanded search for paths originating at that SN. If the path is resolved, a new entry is added to the PAT. If not, the NPA module sends a trace path control message to the SN to resolve the path.</p><p>4.4.3. Network Dynamics. The NDB must be updated when nodes join or leave the network. When joining the network, new nodes must notify the Sink of their ID and 1-hop connectivity. The NPA module must add the node to the NAT and generate records for the new network paths in the PAT. Path generation proceeds in a similar way to that described in Algorithm 2 except that the SNs are constrained to only include the new node and those SNs further from the Sink. When a node leaves the network, the NAT is updated and all records involving the node ID are deleted from the PAT. If a node fails permanently, the NDB can be updated in a similar fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4.">Implementation Issues.</head><p>There is obviously a trade-off between the size of the NAT and computational complexity at the Sink in terms of on-the-fly path searches. A high value of r leads to a large NAT with many unused paths (freq= 0) but low operational computational complexity. Conversely, a low value for r leads to low storage requirements but higher operational computational complexity. Since WSNs are battery powered and targeted at long network lifetime, the number of packets arriving per second is typically low. Therefore, provided that a powerful Sink node is used, on-the-fly path searches are not particularly onerous in terms of computational complexity. NAT size can be reduced during operation by removing paths which have never been observed, i.e. freq= 0, or have not been observed for a long time, i.e. timestamp≪current_time.</p><p>Clearly, the size of the NDB must be reasonable for practical implementation. The average size of each field in the PAT and the NAT is {2, 2, 4, 4, h} and {2, 4} bytes, respectively. The average path field is a sequence of 2 byte node IDs where the average number of nodes in the path is half the Network Length (h/2). Clearly, the total size of the NAT is 6N bytes. The total size of the PAT is can be estimated as follows. If α is the fraction of SNs in the network then αN is the total number of SNs. For each SN, and only considering r = 0, there are (d µ /2) h/2 paths since, on average, there are d µ /2 links closer to the Sink at each hop and a total of h/2 hops to the Sink. For a small r, the total number of paths from a SN to the Sink stored in the database is, on average, approximately (r + 1)(d µ /2) h/2 . The total size S of the NDB in bytes is then:</p><formula xml:id="formula_3">S = αN (r + 1)(d µ /2) h/2 (h + 12) + 6N<label>(3)</label></formula><p>For a circular network of N = 2, 000 nodes with the Sink in the center, we have α = 0.5, h = 15, d µ = 10, r = 5 and total storage requirements of S = 5.7 GB. Today, modern database systems are capable of efficient data handling in the range of TBs without significant performance penalty [Oracle Database 2012],[MySQL Reference Guide 2012]. For larger networks, clustering techniques can be used to reduce the number of paths and so decrease the data storage requirements. Moreover, path computation and storage can be done off-line before the actual network becomes operational. Since IPA operates on copies of the received packets, IPA has no functional impact on the application software and can run concurrently with it at the Sink. IPA can be scheduled so as to only use processor cycles which are not used for the application. In this way, IPA has no impact on the latency of application processing at the Sink.</p><p>Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":11 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Fault Detection &amp; Identification</head><p>The Sink performs FDI in two steps. The first step, Fault Detection (FD), identifies possible faults in the network by monitoring the NDB. The output FD is a list of possible faults, called the Suspect List (SL). The second step, Fault Identification (FI), uses this SL to localize and classify faults. It tests its hypothesis by sending control packets to nodes within the network. FI seeks to identify three types of failure -Node Failure, Node Reboot and Link Failure.</p><p>4.5.1. Fault Detection. The overall FD algorithm is presented in Algorithm 3. FD consists of two steps: Persistent Path Change (PPC) detection and Elimination.</p><p>On arrival of each packet at the Sink and successful CRC checking, the Sink searches the PAT for all records with matching SN IDs to obtain the path of the most recently received packet from that SN. If the path of the received packet (P new ) matches that of the most recently received previous packet from that SN (P old ) then there has been no path change, there is no evidence of a new fault and FD moves on the next received packet. Otherwise, the Sink temporarily stores the old path checksum C old and the new path checksum C new and places a watch on the SN ID for the next T th time units where T th = mf where m is a multiplicative sensitivity factor (&gt; 1) and f is the sensing frequency of the SN (line number 5). After T th time units, the Sink checks whether any new packets have been received from the SN via the old path. If one or more packets have been received using the old path then the change was not persistent, there is Once a Persistent Path Change has been detected, FD identifies the Divergent Node, the Suspect Node and the Suspect Link (line number 17). As illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, the Divergent Node is the node which is the last common node in two paths from a single SN to the Sink. The Suspect Node is the node immediately after the DN in the old path. The Suspect Link (SuL) is the link between the DN and the SuN.</p><p>Only one SuN and one SuL are considered since it is assumed that only one node or link failure can occur on a single path at a time. If multiple failures do occur simultaneously on a single path, only the failure closest to the SN will be detected. However, it is likely that the other failures will be detected later due to changes in other paths from different SNs.</p><p>The FD module retrieves the NAT record for the SuN and compares the timestamp to the current time. If the SuN has been active in the previous T th time units then it must be used as part of a different path. As a consequence, the node must still be active and is eliminated as an SuN (i.e. SuN=NULL, line number 20, 21). If the SuN is eliminated, the timestamp of the first node in the SuL pair (i.e. the DN) is checked in the NAT. If both sides of the SuL have the same timestamp in the NAT then it is very likely that a single packet passed through both nodes and used the SuL. In this case, the SuL is also eliminated (i.e, SuL=NULL, line number 23). If processing time allows, the PAT entries of the NDB can be searched for the occurrence of the SuL in other paths within the last T th . This final step is time consuming and is not used in the implementation described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2.">Fault Identification.</head><p>The overall FI algorithm is presented in Algorithm 4. FI uses the values of DN and SuN obtained using Algorithm 3 as inputs. The algorithm consists of four steps.</p><p>The first step is to test for Link Failure. A response_request control packet is sent from the Sink to the Divergent Node. The response_request includes two parameters: req_avoid_node and resp_via_node. Both parameters are set equal to the SuN ID. When the packet is routed to the target node, the RNs avoid sending it via the req_avoid_node. When the packet arrives at the DN, the DN responds by sending a response packet to the Sink via the resp_via_node (line number 4). Beyond the req_avoid_node and resp_via_node, the path to and from the target node is unspecified and is decided by the routing algorithm. After sending the response_request, the Sink waits T resp time units for the response packet to arrive. If the response packet is received within that time, the SuL and SuN are proven to be active and FI terminates (line number 6). If the packet is not received within that time, FI moves on to the second step.</p><p>The second step tests for Node Inactivity. A response_request packet is sent to all 1-hop neighbors of the SuN, excluding the neighbor (DN) already tested in the first step. Since, in some highly dense networks (i.e. for higher value of d µ ), the number of 1-hop neighbors may increase the message overhead, the Algorithm restricts the total number of 1-hop nodes to a pre-defined maximum value Q max . This is implemented in line 8. Again, the req_avoid_node and resp_via_node parameters are set equal to the SuN. The Sink waits T resp time units for the response packets to arrive. If one or more response messages are received within that time, the SuN is proven to be active and the SuL is proven to have failed. Link Failure is reported and FI terminates (line number 11). If no packet is received within that time, the SuN is shown to be inactive and FI moves on to the third step.</p><p>The end if 21: end if within T resp time units, the node is deemed to have suffered Node Failure (line 18). If a response is received within that time, the node is considered to have undergone a Node Reboot (line 16). In both cases, the FI result is reported.</p><p>The Fault Identification (FI) Algorithm issues a maximum of (Q+2) control messages (i.e. in the case of Node Failures or Reboots) from the Suspect Node (SuN) and its 1-hop nodes towards the Sink in each round of fault detection. The value of Q is conditionally set as has already been explained. Therefore, the algorithm incurs complexity O(1) which is independent of network parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Low Data-rate Network</head><p>SBFD detects faults in networks with periodic data transmission to the Sink. In most applications <ref type="bibr" target="#b3">[Beckwith et al. 2004;</ref><ref type="bibr" target="#b26">Szewczyk et al. 2004;</ref><ref type="bibr" target="#b6">Corke et al. 2010</ref>] data collection periods are short. However, in some applications the data reporting rate is very low. To cope with such scenarios, we employ the concept of a heartbeat message <ref type="bibr" target="#b24">[Rost and Balakrishnan 2006]</ref>. At regular intervals, every SN computes the time difference T dif f between the current time T now and the time it sent its last packet T last . If the time difference T dif f goes beyond a pre-defined threshold T th the node realizes that it did not send any data for a prolonged period. As a result, it sends a heartbeat message to the Sink. The Checksum field of the message is treated exactly in the same manner as a regular data packet. Algorithm 5 summarizes the process. The path deduction and fault identification processes are the same as described before.</p><p>Algorithm 5 Heartbeat Message 1: System variable:</p><p>T th , The predefined value of time threshold to verify "No traffic for long time" 2:</p><formula xml:id="formula_4">T dif f = T now -T last 3: if T dif f &gt; T th then 4:</formula><p>heartbeatmsg.Destination=Sink heartbeatmsg.sendMessage() T last = T now 5: end if</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION</head><p>The efficiency and accuracy of the SBFD system was evaluated via a testbed implementation and in comprehensive simulations. A performance comparison with existing solutions were also conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Implementation</head><p>SBFD was implemented in nesC, the language for TinyOS, an open source operating system for WSNs <ref type="bibr">[TinyOS 2010</ref>]. TinyOS version 2.1.1 and nesC compiler version 1.3.1 were used. The Collection Tree Protocol (CTP) was used in the routing layer. The Crossbow TelosB mote TPR2400 <ref type="bibr" target="#b7">[Crossbow 2012</ref>] was used in the testbed for both SNs and RNs. The TelosB mote has a 8MHz microcontroller, RAM size of 10 KB, flash memory of 48 KB and integrated temperature, humidity and light sensors. The radio was a 2.4 GHz IEEE 802.15.4 Chipcon Wireless Transceiver with a data rate of 250 kbps. The Sink node was connected via USB to a PC server running Oracle Express Edition 10g, version 10.2.0.1.0, supporting the NDB. Linux 3.0.0-17-generic was used for the OS of the server. The Java based MessageReader was used to capture packets from the radio network for processing by the NPA module. On reception of each packet, MessageReader posted it to the NDB. PPC detection was automated with the aid of a row-level trigger in the appropriate entries of the NDB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Testbed Results</head><p>This section reports on the performance of SBFD in a real network testbed.</p><p>5.2.1. Accuracy. The accuracy of SBFD was evaluated using a small testbed network into which failures were manually inserted. Accuracy is defined as the ratio of the total number of faults detected correctly to the total number of faults inserted into the network. A network of 10 nodes was set-up as shown in Figure <ref type="figure">4</ref>. The network contained both SNs and RNs. The Sink (Node ID 100) was located in the middle of the network. The SNs sensed temperature every 5 seconds and sent the data to the Sink. The testbed ran for almost 50 minutes. On average each SN sent 569 data packets to the Sink. For PPC detection T th was set to 15 seconds.</p><p>All three failures types were manually inserted into the network. A Node Failure was inserted by removing the battery from a node. Pressing the reset button on a node was used to induce Node Reboot. To insert Link Failure, an indirect method was used. The node on the end of the link was physically moved so that it could not communicate with its previously neighboring node. A total of 10 failures were inserted into the network during operation.</p><p>Table <ref type="table">I</ref> lists each fault event, the time at which it was inserted and the consequences in terms of path change observed at the Sink using SFBD. Figure <ref type="figure">5</ref> shows example variations in the path checksums receiver for four SNs with time. The corresponding paths and checksums are given in Table <ref type="table" target="#tab_4">II</ref>. These observations indicate that the Sink was successful in detecting Persistence Path Changes (PPC) for most of the Network Failures.</p><p>The accuracy of SFBD during the experiment is summarized in Table <ref type="table" target="#tab_5">III</ref>. The overall accuracy achieved was 90%. Only 1 fault, a Node Reboot (at time 34), was not detected. This was due to the fact that RN 560 received packets from its neighboring SN 570 every 5 seconds. RN 560 rebooted successfully before a new packet arrived from the SN. As a result, no path change was not observed at the Sink. The results indicate good accuracy for the method on a small network. Simulations were conducted to assess its performance on a large network, as detailed in section 5.3.  SN and Sink with two RNs placed between them. The SN could communicate with the Sink via either RN. The sensing period of the SN was set to a specific value and Node Reboots were manually applied to the RNs. Reboots were inserted individually and the node affected was selected randomly. The experiment was repeated 5 times with each round taking 15 minutes and the results averaged. The experiment was repeated for sensing periods from 10 s to 250 ms. Table <ref type="table" target="#tab_6">IV</ref> presents the experimental results. We manually measured the reboot time as 5 seconds. Clearly, accuracy of detection improves as the sending period decreases. Specifically, the accuracy is just greater than 80% when the sensing period is equal to the reboot time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Impact on Node</head><p>Performance. This section describes experiments conducted to determine SBFD's impact on node lifetime and its memory requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on Relay Node (RN).</head><p>A network was set-up as shown in Figure <ref type="figure" target="#fig_7">6</ref>. The SNs and RNs were placed 30m apart. In Link X, the RN (R1) does not perform IPT. In Link Y, the RN (R2) does perform IPT. Environmental temperature and node internal voltage level data were collected by the SNs (S1 and S2) and sent to the BS via their respective RNs (R1 and R2) every 2 seconds. The packet payload lengths were 10 and 12 bytes in Link X and Y, respectively. The nodes were loaded with fresh batteries and the network was run until the interval voltage level of a RN went below its minimum operating voltage (2.1V) <ref type="bibr" target="#b7">[Crossbow 2012</ref>]. The collected packets were then analyzed to evaluate the impact of IPT on node lifetime. Since all nodes operated under identical conditions, any variation in the number of packets processed or voltage levels were a direct result of the processing and transmission overhead of IPT.</p><p>The lifetimes of the links are summarized in Table <ref type="table" target="#tab_7">V</ref>. Link X and Y processed 210,871 and 209,903 packets, respectively, before their associated RNs ran out of energy. Overall, Link Y forwarded only 0.46% less packets than Link X. The internal voltage levels of both RNs are plotted against time in Figure <ref type="figure" target="#fig_8">7</ref>. The RN voltage levels show almost identical trends. These results show that IPT has very low overhead in terms of lifetime reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on Dedicated Relay Node (DRN).</head><p>A second network was deployed using the same topology as shown in Figure <ref type="figure" target="#fig_7">6</ref>. In this case, the SNs (i.e. S1 and S2) power supply was from the mains. The intermediate nodes (i.e. R1 and R2) were simply Dedicated Relay Nodes (DRN), that is they did not perform sensing. Since the SNs could not directly transmit packets to the Sinks, a persistent discontinuation of packet reception from a specific SN at the Sink indicated the intermediate DRN's death due to energy depletion. We conducted 3 rounds of experiments. In each round the DRNs were loaded with fresh batteries and the lifetime of the network was assessed in terms of the number of packets received at the Sink. The results are shown in Table <ref type="table" target="#tab_9">VI</ref>. The number of data packets processed by each network was higher than in the RN case (i.e. Table <ref type="table" target="#tab_7">V</ref>). The results show that the average node lifetime penalty due to IPT was 0.74% in terms of the number of packets processed by the DRNs. It is important to note that the impact of IPT is similar in both the RN and DRN cases. This shows that IPT incurs very low overhead and does not significantly reduce network lifetime.</p><p>Impact on Node Memory. To assess the impact of IPT on node memory, two separate versions of a program for data collection were written and installed in two nodes. The only difference between the versions was that one supported IPT and the other did not. Both programs used CTP as the multi-hop routing protocol. As shown in Table <ref type="table" target="#tab_9">VII</ref>, including IPT was found to increase RAM size by 2 bytes (0.1%) and ROM size by 304 bytes (1.01%). It is clear that SBFD has negligible impact on node memory size.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Simulation Results</head><p>This section considers the performance of SBFD in large networks.</p><p>For the purposes of experimentation, the network testbed was replaced by TOSSIM, a discrete event network simulator which compiles programs directly from TinyOS code <ref type="bibr" target="#b17">[Levis et al. 2003</ref>]. The real sensing data was replaced by a dummy sensor function. The simulation parameters are listed in Table <ref type="table" target="#tab_10">VIII</ref>. The default values of all MAC layer parameters were used with the exception of maxIterations which was initialized to 10 since the default value (0) sets the number of radio back offs to infinity. A noise trace collected from Meyer Library, Stanford University was used to model RF noise and interference. The topology generator and the fault modeler were written in Python 2.7.  <ref type="table" target="#tab_11">IX</ref>. In all cases, the Sink node was placed in the middle of the network with ID 1. Node IDs were then allocated sequentially. Nodes with even IDs were designated as SNs. Nodes with odd IDs were designated as DRNs. Hence, the SN Ratio α was 0.5.</p><p>In each simulation, the number of faults injected was set as a percentage of the network size N . Experience from WSN deployments, such as <ref type="bibr" target="#b2">[Arora et al. 2004;</ref><ref type="bibr" target="#b3">Beckwith et al. 2004]</ref>, suggests that Node Failure and Link Failure are more likely than Node Reboot. Hence, over the course of the simulation, 10% of nodes suffered Node Failures, 10% of links suffered Link Failures and 5% of nodes suffered Node Reboots. The timing Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":21 of each fault was determined randomly. Three rounds of simulation were performed for each topology and the results were averaged. SNs sent a packet to the Sink periodically every 250 milliseconds. The simulation duration was 100 seconds. On average, each SN transmitted 395 packets to the Sink. The network experienced a Packet Drop Rate (PDR) of around 4.2% because of the noise modeled in the simulation. SBFD was applied, as described in Section 4.5 with m = 3 and T th = 750ms.</p><p>Tables XI and XII and Figure <ref type="figure">8</ref> report the accuracy of fault detection. Overall detection accuracy is expressed as a weighted average taking into consideration the probability of each fault type. We consider the results for the sparse topologies first. Detection accuracy for Node Failure was bounded between 88.8% and 93.3% and was unaffected by network size. Even for large values of N (i.e. 250), accuracy was greater than 90%. The same trend was noticeable for both Link Failure and Node Reboot faults. The overall accuracy was close to 91.5% for all values of N . The high accuracy of SBFD, regardless of network size, is due to the distributed nature of IPT and the localization of faults using control messages in the FI step. Detection accuracy for Dense topologies was higher for all types of faults. In the case of Node Failures, for instance, accuracy ranged between 91.6% and 97.5%. As for sparse topologies, the accuracy in dense networks was not affected by network size. Figures for overall accuracy were close to 93.9%, giving an average improvement of 2.3% relative to the results for the Dense topologies. The improvement is due to the higher number of alternate routes in the Dense networks which allows for better fault discrimination using control messages.</p><p>Two further factors were found to impact on overall accuracy. Firstly, since the topology was built randomly there were some Idle Nodes and Idle Links, especially at the network edge. Clearly, failures in Idle Nodes and Links cannot be detected based on Persistent Path Change. In the case of fixed rate transmissions from the SNs to the Sink, Idle SNs can be detected by checking the NAT for SNs with timestamps greater than the transmission period. This technique could be applied in the simulation but was not used since, to allow more general usage, the algorithm assumes that the SN packet transmission rate is not known a priori (see Section 3). Alternatively, the concept of periodic heartbeat message as described in Section 4.6 could be exploited to detect these Idle Nodes. We did not apply this concept in simulation since SBFD is primarily designed for WSN applications with frequent data reporting. Secondly, loss of control messages and responses impacts on detection accuracy. Thus detection accuracy is somewhat dependent on the average network Packet Drop Ratio (PDR). To investigate this further, we performed a series of simulations with a fixed network (dense N = 150, see Table <ref type="table" target="#tab_11">IX</ref>) and increasing workload, so as to introduce congestion and increase PDR. Simulation duration, noise injection and network protocols were identical to the previous simulations. Workload W was defined as:</p><formula xml:id="formula_5">W = N 1 T s α<label>(4)</label></formula><p>where T s is the sensing period. The workloads used in the simulations are listed in Table <ref type="table" target="#tab_14">XIII</ref>. PDR and overall fault detection accuracies were measured and are plotted in Figure <ref type="figure" target="#fig_10">9</ref>. The figure shows that higher network traffic leads to higher PDR which reduces accuracy. Initially, PDR was 4.1% and accuracy was 96.5%. A PDR of 21.2% is associated with an accuracy of 81.2%. This result indicates that SBFD's accuracy also depends on the routing performance of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2.">Message</head><p>Overhead &amp; Detection Latency. In Section 5.2.2, we considered the impact of IPT on node lifetime. The Network overhead of FI is also affected by the number of control messages sent by the Sink when Suspect Nodes and Links are detected. This Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":23  The number of control messages sent by the Sink is presented in Tables XIV and XV for the Sparse and Dense networks respectively. Two scenarios are considered: a network simulation with zero faults and a simulation with faults injected as described previously.</p><p>When there are no faults, SBFD sends few control messages because the false positive rate at the Fault Detection (FD) stage is typically low. Occasionally false positives are due to a node's parent change because it discovered a better parent in terms of connectivity. This is due a greedy approach in the underlying routing protocol. These unnecessary control messages constitute an average overhead of 0.01% and 0.04% in terms of network traffic for Sparse and Dense networks, respectively, as shown in Figure <ref type="figure" target="#fig_11">10</ref>. After subtracting this baseline activity, SFDB, on average in the faulty network simulation, sends 2.3 and 3.3 control messages per fault detected in Sparse and Dense networks, respectively. The number is higher for Dense networks since the FD algorithm generally issues d µ control messages to detect Node Failure and Reboot faults. For higher values of d µ the algorithm restricts it to a maximum of Q max .</p><p>In the presence of faults, the control message overhead was 0.164% and 0.239% of the total data traffic at the SN for the Sparse and Dense networks, respectively. Overall, SFDB incurs very low overhead in terms of additional network traffic.</p><p>The latency of fault detection in SBFD was also assessed. It is primarily bounded by T th + T search where T th is described in section 4.5 and T search is the processing delay at the Sink which is dominated by the NDB look-up during NPA. Since T th = mf , the value of T th largely depends on the sensing frequency which is typically set according to application requirements. NDB look-up delay was measured for the first 100 packets sent by 5 randomly selected SNs in the Dense network simulation with N =400. The size of the NDB for this network was 100.4 MB. The empirical cumulative distribution funciton (ECDF) of the search time is shown in Figure <ref type="figure" target="#fig_0">11</ref>. In over 80% of cases, the  delay was in the range of 1 ms to 5 ms. The results indicate that fault detection latency in SBFD is not significantly affected by the NDB search delay even for a large network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Comparative Study</head><p>This section presents a performance comparison between SBFD and other state-ofthe-art proposals for fault detection in WSNs. Comparison was performed by means of network simulation using TOSSIM <ref type="bibr" target="#b17">[Levis et al. 2003]</ref>, and using the simulation parameters in the Table VIII and the fault model described in Section 5.3. SBFD was compared with Sympathy <ref type="bibr" target="#b24">[Rost and Balakrishnan 2006]</ref> and PAD <ref type="bibr" target="#b18">[Liu et al. 2010]</ref>.</p><p>Sympathy is based on the principal that there is a direct correlation between the amount of data collected from nodes and the presence of failures in the network. PAD, on the other hand, detects faults based on mismatches between expected and deduced paths for each data packet. Detection accuracy was used as a metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sympathy and SBFD.</head><p>Figure <ref type="figure" target="#fig_2">12</ref> shows the results, for the dense topology with varying network size N and SN ratio α. In Figure <ref type="figure" target="#fig_2">12</ref> (a) with α = 1, the overall detection accuracy of both schemes were similar for N ≤ 150, i.e. 84.2% and 87.5% for Sympathy and SBFD, respectively. With N &gt; 150, Sympathy accuracy falls to around 80%. This is because large dense networks offer a larger number of alternate paths to the Sink. If one link or node fails, the routing engine uses an alternative path without any noticeable difference in the quantity of the received data. As a result, some link and node failures were not correctly detected using Sympathy. In Figures <ref type="figure" target="#fig_2">12 (b),</ref><ref type="figure">(c</ref>) and (d) the number of DRNs is increased by reducing the value of α. This was investigated because in many real deployments the network contains SNs, RNs and DRNs. As α decreases, Sympathy accuracy reduces to 81.2%, 78.1% and 75.7%. This is 8.3%, 13.9% and 16.7% less than SBFD. This is due to the working principal of Sympathy-it detects faults based on significant deviations in expected traffic. Thus, provided there are alternative paths, it is difficult to detect faults for DRNs in Sympathy. Figure <ref type="figure" target="#fig_4">13</ref> shows the results for Sparse networks. In Figure <ref type="figure" target="#fig_4">13</ref> (a), with α = 1, the overall accuracy of Sympathy was 83.4% which is 2.3% less than SBFD. In the Sparse topology, nodes do not have sufficient alternate paths to the Sink which makes failure detection more accurate in Sympathy. Lower values of α reduce Sympathy accuracy. For α = .25, for instance, the accuracy of Sympathy reduces to 76.1% which is 13.4% lower than SBFD.</p><p>PAD and SBFD. We investigated the performance of PAD and SBFD with varying network size N and SN ratio α. Since PAD has no mechanism to detect Node Reboot, we eliminated it from our fault model. As PAD supports tree-based routing we used CTP in the routing layer of both schemes. PAD introduces a new connection variable (i.e. C i ) for detecting failures of DRNs. The results are shown in Figures <ref type="figure" target="#fig_2">12</ref> and<ref type="figure" target="#fig_4">13</ref>. Both figures show that the impact of α is not significant for PAD. For instance, the overall accuracy of PAD was 82.47% with α = 1 whereas it was 80.84% with α = .25 as shown in Figures <ref type="figure" target="#fig_2">12 (a</ref>) and (d), respectively. The overall accuracy of PAD in Dense and Sparse networks was 81.7% and 82.6%, respectively, which were 8.7% and 6% lower than SBFD. Path deduction in PAD incurs significant latency due to the synchronized, We also assessed the performance of PAD and SBFD in the presence of packet drops for a single network (i.e. Dense N = 180). We varied the workload W to introduce packet drops in the network (see Table <ref type="table" target="#tab_14">XIII</ref>). Figure <ref type="figure" target="#fig_14">14</ref> shows the results obtained. With lower PDR (i.e. below 5%) the overall accuracy of PAD and SBFD was 86% and 92.8%, respectively. When PDR fell below 12% the accuracy of PAD significantly reduced to 79.1% while it was 89.4% in SBFD. Above this, SBFD maintained an average of 12.3% greater accuracy than PAD. The main factor that influences the overall  performance of PAD is the order of each packet being maintained. In most WSN applications, the network intermittently experiences out-of-order packet delivery due to unavoidable factors such as congestion, failures of nodes/links. PDR also impacts on the accuracy of SBFD which has been discussed in Section 5.3.1. The results indicate that SBFD is more robust to packet drops than PAD.</p><p>We compared the latency of path deduction in both schemes. The results are shown in Table <ref type="table" target="#tab_17">XVI</ref>. The average latencies were 1085 ms and 2.54 ms for PAD and SBFD, respectively. Packet marking in PAD incurs higher delay since it is directly dependent on hop distance h and sensing frequency f . In this simulation the average hop distance h of the selected SNs was 5.3 and the value of f was 250 ms. In PAD, the Sink must wait for an additional (h -1) packets after receiving the first packet from a SN to deduce the observed path. In SBFD, on the other hand, the path deduction latency is primarily dependent on NDB look-up time. The results indicate that SBFD incurs very low path deduction latency in comparison with PAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK</head><p>To the best of the authors' knowledge, SBFD is the first proposal which exploits a lightweight tagging mechanism and server-side storage-intensive computational to deterministically extract packet path and to utilize this information for efficient and accurate detection of network faults.</p><p>Considerable work been conducted on fault detection for enterprise networks. Commercial tools, such as HP Openview [ <ref type="bibr">HPO 2007]</ref> and IBM <ref type="bibr">Tivoli [IBM 1996]</ref>, independently monitor servers and routers by means of periodic message exchange. These systems are very effective for large-scale enterprise networks but are not suitable for WSNs since the tools are designed to operate on high bandwidth, mains powered equipment.</p><p>A number of research papers have considered the use of bipartite graphs for enterprise network fault detection. In <ref type="bibr" target="#b12">[Kandula et al. 2005</ref>], the authors propose Shrink which uses a probabilistic inference model based on a bipartite dependency graph which assesses dependency between network components. The authors of <ref type="bibr" target="#b25">[Steinder and Sethi 2002]</ref> evaluate the relationships between links to identify faults using a combination of bipartite graphs and a belief network. The major limitation of these solutions in the context of WSNs is that they require complete a priori information on the dependencies in the network which is not feasible in a sensor network. Furthermore, they are very expensive in terms of computation and storage.</p><p>Most previous research on fault detection in WSNs uses the proactive approach whereby either a special node or debugging agent is deployed to collect information and periodic control messages are transmitted to the Sink. In the paper on Sympathy <ref type="bibr" target="#b22">[Ramanathan et al. 2005]</ref>, the authors propose a pre-deployment architecture that periodically logs communication statistics, such as the routing table, number of packets, and the level of congestion. Sympathy is based on the principal that there should be a predictable relationship between these data statistics and the number of faults in the network. Scanning residual energy to monitor the status of nodes has been investigated by many researchers, e.g., <ref type="bibr" target="#b29">[Zhao et al. 2002]</ref>. In Memento <ref type="bibr" target="#b24">[Rost and Balakrishnan 2006</ref>] every node periodically sends a heartbeat message to its parent. In order to reduce overall traffic, it uses aggregation to summarize messages. In <ref type="bibr" target="#b13">[Khan et al. 2008]</ref>, the authors propose a debugging framework, Dustminer, that identifies culprit sequences and uses them to pinpoint failures. Dustminer mainly targets soft faults in the protocol stack. In a recent publication, the authors of <ref type="bibr" target="#b14">[Khan et al. 2010]</ref> propose a remote monitoring system, Powertracer, which determines the internal health of unresponsive nodes in the network. It can effectively classify faults including node failure, link failure and frequent node reboot. The downside of Powertracer is the additional requirement for a wireless power meter in every node. For a large network, the cost of deploying Powertracer may be significant. All of these methods involve periodic message exchange (either for control or statistic passing). Thus they incur a heavy penalty in terms of lifetime reduction in resource-constrained WSNs.</p><p>Recently, passive information collection has been seen as an lightweight approach to failure detection in WSNs since it extracts information on network behavior with low overhead. LiveNet <ref type="bibr" target="#b5">[Chen et al. 2008</ref>] employs several sniffer nodes distributed throughout the network. Each sniffer node collects network meta-data. The trace files collected are merged to provide a global view of the status of the network. Deploying sniffer nodes in the network makes this scheme hard to accommodate in many applications. The concept of a sniffer node for network data collection has also been investigated by the designers of PDA <ref type="bibr" target="#b23">[Romer and Ma 2009]</ref>. PDA presents various options for trace collection, including an offline and an online approach. In the offline approach, the sniffer nodes collect both network information and application data. In the online scheme, a separate radio channel is established for the sniffer nodes. PDA has the major drawback of high message overhead and its scalability is not assessed in the paper.</p><p>A recent publication related to SBFD is PAD <ref type="bibr" target="#b18">[Liu et al. 2010]</ref>. PAD is founded upon the concept of packet marking to deduce the sequence of relay nodes. A comparison in terms of fault detection accuracy and path deduction latency is presented in Section 5.4. We distinguish our approach from PAD in the following ways. Firstly, the packet marking scheme in PAD appends two fields to regular data packets: Stamping Node ID (2 bytes) and Hop Distance (2 bytes) incurring a total overhead of 4 bytes per packet. IPT in SBFD incurs a 2 bytes overhead for storing the checksum value. Secondly, the Failure Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":29 PAD marking algorithm requires synchronization between all nodes in a path from source to sink. Synchronization must be maintained by the Sink to deduce the path from the marking scheme. This requirement poses additional complexity, particularly when a relay node processes multiple packets from different sources within the same time slot. Thirdly, to deduce a path using PAD the Sink must receive k consecutive packets from the same SN, where k is the number of hops between the SN and Sink. Thus PAD experiences higher latency in detecting a path change which, in turn, affects the overall accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS AND FUTURE WORK</head><p>There have been a number of interesting publications on fault detection in WSN. However most existing methods either reduce network lifetime due to additional message exchange, or suffer from poor accuracy due to lack of up-to-date view of activity in the network. In this paper we propose a fault detection framework named SBFD which is lightweight, accurate and scalable.</p><p>The framework was implemented in a testbed network. The accuracy of the framework was measured and found to be 90% in testbed experiments. The impact of path tagging on sensor node lifetime was found to be 0.50% and additional memory requirements were less than 1.2 %. Extensive simulation using a variety of network parameters was performed to assess the method's scalability. Detection accuracy in simulation varied from 90.7% to 92.7% for Sparse networks while for Dense networks accuracy ranged from 93.3% to 95.0%. Accuracy was found be almost constant with increasing network size. The overhead in terms of control messages was found to be 2.23 and 3.32 control packets on average per fault for Sparse and Dense networks, respectively. Finally we conducted a comparative study with existing solutions.</p><p>In future work, we plan to extend the basic concept to analyze network behavior during network operation, including deduction of possible reasons for failures, methods for sensor hotspot detection and evaluation of routing protocols.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example WSN failure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. SBFD framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Sink of the network :r, maximum allowable alternative paths s.t. r ≤ d µ 2: Output variables : P i , possible paths from SN to Sink 3: Local variables : V N , to hold the value of SN : N N [], an array to hold next nodes at each iteration 4: Initialize variables: V N = SN r = selectValueBetween(1, d µ ) // The function getNextNodes(VN,r) selects r //next nodes (1-hop) to form the routing tree rooted at Sink. N N [] = getNextNodes(VN,r) getNode(NN[]) // The function TowardsSink(n1,n2,sink) returns 1 if ¡n1,n2¿ is a valid path // based on the routing metric used 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Path deduction process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Fig. 4. Testbed network topology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Failure</head><label></label><figDesc>Detection in Wireless Sensor Networks: A Sequence-based Dynamic Approach "x":19</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Network setup for node life-time evaluation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. RN internal voltage level variation with time (min. operating voltage = 2.1V).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Fig. 8. Detection accuracy: a) Sparse topologies, b) Dense topologies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Overall fault detection accuracy under varied Workload (Network Size N=150, Dense Topology)section evaluates the impact of SBDF in terms of additional message exchange for the purpose of fault detection.The number of control messages sent by the Sink is presented in Tables XIV and XV for the Sparse and Dense networks respectively. Two scenarios are considered: a network simulation with zero faults and a simulation with faults injected as described previously.When there are no faults, SBFD sends few control messages because the false positive rate at the Fault Detection (FD) stage is typically low. Occasionally false positives are due to a node's parent change because it discovered a better parent in terms of connectivity. This is due a greedy approach in the underlying routing protocol. These unnecessary control messages constitute an average overhead of 0.01% and 0.04% in terms of network traffic for Sparse and Dense networks, respectively, as shown in Figure10. After subtracting this baseline activity, SFDB, on average in the faulty network simulation, sends 2.3 and 3.3 control messages per fault detected in Sparse and Dense networks, respectively. The number is higher for Dense networks since the FD algorithm generally issues d µ control messages to detect Node Failure and Reboot faults. For higher values of d µ the algorithm restricts it to a maximum of Q max .In the presence of faults, the control message overhead was 0.164% and 0.239% of the total data traffic at the SN for the Sparse and Dense networks, respectively. Overall, SFDB incurs very low overhead in terms of additional network traffic.The latency of fault detection in SBFD was also assessed. It is primarily bounded by T th + T search where T th is described in section 4.5 and T search is the processing delay at the Sink which is dominated by the NDB look-up during NPA. Since T th = mf , the value of T th largely depends on the sensing frequency which is typically set according to application requirements. NDB look-up delay was measured for the first 100 packets sent by 5 randomly selected SNs in the Dense network simulation with N =400. The size of the NDB for this network was 100.4 MB. The empirical cumulative distribution funciton (ECDF) of the search time is shown in Figure11. In over 80% of cases, the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Message overhead due to False Positive w.r.t. total traffic of the network (a) Sparse (b) Dense</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Failure</head><label></label><figDesc>Fig. 11. Delay incurred in NDB search for the first 100 packets received in the Dense Network, N =400</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Fig. 12. Fault Detection Accuracy in the Dense Network, comparative study with Sympathy and PAD (a) α = 1, (b) α = .75, (c) α = .5, (d) α = .25</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>FailureFig. 14 .</head><label>14</label><figDesc>Figures in %</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,30.00,24.89,873.00,72.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>For a given network, the SN Ratio α is the fraction of the total nodes which are SNs. The ratio ranges between 0 and 1.-Network Length: For a given SN, the shortest path to the Sink is the one which uses the least number of intermediate RNs, i.e. fewest hops. For a given network, the farthest SN is the one with the longest shortest path to the Sink. The network length h is the number of intermediate Relay Nodes in the shortest path from the farthest SN plus one, i.e. the network length includes the SN itself. -Mean Connectivity: A node x i is deemed to have connectivity d i if j=0 link(xi,xj ) /2 = d i where link(x i , x j ) = 1 if there exists bidirectional direct radio communication between nodes x i and x j and link(x i , x j ) = 0 otherwise. A network is characterized by its Mean Connectivity, d µ = i=0 di /N, that is the average number of nodes with which a node has direct connectivity. -Dense &amp; Sparse Network: For a given Network Length, a network can be classified either as Dense or Sparse depending on Network Size N and Mean Connectivity d µ . Higher values of N and d µ indicate a Dense Topology and lower values indicate a Sparse Topology. -Network Topology: The Network Topology consists of the node IDs, their role (i.e. SN, RN, DRN, or Sink), and the connectivity between nodes (the links). -Divergent Node: The Divergent Node (DN) is the node which is the last common node in two paths from a single SN to the Sink, i.e. the DN is the last node for which P old (i) = P new (i) where P old (0) is the SN ID. -Suspect Node: The Suspect Node (SuN) is the node immediately after the DN in the old path, i.e. the SuN is first node of P old for which P old</figDesc><table><row><cell>N -1</cell></row><row><cell>N -1</cell></row></table><note><p><p>-Relay Node: Relay Nodes (RNs) send received packets from neighboring nodes to other neighboring nodes. RNs are needed if there is no direct radio link between a Source Node and the Sink Node due to the limited range of WSN radios. As well as sending its own data, a SN may act as a Relay Node. Dedicated Relay Nodes (DRNs) do not act as SNs.</p>-Sink Node: The Sink Node collects the data generated by the SNs. It is sometimes referred to as the Base Station (BS). -Network Size: The network is a collection of N nodes, arranged in such a way that every node, x i , where i is between 0 and N -1, is in radio communication with the Sink Node, either directly or through a number of intermediate hops. We refer to N as the size of the network. -SN Ratio:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>order from the SN to the Sink but excluding the SN and the Sink IDs). The unique key of the table is sn_id,path_checksum.</figDesc><table><row><cell cols="2">Algorithm 1 Fletcher Checksum</cell></row><row><cell cols="2">1: Input variables</cell></row><row><cell></cell><cell>:CHK , checksum of the traversed nodes,initialized to 0</cell></row><row><cell></cell><cell>:N ODEID , Node ID of the source node and receiving node</cell></row><row><cell cols="2">2: Output variables</cell></row><row><cell></cell><cell>: CHK , 16-bit cheksum computed over the previous checksum and node ID</cell></row><row><cell cols="2">3: Local variables</cell></row><row><cell></cell><cell>: inputdata[4], an array for storing data after compacting into 8-bit chunks</cell></row><row><cell></cell><cell>: S1, S2, variables to store partial results</cell></row><row><cell cols="2">4: Initialize variables:</cell></row><row><cell></cell><cell>S1=0;</cell></row><row><cell></cell><cell>S2=0;</cell></row><row><cell></cell><cell>//Perform compacting Previous Result(16-bit) into two 8-bit inputs</cell></row><row><cell cols="2">5: inputdata[1]=CHK &amp; 0xFF</cell></row><row><cell></cell><cell>inputdata[2]=CHK &gt;&gt; 8</cell></row><row><cell></cell><cell>//Perform compacting Node ID (16-bit) into two 8-bit inputs</cell></row><row><cell cols="2">6: inputdata[3]=NODEID &amp; 0xFF</cell></row><row><cell></cell><cell>inputdata[4]=NODEID &gt;&gt; 8</cell></row><row><cell cols="2">7: for i = 1 to 4 do</cell></row><row><cell>8:</cell><cell>S1=S1+inputdata[i] % 255</cell></row><row><cell></cell><cell>S2=(S2+S1) % 255</cell></row><row><cell cols="2">9: end for</cell></row><row><cell cols="2">10: CHK=(S2 &lt;&lt; 8) | S1</cell></row><row><cell cols="2">11: Return CHK</cell></row><row><cell cols="2">path (in</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Coutner = 0, P P C = F alse 5: if P old = P new for the next T th time units then no evidence of a new fault and FD moves on to the next packet (line number 7, 8). Otherwise, a Persistent Path Change has been detected (line number 13, 14).</figDesc><table><row><cell cols="2">Algorithm 3 Fault Detection</cell></row><row><cell cols="2">1: Input variables</cell></row><row><cell></cell><cell>:SN , Source Node</cell></row><row><cell></cell><cell>:P old , old path</cell></row><row><cell></cell><cell>:P new , new path</cell></row><row><cell cols="2">2: Output variables</cell></row><row><cell></cell><cell>: SuN , Suspect Node</cell></row><row><cell></cell><cell>: SuL, Suspect Link</cell></row><row><cell cols="2">3: Local variables</cell></row><row><cell></cell><cell>: T P acket, to hold the value of total packets received from a specified SN</cell></row><row><cell></cell><cell>:Counter, to count the number of packets</cell></row><row><cell></cell><cell>:P P C, Persistent Path Change variable</cell></row><row><cell cols="2">4: Initialize variables:</cell></row><row><cell></cell><cell>SuN = N U LL, SuL = N U LL</cell></row><row><cell cols="2">T P acket = 0, 6: T P acket + +</cell></row><row><cell>7:</cell><cell>if P acket i ⊆ P old then</cell></row><row><cell>8:</cell><cell>Exit()</cell></row><row><cell>9:</cell><cell>else</cell></row><row><cell>10:</cell><cell>Counter + +</cell></row><row><cell>11:</cell><cell>end if</cell></row><row><cell cols="2">12: end if</cell></row><row><cell cols="2">13: if Counter==T P acket then</cell></row><row><cell>14:</cell><cell>set PPC=True</cell></row><row><cell cols="2">15: end if</cell></row><row><cell></cell><cell>// Persistent Path Change occurs so, go to the next steps:</cell></row><row><cell cols="2">16: if P P C = T rue then</cell></row><row><cell>17:</cell><cell>SuN =getSuspectNode(P new , P old )</cell></row><row><cell></cell><cell>DN =getDivergentNode(P new , P old )</cell></row><row><cell></cell><cell>SuL=[DN,SuN], link from DN to SuN</cell></row><row><cell cols="2">18: end if</cell></row><row><cell></cell><cell>// Now go for elimination steps:</cell></row><row><cell cols="2">19: Consult N AT entries of N DB</cell></row><row><cell cols="2">20: if SuN .status==active then</cell></row><row><cell>21:</cell><cell>set SuN =NULL</cell></row><row><cell>22:</cell><cell>if SuN .Timestamp==DN .Timestamp then</cell></row><row><cell>23:</cell><cell>set SuL=NULL</cell></row><row><cell>24:</cell><cell>end if</cell></row><row><cell>25:</cell><cell>Consult P AT entries of N DB</cell></row><row><cell>26:</cell><cell>if SuL ⊆ P AT then</cell></row><row><cell>27:</cell><cell>set SuL=NULL</cell></row><row><cell>28:</cell><cell>end if</cell></row><row><cell cols="2">29: end if</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>third step checks for Node Failure and Node Reboot. A final response_request packet is sent to the SuN after T reboot time units. If no response is received at the Sink</figDesc><table><row><cell cols="2">Algorithm 4 Fault Identification</cell></row><row><cell cols="2">1: Input variables</cell></row><row><cell></cell><cell>:SuN ,DN , these values are obtained from the Fault Detection algorithm</cell></row><row><cell></cell><cell>:SuL=[DN,SuN]</cell></row><row><cell></cell><cell>:Q max , upper limit of neighbors to be selected</cell></row><row><cell cols="2">2: Output variables</cell></row><row><cell></cell><cell>: status of SuN and SuL</cell></row><row><cell cols="2">3: // Check for Link Failure first:</cell></row><row><cell></cell><cell>response_request.Destination=DN</cell></row><row><cell></cell><cell>response_request.avoid_node=SuN</cell></row><row><cell></cell><cell>response_request.sendMessage()</cell></row><row><cell cols="2">4: response.Destination=Sink</cell></row><row><cell></cell><cell>response.via_node=SuN</cell></row><row><cell></cell><cell>response.sendMessage()</cell></row><row><cell cols="2">5: if Sink.receivedResponse==True then</cell></row><row><cell>6:</cell><cell>set SuN.status=Active</cell></row><row><cell></cell><cell>set SuL.status=Active</cell></row><row><cell></cell><cell>exit()</cell></row><row><cell cols="2">7: else</cell></row><row><cell>8:</cell><cell>Q=(d i &lt; Q max )?d i : Q max</cell></row><row><cell></cell><cell>// getNeighbors(x,y) returns a maximum of y 1-hop neighbors of node x</cell></row><row><cell></cell><cell>response_request.Destination=getNeighbors(SuN ,Q)</cell></row><row><cell></cell><cell>response_request.avoid_node=SuN</cell></row><row><cell></cell><cell>response_request.sendMessage()</cell></row><row><cell>9:</cell><cell>response.Destination=Sink</cell></row><row><cell></cell><cell>response.via_node=SuN</cell></row><row><cell></cell><cell>response.sendMessage()</cell></row><row><cell>10:</cell><cell>if Sink.receivedResponse==True then</cell></row><row><cell>11:</cell><cell>set SuN.status=Active</cell></row><row><cell></cell><cell>set SuL.status=Failed</cell></row><row><cell></cell><cell>exit()</cell></row><row><cell>12:</cell><cell>else</cell></row><row><cell>13:</cell><cell>//Check for Node Failure and Reboot:</cell></row><row><cell></cell><cell>Wait upto T reboot time units</cell></row><row><cell></cell><cell>response_request.Destination=SuN</cell></row><row><cell></cell><cell>response_request.sendMessage()</cell></row><row><cell>14:</cell><cell>Wait upto T resp time units</cell></row><row><cell>15:</cell><cell>if Sink.receivedResponse==True then</cell></row><row><cell>16:</cell><cell>set SuN.status=Reboot</cell></row><row><cell>17:</cell><cell>else</cell></row><row><cell>18:</cell><cell>set SuN.status=Failed</cell></row><row><cell>19:</cell><cell>end if</cell></row><row><cell>20:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table II .</head><label>II</label><figDesc>Path checksums</figDesc><table><row><cell>Source Node</cell><cell>Path</cell><cell>Path Checksum</cell></row><row><cell>530</cell><cell>530,520</cell><cell>54340</cell></row><row><cell>530</cell><cell>530,501</cell><cell>44849</cell></row><row><cell>530</cell><cell>530,540,520</cell><cell>27231</cell></row><row><cell>540</cell><cell>540,530,520</cell><cell>43971</cell></row><row><cell>540</cell><cell>540,520</cell><cell>14690</cell></row><row><cell>540</cell><cell>540,530,501</cell><cell>34480</cell></row><row><cell>570</cell><cell>570,565,550</cell><cell>14546</cell></row><row><cell>570</cell><cell>570,565,575</cell><cell>27371</cell></row><row><cell>570</cell><cell>570,560,550</cell><cell>1731</cell></row><row><cell>580</cell><cell>580,575</cell><cell>14610</cell></row><row><cell>580</cell><cell>580,501</cell><cell>42439</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table III .</head><label>III</label><figDesc>Testbed fault detection accuracy.</figDesc><table><row><cell>Fault Type</cell><cell>Number Inserted</cell><cell>Number Detected</cell><cell>Accuracy (%)</cell></row><row><cell>Node Failure</cell><cell>6</cell><cell>6</cell><cell>100</cell></row><row><cell>Link Failure</cell><cell>2</cell><cell>2</cell><cell>100</cell></row><row><cell>Node Reboot</cell><cell>2</cell><cell>1</cell><cell>50</cell></row><row><cell>Total</cell><cell>10</cell><cell>9</cell><cell>90</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table IV .</head><label>IV</label><figDesc>Node Reboot detection accuracy variation with sensing period.</figDesc><table><row><cell>Sensing period</cell><cell>Number Inserted</cell><cell>Number Detected</cell><cell>Accuracy (%)</cell></row><row><cell>10 s</cell><cell>50</cell><cell>37</cell><cell>74</cell></row><row><cell>5 s</cell><cell>50</cell><cell>41</cell><cell>82</cell></row><row><cell>2.5 s</cell><cell>50</cell><cell>46</cell><cell>92</cell></row><row><cell>500 ms</cell><cell>50</cell><cell>48</cell><cell>96</cell></row><row><cell>250 ms</cell><cell>50</cell><cell>50</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table V .</head><label>V</label><figDesc>Relay Node (RN) lifetime</figDesc><table><row><cell>Node</cell><cell></cell><cell cols="2">Lifetime (in packets)</cell><cell cols="2">Lifetime (in seconds)</cell><cell>Lifetime</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>w.r.t. R1 (%)</cell></row><row><cell cols="2">R1 (without IPT)</cell><cell>210,871</cell><cell></cell><cell>421,742</cell><cell></cell><cell>100.0</cell></row><row><cell cols="2">R2 (with IPT)</cell><cell>209,903</cell><cell></cell><cell>419,806</cell><cell></cell><cell>99.5</cell></row><row><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Min. Operating Voltage</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>0</cell><cell>Day 1</cell><cell>Day 2</cell><cell>Day 3</cell><cell>Day 4</cell><cell>Day 5</cell></row><row><cell></cell><cell>Time [</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Experiment started on 07-NOV-11 01.24.54.927326 PM, ended on 12-NOV-11 04.59.22.700802 AM ] Voltage Level</head><label></label><figDesc></figDesc><table><row><cell>Node with Checksum Mechanism</cell></row><row><cell>Node without Checksum Mechanism</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table VI .</head><label>VI</label><figDesc>Dedicated Relay Node (DRN) lifetime</figDesc><table><row><cell>Node</cell><cell></cell><cell cols="3">Lifetime (in packets)</cell><cell cols="2">Lifetime (in seconds)</cell><cell>Lifetime</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>w.r.t. R1 (%)</cell></row><row><cell cols="2">R1 (without IPT)</cell><cell cols="2">269,258</cell><cell></cell><cell>538,515</cell><cell></cell><cell>100.0</cell></row><row><cell>R2 (with IPT)</cell><cell></cell><cell cols="2">267,255</cell><cell></cell><cell>534,509</cell><cell></cell><cell>99.26</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">Table VII. SBFD Memory Size</cell></row><row><cell></cell><cell cols="2">ROM size</cell><cell>Increase</cell><cell cols="2">Increase</cell><cell>RAM size</cell><cell>Increase</cell><cell>Increase</cell></row><row><cell></cell><cell cols="2">(in bytes)</cell><cell>(in bytes)</cell><cell>(%)</cell><cell></cell><cell>(in bytes)</cell><cell>(in bytes)</cell><cell>(in %)</cell></row><row><cell>Node without IPT</cell><cell cols="2">30,254</cell><cell>-</cell><cell>-</cell><cell></cell><cell>1,910</cell><cell>-</cell><cell>-</cell></row><row><cell>Node with IPT</cell><cell cols="2">30,558</cell><cell>304</cell><cell cols="2">1.01</cell><cell>1,912</cell><cell>2</cell><cell>0.11</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table VIII .</head><label>VIII</label><figDesc>Simulation parameter settings. Accuracy. A program was written to generate random network topology files. The networks were generated for various combinations of number of nodes N , Network Length h, and Mean Connectivity d µ . The parameters for the Sparse networks are listed in Table X and those for Dense networks are listed in Table</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>PHY Layer</cell><cell>2.4GHz IEEE 802.15.4</cell></row><row><cell>MAC Layer</cell><cell>Default CSMA</cell></row><row><cell>Clear Channel Assessment</cell><cell>-70dbM</cell></row><row><cell>Routing Layer</cell><cell>CTP</cell></row><row><cell>External Noise</cell><cell>Added (Mayer Library)</cell></row><row><cell>Network Size</cell><cell>Variable (25 to 400)</cell></row><row><cell>SN ratio α</cell><cell>.5</cell></row><row><cell>No. of BS/Sink</cell><cell>1 (ID=1)</cell></row><row><cell>Sensing Period f</cell><cell>250 ms</cell></row><row><cell>T th</cell><cell>750 ms</cell></row><row><cell>m</cell><cell>3</cell></row><row><cell>r</cell><cell>3</cell></row><row><cell>Qmax</cell><cell>5</cell></row><row><cell>Sim. Duration</cell><cell>100 s</cell></row><row><cell>No. of Iterations</cell><cell>3</cell></row><row><cell>5.3.1.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table IX .</head><label>IX</label><figDesc>Parameters: Dense networks.</figDesc><table><row><cell>Network Size (N )</cell><cell>MaxHop (h)</cell><cell>Mean Connectivity (dµ)</cell></row><row><cell>40</cell><cell>5</cell><cell>2.8</cell></row><row><cell>75</cell><cell>6</cell><cell>3.1</cell></row><row><cell>150</cell><cell>8</cell><cell>3.85</cell></row><row><cell>200</cell><cell>10</cell><cell>7.2</cell></row><row><cell>300</cell><cell>10</cell><cell>9.3</cell></row><row><cell>400</cell><cell>10</cell><cell>10.5</cell></row><row><cell cols="3">Table X. Parameters: Sparse networks.</cell></row><row><cell>Network Size (N )</cell><cell>MaxHop (h)</cell><cell>Mean Connectivity (dµ)</cell></row><row><cell>25</cell><cell>5</cell><cell>1.5</cell></row><row><cell>50</cell><cell>6</cell><cell>1.7</cell></row><row><cell>100</cell><cell>8</cell><cell>1.85</cell></row><row><cell>150</cell><cell>10</cell><cell>1.91</cell></row><row><cell>200</cell><cell>10</cell><cell>1.98</cell></row><row><cell>250</cell><cell>10</cell><cell>2.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table XI .</head><label>XI</label><figDesc>Detection accuracy: Sparse topologies.</figDesc><table><row><cell>Network Size (N )</cell><cell></cell><cell cols="2">Detection Accuracy (%)</cell><cell></cell></row><row><cell></cell><cell>Node Failure</cell><cell>Link Failure</cell><cell>Node Reboot</cell><cell>Overall</cell></row><row><cell>25</cell><cell>88.8</cell><cell>88.8</cell><cell>100</cell><cell>91.1</cell></row><row><cell>50</cell><cell>93.3</cell><cell>93.3</cell><cell>88.8</cell><cell>92.4</cell></row><row><cell>100</cell><cell>90</cell><cell>93.3</cell><cell>86.6</cell><cell>90.6</cell></row><row><cell>150</cell><cell>93.3</cell><cell>91.1</cell><cell>87.5</cell><cell>91.2</cell></row><row><cell>200</cell><cell>90</cell><cell>95</cell><cell>93.3</cell><cell>92.6</cell></row><row><cell>250</cell><cell>90.6</cell><cell>93.3</cell><cell>92.3</cell><cell>92.1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table XII .</head><label>XII</label><figDesc>Detection accuracy: Dense topologies.</figDesc><table><row><cell>Network Size (N )</cell><cell></cell><cell cols="2">Detection Accuracy (%)</cell><cell></cell></row><row><cell></cell><cell>Node Failure</cell><cell>Link Failure</cell><cell>Node Reboot</cell><cell>Overall</cell></row><row><cell>40</cell><cell>91.7</cell><cell>100</cell><cell>83.3</cell><cell>93.3</cell></row><row><cell>75</cell><cell>91.6</cell><cell>95.8</cell><cell>91.6</cell><cell>93.3</cell></row><row><cell>150</cell><cell>93.3</cell><cell>95.6</cell><cell>91.7</cell><cell>93.9</cell></row><row><cell>200</cell><cell>96.7</cell><cell>95.0</cell><cell>86.7</cell><cell>94.0</cell></row><row><cell>300</cell><cell>95.6</cell><cell>94.4</cell><cell>91.1</cell><cell>94.2</cell></row><row><cell>400</cell><cell>97.5</cell><cell>94.2</cell><cell>91.7</cell><cell>95.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table XIII .</head><label>XIII</label><figDesc>Workload parameters.</figDesc><table><row><cell cols="4">Network Size (N )</cell><cell>SN Ratio (α)</cell><cell>Sensing Frequency (Ts) in ms</cell><cell>Workload (W )</cell></row><row><cell cols="3">150</cell><cell></cell><cell>0.50</cell><cell>250</cell><cell>0.30</cell></row><row><cell cols="3">150</cell><cell></cell><cell>0.60</cell><cell>150</cell><cell>0.60</cell></row><row><cell cols="3">150</cell><cell></cell><cell>0.70</cell><cell>100</cell><cell>1.05</cell></row><row><cell cols="3">150</cell><cell></cell><cell>0.75</cell><cell>75</cell><cell>1.50</cell></row><row><cell cols="3">150</cell><cell></cell><cell>0.80</cell><cell>50</cell><cell>2.40</cell></row><row><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>90</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Detection Accuracy Network Packet Drop Ratio (PDR)</cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Figures in %</cell><cell>40 50 60</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0</cell><cell>0.3</cell><cell>0.6</cell><cell>1.05</cell><cell>2.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Workload W</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table XIV .</head><label>XIV</label><figDesc>Message overhead of SBDF in Sparse Networks</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Zero Fault Scenario</cell><cell></cell><cell cols="2">Faulty Scenario</cell></row><row><cell>Network Size</cell><cell>Total Data</cell><cell>Control</cell><cell>Control</cell><cell>Control</cell><cell>Control</cell><cell>Mean Control</cell></row><row><cell>(N )</cell><cell>Packets received</cell><cell>Packets sent</cell><cell>Packets</cell><cell>Packets</cell><cell>Packets</cell><cell>Packets</cell></row><row><cell></cell><cell>by the Sink</cell><cell></cell><cell>sent ( %)</cell><cell>sent</cell><cell>sent (%)</cell><cell>per Fault</cell></row><row><cell>25</cell><cell>9875</cell><cell>2</cell><cell>0.021</cell><cell>19</cell><cell>0.192</cell><cell>2.4</cell></row><row><cell>50</cell><cell>19750</cell><cell>2</cell><cell>0.01</cell><cell>31</cell><cell>0.157</cell><cell>2.2</cell></row><row><cell>100</cell><cell>39500</cell><cell>4</cell><cell>0.01</cell><cell>61</cell><cell>0.154</cell><cell>2.2</cell></row><row><cell>150</cell><cell>59250</cell><cell>4</cell><cell>0.006</cell><cell>95</cell><cell>0.160</cell><cell>2.4</cell></row><row><cell>200</cell><cell>79000</cell><cell>8</cell><cell>0.012</cell><cell>126</cell><cell>0.159</cell><cell>2.3</cell></row><row><cell>250</cell><cell>98750</cell><cell>8</cell><cell>0.008</cell><cell>163</cell><cell>0.165</cell><cell>2.4</cell></row><row><cell>Average:</cell><cell>-</cell><cell>-</cell><cell>0.01</cell><cell>-</cell><cell>0.164</cell><cell>2.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table XV .</head><label>XV</label><figDesc>Message overhead of SBDF in Dense Networks</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Zero Fault Scenario</cell><cell></cell><cell cols="2">Faulty Scenario</cell></row><row><cell>Network Size</cell><cell>Total Data</cell><cell>Control</cell><cell>Control</cell><cell>Control</cell><cell>Control</cell><cell>Mean Control</cell></row><row><cell>(N )</cell><cell>Packets received</cell><cell>Packets sent</cell><cell>Packets</cell><cell>Packets</cell><cell>Packets</cell><cell>Packets</cell></row><row><cell></cell><cell>by the Sink</cell><cell></cell><cell>sent ( %)</cell><cell>sent</cell><cell>sent (%)</cell><cell>per Fault</cell></row><row><cell>40</cell><cell>15800</cell><cell>3</cell><cell>0.019</cell><cell>32</cell><cell>0.203</cell><cell>2.9</cell></row><row><cell>75</cell><cell>29625</cell><cell>6</cell><cell>0.020</cell><cell>60</cell><cell>0.203</cell><cell>2.7</cell></row><row><cell>150</cell><cell>59250</cell><cell>19</cell><cell>0.032</cell><cell>135</cell><cell>0.228</cell><cell>3.1</cell></row><row><cell>200</cell><cell>79000</cell><cell>30</cell><cell>0.038</cell><cell>214</cell><cell>0.271</cell><cell>4.9</cell></row><row><cell>300</cell><cell>118500</cell><cell>35</cell><cell>0.030</cell><cell>319</cell><cell>0.269</cell><cell>6.3</cell></row><row><cell>400</cell><cell>158000</cell><cell>50</cell><cell>0.032</cell><cell>414</cell><cell>0.262</cell><cell>6.7</cell></row><row><cell>Average:</cell><cell>-</cell><cell>-</cell><cell>0.028</cell><cell>-</cell><cell>0.239</cell><cell>3.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table XVI .</head><label>XVI</label><figDesc>Path Deduction Latency.</figDesc><table><row><cell></cell><cell></cell><cell>Latency in ms</cell></row><row><cell></cell><cell>Maximum</cell><cell>1750</cell></row><row><cell>PAD</cell><cell>Minimum</cell><cell>250</cell></row><row><cell></cell><cell>Average</cell><cell>1085</cell></row><row><cell></cell><cell>Maximum</cell><cell>4</cell></row><row><cell>SBFD</cell><cell>Minimum</cell><cell>1</cell></row><row><cell></cell><cell>Average</cell><cell>2.54</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>ACM Transactions on Sensor Networks, Vol. "x", No. "x", Article "x", Publication date: Month "20xx".</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>, <rs type="grantNumber">2012</rs>. <rs type="projectName">Failure Detection in Wireless Sensor Network: A Sequence-based Dynamic Approach ACM Trans. Sensor Netw. "x", "x", Article "x" (Month "20xx</rs>"), 30 pages. This work is partially supported by the <rs type="funder">Higher Education Authority</rs> <rs type="grantNumber">PRTLI4</rs> under grant number <rs type="grantNumber">R10891</rs>, "<rs type="projectName">NEMBES: Networked Embedded Systems</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_zqZYvTZ">
					<idno type="grant-number">2012</idno>
					<orgName type="project" subtype="full">Failure Detection in Wireless Sensor Network: A Sequence-based Dynamic Approach ACM Trans. Sensor Netw. &quot;x&quot;, &quot;x&quot;, Article &quot;x&quot; (Month &quot;20xx</orgName>
				</org>
				<org type="funding" xml:id="_pUjuXeQ">
					<idno type="grant-number">PRTLI4</idno>
				</org>
				<org type="funded-project" xml:id="_Fj4JwN2">
					<idno type="grant-number">R10891</idno>
					<orgName type="project" subtype="full">NEMBES: Networked Embedded Systems</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Tivoli</surname></persName>
		</author>
		<ptr target="http://www.ibm.com/software/tivoli" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><surname>Hp Openview</surname></persName>
		</author>
		<ptr target="http://www.openview.hp.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A line in the sand: A wireless sensor network for target detection, classification, and tracking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bapat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kulathumani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gouda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Arumugam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nesterenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miyashita</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Elsevier</publisher>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="605" to="634" />
		</imprint>
	</monogr>
	<note>Computer Networks</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unwired wine: sensor networks in vineyards</title>
		<author>
			<persName><forename type="first">R</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Teibel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bowen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="561" to="564" />
		</imprint>
	</monogr>
	<note>Sensors</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Task: Sensor network in a box</title>
		<author>
			<persName><forename type="first">P</forename><surname>Buonadonna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Workshop on Sensor Networks</title>
		<meeting>European Workshop on Sensor Networks</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="133" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Livenet: Using passive monitoring to reconstruct sensor network dynamics</title>
		<author>
			<persName><forename type="first">B.-R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mainland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th IEEE international conference on Distributed Computing in Sensor Systems. DCOSS &apos;08</title>
		<meeting>the 4th IEEE international conference on Distributed Computing in Sensor Systems. DCOSS &apos;08<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="79" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Environmental wireless sensor networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Corke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jurdak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valencia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="1903" to="1917" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><surname>Crossbow</surname></persName>
		</author>
		<ptr target="http://www.xbow.com/Products/productdetails.aspx?sid=252" />
		<title level="m">Data Sheet from Crossbow</title>
		<imprint>
			<date type="published" when="2010">2012. Jan 02, 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An arithmetic checksum for serial transmissions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fletcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="247" to="252" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
	<note>Communications</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Collection tree protocol</title>
		<author>
			<persName><forename type="first">O</forename><surname>Gnawali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems. SenSys &apos;09</title>
		<meeting>the 7th ACM Conference on Embedded Networked Sensor Systems. SenSys &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Find: faulty node detection for wireless sensor networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems. SenSys &apos;09</title>
		<meeting>the 7th ACM Conference on Embedded Networked Sensor Systems. SenSys &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="253" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Vigilnet: An integrated sensor network system for energy-efficient surveillance</title>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Stoleru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vicaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stankovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Abdelzaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Krogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Sen. Netw</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Shrink: a tool for failure diagnosis in ip networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Vasseur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 ACM SIGCOMM workshop on Mining network data. MineNet &apos;05</title>
		<meeting>the 2005 ACM SIGCOMM workshop on Mining network data. MineNet &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="173" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dustminer: troubleshooting interactive complexity bugs in sensor networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Abdelzaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM conference on Embedded network sensor systems. SenSys &apos;08</title>
		<meeting>the 6th ACM conference on Embedded network sensor systems. SenSys &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="99" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Diagnostic powertracing for sensor node failure analysis</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M H</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lemay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moinzadeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Abdelzaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM/IEEE International Conference on Information Processing in Sensor Networks. IPSN &apos;10</title>
		<meeting>the 9th ACM/IEEE International Conference on Information Processing in Sensor Networks. IPSN &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Design and deployment of industrial sensor networks: experiences from a semiconductor plant and the north sea</title>
		<author>
			<persName><forename type="first">L</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buonadonna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chhabra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kushalnagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nachman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yarvis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international conference on Embedded networked sensor systems. SenSys &apos;05</title>
		<meeting>the 3rd international conference on Embedded networked sensor systems. SenSys &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="64" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Murphy loves potatoes: experiences from a pilot sensor network deployment in precision agriculture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Langendoen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel and Distributed Processing Symposium</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
	<note>IPDPS 2006. 20th International. 8 pp</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tossim: accurate and scalable simulation of entire tinyos applications</title>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Culler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international conference on Embedded networked sensor systems. SenSys &apos;03</title>
		<meeting>the 1st international conference on Embedded networked sensor systems. SenSys &apos;03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="126" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Passive diagnosis for wireless sensor networks. Networking</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1132" to="1144" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<ptr target="http://dev.mysql.com/doc/refman/5.5/en/" />
		<title level="m">MySQL Reference Manual for 5.5 version</title>
		<imprint>
			<date type="published" when="2012-04-30">2012. April 30, 2012</date>
		</imprint>
	</monogr>
	<note>MySQL Reference Guide</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Oracle Database Performance Tuning Guide,11g Release 1 (11.1)</title>
		<ptr target="http://www.oracle.com/pls/db111/portal.portal_db?selected=17&amp;frame=" />
		<imprint>
			<date type="published" when="2012-05-02">2012. May 02, 2012</date>
		</imprint>
	</monogr>
	<note>Oracle Database</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reliable data delivery in large-scale low-power sensor networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Puccinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Haenggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Sen. Netw</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sympathy for the sensor network debugger</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kapur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Girod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd international conference on Embedded networked sensor systems. SenSys &apos;05</title>
		<meeting>the 3rd international conference on Embedded networked sensor systems. SenSys &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="255" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pda: Passive distributed assertions for sensor networks</title>
		<author>
			<persName><forename type="first">K</forename><surname>Romer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 International Conference on Information Processing in Sensor Networks. IPSN &apos;09</title>
		<meeting>the 2009 International Conference on Information Processing in Sensor Networks. IPSN &apos;09<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="337" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Memento: A Health Monitoring System for Wireless Sensor Networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE SECON</title>
		<meeting><address><addrLine>Reston, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Increasing robustness of fault localization through analysis of lost, spurious, and positive symptoms</title>
		<author>
			<persName><forename type="first">M</forename><surname>Steinder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INFOCOM 2002. Twenty-First Annual Joint Conference of the IEEE Computer and Communications Societies</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="322" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An analysis of a large scale habitat monitoring application</title>
		<author>
			<persName><forename type="first">R</forename><surname>Szewczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mainwaring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Polastre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Culler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on Embedded networked sensor systems. SenSys &apos;04</title>
		<meeting>the 2nd international conference on Embedded networked sensor systems. SenSys &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<ptr target="http://docs.tinyos.net/index.php/Main_Page" />
		<title level="m">TinyOS 2010. TinyOS Documentation</title>
		<imprint>
			<date type="published" when="2010-10">Jan-10-2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Visibility: a new metric for protocol design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wachs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th international conference on Embedded networked sensor systems. SenSys &apos;07</title>
		<meeting>the 5th international conference on Embedded networked sensor systems. SenSys &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="73" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Residual energy scan for monitoring sensor networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wireless Communications and Networking Conference</title>
		<imprint>
			<date type="published" when="2002">2002. 2002. 2002. 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="356" to="362" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
