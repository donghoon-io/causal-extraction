<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Analysis of Adaptive Operator Selection Techniques on the Royal Road and Long K-Path Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Álvaro</forename><surname>Fialho</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">INRIA Joint Centre Parc Orsay Université</orgName>
								<address>
									<postCode>91893</postCode>
									<settlement>Orsay Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Schoenauer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">INRIA Joint Centre Parc Orsay Université</orgName>
								<address>
									<postCode>91893</postCode>
									<settlement>Orsay Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Project-Team TAO</orgName>
								<orgName type="institution" key="instit2">INRIA Saclay -Île-de-France LRI</orgName>
								<address>
									<addrLine>Bât. 490</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michèle</forename><surname>Sebag</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Microsoft Research</orgName>
								<orgName type="institution" key="instit2">INRIA Joint Centre Parc Orsay Université</orgName>
								<address>
									<postCode>91893</postCode>
									<settlement>Orsay Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Project-Team TAO</orgName>
								<orgName type="institution" key="instit2">INRIA Saclay -Île-de-France LRI</orgName>
								<address>
									<addrLine>Bât. 490</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Université Paris-Sud</orgName>
								<address>
									<postCode>91405</postCode>
									<settlement>Orsay Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Analysis of Adaptive Operator Selection Techniques on the Royal Road and Long K-Path Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.2.8 [Computing Methodologies]: Artificial Intelligence: Problem Solving</term>
					<term>Control Methods</term>
					<term>and Search Genetic Algorithms</term>
					<term>Parameter Control</term>
					<term>Adaptive Operator Selection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>One of the choices that most affect the performance of Evolutionary Algorithms is the selection of the variation operators that are efficient to solve the problem at hand. This work presents an empirical analysis of different Adaptive Operator Selection (AOS) methods, i.e., techniques that automatically select the operator to be applied among the available ones, while searching for the solution. Four previously published operator selection rules are combined to four different credit assignment mechanisms. These 16 AOS combinations are analyzed and compared in the light of two wellknown benchmark problems in Evolutionary Computation, the Royal Road and the Long K-Path.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Evolutionary Algorithms (EAs) constitute efficient solvers for general optimization problems and their performances have been assessed on a wide range of applications. Algorithmically, EAs proceed by selecting and applying transformation, a.k.a. variation, operators on sets of possible configurations of the problem to be solved. The EAs efficiency relies on making quite a few appropriate algorithmic and parametric decisions. On the so-called genotypic level are the suitable encoding of the search space and the variation operators, e.g., mutation and crossover; on the phenotypic level are the selection procedures and the size of the population.</p><p>This paper focuses on parameter setting in EAs, which usually requires an extensive expertise in either the problem to be solved, or EAs, or both. Parameter setting has been and still is acknowledged a most critical aspect of Evolutionary Computation <ref type="bibr" target="#b26">[23]</ref>. Interestingly, the search for algorithmic technologies enabling the (naive) end-user to benefit from good performances through autonomous parameter setting is considered a priority in neighbor fields such as operation research or constraint programming <ref type="bibr" target="#b20">[18,</ref><ref type="bibr" target="#b27">24]</ref>; these fields likewise involve sophisticated solver platforms, requiring an extensive expertise to be used to their fullest extent.</p><p>Parameter setting involves two main components: acquiring some knowledge about the fitness landscape of the problem at hand, referred to as learning; and exploiting the acquired knowledge to appropriately shape the algorithm, referred to as adaptation. While parameter setting actually regards the selection of any solver components, this paper will only consider the on-line selection rate of the variation operators, such as mutation and crossover.</p><p>On-line learning and adaptation raise two specific issues compared to their offline equivalent. Firstly, on-line learning associates a value or reward to each operator, depending on its current effects, while offline learning observes a posteriori the contribution of the operator to the overall performance. On-line learning requires a Credit Assignment mechanism to be designed, typically considering the average effects of the operator and/or its peak (extreme) effects. Secondly, the past rewards attached to each operator are used to define a selection rule in charge of actually selecting the current operator (Operator Selection). Lastly, the Credit Assignment and Operator Selection together must account for the fact that the genetic population follows some trajectory in the fitness landscape; the instant reward attached to each operator, measuring e.g., the fitness gain of the offspring w.r.t. the parent, not only is a random variable; furthermore, the underlying distribution of this random variable is a dynamic one, changing as evolution goes on.</p><p>A short survey of autonomous parameter setting, Credit Assignment and Operator Selection in EAs is presented in Section 2, focussing on four Operator Selection methods, namely Probability Matching and Adaptive Pursuit <ref type="bibr" target="#b33">[30,</ref><ref type="bibr" target="#b34">31]</ref> on the one hand, and the static and dynamic versions of the Multi-Armed Bandit <ref type="bibr" target="#b6">[5,</ref><ref type="bibr" target="#b11">10]</ref> on the other hand.</p><p>The first contribution of this paper is an extensive experimental study of the above four Operator Selection methods, combined with four Credit Assignment mechanisms, namely the extreme <ref type="bibr" target="#b36">[33]</ref> and the average fitness improvements, either in absolute value, or normalized w.r.t. the current ones. While the above-mentioned methods have been studied on merely artificial settings <ref type="bibr" target="#b33">[30,</ref><ref type="bibr" target="#b34">31,</ref><ref type="bibr" target="#b6">5]</ref> or on the OneMax problem <ref type="bibr" target="#b11">[10]</ref>, the present paper considers the Royal Road <ref type="bibr" target="#b18">[16]</ref> and the Long K-Path <ref type="bibr" target="#b19">[17]</ref> problems, which have been extensively investigated in the Evolutionary Computation (EC) literature. For the sake of efficiency, the 16 parameter setting frameworks are experimented at their best; a racing mechanism <ref type="bibr" target="#b4">[4]</ref> is used to find the best hyper-parameters for these frameworks in a tractable way. The experimental results are presented and discussed in Section 4, and the paper concludes with some perspectives for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND AND STATE OF THE ART</head><p>After a brief introduction to Evolutionary Parameter Setting, this section focuses on Credit Assignment and Operator Selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Evolutionary Parameter Setting</head><p>After <ref type="bibr" target="#b9">[8,</ref><ref type="bibr" target="#b10">9]</ref>, Evolutionary Parameter Setting proceeds along two main modes. Offline or external tuning, referred to as Parameter Tuning, determines a priori the appropriate parameter values. Parameter tuning thus takes place before the run, e.g., exploiting the lessons learned from previous runs. Standard approaches from experimental studies such as ANOVA or Design Of Experiments have been used for Parameter Tuning, e.g., modeling the impact of parameter values on the overall performance and accordingly determining the optimal values <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b37">34,</ref><ref type="bibr" target="#b3">3,</ref><ref type="bibr" target="#b30">27]</ref>. These methods however are very computationally expensive as each observation corresponds to the average of a few evolutionary runs; furthermore, only static settings are considered (the parameter value is fixed along the run), whereas the optimal setting likely depends on the local landscape explored by the genetic population.</p><p>On-line or internal tuning, referred to as Parameter Control. determines the appropriate parameter values at each time step during the evolutionary run. One further distinguishes Deterministic (parameter values are predefined functions of time), Self-Adaptive (parameters are part of the genotypic information and optimized by evolution itself), and Adaptive (parameter values are predefined functions of the whole history of the run) Parameter Control.</p><p>Deterministic Parameter Control essentially raises the same difficulties as Parameter Tuning: while the parameter values depend on the time step, these functions must still be defined a priori. Self-Adaptive Parameter Control is acknowledged one of the most effective approaches to evolutionary parameter setting, specifically in the framework of continuous parameter optimization (see the discussion in <ref type="bibr">[7]</ref> and references therein). In the general case however, selfadaptive approaches often significantly increase the size of the search space, and/or the complexity of the optimization problem (not only should a successful individual have good genes; it should also bear parameter values enforcing some effective transmission of its genes).</p><p>Adaptive Parameter Control, also referred to as Feedback-Based control, use information from the history of evolution to modify the parameter values while solving the problem. Adaptive Operator Selection (AOS), a particular case of adaptive parameter control, aims to defining an on-line strategy for selecting the most appropriate variation oper-ators. As shown on Fig. <ref type="figure" target="#fig_0">1</ref>, AOS involves two subproblems, detailed in next subsections: i) assessing the impact of each operator upon the progress of evolution (Credit Assignment); ii) using these assessments to actually select the operator with best impact expectation (Operator Selection). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Credit Assignment</head><p>Several Credit Assignment mechanisms have been proposed in the literature, following Davis' seminal paper <ref type="bibr" target="#b7">[6]</ref>. These mechanisms mostly differ by the measure used to compute the credit, and the genetic individuals taken into consideration.</p><p>Most approaches consider the new offspring and use its fitness improvement as credit measure. The fitness improvement is assessed by comparison with i) the current best individual <ref type="bibr" target="#b7">[6]</ref>; ii) the median fitness <ref type="bibr" target="#b22">[20]</ref>; or iii) the parent fitness <ref type="bibr" target="#b25">[22,</ref><ref type="bibr" target="#b35">32,</ref><ref type="bibr" target="#b2">2]</ref>. When there is no improvement, the offspring is simply discarded.</p><p>In the case of multi-modal optimization, another relevant measure concerns the population diversity, which must be enforced to avoid premature convergence. Along this line, <ref type="bibr" target="#b28">[25]</ref> proposed another credit measure called Compass, defined as a weighted sum of fitness improvement (intensification) and offspring diversity (diversification).</p><p>While the credit measure usually considers instantaneous or average improvement (the average being taken over the last n applications of the operator), <ref type="bibr" target="#b36">[33]</ref> proposes instead to consider extreme improvements, using a statistical measure aimed at outlier detection. The experimental results presented show that the method significantly outperforms its competitors on a set of continuous benchmark problems.</p><p>Independently, some authors consider that the operator impact should be measured after the genealogy of the outstanding offspring, e.g., rewarding the operators producing the ancestors of a good offspring according to a bucket brigade algorithm <ref type="bibr" target="#b7">[6,</ref><ref type="bibr" target="#b22">20]</ref>. No clear indication however about the benefits of this approach is found in the literature to the best of our knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Operator Selection Rules</head><p>Most Operator Selection rules attach a probability of success to each operator<ref type="foot" target="#foot_0">foot_0</ref> . These probabilities can be used for selection along a roulette wheel-like process, like Probability Matching (PM) and Adaptive Pursuit (AP) (section 2.3.1); another possibility is based on the so-called Multi-Armed Bandit framework <ref type="bibr" target="#b1">[1]</ref> (section 2.3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Probability Matching and Adaptive Pursuit</head><p>Let K denote the number of variation operators. PM and AP both maintain a probability vector (si,t)i=1,K and an estimate of the current operator reward noted pi,t . At each time t: i) the i-th operator is selected with probability si,t, and gets an instant reward r computed after the credit assignment at hand ii) the reward estimate pi,t of the i-th operator is updated using an additive relaxation mechanism with adaptation rate α (0 &lt; α ≤ 1, the memory span decreases as α increases):</p><formula xml:id="formula_0">pi,t+1 = (1 -α) pi,t + α r<label>(1)</label></formula><p>Probability Matching mostly selects the i-the operator proportionally to pi,t , except for the fact that a minimum amount of exploration can be enforced. If the selection probability of an operator would become too low at some point, it would never be used again, thus precluding AOS from discovering that it becomes the optimal one in further stages of evolution.</p><p>Formally, letting pmin denote the minimal selection probability, then the selection probability of the i-th operator is defined as:</p><formula xml:id="formula_1">si,t+1 = pmin + (1 -K * pmin)</formula><p>pi,t+1</p><formula xml:id="formula_2">P K j=1 pj,t+1<label>(2)</label></formula><p>After Eq (2), any ineffective operator (not getting any reward) would be selected with probability pmin, while the best operator (getting maximal rewards) would be selected with probability 1 -K * pmin. In practice, all mildly relevant operators keep being selected, hindering the Probability Matching performance (all the more so as the number of operators increases) <ref type="bibr" target="#b33">[30]</ref>.</p><p>Adaptive Pursuit, originally proposed for learning automata, has been used in AOS to address the above Probability Matching shortcoming; a winner-take-all strategy is used to push forward the best current operator noted i * t as follows, where pmax = (1 -(K -1)pmin):</p><formula xml:id="formula_3">8 &lt; : i * t = arg maxi=1...K{ pi,t } si,t+1 =  si,t + β (pmax -si,t) if i = i * t si,t + β (pmin -si,t) otherwise<label>(3)</label></formula><p>Finally, both PM and AP are controlled from the pmin parameter (enforcing the exploration of the operators) and adaptation rate α (ruling the memory span of the AOS). AP additionally involves learning rate β, ruling the greediness of the winner-take-all strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Static and Dynamic Multi-Armed Bandit</head><p>Operator selection can be framed as another Exploration vs. Exploitation (EvE) dilemma, where Exploitation aims at selecting the best rewarded operators in the last stages of evolution whereas Exploration is concerned with checking whether other operators might in fact become the best ones at some later stages. The EvE dilemma has been intensively studied in Game Theory, more specifically in the so-called Multi-Armed Bandit (MAB) framework <ref type="bibr" target="#b24">[21,</ref><ref type="bibr" target="#b1">1]</ref>.</p><p>The MAB framework considers a set of K independent arms, each one of which having some unknown probability of getting a (boolean) reward. The optimal selection strategy is one maximizing the cumulative reward along time. The Upper Confidence Bound (UCB) selection strategy proposed by Auer et al. <ref type="bibr" target="#b1">[1]</ref>, providing asymptotic optimality guarantees, can be phrased as Optimism in front of the Unknown. Formally, to the i-th arm is associated i) its empirical reward pi (the average reward obtained) and ii) a confidence interval, depending on the number of times ni the i-th arm has been tried. UCB selects in each time step the arm with best upper bound of the confidence interval:</p><formula xml:id="formula_4">Select arg max i=1...K pi,t + C s log P k n k,t ni,t !<label>(4)</label></formula><p>The C parameter, referred to as scaling factor, controls the tradeoff between exploitation (left term in Eq. ( <ref type="formula" target="#formula_4">4</ref>), favoring the arms with best empirical reward) and exploration (right term, favoring the infrequently tried arms). The efficiency of the UCB rule follows from the fact that, although every arm is selected exponentially often, the lapse of time between two selections of some under-optimal arm increases exponentially.</p><p>The standard MAB framework and the UCB algorithm however consider a static environment (the unknown reward probability of any arm being fixed along time), whereas the AOS framework is intrinsically dynamic (the quality of any operator is bound to vary along evolution). Even though every operator keeps being selected, enabling UCB to ultimately realize that some new operator has become the best one, in practice UCB would need to wait way too long before switching to the best operator. A Dynamic Multi-Armed Bandit (DMAB) strategy <ref type="bibr" target="#b16">[14]</ref> has thus been used in <ref type="bibr" target="#b6">[5]</ref> to address this limitation, coupling UCB with a change detection test, the statistical Page-Hinkley (PH) test <ref type="bibr" target="#b17">[15]</ref>. Basically, the PH test is in charge of checking whether the operator reward distribution has changed; upon its triggering, UCB is restarted (i.e., the empirical rewards and confidence intervals are re-initialized) in order to quickly identify the new best operators without being slowed down by now irrelevant information.</p><p>Formally, the PH test works as follows, where rt denotes the average reward over the last t steps, and et the difference between the instant and average reward, plus some small tolerance δ. Considering the random variable mt = P t 1 ei, the PH test is triggered when the difference between Mt = max i≤t |mi| and |mt| is greater than some user-specified threshold γ:</p><formula xml:id="formula_5">rt = 1 t P t i=1 ri mt = P t i=1 (ri -ri + δ) Return (maxi=1...t{|mi|} -|mt| &gt; γ)<label>(5)</label></formula><p>The PH test thus is parametrized by γ (controlling the test sensitivity and the rate of false alarms) and δ (enforcing the test robustness w.r.t slowly varying environments). Following early experiments, δ has been kept fixed to 0.15 throughout this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">GOALS OF THE STUDY</head><p>As mentioned earlier on, the above AOS settings have been mostly considered outside of any evolutionary environment <ref type="bibr" target="#b33">[30,</ref><ref type="bibr" target="#b34">31,</ref><ref type="bibr" target="#b6">5]</ref>, assuming the operator reward to be neatly defined as a (continuous or boolean) random variable following a periodically changing (uniform or Bernoulli) distribution. The first embedding of the above AOS schemes within an actual evolutionary algorithm has been investigated in <ref type="bibr" target="#b11">[10]</ref>; the operator reward was based on the fitness improvement of the offspring compared to the parent, and computed as either the average (AverageReward) or the maximum (ExtremeReward) fitness improvement observed the last W times the operator had been applied. The fitness landscape considered in <ref type="bibr" target="#b11">[10]</ref>, the OneMax landscape, however is devoid of any deceptivity or discontinuity, two among the main difficulties faced by EC on real-world problems. Deceptive landscapes, intensively investigated in the EC literature <ref type="bibr" target="#b14">[13]</ref>, involve a (concatenation of) sub-optimal, One-Max like regions, besides an external optimal peak. Discontinuous landscapes involves short-cuts, where significantly higher fitness regions can be discovered through the lucky application of a given variation operator.</p><p>The goal of the present paper thus is to study the AOS behavior w.r.t deceptive and discontinuous landscapes; the deceptive Royal Road <ref type="bibr" target="#b18">[16,</ref><ref type="bibr" target="#b31">28]</ref> and Long K-Path problems (briefly described in section 4.1 for the sake of self containedness) are considered as well-studied representatives of both types of difficulties. Specifically, Royal Road and Long K-Path problems raise an additional challenging issue for AOS compared to the OneMax problem. Fitness improvements are no longer homogeneous along evolution; whereas beneficial mutations all increase the fitness by the same amount in the OneMax problem, a beneficial crossover in Royal Road, or a beneficial mutation in Long K-Path, improve the fitness by an order of magnitude more than the standard fitness improvement. Furthermore, upon such a beneficial event, evolution migrates toward another region, potentially causing the reward distribution of all operators to change abruptly.</p><p>The effects of such fitness leaps will be empirically investigated through introducing an additional normalization mechanism as follows. In the rest of the paper, the instant operator value refers to the fitness gain of the offspring compared to its parent (mutation case) or its best parent (crossover case). The value is either set to the fitness gain (AbsoluteValue), or to the fitness gain divided by the best fitness gain gathered by an operator in the last W time steps (NormalizedValue). The operator reward is finally set to either the instant value averaged over the last W times the operator has been applied (AverageReward), or to the maximal (extreme) instant value observed during the last W times the operator has been applied (ExtremeReward). Overall, four types of reward will thus be considered: ExtremeAb-soluteReward(XAbs), ExtremeNormalizedReward(XNorm), AverageAbsoluteReward (AvgAbs) and AverageNormalize-dReward (AvgNorm). All four Credit Assignment involve the time window W as single hyper-parameter. Note that W relates to the time scale of evolution; if too large, operators will be applied after their optimal epoch and the switch from the previous best operator to the new best one will be delayed. If W is too small, operators causing large but infrequent jumps will be ignored (as lucky events will not be observed in the first place), or rapidly forgotten.</p><p>These four Credit Assignment will be independently combined with the four Operator Selection (PM, AP, Multi-Armed Bandit and Dynamic Multi-Armed Bandit) described in section 2.3. For the sake of the lessons learned, each one of these 16 AOS settings will be launched with the best hyperparameters. A secondary goal of the study is to assess the stability and robustness of the AOS settings with respect to their hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL SETTING</head><p>This section first describes the Royal Road and Long K-Path problems used for the empirical validation of the AOS schemes. AOS hyper parameters are thereafter summarized, and the racing procedure used to select appropriate values for these hyper-parameters in a tractable way is last described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Royal Road</head><p>Royal Road problems were purposely devised as difficult optimization problems for hill-climbing algorithms, while being easy for GAs as they are made of "building blocks" <ref type="bibr" target="#b29">[26]</ref>. Due to unexpected difficulties (the so-called hitch-hiking phenomenon), revised Royal Road problems were proposed <ref type="bibr" target="#b18">[16]</ref> and analyzed <ref type="bibr" target="#b21">[19]</ref>.</p><p>In the revised Royal Road landscape, each bit-string is divided in 2 k regions, referred to as first-level schemata; each schema is made of a block and a gap string, of respective length b and g. Higher level schemata are formed by combining lower-level ones. Formally, 2 k-L schemata of level L are defined, each one being made of 2 L 1st-level ones, supposedly defining a crossover-friendly landscape.</p><p>The fitness function only considers the block region of each low level schema, ignoring the gap region. The PART function computes the number z of correct bits in the blength block; the associated fitness is z × v if z &lt; m and (b -z) × v for m &lt; z &lt; b, thus corresponding to a locally deceptive fitness function. If the block is complete (z = b), and the block is the first one to be formed in the individual, the PART function is replaced by a BONUS one, and the individual fitness scores a bonus of u * ; any further complete block is worth an additional u fitness score.</p><p>After <ref type="bibr" target="#b31">[28]</ref>, uniform crossover (respectively 1-point crossover) allegedly is the best operator during the first (resp. the last) evolution stages; the 4-point crossover is the best operator in-between. The goal of the experiments with the Royal Road problem thus is whether the AOS approaches actually select the appropriate operators at different stages of evolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Long K-Path Problem</head><p>Originally proposed by Horn et al. <ref type="bibr" target="#b19">[17]</ref>, Long paths problems are unimodal optimization problems defined on {0, 1} ℓ , designed to challenge local search algorithms. The optimum can be found by climbing a path, the length of which increases exponentially with the dimension ℓ of the search space; efficient optimization thus relies on finding short-cuts on the path.</p><p>The so-called Long k-paths problems, introduced by <ref type="bibr" target="#b32">[29]</ref>, generalizes the long paths problems; k is the minimal number of bits that must be simultaneously flipped in order to take a shortcut on the path. Formally the Long K-Path can be described as follows <ref type="bibr" target="#b13">[12]</ref>:</p><p>• The path starts at point 0, . . . , 0, with fitness ℓ; the fitness of any point not on the path is the number of its 0 bits;</p><p>• Any point on the path has exactly 2 neighbors at Hamming distance 1 that are on the path;</p><p>• Mutating i &lt; k bits of a point on the path leads to a point which is either off the path (hence with a very low fitness), or on the path but only i positions away from the parent point;</p><p>• A shortcut is found by mutating the correct k bits (or more), thus with probability p k (1 -p) l-k .</p><p>Long K-Path problems are defined by recurrence on ℓ. The path associated to problem P (k, ℓ + k) is built as the sequence of (xi, 0 k ) where xi belongs to P (k, ℓ) and 0 k is the k-length vector made of 0s, followed by a "bridge", followed by the sequence (xL-i, 1 k ), where xL-i ranges in inverse order in P (k, ℓ) and 1 k is the k-length vector made of 1s. The bridge is the sequence of (xL, yz) where xL is the last point of path P (k, ℓ) and yz is the k-length vector made of z 0s followed by k-z 1s. It turns out that the path length decreases as k increases (the original long path corresponds to k = 2). The probability of finding a shortcut however exponentially decreases with k, and the fastest strategy for k &gt; √ ℓ is to simply follow the path <ref type="bibr" target="#b13">[12]</ref>. Otherwise (k ≤ √ l), optimization should provably strive to find the shortcuts; in such cases, exceptional properties of operators are more relevant to EAs behavior than their average properties.</p><p>Overall, the choice of the Long K-Path problem is meant to investigate whether (and which) AOS approaches manage to use operators which rarely but very significantly contribute to the progress of optimization. This problem was also considered in <ref type="bibr" target="#b12">[11]</ref> to investigate the relevance of extremevalue based (as opposed to average-value based) rewards. Finally, artificial Long K-Path problems make it feasible to identify the optimal operator at each point of the path (e.g., through intensive Monte-Carlo simulations), and to assess the AOS approaches by comparison with the optimal strategy. The hyper-parameters involved in the presented AOS schemes are summarized in Table <ref type="table" target="#tab_0">1</ref>. In the absence of any theoretical guidance, how to tune the hyper-parameter values depending on the optimization problem at hand defines yet another optimization problem. An exhaustive exploration of the (discretized) search space, a.k.a complete factorial design of experiment, is quite computationally expensive; it requires one to compute the performance associated to every possible hyper-parameter setting, averaged over some independent M runs for the sake of significance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Hyper-parameters and F-Racing</head><p>Therefore a racing method is used for discarding as early as possible the unpromising settings. Formally, the Friedman's two-way Analysis of Variances by the ranks is used as statistical test <ref type="bibr" target="#b4">[4]</ref> to determine whether a setting is significantly worse than the current best one. F-racing proceeds by repeating an "execution/comparison/elimination" cycle until there is a single candidate setting left, or all remaining candidates have been run M times. The criterion used for Friedman's test is the number of generations needed to reach the optimal solution, or 25000 if the optimum is not found before that many generations. The number M of runs is set to 50, due to the high variance of the results (e.g., as compared to <ref type="bibr" target="#b4">[4]</ref>); for the same reason, a minimum number of 11 runs for each setting was launched before elimination starts; elimination is based on Friedman's test with 95% confidence. Overall, F-racing reduces the computational cost by 50% compared to the complete factorial DoE, bringing a significantly lesser gain than in <ref type="bibr" target="#b4">[4]</ref>.</p><p>Table <ref type="table" target="#tab_2">2</ref> displays the result of the F-race for each AOS setting, providing some insight into their sensitivity and robustness. Interestingly, the Dynamic Multi-Armed Bandit AOS retains many good hyper-parameter settings until the end; although this increases the computational load as less settings are eliminated, it suggests that Dynamic Multi-Armed Bandit is actually more robust w.r.t. hyper-parameter values than other AOS settings. Quite the opposite, AP shows a fast convergence toward a unique hyper-parameter setting in most of the cases, finding the optimal pmin value as = .2 -which actually corresponds to a uniform selection among the five variation operators considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Conditions</head><p>In the Long K-Path problems, k is set to 3; the bit-string length ℓ ranges in {43, 49, 55, 61}. Most results will however be presented on the instance of size 49, an arbitrary choice as all instances seem to give approximately the same results with respect to AOS performance (except the largest one that proved too difficult). Five mutation operators are considered: 1, 3 and 5-bit mutations (mutating exactly 1, 3 or 5 bits uniformly selected in the bitstring); the 1/ℓ bit-flip (every bit is flipped with probability 1/ℓ, ℓ being the bit-string length), and lastly the k/ℓ bit-flip, supposedly the optimal single operator on Long K-Path problems <ref type="bibr" target="#b13">[12]</ref>.</p><p>All AOS schemes are embedded into a (1+50)-EA<ref type="foot" target="#foot_1">foot_1</ref> ; the hyper-parameters are set to their optimal values according to the racing results, that can be found in Table <ref type="table" target="#tab_3">3</ref>. Their results are assessed comparatively to two reference strategies: the Naive strategy uniformly selects one operator among the available ones; and the Optimal strategy only selects the optimal operator at each point of the path (section 4.2).</p><p>The Royal Road problems involve the default values proposed by Holland <ref type="bibr" target="#b18">[16]</ref>, i.e., k = 4, b = 8, g = 7, m = 4, v = 0.02, u * = 1.0 and u = 0.3. Each one of the 2 k regions involving (b + g) bits, the dimension of the search space is 240 bits <ref type="foot" target="#foot_2">3</ref> .</p><p>The AOS schemes are embedded into a (100, 100)-EA with weak elitism (the best individual is never lost) with a tournament size 2. Five variation operators are considered: 1-point, 2-point, 4-point and uniform crossover, plus a disruptive mutation operator that flips each bit with a probability of 1/30, thus flipping 8 bits (and hence possibly one block) on average. Each crossover is followed by a 1/100 bit-flip mutation. Contrasting with Long K-Path, the optimal operator cannot be easily accessed, as the fitness landscape includes many paths toward the optimal solution. The AOS schemes (likewise parametrized after the optimal setting, see the results in  Such different settings corresponds to different characteristics of the operators under scrutiny here: the Long K-Path problem is better solved by mutations, and crossover is of poor help: a few trials with the (100,100)-EA scheme gave very poor results indeed. The situation is even more constrained with the crossover operators, as they do not make any sense with a population of size 1, as in the (1+50)-EA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS AND DISCUSSION</head><p>For each problem and AOS scheme, the results will be assessed through the number of generations needed to reach the optimal solution. Because of the high dispersion of the results, averages and standard deviations are not meaningful, and best and median results will be presented, grouped in Tables <ref type="table" target="#tab_3">3</ref> and<ref type="table" target="#tab_1">4</ref>. However, those numbers are clearly insufficient, and some empirical distributions of the results will also be presented as boxplots. Furthermore, all differences between AOS schemes will be validated using both unsigned Wilcoxon rank sum, and Kolmogorov-Smirnov nonparametric tests, (termed W and KS in the following).</p><p>Regarding the Long K-Path problem, the best AOS scheme is Dynamic Multi-Armed Bandit with ExtremeAbsoluteReward which outperforms all other selection rules with Ex- tremeAbsoluteReward (Fig. <ref type="figure" target="#fig_1">2</ref>; the difference is significant w.r.t. MAB for W 99% and KS 95%, AP for W 95%, and the naive approach for W 90%), as well as all other rewards with Dynamic Multi-Armed Bandit selection (Fig. <ref type="figure" target="#fig_2">3</ref>; the difference is significant w.r.t. AverageAbsoluteReward for both tests at 95% confidence level). Moreover, this best AOS scheme is not statistically different from the optimal Long K-Path strategy for both tests at 99% confidence level. The high dispersion of the results is explained as some runs happen to discover shortcuts at the beginning of evolution, after the initial bump in the performance distribution noted in <ref type="bibr" target="#b13">[12]</ref>. This high dispersion also justifies a posteriori the choice of a large number of runs (M = 50) in the F-Race (section 4.3).</p><p>The situation is similar in the Royal Road problem: Dynamic Multi-Armed Bandit with ExtremeAbsoluteReward is better than all other selection rules with the same Credit Assignment (Fig. <ref type="figure" target="#fig_3">4</ref>; the difference is significant w.r.t. AP for W 90%, PM for both tests at 90%, and the naive approach for both tests at 99%). The extreme value-based rewards, either absolute or normalized (XAbs and XNorm) significantly  From left to right: ExtremeAbsolute, ExtremeNormalized, AverageAbsolute and Aver-ageNormalized Credit Assignment, and the naive uniform strategy. outperform the average-value based ones for both Dynamic Multi-Armed Bandit (Fig. <ref type="figure" target="#fig_4">5</ref>) and Multi-Armed Bandit (not shown), at 95% confidence level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DISCUSSION AND PERSPECTIVES</head><p>The systematic assessment of diverse Adaptive Operator Selection schemes on two challenging although artificial fitness landscapes supports some former claims, while bringing some unexpected results. A first claim, fully supported by the empirical evidence in the limit of the considered problem instances, concerns the relevance of extreme-value based rewards, significantly outperforming average-based value rewards on all considered problem instances. This result confirms the importance of extreme events for the success of evolution.</p><p>A second experimental finding concerns the good general performance of Dynamic Multi-Armed Bandit (although slightly outperformed by Multi-Armed Bandit on the Royal  <ref type="table" target="#tab_1">4</ref>: Royal Road (5 operators). For each AOS is reported the best -median result; the optimal hyper-parameter setting after F-Racing is indicated below, where * stands for W = 500 (50 otherwise). Rows are as in Table <ref type="table" target="#tab_3">3</ref>.</p><p>Road), together with its stability w.r.t. the hyper-parameters of AOS (Table <ref type="table" target="#tab_2">2</ref>) and its lesser variance compared to Multi-Armed Bandit (see for instance Fig. <ref type="figure" target="#fig_1">2</ref>, and, to a lesser extent, Fig. <ref type="figure" target="#fig_3">4</ref>); the same behavior is observed in many others settings (not shown). These results contrast with Adaptive Pursuit, whose best setting in fact implement a uniform search (pmin = .2 for the selection among 5 operators).</p><p>Overall, the relevance of AOS schemes can be argued from the fact that they significantly improve on fixed operator selection strategies<ref type="foot" target="#foot_3">foot_3</ref> . While one might object that AOS schemes involve hyper-parameters, and thus also require some preliminary parameter tuning phase, it must be observed that the number of hyper-parameters does not depend on the number of variation operators. Furthermore, as suggested by Table <ref type="table" target="#tab_2">2</ref>, the question of finding good hyperparameters might be less peaked and thus less critical than the question of finding good parameters.</p><p>Further research is concerned with devising artificial problems with known optimal AOS strategies, in order to identify more precisely the strengths and limitations of the AOS schemes under investigation. Another issue is to self-adapt the change detection threshold γ in Dynamic Multi-Armed Bandit, to account for the fact that the fitness improvements vary along the different evolution stages. Specifically, the bounding of the total number of restarts allowed along evolution will be investigated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Adaptive Operator Selection scheme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: AOS performances on Long K-Path, using the Extreme/Absolute Credit Assignment. From left to right: optimal strategy, Dynamic Multi-Armed Bandit, Multi-Armed Bandit, AP, PM and the naive uniform strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: AOS performances on Long K-Path, using the Dynamic Multi-Armed Bandit Operator Selection. From left to right: optimal strategy, Ex-tremeAbsolute, ExtremeNormalized, AverageAbsolute and AverageNormalized Credit Assignment, and the naive uniform strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: AOS performances on Royal Road, using the Extreme/Absolute Credit Assignment. From left to right: Dynamic Multi-Armed Bandit, Multi-Armed Bandit, AP, PM and the naive strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: AOS performances on Royal Road, using the Dynamic Multi-Armed Bandit Operator Selection.From left to right: ExtremeAbsolute, ExtremeNormalized, AverageAbsolute and Aver-ageNormalized Credit Assignment, and the naive uniform strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>AOS Hyper-parameters and value range</figDesc><table><row><cell>Heuristic</cell><cell>H-P</cell><cell>Range</cell><cell>Comments</cell></row><row><cell>XAbs, XNorm,</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Avg{Abs,Norm}</cell><cell>W</cell><cell>{50, 500}</cell><cell>Time window</cell></row><row><cell>AP, PM AP, PM</cell><cell>p min α</cell><cell>{0; .05; .1; .2} {.1, .3, .6, .9}</cell><cell>Min. select. prob. Adaptation rate</cell></row><row><cell>AP</cell><cell>β</cell><cell>{.1, .3, .6, .9}</cell><cell>Learning rate</cell></row><row><cell>MAB, DMAB</cell><cell>C</cell><cell>{{1, 5}.10 {-4≤i≤1} , 25, 100}</cell><cell>Scaling factor</cell></row><row><cell>DMAB (PH)</cell><cell>γ</cell><cell>Range(C) ∪ {250, 500, 1000}</cell><cell>PH threshold</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 )</head><label>4</label><figDesc>are assessed comparatively to the Naive reference strategy, uniformly selecting one operator among the available ones.</figDesc><table><row><cell>Problem</cell><cell>Reward</cell><cell cols="2">DMAB Exps. Configs.</cell><cell cols="2">MAB Exps. Configs.</cell><cell>Exps.</cell><cell>AP</cell><cell>Configs.</cell><cell>Exps.</cell><cell>PM</cell><cell>Configs.</cell></row><row><cell></cell><cell>XAbs</cell><cell>9352/23800</cell><cell>40/476</cell><cell>1197/1400</cell><cell>21/28</cell><cell cols="2">2304/6400</cell><cell>17/128</cell><cell cols="2">1156/1600</cell><cell>20/32</cell></row><row><cell>RR's m  *  =4</cell><cell>XNorm AvgAbs</cell><cell cols="3">11623/23800 108/476 1124/1400 11650/23800 89/476 1092/1400</cell><cell>20/28 14/28</cell><cell cols="2">2518/6400 1478/6400</cell><cell>18/128 1/128</cell><cell cols="2">1236/1600 898/1600</cell><cell>11/32 14/32</cell></row><row><cell></cell><cell cols="2">AvgNorm 8790/23800</cell><cell>51/476</cell><cell>821/1400</cell><cell>11/28</cell><cell cols="2">1478/6400</cell><cell>1/128</cell><cell cols="2">400/1600</cell><cell>1/32</cell></row><row><cell></cell><cell>XAbs</cell><cell>6572/23800</cell><cell>16/476</cell><cell>1088/1400</cell><cell>20/28</cell><cell cols="2">1819/6400</cell><cell>1/128</cell><cell cols="2">841/1600</cell><cell>11/32</cell></row><row><cell>3-Path(49)</cell><cell>XNorm AvgAbs</cell><cell cols="2">10397/23800 17878/23800 261/476 72/476</cell><cell>437/1400 971/1400</cell><cell>1/28 17/28</cell><cell cols="2">1770/6400 2666/6400</cell><cell>1/128 1/128</cell><cell cols="2">840/1600 1564/1600</cell><cell>10/32 29/32</cell></row><row><cell></cell><cell cols="2">AvgNorm 12449/23800</cell><cell>78/476</cell><cell>1088/1400</cell><cell>20/28</cell><cell cols="2">1608/6400</cell><cell>1/128</cell><cell cols="2">1600/1600</cell><cell>32/32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results of F-racing procedure, comparing all selection schemes over 5 variation operators, on the Royal Road and Long K-Path problems. Exps columns indicate the number of runs which were not pruned (not significantly worse than the best one) out of the complete factorial DoE. Columns Configs give the number of optimal hyper-parameter settings after the F-racing.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Long K-Path, k = 3, ℓ = 49. For each AOS scheme is reported the best -median result; the optimal hyper-parameter setting after F-Racing is indicated below, where * stands for W = 500 (50 otherwise).</figDesc><table><row><cell>Reward</cell><cell>DMAB</cell><cell>MAB</cell><cell>AP</cell><cell>PM</cell></row><row><cell>XAbs</cell><cell>38 -3641 C50γ10 *</cell><cell>33 -7201 C100</cell><cell>43 -5207 Pm.2 *</cell><cell>38 -5003 Pm.1α.1 *</cell></row><row><cell>XNorm</cell><cell>14 -4680 C10γ.1</cell><cell>23 -4851 C100</cell><cell>43 -5207 Pm.2 *</cell><cell>43 -5198 Pm.2</cell></row><row><cell>AvgAbs</cell><cell>45 -5794 C.5γ500</cell><cell cols="2">736 -3851 43 -5207 C10 Pm.2 *</cell><cell>65 -4592 Pm0α.3</cell></row><row><cell>AvgNorm</cell><cell cols="3">770 -3840 736 -3304 43 -5207 C.005γ10 C.001 Pm.2 *</cell><cell>4 -4720 Pm.05α.3</cell></row><row><cell>DMAB</cell><cell>MAB</cell><cell></cell><cell>AP</cell><cell>PM</cell></row><row><cell cols="2">1889 -6572</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Methods that recompute those probabilities from scratch from the most recent rewards<ref type="bibr" target="#b22">[20,</ref><ref type="bibr" target="#b35">32]</ref> will not be considered here.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>50 offspring are created from the single parent; next parent is the best out of the offspring and the current parent.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>Notably, the fully deceptive (m = 1) and not deceptive (m = 7) Royal Road were also investigated. The former problem was however found too difficult to be solved within 100,000 generations whereas the latter was too easy.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>With however one exception: the 4-point crossover (followed by a 1% bit-flip mutation) is shown to be the best single operator on Royal Road; it needs 6,500 generations in average to find the optimum, which is not statistically different from the ExtremeAbsoluteReward Dynamic Multi-Armed Bandit performance for both tests at 95%.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On adaptive operator probabilities in real coded genetic algorithms</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J C</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Sá</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intl. Conf. Chilean Computer Science Society</title>
		<meeting>Intl. Conf. Chilean Computer Science Society</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sequential parameter optimization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Bartz-Beielstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lasarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Preuss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CEC</title>
		<meeting>CEC</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="773" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A racing algorithm for configuring metaheuristics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Birattari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stützle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Paquete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Varrentrapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive operator selection with dynamic multi-armed bandits</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Da</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO</title>
		<meeting>GECCO</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="913" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adapting operator probabilities in genetic algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICGA</title>
		<meeting>ICGA</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Parameter Setting in EAs: a 30 Year Perspective</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">De</forename><surname>Jong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parameter Setting in Evolutionary Algorithms</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Lobo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lima</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Parameter control in Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hinterding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">124</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parameter Control in Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parameter Setting in Evolutionary Algorithms</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Lobo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lima</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="19" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extreme value based adaptive operator selection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Da</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PPSN X</title>
		<meeting>PPSN X</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="175" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic multi-armed bandits and extreme value-based rewards for adaptive operator selection</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dacosta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LION-3</title>
		<meeting>LION-3</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Statistical distribution of the convergence time of evolutionary algorithms for long-path problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Garnier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kallel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="30" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deception considered harmful</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Genetic Algorithms</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="75" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Change point detection and meta-bandits for online learning in dynamic environments</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hartland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Teytaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CAp&apos;07</title>
		<meeting>CAp&apos;07</meeting>
		<imprint>
			<date type="published" when="2007-07">July 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Inference about the change point from cumulative sum-tests</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hinkley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="509" to="523" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Royal road functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Internet Genetic Algorithms Digest</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">22</biblScope>
			<date type="published" when="1993">1993</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long path problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PPSN III</title>
		<meeting>PPSN III</meeting>
		<imprint>
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Performance prediction and automated tuning of randomized and parametric algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hamadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CP 2006, number 4204 in LNCS</title>
		<meeting>CP 2006, number 4204 in LNCS</meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="213" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A description of Holland&apos;s Royal Road</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="409" to="415" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">What have you done for me lately? Adapting Operator Probabilities in a Steady-State Genetic Algorithms</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Julstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICGA</title>
		<meeting>ICGA</meeting>
		<imprint>
			<biblScope unit="page" from="81" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Asymptotically efficient adaptive allocation rules</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in applied mathematics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="4" to="22" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Decision making in a hybrid genetic algorithm</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICEC&apos;97</title>
		<meeting>ICEC&apos;97</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="121" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Parameter Setting in Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lobo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>IEEE Press</publisher>
			<pubPlace>Piscataway, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Battiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Watson</surname></persName>
		</author>
		<title level="m">Learning and Intelligent Optimization, Foundations of Computing</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A compass to guide genetic algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Saubion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. PPSN X</title>
		<meeting>PPSN X</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="256" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The royal road for genetic algorithms: Fitness landscapes and GA performance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Forrest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECAL</title>
		<meeting>ECAL<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="245" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Relevance estimation and value calibration of evolutionary algorithm parameters</title>
		<author>
			<persName><forename type="first">V</forename><surname>Nannen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Eiben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI&apos;07</title>
		<meeting>IJCAI&apos;07<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="975" to="980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The royal road functions: Description, intent and experimentation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Quick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Rayward-Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Selected Papers from AISB Workshop on Evolutionary Computing</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="223" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Convergence Properties of Evolutionary Algorithms</title>
		<author>
			<persName><forename type="first">G</forename><surname>Rudolph</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Verlag Dr. Kovac</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An adaptive pursuit strategy for allocating operator probabilities</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO&apos;05</title>
		<editor>
			<persName><forename type="first">H.-G</forename><surname>Beyer</surname></persName>
		</editor>
		<meeting>GECCO&apos;05</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="1539" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adaptive Strategies for Operator Allocation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Thierens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parameter Setting in Evolutionary Algorithms</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Lobo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lima</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Michalewicz</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="77" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adapting operator settings in genetic algorithms</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tuson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="184" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Use of statistical outlier detection method in adaptive evolutionary algorithms</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Whitacre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Q</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Sarker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GECCO&apos;06</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Cattolico</surname></persName>
		</editor>
		<meeting>GECCO&apos;06</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1345" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Statistical racing techniques for improved empirical evaluation of evolutionary algorithms</title>
		<author>
			<persName><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gallagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<editor>
			<persName><forename type="first">Xin</forename><surname>Yao</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3242</biblScope>
			<biblScope unit="page" from="172" to="181" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
