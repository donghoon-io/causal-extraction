<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RootPath: Root Cause and Critical Path Analysis to Ensure Sustainable and Resilient Consumer-Centric Big Data Processing under Fault Scenarios</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Umit</forename><surname>Demirbaga</surname></persName>
						</author>
						<author role="corresp">
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Gagangeet</forename><surname>Singh Aujla</surname></persName>
							<email>gagangeet.s.aujla@durham.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Medicine</orgName>
								<orgName type="institution">University of Cam- bridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Bartin University</orgName>
								<address>
									<settlement>Türkiye</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Durham University</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RootPath: Root Cause and Critical Path Analysis to Ensure Sustainable and Resilient Consumer-Centric Big Data Processing under Fault Scenarios</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/tce.2023.3329545</idno>
					<note type="submission">This accepted manuscript is licensed under the Creative Commons Attribution licence.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T19:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Big data</term>
					<term>Root cause analysis</term>
					<term>Critical path analysis</term>
					<term>Artificial intelligence Demirbaga</term>
					<term>U.</term>
					<term>&amp; Aujla</term>
					<term>G. S</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The exponential growth of consumer-centric big data has led to increased concerns regarding the sustainability and resilience of data processing systems, particularly in the face of fault scenarios. This paper presents an innovative approach integrating Root Cause Analysis (RCA) and Critical Path Analysis (CPA) to address these challenges and ensure sustainable, resilient consumer-centric big data processing. The proposed methodology enables the identification of root causes behind system faults probabilistically, implementing Bayesian networks. Furthermore, an Artificial Neural Network (ANN)-based critical path method is employed to identify the critical path that causes high makespan in MapReduce workflows to enhance fault tolerance and optimize resource allocation. To evaluate the effectiveness of the proposed methodology, we conduct a series of fault injection experiments, simulating various real-world fault scenarios commonly encountered in operational environments. The experiment results show that both models perform very well with high accuracies, 95%, and 98%, respectively, enabling the development of more robust and reliable consumer-centric systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>trends. Organizations can obtain actionable knowledge from data by using sophisticated analytics and machine learning algorithms to enhance decision-making, develop consumercentric strategies, and personalize experiences at scale. As a result, the incorporation of strong big data platforms becomes critical in effectively processing and exploiting the quantity of information created by consumer-centric contact, enabling businesses to provide heightened value and optimize their customer-centric activities.</p><p>Hadoop <ref type="foot" target="#foot_0">1</ref> implements the MapReduce programming model. MapReduce is developed for the parallel processing of largescale data by utilising map and reduce functions <ref type="bibr" target="#b0">[1]</ref>. Numerous map and reduce tasks are spread and carried out simultane- Critical path = B + F + J + L + M = 68 (s)</p><p>ously depending on the amount of data. This complexity of interactions and data transmission between dependent tasks leads to high execution time and poor performance, making it difficult to understand the root cause of problems (such as data skew, resource heterogeneity, and network issues). The performance of the MapReduce implementations is affected by the specific task, such as the poorly performed mapper in the red circle in Fig. <ref type="figure" target="#fig_0">1</ref>(a), as well as a set of operations called paths formed by interdependent tasks depicted in Fig. <ref type="figure" target="#fig_0">1(b)</ref>. Table <ref type="table" target="#tab_1">I</ref> presents the total execution times, measured in seconds, for each path of the MapReduce workflow. The critical path of the MapReduce workflow is the sequence of tasks that collectively take the longest time to complete. In this case, the critical path is identified to have a total execution time of 68 seconds. This critical path plays a crucial role in determining the overall efficiency and performance of the MapReduce workflow. Such struggling tasks or paths within jobs significantly influence the total execution time called makespan as the tasks must be completed to finalize the job in MapReduce. Some common reasons causing outlier problems and critical paths in the MapReduce framework include insufficient computing resources, network failures, and data skew, resulting in time loss, energy waste, and increasing cost <ref type="bibr" target="#b1">[2]</ref>. As a result, this complexity in such systems makes it complicated to identify the core reasons for high makespan resulting in performance reduction. To address the issues defined above, in this paper, we investigate the following research questions:</p><p>• (RQ1) How can one methodically and rigorously identify the underlying causal elements responsible for the prevalent issue of extended makespan, specifically within consumer-centric touch, while considering the intricate complexities and interdependencies inherent to contemporary big data systems? • (RQ2) How can we proficiently employ predictive methodologies and approaches to systematically predict the critical path embedded within the MapReduce workflow, which invariably exacerbates prolonged makespan while considering various fault scenarios and their potential impacts in consumer-centric interactions?</p><p>Much recent work focus on addressing big data systems problems, including debugging <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, task scheduling <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, modelling <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. Numerous papers discussing the root cause analysis in big data systems have been published in the literature. The authors of <ref type="bibr" target="#b8">[9]</ref> propose an offline framework for root cause analysis for MapReduce workflows by defining an outlier detection model. Garraghan et al. <ref type="bibr" target="#b9">[10]</ref> suggest a new approach to identifying long-tail behavior in big data systems, evaluated through Google cluster workload traces. The authors of <ref type="bibr" target="#b10">[11]</ref> propose a root cause analysis method based on Regression Neural Network (RNN) that defines the outlier tasks for Apache Spark. Another ML-based root cause analysis method is proposed by <ref type="bibr" target="#b11">[12]</ref> implementing Reinforcement Learning for performing root cause analysis of outliers. A statistical approach is proposed by <ref type="bibr" target="#b12">[13]</ref> to perform real-time performance diagnosis for big data systems. They develop user-defined functions to find outliers by referring to a threshold, then process the collected logs to find the reasons for outliers based on common big data issues, namely data skew, resource heterogeneity, and network problems (e.g., disconnection). However, these works can perform root cause analysis by considering the complex relationship between stochastic factors and not analysing such features probabilistically. Some published works discuss critical path analysis to diagnose big data systems. Gianniti et al. <ref type="bibr" target="#b13">[14]</ref> suggest a critical path approach that models the prediction of execution time for MapReduce and Spark applications by deploying Fluid Petri Nets techniques. They, however, consider only the limited features determining the job execution time, not considering the faults scenarios. Böhme et al. <ref type="bibr" target="#b14">[15]</ref> introduce an innovative and adaptable performance analysis methodology by considering the critical path method. They suggest numerous concise performance indicators that intuitively direct the examination of complicated load-imbalance phenomena by illuminating the connection between critical and non-critical operations to calculate the performance indicators in a very scalable manner by replaying event traces for massively parallel programs with thousands of processes. Heath et al. <ref type="bibr" target="#b15">[16]</ref> propose a highlevel abstract tool that depicts the critical path in a spacetime diagram for performance visualization. The performed case studies demonstrate the relationships between the fundamental data visualisation ideas and the model. The authors in <ref type="bibr" target="#b16">[17]</ref> propose a distributed big data analytics framework that implements projection insertion to extract unused data and redundant codes to optimize the performance of the applications based on the critical path. To evaluate the proposed method, they implement it for both Spark and Hadoop frameworks. However, these works do not consider end-to-end critical path analysis for big data systems.</p><p>As indicated above, the existing literature on consumercentric touch and big data systems has primarily focused on the importance of personalized customer experiences and the utilization of big data platforms for gathering insights. However, there is a considerable gap in the literature surrounding identifying and analysing the core causes of performance degradation and high execution time in big data systems. Moreover, while the literature acknowledges that issues such as data skew, resource heterogeneity, and network failures can impact performance, there is limited research on understanding and addressing these complex interactions and transmission problems between dependent tasks in MapReduce frameworks. Bridging this gap would give useful information for organizations looking to optimize their customer-centric operations and improve big data platforms' performance in customer-centric contact. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Contributions</head><p>To the extent of our knowledge, no study has examined the research questions (RQ1 and RQ2) about performing the root cause analysis for dependent components in MapReduce workflow and forecasting the makespan under fault conditions. To this end, in this paper, we focus on performing the contributions indicated below:</p><p>• To address RQ1, we propose a root cause analysis technique that implements the Complex Bayesian Network algorithm that allows us to represent the causal relationships between MapReduce performance variables in a graphical form to detect the main reason for the high makespan probabilistically. • To address RQ2, we develop an Artificial Neural Networks (ANNs)-based prediction model defining the critical path that causes high makespan in MapReduce workflow. We adopt ANNs as they are particularly well-suited for applications where the relationships between input and output variables are complex and non-linear and can learn from large amounts of data and identify patterns and relationships. The proposed system is presented in §II. While §III discuss the experimental results, §IV concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED SYSTEM: ROOTPATH</head><p>In this section, we present RootPath, which comprises two systems: a Bayesian network-based root cause analysis method and an ANN-based critical path prediction model for big data systems. We deploy SmartMonit <ref type="bibr" target="#b17">[18]</ref> to monitor and collect the performance metrics in one-second intervals. SmartMonit employs counters to collect statistics related to the MapReduce job. These counters include MapInputRecords, MapOutRecords, and ShuffleErrors, which facilitate progress monitoring within User-Defined Functions (UDFs). Concurrently, the collected time series data is injected into InfluxDB, a time series database, via the RabbitMQ message broker system to enable comprehensive data analysis and visualization. This robust architecture ensures efficient monitoring and data collection, enhancing the reliability and performance of consumer-centric big data processing systems. While Fig. <ref type="figure" target="#fig_1">2</ref> depicts the RootPath architecture for consumer-centric touch big data processing, Table <ref type="table" target="#tab_2">II</ref> shows these performance metrics used in implementing the proposed systems in this paper.</p><p>To create real-world big data systems problems, such as insufficient computing resources, network failures, and data skew, we injected different faults, such as data skew, CPU and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Bayesian Network for Root Cause Analysis</head><p>Bayesian networks, also known as probabilistic networks, are versatile models operating at the intersection of statistics and machine learning <ref type="bibr" target="#b18">[19]</ref>. They can replicate complex interaction systems with a network topology that uses nodes to represent measured characteristics and directed edges to indicate the interactions between those nodes. As a result, Bayesian networks provide a clear graphical representation of multivariate interdependencies, showing how information spreads. By leveraging such abilities of Bayesian networks, discovering the relationship among the components of big data applications can provide a deep understanding and insight into the context of root cause analysis for big data systems <ref type="bibr" target="#b19">[20]</ref>. In our approach, probabilistic inference, structure estimation, and parameter estimation methods collectively contribute to the effectiveness of the Complex Bayesian network. Probabilistic inference, realized through rejection sampling, facilitates the computation of conditional probabilities for unobserved variables, aiding in root cause identification. The network's predefined structure is complemented by dynamic structure estimation, enabling adaptability to specific data scenarios. Bayesian parameter estimation iteratively refines Conditional Probability Tables (CPTs), capturing intricate dependencies and enhancing accuracy in representing system dynamics. These methods empower the network to discern complex interdependencies and probabilistic relationships within consumercentric big data systems, crucial for robust root cause analysis. The proposed root cause analysis method offers several distinct advantages over conventional UDFs in the context of big data systems. While UDFs are typically manually crafted and necessitate extensive domain-specific expertise, the proposed method leverages automated algorithms and machine learning techniques to autonomously identify and categorize root causes of performance anomalies. This expedites the analysis process and enhances accuracy by eliminating potential human biases. Additionally, the scalability and adaptability of our </p><formula xml:id="formula_1">, G) = π i P (X i |P a(X i ), CP T )</formula><p>system to diverse data sets and evolving system conditions make it particularly well-suited for the dynamic and complex nature of consumer-centric big data processing systems.</p><p>To this end, we develop a novel root cause analysis technique built on a Complex Bayesian network, which reveals the complex and hidden relationship between the performance metrics (see Table <ref type="table" target="#tab_2">II</ref>) and between them and makespan. By leveraging the CPTs associated with each variable (X), the algorithm calculates the joint probability distribution (P ), enabling the assessment of how changes in various performance metrics probabilistically affect the makespan within our consumer-centric big data processing system. The complex Bayesian network algorithm is selected due to its capacity to model intricate variable dependencies in consumercentric big data. Unlike simpler methods like Naive Bayes, it accommodates non-linear relationships. It captures nuanced interactions, which better aligns with the complex and dynamic nature of consumer-centric data, enhancing the accuracy and robustness of our analysis. This enables us to build a root cause analysis for big data systems. Algorithm 1 explains the Complex Bayesian Network learning model to determine the probability of the evidence given some observed evidence. It initially arranges the nodes in a topological order (line 2) before utilizing rejection sampling to provide samples for unseen nodes (line 8). We optimized rejection sampling by employing topological sorting to streamline the sampling order, estimating accurate CPTs from available data, and fine-tuning the sampling strategy to balance accuracy and computational efficiency. Following that, Bayesian parameter estimation is used to estimate the CPTs for unobserved nodes (line 14). Finally, it uses CPTs to calculate the likelihood of the evidence given the evidence (line 18). The approach relies on CPTs that are known or estimable and an acyclic Complex Bayesian network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Critical Path Prediction using ANN</head><p>Critical path helps to model the Program Activity Graph (PAG) for parallel-running applications. The critical path within a MapReduce workflow holds significant importance as it represents the sequence of tasks that, if delayed, would result in the maximum extension of the job's completion time. Identifying and predicting the critical path is instrumental in optimizing the overall efficiency of MapReduce computations. By focusing on the critical path, resource allocation and task scheduling decisions can be tailored to prioritize the most time-sensitive tasks, thereby minimizing job completion times. Predicting the critical path aids in understanding job completion times by offering insights into the factors that exert the most substantial influence on the workflow's overall duration. As seen from Fig. <ref type="figure" target="#fig_0">1(b)</ref>, the longest way drawn in the red line also defines the end-to-end job completion time. Prediction of the critical path gives us preliminary information about the completion time of the job. ANN is a deep learning technique that is a valuable model for classification, clustering, pattern recognition, and prediction in numerous domains. In our proposed methodology, the ANN-based critical path prediction model employs a learning algorithm to adapt its network parameters and enhance its accuracy in predicting critical paths within consumer-centric big data processing workflows. This algorithm leverages a backpropagation mechanism, a widely utilized technique in neural network training, to iteratively adjust the model's weights and biases based on the discrepancy between predicted critical paths and ground truth data. Through this iterative process, the ANN endeavors to minimize the prediction error by updating its parameters, effectively learning the intricate patterns and relationships that govern critical paths in MapReduce workflows. The iterative ANN-based critical path model employs mechanisms to ensure convergence and prevent overfitting. We use dropout layers, randomly deactivating neurons in training to reduce reliance on specific ones, mitigating overfitting. We employ early stopping criteria, monitoring validation performance during training. Training is halted to prevent overfitting if the model's performance on the validation set deteriorates.</p><p>Our proposed algorithm (Algorithm 2) executes an iterative loop that goes through each instance in the training set for each epoch time. The iterative loop (line 8) is instrumental in detecting the critical path within our MapReduce workflow, aligning with the temporal nature of performance metric collection facilitated by our adopted big data monitoring framework, SmartMonit <ref type="bibr" target="#b17">[18]</ref>. This framework captures performance metrics at three-second intervals and stores them in a time-series database for analysis. Our critical path prediction module employs this iterative loop to analyze the collected data within predefined time intervals to pinpoint the critical path effectively. This approach accommodates the dynamic nature of performance metrics in big data processing, ensuring adaptive and responsive critical path detection. After that, the ANN learning algorithm gains insights into how often each hidden node contributes to the predictions of networks (line 10) before gaining insights into the behavior and performance of the ANN by computing the output node activation rates (line  ANN extracts important features and representations from input data by changing the weights from the input to the hidden layer (line 3). Updating the weights from the hidden to the output layers allows the network to produce more accurate predictions or classifications based on the hidden layer's characteristics (line 5). As a final step, the final activation rate of output nodes is determined to acquire the network's predictions or outputs for a given input (line 21).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RESULT AND DISCUSSION</head><p>RootPath is validated and tested extensively to evaluate its performance in big data processing systems under fault scenarios. The details are discussed in the subsequent sections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment Setup</head><p>Environments and benchmark. We deploy a Hadoop cluster over Ubuntu-based 30 AWS virtual machines (VMs). All the nodes have 4 CPUs and 16 GB memory, with SSD-based storage. We process the data, Consumer electronic dataset<ref type="foot" target="#foot_1">foot_1</ref> , consisting of 20 features, taken from Kaggle to gather performance metrics and train and test the proposed models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training Dataset</head><p>Table <ref type="table" target="#tab_2">III</ref> summarises the dataset used to develop the models for big data processing systems. It provides a concise summary of various performance metrics and their statistical characteristics, where each metric is followed by its mean, standard deviation, minimum, maximum, and count values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Fault Injection</head><p>Fault injections are required for testing diagnosis systems developed for big data systems to validate their accuracy, efficacy, and resilience in identifying and fixing failures or performance issues. They provide a controlled environment for recreating difficult fault scenarios, allowing for complete evaluation and development of the capabilities of the diagnosis systems. To this end, we develop fault injection models to create real-world problems encountered in big data systems: CPU fault, memory fault, network fault, and data skew fault. The CPU fault injection module emulates the generation of Pascal's Triangle, initializing with an initial row containing the value 1. Subsequently, it iteratively constructs each successive row by performing addition operations on the two numbers immediately preceding a given position. This process persists indefinitely until the user intervenes to halt it. To measure the impact of CPU faults, we monitor key performance metrics, including execution time, CPU utilization, and error rates, during fault injection experiments. The memory fault injection module initiates memory allocation operations, progressively allocating memory until it attains the predefined threshold established by the user. Similarly, we assessed the impact of memory faults by tracking memory usage, execution time, and error rates. The network fault injection module disrupts the network connectivity of the host machine upon its execution, and we quantified its impact on network latency, data transfer rates, and communication errors. Lastly, the data skew fault  injection module is responsible for deleting all data blocks resident on the machine, inducing delays from the need to transfer data from an alternate node. We analyze the effect on data transfer times, job completion rates, and loss for this fault. By measuring these specific performance indicators, we could comprehensively evaluate the impact of various fault scenarios on our system's resilience and performance. Fig. <ref type="figure" target="#fig_3">3</ref> shows the performance degradation when the system experiences faults, presenting the time differences between the tasks executed under different scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Findings and Interpretations</head><p>This section presents all the results for root cause analysis using the Complex Bayesian network and ANN-based critical path prediction.</p><p>1) Bayesian Network-based Root Cause Analysis Results: In this section, we provide two important results of implementing a Complex Bayesian network: the complex relationships between features and the probabilities of the features depending on other feature(s). The complex relationships between performance metrics and makespan are shown in Fig. <ref type="figure" target="#fig_4">4</ref>. The connections show the dependencies between the features, and the directions of the arrows indicate the parent-child status. For example, CPU usage is the parent of data split while data split is the parent of shuffle. In other words, CPU usage affects the data split, and shuffle is affected by data split. Considering Table <ref type="table" target="#tab_5">IV</ref> shows the CPTs uncovering the interdependencies between the different ranges of makespan and other performance metrics, such as CPUusage, dataSplit, reduce, and dat-aCombine. The numbers for dataSplit, reduce, dataCombine, and makespan are evaluated in seconds while CPUusage is considered as a percentage. We discretize the makespan into three different values based on the values in the dataset and focus on high makespan, namely the values higher than 75 seconds. Let us focus on the highest makespan values, higher than 75 seconds, as it is one of the factors that directly affects the critical path as shown in Fig. <ref type="figure" target="#fig_4">4</ref>. In this CPT, dataCombine greatly impacts makespan. There is a 26.11% probability of the makespan being over 75 seconds when the dataCombine is under 6 seconds, while there is an 85.3% probability of the makespan being over 75 seconds when the dataCombine is over 7 seconds. Fig. <ref type="figure" target="#fig_5">5</ref> demonstrates the structure correlation scores, namely F1 score, precision, recall, and overall accuracy of the developed Complex Bayesian network. The model performs well, with an accuracy of over 95%.</p><p>2) ANN-based Critical Path Prediction Results: Now, we will discuss the critical path prediction model performance results. Fig. <ref type="figure">6</ref> demonstrates the distributions of time densities for performance-related measures, evaluated as a healthy and unhealthy path. The unhealthy path, namely the critical path, represents the path of processes that cause long-term processing periods, called high makespan. As seen from the figures, for example, Fig. <ref type="figure">6</ref>(g) shows the CPU utilization distribution that critical path metrics are concentrated between 72% and 78% while health path metrics reach up to 90%. To give another example, the distribution of dataCombine time for the critical paths reaches up to 10 seconds while the distribution of healthy paths starts going down after 8 seconds, as shown in Fig <ref type="figure">6(e</ref>). Here, the makespan, which is the main criteria Healthy Critical defining the critical path, shows that the distribution of critical paths lies between 80 and 90 seconds while health paths vary from 55 to 85 seconds, in Fig. <ref type="figure">6</ref>(i). Fig. <ref type="figure">7</ref> shows the accuracies of training and validation over the number of epochs to monitor the performance of the ANN during the training process. The aim is to maintain a small gap between training and validation accuracy while achieving high accuracy on both the training and validation sets, which helps minimize overfitting. The performance of the critical path prediction model is shown through different performance values in Fig. <ref type="figure">8</ref>. The model reaches a high performance with a 98% accuracy rate. Fig. <ref type="figure">9</ref> depicts the relationship between the number of big data tasks running in parallel and the corresponding response time in seconds for two algorithms, Complex Bayesian Networks and ANN. Both algorithms demonstrate a similar increasing trend in response time as the workload intensifies. The Bayesian Networks algorithm's response time starts at 0.09 seconds for 50 tasks and gradually grows to 2.852 seconds for 500 tasks. Similarly, the ANN algorithm displays an initial response time of 0.12 seconds for 50 tasks, which escalates to 4.656 seconds for 500 tasks.</p><p>3) Comparative Analysis: We implement different algorithms along with ANN to evaluate the performance of  IV. CONCLUSION This study introduces RootPath, which comprises two innovative models to address challenges associated with debugging big data systems. The first model, centred on probabilistic root cause analysis and implemented within a Bayesian Network framework, is designed to identify the contributing features responsible for performance degradation in large-scale data processing systems. The second model, focused on critical path prediction and utilizing ANN, aims to forecast the critical path duration within MapReduce-based big data frameworks, offering insights into potential performance bottlenecks. Extensive experimentation has been conducted across various fault scenarios to assess the reliability and robustness of both models. The experimental results underscore the efficacy of RootPath, with the probabilistic root cause analysis achieving an impressive accuracy rate of ≈95%, while the ANN-based critical path prediction attains a notable accuracy rate of 98%. These findings underscore the potential of RootPath as a valuable tool for enhancing the diagnosis and optimization of big data systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Makespan evaluation in MapReduce workflow</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. RootPath diagnosing architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 2 : 2 //Update weights from input to hidden 3 U 4 //Update weights from hidden to output 5 V 9 /</head><label>223459</label><figDesc>Neural network learning algorithmInput: a ∈ R n in : input data k ∈ R n out : target output data, U ∈ R n in ×n hidden : weights from input to hidden, V ∈ R n hidden ×n out : weights from hidden to output, α ∈ R: learning rate, g(): activation function.Output: z ∈ R n out : final output prediction. 1 Function backPropagate(U, V, a, b, δz, δ b , α): begin ← U -αa T δ b ← V -αb Tδz 6 end 7 //Begin an iterative loop 8 for each epoch do /Compute the hidden node activation rates 10 b = g(aU ) 11 //Compute the output node activation rates 12 z = g(bV ) 13 //Compute the output error rate 14 δz = (z -k) ⊙ g ′ (bV ) 15 //Compute the hidden error rate 16 δ b = δzV T ⊙ g ′ (aU ) 17 //Update weights using backpropagation algorithm 18 backPropagate(U, V, a, b, δz, δ b , α) 19 end 20 //Compute the final activation rate of output nodes 21 z = g(aU V )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Execution time comparison</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Dependency network for Complex Bayesian network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Evaluation scores of the Complex Bayesian model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig. 6. Time density distributions for performance metrics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig. 11. Time-consuming for training and testing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I END</head><label>I</label><figDesc>-TO-END PATH DURATION OF FIG. 1(B)</figDesc><table><row><cell>A</cell><cell>B</cell><cell>C</cell><cell>D</cell><cell>E</cell><cell>F</cell><cell>G</cell><cell>H</cell><cell>I</cell><cell>J</cell><cell>K</cell><cell>L</cell><cell>M</cell><cell>Total</cell></row><row><cell>5</cell><cell cols="3">---</cell><cell cols="3">38 --</cell><cell>-</cell><cell>9</cell><cell>-</cell><cell>3</cell><cell>-</cell><cell>5</cell><cell>60</cell></row><row><cell>5</cell><cell cols="3">---</cell><cell cols="6">38 ----13</cell><cell>-</cell><cell>4</cell><cell>5</cell><cell>65</cell></row><row><cell>-</cell><cell>6</cell><cell cols="2">--</cell><cell cols="3">-40 -</cell><cell>-</cell><cell>9</cell><cell>-</cell><cell>3</cell><cell>-</cell><cell>5</cell><cell>63</cell></row><row><cell>-</cell><cell>6</cell><cell cols="2">--</cell><cell cols="3">-40 -</cell><cell cols="4">--13 -</cell><cell>4</cell><cell>5</cell><cell>68</cell></row><row><cell cols="2">--</cell><cell>5</cell><cell>-</cell><cell cols="3">--37</cell><cell>-</cell><cell>9</cell><cell>-</cell><cell>3</cell><cell>-</cell><cell>5</cell><cell>59</cell></row><row><cell cols="2">--</cell><cell>5</cell><cell>-</cell><cell cols="6">--37 --13</cell><cell>-</cell><cell>4</cell><cell>5</cell><cell>64</cell></row><row><cell cols="3">---</cell><cell>6</cell><cell cols="3">---</cell><cell>35</cell><cell>9</cell><cell>-</cell><cell>3</cell><cell>-</cell><cell>5</cell><cell>58</cell></row><row><cell cols="3">---</cell><cell>6</cell><cell cols="6">---35 -13</cell><cell>-</cell><cell>4</cell><cell>5</cell><cell>63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II BIG</head><label>II</label><figDesc>DATA PERFORMANCE METRICS Metrics Description dataSplit Time spent on data splitting in seconds. mapperTime Execution time since the mapper task started in seconds. shuffleTime Execution time spent on the shuffle phase in seconds. reducerTime Execution time since the reducer task started in seconds. dataCombine Time spent on data combining in seconds.</figDesc><table><row><cell>networkTraff</cell><cell>Network upload/download traffic of nodes in kilobytes.</cell></row><row><cell>CPUusage</cell><cell>CPU utilization of nodes as a percentage.</cell></row><row><cell>memUsage</cell><cell>Memory utilization of nodes as a percentage.</cell></row><row><cell>makespan</cell><cell>The total time spent on completing the job in seconds.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Algorithm 1 :</head><label>1</label><figDesc>Complex Bayesian Network Output: P (X e|e 1, ..., e k): probability of the evidence X e. 1 //Sort the V in G topologically to obtain a list W . 2 W l ← Sort V in G 3 for each X i in W l do Compute the X e given the evidence e 1, ..., e k using CP T . 18 P (Xe|e 1 , . . . , e k</figDesc><table><row><cell cols="2">Input: X: random variable</cell></row><row><cell></cell><cell>G: directed acyclic graph,</cell></row><row><cell></cell><cell>V : nodes,</cell></row><row><cell></cell><cell>E: directed edges,</cell></row><row><cell></cell><cell>CP T : conditional probability table,</cell></row><row><cell>4</cell><cell>if (X i observed Xe) then</cell></row><row><cell>5</cell><cell>X i ← Set e i</cell></row><row><cell>6</cell><cell>end</cell></row><row><cell>7</cell><cell>else</cell></row><row><cell>8</cell><cell>X i = RejectionSampling(P (X i|P a(X i), CP T ))</cell></row><row><cell>9</cell><cell>end</cell></row><row><cell>10 end</cell><cell></cell></row><row><cell cols="2">11 for each X i in W l do</cell></row><row><cell>12</cell><cell>if (X i not observed Xe) then</cell></row><row><cell>13</cell><cell>//Estimate CP T</cell></row><row><cell>14</cell><cell>CP T = BayesianP arameEst(X i, P a(X i), data)</cell></row><row><cell>15</cell><cell>end</cell></row><row><cell>16 end</cell><cell></cell></row><row><cell>17 //</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV CONDITIONAL</head><label>IV</label><figDesc>PROBABILITY TABLE (CPT) FOR MAKESPAN AND SOME OTHER PERFORMANCE METRICS</figDesc><table><row><cell>CPUusage (%)</cell><cell>CPUusage (&lt;75)</cell><cell>CPUusage (&lt;75)</cell><cell>CPUusage (&lt;75)</cell><cell>CPUusage (&lt;75)</cell><cell>CPUusage (&lt;75)</cell></row><row><cell>dataSplit (s)</cell><cell>dataSplit (&gt;11)</cell><cell>dataSplit (&gt;11)</cell><cell>dataSplit (&gt;11)</cell><cell>dataSplit (&gt;11)</cell><cell>dataSplit (&gt;11)</cell></row><row><cell>reduce (s)</cell><cell>reduce (&gt;4 &amp; &lt;5.5)</cell><cell>reduce (&gt;4 &amp; &lt;5.5)</cell><cell>reduce (&gt;4 &amp; &lt;5.5)</cell><cell>reduce (&gt;4 &amp; &lt;5.5)</cell><cell>reduce (&gt;4 &amp; &lt;5.5)</cell></row><row><cell>dataCombine (s)</cell><cell>dataCombine (&lt;6)</cell><cell>dataCombine (&gt;6 &amp; &lt;7)</cell><cell>dataCombine (&gt;6 &amp; &lt;7)</cell><cell>dataCombine (&gt;7)</cell><cell>dataCombine (&gt;7)</cell></row><row><cell>makespan (s) (&lt;67)</cell><cell>0.16%</cell><cell>0.01%</cell><cell>0.01%</cell><cell>0.04%</cell><cell>0.04%</cell></row><row><cell>makespan (s) (67 -75)</cell><cell>73.72%</cell><cell>51.82%</cell><cell>36.50%</cell><cell>24.74%</cell><cell>14.68%</cell></row><row><cell>makespan (s) (&gt;75)</cell><cell>26.11%</cell><cell>48.27%</cell><cell>63.48%</cell><cell>75.25%</cell><cell>85.30%</cell></row><row><cell cols="3">Abbreviations: &lt;, less than; &gt;, greater than; &amp;, and.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Weight adjustments through backpropagation finetune the network, helping it capture intricate data patterns that enhance the ANN's ability to identify critical paths by adapting its parameters to minimize prediction errors. Fig.11shows training and testing times, which vary due to their unique specifications. The ANN algorithm has complex architecture and computational requirements as it involves iterative adjustments of weights and biases, resulting in longer training and testing times. In contrast, PCA and ICA, which have lower times, employ linear transformations without extensive iterative computations. AE' training time depends on factors like the number of layers and data complexity, while the K-means algorithm's training time relies on data size, dimensionality, and convergence criteria. In summary, AE demonstrates superior performance regarding the temporal efficiency exhibited during the model's training and testing phases.In evaluating the ANN-based prediction model against traditional regression and statistical models, we found that the ANN</figDesc><table><row><cell>6FRUH</cell><cell>0HWULFV $FFXUDF\ )6FRUH 3UHFLVLRQ 5HFDOO</cell><cell>3HUFHQWDJH</cell></row><row><cell></cell><cell></cell><cell>$FFXUDF\ 3UHFLVLRQ</cell><cell>5HFDOO</cell><cell>)6FRUH</cell></row><row><cell></cell><cell></cell><cell cols="2">(YDOXDWLRQPHWULFVRIWKHPRGHO</cell></row><row><cell cols="4">Fig. 8. Performance evaluation values of the ANN model 50 100 150 200 250 300 350 400 450 500 Number of big data tasks running in parallel 0 1 2 3 4 Response time (s) Fig. 9. RootPath response time other techniques and identify the best approach. Accuracy Algorithms Bayesian ANN is considered the essential criterion in analyzing performance metrics for algorithms, including Principal Component Anal-ysis (PCA), Independent Component Analysis (ICA), Au-toencoders (AE), and K-means shown in Fig. 10. According to the results, the ANN has the maximum accuracy with a score of 0.980 (see Fig. 8), making it the best-performing algorithm in this respect. While other methods, such as PCA and AE, have comparable accuracy ratings (0.974 and 0.976, respectively), the ANN surpassed them. However, when other measures such as F1 score, accuracy, and recall are included, PCA demonstrates greater performance. These data illustrate the trade-off between accuracy and other measures, implying that the ANN is excellent in accuracy while other algorithms excelled in various aspects of performance. Moreover, the ANN's multilayer structure allows it to automatically extract essential features from input data in the critical path prediction process. 3&amp;$ ,&amp;$ $( .PHDQV $OJRULWKP Fig. 10. Comparison of algorithm performance and accuracy ANN K-means PCA ICA Algorithm AE 0.00 0.130 0.090 0.060 0.25 0.50 1.020 0.75 1.00 1.25 1.50 1.75 1.750 0.100 Time (s) 0.120 Comparison Training Testing</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://hadoop.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>https://www.kaggle.com/datasets/ashydv/consumer-electronics-data</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mapreduce: simplified data processing on large clusters</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="113" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scarlett: coping with skewed content popularity in mapreduce clusters</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Harlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth conference on Computer systems</title>
		<meeting>the sixth conference on Computer systems</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="287" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bigdebug: Debugging primitives for interactive big data processing in spark</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gulzar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Interlandi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Tetali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Condie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Millstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Software Engineering</title>
		<meeting>the 38th International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="784" to="795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tagsniff: Simplified big data debugging for dataflow jobs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Contreras-Rojas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-A</forename><surname>Quiané-Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kaoudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thirumuruganathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on Cloud Computing</title>
		<meeting>the ACM Symposium on Cloud Computing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="453" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A multiobjective optimization scheme for job scheduling in sustainable cloud data centers</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Aujla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cloud Computing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="172" to="186" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Slope: a self learning optimization and prediction ensembler for task scheduling</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benslimane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Aujla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 14th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Modelling and prediction of resource utilization of hadoop clusters: A machine learning approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tariq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Al-Sahaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Welch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th IEEE/ACM international conference on utility and cloud computing</title>
		<meeting>the 12th IEEE/ACM international conference on utility and cloud computing</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Benchmarking and performance modelling of mapreduce communication pattern</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ceesay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reining in the outliers in map-reduce clusters using mantri</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kandula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Osdi</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Timely long tail identification through agent based monitoring and analytics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Garraghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Townend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 18th International Symposium on Real-Time Distributed Computing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ladra: Log-based abnormal task detection and root-cause analysis in big data processing with spark</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="392" to="403" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hawkeye: Adaptive straggler identification on heterogeneous spark cluster with reinforcement learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="57" to="822" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Autodiagn: An automated real-time diagnosis framework for big data systems</title>
		<author>
			<persName><forename type="first">U</forename><surname>Demirbaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Noor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Alwasel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zomaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1035" to="1048" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fluid petri nets for the performance evaluation of mapreduce and spark applications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gianniti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barbierato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gribaudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ardagna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMETRICS Performance Evaluation Review</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="23" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scalable critical-path based performance analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Böhme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>De Supinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Geimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 26th International Parallel and Distributed Processing Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1330" to="1340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The visual display of parallel performance data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Malony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Rover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="21" to="28" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Jet: An embedded dsl for high performance big data processing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ackermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Jovanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rompf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Odersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on End-to-end Management of Big Data</title>
		<imprint>
			<publisher>CONF</publisher>
			<date type="published" when="2012">BigData 2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Smartmonit: Real-time big data monitoring system</title>
		<author>
			<persName><forename type="first">U</forename><surname>Demirbaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Noor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 38th symposium on reliable distributed systems (SRDS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="357" to="3572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Advances in bayesian network modelling: Integration of modelling technologies</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Marcot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Penman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Environmental modelling &amp; software</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="386" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Machine learning on big data: Opportunities and challenges</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Vasilakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="page" from="350" to="361" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
