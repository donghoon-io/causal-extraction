<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How would surround vehicles move? A Unified Framework for Maneuver Classification and Motion Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2018-01-19">19 Jan 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Nachiket</forename><surname>Deo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Akshay</forename><surname>Rangesh</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE</roleName><forename type="first">Mohan</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
						</author>
						<title level="a" type="main">How would surround vehicles move? A Unified Framework for Maneuver Classification and Motion Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-01-19">19 Jan 2018</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:1801.06523v1[cs.CV]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T21:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Maneuver recognition</term>
					<term>interaction-aware motion prediction</term>
					<term>vehicle mounted cameras</term>
					<term>variational gaussian mixture models (VGMM)</term>
					<term>hidden markov models (HMM)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Reliable prediction of surround vehicle motion is a critical requirement for path planning for autonomous vehicles.</p><p>In this paper we propose a unified framework for surround vehicle maneuver classification and motion prediction that exploits multiple cues, namely, the estimated motion of vehicles, an understanding of typical motion patterns of freeway traffic and inter-vehicle interaction. We report our results in terms of maneuver classification accuracy and mean and median absolute error of predicted trajectories against the ground truth for real traffic data collected using vehicle mounted sensors on freeways. An ablative analysis is performed to analyze the relative importance of each cue for trajectory prediction. Additionally, an analysis of execution time for the components of the framework is presented. Finally, we present multiple case studies analyzing the outputs of our model for complex traffic scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>For successful deployment in challenging traffic scenarios, autonomous vehicles need to ensure the safety of its passengers and other occupants of the road, while navigating smoothly without disrupting traffic or causing discomfort to its passengers. Existing tactical path planning algorithms <ref type="bibr" target="#b29">[30]</ref>- <ref type="bibr" target="#b31">[32]</ref> hinge upon reliable estimation of future motion of surrounding vehicles over a prediction horizon of up to 10 s. While approaches leveraging vehicle-to-vehicle communication <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref>, offer a possible solution, these would require widespread adoption of autonomous driving technology in order to become viable. In order to safely share the road with human drivers, an autonomous vehicle needs to have the ability to predict the future motion of surrounding vehicles purely based on perception. Thus, we address the problem of surround vehicle motion prediction purely based on data captured using vehicle mounted sensors.</p><p>Prediction of surround vehicle motion is an extremely challenging problem due to a large number of factors that affect the future trajectories of vehicles. Prior works addressing the problem seem to incorporate three cues in particular: the instantaneous estimated motion of surround vehicles, an understanding of typical motion patterns of traffic and intervehicle interaction. A large body of work uses the estimated state of motion of surround vehicles along with a kinematic</p><p>The authors are with the Laboratory for Intelligent and Safe Automobiles (LISA), University of California at San Diego, La Jolla, CA 92093 USA (email:ndeo@ucsd.edu, arangesh@ucsd.edu, mtrivedi@ucsd.edu) Manuscript info.</p><p>Fig. <ref type="figure">1</ref>: To smoothly navigate through freeways an autonomous vehicle must estimate a distribution over the future motion of the surrounding vehicles. We propose a unified model for trajectory prediction that leverages the instantaneous motion of the vehicles, the maneuver being performed by the vehicles and inter-vehicle interactions, while working purely with data captured using vehicle mounted sensors.</p><p>The above figure shows the data captured by 8 surround cameras (top), the track histories of surround vehicles, the mean predicted trajectories (bottom left) and a heat map of the predicted distribution in the ground plane (bottom right).</p><p>model to make predictions of their future trajectories <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b7">[8]</ref>. While these approaches are computationally efficient, they become less reliable for long term prediction, since they fail to model drivers as decision making entities capable of changing the motion of vehicles over long intervals. An alternative is offered by probabilistic trajectory prediction approaches <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b16">[17]</ref> that learn typical motion patterns of traffic from a trajectory dataset. However these approaches are prone to poorly modeling safety critical motion patterns that are under represented in the training data. Many works address these shortcomings of motion models and probabilistic models by defining a set of semantically interpretable maneuvers <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b26">[27]</ref>. A separate motion model or probabilistic model can then be defined for each maneuver for making future predictions. Finally some works leverage inter-vehicle interaction for making trajectory predictions <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>. While many promising solutions have been proposed, they seem to have the following limitations. (i) Most works consider a restrictive setting such as only predicting longitudinal motion, a small subset of motion patterns, or specific cases of inter-vehicle interaction, whereas many of the biggest challenges for vehicle trajectory prediction originate from the generalized setting of simultaneous prediction of the complete motion of all vehicles in the scene. (ii) Many approaches have been evaluated using simulated data, or based on differential GPS, IMU readings of target vehicles, whereas evaluation using real traffic data captured using perceptual vehicle mounted sensors is more faithful to the setting being considered. (iii) There is a lack of a unifying approach that combines each of the three cues mentioned above and analyzes their relative importance for trajectory prediction.</p><p>In this work, we propose a framework for holistic surround vehicle trajectory prediction based on three interacting modules: A hidden Markov model (HMM) based maneuver recognition module for assigning confidence values for maneuvers being performed by surround vehicles, a trajectory prediction module based on the amalgamation of an interacting multiple model (IMM) based motion model and maneuver specific variational Gaussian mixture models (VGMMs), and a vehicle interaction module that considers the global context of surround vehicles and assigns final predictions by minimizing an energy function based on outputs of the other two modules. We work with vehicle tracks obtained using 8 vehicle mounted cameras capturing the full surround and generate the mean predicted trajectories and prediction uncertainties for all vehicles in the scene as shown in Figure <ref type="figure">1</ref>. We evaluate the model using real data captured on Californian freeways.</p><p>The main contributions of this work are: 1) A unified framework for surround vehicle trajectory prediction that exploits instantaneous vehicle motion, an understanding of typical motion patterns of traffic and inter-vehicle interaction. 2) An ablative analysis for determining the relative importance of each cue in trajectory prediction. 3) Evaluation based on real traffic data captured using vehicle mounted sensors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED RESEARCH</head><p>Data-driven trajectory prediction: Data driven trajectory prediction approaches can be broadly classified into clustering based approaches and probabilistic approaches. Clustering based approaches <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b18">[19]</ref> cluster the training data to give a set of prototype trajectories. Partially observed trajectories are matched with a prototype trajectory based on distance measures such as DTW, LCSS or Hausdorff distance, and the prototype trajectory used as a model for future motion. The main drawback of clustering based approaches is the deterministic nature of the predictions. Probabilistic approaches in contrast, learn a probability distribution over motion patterns and output the conditional distribution over future motion given partial trajectories. These have the added advantage of associating a degree of uncertainty to the future predictions. Gaussian Processes are the most popular approach for modeling trajectories <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref>. Other approaches include <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b14">[15]</ref> where the authors use Gaussian mixture regression for predicting the longitudinal and lateral motion of vehicles respectively. Of particular interest is the work by Weist et al. <ref type="bibr" target="#b16">[17]</ref> who use variational Gaussian mixture models (VGMMs) to model the conditional distribution over snippets of trajectory futures given snippets of trajectory history. This approach is much leaner and computationally efficient as compared to Gaussian process regression and was shown to be effective at predicting the highly non-linear motion in turns at intersections. While Weist et al. use the velocity and yaw angle of the predicted vehicle obtained from its Differential GPS data, we extend this approach by learning VGMMs for freeway traffic using positions and velocities of surround vehicles estimated using vehicle mounted sensors, similar to our prior work on pedestrian trajectory prediction <ref type="bibr" target="#b17">[18]</ref>.</p><p>Maneuver-based trajectory prediction: Classification of vehicle motion into semantically interpretable maneuver classes has been extensively addressed in both advanced driver assistance systems as well as naturalistic drive studies <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b26">[27]</ref>. Most approaches involve using heuristics <ref type="bibr" target="#b24">[25]</ref> or training classifiers such as SVMs <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, HMMs <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b22">[23]</ref>, LSTMs <ref type="bibr" target="#b23">[24]</ref> and Bayesian networks <ref type="bibr" target="#b25">[26]</ref> using motion based features such as speed, acceleration, yaw rate and other context information such as lane position, turn signals, distance from leading vehicle. The works most closely related to our approach are those that use the recognized maneuvers to make predictions of future trajectories. Houenou et al. <ref type="bibr" target="#b24">[25]</ref> classify a vehicle's motion as a keep lane or lane change maneuver based on distance to nearest lane marking and predict the future trajectory by fitting a quintic polynomial between the current motion state of the vehicle and a pre-defined final motion state for each maneuver class. Schreier et al. <ref type="bibr" target="#b25">[26]</ref> classify vehicle motion into one of six different maneuver classes using a Bayesian network based on multiple motion and context based features. A class specific motion model is then defined for each maneuver to generate future trajectories. Most similar in principle to our approach are <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b13">[14]</ref> where separate probabilistic prediction models are trained for each maneuver class. Tran and Firl <ref type="bibr" target="#b12">[13]</ref> define a separate Gaussian process for three maneuver classes and generate a multi-modal distribution over future trajectories using each model. However, only case based evaluation has been presented. Laugier et al. <ref type="bibr" target="#b13">[14]</ref> also define separate Gaussian processes for 4 different maneuvers that are classified using a hierarchical HMM. While they report results for maneuver classification on real highway data, they evaluate trajectory prediction in the context of risk assessment simulated data. Schlechtriemen et al. <ref type="bibr" target="#b15">[16]</ref> use a random forest classifier to classify maneuvers into left or right lane changes or keep lane. They use a separate Gaussian mixture regression model for making predictions of lateral movement of vehicles for each class, reporting results on real highway data. Along similar lines, but without maneuver classes, they also predict longitudinal motion for surround vehicles <ref type="bibr" target="#b14">[15]</ref>. Contrary to this approach, we make predictions for the complete motion of vehicles based on maneuver class, since detection of certain maneuvers like overtakes can help predict both lateral and longitudinal motion of vehicles.</p><p>Interaction-aware trajectory prediction: Relatively few works address the effect of inter-vehicle interaction in trajectory prediction. Kafer et al. <ref type="bibr" target="#b27">[28]</ref> jointly assign maneuver classes for two vehicles approaching an intersection using a polynomial classifier that penalizes cases which would lead to near collisions. Closer to our proposed approach, Lawitzky et al. <ref type="bibr" target="#b28">[29]</ref> consider the much more complex case of assigning maneuver classes to multiple interacting vehicles in a highway setting. However, predicted trajectories and states of vehicle motion are assumed to be given, and results reported using a simulated setting. Contrarily, our evaluation considers the combined complexity due to multiple interacting vehicles as well the difficulty of estimating their future motion. We note that inter-vehicle interaction is implicitly modeled in <ref type="bibr" target="#b15">[16]</ref> by including relative positions and velocities of nearby vehicles as features for maneuver classification and trajectory prediction. III. OVERVIEW Figure <ref type="figure" target="#fig_0">2</ref> shows the complete pipeline of our proposed approach. We restrict our setting to purely perception based prediction of surround vehicle motion, without any vehicleto-vehicle communication. Toward this end, the ego vehicle is equipped with 8 cameras that capture the full surround. All vehicles within 40 m of the ego vehicle in the longitudinal direction are tracked for motion analysis and prediction. While vehicle tracking is not the focus of this work, we refer readers to a multi-perspective vision based vehicle trackers described in <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b37">[38]</ref>. The tracked vehicle locations are then projected to the ground plane to generate track histories of the surround vehicles in the frame of reference of the ego vehicle.</p><p>The goal of our model is to estimate the future positions and the associated prediction uncertainty for all vehicles in the ego vehicle's frame of reference over the next t f seconds, given a t h second snippet of their most recent track histories. The model essentially consists of three interacting modules, namely the trajectory prediction module, the maneuver recognition module and the vehicle interaction module. The trajectory prediction module is the most crucial among the three and can function as a standalone block independent of the remaining two modules. It outputs a linear combination of the trajectories predicted by a motion model that leverages the estimated instantaneous motion of the surround vehicles and a probabilistic trajectory prediction model which learns motion patterns of vehicles on freeways from a freeway trajectory training set. We use constant velocity (CV), constant acceleration (CA) and constant turn rate and velocity (CTRV) models in the interacting multiple model (IMM) framework as the motion models since these capture most instances of freeway motion, especially in light traffic conditions. We use Variational Gaussian Mixture Models (VGMM) for probabilistic trajectory prediction owing to promising results for vehicle trajectory prediction at intersections shown in <ref type="bibr" target="#b16">[17]</ref>.</p><p>The motion model becomes unreliable for long term trajectory prediction, especially in cases involving a greater degree of decision making by drivers such as overtakes, cutins or heavy traffic conditions. These cases are critical from a safety stand-point. However, since these are relatively rare occurrences, they tend to be poorly modeled by a monolithic probabilistic prediction model. Thus we bin surround vehicle motion on freeways into 10 maneuver classes, with each class capturing a distinct pattern of motion that can be useful for future prediction. The intra-maneuver variability of vehicle motion is captured through a VGMM learned for each maneuver class. The maneuver recognition module recognizes the maneuver being performed by a vehicle based on a snippet of it's most recent track history. We use hidden Markov models (HMM) for this purpose. The VGMM corresponding to the most likely maneuver can then be used for predicting the future trajectory. Thus the maneuver recognition and trajectory Prediction modules can be used in conjunction for each vehicle to make more reliable predictions.</p><p>Up to this point, our model predicts trajectories of vehicles independent of each other. However the relative configuration of all vehicles in the scene can make certain maneuvers infeasible and certain others more likely, making it a useful cue for trajectory prediction especially in heavy traffic conditions. The vehicle interaction module (VIM) leverages this cue. The maneuver likelihoods and predicted trajectories for the K likeliest maneuvers for each vehicle being tracked are passed to the VIM. The VIM consists of a Markov random field aimed at optimizing an energy function over the discrete space of maneuver classes for all vehicles in the scene. The energy function takes into account the confidence values for all maneuvers given by the HMM and the feasibility of the maneuvers given the relative configuration of all vehicles in the scene. Minimizing the energy function gives the recognized maneuvers and corresponding trajectory predictions for all vehicles in the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. MANEUVER RECOGNITION MODULE A. Maneuver classes</head><p>We define 10 maneuver classes for surround vehicle motion on freeways in the ego-vehicle's frame of reference. Figure <ref type="figure" target="#fig_1">3</ref> illustrates the maneuver classes.</p><p>1) Lane Passes: Lane pass maneuvers involve vehicles passing the ego vehicle without interacting with the ego vehicle lane. These constitute a majority of the surround vehicle motion on freeways and are relatively easy cases for trajectory prediction owing to approximately constant velocity profiles. We define 4 different lane pass maneuvers as shown in Figure <ref type="figure" target="#fig_1">3</ref> 2) Overtakes: Overtakes start with the surround vehicle behind the ego vehicle in the ego lane. The surround vehicle changes lane and accelerates in order to pass the ego vehicle. We define 2 different overtake maneuvers, depending on which side the the surround vehicle overtakes. 3) Cut-ins: Cut-ins involve a surround vehicle passing the ego vehicle and entering the ego lane in front of the egovehicle. Cut-ins and overtakes, though relatively rare, can be critical from a safety stand-point and also prove to be challenging cases for trajectory prediction. We define 2 different cut-ins depending on which side the surround vehicle cuts in from. 4) Drift into Ego Lane: Another important maneuver class is when a surround vehicle drifts into the ego vehicle lane in front or behind the ego vehicle. This is also important from a safety standpoint as it directly affects how sharply the ego vehicle can accelerate or decelerate. A separate class is defined for drifts into ego-lane in front and to the rear of the ego vehicle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Hidden Markov Models</head><p>Hidden Markov models (HMMs) have previously been used for maneuver recognition <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b22">[23]</ref> due to their ability to capture the spatial and temporal variability of trajectories. HMMs can be thought of as combining two stochastic models, an underlying Markov chain of states characterized by state transition probabilities and an emission probability distribution over the feature space for each state. The transition probabilities model the temporal variability of trajectories while the emission probabilities model the spatial variability, making HMMs a viable approach for maneuver recognition.</p><p>Previous works <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b22">[23]</ref> use HMMs for classifying maneuvers after they have been performed, where the HMM for a particular maneuver is trained using complete trajectories belonging to that maneuver class. In our case, the HMMs need to classify a maneuver based on a small t h second snippet of the trajectory. Berndt et al. <ref type="bibr" target="#b19">[20]</ref> address the problem of maneuver classification based on partially observed trajectories by using only the initial states of a trained HMM to fit the observed trajectory. However, this approach requires prior knowledge of the starting point of the maneuver. In our case, the trajectory snippet could be from any point in the maneuver, and not necessarily the start. We need the HMM to classify a maneuver based on any intermediate snippet of the trajectory. We thus divide the trajectories in our training data into overlapping snippets of t h seconds and train the maneuver HMMs using these snippets.</p><p>For each maneuver, we train a separate HMM with a leftright topology with only self transitions and transitions to the next state. The state emission probabilities are modeled as mixtures of Gaussians with diagonal covariances. The x and y ground plane co-ordinates and instantaneous velocities in the x and y direction are used as features for training the HMMs. The parameters of the HMMs: the state transition probabilities and the means, variances and weights of the mixture components are estimated using the Baum-Welch algorithm <ref type="bibr" target="#b35">[36]</ref>.</p><p>For a car i, the HMM for maneuver k outputs the log likelihood:</p><formula xml:id="formula_0">L i k = log(P (x i h , y i h , v x i h , v y i h |m i = k; Θ k ))<label>(1)</label></formula><p>where x i h , y i h are the x and y locations of vehicle i over the last t h seconds and v x i h , v y i h are the velocities along the x and y directions over the last t h seconds. m i is the maneuver assigned to car i and Θ k are the parameters of the HMM for maneuver k</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. TRAJECTORY PREDICTION MODULE</head><p>The trajectory prediction module predicts the future x and y locations of surround vehicles over a prediction horizon of t f seconds and assigns an uncertainty to the predicted locations in the form of a 2×2 covariance matrix. It averages the predicted future locations and covariances given by both a motion model, and a probabilistic trajectory prediction model. The outputs of the trajectory prediction module for a prediction instant t pred are given by:</p><formula xml:id="formula_1">x f (t) = 1 2 x f motion (t) + x f prob (t)<label>(2)</label></formula><formula xml:id="formula_2">y f (t) = 1 2 y f motion (t) + y f prob (t)<label>(3)</label></formula><formula xml:id="formula_3">Σ f (t) = 1 2 Σ f motion (t) + Σ f prob (t)<label>(4)</label></formula><p>where t pred ≤ t ≤ t pred + t f</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motion Models</head><p>We use the interacting multiple model (IMM) framework for modeling vehicle motion, similar to <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. The IMM framework allows for combining an ensemble of Bayesian filters for motion estimation and prediction by weighing the models with probability values. The probability values are estimated at each time step based on the transition probabilities of an underlying Markov model and how well each model fits the observed motion prior to that time step. We use the following motion models in our ensemble: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Probabilistic Trajectory Prediction</head><p>We formulate probabilistic trajectory prediction as estimating the conditional distribution:</p><formula xml:id="formula_4">P (v xf , v y f |x h , y h , v xh , v y h , m)<label>(5)</label></formula><p>i.e. the conditional distribution of the vehicle's predicted velocities given the vehicles past positions, velocities and maneuver class. In particular, we are interested in estimating the conditional expected values [ vxf ; vy f ] and conditional covariance Σ v f of the distribution 5. The predicted locations and x f prob , y f prob can then be obtained by taking the cumulative sum of the predicted velocities, which can be represented using an accumulator matrix A</p><formula xml:id="formula_5">[x f prob ; y f prob ] = A[ vxf ; vy f ]<label>(6)</label></formula><p>Similarly, the uncertainty of prediction Σ prob can be obtained using the expression:</p><formula xml:id="formula_6">Σ f prob = AΣ v f A T<label>(7)</label></formula><p>We use the framework proposed by Weist et al. <ref type="bibr" target="#b16">[17]</ref> for estimating the conditional distribution 5. (x h ,y h ,v xh ,v y h ) and (v xf ,v y f ) are represented in terms of their Chebyshev coefficients, c h and c f . The joint distribution P (c f , c h |m) for each maneuver class is estimated as the predictive distribution of a variational Gaussian mixture model (VGMM). The conditional distribution P (c f |c h , m) can then be estimated in terms of the parameters of the predictive distribution. We briefly review the the expressions for P (c f , c h |m) and P (c f |c h , m) here. However, the reader is encouraged to refer to <ref type="bibr" target="#b16">[17]</ref> for a more detailed treatment.</p><p>VGMMs are the Bayesian analogue to standard GMMs, where the model parameters, {π, µ 1 , µ 2 , ... µ K , Λ 1 , Λ 2 , ... Λ K } are given conjugate prior distributions. The prior over mixture weights π is a Dirichlet distribution</p><formula xml:id="formula_7">P (π) = Dir(π|α 0 )<label>(8)</label></formula><p>The prior over each component mean µ k and component precision Λ k is an independent Gauss-Wishart distribution</p><formula xml:id="formula_8">P (µ k , Λ k ) = N (µ k |m 0 k , (β 0 k Λ k ) -1 )W(Λ k |W 0 k , ν 0 k )<label>(9)</label></formula><p>The parameters of the posterior distributions are estimated using the Variational Bayesian Expectation Maximization algorithm <ref type="bibr" target="#b36">[37]</ref>. The predictive distribution for a VGMM is given by a mixture of Student's t-distributions</p><formula xml:id="formula_9">P (c h , c f ) = 1 sum(α) K k=1 α k St(c h , c f |m k , L k , ν k + 1 -d) (10)</formula><p>where d is the number of degrees of freedom of the Wishart distribution and</p><formula xml:id="formula_10">L k = (ν k + 1 -d)β k 1 + β k W k<label>(11)</label></formula><p>For a new trajectory history c h , the conditional predictive distribution P (c f |c h ) is given by:</p><formula xml:id="formula_11">P (c f |c h ) = 1 sum(α) K k=1 αk St (c f |c h , mk , L k , ν k + 1 -d)<label>(12)</label></formula><p>where ( <ref type="formula">13</ref>)</p><formula xml:id="formula_12">νk = ν k + 1 -d (14) αk = α k St(c h |m k,c h , L k,c h , νk ) K j=1 α j St(c h |m j,c h , L j,c h , νj )<label>(15)</label></formula><formula xml:id="formula_13">mk = m k,c f + Σ k,c f c h Σ -1 k,c h c h (c h -m k,c h )<label>(16)</label></formula><formula xml:id="formula_14">L-1 k = νk νk + d -2 1 + ∆ T k Σ k,c h c h νk ∆ k Σ * k (<label>17</label></formula><formula xml:id="formula_15">)</formula><formula xml:id="formula_16">∆ k = (c h -m k,c h ) (18) Σ * k = Σ k,c f c f -Σ k,c f c h Σ k,c h c -1 h Σ k,c h c f<label>(19)</label></formula><formula xml:id="formula_17">Σ k = νk + d -2 νk + d L -1 k<label>(20)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. VEHICLE INTERACTION MODULE</head><p>The vehicle interaction module is tasked with assigning discrete maneuver labels to all vehicles in the scene at a particular prediction instant based on the confidence of the HMM in each maneuver class and the feasibility of the future trajectories of all vehicles based on those maneuvers given the current configuration of all vehicles in the scene. We set this up as an energy minimization problem. For a given prediction instant, let there be N surround vehicles in the scene with the top K maneuvers given by the HMM being considered for each vehicle. The minimization objective is given by:</p><formula xml:id="formula_18">y * = arg min y n i=1 K k=1 y i k E hmm ik + λE ego ik + λ n i=1 K k=1 n j=1 j =i K l=1 y i k y j l E vi ijkl (21) s.t. k y i k = 1 ∀i<label>(22)</label></formula><formula xml:id="formula_19">y i k = 1, if car i is assigned maneuver k 0, otherwise<label>(23)</label></formula><p>The objective consists of three types of energies, the individual Energy terms E hmm ik , E ego ik and the pairwise energy terms E vi ijkl . The individual energy terms E hmm ik are given by the negative of the log likelihoods provided by the HMM. Higher the confidence of an HMM in a particular maneuver, lower is -L i k and thus the individual energy term. The individual energy term E ego ik takes into account the interaction between surround vehicles and the ego vehicle. We define the E ego ik as the reciprocal of the closest point of approach for vehicle i and the ego vehicle over the entire prediction horizon, given that it is performing maneuver k, where the ego vehicle position is always fixed to 0, since it is the origin of the frame of reference. Similarly, the pairwise energy term E vi ijkl is defined as the reciprocal of the minimum distance between the corresponding predicted trajectories for the vehicles i and j, assuming them to be performing maneuvers k and l respectively . The terms E ego ik and E vi ijkl penalize predictions where at any point in the prediction horizon, two vehicles are very close to each other. This term leverages the fact that drivers tend to follow paths with low possibility of collisions with other vehicles. The weighting constant λ is experimentally determined through cross-validation.</p><p>The minimization objective in the formulation shown in Eq. 21, 22 and 23 has quadratic terms in y values. In order to leverage integer linear programming for minimizing the energy, we modify the formulation as follows:</p><formula xml:id="formula_20">y * , z * = arg min y,z n i=1 K k=1 y i k E hmm ik + λE ego ik + λ n i=1 K k=1 n j=1 j =i K l=1 z i,j k,l E vi ijkl<label>(24)</label></formula><p>s.t.</p><formula xml:id="formula_21">k y i k = 1 ∀i (<label>25</label></formula><formula xml:id="formula_22">)</formula><formula xml:id="formula_23">y i k ∈ 0, 1<label>(26)</label></formula><formula xml:id="formula_24">z i,j k,l ≤ y i k (<label>27</label></formula><formula xml:id="formula_25">)</formula><formula xml:id="formula_26">z i,j k,l ≤ y j l (<label>28</label></formula><formula xml:id="formula_27">)</formula><formula xml:id="formula_28">z i,j k,l ≥ y i k + y j l -1<label>(29)</label></formula><p>This objective can now be optimized using integer linear programming, where the optimal values y * give the maneuver assignments for each of the vehicles. These assigned maneuver classes are used by the trajectory prediction module to make future predictions for all vehicles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXPERIMENTAL EVALUATION A. Dataset</head><p>We evaluate our framework using real freeway traffic data captured using the testbed described in <ref type="bibr" target="#b38">[39]</ref>. The vehicle is equipped with 8 RGB video cameras, LIDARs and RADARs synchronously capturing the full surround at a frame rate of 15 fps. Our complete dataset consists of 52 video sequences extracted from multiple drives spanning approximately 45 minutes. The sequences were chosen to capture varying lighting conditions, vehicle types, and traffic density and behavior.</p><p>The 4 longest video sequences, of about 3 minutes each were ground-truthed by human annotators and used for evaluation. Three sequences from the evaluation set represent light to moderate or free-flowing traffic conditions, while the remaining sequence represents heavy or stop-and-go traffic.  The video feed from the evaluation set was annotated with detection boxes and vehicle track-ids for each of the 8 views. All tracks were then projected to the ground plane and assigned a maneuver class label corresponding to the 10 maneuver classes described in Section IV-A. If a vehicle track was comprised by multiple maneuvers, the start and end-point of each maneuver was marked. A multi-perspective tracker <ref type="bibr" target="#b22">[23]</ref> was used for assigning vehicle tracks for the remaining 48 sequences. These tracks were only used for training the models. Figure <ref type="figure" target="#fig_3">4</ref> shows the track annotations as well as the complete set of trajectories belonging to each maneuver class. Since each trajectory is divided into overlapping snippets of t h = 3 seconds for training and testing our models, we report the data statistics in terms of the total number of trajectories as well as the number of trajectory snippets belonging to each maneuver class in Table <ref type="table" target="#tab_0">I</ref> We report all results using a leave on sequence crossvalidation scheme. For each of the 4 evaluation sequences, the HMMs and VGMMs are trained using data from the remaining 3 evaluation sequences as well as the 48 training sequences. Additionally, we use two simple data-augmentation schemes for increasing the size of our training datasets in order to reduce overfitting in the models:</p><p>1) Lateral inversion: We flip each trajectory along the lateral direction in the ego frame to give an instance of a different maneuver class. For example, a left cut-in on lateral inversion becomes a right cut in. 2) Longitudinal shifts: We shift each of the trajectories by ± 2, 4 and 6 m in the longitudinal direction in the ego frame to give additional instances of the same maneuver class. We avoid lateral shifts since this would interfere with lane information that is implicitly learned by the probabilistic model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Measures and Experimental Settings</head><p>Our models predict the future trajectory over a prediction horizon of 5 seconds for each 3 second snippet of track history based on the maneuver classified by the HMMs or by the VIM. We use the following evaluation measures for reporting our results:</p><p>1) Mean Absolute Error: This measure gives the average absolute deviation of the predicted trajectories from the underlying ground truth trajectories. To compare how the models perform for short term and long term predictions, we report this measure separately for prediction instants up to 5 seconds into the future, sampled with increments of 1 second. The mean absolute error captures the effect of both the number of errors made by the models as well as the severity of the errors. 2) Median Absolute Error: We also report the median values of the absolute deviations for up to 5 seconds into the future with 1 second increments, as was done in <ref type="bibr" target="#b14">[15]</ref>. The median absolute error better captures the distribution of the errors made by the models while sifting out the effect of a few drastic errors. 3) Maneuver classification accuracy: We report maneuver classification accuracy for configurations using the maneuver recognition module or the vehicle interaction module. 4) Execution time: We report the average execution time per frame, where each frame involves predicting trajectories of all vehicles being tracked at a particular instant.</p><p>In order to analyze the effect of each of our proposed modules, we compare the trajectory prediction results for following systems</p><p>• Motion model (IMM): We use the trajectories predicted by the IMM based motion model as our baseline.</p><p>• Monolithic VGMM (M-VGMM): We consider the trajectories predicted by our trajectory prediction module, where the probabilistic model used is a single monolithic VGMM. This alleviates the need for the • Class VGMMs (C-VGMM): Here we consider separate VGMMs for each maneuver class in the trajectory prediction module. We use the VGMM corresponding to the maneuver with the highest HMM log likelihood for making the prediction. In this case, maneuver predictions for each vehicle are made independent of the other vehicles in the scene. To keep the comparison with the M-VGMM fair, we use 8 mixture components for each maneuver class for the C-VGMMs, while we use a single VGMM with 80 mixture components for the M-VGMM, ensuring that both models have the same complexity.</p><p>• Class VGMMs with Vehicle Interaction Module (C-VGMM + VIM): We finally consider the effect of using the vehicle interaction module. In this case, we use the C-VGMMs with the maneuver classes for each of the vehicles in the scene assigned by the vehicle interaction module We report our results for the complete set of trajectories in the evaluation set. Additionally, we also report results on the subsets of overtake and cut-in maneuvers and stop-and-go traffic. Since overtakes and cut-ins are rare safety critical maneuvers with significant deviation from uniform motion, these are challenging cases for trajectory prediction. Similarly, due to the high traffic density in stop-and-go scenarios, vehicles affect each others motion to a much greater extent as compared to free-flowing traffic, making it a challenging scenario for trajectory prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablative Analysis</head><p>Table <ref type="table" target="#tab_1">II</ref> shows the quantitative results of our ablation experiments. We note from the results on the complete evaluation set that the probabilistic trajectory prediction models outperform the baseline of the IMM. The M-VGMM has lower values for both mean as well as median absolute error as compared to the IMM suggesting that the probabilistic model makes fewer as well as less drastic errors on an average. We get further improvements in mean and median absolute deviations using the C-VGMMs suggesting that subcategorizing trajectories into maneuver classes leads to a better probabilistic prediction model. This is further highlighted based on the prediction results for the challenging maneuver classes of overtakes and cutins. We note that the C-VGMM significantly outperforms the CV and M-VGMM models both in terms of mean and median absolute deviation for overtakes and cut-ins. This trend becomes more pronounced as the prediction horizon is increased. This suggests that the motion model is more error prone due to the non-uniform motion in overtakes and cut-ins while these rare classes get underrepresented in the distribution learned by the monolithic M-VGMM. Both of these issues get addressed through the C-VGMM. We analyze this further by considering specific cases of predictions made by the IMM, M-VGMM and C-VGMM in Section VII-E Comparing the maneuver classification accuracies for the case of C-VGMM and C-VGMM + VIM, we note that the VIM corrects some of the maneuvers assigned by the HMM. This in turn leads to improved trajectory prediction as seen from the mean and median absolute error values. We note that this effect is more pronounced in case of stop-and-go traffic, since the dense traffic conditions cause more vehicles to affect each others motion leading to a greater proportion of maneuver class labels to be re-assigned by the VIM. Section VII-F analyses cases where the VIM reassigns maneuver labels assigned by the HMM due to the relative configuration of all vehicles in the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Analysis of execution time</head><p>Table II also shows the average execution time per frame for the 4 system configurations considered. As expected, the IMM baseline has the lowest execution time since all other configurations build upon it. We note that the C-VGMM runs faster than the M-VGMM in spite of having the overhead of the HMM based maneuver recognition module. This is because the M-VGMM is a much bulkier model as compared to any single maneuver C-VGMM. Thus in spite of involving an extra step, the maneuver recognition module allows us to choose a much leaner model, effectively reducing the execution time while improving performance. The VIM is a more time intensive overhead and almost doubles the run time of the C-VGMM. However, even in it's most complex setting, the proposed framework can be deployed at a frame rate of almost 6 fps, which is more than sufficient for the application being considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Analyzing predictions of IMM, M-VGMM and C-VGMM models</head><p>Figure <ref type="figure" target="#fig_4">5</ref> shows the trajectories predicted by the CV, M-VGMM and C-VGMM models for 8 different instances.</p><p>Figure <ref type="figure" target="#fig_4">5a</ref> shows two prediction instants where the vehicle is just about to start the non-linear part of overtake maneuvers. We observe that the IMM makes erroneous predictions in both cases. However, both the M-VGMM and C-VGMM manage to predict the non-linear future trajectory.</p><p>Figure <ref type="figure" target="#fig_4">5b</ref> shows two prediction instants in the early part of overtake maneuvers. We note that both the IMM and M-VGMM make errors in prediction. However the position of the surround vehicle along with the slight lateral motion provide enough context to the maneuver recognition module to detect the overtake maneuver early. Thus, the C-VGMM manages to predict that the surround vehicle would move to the adjacent lane and accelerate in the longitudinal direction, although there is no such cue from the vehicles existing state of motion Figure <ref type="figure" target="#fig_4">5c</ref> shows two instants the trajectory of a vehicle that decelerates as it approaches the ego vehicle from the front. This trajectory corresponds to the drift into ego-lane maneuver class. In the first case (left), the vehicle has not started decelerating, causing the IMM to assign a high probability to the CV model. The IMM thus predicts the vehicle to keep moving at a constant velocity and come dangerously close to the ego vehicle. Similarly, the M-VGMM makes a poor prediction since these maneuvers are underrepresented in the training data. The C-VGMM however manages to correctly predict the surround vehicle to decelerate. In the second case (right), we observe that the car has already started decelerating. This allows the IMM to assign a greater weight to the CA model and correct its prediction Finally Figure <ref type="figure" target="#fig_4">5d</ref> shows two interesting instances of the lane pass right back maneuver that is well represented in the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Vehicle Interaction Model Case Studies</head><p>Figure <ref type="figure" target="#fig_5">6</ref> shows three cases where the recognized maneuvers and predicted trajectories are affected by the VIM. In each case, the green plots show the ground truth of future tracks, the blue plots show the predictions made for each vehicle independently and the red plots show the predictions based on the VIM. Additionally we plot the prediction uncertainties for either case.</p><p>Consider the first case in Figure <ref type="figure" target="#fig_5">6a</ref>, in particular vehicle 3. We note from the blue plot that the HMM predicts the vehicle to perform a lane pass. However the the vehicle's path forward is blocked by vehicles 1 and 5. The VIM thus infers vehicle 3 to perform a cut-in in with respect to the ego-vehicle in order to overtake vehicle 5.</p><p>In Figure <ref type="figure" target="#fig_5">6b</ref>, the HMM predicts vehicle 18 to overtake the ego-vehicle from the right. However, we can see that the right lane is occupied by vehicles 11, 3 and 2. These vehicles yield high values of pairwise energies with vehicle 18 for the overtake maneuver. The VIM thus correctly manages to predict that vehicle 18 would end up tail-gating by assigning it the maneuver drift into ego lane (rear).</p><p>Finally Figure <ref type="figure" target="#fig_5">6c</ref> shows a very interesting case where the HMM predicts vehicle 1 to overtake the ego vehicle from the left. Again, the left lane is occupied by other vehicles making the overtake impossible to execute from the left. However, compared to the previous case, these vehicles are slightly further away and can be expected to yield relatively smaller energy terms as compared to case (b). However, these terms are enough to offset the very slight difference in the HMM's confidence values between the left and right overtake since both maneuvers do seem plausible if we consider vehicle 1 independently. Thus the VIM reassigns the maneuver for vehicle 1 to a right overtake, making the prediction closely match the ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSIONS</head><p>In this paper, we have presented a unified framework for surround vehicle maneuver recognition and motion prediction using vehicle mounted perceptual sensors, that leverages the instantaneous motion of vehicles, an understanding of motion patterns of freeway traffic and the effect of inter-vehicle interactions. The proposed framework outperforms an interacting multiple model based trajectory prediction baseline and runs in real time at about 6 frames per second.</p><p>An ablative analysis for the relative importance of each cue for trajectory prediction has been presented. In particular, we have shown that probabilistic modeling of surround vehicle trajectories is a more versatile approach, and leads to better predictions as compared to a purely motion model based approach for many safety critical trajectories around the ego vehicle. Additionally, subcategorizing trajectories based on maneuver classes leads to better modeling of motion patterns. Finally, incorporating a model that takes into account interactions between surround vehicles for simultaneously predicting each of their motion leads to better prediction as compared to predicting each vehicle's motion independently.</p><p>The proposed approach could be treated as a general framework, where improvements could be made to each of the three interacting modules.</p><p>Nachiket Deo is currently working towards his PhD in electrical engineering from the University of California at San Diego (UCSD), with a focus on intelligent systems, robotics, and control. His research interests span computer vision and machine learning, with a focus on motion prediction for vehicles and pedestrians Akshay Rangesh is currently working towards his PhD in electrical engineering from the University of California at San Diego (UCSD), with a focus on intelligent systems, robotics, and control. His research interests span computer vision and machine learning, with a focus on object detection and tracking, human activity recognition, and driver safety systems in general. He is also particularly interested in sensor fusion and multi-modal approaches for real time algorithms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mohan Manubhai Trivedi</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Overview of the proposed model: Track histories of all surround vehicles are obtained via a multi-perspective tracker and projected to the ground plane in the ego vehicle's frame of reference. The model consists of three interacting modules: The maneuver recognition module assigns confidence values to possible maneuvers being performed by each vehicle. The trajectory prediction module outputs future trajectories for each maneuver class. The vehicle interaction module assigns the true recognized maneuver for each vehicle by combining the confidence values provided by the maneuver recognition module and the feasibility of predicted trajectories given the relative configuration of all vehicles</figDesc><graphic coords="3,54.00,56.07,503.99,176.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Maneuver Classes for Freeway Traffic: We bin the trajectories of surround vehicles in the ego-vehicle frame of reference into 10 maneuver classes: 4 lane pass maneuvers, 2 overtake maneuvers, 2 cut-in maneuvers and 2 maneuvers involving drifting into ego vehicle lane.</figDesc><graphic coords="4,48.96,56.07,252.00,80.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 ) 2 ) 3 )</head><label>123</label><figDesc>Constant velocity (CV): The constant velocity models maintains an estimate of the position and velocity of the surround vehicles under the constraint that the vehicles move with a constant velocity. We use a Kalman filter for estimating the state and observations of the CV model. The CV model captures a majority of freeway vehicle motion. Constant acceleration (CA): The constant acceleration model maintains estimates of the the vehicle position, velocity and acceleration under the constant acceleration assumption using a Kalman Filter. The CA model can be useful for describing freeway motion especially in dense traffic. Constant turn rate and velocity (CTRV): The constant turn rate and velocity model maintains estimates of the the vehicle position, orientation and velocity magnitude under the constant yaw rate and velocity assumption. Since the state update for the CTRV model is non-linear, we use an extended Kalman filter for estimating the state and observations of the CTRV model. The CTRV model can be useful for modeling motion during lane changes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Dataset: Examples of annotated frames from the evaluation set (top left and top right) and trajectories belonging to all maneuver classes projected in the ground plane (bottom). We can observe that the trajectory patterns implicitly capture lane information</figDesc><graphic coords="7,59.29,56.07,230.40,227.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Analysis of predictions made by CV, M-VGMM and C-VGMM models: (a): Better prediction of lateral motion in overtakes by the probabilistic models. (b): Early detection of overtakes by the HMM. (c): Deceleration near the ego vehicle predicted by the C-VGMM. (d): Effect of lane information implicitly encoded by the M-VGMM and C-VGMM</figDesc><graphic coords="9,150.03,246.26,154.22,166.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Case Studies analyzing the effect of the VIM: Each case shows from left to right: The ground truth, predictions made independently for each vehicle, uncertainty of the independent predictions, predictions made with the VIM, uncertainties of the VIM predictions</figDesc><graphic coords="10,126.08,403.46,359.85,158.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>is a Distinguished Professor at University of California, San Diego (UCSD) and the founding director of the UCSD LISA: Laboratory for Intelligent and Safe Automobiles, winner of the IEEE ITSS Lead Institution Award (2015). Currently, Trivedi and his team are pursuing research in intelligent vehicles, autonomous driving, machine perception, machine learning, human-robot interactivity, driver assistance. Three of his students have received "best dissertation" recognitions and over twenty best papers/finalist recognitions. Trivedi is a Fellow of IEEE, ICPR and SPIE. He received the IEEE ITS Society's highest accolade "Outstanding Research Award" in 2013. Trivedi serves frequently as a consultant to industry and government agencies in the USA and abroad.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,333.11,199.53,208.80,329.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Dataset Statistics</figDesc><table><row><cell>Maneuver</cell><cell>Number of trajectories</cell><cell>Number of trajectory snippets</cell></row><row><cell>Lane Pass (Left Forward)</cell><cell>59</cell><cell>9500</cell></row><row><cell>Lane Pass (Left Back)</cell><cell>75</cell><cell>10332</cell></row><row><cell>Lane Pass (Right Forward)</cell><cell>110</cell><cell>10123</cell></row><row><cell>Lane Pass (Right Back)</cell><cell>48</cell><cell>12523</cell></row><row><cell>Overtake (Left)</cell><cell>8</cell><cell>1629</cell></row><row><cell>Overtake (Right)</cell><cell>17</cell><cell>2840</cell></row><row><cell>Cut-in (Left)</cell><cell>8</cell><cell>1667</cell></row><row><cell>Cut-in (Right)</cell><cell>19</cell><cell>3201</cell></row><row><cell>Drift into ego lane (Front)</cell><cell>11</cell><cell>1317</cell></row><row><cell>Drift into ego lane (Rear)</cell><cell>8</cell><cell>553</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Quantitative results showing ablative analysis of our proposed model</figDesc><table><row><cell>Metric</cell><cell>Setting</cell><cell></cell><cell cols="2">All Trajectories</cell><cell></cell><cell cols="3">Overtakes and Cut-ins</cell><cell></cell><cell cols="2">Stop-and-Go Traffic</cell></row><row><cell></cell><cell>Prediction Horizon (s)</cell><cell>IMM</cell><cell cols="2">M-VGMM C-VGMM</cell><cell>C-VGMM + VIM</cell><cell cols="5">IMM M-VGMM C-VGMM IMM C-VGMM</cell><cell>C-VGMM +VIM</cell></row><row><cell>Mean Absolute Error (m)</cell><cell>1 2 3 4 5</cell><cell>0.25 0.72 1.25 1.78 2.36</cell><cell>0.24 0.70 1.19 1.70 2.24</cell><cell>0.24 0.69 1.18 1.68 2.20</cell><cell>0.24 0.69 1.18 1.66 2.18</cell><cell>0.29 0.83 1.47 2.17 2.90</cell><cell>0.32 0.87 1.46 2.05 2.68</cell><cell>0.29 0.82 1.39 1.94 2.49</cell><cell>0.22 0.68 1.21 1.74 2.29</cell><cell>0.20 0.65 1.17 1.68 2.21</cell><cell>0.20 0.64 1.14 1.65 2.17</cell></row><row><cell>Median Absolute Error (m)</cell><cell>1 2 3 4 5</cell><cell>0.19 0.55 0.96 1.38 1.85</cell><cell>0.17 0.52 0.92 1.32 1.77</cell><cell>0.17 0.52 0.91 1.30 1.72</cell><cell>0.17 0.52 0.91 1.29 1.72</cell><cell>0.23 0.68 1.24 1.92 2.64</cell><cell>0.23 0.65 1.13 1.71 2.27</cell><cell>0.23 0.65 1.12 1.68 2.12</cell><cell>0.15 0.48 0.89 1.32 1.8</cell><cell>0.13 0.46 0.87 1.29 1.78</cell><cell>0.13 0.45 0.83 1.27 1.75</cell></row><row><cell>Class. acc. (%)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>83.49</cell><cell>84.24</cell><cell>-</cell><cell>-</cell><cell>55.89</cell><cell>-</cell><cell>84.84</cell><cell>87.19</cell></row><row><cell>Exec. time (s)</cell><cell>-</cell><cell>0.0346</cell><cell>0.1241</cell><cell>0.0891</cell><cell>0.1546</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">maneuver recognition module, since the same model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">makes predictions irrespective of the maneuver being</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>performed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We would like to thank our colleague <rs type="person">Kevan Yuen</rs> for his invaluable contribution in the design and development of the testbed used in this work, and its software system. We are pleased to acknowledge the support of our research by various sponsoring agencies. Finally, we would like to thank the anonymous reviewers for their valuable feedback.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real time trajectory prediction for collision risk estimation between vehicles</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ammoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Nashashibi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Computer Communication and Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="417" to="422" />
		</imprint>
	</monogr>
	<note>ICCP 2009. IEEE 5th International Conference on</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">IMM object tracking for high dynamic driving maneuvers</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kaempchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dietmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="825" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A multilevel collision mitigation approachIts situation assessment, decision making, and performance tradeoffs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hillenbrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Spieker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kroschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on intelligent transportation systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="528" to="540" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sensor fusion for predicting vehicles&apos; path for collision avoidance systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tsogas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Amditis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Andreone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="549" to="562" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Where will the oncoming vehicle be the next second?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1068" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Comparison and evaluation of advanced motion models for vehicle tracking</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Wanielik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Fusion, 2008 11th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">EM-IMM based land-vehicle navigation with GPS/INS</title>
		<author>
			<persName><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. The 7th International IEEE Conference on</title>
		<meeting>The 7th International IEEE Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="624" to="629" />
		</imprint>
	</monogr>
	<note>Intelligent Transportation Systems</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">IMM-based lane-change prediction in highways with low-cost GPS/INS</title>
		<author>
			<persName><forename type="first">R</forename><surname>Toledo-Moreo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Zamora-Izquierdo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="180" to="185" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long-term vehicle motion prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hermes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wohler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kummert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009">2009. 2009</date>
			<biblScope unit="page" from="652" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Motion prediction for moving objects: a statistical approach</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vasquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fraichard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. ICRA&apos;04. 2004 IEEE International Conference on</title>
		<meeting>ICRA&apos;04. 2004 IEEE International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="3931" to="3936" />
		</imprint>
	</monogr>
	<note>Robotics and Automation</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Growing hidden markov models: An incremental tool for learning and predicting human and vehicle motion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vasquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fraichard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laugier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11-12</biblScope>
			<biblScope unit="page" from="1486" to="1506" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Bayesian nonparametric approach to modeling mobility patterns</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Fourth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Online maneuver recognition and multimodal trajectory prediction for intersection assistance using non-parametric regression</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Firl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium Proceedings</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="918" to="923" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic analysis of dynamic scenes and collision risks assessment to improve driving safety</title>
		<author>
			<persName><forename type="first">C</forename><surname>Laugier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">E</forename><surname>Paromtchik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Perrollaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-D</forename><surname>Yoder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mekhnacha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ngre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Transportation Systems Magazine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4" to="19" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A probabilistic long term prediction approach for highway scenarios</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schlechtriemen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-D</forename><surname>Kuhnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="732" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">When will it change the lane? A probabilistic regression approach for rarely occurring events</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schlechtriemen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wirthmueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K-D</forename><surname>Kuhnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="1373" to="1379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Probabilistic trajectory prediction with gaussian mixture models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wiest</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hffken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kreel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dietmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="141" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning and Predicting On-road Pedestrian Behavior around vehicles</title>
		<author>
			<persName><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Transportation Systems (ITSC), 2017 20th International IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Trajectory learning for activity understanding: Unsupervised, multilevel, and long-term adaptive approach</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2287" to="2301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Continuous driver intention recognition with hidden markov models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Emmert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dietmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ITSC 2008. 11th International IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1189" to="1194" />
		</imprint>
	</monogr>
	<note>Intelligent Transportation Systems</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using support vector machines for lanechange detection</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Mandalia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Salvucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the human factors and ergonomics society annual meeting</title>
		<meeting>the human factors and ergonomics society annual meeting</meeting>
		<imprint>
			<publisher>SAGE Publications</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1965" to="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Threat assessment design for driver assistance system at intersections</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Aoude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Luders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><surname>How</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Transportation Systems (ITSC), 2010 13th International IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1855" to="1862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Trajectories and Maneuvers of Surrounding Vehicles with Panoramic Camera Arrays</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Dueholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Kristoffersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Satzoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Vehicles</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="214" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Surround vehicles trajectory analysis with recurrent neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Khosroshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ohn-Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="2267" to="2272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Vehicle trajectory prediction based on motion model and maneuver recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Houenou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bonnifait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Cherfaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="4363" to="4369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bayesian, maneuver-based, longterm trajectory prediction and criticality assessment for driver assistance systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schreier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Willert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Adamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page" from="334" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tactical driver behavior prediction and intent inference: A review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Doshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Transportation Systems (ITSC), 2011 14th International IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1892" to="1897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recognition of situation classes at road intersections</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hermes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Whler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kummert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Automation (ICRA), 2010 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="3960" to="3965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interactive scene prediction for automotive applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lawitzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Althoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Passenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tanzmeister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wollherr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Buss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="page" from="1028" to="1033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards tactical lane change behavior planning for automated vehicles</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ulbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="989" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">If, when, and how to perform lane change maneuvers on highways</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Silvlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brannstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Coelingh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fredriksson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Transportation Systems Magazine</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="68" to="78" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic probabilistic drivability maps for lane change and merge driver assistance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2063" to="2073" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">DGPS-based vehicle-to-vehicle cooperative collision warning: Engineering feasibility viewpoints</title>
		<author>
			<persName><forename type="first">H-S</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="415" to="428" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cooperative collision avoidance at intersections: Algorithms and experiments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Caminiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Del</surname></persName>
		</author>
		<author>
			<persName><surname>Vecchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1162" to="1175" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Towards cooperative, predictive driver assistance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Transportation Systems-(ITSC), 2013 16th International IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1719" to="1724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains. The annals of mathematical statistics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Petrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soules</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Weiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="164" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pattern recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="1" to="58" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">No Blind Spots: Full-Surround Multi-Object Tracking for Autonomous Vehicles using Cameras &amp; LiDARs/ Under Review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rangesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Rangesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Satzoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Rajaram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName><surname>Multimodal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07502</idno>
		<title level="m">Full-Surround Vehicular Testbed for Naturalistic Studies and Benchmarking: Design, Calibration and Deployment</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
