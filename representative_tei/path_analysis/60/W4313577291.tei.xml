<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic Time Warping based Adversarial Framework for Time-Series Domain</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Taha</forename><surname>Belkhouja</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Yan</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName><roleName>Senior Member, IEEE</roleName><forename type="first">Janardhan</forename><surname>Rao Doppa</surname></persName>
						</author>
						<title level="a" type="main">Dynamic Time Warping based Adversarial Framework for Time-Series Domain</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T01:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Time Series</term>
					<term>Robustness</term>
					<term>Deep Neural Networks</term>
					<term>Adversarial Examples</term>
					<term>Dynamic Time Warping</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the rapid progress on research in adversarial robustness of deep neural networks (DNNs), there is little principled work for the time-series domain. Since time-series data arises in diverse applications including mobile health, finance, and smart grid, it is important to verify and improve the robustness of DNNs for the time-series domain. In this paper, we propose a novel framework for the time-series domain referred as Dynamic Time Warping for Adversarial Robustness (DTW-AR) using the dynamic time warping measure. Theoretical and empirical evidence is provided to demonstrate the effectiveness of DTW over the standard Euclidean distance metric employed in prior methods for the image domain. We develop a principled algorithm justified by theoretical analysis to efficiently create diverse adversarial examples using random alignment paths. Experiments on diverse real-world benchmarks show the effectiveness of DTW-AR to fool DNNs for time-series data and to improve their robustness using adversarial training.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>T O deploy deep neural network (DNN) based systems in important real-world applications such as healthcare, we need them to be robust <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. Adversarial methods expose the brittleness of DNNs <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> and motivate methods to improve their robustness. There is little principled work for the time-series domain <ref type="bibr" target="#b4">[5]</ref> even though this type of data arises in many real-world applications including mobile health <ref type="bibr" target="#b5">[6]</ref>, finance <ref type="bibr" target="#b6">[7]</ref>, and smart grid analytics <ref type="bibr" target="#b7">[8]</ref>. The time-series modality poses unique challenges for studying adversarial robustness that are not seen in images <ref type="bibr" target="#b8">[9]</ref> and text <ref type="bibr" target="#b9">[10]</ref>. The standard approach of imposing an l p -norm bound to create worst possible scenarios from a learning agent's perspective does not capture the true similarity between time-series instances. Consequently, l p -norm constrained perturbations can potentially create adversarial examples that correspond to a completely different class label. There is no prior work on filtering methods in the signal processing literature to automatically identify such adversarial candidates. Hence, adversarial examples from prior methods based on l pnorm will confuse the learner when they are used to improve the robustness of DNNs. In other words, the accuracy of DNNs will degrade on real-world data after adversarial training.</p><p>This paper proposes a novel adversarial framework for time-series domain referred as Dynamic Time Warping for Adversarial Robustness (DTW-AR) to address the abovementioned challenges. DTW-AR employs the dynamic time warping measure <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref> as it can be used to measure a realistic distance between two time-series signals (e.g., invariance to shift and scaling operations) <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. For example, a signal that has its frequency changed due to Doppler effect would output a small DTW measure to the original signal. However, if Euclidean distance is used, both signals would look very dissimilar, unlike the reality. We theoretically analyze the suitability of DTW measure over the Euclidean distance. Specifically, the space of candidate adversarial examples in the DTW space is a superset of those in Euclidean space for the same distance bound. Therefore, DTW measure provides a more appropriate bias than the Euclidean space for the time series domain and our experiments demonstrate practical benefits of DTW-based adversarial examples. While certain time-series classification tasks can be solved using low-complexity algorithms such as 1NN-DTW and avoid the adversarial setting, we find that deep models are better suited for multivariate time-series data. Due to the rising complexity of time-series data in several applications (e.g., mobile health <ref type="bibr" target="#b5">[6]</ref>, Human activity recognition <ref type="bibr" target="#b13">[14]</ref>, or sleep monitoring <ref type="bibr" target="#b14">[15]</ref>), low-complexity algorithms such as kNN-DTW can potentially perform badly on high-dimensional multivariate data as we demonstrate in Section B. Therefore, the adversarial setting remains applicable for time-series domain.</p><p>To create targeted adversarial examples, we formulate an optimization problem with the DTW measure bound constraint and propose to solve it using an iterative gradientbased approach. However, this simple method has two drawbacks. First, this method allows us to only find one valid adversarial example out of multiple solution candidates from the search space because it operates on a single optimal alignment. Second, we need to compute DTW measure in each iteration as the optimal DTW alignment path changes over iterations. Since the number of iterations are typically large and DTW computation is expensive, the overall algorithm becomes prohibitively slow. To successfully overcome these two drawbacks, our key insight is to employ stochastic alignments to create adversarial examples. We theoretically and experimentally show that a simpler distance measure based on random alignment path upper-bounds the DTW measure measure and that this bound is tight. This algorithm allows us to efficiently create many diverse adversarial examples using different alignment paths to improve the robustness arXiv:2207.04308v2 [cs.LG] 22 Nov 2022 of DNN models via adversarial training. Our experiments on real-world time-series datasets show that the DTW-AR creates more effective adversarial attacks to fool DNNs when compared to prior methods and enables improved robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions.</head><p>The key contribution of this paper is the development and evaluation of the DTW-AR framework for studying adversarial robustness of DNNs for time-series domain. Specific list includes: of invariance for time-series signals. Hence, l p -norm based perturbations can lead to a time-series signal that semantically belongs to a different class-label. Our experiments show that small perturbations result in adversarial examples whose l 2 distance from the original time-series signal is greater than the distance between time-series signals from two different class labels (see <ref type="bibr">Section 5.2)</ref>. Therefore, we need to study new methods by exploiting the structure and unique characteristics of time-series signals.</p><p>DTW measure. The DTW measure between two uni-variate signals X and Z ∈ R T is computed via a cost matrix C ∈ R T ×T using a dynamic programming (DP) algorithm with time-complexity O(T 2 ). The cost matrix is computed recursively using the following equation:</p><formula xml:id="formula_0">C i,j = d(X i , Z j ) + min C i-1,j , C i,j-1 , C i-1,j-1<label>(1)</label></formula><p>where d(•, •) is any given distance metric (e.g., • p norm).</p><p>The DTW measure between signals X and Z is DT W (X, Z) = C T,T . The sequence of cells P = {c i,j = (i, j)} contributing to C T,T is the optimal alignment path between X and Z. Figure <ref type="figure" target="#fig_0">1</ref> provides illustration for an optimal alignment path. We note that the diagonal path corresponds to the Euclidean distance metric. For the multi-variate case, where X and Z ∈ R n×T , to measure the DTW measure using Equation 1, we have d(X i , Z j ) with X i , Z j ∈ R n <ref type="bibr" target="#b15">[16]</ref>. We define the distance function dist P (X, Z) between time-series inputs X and Z according to an alignment path P using the following equations:</p><formula xml:id="formula_1">dist P (X, Z) = (i,j)∈P d(X i , Z j )<label>(2)</label></formula><p>Hence, the DTW measure between X and Z is given by: DT W (X, Z) = min</p><formula xml:id="formula_2">P dist P (X, Z)<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DYNAMIC TIME WARPING BASED ADVERSARIAL ROBUSTNESS FRAMEWORK</head><p>The DTW-AR framework creates targeted adversarial examples for time-series domain using the DTW measure as illustrated in Figure <ref type="figure">2</ref>. For any given time-series input X, DNN classifier F θ , and distance bound δ, we solve an optimization problem to identify an adversarial example This abstraction is tightly based on the observations made on real-world data. We employ multi-dimensional scaling (MDS), a visual representation of dissimilarities between sets of data points <ref type="bibr" target="#b16">[17]</ref>, to compare DTW and Euclidean spaces. MDS is a dimensionality reduction method that preserves the distances between data points in the original space. Figure <ref type="figure" target="#fig_2">4</ref> shows MDS results of SC dataset. We can clearly see how the data from different class labels are better clustered in the DTW space compared to the Euclidean space, as provided in Figure <ref type="figure" target="#fig_2">4</ref>. An adversarial example for an SC data point in the green-labeled class is more likely to semantically belong to the red-labeled distribution in the Euclidean space. However, in the DTW space, the adversarial example is more likely to remain in the green-labeled space, while only being misclassified by the DNN classifier due the adversarial problem.  Observation 1. Let l 2 be the equivalent of Euclidean distance using the cost matrix in the DTW space. ∀X ∈ R n×T (n &gt; 1, T &gt; 1), there exists ∈ R n×T and an alignment path P such that dist P (X, X + ) ≤ δ and l 2 (X, X + ) &gt; δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Euclidean Space DTW Space</head><p>Theorem 1. For a given input space R n×T , a constrained DTW space for adversarial examples is a strict superset of a constrained euclidean space for adversarial examples. If X ∈ R n×T :</p><formula xml:id="formula_3">X adv DT W (X, X adv ) ≤ δ ⊃ X adv X -X adv 2 2 ≤ δ<label>(4)</label></formula><p>As an extension of Observation 1, the above theorem states that in the space where adversarial examples are constrained using a DTW measure bound, there exists more adversarial examples that are not part of the space of adversarial examples based on the Euclidean distance for the same bound (i.e., blind spots). This result implies that DTW measure has an appropriate bias for the time-series domain. We present the proofs of both Observation 1 and Theorem 1 in the Appendix. Hence, our DTW-AR framework is potentially capable of creating more effective adversarial examples than prior methods based on l 2 distance for the same distance bound constraint. These adversarial examples are potentially more effective as they are able to break deep models by leveraging the appropriate bias of DTW measure.</p><p>However, to convert this potential to reality, we need an algorithm that can efficiently search this larger space of attacks to identify most or all adversarial examples which meet the DTW measure bound. Indeed, developing such an algorithm is one of the key contributions of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Naive optimization based formulation and challenges to create adversarial examples</head><p>To create adversarial examples to fool the given DNN F θ , we need to find an optimized perturbation of the input timeseries X to get X adv . Our approach is based on minimizing a loss function L using gradient descent that achieves two goals. 1) Misclassification goal: Adversarial example X adv to be mis-classified by F θ as a target class-label y target ; and 2) DTW similarity goal: close DTW-based similarity between time-series X and adversarial example X adv .</p><p>To achieve the mis-classification goal, we employ the formulation of <ref type="bibr" target="#b17">[18]</ref> to define a loss function:</p><formula xml:id="formula_4">L label (X adv ) = max max y =ytarget (S y (X adv )) -S ytarget (X adv ) , ρ<label>(5)</label></formula><p>where ρ &lt; 0. It ensures that the adversarial example will be classified by the DNN as class-label y target with a confidence |ρ| using the output of the pre-softmax layer {S y } y∈Y .</p><p>To achieve the DTW similarity goal, we need to create X adv for a given time-series input X such that DT W (X, X adv ) ≤ δ. We start by a naive optimization over the DTW measure using the Soft-DTW measure SDTW(X, X adv ) <ref type="bibr" target="#b18">[19]</ref>. Hence, the DTW similarity loss function is:</p><formula xml:id="formula_5">L DT W (X adv ) = SDTW(X, X adv )<label>(6)</label></formula><p>The final loss function L we want to minimize to create optimized adversarial example X adv is:</p><formula xml:id="formula_6">L(X adv ) = L label (X adv ) + L DT W (X adv ) ( )</formula><p>We operate under white-box setting and can employ gradient descent to minimize the loss function in Equation over X adv . This approach works for black-box setting also. In this work, we consider the general case where we do not query the black-box target DNN classifier. We show through experiments that the created adversarial examples can generalize to fool other black-box DNNs.</p><p>Challenges of Naive approach. Recall that our overall goal is to identify most or all targeted adversarial time-series examples that meet the DTW measure bound. This will allow us to improve the robustness of DNN model using adversarial training. This naive approach has two main drawbacks.</p><p>(a) (b) Fig. <ref type="figure">5</ref>. Illustration of the close-similarity space around a given time-series signal (black center) in the Euclidean and DTW space. Using l 2 norm is sufficient to explore the entire Euclidean space around the input. However, in the DTW space, each colored section corresponds to one adversarial example that meets the DTW measure bound constraint. Each of them can be found using only a subset of candidate alignment paths.</p><p>• Single adversarial example. The method allows us to only find one valid adversarial example out of multiple solution candidates from the search space because it operates on a single optimal alignment path. Using a single alignment path (whether the diagonal path for Euclidean distance or the optimal alignment path generated by DTW), the algorithm will be limited to the adversarial examples which use that single alignment. In Figure <ref type="figure">5</ref>, we provide a conceptual illustration of S ADV (X), the set of all adversarial examples X adv which meet the distance bound constraint DT W (X, X adv ) ≤ δ. In the Euclidean space, using l 2 norm is sufficient to explore the entire search space around the original input to create adversarial examples. However, in the DTW space, each colored section in S ADV (X) can only be found using a subset of candidate alignment paths.</p><p>• High computational cost. DTW is non-differentiable and approximation methods are often used in practice. These methods require O(n.T 2 ) to fill the cost matrix and O(T ) to backtrack the optimal alignment path. These steps are computationally-expensive. Gradient-based optimization iteratively updates the adversarial example X adv to achieve the DTW similarity goal, i.e., DT W (X, X adv ) ≤ δ, and the mis-classification goal, i.e., F θ (X adv )=y target . Standard algorithms such as projected gradient descent (PGD) <ref type="bibr" target="#b0">[1]</ref> and Carloni &amp; Wagner (CW) <ref type="bibr" target="#b17">[18]</ref> require a large number of iterations to generate valid adversarial examples. This is also true for the recent computer vision specific adversarial algorithms <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>. For time-series signals arising in many real-world applications, the required number of iterations to create successful attacks can grow even larger. We need to compute DTW measure in each iteration as the optimal DTW alignment path changes over iterations. Therefore, it is impractical to use the exact DTW computation algorithm to create adversarial examples. We also show that the existing optimized approaches to estimate the DTW measure remain computationally expensive for an adversarial framework. We provide results to quantify the runtime cost in our experimental evaluation. L(X adv ) ← L label (X adv ) + L DT W (X adv , P rand )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Compute gradient ∇ X adv L(X adv )</p><p>6:</p><p>Perform gradient descent step: X adv ← X adv -η × ∇ X adv L(X adv ) 7: end for 8: return optimized adversarial example X adv</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Stochastic alignment paths for the DTW similarity goal and theoretical justification</head><p>In this section, we describe the key insight of DTW-AR to overcome the above-mentioned two challenges and provide theoretical justification.</p><p>To overcome the above-mentioned two challenges of the naive approach, we propose the use of a random alignment path to create adversarial attacks on DNNs for time-series domain. The key idea is to select a random alignment path P and to execute our adversarial algorithm while constraining over dist P (X, X adv ) instead of DT W (X, X adv ). This choice is justified from a theoretical point-of-view due to the special structure in the problem to create DTW based adversarial examples. Using the distance function dist P (X, X adv ), we redefine Equation 6 as follows:</p><formula xml:id="formula_7">L DT W (X adv , P ) = α 1 × dist P (X, X adv ) -α 2 × dist P diag (X, X adv )<label>(7)</label></formula><p>where α 1 &gt; 0, α 2 ≥ 0, P diag is the diagonal alignment path equivalent to the Euclidean distance, and P is a given alignment path (P = P diag ). The first term of Equation <ref type="formula" target="#formula_7">7</ref>is defined to bound the DTW similarity of adversarial example X adv to a threshold δ as stated in Observation 2. The second term represents a penalty term to account for adversarial example with close Euclidean distance to the original input X and pushes the algorithm to look beyond adversarial examples in the Euclidean space. The coefficients α 1 and α 2 contribute in defining the position of the adversarial output in the DTW and/or Euclidean space. If α 2 → 0, the adversarial example X adv will be highly similarity to the original input X in the DTW space with no consideration to the Euclidean space. Hence, the adversarial example may be potentially adversarial in the Euclidean space also. However, if α 2 &gt; 0, the adversarial output will be highly similar to the original input in the DTW space but out of the scope of adversarial attacks in the Euclidean space (i.e., a blind spot). Recall from Theorem 1 that DTW space allows more candidate adversarial examples than Euclidean space. Hence, this setting allows us to find blind spots of Euclidean space based attacks.</p><p>The DTW-AR approach to create adversarial examples is shown in Algorithm 1. We note that the naive approach that uses Soft-DTW with the Carlini &amp; Wagner loss function is a sub-case of DTW-AR as shown below:</p><formula xml:id="formula_8">SDTW(X, X adv ) = L DT W (X adv , P DT W ) = 1 × dist P DT W (X, X adv ) -0 × dist P diag (X, X adv )<label>(8)</label></formula><p>where P DT W is the optimal DTW alignment path.</p><p>Observation 2. Given any alignment path P and two multivariate time-series signals</p><formula xml:id="formula_9">X, Z ∈ R n×T . If we have dist P (X, Z) ≤ δ, then DT W (X, Z) ≤ δ.</formula><p>Observation 2 states that dist P (X, Z) defined with respect to a path P is always an upper bound for DT W (X, Z), since DTW uses the optimal alignment path. Hence, when the alignment path is fixed, the time-complexity is reduced to a simpler similarity measure that requires only O(n.T ), which results in significant computational savings due to repeated calls within the adversarial algorithm.</p><p>Our stochastic alignment method also improves the search strategy for finding multiple desired adversarial examples. Suppose S ADV (X) is the set of all adversarial examples X adv which meet the distance bound constraint DT W (X, X adv ) ≤ δ. Each adversarial example in S ADV (X) can be found using only a subset of candidate alignment paths. By using a stochastic alignment path, we can leverage the large pool of different alignment paths to uncover more than one adversarial example from S ADV (X). On the other hand, if the exact DTW computation based algorithm was feasible, we would only find a single X adv , as DTW based algorithm operates on a single optimal alignment path.</p><p>Theoretical tightness of bound. While Observation 2 provides an upper bound for the DTW measure, it does not provide any information about the tightness of the bound. To analyze this gap, we need to first define a similarity measure between two alignment paths to quantify their closeness. We define PathSim as a similarity measure between two alignment paths P 1 and P 2 in the DTW cost matrix of time-series signals X, Z ∈ R n×T . Let P 1 = {c 1  1 , ..., c 1 k } and</p><formula xml:id="formula_10">P 2 = {c 2 1 , .</formula><p>.., c 2 l } represent the sequence of cells for paths P 1 and P 2 respectively.</p><formula xml:id="formula_11">PathSim (P 1 , P 2 ) = 1 2T   c 1 i min c 2 j c 1 i -c 2 j 1 + c 2 i min c 1 j c 2 i -c 1 j 1  <label>(9)</label></formula><p>As PathSim(P 1 , P 2 ) approaches 0, P 1 and P 2 are very similar, and they will be the exact same path if PathSim(P 1 , P 2 ) = 0. For X, Z ∈ R n×T , two very similar alignment paths corresponds to a similar feature alignment between X and Z. Theorem 2 shows the tightness of the bound given in Observation 2 using the path similarity measure defined above.</p><p>Theorem 2. For a given input X ∈ R n×T and a random alignment path P rand , the resulting adversarial example X adv from the minimization over dist P rand (X, X adv ) is equivalent to minimizing over DT W (X, X adv ). For any X adv generated by DTW-AR using P rand , we have:</p><formula xml:id="formula_12">     PathSim(P rand , P DT W ) = 0 &amp; dist P rand (X, X adv ) = DT W (X, X adv ) (10)</formula><p>where P DT W is the optimal alignment path found using DTW computation between X and X adv .</p><p>Similarity measure PathSim definition. For DTW-AR, we rely on a stochastic alignment path to compute dist P defined in Equation 2. To improve our understanding of the behavior of DTW-AR framework based on stochastic alignment paths, we propose to define a similarity measure that we call PathSim. This measure quantifies the similarities between two alignment paths P 1 and P 2 in the DTW cost matrix for two time-series signals X, Z ∈ R n×T . If we denote the alignment path sequence</p><formula xml:id="formula_13">P 1 = {c 1 1 , • • • , c 1 k } and P 2 = {c 2 1 , • • • , c 2</formula><p>l }, then we can measure their similarity as defined in Equation <ref type="formula" target="#formula_11">9</ref>.</p><p>This definition is a valid similarity measure as it satisfies all the distance axioms <ref type="bibr" target="#b21">[22]</ref>:</p><p>Non-negativity: By definition, PathSim(P 1 , P 2 ) is a sum of l 1 distances, which are all positives. Hence, PathSim(P 1 , P 2 ) ≥ 0.</p><formula xml:id="formula_14">Unicity: PathSim(P 1 , P 2 ) = 0 ⇐⇒ 1 2T ( c 1 i min c 2 j c 1 i -c 2 j 1 + c 2 i min c 1 j c 2 i -c 1 j 1 ) = 0 ⇐⇒ c 1 i min c 2 j c 1 i -c 2 j 1 + c 2 i min c 1 j c 2 i -c 1 j 1 = 0</formula><p>As we have a sum equal to 0 of all positive terms, we can conclude that each term (min • 1 ) is equal to 0:</p><formula xml:id="formula_15">PathSim(P 1 , P 2 ) = 0 ⇐⇒ ∀i : c 1 i -c 2 i 1 = 0 ⇐⇒ ∀i : c 1 i = c 2 i</formula><p>As both paths have the same sequence of cells, we can safely conclude that PathSim(P 1 , P 2 ) = 0 ⇐⇒ P 1 = P 2 :</p><p>Symmetric Property:</p><formula xml:id="formula_16">PathSim(P 1 , P 2 ) = 1 2T   c 1 i min c 2 j c 1 i -c 2 j 1 + c 2 i min c 1 j c 2 i -c 1 j 1   = 1 2T   c 2 i min c 1 j c 2 i -c 1 j 1 + c 1 i min c 2 j c 1 i -c 2 j 1   = PathSim(P 2 , P 1 )</formula><p>Note that the triangle inequality is not applicable as the alignment path spaces does not support additive operations.</p><p>This similarity measure quantifies the similarity between two alignment paths as it measures the l 1 distance between the different cells of each path. The multiplication factor 1/2T is introduced to prevent scaling of the measure for large T values for a given time-series input space R n×T .</p><p>In Figure <ref type="figure" target="#fig_3">6</ref>, we visually show the relation between PathSim measure and the alignment path for a given cost matrix. We observe that when PathSim(P 1 , P 2 ) → 0, P 1 and P 2 are very similar, and they will be the exact same path if PathSim(P 1 , P 2 ) = 0. For PathSim(P 1 , P 2 ) 0, the alignment path will go through different cells which are far-placed from each other in the cost matrix.</p><p>Empirical tightness of bound. Figure <ref type="figure" target="#fig_4">7</ref> shows that over the iterations of the DTW-AR algorithm, the updated adversarial example yields to an optimal alignment path that is more similar to the input random path. This result strongly demonstrate that Theorem 2 holds empirically.</p><p>Corollary 1. Let P 1 and P 2 be two alignment paths such that PathSim(P 1 , P 2 ) &gt; 0. If X 1 adv and X 2 adv are the adversarial examples generated using DTW-AR from any given time-series X using paths P 1 and P 2 respectively such that DT W (X, X 1 adv ) = δ and DT W (X, X 2 adv ) = δ, then X 1 adv and X 2 adv are not necessarily the same. Theorem 2 shows that the adversarial example generation using DTW-AR is equivalent to the ideal setting where it is possible to optimize DT W (X, X adv ). The above corollary extends Theorem 2 to show that if we employ different alignment paths within Algorithm 1, we will be able to find more adversarial examples which meet the distance bound in contrast to the naive approach. <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. Such methods include Carlini &amp; Wagner attack <ref type="bibr" target="#b17">[18]</ref>, boundary attack <ref type="bibr" target="#b22">[23]</ref>, and universal attacks <ref type="bibr" target="#b23">[24]</ref>. Recent work focuses on regularizing adversarial example generation methods to obey intrinsic properties of images <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. In NLP domain, methods to fool text classifiers employ the saliency map of input words to generate adversarial examples while preserving meaning to a human reader in white-box setting <ref type="bibr" target="#b27">[28]</ref>. DeepWordBug <ref type="bibr" target="#b28">[29]</ref> employs a black-box strategy to fool classifiers with simple character-level transformations. Since   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adversarial methods. Prior work on adversarial examples mostly focus on image and text domains</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adversarial attacks for time-series domain.</head><p>There is little to no principled prior work on adversarial methods for timeseries 1 . Fawaz et al., <ref type="bibr" target="#b1">[2]</ref> employed the standard Fast Gradient Sign method <ref type="bibr" target="#b37">[38]</ref> to create adversarial noise with the goal of reducing the confidence of deep convolutional models for classifying uni-variate time-series. Network distillation is employed to train a student model for creating adversarial attacks <ref type="bibr" target="#b2">[3]</ref>. However, this method is severely limited: it can generate adversarial examples for only a small number of target labels and cannot guarantee generation of adversarial example for every input. <ref type="bibr" target="#b3">[4]</ref> tried to address adversarial examples with elastic similarity measures, but does not propose any elastic-measure based attack algorithm.</p><p>Time-series pre-processing methods. A possible solution to overcome the Euclidean distance concerns is to introduce pre-processing steps that are likely to improve the existing frameworks. Simple pre-processing steps such as MinMaxnormalization or z-normalization only solves problems such as scaling problem. However, they do not address any concern about signal-warping or time-shifts. Other approaches rely on learning feature-preserving representations. A wellknown example is the GRAIL <ref type="bibr" target="#b38">[39]</ref> framework. This framework aims to learn compact time-series representations that preserve the properties of a pre-defined comparison function such as DTW. The main concern about feature-preserving pre-processing steps is that the representation learnt is not reversible. In other words, a real-world time-series signal cannot be generated from the estimated representation. The goal of adversarial attacks is to create real-world time-series that can be used to fool any DNN. Such challenges would limit the usability and the generality of methods based on pre-processing steps to study the robustness of DNNs for time-series data.</p><p>In summary, existing methods for time-series domain are lacking in the following ways: 1) they do not create 1. In a concurrent work, Belkhouja et al., developed an adversarial framework for using statistical features <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref> and another min-max optimization methods <ref type="bibr" target="#b36">[37]</ref> to explicitly train robust deep models for time-series domain using global alignment kernels targeted adversarial attacks; and 2) they employ l p -norm based perturbations which do not take into account the unique characteristics of time-series data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS AND RESULTS</head><p>We empirically evaluate the DTW-AR framework and discuss the results along different dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head><p>Datasets. We employ the UCR datasets benchmark <ref type="bibr" target="#b39">[40]</ref>. We present the results on five representative datasets (AtrialFibrillation, Epilepsy, ERing, Heartbeat, RacketSports) from diverse domains noting that our findings are general as shown by the results on remaining UCR datasets in the Appendix. We employ the standard training/validation/testing splits from these benchmarks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Discussion</head><p>Spatial data distribution with DTW. We have shown in Figure <ref type="figure" target="#fig_2">4</ref>   Admissible alignment paths. The main property of DTW alignment is the one-to-many match between time-steps to identify similar warped pattern. Intuitively, if an alignment path matches few time-steps from the first signal with too many steps in the second signal, both signals are not considered similar. Consequently, the optimal path would be close to the corners of the cost matrix. Figure <ref type="figure" target="#fig_6">8</ref> provides a comparison between two adversarial signals generated using a green colored path closer to the diagonal vs. a red colored path that is close to the corners. We can see that the red path produces an adversarial example that is not similar to the original input. Hence, we limit the range of the random path P rand used to a safe range omitting the cells at the top and bottom halves of the top-left and bottom-right corners. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple diverse adversarial examples using DTW-AR.</head><p>In section 3.2, we argued that using stochastic alignment paths, we can create multiple diverse adversarial time-series examples within the same DTW measure bound. DTW-AR method leverages the large pool of candidate alignment paths to uncover more than one adversarial example as illustrated in Figure <ref type="figure">5</ref>. To further test this hypothesis, we perform the following experiment. We sample a subset of different (using PathSim) alignment paths {P rand } i and execute DTW-AR algorithm to create adversarial examples for the same time-series X. Let X adv,i be the adversarial example generated from X using P rand,i . We measure the similarities between the generated {X adv } i using DTW and l 2 distance. If the distance between two adversarial examples is less than a threshold sim , then they are considered the same adversarial example. Table <ref type="table" target="#tab_5">2</ref> shows the percentage of adversarial examples generated using different alignment paths from a given time-series signal that are not similar to any other adversarial example. We conclude that DTW-AR algorithm indeed creates multiple different adversarial examples from a single time-series signal for the same DTW measure bound.</p><p>Empirical justification for Theorem 2. We provided a proof for the gap between creating an adversarial example using the proposed DTW-AR algorithm and an ideal DTW algorithm. In Figure <ref type="figure" target="#fig_4">7</ref>(a), we provide an illustration of the optimal alignment path update using DTW-AR. This experiment was performed on the ECG200 dataset as an example (noting that we observed similar patterns for other datasets as well): the blue path represents the selected random path to be used by DTW-AR and the red path represents the optimal alignment path computed by DTW. At the beginning, the optimal alignment path (dotted path) and the random path are dissimilar. However, as the execution of DTW-AR progresses, the updated adversarial example yields to an optimal alignment path similar to the random path. In Figure <ref type="figure" target="#fig_4">7</ref>(b), we show the progress of the PathSim score as a function of the iteration numbers of Algorithm 1. This figure shows the convergence of the PathSim score to 0. These strong results confirm the main claim of Theorem 2 that the resulting adversarial example X adv from the minimization over dist P rand (X, X adv ) is equivalent to minimizing over DT W (X, X adv )! Loss function scaling.As the final loss function is using two different terms to create adversarial attacks, the absence of a scaling parameter can affect the optimization process. In Figure <ref type="figure" target="#fig_0">10</ref>, we demonstrate that empirically, the first term of the Equation plateaus at ρ before minimizing L DT W .</p><p>The figure shows the progress of both L label and L DT W = α 1 × dist P (X, X adv ) over the first 100 iterations of DTW-AR algorithm. We conclude that there is no need to scale the loss function noting that our findings were similar for other time-series datasets. In the general case, if a given application requires attention to scaling both terms (L DT W and L label ), the learning rate can be adjusted    AR examples to increase the robustness of a given DNN. When set to 0, we see that there is no significant difference in the performance against baseline attacks. However, the DNN cannot defend against all DTW-AR attacks. We can also observe that the setting where α 2 is strictly different than 0 is the worst, as the DNN does not learn from the adversarial examples that are found in the Euclidean space by DTW-AR or the given baselines.</p><p>Naive approach: Carlini &amp; Wagner with Soft-DTW. Recall that naive approach uses DTW measure within the Carlini &amp; Wagner loss function. SoftDTW <ref type="bibr" target="#b18">[19]</ref> allows us to create a differentiable version of DTW measure. Hence, we provide results for this naive approach to verify if the the use of Soft-DTW with existing Euclidean distance based methods can solve the challenges for the time-series domain mentioned in this paper. We compare the DTW-AR algorithm with the CW-SDTW that plugs Soft-DTW within the Carlini &amp; Wagner algorithm instead of the standard l 2 distance. CW-SDTW has the following limitations when comapred against DTW-AR:</p><p>•</p><p>The time-complexity of Soft-DTW is quadratic in the dimensionality of time-series input space, whereas the distance computation in DTW-AR is linear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The CW-SDTW attack method is a sub-case of the DTW-AR algorithm. If DTW-AR algorithm uses the optimal alignment path instead of a random path, the result will be equivalent to a CW-SDTW attack. In conclusion, both challenges that were explained in the Challenges of Naive approach in Section 3.1 cannot be solved using CW-SDTW. As a consequence, the robustness goal aimed by this paper cannot be achieved using solely CW-SDTW. Indeed, our experiments support this hypothesis.  better than this naive baseline. Figure <ref type="figure" target="#fig_14">16</ref> shows that DTW-AR significantly improves the robustness of deep models for time-series as it is able to evade attacks generated CW-SDTW. Both these experiments demonstrate that CW-SDTW is neither able to create stronger attacks nor a more robust deep model when compared to DTW-AR.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DTW-AR outperforms [3] due to following reasons:</head><p>• DTW-AR generates at least one adversarial example for every input X ∈ R n×T as shown in our experiments.</p><p>• Adversarial examples created by DTW-AR are highly effective against deep models relying on <ref type="bibr" target="#b2">[3]</ref> for adversarial training as this baseline fails to create adversarial examples for many inputs and target classes (shown in <ref type="bibr" target="#b2">[3]</ref>).</p><p>• Adversarial examples created by the method from <ref type="bibr" target="#b2">[3]</ref> does not evade deep models from DTW-AR based adversarial training.</p><p>Computational runtime of DTW-AR vs. DTW. As explained in the technical section, optimization based attack algorithm requires a large number of iterations to create a highly-similar adversarial example. For example, 10 3 iterations is the required default choice for CW to create successful attacks, especially, for large time-series in our experiments. The exact DTW method is non-differentiable, thus, it is not possible to perform experiments to compare DTW-AR method to the exact DTW method. Hence, we assume that each iteration will compute the optimal DTW path and use it instead of the random path. To assess the runtime of computing the DTW measure, we employ three different approaches: 1) The standard DTW algorithm, 2)</p><p>The FastDTW <ref type="bibr" target="#b40">[41]</ref> that was introduced to overcome DTW computational challenges, and 3) cDTW <ref type="bibr" target="#b41">[42]</ref> that measures DTW in a constrained manner using warping windows. We note that FastDTW was proven to be inaccurate, and cDTW is faster and more accurate for computing DTW measure <ref type="bibr" target="#b42">[43]</ref>. We show both baselines for the sake of completeness. We provide the runtime of performing each iteration using the different algorithms in Figure <ref type="figure" target="#fig_16">18</ref>. We can clearly observe that DTW-AR is orders of magnitude faster than the standard DTW and the accelerated DTW algorithms. The overall computational cost will be significantly reduced using DTW-AR compared to exact DTW or soft-DTW <ref type="bibr" target="#b18">[19]</ref> for large-size time-series signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DTW-AR extension to other multivariate DTW mea-</head><p>sures.The DTW-AR framework relies on the distance function dist P (X, Z) = (i,j)∈P d(X i , Z j ) between two timeseries signals X and Z according to an alignment path P to measure their similarity. Extending the DTW notion from univariate to multivariate is a known prob-lem, where depending on the application, researchers' suggest to change the definition of dist P (X, Z) to better fit the characteristics of the application at hand. In all cases, DTW-AR relies on using the final cost matrix DT W (X, Z) = min</p><formula xml:id="formula_17">P dist P (X, Z) using dynamic program- ming C i,j = d(X i , Z j ) + min C i-1,j , C i,j-1 , C i-1,j-1 .</formula><p>Therefore, the use of different variants of dist P (X, Z) (e.g., DT W I or DT W D <ref type="bibr" target="#b15">[16]</ref>) will only affect the cost matrix values, but will not change the assumptions and applicability of DTW-AR. Therefore, DTW-AR is general and can work with any variant of DTW. In Figure <ref type="figure" target="#fig_17">19</ref>, we demonstrate that using a different family of DTW (DT W I ) does not have a major impact on DTW-AR's performance and effectiveness. The performance of DTW-AR framework using both alternative measures of multi-variate DTW does not affect the overall performance. Therefore, for a given specific application, the practitioner can configure DTW-AR appropriately. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Summary of Experimental Results</head><p>Our experimental results supported all the claims made in Section 3. The summary list includes:</p><p>• Figure <ref type="figure" target="#fig_2">4</ref> showed that DTW space is more suitable for adversarial studies in the time-series domain than Euclidean distance to support Theorem 1.</p><p>• Using stochastic alignment paths, DTW-AR creates multiple diverse adversarial examples to support Corollary 1 (Table <ref type="table" target="#tab_5">2</ref>), which is impossible using the optimal alignment path.</p><p>• Figure <ref type="figure" target="#fig_4">7</ref> provides empirical justification for Theorem 2 showing that minimizing over a given alignment path is equivalent to minimizing using exact DTW method (bound is tight).  • Figure <ref type="figure" target="#fig_17">19</ref> demonstrates that DTW-AR can generalize to any multivariate DTW measure (such as DTWAdaptive <ref type="bibr" target="#b15">[16]</ref>) without impacting on its performance and effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We introduced the DTW-AR framework to study adversarial robustness of deep models for the time-series domain using dynamic time warping measure. This framework creates effective adversarial examples by overcoming the limitations of prior methods based on Euclidean distance. We theoretically and empirically demonstrate the effectiveness of DTW-AR to fool deep models for time-series data and to improve their robustness. We conclude that the time-series domain needs focused investigation for studying robustness of deep models by shedding light on the unique challenges. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A EXPERIMENTAL AND IMPLEMENTATION DETAILS</head><p>Datasets. We have employed the standard benchmark training, validation, and testing split on the datasets. All datasets are publicly available from the UCR repository <ref type="bibr" target="#b39">[40]</ref>. We employ the datasets in the main paper on which the classifier is able to have a performance better than random guessing. Experiments on the effectiveness of adversarial attack that aim to fool poor classifiers would not exhibit trust-worthy results, as the classifier originally is unable to predict clean data.</p><p>DNN architectures. To evaluate the DTW-AR framework, we employ two different 1D-CNN architectures -A 0 and A 1 -to create two DNNs: W B uses A 0 to evaluate the adversarial attack under a white-box setting, and is trained using clean training examples. BB uses the architecture A 1 to evaluate the black-box setting for a model trained using clean examples. The architecture details of the deep learning models are presented in Table <ref type="table" target="#tab_6">3</ref>. DTW-AR implementation. We implemented the DTW-AR framework using TensorFlow 2 <ref type="bibr" target="#b43">[44]</ref>. The parameter ρ that was introduced in Equation 5 plays an important role in the algorithm.</p><p>L label (X adv ) = max[ max y =ytarget (S y (X adv ))-S ytarget (X adv ) , ρ]</p><p>(5) ρ will push gradient descent to minimize mainly the second term (L DT W ) when the first term plateaus at ρ. Otherwise, the gradient can minimize the general loss function by pushing L label to -∞, which is counter-productive for our goal. In all our experiments, we employ ρ = -5 for L label in Equation 5 for a good confidence in the classification score. A good confidence score is important for the attack's effectiveness in a black-box setting. Black-box setting assumes that information about the target deep model including its parameters θ are not accessible. In general, the attacker will create a proxy deep model to mimic the behavior of the target model using regular queries. This technique can be more effective when a target scenario is well-defined <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b44">[45]</ref>. However, in this work, we consider the general case where we do not query the black-box target DNN classifier for a better assessment of the proposed framework. Figure <ref type="figure" target="#fig_21">20</ref> shows the role of ρ value in enhancing DTW-AR attacks in a black-box setting on ECG200 dataset noting that we see similar patterns for other datasets as well. Adversarial examples are generated using a maximum of 5 × 10 3 iterations of gradient descent with the fixed learning rate η=0.01. After all the iterations, the final adversarial output is chosen from the iteration with the lowest DTW loss provided from Equation <ref type="formula" target="#formula_7">7</ref>. L DT W (X adv , P ) =α 1 × dist P (X, X adv )</p><p>-</p><formula xml:id="formula_18">α 2 × dist P diag (X, X adv )<label>(7)</label></formula><p>Experimentally, we notice that for d(•, •) in Equation 1 of the main paper, there is no influence on the performance between choosing p = 1, 2 or ∞ for d(•, •) = • p . However, for datasets in R n×T with n ≥ 2, we do not use p = ∞ as the dimensions are not normalized and data points will be compared only along the dimension with the greater magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation of baselines.</head><p>The baseline methods for CW, PGD ,and FGS were implemented using the CleverHans library <ref type="bibr" target="#b45">[46]</ref> with updates to TensorFlow 2. For FGS and PGD algorithms, we employed a minimal perturbation factors ( &lt; 1 ) for two main reasons. First, larger perturbations significantly degrade the overall performance of the adversarial training and potentially creates adversarial signals that are semantically different than the original time-series input. Second, we want to avoid the risk of leaking label information <ref type="bibr" target="#b0">[1]</ref>. STN was implemented using the code provided with the paper <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B ADDITIONAL EXPERIMENTAL RESULTS</head><p>Discussion on kNN-DTW based classification. It has been shown previously <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b41">[42]</ref> that the Nearest-Neighbour (NN) algorithm is suitable for time-series classification using DTW measure. Nevertheless, DNN classifiers show promising results (e.g., high accuracy, ease of deployment) in their use for the time-series domain:</p><p>• While kNN-DTW can be effective in many settings, as demonstrated by the results in Table <ref type="table" target="#tab_7">4</ref>, the accuracy of kNN-DTW algorithm remains lower when compared to the deep models considered in our study on the real-world multivariate datasets used for evaluation in the main paper. To implement kNN-DTW, we consider the implementation of a regular kNN algorithm, and we use cDTW <ref type="bibr" target="#b35">[36]</ref> with its provided public python implementation (<ref type="url" target="https://wu.renjie.im/research/fastdtwis-slow/#cdtw-alone">https://wu.renjie.im/research/fastdtwis-slow/#cdtw-alone</ref> Copyright 2020 Renjie Wu and Sara Alaee) with c = 10 (This choice is based on the empirical evaluation in the cDTW paper <ref type="bibr" target="#b41">[42]</ref>).</p><p>• Using kNN-DTW (k &gt; 1) instead of 1NN-DTW is not appropriate and principled for multivariate timeseries data. By definition, DTW is an elastic similarity measure (the triangle inequality does not hold for DTW). Hence, if we have -X and X 1 are DTW-similar according to a warping path P ath 1 -X and X 3 are DTW-similar according to a warping path P ath 2 , then we cannot draw a straightforward conclusion that X 1 and X 2 are DTW-similar. Such an assumption yields a weak voting accuracy on the predicted label for high-dimensional and multivariate data. Consequently, kNN-DTW with k &gt; 1 for multivariate data can fail. Our empirical results in Table <ref type="table" target="#tab_7">4</ref> corraborate this hypothesis by showing that 1NN-DTW performs better then kNN-DTW (k &gt; 1) in most cases.</p><p>• To be able to use kNN-DTW algorithms, the training data must be stored and accessible by the end-user. This rises many concerns including -Data privacy: For applications such as healthcare and finance, the data is privileged and needs to be secured. A deployed classification model should not have direct access to the data. -Storage space and scalability: For applications such as Human Activity Recognition where the models are deployed on resource-constrained hardware platforms, the use of resources for merely storing the data is inefficient. The data cannot be stored along with the classifier.</p><p>Therefore, the use of DNNs for time-series data is wellmotivated. Hence, there is a clear need for focused investigation to study robustness of deep models for the time-series domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison of DTW-based adversarial example generation.</head><p>A different approach to create new examples that can be used for data augmentation is proposed by using resampling perturbations <ref type="bibr" target="#b41">[42]</ref>. This approach ensures a close DTW measure to the original example. However, we would like to clarify that the algorithm proposed in <ref type="bibr" target="#b41">[42]</ref> and our DTW-AR have different goals. While the method in <ref type="bibr" target="#b41">[42]</ref>   the clean time-series input DTW-wise as illustrated in Figure <ref type="figure" target="#fig_22">21</ref>.</p><p>For a fair comparison, we implemented the method proposed by <ref type="bibr" target="#b41">[42]</ref> in python as follows:</p><p>1 def add_warping(T,p): We use the method from <ref type="bibr" target="#b41">[42]</ref> to generate additional examples to be used for adversarial training. Next, we compare the accuracy of the learned predictive models from adversarial training using DTW-AR and method in <ref type="bibr" target="#b41">[42]</ref>. Table <ref type="table" target="#tab_10">5</ref> shows the results on multiple real-world time-series datasets. The accuracy is evaluated on 1) Clean examples, 2) Examples generated by the warping function provided by <ref type="bibr" target="#b41">[42]</ref>, and 3) DTW-AR adversarial examples. Table <ref type="table" target="#tab_10">5</ref> clearly show that adversarial training based on <ref type="bibr" target="#b41">[42]</ref> does not yield a robust model that can improve the performance of deep models against perturbations. Additionally, the same table explains that examples generated by method in <ref type="bibr" target="#b41">[42]</ref> cannot be considered as adversarial. We clearly observe that these examples have low effect on decreasing the models' classification accuracy performance (unlike DTW-AR based examples). Hence, we can conclude that the method in <ref type="bibr" target="#b41">[42]</ref> and DTW-AR are complementary for DTW-based data generation tasks, where <ref type="bibr" target="#b41">[42]</ref> aims for simple and trainingeffective warped examples for standard classification tasks, and DTW-AR aims for improving the robustness of deep classifiers over time-series data.</p><p>Results on the full UCR multivariate dataset. First, we provide in <ref type="bibr">Figures 22,</ref><ref type="bibr">23 and 24</ref> the experiments conducted in the main paper on the Effectiveness of adversarial attacks and the DTW-AR based adversarial training on all the UCR multivariate dataset to our DTW-AR framework is general and highly-effective for all datasets.</p><p>In Figure <ref type="figure">22</ref>, we can observe that DTW-AR performs lower (α Ef f ≤ 0.5) for some cases. We explain below how the other baseline attacks fail to outperform the proposed DTW-AR method on the same datasets. In Figure <ref type="figure" target="#fig_25">25</ref> and 26, we show results to evaluate the effectiveness of baseline attacks against the models shown in Figure <ref type="figure">22</ref>. These results show that DTW-AR is more effective in fooling DNNs created using baseline attacks-based adversarial training. For datasets where DTW-AR did not succeed in fooling the deep models with a high score, Figure <ref type="figure" target="#fig_25">25</ref> and 26 show that baselines fail to outperform our proposed DTW-AR attack. We also demonstrate in Figure <ref type="figure" target="#fig_2">24</ref> that the baselines are not suitable for time-series domain since DTW-AR based adversarial training is able to defend against these attacks.</p><p>Results and Discussion on l 1 and l ∞ . Figure <ref type="figure" target="#fig_27">27</ref> shows the MDS results of SC and Plane in the space using l 1 as a similarity measure (left) and in the space using l ∞ as a similarity measure (right). We can observe that similar to the Euclidean space, there is a substantial entanglement between different classes. Thus, using l 1 and l ∞ comes with similar drawbacks to using the Euclidean space for adversarial studies.</p><p>Figure <ref type="figure" target="#fig_28">28</ref> and 29 show the results of DTW-AR based adversarial training against adversarial attacks generated using l 1 and l ∞ as a metric.</p><p>We conclude that DTW-AR is able to generalize against attacks in other spaces than the Euclidean one. Since the Manhattan distance is similar to the Euclidean distance in the point-to-point matching, and ∞-norm describes a signal by solely its maximum value, DTW measure is still considered a better similarity measure. The empirical success of the DTW-AR suggests that the framework can be further analyzed theoretically and empirically for future research into adversarially robust classification when compared to different alternative similarity measures.</p><p>Comparison with <ref type="bibr" target="#b2">[3]</ref> on the full MV UCR dataset. Figure <ref type="figure" target="#fig_30">30</ref> shows that the observations made within the main paper are still valid over the different datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DTW-AR on non-CNN models</head><p>We want to clarify that the proposed DTW based adversarial framework is modelagnostic. The adversarial attack algorithm is based on Equations ( <ref type="formula" target="#formula_4">5</ref>) and <ref type="bibr" target="#b6">(7)</ref>. Equation <ref type="bibr" target="#b6">(7)</ref> relies on the output of the presoftmax layer of the deep model and is independent of the model's core architecture. If the main layers of the model are based on convolutional layers, recurrent layers or attention layers, our proposed algorithm (Algorithm 1 in the main paper) is the same. As both LSTM and Transformer based models are typically used for forecasting applications <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, we focus on 1D-CNNs in this work. In Tables <ref type="table" target="#tab_11">6</ref> and<ref type="table" target="#tab_12">7</ref>, we provide additional results on non-CNN models. We clearly observe that DTW-AR remains effective on non-CNN models Results on the UCR univariate datasets. To show the effectiveness of our proposed method, we additionally evaluate DTW-AR on univariate datasets from the UCR time-series benchmarks repository <ref type="bibr" target="#b39">[40]</ref>. We show the results of DTW-AR based adversarial training to predict the ground-truth labels of adversarial attacks generated by DTW-AR and the baseline attack methods on the univariate datasets in Figure <ref type="figure" target="#fig_31">32</ref>. We observe similar results as the datasets shown in the main paper. DTW-AR is successful in identifying attacks from the baseline methods by creating robust deep models. These strong results show that DTW-AR outperforms baselines for creating more effective adversarial attacks and yields to more robust DNN classifiers. We conclude that the proposed DTW-AR framework is generic, and more suitable for time-series domain to create robust deep models.          </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Proof of Corollary 1</head><p>Let P 1 and P 2 be two alignment paths such that PathSim(P 1 , P 2 ) &gt; 0. If X 1 adv and X 2 adv are the adversarial examples generated using DTW-AR from any given time-series X using paths P 1 and P 2 respectively such that DT W (X, X 1 adv ) = δ and DT W (X, X 2 adv ) = δ, then X 1 adv and X 2 adv are not necessarily the same.</p><p>Let P 1 and P 2 be two alignment paths such that PathSim(P 1 , P 2 ) &gt; 0. We want to create an adversarial example from time-series signal X using one given alignment path. When using P 1 , we will obtain X adv,1 such that DT W (X, X adv,1 ) = δ, and when using P 2 , we will obtain X adv,2 such that DT W (X, X adv,2 ) = δ.</p><p>To show that X adv,1 and X adv,2 are more likely to be different, let us suppose that given P 1 and P 2 , we always have X adv,1 = X adv,2 .</p><p>Again, to simplify notations, let us notate X adv,1 by Z and X adv,2 by Z for this proof. As we have DT W (X, Z) = DT W (X, Z ) = δ, then (i,j)∈P1 d(X i , Z j ) = (i,j)∈P2 d(X i , Z j ). If we suppose that by construction Z is always equal to Z , this means that for Z = Z , the statement (i,j)∈P1 d(X i , Z j ) = (i,j)∈P2 d(X i , Z j ) does not hold. The last claim is clearly incorrect. Let us suppose that Z is pre-defined and we assume Z = Z . Let the ensemble of indices {k} refer to the indices where Z k = Z k . This means that we have k -1 degrees of freedom to modify Z k to fix the equality (i,j)∈P1 d(X i , Z j ) = (i,j)∈P2 d(X i , Z j )). Therefore, considering PathSim(P 1 , P 2 ) &gt; 0, we can construct X adv,1 = X adv,2 such that DT W (X, X adv,1 ) = δ and DT W (X, X adv,2 ). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Illustration of DTW alignment between two uni-variate signals X and Z of length 4. The optimal alignment path (shown in green color) is P = {(1, 1), (2, 1), (3, 2), (4, 2), (4, 3), (4, 4)}.</figDesc><graphic coords="2,330.90,325.68,214.20,127.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 . 3 . 1 Fig. 3 .</head><label>2313</label><figDesc>Fig. 2. Overview of the DTW-AR framework to create targeted adversarial examples. Given an input X, a target class-label ytarget and a distance bound δ, DTW-AR aims to identify an adversarial example X adv using a random alignment path P rand . DTW-AR solves an optimization problem involving a DTW-similarity loss and a classification loss using a random alignment path P rand and a DNN classifier F θ . Using different random alignment paths, DTW-AR will be able to create diverse adversarial examples which meet the DTW measure bound δ.</figDesc><graphic coords="3,48.00,43.70,515.96,150.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Multi-dimensional scaling results showing the labeled data distribution in Euclidean space (left column) and DTW space (right column) for the SC dataset. DTW space exhibits better clustering for same-class data than Euclidean space.</figDesc><graphic coords="3,312.00,536.69,120.95,74.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Visualization of PathSim values along different example alignment paths in R n×10 (First row) and R n×100 (Second row) spaces.</figDesc><graphic coords="7,60.90,148.30,98.04,91.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. (a) Example of the convergence of the optimal alignment path between the adversarial example and the original example at the start of the algorithm (dotted red path) and at the end (red path) to the given random alignment path (blue path). (b) PathSim score of the optimal alignment path between the adversarial example and the original example and the given random path for the ECG200 dataset averaged over multiple random alignment paths.</figDesc><graphic coords="7,59.86,285.20,108.36,106.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Configuration of algorithms. We employ a 1D-CNN architecture for the target DNNs. We operate under a white-box (WB) setting for creating adversarial examples to fool W B model. To assess the effectiveness of attacks, we evaluate the attacks under the black-box (BB) setting and to fool BB model. Neural architectures of both W B and BB models are in the Appendix. The adversarial algorithm has no prior knowledge/querying ability of target DNN classifiers. Target DNNs include: 1) DNN model with a different architecture trained on clean data (BB); 2) DNNs trained using augmented data from baselines attacks that are not specific to image domain: Fast Gradient Sign method (F GS) [38], Carlini &amp; Wagner (CW ) attack [18], and Projected Gradient Descent (P GD) [1]; and 3) DNN models trained using stability training [31] (ST N ) for learning robust classifiers. Evaluation metrics. We evaluate attacks using the efficiency metric α Ef f ∈ [0, 1] over the created adversarial examples. α Ef f (higher means better attacks) measures the capability of adversarial examples to fool a given DNN F θ to output the target class-label. α Ef f is calculated as the fraction of adversarial examples that are predicted correctly by the classifier: α Ef f = # Adv. examples s.t.F (X)==ytarget # Adv. examples . We evaluate adversarial training by measuring the accuracy of the model to predict ground-truth labels of adversarial examples. A DNN classifier is robust if it is successful in predicting the true label of any given adversarial example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Effect of alignment path on adversarial example.</figDesc><graphic coords="8,412.80,395.34,151.19,66.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Results for the effectiveness of adversarial examples from DTW-AR on different DNNs under white-box (WB) and black-box (BB) settings, and using adversarial training baselines (PGD, FGS, CW and STN) on different datasets.</figDesc><graphic coords="9,116.04,645.97,115.90,56.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .Fig. 11 .</head><label>1011</label><figDesc>Fig. 10. The progress of loss function values over the first 100 iterations of DTW-AR on different examples from ATRIALFIBRILLATION datasets. We observe that empirically, the Equation plateaus at ρ before minimizing L DT W .</figDesc><graphic coords="9,362.40,43.70,151.20,98.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Results of adversarial training using baseline attacks and DTW-AR, and comparison with standard training without adversarial examples (No Attack) to classify clean data.</figDesc><graphic coords="10,116.04,580.16,115.91,50.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 13 .</head><label>13</label><figDesc>Fig. 13. Results of DTW-AR based adversarial training to predict the true labels of adversarial examples generated by DTW-AR and the baseline attack methods. The adversarial examples considered are those which successfully fooled DNNs that do not use adversarial training.</figDesc><graphic coords="10,380.04,167.15,115.91,61.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>•</head><label></label><figDesc>For a given time-series signal, CW-SDTW will output one single adversarial example and cannot uncover multiple adversarial examples which meet the DTW measure bound. However, DTW-AR algorithm gives the user control over the alignment path and can create multiple diverse adversarial examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 15 Fig. 14 .</head><label>1514</label><figDesc>Fig. 14. Results of DTW-AR based adversarial training to predict the true labels of adversarial examples generated by DTW-AR and the baseline attack methods. The adversarial examples considered are those that successfully fooled DNNs that do not use adversarial training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 15 .</head><label>15</label><figDesc>Fig. 15. Results for the effectiveness of adversarial examples from DTW-AR against adversarial training using examples created by CW-SDTW on different datasets.</figDesc><graphic coords="11,184.08,105.46,115.91,61.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 16 .</head><label>16</label><figDesc>Fig. 16. Results for the effectiveness of adversarial training using DTW-AR based examples against adversarial attacks from CW-SDTW on different datasets.</figDesc><graphic coords="11,337.20,273.89,201.59,86.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 17 .</head><label>17</label><figDesc>Fig. 17. Results of the success rate of deep model from DTW-AR based adversarial training to predict the true label of adversarial attacks generated using method in [3].</figDesc><graphic coords="11,337.20,577.34,201.59,86.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 18 .</head><label>18</label><figDesc>Fig. 18. Average runtime per iteration for standard DTW, FastDTW, cDTW, and DTW-AR (on NVIDIA Titan Xp GPU).</figDesc><graphic coords="12,116.04,146.32,115.92,51.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 19 .</head><label>19</label><figDesc>Fig. 19. Results for the effectiveness of adversarial examples from DTW-AR using DTWAdaptive [16] (DTW D top row, DTW I bottom row) on different DNNs under different settings.</figDesc><graphic coords="12,312.00,311.85,115.92,56.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>•</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 9 Figure 18</head><label>918</label><figDesc>Figure 9 shows that adversarial examples created by DTW-AR have higher potential to break time-series DNN classifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Taha</head><label></label><figDesc>Belkhouja (S'19) is a PhD Candidate in Computer Science at Washington State University, USA. His general research interest include robust and trustworthy machine learning for safe deployment in real-world applications. His current research focuses on robustness of machine learning models for time-series domain and theoretically sound uncertainty quantification. He won a Outstanding Teaching Assistant Award from the College of Engineering, Washington State University. Yan Yan (Senior Member from 2022) is an Assistant Professor of Computer Science at Washington State University, USA. He received his PhD in information systems from the University of Technology Sydney. His current research interest includes developing robust machine learning systems and developing sample-efficient learning algorithms. He has published papers in toptier conferences including NeurIPS, AAAI, IJCAI, ICCV, CVPR, and ECCV. Janardhan Rao Doppa (Senior Member, IEEE) is the Huie-Rogers Endowed Chair Associate Professor at Washington State University. He received his PhD in computer science from Oregon State University. His research interests include both foundations of machine learning and applications to real-world problems. He won NSF CAREER award, Outstanding Paper Award from AAAI conference (2013), Best Paper Award from ACM Transactions on Design Automation of Electronic Systems (2021), IJCAI Early Career Award (2021), Best Paper Award from Embedded Systems Week Conference (2022), Outstanding Junior Faculty in Research Award (2020) and Reid-Miller Teaching Excellence Award (2018) from the College of Engineering, Washington State University.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 20 .</head><label>20</label><figDesc>Fig. 20. Results for the fooling rate on ECG200 dataset w.r.t different ρ values for a black-box attack setting.</figDesc><graphic coords="15,337.20,43.70,201.59,105.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 21 .</head><label>21</label><figDesc>Fig. 21. DTW-AR adversarial examples from Epilepsy dataset using pre-defined warping path from user.</figDesc><graphic coords="16,337.20,193.05,201.60,149.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>3 i</head><label>3</label><figDesc>= numpy.arange(len_T) 4 numpy.random.shuffle(i) 5 i = sorted(i[:-int(np.floor(len_T * p))]) 6 warped_T = scipy.signal.savgol_filter(scipy. signal.resample(T[i], len_T),1,0) 7 return warped_T</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 22 .Fig. 23 .Fig. 24 .</head><label>222324</label><figDesc>Fig. 22. Results for the effectiveness of adversarial examples from DTW-AR on different DNNs under white-box (WB) and black-box (BB) settings, and using adversarial training baselines (PGD, FGS, CW and STN) on all the UCR multivariate datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 25 .</head><label>25</label><figDesc>Fig. 25. Results for the effectiveness of adversarial examples from CW on different deep models using adversarial training baselines (PGD, FGS, CW).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 26 .</head><label>26</label><figDesc>Fig. 26. Results for the effectiveness of adversarial examples from PGD and FGS on different deep models using adversarial training baselines (PGD, FGS, CW).</figDesc><graphic coords="19,166.44,355.10,118.44,74.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 27 .</head><label>27</label><figDesc>Fig. 27. Multi-dimensional scaling results showing the labeled data distribution in spaces using l 1 as a similarity measure (left column) and l∞ (right column) for two datasets: SC (top row) and Plane (bottom row).</figDesc><graphic coords="19,166.44,429.71,118.44,74.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig. 28 .</head><label>28</label><figDesc>Fig. 28. Results for the effectiveness of adversarial examples from DTW-AR on different deep models using adversarial training baselines (PGD, FGS, CW) with l 1 -norm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Fig. 29 .</head><label>29</label><figDesc>Fig. 29. Results for the effectiveness of adversarial examples from DTW-AR on different deep models using adversarial training baselines (PGD, FGS, CW) with l∞-norm.</figDesc><graphic coords="20,312.00,364.91,115.92,54.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Fig. 30 .</head><label>30</label><figDesc>Fig. 30. Results of the success rate of DTW-AR adversarial trained model to predict the true label of adversarial attack generated from [3].</figDesc><graphic coords="20,48.00,364.91,251.99,117.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Fig. 32 .</head><label>32</label><figDesc>Fig. 32. Results of DTW-AR based adversarial training to predict the true labels of adversarial examples generated by DTW-AR and the baseline attack methods on the Univariate dataset. The adversarial examples considered are those that successfully fooled DNNs that do not use adversarial training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Euclidean distance) between two timeseries signals is not always the optimal alignment. Hence, the existence of adversarial examples which are similar based on DTW and may not be similar based on the Euclidean distance. To formalize this intuition, we provide Observation 1. We characterize the effectiveness of DTW-AR based attack as better for their ability to extend the space of attacks based on the Euclidean distance and their potential to fool DNN classifiers that rely on Euclidean distance for adversarial training. Our experimental results demonstrate that DTW-AR generates effective adversarial examples to fool the target DNN classifiers by leveraging the appropriate bias of DTW for time-series data.</figDesc><table /><note><p>Theoretical justification. We prove that the DTW measure allows DTW-AR to explore a larger space of candidate adversarial examples when compared to perturbations based on the Euclidean distance, i.e., identifies blind spots of prior methods. This result is based on the fact that the point-to-point alignment (i.e.,</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>how the data from different class labels are better clustered in the DTW space compared to the Euclidean space. These results demonstrate that DTW suits better the time-series domain as generated adversarial examples lack true-label guarantees. Moreover, Euclidean distance based attacks can potentially create adversarial examples that are inconsistent for adversarial training. Our analysis showed that for datasets such as WISDM, there are time-series signals from different classes with l 2 -distances ≤ 2, while PGD or FGS require ≥ 2 to create successful adversarial examples for more than 70% time-series instances. We provide in the Appendix an additional visualization of the adversarial examples using DTW.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 2</head><label>2</label><figDesc>Average percentage of dissimilar adversarial examples created by DTW-AR using stochastic alignment paths for a given time-series. The threshold sim determines whether two adversarial examples are dissimilar or not based on l 2 and DTW measures.</figDesc><table><row><cell></cell><cell cols="3">sim l 2 norm</cell><cell></cell><cell>sim DTW</cell><cell></cell></row><row><cell></cell><cell>0.01</cell><cell>0.05</cell><cell>0.1</cell><cell>0.01</cell><cell>0.05</cell><cell>0.1</cell></row><row><cell>Atrial Fibrillation</cell><cell>98%</cell><cell>90%</cell><cell>87%</cell><cell>100%</cell><cell>100%</cell><cell>98%</cell></row><row><cell>Epilepsy</cell><cell>99%</cell><cell>96%</cell><cell>93%</cell><cell>100%</cell><cell>100%</cell><cell>97%</cell></row><row><cell>ERing</cell><cell>99%</cell><cell>95%</cell><cell>93%</cell><cell>100%</cell><cell>100%</cell><cell>98%</cell></row><row><cell>Heartbeat</cell><cell>99%</cell><cell>94%</cell><cell>92%</cell><cell>100%</cell><cell>99%</cell><cell>98%</cell></row><row><cell>RacketSports</cell><cell>99%</cell><cell>94%</cell><cell>92%</cell><cell>100%</cell><cell>100%</cell><cell>96%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 3</head><label>3</label><figDesc>Details of DNN architectures. C: Convolutional layers, K: kernel size, P: max-pooling kernel size, and R: rectified linear layer.</figDesc><table><row><cell></cell><cell>C</cell><cell>K</cell><cell>C</cell><cell>K</cell><cell>P</cell><cell>R</cell><cell>R</cell></row><row><cell>A 0</cell><cell>x</cell><cell>x</cell><cell cols="4">66 12 12 1024</cell><cell>x</cell></row><row><cell>A 1</cell><cell>100</cell><cell>5</cell><cell>50</cell><cell>5</cell><cell>4</cell><cell>200</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 4</head><label>4</label><figDesc>Accuracy (%) of kNN-DTW classifier vs. 1D-CNN classifier task on the clean multivariate time-series data.</figDesc><table><row><cell></cell><cell>Atrial Fibrillation</cell><cell>Epilepsy</cell><cell>ERing</cell><cell>Heartbeat</cell><cell>RacketSports</cell></row><row><cell>1NN-DTW</cell><cell>38</cell><cell>56</cell><cell>85</cell><cell>63</cell><cell>75</cell></row><row><cell>5NN-DTW</cell><cell>13</cell><cell>40</cell><cell>86</cell><cell>67</cell><cell>70</cell></row><row><cell>10NN-DTW</cell><cell>36</cell><cell>32</cell><cell>75</cell><cell>68</cell><cell>65</cell></row><row><cell>1D-CNN</cell><cell>40</cell><cell>95</cell><cell>94</cell><cell>70</cell><cell>86</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>aims for simple and effective DTW-based data augmentation, these examples cannot be considered as adversarial. Additionally, it does not provide control to the user over the warping path. Using DTW-AR and the tightness guarantees provided in Section 3.3, the user can generate several warped examples with full control over the warped timesteps. Finally, using Equation (5), the generated example is adversarial by definition. As a result, we obtain adversarial examples that remain close to</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>using the efficiency metric α Ef f ∈ [0, 1] over the created adversarial examples. α Ef f = # Adv. examples s.t.F (X)==ytarget # Adv. examples (higher means better attacks) was introduced in the paper to measure the capability of adversarial examples to fool a given DNN F θ to output the true class-label. Therefore, DTW-AR generalizes over any given deep model. Furthermore, we note that all our assumptions and claims made in the paper are not based specifically on CNN models, but are general to any DNN classifier F θ . Finally, we note that LSTM-based models are slower in execution than CNN models and Transformer-based models are too complex for classification tasks whereas CNNs perform similarly with less computational resources. As explained in Section 3, one main advantage of DTW-AR is reducing the time complexity of using DTW to create adversarial examples. We provide in Figure 31 a comparison of the average runtime per iteration to create one targeted adversarial example by iterative baseline methods. We note that we only compare to CW because FGSM and PGD are not considered targeted attacks, and Karim et al. [3], fails to create adversarial examples for every input. While we observe that CW is faster, we note that we have already demonstrated empirically (Figure 22 and 25) that DTW-AR always outperforms CW in both effectiveness of adversarial examples and adversarial training. We also observe differences in the DTW-AR's runtime across datasets. DTW-AR is relatively quick for small-size data such as RacketSports (30 × 6) and slower for large-size data such as HeartBeat (405 × 61). The additional runtime cost is explained by the proposed loss function in Equation 7 that guarantees a highlysimilar adversarial example. For future work, we aim to optimize the implementation of DTW-AR to further reduce the runtime on large time-series datasets.</figDesc><table><row><cell>Runtime comparison of DTW-AR vs. Carlini &amp; Wagner.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 5</head><label>5</label><figDesc>Accuracy (%) of method in<ref type="bibr" target="#b41">[42]</ref> and DTW-AR based adversarial training on testing examples from different datasets.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Atrial Fibrillation</cell><cell></cell><cell>Epilepsy</cell><cell></cell><cell></cell><cell>ERing</cell><cell></cell></row><row><cell></cell><cell>Clean Exp.</cell><cell>[42] Exp.</cell><cell>DTW-AR Exp.</cell><cell>Clean Exp.</cell><cell>[42] Exp.</cell><cell>DTW-AR Exp.</cell><cell>Clean Exp.</cell><cell>[42] Exp.</cell><cell>DTW-AR Exp.</cell></row><row><cell>[42] Adv. training</cell><cell>42</cell><cell>42</cell><cell>29</cell><cell>90</cell><cell>90</cell><cell>26</cell><cell>90</cell><cell>89</cell><cell>43</cell></row><row><cell>DTW-AR Adv. training</cell><cell>42</cell><cell>38</cell><cell>82</cell><cell>98</cell><cell>93</cell><cell>96</cell><cell>96</cell><cell>90</cell><cell>99</cell></row><row><cell></cell><cell></cell><cell>Heartbeat</cell><cell></cell><cell></cell><cell cols="2">RacketSports</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Clean Exp.</cell><cell>[42] Exp.</cell><cell>DTW-AR Exp.</cell><cell>Clean Exp.</cell><cell>[42] Exp.</cell><cell>DTW-AR Exp.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>[42] Adv. training</cell><cell>70</cell><cell>68</cell><cell>20</cell><cell>86</cell><cell>83</cell><cell>52</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DTW-AR Adv. training</cell><cell>75</cell><cell>72</cell><cell>96</cell><cell>86</cell><cell>80</cell><cell>92</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>TABLE 6</head><label>6</label><figDesc>Results for the effectiveness α Ef f of adversarial examples from DTW-AR using LSTM-based deep neural network in a black-box (BB) setting.</figDesc><table><row><cell></cell><cell>Clean Test Accuracy</cell><cell></cell><cell>α Ef f</cell><cell></cell></row><row><cell>Dataset</cell><cell>Standard</cell><cell>Standard</cell><cell>PGD Adv. Trn.</cell><cell>FGS Adv. Trn.</cell></row><row><cell>Atrial Fibrillation</cell><cell>0.26</cell><cell>0.97</cell><cell>0.93</cell><cell>0.95</cell></row><row><cell>Epilepsy</cell><cell>0.61</cell><cell>0.89</cell><cell>0.75</cell><cell>0.75</cell></row><row><cell>ERing</cell><cell>0.74</cell><cell>0.98</cell><cell>0.91</cell><cell>0.91</cell></row><row><cell>Heartbeat</cell><cell>0.73</cell><cell>0.65</cell><cell>0.55</cell><cell>0.54</cell></row><row><cell>RacketSports</cell><cell>0.86</cell><cell>0.91</cell><cell>0.85</cell><cell>0.85</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 7</head><label>7</label><figDesc>Results for the effectiveness α Ef f of adversarial examples from DTW-AR using Transformer-based deep neural network in a black-box (BB) setting.</figDesc><table><row><cell></cell><cell>Clean Test Accuracy</cell><cell></cell><cell>α Ef f</cell><cell></cell></row><row><cell>Dataset</cell><cell>Standard</cell><cell>Standard</cell><cell>PGD Adv. Trn.</cell><cell>FGS Adv. Trn.</cell></row><row><cell>Atrial Fibrillation</cell><cell>0.22</cell><cell>0.95</cell><cell>0.95</cell><cell>0.95</cell></row><row><cell>Epilepsy</cell><cell>0.61</cell><cell>0.85</cell><cell>0.65</cell><cell>0.64</cell></row><row><cell>ERing</cell><cell>0.38</cell><cell>0.73</cell><cell>0.69</cell><cell>0.65</cell></row><row><cell>Heartbeat</cell><cell>0.71</cell><cell>0.91</cell><cell>0.85</cell><cell>0.85</cell></row><row><cell>RacketSports</cell><cell>0.66</cell><cell>0.73</cell><cell>0.66</cell><cell>0.65</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C THEORETICAL PROOFS C.1 Proof of Observation 1</head><p>Let l 2 be the equivalent of Euclidean distance using the cost matrix in the DTW space. ∀X ∈ R n×T , there exists ∈ R n×T and an alignment path P such that dist P (X, X + ) ≤ δ and l 2 (X, X + ) &gt; δ.</p><p>The existence of is guaranteed as follows: We know from the nature of the DTW algorithm and the alignment paths that for two time-series signals X and X , the optimal alignment path is not always the diagonal path. If does not exist, it means that for all signals X that are different from X, the diagonal path is an optimal alignment path, which is absurd. Thus, = X -X and it always exists for any time-series signal .</p><p>Let P diag be the diagonal alignment path in the cost matrix C. For X ∈ R n×T , let ∈ R n×T such that the optimal alignment path P * between X and X + is different than</p><p>Let us suppose that there is no alignment path P between X and X + such that dist P (X, X + ) ≤ δ and l 2 (X, X + ) &gt; δ. The last statement is equivalent to: dist P (X, X + ) &lt; dist P diag (X, X + ). Since we assumed that there is no alignment path P that satisfies this statement, this implies:</p><p>Therefore, from the definition of DT W (•, •) as a min operation during backtracing of the DP process, we get:</p><p>Hence, P diag = P * , which contradicts our main assumption in constructing such that P diag = P * .</p><p>Therefore, we conclude that:</p><p>∃P s.t. dist P (X, X + ) ≤ δ and l 2 (X, X + ) &gt; δ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Proof of Theorem 1</head><p>For a given input space R n×T , a constrained DTW space for adversarial examples is a strict superset of a constrained euclidean space for adversarial examples. If X ∈ R n×T :</p><p>We want to prove that a constrained DTW space allows more candidates adversarial examples than a constrained Euclidean space. Let X ∈ R n×T be an input time-series and X adv denote a candidate adversarial example generated from X. In the DTW-space, this requires that DT W (X, X adv ) ≤ δ. In the Euclidean space, this requires that X -X adv</p><p>Suppose A be the space of all candidate adversarial examples in DTW space X adv /DT W (X, X adv ) ≤ δ and B be the space of all candidate adversarial examples in Euclidean space X adv X -X adv 2 2 ≤ δ . To prove A B, we need to prove:</p><p>For the optimal alignment path P * between X and X adv , if:</p><p>Statement 2: Let X adv ∈ A such that P * = P diag . Consequently, according to Observation 1, dist P diag (X, X + ) &gt; DT W (X, X + ).</p><p>⇒ dist P diag (X, X + ) &gt; δ.</p><p>As the diagonal path corresponds to the Euclidean distance, we conclude that X adv / ∈ B. Hence, ∃X adv /X adv ∈ A and X adv / ∈ B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Proof of Observation 2</head><p>Given any alignment path P and two multivariate time-series signals X, Z ∈ R n×T . If we have dist P (X, Z) ≤ δ, then DT W (X, Z) ≤ δ.</p><p>Let P any given alignment path and P * be the optimal alignment path used for DTW measure along with the DTW cost matrix C. Let us suppose that dist P (X, Z) &gt; DT W (X, Z).</p><p>We denote</p><p>Let us denote by k the index at which, P and P * are not using the same cells anymore, and by l, the index where P and P * meet again using the same cells until (T, T ) in a continuous way. By definition, k &gt; 1 and l &lt; min(len(P ), len(P * )). For example, if P ={(1, 1), (1, 2), (2, 2), <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b2">3)</ref>, <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b3">4)</ref>, <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b4">5)</ref>, <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b4">5)</ref>} and P * ={(1, 1), (1, 2), (2, 3), <ref type="bibr" target="#b2">(3,</ref><ref type="bibr" target="#b3">4)</ref>, <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b3">4)</ref>, <ref type="bibr" target="#b4">(5,</ref><ref type="bibr" target="#b4">5)</ref>}, then k=3 and l=6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>If k=l, then P =P * . Therefore, dist P (X, Z) &gt; DT W (X, Z) is absurd.</p><p>• If k = l: To provide the (k + 1) th element of P * , we have</p><p>To provide the (k + 1) th element of P , we have</p><p>Using the definition of the optimal alignment path provided in Equation 1, we have</p><p>If we suppose that the remaining elements of P would lead to dist P (X, Z) &lt; dist P * (X, Z), then this would lead to C T,T &lt; DT W (X, Z), which contradicts the definition of DTW. Hence, we have dist P (X, Z) ≤ dist P * (X, Z) implying that dist P (X, Z) &gt; DT W (X, Z) is absurd.</p><p>Therefore, if we upper-bound dist P (X, Z) by δ for any given P , then we guarantee that DT W (X, Z) ≤ δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Proof of Theorem 2</head><p>For a given input space R n×T and a random alignment path P rand , the resulting adversarial example X adv from the minimization over dist P rand (X, X adv ) is equivalent to minimizing over DT W (X, X adv ). For any X adv generated by DTW-AR using P rand , we have:</p><p>where P DT W is the optimal alignment path found using DTW computation between X and X adv . Let P rand be the random alignment path over which the algorithm would minimize dist P rand (X, X adv ). For the ease of notation, within this proof, we will refer to X adv by X .</p><p>We have dist P rand (X, X ) = (i,j)∈P rand d(X i , X j ). As ∀i, j, d(X i , X j ) ≥ 0, then minimizing dist P rand (X, X ) translates to minimizing each d(X i , X j ).</p><p>Let us denote min d(X i , X j ) by d min (X i , X j ), then min dist P rand (X, X ) = (i,j)∈P rand d min (X i , X j ).</p><p>Using the back-tracing approach of DTW to define the optimal alignment path, we want to verify if PathSim(P rand , P DT W ) = 0. Let P rand be the sequence of cells {c k,l } and P DT W be the sequence {c k ,l }. Every cell {c k ,l } in P DT W is defined to be the successor of one of the cells {c k -1,l }, {c k ,l -1 }, {c k -1,l -1 } which will make the distance sum along P DT W until the cell {c k ,l } be the minimum distance. As we have minimized the distance over the path P rand to be d min (X i , X j ), the cells of P DT W and P rand will overlap. This is due to the recursive nature of DTW computation and the fact that the last cells in both sequences P DT W and P rand is the same (by the definition of DTW alignment algorithm).</p><p>Hence, ∀(k, l) ∈ P rand , (k , l ) ∈ P DT W , we have k = k and l = l .</p><p>Therefore, the optimal alignment between between X and X adv will overlap with P rand and we obtain PathSim(P rand , P DT W ) = 0.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adversarial attacks on deep neural networks for time series classification</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Fawaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Forestier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Idoumghar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-07-14">2019. July 14-19, 2019. 2019</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adversarial attacks on time series</title>
		<author>
			<persName><forename type="first">F</forename><surname>Karim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Darabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adversarial sample crafting for time series classification with elastic similarity measures</title>
		<author>
			<persName><forename type="first">I</forename><surname>Oregi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lozano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Distributed Computing XII, 12th International Symposium on Intelligent Distributed Computing, IDC 2018</title>
		<meeting><address><addrLine>Bilbao, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-10-17">15-17 October 2018. 2018</date>
			<biblScope unit="volume">798</biblScope>
			<biblScope unit="page" from="26" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analyzing deep learning for timeseries data through adversarial lens in mobile and iot applications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Belkhouja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Doppa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput. Aided Des. Integr. Circuits Syst</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3190" to="3201" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-time human activity recognition from accelerometer data using convolutional neural networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ignatov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="915" to="922" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep learning for financial applications : A survey</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Özbayoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Gudelek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">B</forename><surname>Sezer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Soft Comput</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page">106384</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Wide and deep convolutional neural networks for electricity-theft detection to secure smart grids</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-N</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tutorial adversarial robustness: Theory and practice</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep adversarial learning for NLP</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Sarkar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Strube</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02">June 2, 2019. 2019</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamic-programming approach to continuous speech recognition</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the International Congress of Acoustics</title>
		<meeting>the International Congress of Acoustics<address><addrLine>Budapest</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1971">1971. 1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Information retrieval for music and motion</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Üller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
	<note>Dynamic time warping</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using dynamic time warping to find patterns in time series</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD workshop</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human activity recognition with smartphone and wearable sensors using deep learning techniques: A review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ramanujam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Perumal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Padmavathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sensors Journal</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning sleep stages from radio signals: A conditional adversarial architecture</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Katabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Bianchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generalizing dtw to the multi-dimensional case requires an adaptive approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shokoohi-Yekta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Data visualization with multidimensional scaling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Swayne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and graphical statistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="444" to="472" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Symposium on Security and Privacy</title>
		<meeting><address><addrLine>San Jose, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017">May 22-26, 2017. 2017</date>
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page" from="39" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Soft-dtw: a differentiable loss function for time-series</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="894" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Functional adversarial attacks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (Neur&apos;IPS)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Universal adversarial training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shafahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Najibi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Metric axioms and distance</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Cullinane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Mathematical Gazette</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="414" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decision-based adversarial attacks: Reliable attacks against black-box machine learning models</title>
		<author>
			<persName><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Universal adversarial perturbations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-07-21">2017. July 21-26, 2017. 2017</date>
			<biblScope unit="page" from="86" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Functional adversarial attacks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (Neur&apos;IPS)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">418</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Spatially transformed adversarial examples</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the limitation of convolutional neural networks in recognizing negative images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Poovendran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th International Conference on Machine Learning and Applications (ICMLA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Towards crafting text adversarial samples</title>
		<author>
			<persName><forename type="first">S</forename><surname>Samanta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.02812</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Black-box generation of adversarial text sequences to evade deep learning classifiers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Soffa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Security and Privacy Workshops (SPW)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="50" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">On adaptive attacks to adversarial example defenses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08347</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improving the robustness of deep neural networks via stability training</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016-06-27">2016. June 27-30, 2016. 2016</date>
			<biblScope unit="page" from="4480" to="4488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples</title>
		<author>
			<persName><forename type="first">A</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ser. Proceedings of Machine Learning Research</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Dy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Krause</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="274" to="283" />
			<date type="published" when="2018-07-15">10-15 Jul 2018</date>
			<publisher>PMLR</publisher>
			<pubPlace>Stockholm Sweden</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Distillation as a defense to adversarial perturbations against deep neural networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="582" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ensemble adversarial training: Attacks and defenses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s">Conference Track Proceedings. OpenReview.net</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adversarial framework with certified robustness for time-series domain via statistical features</title>
		<author>
			<persName><forename type="first">T</forename><surname>Belkhouja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Doppa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research (JAIR)</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="1435" to="1471" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Reliable machine learning for wearable activity monitoring: Novel algorithms and theoretical guarantees</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Belkhouja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Doppa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 41st International Conference on Computer-Aided Design (ICCAD)</title>
		<meeting>41st International Conference on Computer-Aided Design (ICCAD)</meeting>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Training robust deep models for time-series domain: Novel algorithms and theoretical analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Belkhouja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Doppa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="6055" to="6063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adversarial examples in the physical world</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24">2017. April 24-26, 2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Grail: Efficient time-series representation learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Paparrizos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endowment</title>
		<meeting>VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The UEA &amp; UCR time series classification rep</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bagnall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Vickers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>www.timeseriesclassification.com</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Toward accurate dynamic time warping in linear time and space</title>
		<author>
			<persName><forename type="first">S</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Data Analalysis</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Optimizing dynamic time warping&apos;s window width for time series data mining applications</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Dau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petitjean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Forestier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bagnall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Fastdtw is approximate and generally slower than the algorithm it approximates</title>
		<author>
			<persName><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2003.11246" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/" />
	</analytic>
	<monogr>
		<title level="m">2015, software available from tensorflow.org</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against machine learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">B</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Asia Conference on Computer and Communications Security (ASIACCS)</title>
		<meeting>Asia Conference on Computer and Communications Security (ASIACCS)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Technical report on the cleverhans v2.1.0 adversarial examples library</title>
		<author>
			<persName><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.00768</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
