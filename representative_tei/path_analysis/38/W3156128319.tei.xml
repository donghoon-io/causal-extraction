<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph</title>
				<funder ref="#_Mw3RV2G">
					<orgName type="full">Institute for Guo Qiang, Tsinghua University</orgName>
				</funder>
				<funder ref="#_Z2f8Swd">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_sEcQCyU">
					<orgName type="full">NSFC Key Project</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Jiaxin</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">BNRist</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Cloud BU</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shulin</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">BNRist</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lei</forename><surname>Hou</surname></persName>
							<email>houlei@</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">BNRist</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Juanzi</forename><surname>Li</surname></persName>
							<email>lijuanzi@tsinghua.edu</email>
						</author>
						<author>
							<persName><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
							<email>hanwangzhang@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit1">BNRist</orgName>
								<orgName type="institution" key="instit2">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T01:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Relation Graph</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-hop Question Answering (QA) is a challenging task because it requires precise reasoning with entity relations at every step towards the answer. The relations can be represented in terms of labels in knowledge graph (e.g., spouse) or text in text corpus (e.g., they have been married for 26 years). Existing models usually infer the answer by predicting the sequential relation path or aggregating the hidden graph features. The former is hard to optimize, and the latter lacks interpretability. In this paper, we propose Trans-ferNet, an effective and transparent model for multi-hop QA, which supports both label and text relations in a unified framework. Trans-ferNet jumps across entities at multiple steps. At each step, it attends to different parts of the question, computes activated scores for relations, and then transfer the previous entity scores along activated relations in a differentiable way. We carry out extensive experiments on three datasets and demonstrate that TransferNet surpasses the state-of-the-art models by a large margin. In particular, on MetaQA, it achieves 100% accuracy in 2-hop and 3-hop questions. By qualitative analysis, we show that TransferNet has transparent and interpretable intermediate results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question answering (QA) plays a central role in artificial intelligence. It requires machines to understand the free-form questions and infer the answers by analyzing information from a large corpus <ref type="bibr" target="#b21">(Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b13">Joshi et al., 2017;</ref><ref type="bibr" target="#b16">Chen et al., 2017)</ref> or structured knowledge base <ref type="bibr" target="#b2">(Bordes et al., 2015;</ref><ref type="bibr" target="#b32">Yih et al., 2015;</ref><ref type="bibr" target="#b12">Jiang et al., 2019)</ref>. Along with the fast development of deep learning, especially the pretraining technology <ref type="bibr" target="#b7">(Devlin et al., 2018;</ref><ref type="bibr" target="#b15">Lan et al., 2019)</ref>, state-of-the-art models have been shown comparative with human per-Figure <ref type="figure">1</ref>: Answering a multi-hop question over the relation graph. The relations are constrained predicates in the label form (i.e., knowledge graph) while free texts in the text form. The reasoning process has been marked in the graph, where the correspondence between relations and question words has been highlighted in the same color.</p><p>formance on simple questions that only need a single hop <ref type="bibr" target="#b19">(Petrochuk and Zettlemoyer, 2018;</ref><ref type="bibr" target="#b35">Zhang et al., 2020)</ref>, e.g., Who is the CEO of Microsoft Corporation. However, multi-hop QA, which requires reasoning with the entity relations at multiple steps, is far from resolved <ref type="bibr" target="#b31">(Yang et al., 2018;</ref><ref type="bibr" target="#b9">Dua et al., 2019;</ref><ref type="bibr" target="#b34">Zhang et al., 2017;</ref><ref type="bibr" target="#b26">Talmor and Berant, 2018)</ref>.</p><p>In this paper, we focus on multi-hop QA based on relation graphs, which consists of entities and their relations. As shown in Figure <ref type="figure">1</ref>, the relations can be represented by two forms:</p><p>• Label form, also known as knowledge graph (e.g., Freebase <ref type="bibr" target="#b1">(Bollacker et al., 2008)</ref>, Wikidata <ref type="bibr" target="#b29">(Vrandečić and Krötzsch, 2014)</ref>), whose relations are manually-defined constrained predicates (e.g., Spouse, CEO).</p><p>• Text form, whose relations are free texts retrieved from textual corpus. We can easily build the graph by extracting the co-occuring sentences of two entities. Since the label form is expensive and usually incomplete, the text form is more economical and practical.</p><p>In this paper, we aim to tackle multi-hop questions over these two different forms in a unified framework.</p><p>Existing methods for multi-hop QA have two main strands. The first is to predict the sequential relation path in a weakly supervised setting <ref type="bibr" target="#b34">(Zhang et al., 2017;</ref><ref type="bibr" target="#b20">Qiu et al., 2020)</ref>, that is, to learn the intermediate path only based on the final answer. These works suffer from the convergence issues due to the huge search space, which heavily hinders their performance. Besides, they are mostly proposed for the label form. So, it is not clear how to adapt them to the text form, whose search space is even much huger. The second strand is to collect evidences by using graph neural networks <ref type="bibr" target="#b25">(Sun et al., 2018</ref><ref type="bibr" target="#b24">(Sun et al., , 2019))</ref>. They can handle both the two relation forms and achieve state-of-the-art performance. Although they prevail over the path-based models in performance, they are weak in interpretability since their intermediate reasoning process is black-box neural network layers.</p><p>In this paper, we propose a novel model for multi-hop QA, dubbed TransferNet, which has the following advantages: 1) Generality. It can deal with the label form, the text form, and their combinations in a unified framework. 2) Effectiveness. TransferNet outperforms previous models significantly, achieving 100% accuracy of 2-hop and 3-hop questions in MetaQA dataset. 3) Transparency. TransferNet is fully attention-based, so its intermediate steps can be easily visualized and understood by humans.</p><p>Specifically, TransferNet infers the answer by transfering entity scores along relation scores of multiple steps. It starts from the topic entity of the question and maintains an entity score vector, whose elements indicate the probability of an entity being activated. At each step, it attends to some question words (e.g., the wife of ) and compute scores for the relations in the graph. Relations relevant to the question words will have high scores (e.g., Spouse). We formulate these relation scores into an adjacent matrix, where each entry indicates the transfer probability of an entity pair. By multiplying the entity score vector with the relation score matrix, we can "hop" along relations in a differentiable manner. After repeating for multiple steps, we can finally arrive at the target entity.</p><p>We conduct experiments for the two forms respectively.</p><p>For the label form, we use MetaQA <ref type="bibr" target="#b34">(Zhang et al., 2017)</ref>, WebQSP <ref type="bibr" target="#b33">(Yih et al., 2016)</ref> and CompWebQ <ref type="bibr" target="#b26">(Talmor and Berant, 2018)</ref>. TransferNet achieves 100% accuracy in the 2-hop and 3-hop questions of MetaQA. On WebQSP and CompWebQ, we also achieve a significant improvement over state-of-the-art models. For the text form, following <ref type="bibr" target="#b24">(Sun et al., 2019)</ref>, we construct the relation graph of MetaQA from the WikiMovies corpus <ref type="bibr" target="#b18">(Miller et al., 2016)</ref>. We demonstrate that TransferNet surpasses previous models by a large margin, especially for the 2-hop and 3-hop questions. When we mix the label form and the text form, TransferNet still keeps its superiority. Moreover, by visualizing the intermediate results, we show its strong interpretability.<ref type="foot" target="#foot_0">foot_0</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this paper we focus on multi-hop question answering over the graph structure that is either knowledge graph or built from text corpus. In previous works, GraftNet <ref type="bibr" target="#b25">(Sun et al., 2018)</ref> and PullNet <ref type="bibr" target="#b24">(Sun et al., 2019)</ref> have a similar setting to ours but they mostly aim at the mixed form, which includes both label relations and text relations. They first retrieve a question-specific subgraph and then use graph convolutional networks <ref type="bibr" target="#b14">(Kipf and Welling, 2016)</ref> to implicitly infer the answer entity. These GCN-based methods are usually weak in interpretability because they cannot produce the intermediate reasoning path, which is necessary in our opinion for the task of multi-hop question answering. Besides, there are many works specifically for only one graph form:</p><p>For the label form, which is also known as "KBQA" or "KGQA", existing methods fall into two categories: information retrieval <ref type="bibr" target="#b18">(Miller et al., 2016;</ref><ref type="bibr" target="#b30">Xu et al., 2019;</ref><ref type="bibr">Zhao et al., 2019b;</ref><ref type="bibr" target="#b23">Saxena et al., 2020)</ref> and semantic parsing <ref type="bibr" target="#b0">(Berant et al., 2013;</ref><ref type="bibr" target="#b32">Yih et al., 2015;</ref><ref type="bibr" target="#b16">Liang et al., 2017;</ref><ref type="bibr" target="#b11">Guo et al., 2018;</ref><ref type="bibr" target="#b22">Saha et al., 2019)</ref>. The former retrieves answer from KG by learning representations of question and graph, while the latter queries answer by parsing the question into logical form. Among these methods, VRN <ref type="bibr" target="#b34">(Zhang et al., 2017)</ref> and SRN <ref type="bibr" target="#b20">(Qiu et al., 2020)</ref> have a good interpretability as they learn an explicit reasoning path with reinforcement learning. However, they suffer from the convergency issue due to the huge search space. IRN <ref type="bibr" target="#b38">(Zhou et al., 2018)</ref> and <ref type="bibr">ReifKB (Cohen et al., 2020)</ref> learn a soft distribution for intermediate relations and can be optimized using only the final answer. However, it is not clear how to extend them to the text form.</p><p>Question answering over text corpus is also known as "reading comprehension". For simple questions, whose answer can be retrieved directly from the text, pretrained models <ref type="bibr" target="#b7">(Devlin et al., 2018;</ref><ref type="bibr" target="#b15">Lan et al., 2019)</ref> have performed better than humans <ref type="bibr" target="#b35">(Zhang et al., 2020)</ref>. For multi-hop questions that are much more challenging, existing works <ref type="bibr" target="#b8">(Ding et al., 2019;</ref><ref type="bibr" target="#b10">Fang et al., 2019;</ref><ref type="bibr" target="#b28">Tu et al., 2020;</ref><ref type="bibr">Zhao et al., 2019a)</ref> usually convert the text into a rule-based or learning-based entity graph, and then use graph neural networks <ref type="bibr" target="#b14">(Kipf and Welling, 2016)</ref> to perform implicit reasoning. Similar to PullNet, they are weak in interpretability. Besides, most of them build the graph by just connecting relevant entities, missing the important edge textual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary</head><p>We conduct multi-hop reasoning on a relation graph, which takes entities as nodes and relations between them as edges. The relations can be of different forms, specifically, constrained labels or free texts. The former is also known as structured Knowledge Graph (e.g., Wikidata <ref type="bibr" target="#b29">(Vrandečić and Krötzsch, 2014)</ref>), which predefines a set of predicates to represent the entity relations. The latter can be easily extracted from large-scale document corpora according to the co-occurence of entity pairs. Figure <ref type="figure">1</ref> shows examples of these two forms. In this paper we call them label form and text form respectively, and use mixed form to denote a relation graph consisting of both labels and texts.</p><p>We denote a relation graph as G, its entities as E and its edges as R. Let n denote the number of entities, then R is an n × n matrix whose element r i,j represents the relations between the head entity e i and the tail entity e j . r i,j can be a set of labels (for label form) or texts (for text form) or both (for mixed form). A multi-hop question q usually starts from a topic entity e x and needs to traverse across relations to reach the answer entities Y = {e y 1 , • • • , e y |Y | }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TransferNet</head><p>To infer the answer of a multi-hop question, Trans-ferNet starts from the topic entity and jumps for T steps. At each step, it attends to different parts of the question to determine the most proper relation. TransferNet maintains a score for each entity to denote their activated probabilities, which are initialized to 1 for the topic entity and 0 for the others. At each step, TransferNet computes a score for each relation to denote their activated probabilities in terms of the current query, and then transfer the entity scores across those activated relations. Figure <ref type="figure" target="#fig_2">2</ref> shows the framework.</p><p>Formally, we denote the entity scores of step t as a row vector a t ∈ [0, 1] n , where [0, 1] means a real number between 0 and 1. a 0 is the initial scores, i.e., only the topic entity e x gets 1. At step t, we attend to part of the question to get the query vector q t ∈ R d , where d is the hidden dimension.</p><formula xml:id="formula_0">q, (h 1 , • • • , h |q| ) = Encoder(q; θ e ), qk t = f t (q; θ f t ), b t = Softmax(qk t • [h 1 ; • • • ; h |q| ] ), q t = |q| i=1 b t i h i .</formula><p>(1)</p><p>q denotes the question embedding. f t is a projecting function of step t, which maps q to a specific query key qk t . qk t is the attention key to compute scores for each word based on their hidden vector h i . q t is the weighted sum of h i .</p><p>In terms of q t TransferNet computes the relation scores W t ∈ [0, 1] n×n : W t = g(q t ; θ g ).</p><p>(2) θ g denotes the learnable parameters. We will have different implementations of g for the label form and the text form, which will be introduced in Sec.3.5. Then we can simulate the "jumping across edges" as the following formulation:</p><formula xml:id="formula_1">a t = a t-1 W t .</formula><p>(3) Specifically, we have</p><formula xml:id="formula_2">a t j = n i=1 a t-1 i × W t i,j .<label>(4)</label></formula><p>It means that the production of entity e i 's previous score and the edge r i,j 's current score will be collected into e j 's current score. Bill &amp; Melinda Gates Foundation &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z q f u J / y T r J U h x 4 </p><formula xml:id="formula_3">I / l u h m k B 4 + O Y I = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q m R E U X c F N y 4 r 2 A e 0 Y 8 m k m T Y 0 k x m S j F K G + Q 8 3 L h R x 6 7 + 4 8 2 / M t L P Q 1 g O B w z n 3 c k + O H w u u D c b f T m l l d W 1 9 o 7 x Z 2 d r e 2 d 2 r 7 h + 0 d Z Q o y l o 0 E p H q + k Q z w S V r G W 4 E 6 8 a K k d A X r O N P b n K / 8 8 i U 5 p G 8 N 9 O Y e S E Z S R 5 w S o y V H v o h M W M / S E k 2 S H E 2 q N Z w H c + A l o l b k B o U a A 6 q X / 1 h R J O Q S U M F 0 b r n 4 t h 4 K V G G U 8 G y S j / R L C Z 0 Q k a s Z 6 k k I d N e O k u d o R O r D F E Q K f u k Q T P 1 9 0 Z K Q q 2 n o W 8 n 8 5 R 6 0 c v F / 7 x e Y o I r L + U y T g y T d H 4 o S A Q y E c o r Q E O u G D V i a g m h i t u s i I 6 J I t T Y o i q 2 B H f x y 8 u k f V Z 3 L + r 4 7 r z W u C 7 q K M M R H M M p u H A J D b i F J r S A</formula><formula xml:id="formula_4">p V K + m I x E c x 1 R m P Z O b B x 8 = " &gt; A A A B 9 X i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s y I o u 4 K b l x W s A 9 o x 5 J J M 2 1 o k h m S j F K G + Q 8 3 L h R x 6 7 + 4 8 2 / M t L P Q 1 g O B w z n 3 c k 9 O E H O m j e t + O 6 W V 1 b X 1 j f J m Z W t 7 Z 3 e v u n / Q 1 l G i C G 2 R i E e q G 2 B N O Z O 0 Z Z j h t B s r i k X A a S e Y 3 O R + 5 5 E q z S J 5 b 6 Y x 9 Q U e S R Y y g o 2 V H v o C m 3 E Q p p 1 s k H r Z o F p z 6 + 4 M a J l 4 B a l B g e a g + t U f R i Q R V B r C s d Y 9 z 4 2 N n 2 J l G O E 0 q / Q T T W N M J n h E e 5 Z K L K j 2 0 1 n q D J 1 Y Z Y j C S N k n D Z q p v z d S L L S e i s B O 5 i n 1 o p e L / 3 m 9 x I R X f s p k n B g q y f x Q m H B k I p R X g I Z M U W L 4 1 B J M F L N Z E R l j h Y m x R V V s C d 7 i l 5 d J + 6 z u X d T d u / N a 4 7 q o o w x H c A y n 4 M E l N O A W m t A C A g q e 4 R X e n C f n x X l 3 P u a j J a f Y O Y Q / c D 5 / A M K a k q Y = &lt; / l a t e x i t &gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W1</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g E j e l H 8 4 / + 3 S g q r 4 C + 4 s e A w P y J 8</p><formula xml:id="formula_5">= " &gt; A A A C E X i c b V D L S s N A F L 2 p r 1 p f U Z d u B o v Q V U l E U R d C w Y 3 L C v Y B b Q i T 6 a Q d O n k w M x F K y C + 4 8 V f c u F D E r T t 3 / o 2 T N k J t P T B w 7 j n 3 M v c e L + Z M K s v 6 N k o r q 2 v r G + X N y t b 2 z u 6 e u X / Q l l E i C G 2 R i E e i 6 2 F J O Q t p S z H F a T c W F A c e p x 1 v f J P 7 n Q c q J I v C e z W J q R P g Y c h 8 R r D S k m v W + g F W I 8 9 P c e a m d n Y 9 V 1 r o t + h k r u 2 a V a t u T Y G W i V 2 Q K h R o u u Z X f x C R J K C h I h x L 2 b O t W D k p F o o R T r N K P 5 E 0 x m S M h 7 S n a Y g D K p 1 0 e l G G T r Q y Q H 4 k 9 A s V m q r z E y k O p J w E n u 7 M d 5 S L X i 7 + 5 / U S 5 V 8 6 K Q v j R N G Q z D 7 y E 4 5 U h P J 4 0 I A J S h S f a I K J Y H p X R E Z Y Y K J 0 i B U d g r 1 4 8 j J p n 9 b t 8 7 p 1 d 1 Z t X B V x l O E I j q E G N l x A A 2 6 h C S 0 g 8 A j P 8 A p v x p P x Y r w b H 7 P W k l H M H M I f G J 8 / 5 x + d p Q = = &lt; / l a t e x i t &gt; a1 = a0W1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " I l i t o T 0 e o r T t D G H S 2 F K J x I E r 6 x U = " &gt; A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l Z m i q L u C G 5 c V 7 A P a s W T S T B u a S Y Y k o 5 R h / s O N C 0 X c + i / u / B s z 7 S y 0 9 U D g c M 6 9 3 J M T x J x p 4 7 r f z s r q 2 v r G Z m m r v L 2 z u 7 d f O T h s a 5 k o Q l t E c q m 6 A d a U M 0 F b h h l O u 7 G i O A o 4 7 Q S T m 9 z v P F K l m R T 3 Z h p T P 8 I j w U J G s L H S Q z / C Z h y E a S c b p P V s U K m 6 N X c G t E y 8 g l S h Q H N Q + e o P J U k i K g z h W O u e 5 8 b G T 7 E y j H C a l f u J p j E m E z y i P U s F j q j 2 0 1 n q D J 1 a Z Y h C q e w T B s 3 U 3 x s p j r S e R o G d z F P q R S 8 X / / N 6 i Q m v / J S J O D F U k P m h M O H I S J R X g I Z M U W L 4 1 B J M F L N Z E R l j h Y m x R Z V t C d 7 i l 5 d J u 1 7 z L m r u 3 X m 1 c V 3 U U Y J j O I E z 8 O A S G n A L T W g B A Q X P 8 A p v z p P z 4 r w 7 H / P R F a f Y O Y I / c D 5 / A M Q f k q c = &lt; / l a t e x i t &gt; W2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D B R 2 9 s F 2 R Y Y G H h u Q p z w W 7 N T J p 3 8 = " &gt; A A A C E X i c b V D L S s N A F L 3 x W e s r 6 t L N Y B G 6 K k l R 1 I V Q c O O y g n 1 A G 8 J k O m m H T h 7 M T I Q S 8 g t u / B U 3 L h R x 6 8 6 d f + O k j V B b D w y c e 8 6 9 z L 3 H i z m T y r K + j Z X V t f W N z d J W e X t n d 2 / f P D h s y y g R h L Z I x C P R 9 b C k n I W 0 p Z j i t B s L i g O P 0 4 4 3 v s n 9 z g M V k k X h v Z r E 1 A n w M G Q + I 1 h p y T W r / Q C r k e e n O H P T e n Y 9 V 9 r o t + h k b t 0 1 K 1 b N m g I t E 7 s g F S j Q d M 2 v / i A i S U B D R T i W s m d b s X J S L B Q j n G b l f i J p j M k Y D 2 l P 0 x A H V D r p 9 K I M n W p l g P x I 6 B c q N F X n J 1 I c S D k J P N 2 Z 7 y g X v V z 8 z + s l y r 9 0 U h b G i a I h m X 3 k J x y p C O X x o A E T l C g + 0 Q Q T w f S u i I y w w E T p E M s 6 B H v x 5 G X S r t f s 8 5 p 1 d 1 Z p X B V x l O A Y T q A K N l x A A 2 6 h C S 0 g 8 A j P 8 A p v x p P x Y r w b H 7 P W F a O Y O Y I / M D 5 / A O v T n a g = &lt; / l a t e x i t &gt; a2 = a1W2</formula><p>Label Form</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Form</head><p>Relation Graphs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example</head><p>Question: What organization did the wife of Bill Gates found?</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = "</p><formula xml:id="formula_6">C r o 1 K F t H 7 9 6 d p k / W w q v F 0 s I z 2 D 4 = " &gt; A A A B + X i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w Y 0 l E 0 Z U U 3 L i s Y B / Q h j C Z T t q h k 0 m Y u S m U k D 9 x 4 0 I R t / 6 J O / / G S Z u F t h 4 Y O J x z L / f M C R L B N T j O t 1 V Z W 9 / Y 3 K p u 1 3 Z 2 9 / Y P 7 M O j j o 5 T R V m b x i J W v Y B o J r h k b e A g W C 9 R j E S B Y N 1 g c l / 4 3 S l T m s f y C W Y J 8 y I y k j z k l I C R f N s e R A T G Q Z i R 3 M / g w s 1 9 u + 4 0 n D n w K n F L U k c l W r 7 9 N R j G N I 2 Y B C q I 1 n 3 X S c D L i A J O B c t r g 1 S z h N A J G b G + o Z J E T H v Z P H m O z 4 w y x G G s z J O A 5 + r v j Y x E W s + i w E w W O f W y V 4 j / e f 0 U w l s v 4 z J J g U m 6 O B S m A k O M i x r w k C t G Q c w M I V R x k x X T M V G E g i m r Z k p w l 7 + 8 S j q X D f e 6 4 T x e 1 Z t 3 Z R 1 V d I J O 0 T l y 0 Q 1 q o g f U Q m 1 E 0 R Q 9 o 1 f 0 Z m X W i / V u f S x G K 1 a 5 c 4 z + w P r 8 A Z U h k 5 s = &lt; / l a t e x i t &gt; a t 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p / b 1 L I n r n v a 7 9 W q s / g W g A N 4 d 3 B c = " &gt; A A A B 9 X i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S i K K r q T g x m U F + 4 A 2 l s l 0 0 g 6 d T O L M j V J C / s O N C 0 X c + i / u / B s n b R b a e m D g c M 6 9 3 D P H j w X X 6 D j f 1 t L y y u r a e m m j v L m 1 v b N b 2 d t v 6 S h R l D V p J C L V 8 Y l m g k v W R I 6 C d W L F S O g L 1 v b H 1 7 n f f m R K 8 0 j e 4 S R m X k i G k g e c E j T S f S 8 k O P K D 9 C H r p 5 j 1 K 1 W n 5 k x h L x K 3 I F U o 0 O h X v n q D i C Y h k 0 g F 0 b r r O j F 6 K V H I q W B Z u Z d o F h M 6 J k P W N V S S k G k v n a b O 7 G O j D O w g U u Z J t K f q 7 4 2 U h F p P Q t 9 M 5 i n 1 v J e L / 3 n d B I N L L + U y T p B J O j s U J M L G y M 4 r s A d c M Y p i Y g i h i p u s N h 0 R R S i a o s q m B H f + y 4 u k d V p z z 2 v O 7 V m 1 f l X U U Y J D O I I T c O E C 6 n A D D W g C B Q X P 8 A p v 1 p P 1 Y r 1 b H 7 P R J a v Y O Y A / s D 5 / A F H j k w g = &lt; / l a t e x i t &gt; q t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P P O r i J K v 8 e 1 V K p N Z H E z k R H x O f + k = " &gt; A A A B 9 X i c b V D L S s N A F L 2 p r 1 p f V Z d u g k V w V R J R d C U F N y 4 r 2 A e 0 s U y m k 3 b o Z B J m b p Q S 8 h 9 u X C j i 1 n 9 x 5 9 8 4 a b P Q 1 g M D h 3 P u 5 Z 4 5 f i y 4 R s f 5 t k o r q 2 v r G + X N y t b 2 z u 5 e d f + g r a N E U d a i k Y h U 1 y e a C S 5 Z C z k K 1 o 0 V I 6 E v W M e f 3 O R + 5 5 E p z S N 5 j 9 O Y e S E Z S R 5 w S t B I D / 2 Q 4 N g P 0 k 4 2 S D E b V G t O 3 Z n B X i Z u Q W p Q o D m o f v W H E U 1 C J p E K o n X P d W L 0 U q K Q U 8 G y S j / R L C Z 0 Q k a s Z 6 g k I d N e O k u d 2 S d G G d p B p M y T a M / U 3 x s p C b W e h r 6 Z z F P q R S 8 X / / N 6 C Q Z X X s p l n C C T d H 4 o S I S N k Z 1 X Y A + 5 Y h T F 1 B B C F T d Z b T o m i l A 0 R V V M C e 7 i l 5 d J + 6 z u X t S d u / N a 4 7 q o o w x H c A y n 4 M I l N O A W m t A C C g q e 4 R X e r C f r x X q 3 P u a j J a v Y O Y Q / s D 5 / A C n 5 k u 4 = &lt; / l a t e x i t &gt; W t</formula><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p W 8 h F 7 U p y 1 7 6 I p M S l p q g C R N w 5 In 2000, Melinda Gates cofounded the &lt;obj&gt; with her husband &lt;sub&gt;.</p><formula xml:id="formula_7">+ E = " &gt; A A A C F 3 i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w Y 0 l E 0 Y 1 S c O O y g n 1 A G 8 J k O m m H T h 7 M 3 A g l 5 C / c + C t u X C j i V n f + j Z M 2 S G 0 9 M H D m n H u 5 9 x 4 v F l y B Z X 0 b p a X l l d W 1 8 n p l Y 3 N r e 8 f c 3 W u p K J G U N W k k I t n x i G K C h 6 w J H A T r x J K R w B O s 7 Y 1 u c r / 9 w K T i U X g P 4 5 g 5 A R m E 3 O e U g J Z c s 9 Y L C A w 9 P y W Z C / g K z 3 x T O L G z X 6 G d C 5 l r V q 2 a N Q F e J H Z B q q h A w z W / e v 2 I J g E L g Q q i V N e 2 Y n B S I o F T w b J K L 1 E s J n R E B q y r a U g C p p x 0 c l e G j 7 T S x 3 4 k 9 Q s B T 9 T Z j p Q E S o 0 D T 1 f m W 6 p 5 L x f / 8 7 o J + J d O y s M 4 A R b S 6 S A / E R g i n I e E + 1 w y C m K s C a G S 6 1 0 x H R J J K O g o K z o E e / 7 k R d I 6 r d n n N e v u r F q / L u I o o w N 0 i I 6 R j S 5 Q H d 2 i B m o i i h 7 R M 3 p F b 8 a T 8 W K 8 G x / T 0 p J R 9 O y j P z A + f w C 5 V K B G &lt; / l a t e x i t &gt; a t = a t 1 W t &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 5 F 7 E N i u S g f z B 1 v b 5 3 T 1 v v i w R y 9 0 = " &gt; A A A C b H i c b V H J T s M w E H X C V s J W l g M I I V l U I E 6 R g 1 j K D Y k L R 5 A o I D V V 5 T j T Y t V x I t t B V F F P / C E 3 P o E L 3 4 B T I p b C S J b f v J n n s Z + j T H B t C H l 1 3 K n p m d m 5 2 r y 3 s L i 0 v F J f X b v V a a 4 Y t F g q U n U f U Q 2 C S 2 g Z b g T c Z w p o E g m 4 i w Y X Z f 3 u E Z T m q b w x w w w 6 C e 1 L 3 u O M G k t 1 6 8 9 h B H 0 u i y y h R v G n k U f w P i b + 2 Y n d w j g 1 u k x x G H r E b 4 7 h B B 0 + V t k 3 i H 8 z p X Z S 6 Y U g 4 6 + Z 3 X q D + G Q c + C 8 I K t B A V V x 1 6 y / 2 J J Y n I A 0 T V O t 2 Q D L T K a g y n A k Y e W G u I a N s Q P v Q t l D S B H S n G J s 1 w n u W i X E v V X Z J g 8 f s T 0 V B E 6 2 H S W Q 7 7 f 0 e 9 G S t J P + r t X P T a 3 Y K L r P c g G S f g 3 q 5 w C b F p f M 4 5 g q Y E U M L K F P c 3 h W z B 6 o o M / Z / P G t C M P n k v + D 2 0 A + O f X J 9 1 D g / q + y o o W 2 0 i w 5 Q g E 7 R O b p E V 6 i F G H p z V p x N Z 8 t 5 d z f c b X f n s 9 V 1 K s 0 6 + h X u / g</formula><p>In 2000, &lt;sub&gt; co-founded the &lt;obj&gt; with her husband Bill Gates.</p><p>During his career at &lt;sub&gt;, &lt;obj&gt; held the positions of chairman, chief executive officer (CEO), president and chief software architect.</p><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z p 3 T u 8 R y N j 5</p><formula xml:id="formula_8">H U p x n v q T S Q k d Q Y 5 o = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y B E 8 l U Q U P U n B i 8 c K 9 g P a U D a b T b t 2 s x t 2 J 0 I J / Q 9 e P C j i 1 f / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e m A p u 0 P O + n Z X V t f W N z d J W e X t n d 2 + / c n D Y M i r T l D W p E k p 3 Q m K Y 4 J I 1 k a N g n V Q z k o S C t c P R 7 d R v P z F t u J I P O E 5 Z k J C B 5 D G n B K 3 U 6 t F I o e l X q l 7 N m 8 F d J n 5 B q l C g 0 a 9 8 9 S J F s 4 R J p I I Y 0 / W 9 F I O c a O R U s E m 5 l x m W E j o i A 9 a 1 V J K E m S C f X T t x T 6 0 S u b H S t i S 6 M / X 3 R E 4 S Y 8 Z J a D s T g k O z 6 E 3 F / 7 x u h v F 1 k H O Z Z s g k n S + K M + G i c q e v u x H X j K I Y W 0 K o 5 v Z W l w 6 J J h R t Q G U b g r / 4 8 j J p n d f 8 y 5 p 3 f 1 G t 3 x R x l O A Y T u A M f L i C O t x B A 5 p A 4 R G e 4 R X e H O W 8 O O / O x 7 x 1 x S l m j u A P n M 8 f r n W P L w = = &lt; / l a t e x i t &gt; • • • Relations &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G M o h Y m r C K b U g w d m P I 2 Y T E v 2 V D E k = " &gt; A A A C G 3 i c b V D L S s N A F J 3 U V 4 2 v q E s 3 g 0 V x V Z K i q L u C G 5 c V 7 A O a U C b T 2 3 b o Z B J m J m I J / Q 8 3 / o o b F 4 q 4 E l z 4 N 0 7 T I t p 6 4 M L h n H t n 7 j 1 h w p n S r v t l F Z a W V 1 b X i u v 2 x u b W 9 o 6 z u 9 d Q c S o p 1 G n M Y 9 k K i Q L O B N Q 1 0 x x a i Q Q S h R y a 4 f B q 4 j f v Q C o W i 1 s 9 S i C I S F + w H q N E G 6 n j V P w Q + k x k S U S 0 Z P d j 2 8 P H 2 D X l d 2 O t c u 7 7 t g + i + 9 P S c U p u 2 c 2 B F 4 k 3 I y U 0 Q 6 3 j f J j H a B q B 0 J Q T p d q e m + g g I 1 I z y m F s + 6 m C h N A h 6 U P b U E E i U E G W 3 z b G R 0 b p 4 l 4 s T Q m N c / X 3 R E Y i p U Z R a D r N f g M 1 7 0 3 E / 7 x 2 q n s X Q c Z E k m o Q d P p R L + V Y x 3 g S F O 4 y C V T z k S G E S m Z 2 x X R A J K H a x G m b E L z 5 k x d J o 1 L 2 z s r u z W m p e j m L o 4 g O 0 C E 6 Q R 4 6 R 1 V 0 j W q o j i h 6 Q E / o B b 1 a j 9 a z 9 W a 9 T 1 s L 1 m x m H / 2 B 9 f k N q q 2 f T Q = = &lt; / l a t e x i t &gt; 1 0 . . . 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y 1 V D d z 5 G R A X u 8 A a b u E a m w 5 H 7 r T Q = " &gt; A A A C H n i c b V B N S w M x E M 3 W r 7 p + V T 1 6 C R b F U 9 k V q / Z W 8 O K x g v 2 A 7 l K y 6 b Q N z W a X J C u W p b / E i 3 / F i w d F B E / 6 b 0 z b R b R 1 I O T l z Z v J z A t i z p R 2 n C 8 r t 7 S 8 s r q W X 7 c 3 N r e 2 d w q 7 e w 0 V J Z J C n U Y 8 k q 2 A K O B M Q F 0 z z a E V S y B h w K E Z D K 8 m + e Y d S M U i c a t H M f g h 6 Q v W Y 5 R o Q 3 U K Z S + A P h N p H B I t 2 f 3 Y d v A x d k q V c 3 N 5 3 U i r y R N 7 n u 2 B 6 P 6 o O o W i U 3 K m g R e B m 4 E i y q L W K X y Y Z j Q J Q W j K i V J t 1 4 m 1 n x K p G e U w t r 1 E Q U z o k P S h b a A g I S g / n a 4 3 x k e G 6 e J e J M 0 R G k / Z 3 x U p C Z U a h Y F R m v k G a j 4 3 I f / L t R P d u / R T J u J E g 6 C z j 3 o J x z r C E 6 9 w l 0 m g m o 8 M I F Q y M y u m A y I J 1 c Z R 2 5 j g z q + 8 C B q n J b d c c m 7 O i t V K Z k c e H a B D d I J c d I G q 6 B</formula><p>r V U B 1 R 9 I C e 0 A t 6 t R 6 t Z + v N e p 9 J c 1 Z W s 4 / + h P X 5 D S 8 3 o A c = &lt; / l a t e x i t &gt; 0 0.96 . . . 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoder t</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Over Words</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STEP t</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W 4 N J c p 4 7 y A b Z Y D Z g L D g V y l 4 e e L M = " &gt; A</p><formula xml:id="formula_9">A A B + X i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w Y 0 l E U X c F N y 4 r 2 A e 0 I U y m k 3 b o Z B J m b g o l 5 E / c u F D E r X / i z r 9 x 0 m a h r Q c G D u f c y z 1 z g k R w D Y 7 z b V X W 1 j c 2 t 6 r b t Z 3 d v f 0 D + / C o o + N U U d a m s Y h V L y C a C S 5 Z G z g I 1 k s U I 1 E g W D e Y 3 B d + d 8 q U 5 r F 8 g l n C v I i M J A 8 5 J W A k 3 7 Y H E Y F x E G Y k 9 z O 4 c H P f r j s N Z w 6 8 S t y S 1 F G J l m 9 / D Y Y x T S M m g Q q i d d 9 1 E v A y o o B T w f L a I N U s I X R C R q x v q C Q R 0 1 4 2 T 5 7 j M 6 M M c R g r 8 y T g u f p 7 I y O R 1 r M o M J N F T r 3 s F e J / X j + F 8 N b L u E x S Y J I u D o W p w B D j o g Y 8 5 I p R E D N D C F X c Z M V 0 T B S h Y M q q m R L c 5 S + v k s 5 l w 7 1 u O I 9 X 9 e Z d W U c V n a B T d I 5 c d I O a 6 A G 1 U B t R N E X P 6 B W 9 W Z n 1 Y r 1 b H 4 v R i l X u H K M / s D 5 / A J O g k 5 Y = &lt; / l a t e x i t &gt; at 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n k e s Y R l z W G i E F e C + B 0 O X 9 S S 6 r 7 k = " &gt; A A A B 9 X i c b V D L S s N A F L 2 p r 1 p f V Z d u g k V w V R J R 1 F 3 B j c s K 9 g F t L J P p p B 0 6 m Y S Z G 6 W E / I c b F 4 q 4 9 V / c + T d O 2 i y 0 9 c D A 4 Z x 7 u W e O H w u u 0 X G + r d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 y h R l L V o J C L V 9 Y l m g k v W Q o 6 C d W P F S O g L 1 v E n N 7 n f e W R K 8 0 j e 4 z R m X k h G k g e c E j T S Q z 8 k O P a D l G S D F L N B t e b U n R n s Z e I W p A Y F m o P q V 3 8 Y 0 S R k E q k g W v d c J 0 Y v J Q o 5 F S y r 9 B P N Y k I n Z M R 6 h k o S M u 2 l s 9 S Z f W K U o R 1 E y j y J 9 k z 9 v Z G S U O t p 6 J v J P K V e 9 H L x P 6 + X Y H D l p V z G C T J J 5 4 e C R N g Y 2 X k F 9 p A r R l F M D S F U c Z P V p m O i C E V T V M W U 4 C 5 + e Z m 0 z + r u R d 2 5 O 6 8 1 r o s 6 y n A E x 3 A K L l x C A 2 6 h C S 2 g o O A Z X u</formula><p>H N e r J e r H f r Y z 5 a s o q d Q / g D 6 / M H N 9 K S 8 w = = &lt; / l a t e x i t &gt; at Answer &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z p 3 T u 8 R y N j 5 H U p</p><formula xml:id="formula_10">x n v q T S Q k d Q Y 5 o = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y B E 8 l U Q U P U n B i 8 c K 9 g P a U D a b T b t 2 s x t 2 J 0 I J / Q 9 e P C j i 1 f / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e m A p u 0 P O + n Z X V t f W N z d J W e X t n d 2 + / c n D Y M i r T l D W p E k p 3 Q m K Y 4 J I 1 k a N g n V Q z k o S C t c P R 7 d R v P z F t u J I P O E 5 Z k J C B 5 D G n B K 3 U 6 t F I o e l X q l 7 N m 8 F d J n 5 B q l C g 0 a 9 8 9 S J F s 4 R J p I I Y 0 / W 9 F I O c a O R U s E m 5 l x m W E j o i A 9 a 1 V J K E m S C f X T t x T 6 0 S u b H S t i S 6 M / X 3 R E 4 S Y 8 Z J a D s T g k O z 6 E 3 F / 7 x u h v F 1 k H O Z Z s g k n S + K M + G i c q e v u x H X j K I Y W 0 K o 5 v Z W l w 6 J J h R t Q G U b g r / 4 8 j J p n d f 8 y 5 p 3 f 1 G t 3 x R x l O A Y T u A M f L i C O t x B A 5 p A 4 R G e 4 R X e H O W 8 O O / O x 7</formula><p>x 1 x S l m j u A P n M 8 f r n W P L w = = &lt; / l a t e x i t &gt;</p><p>• • • &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 A x L Y x j X q L B w O X V 9 V 7 a C I p d 0 0 d Q = " &gt; A A A B 8 3 i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i S i q L u C G 5 c V + o K m l M n 0 p h 0 6 m Y S Z i V B C f 8 O N C 0 X c + j P u / B s n b R Z a P T B w O O d e 7 p k T J I J r 4 7 p f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 5 1 d J w q h m 0 W i 1 j 1 A q p R c I l t w 4 3 A X q K Q R o H A b j C 9 y / 3 u I y r N Y 9 k y s w Q H E R 1 L H n J G j Z V 8 P 6 J m E o Q Z n Q 9 b w 2 r N r b s L k L / E K 0 g N C j S H 1 U 9 / F L M 0 Q m m Y o F r 3 P T c x g 4 w q w 5 n A e c V P N S a U T e k Y + 5 Z K G q E e Z I v M c 3 J m l R E J Y 2 W f N G S h / t z I a K T 1 L A r s Z J 5 R r 3 q 5 + J / X T 0 1 4 M 8 i 4 T F K D k i 0 P h a k g J i Z 5 A W T E F T I j Z p Z Q p r j N S t i E K s q M r a l i S / B W v / y X d C 7 q 3 l X d f b i s N W 6 L O s p w A q d w D h 5 c Q w P u o Q l t Y J D A E 7 z A q 5 M 6 z 8 6 b 8 7 4 c L T n F z j H 8 g v P x D T r o k c c = &lt; / l a t e x i t &gt; aT Target Entity</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STEP t-1 STEP T</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z p 3 T u 8 R y N j 5 H U p After repeating for T times, we get the entity scores of each step a 1 , a 2 , • • • , a T . Then we compute their weighted sum as the final output:</p><formula xml:id="formula_11">x n v q T S Q k d Q Y 5 o = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y B E 8 l U Q U P U n B i 8 c K 9 g P a U D a b T b t 2 s x t 2 J 0 I J / Q 9 e P C j i 1 f / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e m A p u 0 P O + n Z X V t f W N z d J W e X t n d 2 + / c n D Y M i r T l D W p E k p 3 Q m K Y 4 J I 1 k a N g n V Q z k o S C t c P R 7 d R v P z F t u J I P O E 5 Z k J C B 5 D G n B K 3 U 6 t F I o e l X q l 7 N m 8 F d J n 5 B q l C g 0 a 9 8 9 S J F s 4 R J p I I Y 0 / W 9 F I O c a O R U s E m 5 l x m W E j o i A 9 a 1 V J K E m S C f X T t x T 6 0 S u b H S t i S 6 M / X 3 R E 4 S Y 8 Z J a D s T g k O z 6 E 3 F / 7 x u h v F 1 k H O Z Z s g k n S + K M + G i c q e v u x H X j K I Y W 0 K o 5 v Z W l w 6 J J h R t Q G U b g r / 4 8 j J p n d f 8 y 5 p 3 f 1 G t 3 x R x l O A Y T u A M f L i C O t x B A 5 p A 4 R G e 4 R X</formula><formula xml:id="formula_12">c = Softmax(MLP(q)), a * = T t=1 c t a t ,<label>(5)</label></formula><p>where c ∈ [0, 1] T denotes the probability distribution of the question's hop, and c t is the probability value of hop t. We can answer all questions from 1-hop to T -hop by automatically determine its hop number. The entity with maximum score in a * is outputed as the answer.</p><p>TransferNet is a highly-transparent model. As shown in the example of Figure <ref type="figure" target="#fig_2">2</ref>, we can easily track the model behaviour by visualizing the activated words, relations, and entities at each step (see Sec.5.4 for more examples).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>Given the golden answer set Y = {e y 1 , • • • , e y |Y | }, we construct the target score vector y ∈ {0, 1} n by</p><formula xml:id="formula_13">y i = 1, if e i ∈ Y, 0, else. (<label>6</label></formula><formula xml:id="formula_14">)</formula><p>Then we take the L2 Euclidean distance between a * and y as our training objective:</p><formula xml:id="formula_15">L = a * -y . (<label>7</label></formula><formula xml:id="formula_16">)</formula><p>Note that TransferNet is totally differentiable, therefore we can learn all of the intermediate scores (i.e., question attention, relation scores, and entity scores of each step) via this simple objective..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Additional Modules</head><p>We propose two modules to facilitate the learning of TransferNet. Score Truncation. According to Equation 4, a t j may exceed 1 after a transfer step. A too large score will have a bad influence to the gradient computation. Especially when the hop increases, it may lead to gradient explosion. Besides, our loss function, Equation <ref type="formula" target="#formula_15">7</ref>, will fail if the final score has an unlimited value. So we need to rectify the entity scores after each transfer step, to ensure the value range is in [0, 1]. At the same time, we need to maintain the differentiability of the operation. We propose such a truncation function:</p><formula xml:id="formula_17">Trunc(a) = a/z(a), z(a) = a.detach(), if a &gt; 1, 1, if a ≤ 1.<label>(8)</label></formula><p>After each transfer step, we truncate a t by applying this function to each of its elements. Language Mask. TranferNet does not consider the language bias of the question, which may include some hints for its answer. For example, in the textformed relation graph we may have (Harry Potter, &lt;sub&gt; was published in &lt;obj&gt;, United Kingdom) and (Harry Potter, &lt;sub&gt; was published in &lt;obj&gt;, 1997). These two triples depict different aspects (i.e., the publication place and the publication time of Harry Potter) but with the same relation text. As a result, given the question Where was Harry Potter published, TransferNet will produce the same scores for United Kingdom and 1997, and thus use 1997 to wrongly answer the Where-question.</p><p>To solve this issue, we propose a language mask to incorporate the question hints. We predict a mask score for each entity using the question embedding:</p><formula xml:id="formula_18">m = Sigmoid(MLP(q)),<label>(9)</label></formula><p>where m ∈ [0, 1] n , m i denotes the mask score of entity e i , MLP (short for multi-layer perceptron) projects d-dimensional feature to n-dimension. We multiply the mask to the final entity scores,</p><formula xml:id="formula_19">â * = m a * ,<label>(10)</label></formula><p>where means element-wise multiplication. The a * in the objective function Equation <ref type="formula" target="#formula_15">7</ref>should be replaced with â * . Note that we need the language mask only in the text form, because the predicates of label form have no ambiguity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Relation Score Computation</head><p>Consider Equation 2, W t = g(q t ; θ g ), we design different implementations of g for different relation forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Label Form</head><p>In the label form, relations are represented with a fixed predicate set P. We first compute probabilities for these predicates in terms of q t , and then collect corresponding probabilities of r i,j as W t i,j . Formally, the predicate distribution is computed by p t = Softmax(MLP(q t )).</p><p>The Softmax function can be replaced with Sigmoid if predicates are not mutually exclusive, i.e., multiple predicates will be activated meanwhile. Let b denote the maximum number of relations between a pair of entity, then we can denote the relation as</p><formula xml:id="formula_21">r i,j = {r i,j,1 , • • • , r i,j,b }, where r i,j,k ∈ {1, 2, • • • , |P|}.</formula><p>The predicate probabilities are collected in terms of the relation labels:</p><formula xml:id="formula_22">W t i,j = b k=1 p t r i,j,k .<label>(12)</label></formula><p>We gather the probabilities by summing them up. max is another feasible option, but we find is more efficient and more stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Text Form</head><p>In the text form, relations are represented with natural language descriptions. The graph is built by extracting the co-occuring sentence of a pair of entity and replacing the entities with special placeholders. For example, the sentence Bill Gates and Melinda Gates have been married for 26 years contributes an edge from Bill Gates to Melinda Gates, whose relation text is &lt;sub&gt; and &lt;obj&gt; have been married for 26 years, as shown in Figure <ref type="figure" target="#fig_2">2</ref>. We can get the reverse relations by exchanging the placeholders of subject and object, but for simplicity, we do not show them in the figure.</p><p>Let r i,j = {r i,j,1 , • • • , r i,j,b } and r i,j,k denotes the k-th relation sentence. We use a relation encoder to obtain the relation embeddings, and then compute the relation score by</p><formula xml:id="formula_23">r i,j,k = Encoder(r i,j,k ; θ r ), p t r i,j,k = Sigmoid(MLP(r i,j,k q t )), W t i,j = b k=1 p t r i,j,k ,<label>(13)</label></formula><p>where means element-wise product, MLP maps the feature from d-dimensional to 1-dimensional.</p><p>Since there are a huge amount of (usually millions of) relation texts in a relation graph, it is impossible to compute the embeddings and scores for all of them. So in practice, we select a subset of relations at each step. Specifically, at step t, we select entities whose previous score a t-1 i is larger than a predefined threshold τ and only consider relations that start from these entities. Besides, if there are too many relations meeting this condition, we will only preserve top ω of them, sorting based on their subject entity score. By doing so, we just need to consider at most ω relations at each step.</p><p>We use the same method to process the mixed form, by simply regarding the label predicates as one-word sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>MetaQA <ref type="bibr" target="#b34">(Zhang et al., 2017</ref>) is a largescale dataset of multi-hop question answering over knowledge graph, which extends Wiki-Movies <ref type="bibr" target="#b18">(Miller et al., 2016)</ref> from single-hop to multi-hop. It contains more than 400k questions, which are generated using dozens of templates and have up to 3 hops. Its knowledge graph is from the movie domain, including 43k entities, 9 predicates, and 135k triples.</p><p>Besides the label from, we also constructed the text form of MetaQA by extracting the text corpus of WikiMovies <ref type="bibr" target="#b18">(Miller et al., 2016)</ref>, which introduces the information of movies with free text. Following <ref type="bibr" target="#b24">(Sun et al., 2019)</ref>, we used exact match of surface forms for entity recognition and linking. Given an article of a movie, we took the movie as subject and the other relavant entities (e.g., mentioned actor, year, and etc) as objects. The sentence was processed with placeholders, that is, replacing the movie with &lt;sub&gt; (if it occurs) and the object entity with &lt;obj&gt;, and then regarded as the relation texts. An entity pair can have multiple textual relations.</p><p>WebQSP <ref type="bibr" target="#b33">(Yih et al., 2016)</ref> has a smaller scale of questions but larger scale of knowledge graph. It contains thousands of natural language questions based on Freebase <ref type="bibr" target="#b1">(Bollacker et al., 2008)</ref>, which has millions of entities and triples. Its questions are either 1-hop or 2-hop. Following <ref type="bibr" target="#b23">(Saxena et al., 2020)</ref>, we pruned the knowledge base to contain only mentioned predicates and within 2-hop triples of mentioned entities. As a result, the processed knowledge graph includes 1.8 million entities, 572 predicates, and 5.7 million triples. We only consider the label form of WebQSP due to its huge scale.</p><p>CompWebQ <ref type="bibr" target="#b26">(Talmor and Berant, 2018)</ref> is an extended version of WebQSP with more hops and constraints. Following <ref type="bibr" target="#b24">(Sun et al., 2019)</ref>, we retrieved a subgraph for each question using PageRank algorithm. On average, there are 1948 entities in each subgraph and the recall is 64%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>KVMemNN <ref type="bibr" target="#b18">(Miller et al., 2016)</ref> uses the keyvalue memory to store knowledge and conducts multi-hop reasoning by iteratively reading the memory.</p><p>VRN <ref type="bibr" target="#b34">(Zhang et al., 2017)</ref> learns the reasoning path via reinforcement learning. Its intermediate results have a good interpretability. SRN <ref type="bibr" target="#b20">(Qiu et al., 2020)</ref> improves VRN by beam search and reward shaping strategy, boosting its speed and performance.</p><p>GraftNet <ref type="bibr" target="#b25">(Sun et al., 2018)</ref> extracts a questionspecific subgraph from the entire relation graph with heuristics, and then uses graph neural networks to infer the answer.</p><p>PullNet <ref type="bibr" target="#b24">(Sun et al., 2019)</ref> improves GraftNet by learning to retrieve the subgraph with a graph CNN instead of heuristics.</p><p>ReifKB <ref type="bibr" target="#b6">(Cohen et al., 2020)</ref> proposes a scalable implementation of probability transfer over largescale knowledge graph of label form. It can be regarded as a degenerated case of TransferNet.</p><p>EmbedKGQA <ref type="bibr" target="#b23">(Saxena et al., 2020)</ref> takes KGQA as a link prediction task and incorporates knowledge graph embeddings <ref type="bibr" target="#b3">(Bordes et al., 2013;</ref><ref type="bibr" target="#b27">Trouillon et al., 2016)</ref> to help predict the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementations</head><p>We added reversed relations into the relation graph, leading to double size of predicates and triples. For the text form, we exchanged the placeholder &lt;sub&gt; and &lt;obj&gt; as the reversed relation, e.g., &lt;sub&gt; co-founded the &lt;obj&gt; is converted to &lt;obj&gt; cofounded the &lt;sub&gt;.</p><p>For the experiments of MetaQA, we set the step number T = 3. We used bi-directional GRU <ref type="bibr" target="#b5">(Chung et al., 2014)</ref> as the question encoder, and set the hidden dimension as 1024. The projecting function f t was a stack of linear layer and Tanh layer. The involved MLPs were implemented as simple linear layers. For the text form, we used another bi-directional GRU as the relation encoder. The threshold τ was set to 0.7 and ω was set to 400. Since the question hop is provided in MetaQA, we used the golden hop number as an auxiliary objective to help learn the hop distribution c. We computed the cross entropy loss and added it into Equation 7 after multiplying a factor of 0.01. The model was optimized using RAdam <ref type="bibr" target="#b17">(Liu et al., 2020)</ref> with a learning rate 0.001 for 20 epochs, which took several hours for the label form and about one day for the text form on a single GPU of NVIDIA 1080Ti.</p><p>For the experiments of WebQSP and Comp-WebQ, we set the step number T = 2. We used a pretrained BERT <ref type="bibr" target="#b7">(Devlin et al., 2018)</ref> as the question encoder and finetuned its parameters on our task. There is no hop annotations so we did not use the auxiliary loss. Other settings are the same as MetaQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>MetaQA WebQSP CompWebQ 1-hop 2-hop 3-hop KVMemNN <ref type="bibr" target="#b18">(Miller et al., 2016)</ref> 95.8 25.1 10.1 46.7 21.1 VRN <ref type="bibr" target="#b34">(Zhang et al., 2017)</ref> 97.5 89.9 62.5 --GraftNet <ref type="bibr" target="#b25">(Sun et al., 2018)</ref> 97.0 94.8 77.7 66.4 32.8 PullNet <ref type="bibr" target="#b24">(Sun et al., 2019)</ref> 97.0 99.9 91.4 68.1 47.2 SRN <ref type="bibr" target="#b20">(Qiu et al., 2020)</ref> 97 Table <ref type="table">3</ref>: Hits@1 results on MetaQA of the text form and mixed form. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results on Label-Formed Graph</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on Text-Formed Graph</head><p>In Table <ref type="table" target="#tab_2">2</ref>  Besides the pure text form, we also compare the mixed form following <ref type="bibr" target="#b25">(Sun et al., 2018</ref><ref type="bibr" target="#b24">(Sun et al., , 2019))</ref>. That is, randomly selecting 50% of the label-formed triples and add them into the text-formed relation graph. In this setting, we simply consider the predicates as sentences containing just one word, and use the relation encoder (see Sec.3.5.2) to process them. These 50% labels slightly improve the performance of TransferNet over the pure text form (about 0.4%), because some relations are missing in the text corpus. Compared with PullNet, Trans-ferNet is still in the lead by a large gap (85.2% v.s. 94.7%).</p><p>Step 0 topic entity</p><p>Step 1</p><p>Step 2</p><p>Step 3 answer entity who acted in the movies directed by the director of Some Mother's Son Table <ref type="table">4</ref>: Ablation study on MetaQA. We show the average hits@1 of different hops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study</head><p>Table <ref type="table">4</ref> shows results of ablation study. We can see that the score truncation and language mask are both important, especially for the text form. As stated in Sec. 3.4, the language mask is not needed in the label form. The auxiliary loss (see Sec. 4.3) slightly improves the performance because it helps the learning of hop attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Interpretability</head><p>We visualize the intermediate results of Transfer-Net for two 3-hop questions in Figure <ref type="figure">3</ref>. The entities and relations whose score is larger than 0.8 are highlighted in red. The top question is aimed at the label-formed relation graph. The activated predicates for three hops are directed_by, directed_by_rev, and starred_actors respectively, where the suffix _rev means reverse relation. The bottom question is aimed at the text form. At step 1, TransferNet tries to find the screenwriter of the topic movie, and activates the relation whose tex-tual description is "based on the novel of the same name by &lt;obj&gt;". At step 2, the movie written by Harold Bell Wright is found. At step 3, we aim to find the movie's release year. But since the text descriptions of Western (which is the movie's genre) and 1926 are very similar, both of these two entities are activated. Here the proposed language mask successfully filters the wrong answers out. Figure <ref type="figure" target="#fig_3">4</ref> shows the average hits@1 on the label form of MetaQA when the models are trained with partial training examples (left) and at different epochs (right). We can see that TransferNet is very data-efficient and converges very fast. With only 10% training data, it still achieves the same performance as the entire training set. And it only needs two epochs to reach the optimal results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Model Efficiency</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We proposed TransferNet, an effective and transparent framework for multi-hop QA over knowledge graph or text-formed relation graph. It achieved 100% accuracy on 2-hop and 3-hop questions of label-formed MetaQA, nearly solving the dataset. On the more challenging WebQSP, CompWebQ and text-formed MetaQA, it also outperforms other state-of-the-art models significantly. Qualitative analysis shows the good interpretability of Trans-ferNet.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>g o J n e I U 3 5 8 l 5 c d 6 d j / l o y S l 2 D u E P n M 8 f 0 G + S r w = = &lt; / l a t e x i t &gt; a0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L e e B p V Z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The framework of TransferNet (top) and example of reasoning process (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison of data efficiency (left) and convergency speed (right) on label-formed MetaQA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Table 1 lists the statistics of these datasets. Dataset statistics.</figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell>MetaQA 1-hop</cell><cell>96,106</cell><cell>9,992</cell><cell>9,947</cell></row><row><cell cols="4">MetaQA 2-hop 118,948 14,872 14,872</cell></row><row><cell cols="4">MetaQA 3-hop 114,196 14,274 14,274</cell></row><row><cell>WebQSP</cell><cell>2,998</cell><cell>100</cell><cell>1,639</cell></row><row><cell>CompWebQ</cell><cell>27,623</cell><cell>3,518</cell><cell>3,531</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Hits@1 results of the label-formed datasets. TransferNet achieves 100% accuracy in the 2-hop and 3-hop questions of MetaQA. On WebQSP and CompWebQ it also outperforms baseline models by a large margin.</figDesc><table><row><cell></cell><cell>.0</cell><cell>95.1</cell><cell>75.2</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell>ReifKB (Cohen et al., 2020)</cell><cell>96.2</cell><cell>81.1</cell><cell>72.3</cell><cell>52.7</cell><cell></cell><cell>-</cell></row><row><cell>EmbedKGQA (Saxena et al., 2020)</cell><cell>97.5</cell><cell>98.8</cell><cell>94.8</cell><cell>66.6</cell><cell></cell><cell>-</cell></row><row><cell>TransferNet (Ours)</cell><cell>97.5</cell><cell>100</cell><cell>100</cell><cell>71.4</cell><cell></cell><cell>48.6</cell></row><row><cell>Model</cell><cell cols="6">MetaQA Text 1-hop 2-hop 3-hop 1-hop 2-hop MetaQA Text + 50% Label 3-hop</cell></row><row><cell>KVMemNN (Miller et al., 2016)</cell><cell>75.4</cell><cell>7.0</cell><cell>19.5</cell><cell>75.7</cell><cell>48.4</cell><cell>35.2</cell></row><row><cell>GraftNet (Sun et al., 2018)</cell><cell>82.5</cell><cell>36.2</cell><cell>40.2</cell><cell>91.5</cell><cell>69.5</cell><cell>66.4</cell></row><row><cell>PullNet (Sun et al., 2019)</cell><cell>84.4</cell><cell>81.0</cell><cell>78.2</cell><cell>92.4</cell><cell>90.4</cell><cell>85.2</cell></row><row><cell>TransferNet (Ours)</cell><cell>95.5</cell><cell>98.1</cell><cell>94.3</cell><cell>96.0</cell><cell>98.5</cell><cell>94.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>results with Sun et al. (2019) on the dev set. Trans-</cell></row><row><cell>ferNet achieves 48.6% accuracy, still better than</cell></row><row><cell>PullNet (47.2%).</cell></row><row><cell>compares different models on label-formed</cell></row><row><cell>datasets. TransferNet performs perfectly in the</cell></row><row><cell>2-hop and 3-hop questions of MetaQA, that is,</cell></row><row><cell>achieving 100% accuracy. As for the 1-hop ques-</cell></row><row><cell>tions of MetaQA, TransferNet achieves 97.5%, on</cell></row><row><cell>a par with previous models like VRN and Embed-</cell></row><row><cell>KGQA. We analyze the wrong cases of 1-hop and</cell></row><row><cell>find that the errors are caused by the ambiguity of</cell></row><row><cell>entities. For example, the question who acted in</cell></row><row><cell>The Last of the Mohicans asks the actors of the</cell></row><row><cell>movie The Last of the Mohicans. In the knowledge</cell></row><row><cell>graph there are two movies with this name, one re-</cell></row><row><cell>leased in 1936 and the other released in 1920. Our</cell></row><row><cell>model outputs the actors of both movies, whereas</cell></row><row><cell>the MetaQA dataset only considers the actors of the</cell></row><row><cell>1920 one as golden answer, causing an inevitable</cell></row><row><cell>mismatch. Previous work's performance should</cell></row><row><cell>also suffer from this dataset fault. In the ques-</cell></row><row><cell>tions of 2-hop and 3-hop, the ambiguity is mostly</cell></row><row><cell>eliminated by the relation restrictions. Therefore,</cell></row><row><cell>TransferNet can achieve 100% accuracy. We can</cell></row><row><cell>say that the label-formed MetaQA dataset has been</cell></row><row><cell>nearly solved by our TransferNet.</cell></row><row><cell>WebQSP is more challenging than MetaQA, be-</cell></row><row><cell>cause it has a much more predicates and triples yet</cell></row><row><cell>much less training examples. TransferNet achieves</cell></row><row><cell>71.4% accuracy, beating previous state-of-the-art</cell></row><row><cell>models (68.1%) by a large margin, implying that it</cell></row><row><cell>is well qualified for large-scale knowledge base.</cell></row><row><cell>On the CompWebQ dataset, we compare the</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>ub &gt; is a &lt;o bj&gt; Am er ica n W es ter n sil en t film dir ec ted by He nr y Ki ng 1926 the films that share screenwriters with The Shepherd of the Hills were released in which years Figure 3: Reasoning process of 3-hop questions. The top is in label form, where the suffix "_rev" means reverse relation. The bottom is in text form, where "mask" in blue means the language mask. We show the relation scores in purple and highlight the activated entities and relations (score &gt; 0.8) and words (score &gt; 0.05) in red.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Jim Sheridan</cell><cell></cell><cell></cell><cell>A Bright Shining Lie</cell><cell>Bill Paxton</cell></row><row><cell>Some Mother's Son</cell><cell></cell><cell>directed_by wr itt en _b y</cell><cell cols="2">0.01 0.99</cell><cell>Terry George</cell><cell>d ir e ct e d _ b y_ re v directed_by_rev</cell><cell cols="2">1.00 Reservation Road 1.00</cell><cell>starred_actors rele ase _ye ar starred_actors</cell><cell>1998 Joaquin Phoenix 1.00 0.00 1.00</cell></row><row><cell></cell><cell cols="2">written_by st ar re d_ ac to rs</cell><cell cols="2">0.01 0.00</cell><cell>Helen Mirren</cell><cell>di re ct ed _b y_ re v</cell><cell cols="2">Hotel Rwanda 1.00</cell><cell>starred_actors ha s_ ge nre</cell><cell>1.00 0.00</cell><cell>Don Cheadle Drama</cell></row><row><cell>Question</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">who acted in the movies directed by the director of Some Mother's Son</cell><cell>who acted in the movies directed by the director of Some Mother's Son</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>John Wayne</cell><cell></cell><cell></cell><cell>Track of the Cat</cell><cell>Western</cell></row><row><cell>The Shepherd of the Hills</cell><cell cols="3">based on the novel of the same name by &lt;obj&gt; &lt;s ub &gt; is a 19 41 Am er ica n dr am a film sta rri ng &lt;o bj&gt; &lt;s ub &gt; is a &lt;o bj&gt; Am er ica n dr am a film</cell><cell cols="4">Harold Bell Wright 1941 &lt;obj&gt; is a &lt;sub&gt; twelve-chapter Republic Pictures film serial 0.01 based on the novel ''&lt;obj&gt;'' by &lt;sub&gt;, the film is about an &lt;obj&gt; was produced by &lt;sub&gt; and Robert Fellows 0.03 0.99 engineer</cell><cell>The Winning of Barbara Worth Adventures of 0.02 Captain Marvel &lt;s ub &gt; is a 19 26 Am er ica n &lt;o bj&gt; sil en t 0.01 0.93 film dir ec ted by He nr y Ki ng 0.94 0.94</cell><cell>mask: 0 mask: 1</cell></row><row><cell>Question</cell><cell cols="5">the films that share screenwriters with The Shepherd of the Hills were</cell><cell cols="3">the films that share screenwriters with The Shepherd of the Hills were</cell></row><row><cell></cell><cell cols="4">released in which years</cell><cell></cell><cell cols="2">released in which years</cell></row><row><cell></cell><cell></cell><cell cols="5">Label Form Text Form</cell><cell></cell></row><row><cell>TransferNet</cell><cell></cell><cell cols="2">99.4</cell><cell></cell><cell>95.8</cell><cell></cell><cell></cell></row><row><cell cols="2">w/o score truncation</cell><cell cols="2">94.7</cell><cell></cell><cell>75.3</cell><cell></cell><cell></cell></row><row><cell cols="2">w/o language mask</cell><cell>-</cell><cell></cell><cell></cell><cell>62.1</cell><cell></cell><cell></cell></row><row><cell cols="2">w/o auxiliary loss</cell><cell cols="2">98.6</cell><cell></cell><cell>94.7</cell><cell></cell><cell></cell></row></table><note><p>&lt;s</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>https://github.com/shijx12/TransferNet</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work is supported by the <rs type="funder">NSFC Key Project</rs> (<rs type="grantNumber">U1736204</rs>), grants from the <rs type="funder">Institute for Guo Qiang, Tsinghua University</rs> (<rs type="grantNumber">2019GQB0003</rs>), <rs type="projectName">Beijing Academy of Artificial Intelligence</rs>, <rs type="person">Huawei Inc</rs>, and <rs type="grantNumber">MOE AcRF Tier 2</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_sEcQCyU">
					<idno type="grant-number">U1736204</idno>
				</org>
				<org type="funded-project" xml:id="_Mw3RV2G">
					<idno type="grant-number">2019GQB0003</idno>
					<orgName type="project" subtype="full">Beijing Academy of Artificial Intelligence</orgName>
				</org>
				<org type="funding" xml:id="_Z2f8Swd">
					<idno type="grant-number">MOE AcRF Tier 2</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<title level="m">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Haitian</forename><surname>William W Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName><surname>Siegler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06115</idno>
		<title level="m">Scalable neural methods for reasoning with a symbolic knowledge base</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cognitive graph for multi-hop reading comprehension at scale</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2694" to="2703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2368" to="2378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohit</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03631</idno>
		<title level="m">Hierarchical graph network for multi-hop question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dialog-to-action: Conversational question answering over a large-scale knowledge base</title>
		<author>
			<persName><forename type="first">Duyu</forename><surname>Daya Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Freebaseqa: a new factoid qa data set matching triviastyle question-answer pairs with freebase</title>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dekun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="318" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11942</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Forbus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the variance of the adaptive learning rate and beyond</title>
		<author>
			<persName><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1400" to="1409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Simplequestions nearly solved: A new upperbound and baseline approach</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Petrochuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="554" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stepwise reasoning for multi-relation question answering over knowledge graph with weak supervision</title>
		<author>
			<persName><forename type="first">Yunqi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhuo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="474" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Complex program induction for querying knowledge bases in the absence of gold programs</title>
		<author>
			<persName><forename type="first">Amrita</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ghulam</forename><surname>Ahmed Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Laddha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving multi-hop question answering over knowledge graphs using knowledge base embeddings</title>
		<author>
			<persName><forename type="first">Apoorv</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditay</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="4498" to="4507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pullnet: Open domain question answering with iterative retrieval on knowledge bases and text</title>
		<author>
			<persName><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tania</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2380" to="2390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Open domain question answering using early fusion of knowledge bases and text</title>
		<author>
			<persName><forename type="first">Haitian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathryn</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="4231" to="4242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="641" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Select, answer and explain: Interpretable multi-hop reading comprehension over multiple documents</title>
		<author>
			<persName><forename type="first">Ming</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guangtao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="9073" to="9080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Wikidata: a free collaborative knowledge base</title>
		<author>
			<persName><forename type="first">Denny</forename><surname>Vrandečić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Enhancing key-value memory neural networks for knowledge based question answering</title>
		<author>
			<persName><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2937" to="2947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1321" to="1331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jina</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04071</idno>
		<title level="m">Variational reasoning for question answering with knowledge graph</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09694</idno>
		<title level="m">Retrospective reader for machine reading comprehension</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Transformer-xh: Multi-evidence reasoning with extra hop attention</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Corby</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Simple question answering with subgraph ranking and joint-scoring</title>
		<author>
			<persName><forename type="first">Wenbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tagyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anuj</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angeliki</forename><surname>Metallinou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="324" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">An interpretable reasoning network for multirelation question answering</title>
		<author>
			<persName><forename type="first">Mantong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
