<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The neuroelectric dynamics of the emotional anticipation of other people&apos;s pain</title>
				<funder ref="#_k5ZKvTW">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2018-08-01">August 1, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Dorian</forename><surname>Dozolme</surname></persName>
							<email>dozolmedorian@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CIAMS</orgName>
								<orgName type="institution" key="instit2">Univ. Paris Sud</orgName>
								<orgName type="institution" key="instit3">Universite ´Paris-Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CIAMS</orgName>
								<orgName type="institution">Universite ´d&apos;Orle ´ans</orgName>
								<address>
									<addrLine>Orle ´ans</addrLine>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elise</forename><surname>Prigent</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">LIMSI</orgName>
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">Univ. Paris-Sud</orgName>
								<orgName type="institution" key="instit3">Universite ´Paris-Saclay</orgName>
								<address>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yu-Fang</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CIAMS</orgName>
								<orgName type="institution" key="instit2">Univ. Paris Sud</orgName>
								<orgName type="institution" key="instit3">Universite ´Paris-Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CIAMS</orgName>
								<orgName type="institution">Universite ´d&apos;Orle ´ans</orgName>
								<address>
									<addrLine>Orle ´ans</addrLine>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michel-Ange</forename><surname>Amorim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CIAMS</orgName>
								<orgName type="institution" key="instit2">Univ. Paris Sud</orgName>
								<orgName type="institution" key="instit3">Universite ´Paris-Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">CIAMS</orgName>
								<orgName type="institution">Universite ´d&apos;Orle ´ans</orgName>
								<address>
									<addrLine>Orle ´ans</addrLine>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Universita degli Studi di Udine</orgName>
								<address>
									<country key="IT">ITALY</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The neuroelectric dynamics of the emotional anticipation of other people&apos;s pain</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-08-01">August 1, 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1371/journal.pone.0200535</idno>
					<note type="submission">Received: October 4, 2017 Accepted: June 28, 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T01:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When we observe a dynamic emotional facial expression, we usually automatically anticipate how that expression will develop. Our objective was to study a neurocognitive biomarker of this anticipatory process for facial pain expressions, operationalized as a mismatch effect. For this purpose, we studied the behavioral and neuroelectric (Event-Related Potential, ERP) correlates, of a match or mismatch, between the intensity of an expression of pain anticipated by the participant, and the intensity of a static test expression of pain displayed with the use of a representational momentum paradigm. Here, the paradigm consisted in displaying a dynamic facial pain expression which suddenly disappeared, and participants had to memorize the final intensity of the dynamic expression. We compared ERPs in response to congruent (intensity the same as the one memorized) and incongruent (intensity different from the one memorized) static expression intensities displayed after the dynamic expression. This paradigm allowed us to determine the amplitude and direction of this intensity anticipation by measuring the observer's memory bias. Results behaviorally showed that the anticipation was backward (negative memory bias) for high intensity expressions of pain (participants expected a return to a neutral state) and more forward (memory bias less negative, or even positive) for less intense expressions (participants expected increased intensity). Detecting mismatch (incongruent intensity) led to faster responses than detecting match (congruent intensity). The neuroelectric correlates of this mismatch effect in response to the testing of expression intensity ranged from P100 to LPP (Late Positive Potential). Path analysis and source localization suggested that the medial frontal gyrus was instrumental in mediating the mismatch effect through top-down influence on both the occipital and temporal regions. Moreover, having the facility to detect incongruent expressions, by anticipating emotional state, could be useful for prosocial behavior and the detection of trustworthiness.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Humans possess the capacity of automatically and unconsciously anticipating the following movement of an observed movement that could be an object <ref type="bibr" target="#b0">[1]</ref>, a scene <ref type="bibr" target="#b1">[2]</ref>, a body or a facial expression <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. Indeed, individuals can perceive the facial expressions of other people in order to gain an immediate impression of another individual's current and future emotional state of mind <ref type="bibr" target="#b5">[6]</ref>. The processes used are highly adaptive to meet the demands of a world in which we are constantly required to react to, and often anticipate, the behavior of others <ref type="bibr" target="#b6">[7]</ref>. We have chosen to focus on the perception of pain behavior in other people since the ability to recognize and interpret other people's pain quickly can be of great importance to both the person who is suffering and the observer <ref type="bibr" target="#b7">[8]</ref>. In addition, it is critical to everyday social functioning <ref type="bibr" target="#b8">[9]</ref>.</p><p>Pain is both a specific sensation (i.e., a reflexive reaction of the body) and an emotional state <ref type="bibr" target="#b9">[10]</ref>. Individuals who experience pain often adopt pain behaviors <ref type="bibr" target="#b10">[11]</ref>, either to attenuate their own pain (e.g., by touching or guarding) or to communicate pain to others (through words, sounds and facial expressions). Studies of the production of facial pain expressions have shown that they appear to be specifically adapted to social communication <ref type="bibr" target="#b11">[12]</ref> and have a survival function by demanding attention and prioritizing escape, recovery and healing <ref type="bibr" target="#b12">[13]</ref>. In fact, "suffering offers us the best protection for survival" <ref type="bibr" target="#b13">[14]</ref>. Moreover, perceiving the pain of others is also supported by a complex response in the observer's corticospinal system that may allow a freezing or escaping reaction <ref type="bibr" target="#b14">[15]</ref>. Studies of pain perception have highlighted that, in order to estimate other people's pain levels, individuals assign greater importance to facial expressions than to body language <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. In the same way, facial expressions are assigned a greater importance than verbal information in order to discriminate between genuine, suppressed and faked pain <ref type="bibr" target="#b17">[18]</ref>. That is why, among different pain behavior, we focused our study on the perception of facial pain expression behavior and we investigated the emotional anticipation of dynamic facial pain expressions from both a behavioral and neurocognitive approach.</p><p>The perception of facial expressions of emotion has mostly been studied with the use of static stimuli such as photographs; in real life, however, people's facial expressions of emotion are dynamic. Some studies have shown that facial expression recognition can be improved by employing dynamic (rather than static) information <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. The recognition of subtle (i.e., barely intense) dynamic facial expressions of emotion has proved more effective compared with the identification of subtle static facial expressions <ref type="bibr" target="#b20">[21]</ref>. This difference in perception between static and dynamic facial pain expressions may be explained by the human capacity to anticipate and extrapolate a dynamic movement, such as a dynamic facial expression <ref type="bibr" target="#b21">[22]</ref>.</p><p>People automatically anticipate the future of a movement, which implies memorization of the final position of a moving target often displaced forward in the direction of target motion. Such memory displacement or memory bias has been termed "representational momentum"; namely, a second-order isomorphism between physical and representational inertia <ref type="bibr" target="#b2">[3]</ref>. More specifically, the memorized intensity of an emotional facial expression may obey such a memory bias effect. Yoshikawa and Sato <ref type="bibr" target="#b3">[4]</ref> reported a forward representational momentum effect for dynamic facial expressions of fear, joy, disgust, sadness, anger and surprise (ranging from neutral to maximal emotional intensity), with a memorized intensity superior to the final intensity displayed by the participant (associated to a positive memory bias). However, memory displacements may also be backward and oriented toward the emotionally neutral state (associated to a negative memory bias) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. Some authors have shown additional evidence relating to representational momentum when perceiving facial expressions of emotion <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b24">25]</ref>. When investigating dynamic facial expressions from emotional to neutral, they found that final neutral expressions were judged as presenting an emotional valence opposite to the initial one. For example, Jellema et al. <ref type="bibr" target="#b24">[25]</ref> reported that when an expression, that moved backward from joy to neutral, was presented and disappeared, the final neutral expression remembered was a slightly angry one. On the other hand, an expression that moved backward from anger to neutral was remembered as being slightly happy. These findings were interpreted in terms of "emotional anticipation", which can be defined as the ability to involuntarily anticipate how an agent's emotional state of mind will develop in the immediate future, based on the immediate perceptual history. This emotional anticipation may reflect top-down emotional processes <ref type="bibr" target="#b24">[25]</ref> and constitute a low-level form of the mind-reading mechanism <ref type="bibr" target="#b5">[6]</ref>. According to embodiment and simulation theories, the perception of other people's facial expressions <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>, specifically those of pain <ref type="bibr" target="#b27">[28]</ref>, is associated with automatic and unconscious processes such as the involuntary motor simulation of the observed action. Accordingly, other lines of research have investigated neural correlates of emotional anticipation of the pain of others, by using different physiological techniques, such as single pulse TMS (transcranial magnetic stimulation) to induce MEPs (motor-evoked potentials). Some of these studies <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref> evidenced inhibition of specific MEPs while viewing a needle hurting a human body part, compared to non-painful conditions. Such an inhibition while viewing a painful stimulus on others supports the "mirror-matching" simulation theory. It is worth noting that these authors did not study pain expressions but painful stimuli on a body part. However, another study <ref type="bibr" target="#b31">[32]</ref> reported a similar MEP inhibition while using fearful, happy and neutral body expressions as stimuli. Finally, the sensorimotor structures involved in empathy for pain were also investigated using somatosensory-evoked potentials (SEPs). For example, Bufalary et al. <ref type="bibr" target="#b32">[33]</ref> administered non-painful electrical stimulations to one of the participants' hands while stimuli similar to the one used by Avenanti et al. <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref> and Bucchioni et al. <ref type="bibr" target="#b30">[31]</ref> were displayed. SEPs recorded from the primary somatosensory cortex (S1) showed an increased P45 component (reflecting activity in S1) while participants viewed the painful stimuli, whereas the SEP decreased while they viewed (touched) non-painful stimuli. These results suggest that S1 might contribute to the "mirror-matching" simulation of the pain of others. Neurocognitive literature has emphasized the distributed nature of the areas of the brain which contribute to facial perception. Changeable features, such as facial expressions, relate to visual codes in the Superior Temporal Sulcus (STS). They also involve the fronto-parietal activation of emotion representation and motor programs in the mirror neuron system responsible for producing expressions <ref type="bibr" target="#b33">[34]</ref>. In relation to expressions of pain, Reicherts et al. <ref type="bibr" target="#b34">[35]</ref> used ERPs to support the idea of the prioritized processing (with enhanced Late Positive Potentials, LPPs) of painful dynamic facial expressions when compared with joyful (and possibly fearful) dynamic expressions, as well as neutral dynamic expressions. The perception of dynamic facial expressions triggers automatic low-level processes involved in the prediction of forthcoming expressions <ref type="bibr" target="#b24">[25]</ref>. There is evidence that dynamic facial expressions are represented as anticipated motion trajectories in the visual (fusiform gyrus, STS) and premotor areas <ref type="bibr" target="#b35">[36]</ref>, with their post-stimulus onset as early as 165 ms to 237 ms. These findings, as well as those regarding mirror-matching in sensorimotor brain areas, are consistent with the 'extended' mirror neuron system proposed by Pineda <ref type="bibr" target="#b36">[37]</ref> containing shared representations for action and emotion, automatically retrievable during the observation of others.</p><p>In our study, we conducted behavioral measures and ERPs to investigate the neurocognitive mechanisms involved in the emotional anticipation of facial expressions of pain. For this, we used a representational momentum paradigm inspired by the work of Courgeon et al. <ref type="bibr" target="#b22">[23]</ref> and Thornton <ref type="bibr" target="#b23">[24]</ref>. In this paradigm, a static expression was displayed after a dynamic expression (video), separated by a mask. Participants had to memorize the final intensity of the dynamic expression (the last frame of the video) and compare it to a static test expression intensity (Tes-tEI). As previously mentioned, by using this paradigm, if a memory bias of the final expression intensity is measured, it supposes the participant's automatic anticipation of the immediate future of the expression. In a preliminary experiment (see S1 File), we measured this memory bias (amplitude of the anticipation) for each participant. This allowed us, in the present study, to adapt static test expression intensity (TestEI) as a function of the participants' memory bias, by displaying either TestEI equal (congruent trials) or different (incongruent trials) from the intensity memorized, and therefore anticipated, by the participant. So, independently of the anticipation amplitude of the future of the expression, we displayed a static expression intensity (TestEI) to the participant, congruent or incongruent to the intensity they were expecting. In other words, a static expression different from the expected intensity can be considered as an incongruent intensity, and a static expression equal to the expected intensity can be considered as a congruent intensity by the participant. Our objective was to study a neurocognitive biomarker of anticipatory processes for facial pain expressions, operationalized as a mismatch effect (i.e., difference in ERP between congruent and incongruent trials). Our hypothesis here was that, even if participants were instructed to memorize the state of a dynamic expression at the end of the video, rather than anticipate how the expression would develop, pain anticipation mechanisms were expected to modulate both behavioral (Reaction Time, RT) and physiological (ERP) correlates of mismatch detection when the memorized state of the dynamic expression was to be compared with a static image of pain expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>The ERP data of 25 individuals (15 women, 10 men; M = 24.5 years-old, SD = 4.8) participating in a preliminary behavioral study (see S1 File for details), were analyzed.</p><p>Participants had normal or corrected-to-normal vision. All participants gave informed written consent before the experiment, in accordance with the ethical standards of the Declaration of Helsinki. The EA 4532 local Ethics Committee of Paris-Sud University approved this study for both experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>A facial expression is characterized by the type and number of facial muscles contracted and the intensity with which they contract <ref type="bibr" target="#b37">[38]</ref>. The Facial Action Coding System, known as FACS <ref type="bibr" target="#b37">[38]</ref>, provides a framework for the description of facial expressions in terms of Action Units of the face (AUs). An observable AU results from the contraction of one or a group of muscle(s) and the different facial expressions that result from the activation of one or several AU(s). The facial expression of pain recruits three main AUs: AU 4, which corresponds with brow lowering; AUs 6 and 7, which correspond with orbit tightening; and AUs 9 and 10, which correspond with levator contraction <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>. In the present study, we used a facial expression of pain that requires the activation of the following facial AUs: AU 4, AUs 6 and 7, and AUs 9 and 10.</p><p>Dynamic stimuli were created with the help of realistic 3D synthetic facial movements, aimed at mobilizing specific Action Units (AUs) of pain, using 3ds Max 2010 1 software. A virtual character was imported from the Poser 8 1 software library. For this virtual character, a dynamic facial expression of pain was created, which recruited five principal AUs of pain, based on the FACS <ref type="bibr" target="#b37">[38]</ref>. In accordance with Oliveira et al. <ref type="bibr" target="#b39">[40]</ref>, these AUs were: brow lowering (AU 4), cheek raise (AU 6), lid tightening (AU 7), nose wrinkling (AU 9) and upper raise (AU 10). We created a facial pain expression composed of all five AUs with an intensity of 100% (see <ref type="bibr">Fig 1)</ref>, which was arbitrarily defined and considered as a naturally high facial pain expression (according to Ekman &amp; Friesen <ref type="bibr" target="#b37">[38]</ref> model). Using 3ds Max 2010 1 software, we carried out morphing in equal stages to create the intermediary intensities between neutral expression (by default in the software) and 100% intensity. Two videos of two different intensities were generated: 50% and 90% of Emotional Intensity (EI). These two videos corresponded to the VideoEI50% and VideoEI90% conditions used in both the preliminary and main experiments. Static expressions were also created at different pain intensities, from 10% to 130%, which corresponded to the Test Expression Intensity (TestEI). We set 100% as the maximal natural expression intensity target; thus, TestEIs greater than 100% gave more caricatured expressions.</p><p>TestEIs were defined on an individual basis in a preliminary experiment (See S1 File). For each participant, three TestEI triplets of stimuli (see  condition. Assuming that the PSE in both experiments would be equal, we expected one "Expected Congruent TestEI" triplet to be perceived as being of a similar intensity to that of the final video: it was centered on the participants' PSE, and included the PSE, PSE +5% and PES -5% TestEIs of the preliminary experiment (Figure A in S1 File). In contrast, the "Expected Incongruent TestEIs" triplets (either smaller or greater than PSE by an amount of 30%, 35% and 40%) were expected to be perceived as different with respect to their memorized intensity in the main experiment.</p><p>All stimuli (i.e., videos and static images) were made up of 150 x 150 pixels and displayed on a 1024 x 768 pixels 60 Hz screen at a 57 cm viewing distance. They subtended a 4˚x 4v isual angle. TestEIs could differ between participants because they were selected as a function of the individuals' memory bias, as measured in a preliminary experiment (see S1 File for more details). There were eight repetitions per TestEI and video, resulting in a total of 144 trials (i.e., 8 repetitions � 9 TestEIs � 2 EIs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>This experimental trial sequence, adapted from the one used by Courgeon et al. <ref type="bibr" target="#b22">[23]</ref> and Thornton <ref type="bibr" target="#b23">[24]</ref>, is typical of representational momentum paradigms <ref type="bibr" target="#b2">[3]</ref>. As illustrated in Fig <ref type="figure">2</ref>, each trial started with a written message that remained on the screen for 2000 ms. This instruction invited the participants to blink and was aimed at preventing blinking during the trial itself. It was followed by a black screen, for a random duration of 800 to 1200 ms, and then by a fixation cross, for a random duration of 800 to 1200 ms. Randomization was used to prevent participants from anticipating the beginning of the videos. This was particularly crucial to avoid the build-up of a Contingent Negative Variation in the baseline (pre-stimulus) period, before the oncoming emotional event <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>. A 500 ms static neutral expression was then displayed, followed by a dynamic expression of pain, i.e., a 117 ms video for the VideoEI50% condition and a 200 ms video for the VideoEI90% condition. The video was followed by a 267 ms mask (a pixelated face) and then a TestEI stimulus, which was displayed until each participant had responded. The participants had to estimate whether the TestEI was "equal to" or "different from" the final VideoEI. They had to answer by pressing the corresponding keyboard key (different = escape; equal = Enter). If reaction time to the TestEI exceeded 5 s, a "Wake up!" message was displayed and a beep signal sounded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EEG recording and processing</head><p>All the experiments were conducted in the same lab and in exactly the same environmental conditions. EEG recordings were carried out using the BrainAmp system with active Ag-AgCl electrodes (ActiCap). Six of the twenty-five participants, (see 2.1 Participants section for details) wore a 32-electrode cap, whereas the remaining 19 participants wore a 64-electrode cap. The change in cap type came after the upgrading of our EEG system from 32 to 64 channels a few weeks after the beginning of our experiment. Both 32-and 64-electrode positions conformed to the 10-20 system. In order to avoid mixing data from 32 electrodes with data from 64 electrodes, only the channels corresponding to the 32-electrode cap for all analyses were kept. Recordings were made using the Brainvision Recorder at a 1000 Hz sample rate; no filter was applied during data acquisition. The FCz electrode was used as an electrical reference. All electrode impedances were no greater than 20 kO.</p><p>Brainvision Analyzer 2 was used to process data. Band pass filters were applied to EEG data (0.1-30 Hz, 12 dB/Octave). Then, data were segmented into periods that ranged from -1313 to 720 ms with respect to the TestEI display onset. Semi-automatic artifact rejection was used to remove data with artifacts: namely, a gradient greater than 50 μV/ms, a difference (maximum) greater than an interval of 200 μV per 200 ms, and activity of less than an interval of 0.5 μV per 100 ms. Trials with ocular artifacts were also rejected during this process. The mismatch effect could manifest itself in the LPP component (i.e., up to 700 ms post-onset TestEI); the trials during which participants responded in less than 700 ms were therefore removed from our analysis. Trials were then baseline corrected, with a reference baseline taken between -1313 and -1213 ms pre-TestEI; that is to say, during the fixation point pre-video period. For each participant, data from the two video EIs were pooled in order to have enough data per congruity condition (i.e., TestEIs judged as congruent or incongruent with respect to the final video intensity). Finally, trials were averaged for each condition and participant. Note that the ERPs' time-values were corrected in order to consider the 13 ms latency of the display.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis</head><p>Behavioral data. We conducted two behavioral data analyses, with two complementary objectives: a) determined participants' individual PSE; and b) determined congruent and incongruent TestEI trials with respect to the participants' PSE, on an individual basis (see Fig <ref type="figure" target="#fig_2">3</ref> for an example). First, we computed the PSE values per VideoEI condition, for each participant, using a logistic probability density function fitted to the proportion of "equal" answers as a function of the TestEIs. The PSE provided an estimate of the TestEI stimuli, for which participants would answer "equal" with a probability of 1. The PSE was an estimation of the memorized intensity of the last frame of the video. With regard to statistical analysis, we conducted Student's t tests on the individuals' memory bias (see section Results for the results).</p><p>The second aim of this behavioral data analysis was to identify the trials which corresponded to TestEIs perceived as congruent or incongruent with respect to the memorized final EI (PSE) of each participant. This data would be used for the subsequent ERP analysis. In fact, our objective was to compare ERPs in response to the TestEIs which were perceived as equal to the memorized final EI (congruent TestEI) with ERPs in response to TestEIs that were perceived as different from the memorized final EI (incongruent TestEI). Therefore, the proportion of "equal" responses very seldom reached 1 for the TestEIs that were close to the PSE2, and symmetrically, did not always reach 0 for the TestEIs that were furthest from the PSE2. For this reason, on the basis of individual data, we identified the TestEIs that led to a proportion of "equal" responses superior to 60%, as "PSE congruent TestEIs" (see Fig <ref type="figure" target="#fig_2">3</ref>: continuous line square). In contrast, we identified the TestEIs that had a proportion of "equal" responses inferior to 40%, as "PSE incongruent TestEIs" (Fig 3 : dashed line square). In the example illustrated in Fig <ref type="figure" target="#fig_2">3</ref>, the proportion of "equal" responses given to TestEI60% by the participants was approximately 0.9. Eight repetitions of TestEI60% stimulus were carried out; of these, a response of "different" was recorded only once. Thus, we did not keep this trial as a "PSE congruent TestEI". For the subsequent ERP analysis, we therefore only kept trials in which participants responded "equal" for the "PSE congruent TestEIs" and "different" for the "PSE incongruent TestEIs". Most importantly, for the ERP analysis, we set a minimum of 30 trials per studied condition.</p><p>After this, an average of 45.9 trials were available to each participant in the congruent condition. We kept 38.4 trials (15.82% of those rejected were due to artifacts and &lt; 700 ms responses). Similarly, of the 61 trials available on average in the incongruent condition after applying the initial behavioral criterion, we kept 47.4 trials per participant (20.4% of those rejected were due to artifacts and &lt; 700 ms responses). Although we had more incongruent elementary trials (n = 61) than congruent trials (n = 45.9) for the ERP analysis (t(24) = 3.72, p = .001), the rejection rates due to artifacts and &lt; 700 ms responses did not significantly differ between the two conditions (t(24) = 1.85, p = .08).</p><p>Existing psychophysics literature has shown greater RTs in response to stimuli close to PSEs <ref type="bibr" target="#b42">[43]</ref>. With regard to the mismatch effect, in order to confirm that incongruent stimuli were easier to detect, we tested whether reaction time to congruent trials was greater than to incongruent trials (see section Results for results).</p><p>Event-related potentials (ERPs). Data from EEG electrodes were grouped into four functional anatomical regions of interest (ROIs): frontal (F), centro-parietal (CP), temporal (T) and occipital (O), as illustrated in Fig 4 . The occipital and temporal regions are known to be associated with the P100 and N170 ERPs, concomitant with visual (and especially face) processing <ref type="bibr" target="#b43">[44]</ref>. With regard to the centro-parietal and frontal regions, they are supposed to be sensitive to higher level processes such as context integration (reflected by the N400 ERP <ref type="bibr" target="#b44">[45]</ref>). ERP post-onset TestEI data were analyzed using the averaged signal amplitude of three subsequent but non-overlapping time windows: [50-140 [ms for the P100 ERP; [140-330 [ms for the N170 ERP; and [330-700] ms for the LPP ERP. Indeed, instead of performing a point by point analysis in the time domain or analyzing ERP peaks, we performed a time-window analysis which consisted in dividing waveforms into a series of time windows (see <ref type="bibr" target="#b45">[46]</ref>). Accordingly, in our statistical analyses, there was only one data point per time window and for each "congruity x ROI x hemisphere" cell. This point corresponded to the average signal in a given time window and condition.</p><p>Source localization analysis was performed for each brain wave component using the LOR-ETA transform function of BrainAnalyzer (Low Resolution Electromagnetic Tomography <ref type="bibr" target="#b46">[47]</ref>) which computes the full three-dimensional current density distribution (the current density field). Through this analysis, it was possible to estimate the neurocognitive sources of the previously identified ERPs.</p><p>The modulation of ERP by congruity (between TestEI and memorized expression intensity) was examined using both MANOVAs (multivariate analyses of variance) and ANOVAs (univariate analyses of variance) on the mean amplitude value (μV), as recommended by <ref type="bibr" target="#b47">[48]</ref> for testing repeated measure effects in psychophysiological data. We provide MANOVA results together with Wilks' lambda (Wilks' Λ), and ANOVA results with η 2 p (partial eta squared). Wilks' Λ is the multivariate counterpart of 1-η 2 for univariate variables (see <ref type="bibr" target="#b48">[49]</ref>). It provides a measure of the proportion of variance in the combination of dependent variables unaccounted for by a factor. In contrast, η 2 is a measure of effect size in terms of proportion of variance explained by a factor. The p values for ANOVAs were corrected, when appropriate, using the Greenhouse-Geisser correction, as recommended by <ref type="bibr" target="#b49">[50]</ref>. Post-hoc pairwise comparisons were assessed by means of planned comparisons with a significance threshold corrected with the use of the Bonferroni criterion (α = .05 / n comparisons). Furthermore, p values were considered as significant up to .05 and marginally significant between .05 and .10. Significant or marginally significant differences in the amplitude of the ERPs between the incongruent and the congruent condition were termed the "mismatch effect". Only significant or marginally significant effects would be reported.</p><p>Finally, mediation models of the mismatch effect were tested with path analysis using PRO-CESS v2.13, a macro created by <ref type="bibr" target="#b50">[51]</ref> for SPSS. Bias-corrected bootstrap 95% confidence intervals were constructed with 10,000 samples (i.e., bootstrap estimates of the indirect effect) for testing the indirect effects. Confidence intervals that do not contain zero support the conclusion that the indirect effect has reached a "statistically significant" degree (see <ref type="bibr" target="#b50">[51]</ref>, 2013, p.109). In contrast, according to <ref type="bibr" target="#b50">[51]</ref>, (p.158): "The fact that a confidence interval for an effect contains zero does not mean the effect is zero. It merely means that zero is in the realm of possibility, or that one cannot say with certainty what the direction of the effect is." Bootstrap confidence intervals (BootCI) will be provided between parentheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral data</head><p>We found a significant negative memory bias (i.e., a bias significantly different from 0) in the VideoEI50% condition (-8.6%, SD = 17.2%, ranging from -45.4% to +18.9%), t(24) = 2.5, p = .02, and in the VideoEI90% condition (-20.4%, SD = 21.3%, ranging from -75.2% to +3.7%), t(24) = 4.7, p = .00009. Memory displacement (bias values) varied with VideoEI conditions (50% and 90%), t(24) = 5.1, p = .00003. Variances of bias values among both VideoEI conditions were not significantly different (Fisher's test, F(1, 24) = .65, Var VideoEI50% = 307.2, Var VideoEI90% = 471.8, p = .15). This analysis allowed us to average the two VideoEI conditions in the ERP analysis of the mismatch effect.</p><p>Further analysis of the behavioral data was conducted using reaction time data in order to test our hypothesis that incongruent stimuli are more easily detected than congruent stimuli (see the end of the Behavioral data subsection, in the Data analysis section). An ANOVA with two factors (VideoEI × congruity) confirmed our hypothesis, with a significant main mismatch effect on participants' reaction times, F(1, 24) = 8.7, p = .007, (M congruent = 1263.5 ms, M incongruent = 1180.0 ms), together with no significant effect of VideoEI, and no significant interaction between VideoEI and congruity. Three ERP components were evoked by TestEI onsets. We identified the first component as a P100 wave, peaking in the O ROI, around 100 ms after the stimulus onset. We only found a marginal mismatch effect on this wave (details are presented hereafter). The second component was a N170 wave, peaking in the O ROI around 230 ms after face onset. This wave presented a greater deflection in the right hemisphere than in the left.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event-related potentials (ERP)</head><p>Lastly, we identified an LPP wave, peaking around 500 ms post TestEI onset. The amplitude of this wave was left lateralized in the T ROI. The LPP deflection was also reduced for incongruent trials in all ROIs. LORETAs, presented in Fig <ref type="figure">7</ref>, illustrate the posterior-lateral distribution of the neural generators of the three waves, with a tendency to be distributed more anteriorly for the mismatch effect at the LPP wave.</p><p>Multivariate and univariate analyses. An initial MANOVA was performed in which mean μV values extracted from each ROI (Frontal, Centro-Parietal, Temporal, and Occipital) were considered as different dependent variables, with a time window (P100, N170, LPP), congruity (2), and a hemisphere (2 for each ROI) as within-subject factors. the lines of <ref type="bibr" target="#b45">[46]</ref>, instead of conducting a series of independent tests, we included time windows as a factor in a single statistical test. Note that the size of each time window does not need to be constant (see <ref type="bibr" target="#b45">[46]</ref>, p.48).</p><p>The MANOVA results are summarized in Table <ref type="table" target="#tab_0">1</ref>. The main, interesting MANOVA effect, handling ROIs altogether simultaneously, was that the mismatch effect varied with the time window and brain hemisphere (p &lt; .005, see Table <ref type="table" target="#tab_0">1</ref>). Subsequent MANOVA follow-up results handling ROIs separately, showed a mismatch effect in the temporal and occipital regions (ps &lt; .05), and marginally in the frontal region (p &lt; .079). In addition, the results evidenced that the mismatch effect varied with the time window and brain hemisphere in the occipital region (p &lt; .01). Consequently, follow-up ANOVAs were conducted on data from the O ROI only, for each time window (P100, N170, LPP) separately, with congruity (2), and hemisphere (2 for each ROI) as within-subject factors.</p><p>The ANOVA on the P100 time window in the O ROI showed a marginal mismatch effect, F (1, 24) = 3.50, p = .07, η 2 p = .13, reflecting a greater deflection in response to congruent TestEIs (M congruent = -.70 μV; M incongruent = -1.48 μV). A significantly greater overall positive deflection in the right hemisphere was also evidenced, F(1, 24) = 4.78, p = .039, η 2 p = .17, (M Left hemisphere = -1.45 μV; M Right hemisphere = -.73 μV). However, the mismatch effect did not vary with the hemisphere, F(1, 24) &lt; 1, n.s.).</p><p>The ANOVA on the N170 time window in the O ROI showed a marginal mismatch effect, F(1,24) = 4.16, p = .05, η 2 p = .15, reflecting a greater deflection in response to incongruent TestEIs (M congruent = -4.53 μV; M incongruent = -5.55 μV). A significantly greater overall negative deflection in the right hemisphere was also evidenced, F(1, 24) = 5.99, p = .022, η 2 p = .20, (M left hemisphere = -4.60 μV; M right hemisphere = -5.48 μV). However, the mismatch effect did not vary with the hemisphere, F(1, 24) &lt; 1, n.s.).</p><p>Finally, the ANOVA on the LPP time window in the O ROI showed a marginal mismatch effect, F(1,24) = 4.11, p = .05, η 2 p = .15, reflecting a greater deflection in response to congruent TestEIs (M congruent = -2.90 μV; M incongruent = -3.83 μV). No effect of the brain hemisphere was evidence, F(1, 24) = 1.60, p &gt;.21. However, the mismatch effect varied significantly with the brain hemisphere, F(1, 24) = 4.70, p = .04, η 2 p = .16. Bonferroni-corrected planned comparisons showed a mismatch effect in the left hemisphere with a greater deflection in response to congruent TestEIs (M congruent = -2.59 μV; M incongruent = -3.74 μV), F(1, 24) = 6.98, p = .014 (p &lt; .05/2), but not in the right hemisphere, F(1, 24) = 2.06, p &gt; .16.</p><p>Individual differences. The distribution of the mismatch effect across the participants for the different ERP components (P100, N170, and LPP) can be visually appreciated via a scatterplot of the mean amplitude values of the incongruent trials over those of the congruent trials (see <ref type="bibr">Fig 8)</ref>, along the lines of <ref type="bibr" target="#b51">[52]</ref>. Here, we only examined individual differences in the ROIs showing a marginal or significant mismatch effect according to the MANOVA. We considered that when the paired observations (one dot per participant) fell on the unity line ± .50 μV, no mismatch effect was shown. Although .50 μV is an arbitrary criterion; our idea was to define values that could not be truly differentiated from 0. Note that this criterion is consistent with </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. Average ERPs, by congruity condition (with hemispheres combined).</head><p>Apart from the baseline, data recorded before the 0 ms time value (i.e., data recorded during the presentation of the dynamic facial expression and the mask) are presented for illustrative purposes only. Taking all time windows together, the mismatch effect was significant in the T (panel C) and O (panels D and E) ROIs. It was also marginally significant in the F ROI (panel A). In contrast, the mismatch effect in the O ROI varied across time windows. It showed marginally weaker P100 amplitude in the incongruent condition than in the congruent condition, and marginally greater N170 amplitude in the incongruent condition than in the congruent condition. However, the difference in the mismatch effect on the LPP component was significant in the left O ROI and not in the right O ROI. <ref type="url" target="https://doi.org/10.1371/journal.pone.0200535.g006">https://doi.org/10.1371/journal.pone.0200535.g006</ref> 7. Source localizations (LORETA) for each congruity condition and the mismatch effect, per time window. The LORETA suggested that the main source of the P100 wave was in the occipital lobe in the congruent condition (A1) and in the posterior temporal lobe in the incongruent condition (B1), with the source of the mismatch effect located in the posterior temporal lobe (C1). The sources of the N170 and LPP waves were mainly localized in the posterior temporal lobe in both the congruent condition (A2 and A3) and the incongruent condition (B2 and B3). The strongest sources of the N170 and LPP mismatch effect were in the temporal lobe (C2 and C3), and the frontal lobe, respectively. <ref type="url" target="https://doi.org/10.1371/journal.pone.0200535.g007">https://doi.org/10.1371/journal.pone.0200535.g007</ref>   the mean marginal or significant mismatch effects in the Frontal, Temporal and Occipital ROIs that were greater than .50 μV, whereas the absence of mismatch effect in the CP ROI corresponded to mean effects below or equal to .50 μV.</p><p>Let's first consider the F ROI and T ROI that showed an overall mismatch effect across the three ERP components. For the F ROI, the number of participants showing no effect was 9 for the P100, 4 for the N170, and 7 for the LPP, that is to say, 26.7% of the participants on average. For the T ROI, there were few (5.3%), with only 1 or 2 participants depending on the time window. In contrast, the majority of paired observations were below the unity line for the F ROI (54.7%) and the T ROI (64%), demonstrating an overall mismatch effect with little variation (SD = 5%) across the time windows. The participants localized above the unity line were 18.7% and 30.7%, for the F ROI and R ROI, respectively. Given that idiosyncratic factors such as personality traits may reverse the direction of effects (see <ref type="bibr" target="#b52">[53]</ref> for an example of the effect of empathy on the N400), if we examine the paired observations that fell outside the unity line Path analysis. To investigate the temporal unfolding of the mismatch effect from Occipital P100 to Left Occipital LPP, we adopted a path analytic approach along the lines of <ref type="bibr" target="#b50">[51]</ref>. Path analysis using mediation models has already been applied to EEG data analysis and face perception <ref type="bibr" target="#b53">[54]</ref>, as well as to fMRI data showing that the influence of the amygdala on the processing of visual stimuli, such as the face, is both direct (on the visual cortices) and indirect (via the frontal region) <ref type="bibr" target="#b54">[55]</ref>. Details on the different theoretical assumptions guiding our own path analytic analyses, as well as the interpretation with respect to our LORETA findings, are available in the General Discussion.</p><p>Our path analysis mediation models were tested on the basis of the individual mismatch effect data (mean μV difference between incongruent and congruent trials) illustrated in Fig 8 . 
We only considered the data of F ROI, T ROI, and O ROI because they showed either marginal or significant mismatch effects in the MANOVA. Moreover, in order to simplify the models and make them testable with path analysis, we considered the mismatch effect at Occipital P100 (O_P100) as the initial input, and the mismatch effect at Left Occipital LPP (Lef-t_O_LPP) as the dependent variable to be predicted. Three path analytic models were tested: a) an initial serial multiple mediator model (see <ref type="bibr" target="#b50">[51]</ref> p.143 and after) with two mediators, namely the mismatch effect at Frontal N170 and Temporal N170; b) a model with two simple mediation models arranged in series; and c) a serial multiple mediator model with three mediators. For the sake of simplicity, only the third model will be described here. The two initial models are described in S2 File.</p><p>The model illustrated in Fig <ref type="figure" target="#fig_9">9</ref> is a serial multiple mediator model with three mediators: the mismatch effect at Frontal N170 (F_N170), Temporal (N170), and at Frontal LPP (F_LPP). It models the unfolding of the mismatch effect from O P100 to Left O LPP. The results evidenced a significant "O_P100 ➔ F_N170 ➔ F_LPP ➔ Left_O_LPP" indirect effect (BootCI = [.0474; 1.082]), concomitant with a Direct effect of O_P100 on Left_O_LPP, p = .022. This indirect effect (see <ref type="bibr">Fig 9)</ref> suggests that the Frontal region (possibly the Medial Frontal Gyrus) plays a crucial role in mediating the mismatch effect observed in the Left Occipital ROI at the LPP time-window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The present study investigated the neurocognitive mechanisms involved in the emotional anticipation of facial expressions of pain with the help of behavioral measures and ERPs. Using a representational momentum paradigm, we measured, in the first place, the emotional anticipation (memory displacement) of facial pain expressions. In the second place, we measured ERPs in response to static facial intensities, which were perceived as congruent or incongruent with respect to the memorized intensity.</p><p>Individuals always attempt to anticipate and predict events. At a representational level, Miceli and Castelfranchi <ref type="bibr" target="#b55">[56]</ref> have suggested that our emotions often reflect our anticipation of forthcoming events, with dialectical interaction between "what is" and "what is not (yet)". Thus, the anticipation of future events can induce an emotion (e.g., fear, hope, and trust), and the confirmation, or not, of this anticipation can elicit a reaction in the form of another emotion (e.g., surprise, discouragement, and regret). The anticipation process can be studied at the representational level (for a review, see <ref type="bibr" target="#b55">[56]</ref>), but also at a more perceptual lower level. In fact, these expectancies can lead to the emotional anticipation of a change in facial expression <ref type="bibr" target="#b24">[25]</ref>, which may induce memory bias <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>. When an expression is not congruent with an individual's anticipated expression, either in nature (i.e., emotional valence) or in intensity, our trust in others may be challenged.</p><p>In the present study, we focused on emotional anticipation which accompanies the perception of facial expressions of pain. In truth, the ability to anticipate and thereby rapidly detect the presence of an expression of pain seem to have both a social importance and an adaptive function <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. We used a representational momentum paradigm inspired by Courgeon et al. <ref type="bibr" target="#b22">[23]</ref> and Thornton <ref type="bibr" target="#b23">[24]</ref>, to explore emotional anticipation in response to facial expressions, combining behavioral and neurocognitive (ERP) measures. The participants had to compare the intensity of a static test expression with the memorized final intensity of a previously displayed dynamic expression. We theorized that a mismatch effect may be considered as a neurocognitive biomarker of anticipatory processes for facial expressions. We anticipated that ERPs would be modulated by a TestEI which deviates from the memorized expression intensity (i.e., incongruent trials). However, the idiosyncratic nature of memory biases meant that incongruent and congruent trials could only be defined on an individual basis. Therefore, in order to consider individual variability in emotional anticipation, we adapted TestEI stimuli for each participant as a function of his or her memory bias, as previously measured in a preliminary experiment. To our knowledge, this participant-centered approach has never been proposed until now.</p><p>Assuming that emotional anticipation accompanies our perception of a dynamic event such as an emotional facial expression, if the stimulus abruptly disappears, four scenarios may be considered. The observer may consider that: a) the emotional facial expression can be maintained at its final intensity for a period of time (e.g., apex duration can vary with pain context, see <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b57">58]</ref>); b) the expression intensity may increase; c) the facial expression will once again become neutral; or d) there may be a qualitative change (e.g., from surprise to joy). Scenarios "a" to "c" reflect participants' internal representations of the dynamic progression of a facial expression, which is commonly composed of three stages: onset (increasing), apex (maximum) and offset (decreasing). As a consequence, if a memory displacement was to occur during the mask stimulus displayed before the TestEI, this memory bias would be null, positive, or negative, respectively, for cases a, b, and c. Here, we do not consider scenario "d", given that the participants only observed facial expressions of pain. We found that memory bias varied both with the final expression intensity to be memorized (whether 50% or 90% VideoEI) and at the inter-individual level.</p><p>The overall negative memory bias was smaller for the facial expression of medium intensity (VideoEI50%) than for the facial expression of high intensity (VideoEI90%). However, in terms of the proportion of the displayed dynamic emotional intensity, the bias was roughly equivalent (approximately 20% of the final intensity). Thus, the overall negative memory bias is consistent with the expectation of a return to a neutral expression. Although this negative memory bias concords with findings in previous studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>, literature has also shown positive memory bias for facial expressions <ref type="bibr" target="#b3">[4]</ref>. The added value of our study with respect to this literature is based on the fact that we considered the importance of inter-individual variability of memory bias (negative, positive, or null depending on the participant) to investigate any underlying neurocognitive processes.</p><p>Studies that have examined simulation theory and the embodiment of other people's facial expressions <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b58">59]</ref> have suggested that an involuntary motor simulation of the observed facial expression causes the observer to "experience" the observed action, which in turn gives us information about the agent's emotional state. Previous studies have supported the idea of a dynamic facial expression (displayed before the mask), which induces an immediate perceptual history (here, expression intensity progresses from 50% or 90%) among participants before "emotional anticipation" <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b24">25]</ref>. Contrary to physical events which induce forward memory displacement (i.e., a representational momentum effect), biological motion may induce memory displacement in different directions (see <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b59">60]</ref> for reviews). Thus, we consider the term "emotional anticipation" more appropriate with regard to facial expressions of pain.</p><p>According to literature on event perception and cognition (e.g., <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b60">61]</ref>), the observed motion in daily life may temporarily disappear, or the scene may change dramatically because of a perceptive change (such as a camera cut during filming). Nonetheless, information is still available to the perceiver on the basis of his or her representation of the event. When a moving or changing stimulus reappears, we can easily detect if the current state of the event has deviated from what is expected. Although our participants were instructed to memorize rather than extrapolate the final expression intensity of a facial expression of pain, emotional anticipation may well be irrepressible <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b62">63]</ref>. Accordingly, our participants were able to detect more rapidly a test expression whose intensity had deviated from the expected expression intensity (whatever the memory displacement). Taken together, all neuroelectric markers (P100, N170 and LPP) were concomitant with this mismatch effect in the temporal and occipital regions, and, marginally, in the frontal region. Unexpected intensities of the test expression of pain decreased the P100 amplitude and increased the N170 deflection. These findings suggest an influence of high-level expectancies on low-level rapid perceptual processes, with expectancies acting as priming representations for forthcoming emotional expressions <ref type="bibr" target="#b63">[64]</ref>. The latency of the N170 peak (peaks not studied but visible in Figs <ref type="figure" target="#fig_5">5</ref> and<ref type="figure" target="#fig_4">6</ref>) was closer to 250 ms than 170 ms after TestEI onset. A possible explanation would be that the N170 component could be merged with an N250r component. In effect, the N250r wave was shown to exist for repeated presentations of faces <ref type="bibr" target="#b64">[65]</ref><ref type="bibr" target="#b65">[66]</ref><ref type="bibr" target="#b66">[67]</ref><ref type="bibr" target="#b67">[68]</ref>. Indeed, we presented multiple repetitions of the same face.</p><p>We also examined mismatch effects at the decision-making processing stage. According to Ibanez et al. <ref type="bibr" target="#b43">[44]</ref>, the LPP is a late positive component modulated by either the motivational relevance or semantic valence of the stimulus, and by contextual information. We found that unexpected emotional expression intensities led to lower LPP wave amplitudes, compared with expected intensities. This LPP modulation may be interpreted in view of behavioral response times. The higher amplitude of LPP and greater response time for expected pain intensities are consistent with typical psychophysical data that show greater RTs in response to stimuli that are close to PSEs <ref type="bibr" target="#b42">[43]</ref>. We propose that the P100 and N170 waves reflect the comparison process between the expected (memorized) and test emotional intensities at an early stage of visual processing. In contrast, the LPP wave might reflect a verification process at a higher cognitive level. Indeed, Ibanez et al. <ref type="bibr" target="#b43">[44]</ref> reported that a similar component, the LPC (Late Positive Component), also reflects such a verification process. In the occipital region, the mismatch effect was only significant in the left hemisphere. We found a study <ref type="bibr" target="#b68">[69]</ref> in which the authors also described a (marginally significant) effect on the LPP wave in the left occipital hemisphere but not in the right. The study addressed the categorization of angry versus neutral faces by children. However, the authors did not specifically refer to the effect this had on the left occipital cortex. It might be interesting to investigate at greater length the specific role of the left occipital hemisphere in the late processing of emotional stimuli.</p><p>LORETA source localization showed the activation of different cortical areas involved in facial processing in response to emotional test intensities (cf. <ref type="bibr">Fig 9)</ref>. The neural sources of the P100 wave appeared to be mainly located in the Cuneus (occipital lobe, BA 17) for the congruent condition and in the pMTG (the posterior part of Middle Temporal Gyrus, BA 39) for the incongruent condition. The greater activation mismatch effect in the P100 time window was located in the MOG (Middle Occipital Gyrus, <ref type="bibr">BA 19)</ref>. With regard to the N170 wave, neural sources were stronger in the pMTG for the congruent condition, and in the pSTG (the posterior part of Superior Temporal Gyrus, BA 22) for the incongruent condition. The neural sources of the mismatch effect on the N170 wave were mainly located in the MOG (BA 19). pMTG and pSTG are the visual entry point of a bottom-up activation of the mirror neuron system <ref type="bibr" target="#b69">[70]</ref>. pSTG contributes to a neural network which subserves face-based mentalization, by extracting information about intentions and goals from the face and eyes <ref type="bibr" target="#b70">[71]</ref>. MOG is recruited together with mPFC when judging the emotional valence of a dynamic facial expression <ref type="bibr" target="#b71">[72]</ref>. Finally, the LPP wave mainly originated from the pMTG in the congruent condition, and from the pSTG in the incongruent condition. The generators of the LPP mismatch effect were manifested in greater activation in the MedFG (Medial Frontal Gyrus, BA 10), a sub area of BA 10, the rostral part of the prefrontal cortex <ref type="bibr" target="#b72">[73]</ref>, also called the frontal pole. MedFG belongs to the medial prefrontal cortex (mPFC), a region involved in high-level social cognition for deciphering the mental state of others, <ref type="bibr" target="#b73">[74]</ref>, forming impressions of other people <ref type="bibr" target="#b74">[75]</ref> from their faces, as well as the implicit generation and maintenance of an emotional state <ref type="bibr" target="#b75">[76]</ref>.</p><p>Of particular interest, all the brain regions identified by the LORETA in our study were also found by <ref type="bibr" target="#b76">[77]</ref> to be recruited when participants had to update their memory of individuals who repeatedly expressed negative facial emotions, and then suddenly changed. Although our results did not evidence activity in the sensorimotor cortex (nor any mismatch effect in the centro-parietal region), it would be interesting to replicate our study using MEPs, along the lines of <ref type="bibr" target="#b32">[33]</ref>, to examine if sensorimotor mirror-matching contributes to emotion anticipation.</p><p>The different sources of the brain component are consistent with the path analysis we conducted in order to investigate the spatio-temporal unfolding of the mismatch effect. In our modeling approach, we assumed that visual object recognition is hierarchically organized in a sequence of cortical activation involving both (feedforward) input from early to higher-level areas, and top-down facilitation (feedback) from frontal regions to temporal regions <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b78">79]</ref> and even occipital regions <ref type="bibr" target="#b79">[80]</ref>. This hypothesis has already been validated using dipole modeling of EEG/MEG data <ref type="bibr" target="#b78">[79]</ref>, or dynamic causal modeling of fMRI data <ref type="bibr" target="#b80">[81]</ref>. Along those lines, Garrido et al., <ref type="bibr" target="#b77">[78]</ref> showed that backward connections mediate late components of eventrelated mismatch responses in an oddball paradigm. Similarly, in social context, there is evidence that visually inferring intentions from a confederate strengthen backward connections from mPFC more strongly than the forward connections from the superior occipital gyrus and MTG to mPFC <ref type="bibr" target="#b80">[81]</ref>. New insights into complex social processes, including the perception of facial expressions of emotion, come from studies of white matter tracts (axonal fiber pathways) <ref type="bibr" target="#b81">[82]</ref>.</p><p>Our results regarding the neuroelectric unfolding of the mismatch effect are consistent with the hypothesis that emotional anticipation may reflect top-down emotional processes <ref type="bibr" target="#b24">[25]</ref> and constitute a low-level form of the mind-reading mechanism <ref type="bibr" target="#b5">[6]</ref>. Path analysis and source localization suggested that MedFG was instrumental in mediating the mismatch effect through top-down influence on both the occipital and temporal regions. This is consistent with the involvement of MedFG in the appraisal of emotions <ref type="bibr" target="#b82">[83,</ref><ref type="bibr" target="#b83">84]</ref>. On the one hand, our path analysis confirmed that the frontal region exerts feedback on the N170 in the temporal region in order to facilitate visual recognition <ref type="bibr" target="#b78">[79]</ref>. On the other hand, the mismatch effect on the LPP in the left occipital region is consistent with several results cited in literature. <ref type="bibr" target="#b84">[85]</ref> found that when participants are asked to observe a dynamic expression of pain and then indicate the intensity of the expressed pain with their own face rather than simply imitate the observed movement, there is increased activity in the MedFG, left MTG, and left superior occipital gyrus. Moreover, our results are consistent with investigations of structural anatomic connections between brain areas (using diffusion tensor imaging) showing that better social cognition (including Theory of Mind and emotion recognition) is associated with greater axonal coherence (higher axial diffusivity) in the left Inferior Frontal Fascicle (IFOF) and the left uncinate fasciculus (which connects frontal and temporal regions) <ref type="bibr" target="#b85">[86]</ref>. Along the same lines, it is now well-established that lesions to the IFOF impair emotion recognition from facial expressions <ref type="bibr" target="#b86">[87]</ref>.</p><p>Regarding low-level forms of mind-reading, from our results we can speculate that congruent test images were checked in more depth to ensure they were truly congruent with the anticipated emotional intensity. By way of contrast, incongruent faces would appear to be more obvious. Furthermore, facial expressions of pain seem to be the most important source of information available to observers to evaluate the authenticity of the pain felt <ref type="bibr" target="#b87">[88]</ref>. When an expression is incongruent with an individual's anticipated expression or does not correspond with their expected expression, it could be considered as faked. Therefore, we can assume that automatic emotional anticipation may be useful for prosocial behavior and the detection of trustworthiness, especially for the intermittent viewing of a facial expression. Finally, perceived trustworthiness seems to involve greater empathy <ref type="bibr" target="#b88">[89]</ref>; thus, it would be interesting to explore, in future studies, the link between the individual empathy level and the emotional anticipation process. Moreover, the cognitive anticipation process may be different if an individual perceives a facial expression of pain in an emergency context, and in accordance with his or her experience of this context (e.g., as a clinician, emergency doctor, or firefighter). Whilst clinicians have been shown to underestimate patients' pain <ref type="bibr" target="#b89">[90]</ref><ref type="bibr" target="#b90">[91]</ref><ref type="bibr" target="#b91">[92]</ref>, they may also present a strong degree of emotional anticipation. Such anticipation can be considered adaptive in view of their job constraints. Thus, it remains for future research to explore the neuroelectric correlates of context effect and individual characteristics on the emotional anticipation of pain in others.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure A in S1 File, abscissa) were defined on the basis of their individual memory bias, corresponding to their Point of Subjective Equality, PSE (see Figure A in S1 File), computed in the preliminary experiment, in each video</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig 1 .Fig 2 .</head><label>12</label><figDesc>Fig 1. Illustration of expression intensity displayed during the experiment, ranging from 0% (neutral) to 130%. Morphing at equal stages was used to create intermediary intensities between a neutral (0%) and a naturally high facial expression of pain (100%). Higher intensities were also created (up to 130%), which gave more caricatured expressions. https://doi.org/10.1371/journal.pone.0200535.g001</figDesc><graphic coords="5,200.01,78.01,295.20,227.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig 3 .</head><label>3</label><figDesc>Fig 3. Example of behavioral results from one participant, in response to the VideoEI90% condition. Participants presented a negative memory bias, with a PSE of 65.9%, for a video stopping at 90% of the maximal intensity. Triplets of TestEIs are represented by gray dots. https://doi.org/10.1371/journal.pone.0200535.g003</figDesc><graphic coords="8,113.27,78.01,462.67,353.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig 4 .</head><label>4</label><figDesc>Fig 4. Electrode array. The data from six participants were recorded using 32 electrodes, whilst the data from the remaining 19 participants were recorded using 64 electrodes. For the purposes of statistical analysis, we grouped electrodes into four ROIs, based on anatomical and functional criteria: Frontal (F), Centro-Parietal (CP), Temporal (T) and Occipital (O). https://doi.org/10.1371/journal.pone.0200535.g004</figDesc><graphic coords="9,200.01,78.01,363.35,373.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figs 5 and 6</head><label>6</label><figDesc>Figs 5 and 6 illustrate the ERP signal data for the entire trial sequence, from the baseline to the post-onset TestEI. Statistical analyses were conducted only on ERPs for the TestEI stimuli.Three ERP components were evoked by TestEI onsets. We identified the first component as a P100 wave, peaking in the O ROI, around 100 ms after the stimulus onset. We only found a marginal mismatch effect on this wave (details are presented hereafter). The second component was a N170 wave, peaking in the O ROI around 230 ms after face onset. This wave presented a greater deflection in the right hemisphere than in the left.Lastly, we identified an LPP wave, peaking around 500 ms post TestEI onset. The amplitude of this wave was left lateralized in the T ROI. The LPP deflection was also reduced for incongruent trials in all ROIs. LORETAs, presented in Fig 7, illustrate the posterior-lateral</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig 5 .</head><label>5</label><figDesc>Fig 5. Average ERPs, by hemisphere (with congruity conditions combined). Apart from the baseline, data recorded before the 0 ms time value (i.e., data recorded during the presentation of the dynamic facial expression and the mask) are presented for illustrative purposes only. In the T ROI (panel C), the average amplitude of the EEG signal (across all time windows) was more negative in the right hemisphere (M = -3.81 μV) than in the left hemisphere (M = -2.98 μV). In the O ROI, significantly greater deflections were observed in the right hemisphere than in the left hemisphere, for both P100 and N170 waves (panel D). https://doi.org/10.1371/journal.pone.0200535.g005</figDesc><graphic coords="11,49.95,78.01,526.05,504.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig 6</head><label>6</label><figDesc>Fig 6. Average ERPs, by congruity condition (with hemispheres combined).Apart from the baseline, data recorded before the 0 ms time value (i.e., data recorded during the presentation of the dynamic facial expression and the mask) are presented for illustrative purposes only. Taking all time windows together, the mismatch effect was significant in the T (panel C) and O (panels D and E) ROIs. It was also marginally significant in the F ROI (panel A). In contrast, the mismatch effect in the O ROI varied across time windows. It showed marginally weaker P100 amplitude in the incongruent condition than in the congruent condition, and marginally greater N170 amplitude in the incongruent condition than in the congruent condition. However, the difference in the mismatch effect on the LPP component was significant in the left O ROI and not in the right O ROI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig 8 .</head><label>8</label><figDesc>Fig 8. Scatterplots of the distribution the mismatch effect (A) and of the hemisphere effect (B) across the participants, for the F ROI and T ROI, as well as each hemisphere of the O ROI, for each ERP component (P100, N170, and LPP). https://doi.org/10.1371/journal.pone.0200535.g008</figDesc><graphic coords="16,49.95,78.01,526.05,566.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(i.e., &gt; |.50| μV), it corresponded to 73.4% and 94.7% of the participants for the F ROI and R ROI, respectively. With regard to the occipital region, the number of participants showing no mismatch effect (&lt; |.50| μV) totaled 20% (n = 5 in each time window) for the Left O ROI, and 18.7% (4 or 6 depending on the time window) for the Right O ROI. The majority of paired observations were below the unity line for the O ROI in the left (50.7%) and right ROI (52%) hemisphere, with a smaller dispersion in the left hemisphere (SD = 1.2μV) than the right hemisphere (SD = 1.9 μV), as illustrated in Fig 8. The number of participants localized above the unity line totaled approximately 29% in each occipital ROI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig 9 .</head><label>9</label><figDesc>Fig 9. Path analysis mediation model testing for the spatio-temporal unfolding of the mismatch effect from occipital P100 up to Left occipital LPP. This serial multiple mediator model includes three mediators (F_N170, T_N170, and F_LPP). Standardized (β) coefficients (in bold) are provided together with unstandardized coefficients (between parentheses). The unstandardized coefficients are in μV unit, together with the significance level of effects as §p &lt; .10, � p &lt; .05, �� p &lt; .01, ��� p &lt; .001. Significant indirect effects are illustrated with thicker lines. https://doi.org/10.1371/journal.pone.0200535.g009</figDesc><graphic coords="18,200.01,78.01,275.24,168.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Multivariate tests. Significant effects are highlighted in bold.</figDesc><table><row><cell>Effect</cell><cell>Wilks' Λ</cell><cell>Hypothesis df</cell><cell>Error</cell><cell>F</cell><cell>p value</cell></row><row><cell></cell><cell>value</cell><cell></cell><cell>df</cell><cell></cell><cell></cell></row><row><cell>Time window (A)</cell><cell>0.18</cell><cell>8</cell><cell>17</cell><cell>9.58</cell><cell>&lt;0.0001</cell></row><row><cell>Congruity (B)</cell><cell>0.77</cell><cell>4</cell><cell>21</cell><cell>1.57</cell><cell>0.22</cell></row><row><cell>Hemisphere (C)</cell><cell>0.82</cell><cell>4</cell><cell>21</cell><cell>1.18</cell><cell>0.35</cell></row><row><cell>A × B</cell><cell>0.83</cell><cell>8</cell><cell>17</cell><cell>0.44</cell><cell>0.88</cell></row><row><cell>A × C</cell><cell>0.20</cell><cell>8</cell><cell>17</cell><cell>8.25</cell><cell>&lt;0.001</cell></row><row><cell>B × C</cell><cell>0.83</cell><cell>4</cell><cell>21</cell><cell>1.08</cell><cell>0.39</cell></row><row><cell>A× B× C</cell><cell>0.29</cell><cell>8</cell><cell>17</cell><cell>5.15</cell><cell>&lt;0.005</cell></row><row><cell>Frontal ROI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Time window (A)</cell><cell>0.40</cell><cell>2</cell><cell>23</cell><cell>17.20</cell><cell>&lt;0.0001</cell></row><row><cell>Congruity (B)</cell><cell>0.88</cell><cell>1</cell><cell>24</cell><cell>3.37</cell><cell>0.08</cell></row><row><cell>Hemisphere (C)</cell><cell>0.93</cell><cell>1</cell><cell>24</cell><cell>1.89</cell><cell>0.18</cell></row><row><cell>A × B</cell><cell>1.00</cell><cell>2</cell><cell>23</cell><cell>0.00</cell><cell>1.00</cell></row><row><cell>A × C</cell><cell>0.52</cell><cell>2</cell><cell>23</cell><cell>10.46</cell><cell>&lt;0.001</cell></row><row><cell>B × C</cell><cell>0.96</cell><cell>1</cell><cell>24</cell><cell>1.10</cell><cell>0.30</cell></row><row><cell>A× B× C</cell><cell>0.96</cell><cell>2</cell><cell>23</cell><cell>0.52</cell><cell>0.60</cell></row><row><cell>Centro-parietal ROI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Time window (A)</cell><cell>0.43</cell><cell>2</cell><cell>23</cell><cell>14.99</cell><cell>&lt;0.0001</cell></row><row><cell>Congruity (B)</cell><cell>0.92</cell><cell>1</cell><cell>24</cell><cell>2.02</cell><cell>0.17</cell></row><row><cell>Hemisphere (C)</cell><cell>0.94</cell><cell>1</cell><cell>24</cell><cell>1.66</cell><cell>0.21</cell></row><row><cell>A × B</cell><cell>1.00</cell><cell>2</cell><cell>23</cell><cell>0.04</cell><cell>0.96</cell></row><row><cell>A × C</cell><cell>0.32</cell><cell>2</cell><cell>23</cell><cell>24.39</cell><cell>&lt;0.00001</cell></row><row><cell>B × C</cell><cell>0.97</cell><cell>1</cell><cell>24</cell><cell>0.75</cell><cell>0.39</cell></row><row><cell>A× B× C</cell><cell>0.88</cell><cell>2</cell><cell>23</cell><cell>1.54</cell><cell>0.24</cell></row><row><cell>Temporal ROI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Time window (A)</cell><cell>0.48</cell><cell>2</cell><cell>23</cell><cell>12.45</cell><cell>&lt;0.001</cell></row><row><cell>Congruity (B)</cell><cell>0.84</cell><cell>1</cell><cell>24</cell><cell>4.66</cell><cell>&lt;0.05</cell></row><row><cell>Hemisphere (C)</cell><cell>0.83</cell><cell>1</cell><cell>24</cell><cell>4.91</cell><cell>&lt;0.05</cell></row><row><cell>A × B</cell><cell>0.97</cell><cell>2</cell><cell>23</cell><cell>0.30</cell><cell>0.74</cell></row><row><cell>A × C</cell><cell>0.66</cell><cell>2</cell><cell>23</cell><cell>6.02</cell><cell>0.01</cell></row><row><cell>B × C</cell><cell>0.96</cell><cell>1</cell><cell>24</cell><cell>0.95</cell><cell>0.34</cell></row><row><cell>A× B× C</cell><cell>0.98</cell><cell>2</cell><cell>23</cell><cell>0.19</cell><cell>0.83</cell></row><row><cell>Occipital ROI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Time window (A)</cell><cell>0.43</cell><cell>2</cell><cell>23</cell><cell>15.40</cell><cell>&lt;0.0001</cell></row><row><cell>Congruity (B)</cell><cell>0.81</cell><cell>1</cell><cell>24</cell><cell>5.50</cell><cell>&lt;0.05</cell></row><row><cell>Hemisphere (C)</cell><cell>0.98</cell><cell>1</cell><cell>24</cell><cell>0.41</cell><cell>0.53</cell></row><row><cell>A × B</cell><cell>0.97</cell><cell>2</cell><cell>23</cell><cell>0.30</cell><cell>0.75</cell></row><row><cell>A × C</cell><cell>0.45</cell><cell>2</cell><cell>23</cell><cell>13.78</cell><cell>&lt;0.001</cell></row><row><cell>B × C</cell><cell>0.99</cell><cell>1</cell><cell>24</cell><cell>0.35</cell><cell>0.56</cell></row><row><cell>A× B× C</cell><cell>0.64</cell><cell>2</cell><cell>23</cell><cell>6.49</cell><cell>&lt;0.01</cell></row></table><note><p>https://doi.org/10.1371/journal.pone.0200535.t001</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>PLOS ONE | https://doi.org/10.1371/journal.pone.0200535 August 1, 2018</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>The reported research was funded by a grant from <rs type="funder">Agence Nationale de la Recherche</rs>, <rs type="grantNumber">EMCO 2011</rs> (<rs type="projectName">COMPARSE</rs> project) to M-AA. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_k5ZKvTW">
					<idno type="grant-number">EMCO 2011</idno>
					<orgName type="project" subtype="full">COMPARSE</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>All relevant data are within the paper and its Supporting Information files.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supporting information</head><p>S1 File. Experiment 1. (Figure <ref type="figure">A</ref>) Example of behavioral results for one participant in response to the VideoEI90% in the preliminary experiment. This participant presented a significant memory displacement (PSE = 64.8%, further from 90%). In abscissa, the gray brackets illustrate the three TestEIs triplets shown to this participant in the main experiment. In this example, the "Expected Incongruent TestEIs" triplets were equal to 25%, 30%, 35% and 95%, 100%, 105%. The "expected Congruent TestEIs" triplet was equal to 60%, 65% and 70%. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Representational momentum</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Freyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Finke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="126" to="127" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Can expertise modulate representational momentum?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bla ¨ttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Didierjean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Elslande</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marmèche</surname></persName>
		</author>
		<idno type="DOI">10.1080/13506281003737119</idno>
		<ptr target="https://doi.org/10.1080/13506281003737119" />
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1253" to="1273" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Representational momentum and related displacements in spatial memory: A review of the findings</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Hubbard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="822" to="851" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dynamic facial expressions of emotion induce representational momentum</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive, Affective, &amp; Behavioral Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="25" to="31" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optical flow and viewpoint change modulate the perception and memorization of complex motion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jarraya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-A</forename><surname>Amorim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Bardy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="951" to="961" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond face value: does involuntary emotional anticipation shape the perception of dynamic facial expressions?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Palumbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jellema</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0056003</idno>
		<idno type="PMID">23409112</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0056003" />
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">56003</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamic mental representations</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Freyd</surname></persName>
		</author>
		<idno type="PMID">3317470</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page">427</biblScope>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Perceiving pain in others: automatic and controlled mechanisms</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Versloot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Goubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vervoort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Crombez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jpain.2009.08.008</idno>
		<idno type="PMID">19962352</idno>
		<ptr target="https://doi.org/10.1016/j.jpain.2009.08.008" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Pain</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="101" to="108" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Facial expressions. Handbook of cognition and emotion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="301" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new view of pain as a homeostatic emotion</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Craig</surname></persName>
		</author>
		<idno type="PMID">12798599</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in neurosciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="303" to="307" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Real-time assessment of pain behavior during clinical assessment of low back pain patients</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Prkachin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Joy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hunt</surname></persName>
		</author>
		<idno type="PMID">11790464</idno>
	</analytic>
	<monogr>
		<title level="j">Pain</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="23" to="30" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pain expression in patients with shoulder pathology: validity, properties and relationship to sickness impact</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Prkachin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Mercer</surname></persName>
		</author>
		<idno type="PMID">2616178</idno>
	</analytic>
	<monogr>
		<title level="j">Pain</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="257" to="265" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Facial expression of pain, empathy, evolution, and social learning</title>
		<author>
			<persName><surname>Williams Ac De C</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="475" to="480" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Damasio AR. Descartes&apos; error. London: Papermac</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The pain of a model in the personality of an onlooker: Influence of state-reactivity and personality traits on embodied empathy for pain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avenanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Miniopaluello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bufalari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aglioti</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2008.08.001</idno>
		<idno type="PMID">18761092</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2008.08.001" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="275" to="283" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Judging nonverbal expressions of pain</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Prkachin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Currie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Craig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Behavioural Science/Revue canadienne des sciences du comportement</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="409" to="421" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The influence of communication goals and physical demands on different dimensions of pain behavior</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thibault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Savard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Catchlove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kozey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Stanish</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.pain.2006.06.019</idno>
		<idno type="PMID">16860479</idno>
		<ptr target="https://doi.org/10.1016/j.pain.2006.06.019" />
	</analytic>
	<monogr>
		<title level="j">Pain</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="270" to="277" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Judgments of genuine, suppressed, and faked facial expressions of pain</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Craig</surname></persName>
		</author>
		<idno type="PMID">1447693</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page">797</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A matching advantage for dynamic human faces</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kourtzi</surname></persName>
		</author>
		<idno type="DOI">10.1068/p3300</idno>
		<idno type="PMID">11922118</idno>
		<ptr target="https://doi.org/10.1068/p3300" />
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="113" to="132" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The role of motion in learning new faces</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="897" to="912" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deciphering the enigmatic face: the importance of facial dynamics in interpreting subtle facial expressions</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ambadar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Schooler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.0956-7976.2005.01548.x</idno>
		<idno type="PMID">15869701</idno>
		<ptr target="https://doi.org/10.1111/j" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="403" to="410" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Representational momentum in dynamic facial expressions is modulated by the level of expressed pain: Amplitude and direction effects. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Prigent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-A</forename><surname>Amorim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>De Oliveira</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-017-1422-6</idno>
		<idno type="PMID">28956325</idno>
		<ptr target="https://doi.org/10.3758/s13414-017-1422-6" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="82" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Do users anticipate emotion dynamics in facial expressions of a virtual character</title>
		<author>
			<persName><forename type="first">M</forename><surname>Courgeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Amorim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Giroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on computer animation and social agents (CASA 2010)</title>
		<meeting>the 23rd international conference on computer animation and social agents (CASA 2010)<address><addrLine>Saint Malo, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Representational momentum and the human face: an empirical note</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Thornton</surname></persName>
		</author>
		<idno type="DOI">10.7423/XJENZA.2014.2.09</idno>
		<ptr target="https://doi.org/10.7423/XJENZA.2014.2.09" />
	</analytic>
	<monogr>
		<title level="j">Xjenza</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Biases in the perception and affective valence of neutral facial expressions induced by the immediate perceptual history</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jellema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pecchinenda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Palumbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="616" to="634" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Embodiment in the acquisition and use of emotion knowledge</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Niedenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Barsalou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ric</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Krauth-Gruber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Emotion and consciousness</title>
		<imprint>
			<biblScope unit="page" from="21" to="50" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Both of us disgusted in My insula: the common neural basis of seeing and feeling disgust</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Plailly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-P</forename><surname>Royet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gallese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rizzolatti</surname></persName>
		</author>
		<idno type="PMID">14642287</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="655" to="664" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Viewing facial expressions of pain engages cortical areas involved in the direct experience of pain</title>
		<author>
			<persName><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Bylsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Prkachin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2004.11.043</idno>
		<idno type="PMID">15734365</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2004.11.043" />
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="312" to="319" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Transcranial magnetic stimulation highlights the sensorimotor side of empathy for pain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avenanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bueti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Galati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Aglioti</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn1481</idno>
		<idno type="PMID">15937484</idno>
		<ptr target="https://doi.org/10.1038/nn1481" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="955" to="960" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stimulus-driven modulation of motor-evoked potentials during observation of others&apos; pain</title>
		<author>
			<persName><forename type="first">A</forename><surname>Avenanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Paluello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Bufalari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Aglioti</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2006.03.010</idno>
		<idno type="PMID">16675270</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2006.03.010" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="316" to="324" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Empathy or Ownership? Evidence from Corticospinal Excitability Modulation during Pain Observation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Bucchioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fossataro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cavallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neppi-Modona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Garbarini</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_01003</idno>
		<idno type="PMID">27378331</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_01003" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1760" to="1771" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Seeing fearful body language rapidly freezes the observer&apos;s motor cortex</title>
		<author>
			<persName><forename type="first">S</forename><surname>Borgomaneri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vitale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gazzola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Avenanti</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2015.01.014</idno>
		<idno type="PMID">25835523</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2015.01.014" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="232" to="245" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Empathy for Pain and Touch in the Human Somatosensory Cortex</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bufalari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Aprile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Avenanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Di</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Aglioti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhl161</idno>
		<idno type="PMID">17205974</idno>
		<ptr target="https://doi.org/10.1093/cercor/bhl161" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2553" to="2561" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Distributed neural systems for face perception. The Oxford Handbook of Face Perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Haxby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Gobbini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Electrocortical evidence for preferential processing of dynamic pain expressions compared to other emotional expressions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Reicherts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Gerdes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">U</forename><surname>Likowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Weyers</surname></persName>
		</author>
		<author>
			<persName><surname>Mu ¨hlberger A</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAIN®</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page" from="1959" to="1964" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Modulation of perception and brain activity by predictable trajectories of facial expressions</title>
		<author>
			<persName><forename type="first">N</forename><surname>Furl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kiebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Treves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhp140</idno>
		<idno type="PMID">19617291</idno>
		<ptr target="https://doi.org/10.1093/cercor/bhp140" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="694" to="703" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Sensorimotor cortex as a critical component of an &quot;extended&quot; mirror neuron system: Does it solve the development, correspondence, and control problems in mirroring? Behavioral and Brain Functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Pineda</surname></persName>
		</author>
		<idno type="DOI">10.1186/1744-9081-4-47</idno>
		<idno type="PMID">18928566</idno>
		<ptr target="https://doi.org/10.1186/1744-9081-4-47" />
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Facial action coding system : A technique for the measurement of facial movement</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Friesen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
			<publisher>Consulting Psychologists Press</publisher>
			<pubPlace>Palo Alto</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The consistency of facial expressions of pain: a comparison across modalities</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Prkachin</surname></persName>
		</author>
		<idno type="PMID">1491857</idno>
	</analytic>
	<monogr>
		<title level="j">Pain</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="297" to="306" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Algebraic integration models of facial features of expression: A case made for pain</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Sa ´teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Breda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Da</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Teorie &amp; Modelli Rivista di Storia e Metodologia della Psicologia</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="155" to="166" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">CNV and reaction time task in man: effects of inter-stimulus interval contingencies</title>
		<author>
			<persName><forename type="first">F</forename><surname>Macar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vitton</surname></persName>
		</author>
		<idno type="PMID">7443023</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="585" to="590" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Larger N2 and smaller early contingent negative variation during the processing of uncertainty about future emotional events</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijpsycho.2014.10.004</idno>
		<idno type="PMID">25312204</idno>
		<ptr target="https://doi.org/10.1016/j.ijpsycho.2014.10.004" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="292" to="297" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Using reaction times and binary responses to estimate psychophysical performance: an information theoretic analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Stone</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2014.00035</idno>
		<idno type="PMID">24624053</idno>
		<ptr target="https://doi.org/10.3389/fnins.2014.00035" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">What event-related potentials (ERPs) bring to social neuroscience?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ibanez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Melloni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Huepe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Helgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rivera-Rei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Canales-Johnson</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470919.2012.691078</idno>
		<idno type="PMID">22642412</idno>
		<ptr target="https://doi.org/10.1080/17470919.2012.691078" />
	</analytic>
	<monogr>
		<title level="j">Social Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="632" to="649" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Thirty Years and Counting: Finding Meaning in the N400 Component of the Event-Related Brain Potential (ERP)</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kutas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Federmeier</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.093008.131123</idno>
		<idno type="PMID">20809790</idno>
		<ptr target="https://doi.org/10.1146/annurev.psych.093008.131123" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="621" to="647" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Event-related potentials: A methods handbook</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Handy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Low resolution electromagnetic tomography: a new method for localizing electrical activity in the brain</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Pascual-Marqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lehmann</surname></persName>
		</author>
		<idno type="PMID">7876038</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of psychophysiology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="49" to="65" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Testing treatment effects in repeated measures designs: an update for psychophysiological researchers</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Keselman</surname></persName>
		</author>
		<idno type="PMID">9643062</idno>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="470" to="478" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Certain generalizations in the analysis of variance</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Wilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="page" from="471" to="494" />
			<date type="published" when="1932">1932</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">4 Application of Repeated Measures ANOVA to High-Density ERP. Event-related potentials: A methods handbook</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Santuzzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="57" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Introduction to mediation, moderation, and conditional process analysis: A regression-based approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Hayes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Guilford Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A few simple steps to improve the description of group results in neuroscience</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Rousselet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Foxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Bolam</surname></persName>
		</author>
		<idno type="DOI">10.1111/ejn.13400</idno>
		<idno type="PMID">27628462</idno>
		<ptr target="https://doi.org/10.1111/ejn.13400" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="2647" to="2651" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Neuroelectric Correlates of Pragmatic Emotional Incongruence Processing: Empathy Matters</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dozolme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brunet-Gouet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Passerieux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-A</forename><surname>Amorim</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0129770</idno>
		<idno type="PMID">26067672</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0129770" />
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">129770</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Damage of the temporal lobe and APOE status determine neural compensation in mild cognitive impairment</title>
		<author>
			<persName><forename type="first">Prieto</forename><surname>Del Val</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cantero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Baena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Atienza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2018.01.018</idno>
		<idno type="PMID">29475078</idno>
		<ptr target="https://doi.org/10.1016/j" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="136" to="153" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Segregating the significant from the mundane on a moment-to-moment basis via direct and indirect amygdala contributions</title>
		<author>
			<persName><forename type="first">S-L</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Padmala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pessoa</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0904551106</idno>
		<idno type="PMID">19805383</idno>
		<ptr target="https://doi.org/10.1073/pnas.0904551106" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="16841" to="16846" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Expectancy and Emotion</title>
		<author>
			<persName><forename type="first">M</forename><surname>Miceli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Castelfranchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Facial expression during induced pain</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Patrick</surname></persName>
		</author>
		<idno type="PMID">3989673</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page">1080</biblScope>
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Genuine, suppressed and faked facial behavior during exacerbation of chronic low back pain</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Patrick</surname></persName>
		</author>
		<idno type="PMID">1836259</idno>
	</analytic>
	<monogr>
		<title level="j">Pain</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="161" to="171" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The Simulation of Smiles (SIMS) model: Embodied simulation and the meaning of facial expression</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Niedenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mermillod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hess</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X10000865</idno>
		<idno type="PMID">21211115</idno>
		<ptr target="https://doi.org/10.1017/S0140525X10000865" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="417" to="433" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Forms of momentum across space: Representational, operational, and attentional. Psychonomic</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Hubbard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1371" to="1403" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Event cognition</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Radvansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Spatial memory and explicit knowledge: An effect of instruction on representational momentum</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Courtney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Hubbard</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210802194217</idno>
		<idno type="PMID">18609396</idno>
		<ptr target="https://doi.org/10.1080/17470210802194217" />
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1778" to="1784" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Representational momentum is not (totally) impervious to error feedback</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Ruppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Hubbard</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0013980</idno>
		<idno type="PMID">19271816</idno>
		<ptr target="https://doi.org/10.1037/a0013980" />
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expe ´rimentale</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">N170 response to facial expressions is modulated by the affective congruency between the emotional expression and preceding affective picture</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Hietanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Astikainen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsycho.2012.10.005</idno>
		<idno type="PMID">23131616</idno>
		<ptr target="https://doi.org/10.1016/j.biopsycho.2012.10.005" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Event-related brain potential evidence for a response of inferior temporal cortex to familiar face repetitions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Schweinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kaufmann</surname></persName>
		</author>
		<idno type="PMID">12421663</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Brain Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="398" to="409" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Repetition effects in human ERPs to faces</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Schweinberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Neumann</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2015.11.001</idno>
		<idno type="PMID">26672902</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2015.11.001" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="141" to="153" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Facial misidentifications arise from the erroneous activation of visual face memory</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Wirth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Towler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eimer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2015.09.021</idno>
		<idno type="PMID">26384776</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2015.09.021" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="387" to="399" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Facial identity and facial expression are initially integrated at visual perceptual stages of face processing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Towler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eimer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2015.11.011</idno>
		<idno type="PMID">26581627</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2015.11.011" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="115" to="125" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">The Moderating Effect of Self-Reported State and Trait Anxiety on the Late Positive Potential to Emotional Faces in 6-11-Year-Old Children</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chronaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Broyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Benikos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mjj</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ejs</forename><surname>Sonuga-Barke</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2018.00125</idno>
		<idno type="PMID">29515476</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2018.00125" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The cognitive and neural time course of empathy and sympathy: An electrical neuroimaging study on self-other interaction</title>
		<author>
			<persName><forename type="first">B</forename><surname>Thirioux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Mercier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Blanke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Berthoz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroscience.2014.02.024</idno>
		<idno type="PMID">24583040</idno>
		<ptr target="https://doi.org/10.1016/j.neuroscience.2014.02.024" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="286" to="306" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Neural pathways subserving face-based mentalizing</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">N</forename><surname>Yordanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Duffau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Herbet</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00429-017-1388-0</idno>
		<idno type="PMID">28243761</idno>
		<ptr target="https://doi.org/10.1007/s00429-017-1388-0" />
	</analytic>
	<monogr>
		<title level="j">Brain Structure and Function</title>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="page" from="3087" to="3105" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A Common Neural Code for Perceived and Inferred Emotion</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Skerry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saxe</forename><forename type="middle">R</forename></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1676-14.2014</idno>
		<idno type="PMID">25429141</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.1676-14.2014" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="15997" to="16008" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Distinct functional connectivity associated with lateral versus medial rostral prefrontal cortex: A meta-analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gonen-Yaacovi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Volle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Burgess</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2010.07.032</idno>
		<idno type="PMID">20654722</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2010.07.032" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1359" to="1367" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Social Cognition in Humans</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Frith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Frith</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2007.05.068</idno>
		<idno type="PMID">17714666</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2007.05.068" />
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="724" to="R732" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Forming impressions of people versus inanimate objects: Social-cognitive processing in the medial prefrontal cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Macrae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Banaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2005.01.031</idno>
		<idno type="PMID">15862225</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2005.01.031" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="251" to="257" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">The role of the medial frontal cortex in the maintenance of emotional states</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Waugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Lemus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Gotlib</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsu011</idno>
		<idno type="PMID">24493835</idno>
		<ptr target="https://doi.org/10.1093/scan/nsu011" />
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2001" to="2009" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Age-related similarities and differences in brain activity underlying reversal learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Nashiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sakaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mather</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnint.2013.00037</idno>
		<idno type="PMID">23750128</idno>
		<ptr target="https://doi.org/10.3389/fnint.2013.00037" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Integrative Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Evoked brain responses are generated by feedback loops</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kilner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kiebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0706274105</idno>
		<idno type="PMID">18087046</idno>
		<ptr target="https://doi.org/10.1073/pnas.0706274105" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="20961" to="20966" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Direction of magnetoencephalography sources associated with feedback and feedforward contributions in a visual object recognition task</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Ahlfors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ahveninen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ha ¨ma ¨la ¨inen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Belliveau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neulet.2014.11.029</idno>
		<idno type="PMID">25445356</idno>
		<ptr target="https://doi.org/10.1016/j.neulet.2014.11.029" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience Letters</title>
		<imprint>
			<biblScope unit="volume">585</biblScope>
			<biblScope unit="page" from="149" to="154" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Frontal-Occipital Connectivity During Visual Search</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Pantazatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Yanagihara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hirsch</surname></persName>
		</author>
		<idno type="DOI">10.1089/brain.2012.0072</idno>
		<idno type="PMID">22708993</idno>
		<ptr target="https://doi.org/10.1089/brain.2012.0072" />
	</analytic>
	<monogr>
		<title level="j">Brain Connectivity</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="164" to="175" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Dynamic causal modelling of effective connectivity during perspective taking in a communicative task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hillebrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dumontheil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S-J</forename><surname>Blakemore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Roiser</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.02.072</idno>
		<idno type="PMID">23507383</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2013.02.072" />
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="116" to="124" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">The Original Social Network: White Matter and Social Cognition</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Olson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2018.03.005</idno>
		<idno type="PMID">29628441</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2018.03.005" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Emotional processing in anterior cingulate and medial prefrontal cortex</title>
		<author>
			<persName><forename type="first">A</forename><surname>Etkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Egner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kalisch</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2010.11.004</idno>
		<idno type="PMID">21167765</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2010.11.004" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="85" to="93" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Functional connectivity during masked and unmasked face emotion processing in bipolar disorder</title>
		<author>
			<persName><forename type="first">W-L</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stoddard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Zarate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Pine</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.pscychresns.2016.10.006</idno>
		<idno type="PMID">27814457</idno>
		<ptr target="https://doi.org/10.1016/j.pscychresns.2016.10.006" />
	</analytic>
	<monogr>
		<title level="j">Psychiatry Research: Neuroimaging</title>
		<imprint>
			<biblScope unit="volume">258</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Mirroring Pain in the Brain: Emotional Expression versus Motor Imitation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Budell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rainville</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0107526</idno>
		<idno type="PMID">25671563</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0107526" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Lamm</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">107526</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Altered white matter microstructure is associated with social cognition and psychotic symptoms in 22q11.2 microdeletion syndrome</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jalbrzikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Villalon-Reina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Karlsgodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Senturk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Thompson</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnbeh.2014.00393</idno>
		<idno type="PMID">25426042</idno>
		<ptr target="https://doi.org/10.3389/fnbeh.2014.00393" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Behavioral Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Damage to Association Fiber Tracts Impairs Recognition of the Facial Expression of Emotion</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Philippi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grabowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Adolphs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rudrauf</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0796-09.2009</idno>
		<idno type="PMID">19955360</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0796-09.2009" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="15089" to="15099" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Judgments about pain intensity and pain genuineness: the role of pain behavior and judgmental heuristics</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">O</forename><surname>Martel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Thibault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jpain.2010.10.010</idno>
		<idno type="PMID">21296030</idno>
		<ptr target="https://doi.org/10.1016/j.jpain.2010.10.010" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Pain</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="468" to="475" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Perceived trustworthiness shapes neural empathic responses toward others&apos; pain</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sessa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Meconi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2015.10.028</idno>
		<idno type="PMID">26514617</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2015.10.028" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="97" to="105" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Pain rating by patients and physicians: evidence of systematic pain miscalibration</title>
		<author>
			<persName><forename type="first">´l</forename><surname>Marquie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Raufaste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lauque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">´c</forename><surname>Marine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ecoiffier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sorum</surname></persName>
		</author>
		<idno type="PMID">12670671</idno>
	</analytic>
	<monogr>
		<title level="j">Pain</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="289" to="296" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Pain and negative emotions in the face: judgements by health care professionals</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kappesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
		<idno type="PMID">12237197</idno>
	</analytic>
	<monogr>
		<title level="j">Pain</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="197" to="206" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Perceptual weighting of pain behaviours of others, not information integration, varies with expertise</title>
		<author>
			<persName><forename type="first">E</forename><surname>Prigent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-A</forename><surname>Amorim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Leconte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pradon</surname></persName>
		</author>
		<idno type="DOI">10.1002/j.1532-2149.2013.00354.x</idno>
		<idno type="PMID">23821536</idno>
		<ptr target="https://doi.org/10.1002/j.1532-2149.2013.00354.x" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Pain</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="110" to="119" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
