<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Unified Model of Heading and Path Perception in Primate MSTd</title>
				<funder ref="#_C4W49HZ">
					<orgName type="full">Office of Naval Research</orgName>
					<orgName type="abbreviated">ONR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2014-02-20">February 20, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Oliver</forename><forename type="middle">W</forename><surname>Layton</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Neuroscience and Neural Technology</orgName>
								<orgName type="institution">Boston University</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>Massachusetts</region>
									<country key="US">United States of America</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">N</forename><forename type="middle">Andrew</forename><surname>Browning</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Computational Neuroscience and Neural Technology</orgName>
								<orgName type="institution">Boston University</orgName>
								<address>
									<settlement>Boston</settlement>
									<region>Massachusetts</region>
									<country key="US">United States of America</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Scientific Systems Company Inc. (SSCI)</orgName>
								<address>
									<settlement>Woburn</settlement>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">United Sates of America</orgName>
								<orgName type="institution" key="instit2">-University Marburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Unified Model of Heading and Path Perception in Primate MSTd</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-02-20">February 20, 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1371/journal.pcbi.1003476.g001</idno>
					<note type="submission">Received July 23, 2013; Accepted January 3, 2014;</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T00:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-motion, steering, and obstacle avoidance during navigation in the real world require humans to travel along curved paths. Many perceptual models have been proposed that focus on heading, which specifies the direction of travel along straight paths, but not on path curvature, which humans accurately perceive and is critical to everyday locomotion. In primates, including humans, dorsal medial superior temporal area (MSTd) has been implicated in heading perception. However, the majority of MSTd neurons respond optimally to spiral patterns, rather than to the radial expansion patterns associated with heading. No existing theory of curved path perception explains the neural mechanisms by which humans accurately assess path and no functional role for spiral-tuned cells has yet been proposed. Here we present a computational model that demonstrates how the continuum of observed cells (radial to circular) in MSTd can simultaneously code curvature and heading across the neural population. Curvature is encoded through the spirality of the most active cell, and heading is encoded through the visuotopic location of the center of the most active cell's receptive field. Model curvature and heading errors fit those made by humans. Our model challenges the view that the function of MSTd is heading estimation, based on our analysis we claim that it is primarily concerned with trajectory estimation and the simultaneous representation of both curvature and heading. In our model, temporal dynamics afford time-history in the neural representation of optic flow, which may modulate its structure. This has far-reaching implications for the interpretation of studies that assume that optic flow is, and should be, represented as an instantaneous vector field. Our results suggest that spiral motion patterns that emerge in spatio-temporal optic flow are essential for guiding self-motion along complex trajectories, and that cells in MSTd are specifically tuned to extract complex trajectory estimation from flow.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Gibson noted that animals can navigate about their environment using the changing pattern of light distributions falling on the retina, which is now known as optic flow <ref type="bibr" target="#b0">[1]</ref>. Travel parallel to a ground surface, along a straight path, without eye movements or body rotations produces characteristic patterns of optic flow, which Gibson called a ''melon-shaped family of curves'' (Figure <ref type="figure" target="#fig_0">1a</ref>). These flow patterns contain a singularity known as the focus of expansion (FoE). When the path of travel is straight, the optic flow field expands radially and the FoE specifies the direction in which the animal is going (heading). Gibson observed that animals could navigate using optic flow by aligning the FoE with the direction in which the animal wishes to travel.</p><p>Since Gibson proposed this strategy for navigation, much psychophysical research has focused on understanding human perception of heading <ref type="bibr" target="#b1">[2]</ref>. For the remainder of this article, we define heading to refer to the instantaneous direction of travel of an observer, and we define curvilinear path as the trajectory of travel, which may be curved. Psychophysical studies of human heading judgments have largely been based on static environments, consisting of dot or textured ground planes or 3D dot clouds.</p><p>The observer typically travels along a straight path. In such environments, humans accurately judge their heading, within 1 0 <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. Biologically inspired models of human heading perception often make use of depth variations in the visual scene (motion parallax) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> to estimate the observer's heading given a two dimensional (2D) retinal velocity field. Template matching <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>, whereby the retinal optic flow is compared to a number of largefield radial expansion patterns, or a combination of the approaches is also used.</p><p>Navigation under natural conditions is more complex than traveling on a straight path without any rotation. When the observer travels along a straight path, factors, such as eye movements and gaze, introduce rotation, which may result in optic flow that is not radially expanding or contracting. Sources of rotation are either considered retinal or extra-retinal <ref type="bibr" target="#b9">[10]</ref>. Rotations that occur through the actions of the observer, such as eye, head, or body movements, are considered extra-retinal, whereas rotations due to path curvature are considered retinal. Research on heading perception during smooth-pursuit eye movements shows that human bias in heading judgments remains constant (v+5 0 ) and independent of angular rotation due to eye movement velocities <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. However, when human subjects fixate (no extra-retinal rotation) and are shown optic flow displays that simulate what would be seen by an observer traveling along a straight path with a constant amount of rotation (Figure <ref type="figure" target="#fig_0">1b</ref>), humans make large errors in heading judgments that is proportional to the rate of rotation <ref type="bibr" target="#b10">[11]</ref>. This is often referred to as the simulated rotation condition, in which the retinal rotation experienced by human observers is due to the simulated eye movements. Subjects typically note the experience of traveling along a curved path and not a straight path with eye rotation (compare Figure <ref type="figure" target="#fig_0">1b</ref> and<ref type="figure" target="#fig_0">1c</ref>), which is the assumption of the experimenters. The large heading bias in the simulated rotation condition may therefore arise through the reporting of the subject's path rather than heading or ambiguity in the task instructions <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. Mathematical analyses indicate that the optic flow experienced by subjects when eye movements are simulated is similar to that experienced traveling on a curved path over the time period of a typical experimental trial <ref type="bibr" target="#b14">[15]</ref>. For longer viewing times, the optic flow in the two scenarios diverges and could potentially allow the subjects to disambiguate curved paths from simulated eye rotations.</p><p>Electrophysiological evidence suggests that neurons sensitive to radial expansion in MSTd, which are thought to encode heading, demonstrate modulation due to extra-retinal eye signals <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref>. The modest human bias demonstrated by humans while performing eye movements is less than would be expected given the magnitude of the rotations. Assuming MSTd is involved in heading perception, this could be explained by the extra-retinal signals in MSTd imperfectly 'canceling out' the rotations. Computational models have employed gain fields in MSTd as the mechanism by which this 'canceling out' of rotation may occur <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>Animals navigate over complex terrain and the path of travel is rarely straight <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, but few studies have examined human navigation along curved paths. Those that do tend to examine human path perception in the context of circular paths <ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref>. In the present article, if the path is not straight, we make the assumption of a circular curved path (Figure <ref type="figure" target="#fig_0">1c</ref>). During movement along a curved path, heading and path refer to different characteristics of the observer movement. Heading refers to the instantaneous direction of travel in the world reference frame. From the perspective of the observer, the heading corresponds to the straightaway direction if the curved path were abandoned. Along a circular path, the observer heading is always tangent to circle, aligned in the direction of the clockwise (CW) or counter-clockwise (CCW) traversal. Path corresponds to the fixed curvature trajectory traversed by the observer in world coordinates. Both heading and path are independent of the observer gaze and body orientation.</p><p>When traveling along a curved path without eye or body movements, all rotation in the retinal optic flow is due to the path curvature. Research indicates that in environments composed of random dots, humans can accurately judge the curvature of their path in static environments <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref>. Judgments remain accurate in the presence of independently moving objects <ref type="bibr" target="#b22">[23]</ref>, when the observer gaze or instantaneous heading direction and body orientation are always tangent to the path of travel. This naturally occurs during locomotion. Human judgments of path curvature are not affected by whether the environment is composed of sparse dots, limited lifetime dots, or dense textures <ref type="bibr" target="#b30">[31]</ref>. However, many studies that investigate curvilinear navigation are confounded by whether subjects report heading or future path <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Summary</head><p>Much human and primate psychological and electrophysiological research on visually-guided navigation has focused on heading perception, defined as the instantaneous direction of travel. However, the perception of path of travel, or trajectory, is arguably more important, because it informs in a more general sense whether the observer is on a collision course with moving objects or will intercept a target. In the present article, we describe a theory based on physiological evidence of how primate visual area MSTd may simultaneously and dynamically encode heading and path. The model connects many different sources of data, including psychophysics on human perception of heading and path with and without eye movements, and primate electrophysiological data on path-selective cells in MSTd. We propose neural mechanisms explaining why humans report traveling along curved paths when the display represents a straight path with simulated eye rotations. We predict that perceptual sensitivity to heading and path emerges in primate MSTd through the dynamical and competitive interactions between neurons tuned to the continuum of spiral-radial patterns. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theories of Path Perception</head><p>Existing theories of path perception are a set of heuristics that do not specify the mechanisms by which the path is perceived in the brain. Some theories depend on the active tracking of 'features' in the visual scene <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b34">35]</ref>, while others implicate an extensive cognitive component, such as updating estimates with respect to external reference objects <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>We first summarize the former class of path perception theories. The passing flow line hypothesis observes that optic flow integrated over an extended period of time yields a streamline that passes underneath the observer and coincides with the path of travel <ref type="bibr" target="#b34">[35]</ref>. This hypothesis assumes that the observer gaze is in the direction of heading and requires the environment to have a textured ground plane passing directly underneath the observer. A related hypothesis proposed by Wann and Swapp, which we call the vertical vector hypothesis, notes that if the observer maintains gaze on the destination of travel, the path can be recovered from retinal flow by integrating first-order flow vectors that are vertically aligned <ref type="bibr" target="#b36">[37]</ref>. This strategy does not require knowledge of heading. The vertical flow line hypothesis posits that the visual system tracks the constellation of vertical optic flow streamlines that exist when the observer fixates a point on the future path. This strategy assumes that humans fixate on their destination while traveling along curvilinear paths. The reversal boundary hypothesis notes that the future path of travel coincides with direction reversals or ''zero-crossings'' in the horizontal motion component once the optic flow has been projected onto the retina <ref type="bibr" target="#b26">[27]</ref>; the horizontal motion component of texture inside (outside) the path will be rightward (leftward), or vice versa depending on whether the circle is traversed CW or CCW. While psychophysical evidence suggests that humans are most accurate in judging path curvature when the gaze direction is aligned with the heading, it is not clear how this strategy could tolerate momentary fluctuations in gaze. Warren and colleagues have proposed a vector normal hypothesis whereby the center of the circular path can be determined by computing the intersection of the vector normals of two points in the environment <ref type="bibr" target="#b26">[27]</ref>. Using the vector normals, knowledge of the circular path center, and the observer's current position, the radius and therefore the curvature of the path of travel can be recovered.</p><p>The hypotheses reviewed above suffer from rigid constraints on the environment or observer gaze, and are unlikely to represent general theories of human path perception. The strategies proposed by the passing flow line, vector normal, and vertical vector hypotheses only hold when observers look where they are going-i.e. gaze is along the heading direction. These hypotheses cannot account for activities that presumably depend on the perception of path, such as steering a vehicle <ref type="bibr" target="#b37">[38]</ref>, for which successful control of navigation accompanies natural changes in gaze <ref type="bibr" target="#b36">[37]</ref>. Humans perceive their path of travel in sparse environments composed of small quantities of dots. The boundary reversal hypothesis, however, requires dense optic flow to ascertain the horizontal motion zero-crossing. From a neural computation point of view, it is unclear how the brain could track the contextspecific local features proposed by any of the above hypotheses over time.</p><p>The following path estimation theories rely on external landmarks in the environment. The reference object hypothesis posits that observers either update their position or integrate the change in heading over time with respect to an object embedded in the environment <ref type="bibr" target="#b35">[36]</ref>. Subjects in the experiments of Li and Cheng were able to judge their future path of travel in the absence of persistent objects in the environment, rendering the reference object hypothesis an incomplete strategy <ref type="bibr" target="#b30">[31]</ref>. Li and Cheng tested whether humans can integrate the change in heading without a reference object by tracking the ''drift'' in the FoE over time with gaze remained fixed along a particular axis when the observer travels along the circle without any rotation (Z-axis condition). Subject responses were consistent with the percept of moving along a straight rather than a circular path, making the FoE drift hypothesis unlikely <ref type="bibr" target="#b30">[31]</ref>. Finally, Li and Cheng proposed that observers first estimate heading to established a reference, then estimate the path curvature, which is mathematically defined for a circular path as the ratio between the rotation and translation rates <ref type="bibr" target="#b30">[31]</ref>. It is not clear if, or how, mechanisms in the brain could perform these operations.</p><p>In summary, theories of path perception either treat path perception as independent of heading or depend on its prior estimation. In the present article, we propose a neural model of the primate visual system in which representations of heading and path are determined simultaneously and dynamically interact in the same population of neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neurophysiology of Path Perception</head><p>Neurons in the primate medial superior temporal area (MST) of the superior temporal sulcus (STS) exhibit tuning in the laboratory to radially expanding optic flow patterns, similar to those experienced by an observer moving forward on a straight path. MSTd cells have therefore been the focus of neurophysiological investigations of the mechanisms underlying visually-guided navigation. MST is the earliest visual area, the fewest synapses away from the retina in the primate dorsal stream, that responds to large field pattern motion. Evidence suggests that MST in monkey is composed of functionally distinct dorsal (MSTd) and ventral (MSTv) regions. Whereas neurons in MSTd exhibit sensitivity to optic flow patterns that occupy areas of the visual field as large as 100 0 , MSTv neurons have smaller receptive field sizes and are suspected to be involved in the perception of object motion <ref type="bibr" target="#b38">[39]</ref>. MSTd neurons demonstrate sensitivity to dot speed <ref type="bibr" target="#b39">[40]</ref> and spatial shifts in FoE position <ref type="bibr" target="#b40">[41]</ref>, and therefore are thought to be involved in heading perception <ref type="bibr" target="#b41">[42]</ref>.</p><p>Froehler and Duffy have conducted the only neurophysiological study to date that reports the existence of ''path selective'' neurons in cortex <ref type="bibr" target="#b42">[43]</ref>. Monkeys were placed on a sled in a dark room that contained bright dots on the three walls that were within view. The sled moved CW or CCW along a circular path (Figure <ref type="figure" target="#fig_1">2</ref>). The sled was configured not to rotate the body as it traversed the circular path. The monkeys maintained gaze, throughout the trial, on a target that was projected from the sled onto the distal wall. Because the projector was attached to the sled and the monkey was trained to maintain gaze on the target, the fixation point occupied the same position within the monkeys' visual field over time. The optic flow experienced by the monkeys contained no rotation and appeared to radially expand or contract at each instant, with a FoE or focus of contraction (FoC) that 'drifted' horizontally during the trial. A monkey traveling once around the circle on the sled therefore viewed a sequence of headings and each had an equivalent at antipodal positions in both the CW and CCW trials. Froehler and Duffy recorded from single neurons in MSTd and 73% elicited differential activity at antipodal positions on the track, where expansion/contraction optic flow patterns were identical. The neurons' response depended on whether the circle was traversed CW or CCW, and as a result the authors claimed these cells demonstrated path selectivity. The authors also found heading selective cells, which fired when the optic flow contained their preferred heading irrespective of the CW or CCW traversal direction, and place selective cells, which responded when the monkey moved to a particular location of the room irrespective of the visual motion pattern. The selectivity of neurons in the sample was distributed along a continuum, ranging from those demonstrating high (path selective) to those demonstrating low (heading selective) CW v.s. CCW differential activity. The mechanisms that underlie how these cells in MSTd respond along a continuum to heading and path were not evaluated by the study.</p><p>In summary, neurons in MSTd demonstrate tuning to optic patterns, similar to those that would be viewed by an observer traveling on a straight path, and may exhibit sensitivity to path in the absence of rotation <ref type="bibr" target="#b42">[43]</ref>. Locomotion along curved paths typically involves rotation, so, if the neurons discovered by Froehler and Duffy are in fact path-selective, it remains unclear how their response patterns would generalize to more natural movement conditions. Our model proposes mechanisms by which the MSTd neurons identified by Froehler and Duffy elicit differential firing rates when the instantaneous visual motion appears the same, yet the monkey moves CW or CCW around the circle. Our analysis integrates the findings with other known properties of MSTd neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spiral-Selective MSTd Cells Dynamically Encode Path and Heading Direction</head><p>If the primary role of MSTd were to determine heading, most MSTd neurons would be expected to preferentially respond to radial expansion and contraction. While many neurons in MSTd are tuned to such patterns, many others exhibit preferential responses to patterns in a spiral space spanned by radial and center templates (Figure <ref type="figure" target="#fig_2">3</ref>). Moreover, neurons in MSTd would be expected to discount retinal rotation, as many appear to do with extra-retinal rotation <ref type="bibr" target="#b15">[16]</ref>. However, Orban and colleagues demonstrated that MSTd neurons tuned to radial expansion did not respond to expansion displays when adding simulated retinal rotation <ref type="bibr" target="#b43">[44]</ref>. Therefore, rotation does not appear to be discounted in MSTd neurons when the source is retinal rather than extra-retinal. Graziano and colleagues found that more neurons preferentially responded to CW and CCW spirals than to rotation or contraction, and the tuning curve width and selectivity did not differ across the MSTd population for radial, spiral, and center patterns <ref type="bibr" target="#b44">[45]</ref>. That is, neurons tuned to radial expansion did not exhibit sharper tuning curves than those tuned to spirals. Spiral tuning also appears in neurons in the ventral parietal area (VIP) <ref type="bibr" target="#b45">[46]</ref> and area 7a <ref type="bibr" target="#b46">[47]</ref>, two of the brain regions to which MSTd projects <ref type="bibr" target="#b47">[48]</ref>. Despite the diversity of tuning in MSTd, no well-defined hypothesis has been proposed for the functional role of MSTd neurons tuned to spiral patterns. Graziano and colleagues speculated that spiral tuning may allow MSTd to detect a rotating moving object or perceive the pattern of motion experienced by walking forward while tracking a point on the ground, however, these hypotheses are unproven.</p><p>We claim that selectivity to optic flow across a spiral space continuum simultaneously affords MSTd with sensitivity to the curvature of the path and to the heading direction. When an observer travels along a curvilinear path on a ground plane with a  <ref type="bibr" target="#b42">[43]</ref>. A monkey seated in a sled traveled CCW (a) or CW (c) along a circular track while maintaining gaze on the distal wall of luminous dots. The body, head, and eye did not rotate so that the monkey always directly faced the distal wall. The monkey therefore experienced radially expanding or contracting optic flow without sources of rotation. (b,d) Instantaneous optic flow experienced by the monkey at different locations along the circular track. In (b) at t 0 , the monkey views a radially expanding optic flow while moving CCW when the heading direction is straight ahead, which is the same as the optic flow viewed CW 180 0 on the other side of the circle. Between t 0 and t 1 , the FoE drifts rightward until at t 1 it is out of view. At t 2 , the monkey experiences radial contraction. doi:10.1371/journal.pcbi.1003476.g002 fixed direction of gaze, a spiral-like pattern is experienced and optic flow contains rotation that specifies the path curvature <ref type="bibr" target="#b30">[31]</ref>. Theoretically, spiral selective neurons should be sensitive to the curvature of their preferred spiral pattern and would therefore be capable of extracting information about the future path. Although the actual representation in the brain is unlikely to resemble an abstractly-defined mathematical spiral space <ref type="bibr" target="#b48">[49]</ref>, we assume that the spiral space selectivity in MSTd spans the continuum between radial and center patterns that has been electrophysiologically tested in numerous studies <ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref>. Because we developed a neurophysiological model, it is important to constrain the model to constructs that can be verified by data. Since no neurophysiological data exists with more ecological stimuli we would be unable to verify a model design constructed using such templates designed to reflect our intuitive understanding of the ecologically valid space.</p><p>Figure <ref type="figure" target="#fig_3">4</ref> shows a visualization of the proposed functional organization of MSTd. Each cylindrical volume represents a functional MSTd hypercolumn with respect to spiral selectivity. A hypercolumn contains a subpopulation of MSTd neurons that are sensitive to a spectrum of optic flow patterns in spiral space that have receptive fields centered at the same location of visuotopic space. The horizontal (x) and vertical (y) axes specify the spatial dimensions of the MSTd visuotopic map. Each point in this twodimensional space indicates tuning to a FoE, FoC, or more generally a center of motion (CoM) in that particular visuotopic location-irrespective of the pattern selectivity. For example, the top-right hypercolumn in Figure <ref type="figure" target="#fig_3">4</ref> contains subpopulations of MSTd neurons tuned to motion patterns (e.g. radial expansion, radial contraction, spiral, center) that have the CoM located on the top-right region of the visual field. The axis than spans the depth of the hypercolumn represents the degree of spiral tuning for the subpopulation of neurons that have receptive fields centered at a particular location of the visual field. MSTd neurons may exhibit tuning to CW or CCW spiral patterns that either expand or contract. Spiral patterns smoothly vary in 'spirality' between patterns that are radial with no curvature (top and bottom), and those that are centers (left and right). We propose that the 'spirality' of the most active subpopulation of neurons in MSTd encodes the curvature of the path, and the two-dimensional visuotopic position of that maximally active subpopulation represents the heading.</p><p>In the simple case of travel along a straight path, we expect neurons tuned to radial expansion to be most active, indicating no path curvature, and we anticipate the peak to spatially coincide with the FoE to indicate the heading. Therefore, the population MSTd response in this example is the same as if there were only neurons selective to radial patterns. In the case of a circular path, we expect the spiral-selective neurons with spiral arms that best match the path curvature to be most active. As reported in several psychophysical studies <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b30">31]</ref>, different gaze patterns modulate the rotation present in the optic flow. In the present paper, we test whether the maximal activity of neurons tuned in spiral space maps onto human judgments of path curvature as gaze varies.</p><p>We present a dynamical model of primate MSTd that builds on electrophysiological findings and explains a range of human psychophysical data on path and heading perception with and without eye movements. The main goal is to present a mechanistic hypothesis of path perception that provides a unified framework to interpret psychophysical and neurophysiological data on heading and path perception. Our model goes beyond existing heuristics by providing a mathematical description and biologically-plausible implementation that is readily testable. Our analysis and simulations show that the model yields performance similar to humans under different gaze conditions, circular path radii, and eye movement patterns. The model predicts that the neurons reported by Froehler and Duffy obtain their path selectivity through spiral pattern tuning <ref type="bibr" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Methods</head><p>Our objective was to create a biologically plausible model of the primate visual system that demonstrates the mechanisms by which perception of heading and path may arise from populations and systems of neurons that process optic flow. The model consists of systems of shunting differential equations, each of which models the activity neurons in cortex <ref type="bibr" target="#b49">[50]</ref>. This architecture affords realistic neural temporal and competitive dynamics, including recurrent competition and feedback, gain control, and normalization. By creating a computational model using known functional properties of neurons in the magnocellular pathway of the dorsal stream, we can simultaneously connect neurophysiological mechanisms to human data and our test our hypothesis on diverse types of psychophysical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Area Descriptions</head><p>The proposed neural model contains three stages that correspond to primate primary visual cortex (V1), medial temporal area (MT), and the dorsal medial superior temporal area (MSTd) (Figure <ref type="figure" target="#fig_5">5</ref>). In this paper, we do not model retinal input, but rather use analytical equations to model the vector-based optic flow representation in V1 <ref type="bibr" target="#b50">[51]</ref>. A prior version of the model demonstrates how retinal inputs are processed through neural circuits to generate those representations <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53]</ref> V1 (Local motion detection). We generated videos of dots distributed on a ground or frontoparallel plane, which served as input to the model. The videos approximate the visual displays shown to human subjects in psychophysical experiments that assess human heading and path perception. The local motion of the dots was computed according to a planar pin-hole camera model <ref type="bibr" target="#b53">[54]</ref>. The following equation describes first-order optic flow with translation vector T T~(T x ,T y ,T z ) and rotation vector R R~(R x ,R y ,R z ) <ref type="bibr" target="#b54">[55]</ref>:</p><formula xml:id="formula_0">u x u y ~_ x x _ y y ~1 Z {1 0 x 0 {1 y T x T y T z 0 B @ 1 C A z xy {(1zx 2 ) y (1zy 2 ) {xy {x ! R x R y R z 0 B @ 1 C A:<label>ð1Þ</label></formula><p>The representation in model V1 computed by Eq. 1 describes the instantaneous velocity (u x ,u y ) of each projected dot. In Eq. 1, Z signifies the depth of the projected dot in the world and (x,y) correspond to the spatial position in the 2D projection plane.</p><p>Values for the parameters T T and R R varied according to psychophysical conditions, as described in Experimental Descriptions. For simplicity we use a Cartesian representation of space in V1, although prior work has demonstrated how motion can be processed with cortical magnification <ref type="bibr" target="#b19">[20]</ref>.</p><p>MT (Motion pooling). Model MT units pool the V1 response vectors (u x ,u y ) component-wise with a Gaussian recep-tive field kernel G MT (m MT ,s MT ). We configured model MT neurons with m MT ~0, s MT ~0:05 0 , and radius r~3 0 , as in previous work to mimic the larger receptive fields in MT compared to V1 <ref type="bibr" target="#b50">[51]</ref>. Model MT units respond to large fields of uniform motion and project to MSTd. The pooled model V1 activity in model MT is denoted (v x ,v y ).</p><p>MSTd (Gain fields, spiral template matching, recurrent competition). Model MSTd consists of three stages: 1) eye velocity gain fields, 2) template matching in spiral space, and 3) dynamical recurrent competition. When the eye velocity is nonzero (e.g. during a smooth-pursuit eye movement), the extraretinal signal p p(t) acts presynaptically to MSTd <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>:</p><formula xml:id="formula_1">(w x ,w y )~(v x ,v y ){p p(t):<label>ð2Þ</label></formula><p>In Eq. 2, (v x ,v y ) represents the output of model MT and (w x ,w y ) describes the signal after extra-retinal modulation. We simulated the conditions of Cheng and Li, whereby subjects made judgments about their future curvilinear path while visually tracking a horizontally moving target <ref type="bibr" target="#b24">[25]</ref>. Because the target moved at a constant velocity and the experimenters discarded data 150msec from the onset of the eye movement, we set p p(t)~(n,0), where n is proportional to the mean pursuit eye movement speed across subjects in each respective condition. The sign depends on the eye movement direction. We generated spiral templates that spanned the entire visual field by interpolating radial and center vector field patterns (Figure <ref type="figure" target="#fig_2">3</ref>) <ref type="bibr" target="#b55">[56]</ref>. Eq. 3 defines a radial field A and a center field B:  </p><formula xml:id="formula_2">A ~DA (x{x 0 ,y{y 0 ) B ~DB (y{y 0 ,{(xzx 0 )) D A ,D B [f{1,1g:<label>ð3Þ</label></formula><p>When y~0, the template is radial, when y~1, the template is a CW center, and C is a spiral template for other values of y.</p><p>We created a neural model with 11500 MSTd neurons with motion pattern selectivities determined by the templates in spiral space. The templates were uniformly sampled across the spiral continuum within the visual field (110 0 x94 0 ). We configured the spatial offsets (x 0 ,y 0 ) to encompass possible CoM that appeared outside the retinal projection plane in the experiments of Li and Cheng. We found that simulating templates with CoM selectivities far outside the field of view did not impact model performance. This occurred because laminar flow vectors from the template, which are uniform in direction, appear within the field of view and yield poor matches to the optic flow signal. For example, a CCW center template with a CoM selectivity far to the left only responds to uniform vertical motion within the field of view, which does not closely resemble the optic flow experienced while traveling along a curved path. As described below, a model MSTd neuron with weak input from the template matching stage will be suppressed in the competitive dynamics and not affect heading or path curvature estimates produced by the model.</p><p>Each model neuron receives afferent signals from model MT, which passes through a template matching stage to assess the degree of similarity between the input signal and model neuron's pattern tuning. The match score at time t, M(y,D B ,x,y,t), for the neuron at location (x,y) with preferred spirality y and orientation D B is computed according to the following inner product:</p><formula xml:id="formula_4">M(y,D B ,x,y,t)~l P fm,ng e {((m{x) 2 z(n{y) 2 ) | X fwx,wyg C(y,D B ,m,n)8(w x ,w y ) ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi w 2 x zw 2 y q 0 B @ 1 C A :<label>ð5Þ</label></formula><p>Eq. 5 computes an inner product (i.e. cosine similarity) by performing component-wise multiplication, indicated by 8, between the input optic flow (w x ,w y ) and the spiral template C. The result is normalized by the L 2 norm of the optic flow vector and the vector components are summed. An exponential distancedependent weighting is applied to give matches near the CoM greater weight and to afford sensitivity to the CoM position within the visual field, which is consistent with known properties of MSTd neurons <ref type="bibr" target="#b40">[41]</ref>. This is followed by a summing over all spatial locations to obtain a scalar match score. Exponential distance dependent weighting has been used in a previous version of the model to balance foveal and peripheral motion components in the grouping of time to contact within an object or surface <ref type="bibr" target="#b56">[57]</ref>. The parameter l is set to the reciprocal of the number of dots such that the match score is not biased by the number of vector samples. Eq. 6 defines a dynamical competitive network that describes the activation of model MSTd neuron S at spatial location (x,y) that is selective to a spiral pattern with spirality y and spiral orientation D B (CW v.s. CCW):</p><formula xml:id="formula_5">dS y,D B ,x,y dt ~E({aS y,D B ,x,y z(b{S y,D B ,x,y ) (S 2 y,D B ,x,y zf (M(y,D B ,x,y,t))) {S y,D B ,x,y X i=s X j=o m X k=x X l=y S 2 i,j,k,l ) ! ! :<label>ð6Þ</label></formula><p>Eq. 6 is a recurrent competitive field and is configured as a contrast-enhancing or winner-take-all network <ref type="bibr" target="#b49">[50]</ref>. Competition between neurons in the network occurs across location and spiral template space. The constant E is defined as the reciprocal of the membrane time constant of the model neuron and scales how fast the neuron responds, a signifies the passive decay rate, and b is the saturation upper bound of the model neuron. In Eq. 6, the inhibition model neurons receive from others in the network that have different spiral pattern and orientation sensitivities is set to unity weight, and m differentially weights the spatial competition. Table <ref type="table" target="#tab_0">1</ref> summarizes parameters values that were used in configuring the MSTd dynamics. The function f (w) in Eq. 6 is a sigmoidal transfer function defined as</p><formula xml:id="formula_6">f (w)~½ w{C z À Á 2 fz ½w{C z À Á 2 ,<label>ð7Þ</label></formula><p>where ½ : z indicates the half-wave rectification max( : ,0), C is a threshold on the input from model MT, and f is a sigmoid shape parameter defining the inflection point.</p><p>Path curvature c ? and heading h ? are computed according to Eqs. 8 and 9, respectively, by considering the spirality and spatial position that elicited the maximal MSTd subpopulation activation.</p><formula xml:id="formula_7">c ? ~argmax y S y,D B ,x,y<label>ð8Þ</label></formula><formula xml:id="formula_8">h ? ~argmax x,y ð Þ S y,D B ,x,y<label>ð9Þ</label></formula><p>Note that the argmax operations defined in Eqs. 8-9 are not part of the model computations, and simply allow us to compare the model population activity with judgments made by humans in psychophysical experiments. The MSTd distribution is itself a representation of the confidence that the observer has in the heading direction and path percept. In some senses the distribution itself can be considered a probabalistic read-out, however human subjects were not asked to provide a distribution of confidence over the space so we have no way to validate whether or not our distribution matches human performance. Forcing a decision and taking the maximum likelihood allows us to compare model output against the same forced choice task in humans. We do not claim that the brain decodes information about heading and path distributed across the population in MSTd using maximum likelihood.</p><p>Our model does not require the CoM to appear within the field of view to compute heading or path curvature. Model MSTd neurons that possess CoM selectivities outside the field of view estimate heading and path curvature using the available visual information.</p><p>All simulations were run on a 8-core 2.66 Ghz Mac Pro with 64 GB of memory using Mathematica 8. Routines involving numerical integration of network dynamics (Eq. 6) and template matching (Eq. 5) were written in C++. Parameter values listed in the text specify those that remained constant throughout all simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Descriptions</head><p>Unless otherwise noted, all simulation parameters matched those used in the following psychophysical experiment descriptions.</p><p>Path Perception &amp; Gaze. We simulated the five experimental conditions of Li and Cheng to compare path estimates produced by the model to those produced by human subjects (Figure <ref type="figure" target="#fig_7">6</ref>). In the experiment, subjects viewed computer displays that simulated observer travel along a circular path <ref type="bibr" target="#b30">[31]</ref>. All coordinates are given with respect to a three-dimensional world coordinate system whereby the origin corresponds to the center of the circular path, the observer begins movement at (X ,Y ,Z)~(dr, y y,0), and the observer's position at time t is given by (drcos(vt), y y,drsin(vt)), where r represents the radius of the circular path, the observer either moves CW or CCW about the path, d is 1 for CCW path traversals and {1 for CW traversals, v signifies the rate of traversal around the circle, and y y corresponds to the observer eye height. The observer translation vector T T is given by:</p><formula xml:id="formula_9">T T ~Tx ,T y ,T z À Á ~d dt (drcos(vt), y y,drsin<label>(vt))</label></formula><p>~({drvsin(vt),0,dvcos(vt):</p><p>Each trial lasted 1 sec during which time the observer traveled 3 meters around the circular path. Therefore, we fix v~3 r . No trial resulted in a traversal greater than a quarter circle. Since the observer motion remained parallel with respect to the XZ plane throughout each trial, T y ~0. In the experiments of Li and Cheng, the gaze conditions were simulated in the computer display while subjects fixated a stationary fixation cross above the ground plane horizon throughout the trial. Rotation in the optic flow experienced by subjects therefore results from two sources: the curvature of the circular path, and the simulated gaze direction. For example, when a subject fixates a simulated target, rotation occurs due to a combination of gaze and the path curvature. Gaze was simulated to only vary at eye height. Therefore, R y depended on the gaze condition and R x ~Rz ~0.</p><p>Each condition was identical except for the simulated observer gaze (i.e. no eye movements). In the Z-axis condition, an observer was simulated to travel on a circular path and gaze remained parallel to the Z-axis (Figure <ref type="figure" target="#fig_7">6a</ref>). The instantaneous vector field contained no rotation, the field at any time appeared to radially expand, and over time the FoE laterally 'drifted'. Since there was no rotation in the Z-axis condition, R y ~0. In the outside path condition, the simulated gaze was on a target 15 0 outside the circular path (Figure <ref type="figure" target="#fig_7">6b</ref>). In this case,</p><formula xml:id="formula_11">R y ~rv(x o cos(vt)zz o sin(vt){r) r 2 zx 2 o zz 2 o {2rx o cos(vt){2rz o sin(vt) ,<label>ð11Þ</label></formula><p>where (x 0 , y y,z 0 ) is the position of the target, which was r meters from the observer's initial position (see <ref type="bibr" target="#b57">[58]</ref> for derivations). In the on path condition, the simulated gaze was on a target 30 0 away from the initial heading and R y ~v 2 (Figure <ref type="figure" target="#fig_7">6c</ref>). In the inside path condition, the simulated gaze was on a target located 15 0 inside the path and R y is equal in magnitude but not direction to the value in the outside path condition (Figure <ref type="figure" target="#fig_7">6d</ref>). The gaze along heading condition is the natural case whereby the observer's gaze was simulated to be aligned and rotate with the body and the observer's heading was always tangent to the path, so R y ~v (Figure <ref type="figure" target="#fig_7">6e</ref>). For all path conditions, the observer traveled along circular paths with radii 28 m, 38m, and 58 m. The environment consisted of 200 dots randomly distributed along a ground plane 1:4-50 m in depth. An analysis of model performance as a function of dot count is shown in Results. We clipped dots that exited the 120 0 field of view. The computer projector had a 60 hz refresh rate, so we simulated observer motion across 60 frames of video. At the end of each trial, subjects manipulated a probe a fixed depth away such to intercept the future path, were the trial to continue. Path error was determined by computing the angular difference between the subject response and future path.</p><p>To compare model path estimation performance and human psychophysical data, we must map characteristics from the neural population response in MSTd to human perceptual space. The abscissa of the peak along the spiral pattern continuum (Eq. 8), defines a read-out of the model's representation of path curvature. To compute path error in the model, we subtract model path estimates (Eq. 8) in each gaze condition with that yielded in the gaze along heading condition. Comparing path estimates to that obtained in the gaze along heading condition calibrates the model to the situation wherein judgments of path curvature are accurate. This occurs when humans look where they are going, which is often the case during normal locomotion <ref type="bibr" target="#b25">[26]</ref>. No additional transformation, other than the subtraction, was necessary to fit the psychophysical data.</p><p>Path Perception &amp; Eye Movements. The experiment of Cheng and Li followed the same paradigm as the preceding study <ref type="bibr" target="#b30">[31]</ref>, but introduced real eye rotations through two conditions in which subjects performed smooth-pursuit eye movements to track a horizontally moving target on the computer display <ref type="bibr" target="#b24">[25]</ref>. The orientation along heading condition was the same as the gaze along heading condition, except subjects tracked a target moving toward the exterior of the path, which had the effect of linearizing the optic flow <ref type="bibr" target="#b58">[59]</ref>. The orientation along Z-axis condition was the same as the Z-axis condition, except subjects tracked a target moving toward the interior of the path, which had the effect of adding extra-retinal rotation. The two conditions were configured such that the first-order retinal optic flow appeared the same. In the orientation along heading condition, the mean subject pursuit eye movement speeds were 1:42 0 =sec, 2:05 0 =sec, and 2:75 0 =sec for path rotation rates of 3:0 0 =sec, 4:5 0 =sec, and 6:0 0 =sec. In the orientation along Z-axis condition, the mean subject pursuit eye movement speeds were 1:5 0 =sec, 2:05 0 =sec, and 2:63 0 =sec for path rotation rates of 3:0 0 =sec, 4:5 0 =sec, and 6:0 0 =sec. In the Z-axis condition, an observer was simulated to travel on a circular path and gaze remained parallel to the Z-axis (Figure <ref type="figure" target="#fig_7">6a</ref>). The instantaneous vector field contained no rotation, the field at any time appeared to radially expand, and over time the FoE laterally 'drifted'. In the outside path condition, the simulated gaze was on a target 15 0 outside the circular path (Figure <ref type="figure" target="#fig_7">6b</ref>). In the on path condition, the simulated gaze was on a target 30 0 away from the initial heading (Figure <ref type="figure" target="#fig_7">6c</ref>). In the inside path condition, the simulated gaze was on a target located 15 0 inside the path (Figure <ref type="figure" target="#fig_7">6d</ref>). The gaze along heading condition is the natural case whereby the observer's gaze was simulated to be aligned and rotate with the body and the observer's heading was always tangent to the path (Figure <ref type="figure" target="#fig_7">6e</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path Perception and Gaze</head><p>Positive and negative path errors correspond to overestimations and underestimations of the path curvature, respectively. Zero path error signifies an accurate assessment of path curvature. Mean model path errors agree well with those produced by humans subjects in the experiments of Li and Cheng <ref type="bibr" target="#b30">[31]</ref>. The model and human subjects on average underestimated the path curvature in the Z-axis, outside path, and on path conditions, overestimated the path curvature in the inside path condition, and accurately judged the path curvature when gaze was aligned with the heading direction.</p><p>When optic flow experienced by an observer moving along a curvilinear path is presented to the model, a subpopulation of units in a particular model MSTd hypercolumn becomes most active (Figure <ref type="figure" target="#fig_3">4</ref>). Path curvature is coded by the spiral tuning of these most active units in MSTd. The visuotopic tuning of this maximally active subpopulation does not impact the encoding of path curvature. Figure <ref type="figure" target="#fig_8">7b</ref> plots the peak magnitude of each MSTd unit tuned to a different template in spiral space, irrespective of the unit's tuning in visuotopic space, in the five gaze conditions when the path curvature was 38 m. The x axis corresponds to the pattern tuning across the spiral space continuum, and the y axis shows the maximal activity elicited by units sensitive to a particular optic flow pattern in spiral space, irrespective of its visuotopic tuning. A spirality of 0 signifies a MSTd neuron that is preferentially tuned to radial expansion, a spirality of 1 indicates a tuning to CCW center motion patterns, and intermediate values correspond to preferential responses to CCW spiral patterns. In the Z-axis and outside path conditions, the maximally active MSTd unit was the one that was sensitive to radial expansion (y~0). The positions of MSTd activity peaks in the Z-axis (black) and outside path (red) conditions were to the far left of the spiral space continuum. Radially expansion patterns contain no curvature, therefore, the model signals, similar to humans, in the Z-axis and outside path conditions that the path is straight.</p><p>To compute path error from representations of path curvature in the model, we have to ground the spiral continuum into perceptual space. When humans look where they are going, judgments of path curvature are accurate. This is most often the case during normal locomotion <ref type="bibr" target="#b25">[26]</ref>, so we calibrate the model around the distribution of activity in model MSTd yielded in the natural gaze along heading condition (Figure <ref type="figure" target="#fig_8">7b</ref>, blue). We subtracted the spirality of the peak obtained in each condition (c ? ) from that obtained in the gaze along heading condition to yield the model path error. We were able to configure the model such that no transformation of the subtraction in spiral space was required to yield the results shown in Figure <ref type="figure" target="#fig_8">7</ref>.</p><p>The ordinal positions of peaks shown in Figure <ref type="figure" target="#fig_8">7b</ref> correspond to path errors made by humans in the experiments of Li and Cheng <ref type="bibr" target="#b30">[31]</ref>. As mentioned above, the MSTd activity peaks in the Z-axis and outside path conditions are produced by units tuned to radial expansion. These peaks are positioned far to the left compared to the activity peak in the gaze along heading condition, indicated by the blue *. Subtraction of the abscissae of the peaks yields large magnitude negative path errors, consistent with the large underestimations of path curvature made by human subjects. The position of the activity peak in the on path condition (pink) is closer to that in the gaze along heading condition (blue *). This yields a negative path error, albeit lower in magnitude than those produced in the Z-axis and outside path conditions. Therefore, the model signals an underestimation of path curvature, consistent with the judgments of human subjects.</p><p>The bimodality observed in the MSTd activity distributions shown in Figure <ref type="figure" target="#fig_8">7b</ref> arise due to an interaction between the input optic flow, temporal dynamics, and competition in the model. Retinal flow that contains a large amount of rotation (e.g. inside path condition) yields activity peaks in units tuned to spiralities around 1. Conversely, flow that contains a small amount of rotation (e.g. Z-axis condition) yields activity peaks in units tuned to low spiralities around 0. Due to observer gaze, the rotational component in the optic flow changes over time during travel along the circular path. As a result, the activity peaks in model spiral space, such as those shown in Figure <ref type="figure" target="#fig_8">7b</ref>, ''move'' over time. Subpeaks arise, such as the ''ripples'' in the green curve, because at one point in the time history, a unit with the corresponding spirality of the subpeaks was most active. Competitive dynamics in the network suppress subpeaks over time. Although peaks in spiral space stabilized in the network, subpeaks were not always completely suppressed by the end of the trial. Because the projected CoM location and rotation in the optic flow vary nonlinearly with time (e.g. Eq. 11), peaks are not always displaced Model MSTd activity across spiral pattern selectivity space during an exemplar trial with a 38m path radius for the five gaze conditions. The location of each peak across the spiral continuum determines the model estimate of path curvature. For example, in the Z-axis condition (black), the MSTd activity peak occurs in the subpopulation sensitive to radial expansion (y~0), and therefore the model indicates zero path curvature (straight path). (c) Model path errors (solid lines) compared to human data from Li and Cheng (replotted, dashed lines) in the five gaze conditions as a function of path curvature <ref type="bibr" target="#b30">[31]</ref>. Model path errors were in good agreement in all gaze conditions with those based on human judgments (rw0:94), and path error decreased linearly (R 2 w0:95) with path curvature. Error bars correspond to standard error of the mean (SEM). doi:10.1371/journal.pcbi.1003476.g007 to continuous locations in spiral space. This yields a bimodal distribution. Note that the ''valley'' between the peaks in the inside path and gaze along heading conditions arose due to the spatiotemporal characteristics of the input optic flow and the MSTd network. Peaks emerged within this region of spiral space when simulating travel along paths with different radii.</p><p>Figure <ref type="figure" target="#fig_8">7c</ref> compares the average path produced by the model (solid lines) with those yielded by human subjects (dashed lines) in the five gaze conditions of Li and Cheng <ref type="bibr" target="#b30">[31]</ref>. Model path error is assessed on 58 m, 38 m, and 28 m radii circular paths with curvatures of 0:017m { 1, 0:026m { 1, and 0:035m { 1, respectively. Error bars in Figure <ref type="figure" target="#fig_8">7c</ref> correspond to the standard error of the mean (SEM) yielded over 100 simulations of the model. Our model is deterministic, but the random dot positions in the input introduced variance into the results. Model path estimates produced a good fit to those yielded by human subjects in the Z-axis (r~0:98), outside path (r~0:99), on path (r~0:99), inside path (r~0:96), and gaze along heading (r~0:95) conditions. Similar to human subjects, the model overestimated path curvature when gaze was inside of the path (green) that had the least curvature (0:017m { 1). As the path curvature increased, path curvature estimates in the model converged to those obtained in the gaze along heading condition. In the highest path curvature condition, the model path curvature estimates followed the tendency for humans to largely underestimate the path curvature in the on path, outside path, and Z-axis conditions. Across all conditions, the decrease in path error varied as a linear function of increasing path radius (R 2 w0:95).</p><p>The dynamics in model MSTd explain why humans overestimate path curvature in the gaze inside path condition along paths with larger radii, but yield more accurate estimates when the path radius is small. In the gaze inside path condition (green), a bimodal distribution emerged in model MSTd. The activity peak occurred to the CCW center side of the spectrum, indicated by the green *, and a subpeak occurred closer to the middle of the spiral continuum, indicated by the green { (Figure <ref type="figure" target="#fig_8">7b</ref>). Recall that path error is computed in the model by considering the distance between the peaks obtained in a particular condition and in the gaze along heading condition, indicated by the blue *. As shown in Figure <ref type="figure" target="#fig_8">7b</ref>, a subpeak exists in the gaze along heading condition, indicated by the blue {, which is close to the peak in the gaze inside path condition (green *). When path curvature increases, more rotation is introduced into the optic flow, which changes the distribution of activity in MSTd spiral space. The subpeak in the gaze along heading condition (blue {), becomes dominant and its proximity to the peak in the gaze inside path condition (green *) results in small path errors. Therefore, high path rotation brings the MSTd peaks (blue { and green *) closer together in the gaze inside path and gaze along heading conditions, yielding close to zero path error. The opposite occurs when the path radius increases-the peak in the gaze along heading condition (blue *) shifts leftward in Figure <ref type="figure" target="#fig_8">7b</ref>, yielding larger path error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path Perception and Eye Movements</head><p>Figure <ref type="figure">8</ref> plots the results of model simulations of the two experimental conditions of Cheng and Li, in which human subjects performed smooth pursuit eye movements to track a moving target <ref type="bibr" target="#b24">[25]</ref>. Path errors produced by our model fit the human data well in both the orientation along heading (r~0:97) and orientation along Z axis (r~0:99) conditions. Model gain fields modulate the optic flow signal proportional to the mean eye tracking speeds of human subjects, which increase with path curvature. Model gain fields modulate the optic flow signal proportional to the mean eye tracking speeds of human subjects, which increase with path curvature. Subjects tracked a target moving in the direction of the drift in FoE position in the orientation along Z-axis condition. The only source of rotation in the optic flow field is that due to pursuit eye-movements, the gain field adds rotation in the opposite direction with a pursuit-speed proportional magnitude, effectively nulling the rotation and producing a translation-only optic flow field. The model increasingly underestimates the path curvature as the curvature increases because the combined effect of rotation due to path curvature, rotation due to eye-movements, and rotation added by the gainfields is a rotation component of the flow field that is less than would be observed due to path curvature alone. As a result, model path errors are small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heading</head><p>In Figure <ref type="figure">9a</ref>, model heading bias in the outside path, on path, and inside path conditions is compared to that of human subjects in the experiments of Li and Cheng <ref type="bibr" target="#b30">[31]</ref>. Heading is represented in the model as the preferred 2D visuotopic position of the maximally active MSTd neurons (see Materials and Methods). Positive and negative heading errors correspond to heading judgments biased in the direction of and opposite to the path curvature, respectively. Human heading judgments were slightly biased outside the path in the outside path and on path conditions, and more greatly biased toward the inside of the path in the inside path condition (Figure <ref type="figure">9a</ref>, red) <ref type="bibr" target="#b30">[31]</ref>. The model produced similar heading errors, but unlike the human data, model heading estimates were veridical in the outside path condition. This occurred because the model was not sensitive enough to detect differences between the MSTd activity peaks in the Z-axis and Figure <ref type="figure">8</ref>. Model path error in conditions that involve smooth pursuit eye movements. The optic flow that appears on the observer retinal during smooth pursuit of a horizontally moving target is identical in the orientation along heading and orientation along Z-axis conditions. The orientation along heading condition is similar to the gaze along heading condition, except the observer tracks a target that moves in the direction opposite of the path curvature. The orientation along Z-axis condition is similar to the Z-axis condition, except the observer tracks a target that moves in the same direction of the path curvature. Similar to human subjects, the model yields low path errors for all the path radius conditions because model gain fields compensate in the direction opposite that of the eye movements. The model increasingly underestimates path curvature in the orientation along Zaxis condition, similar to humans. doi:10.1371/journal.pcbi.1003476.g008 Figure <ref type="figure">9</ref>. Heading errors produced by the model during travel along a circular path. Positive and negative heading errors indicate bias in heading judgments in the direction of and the direction opposite to the path curvature, respectively. The model and humans produced small negative heading errors in the on path condition, and more substantial positive bias in the inside path condition. The model yielded veridical heading performance in the outside path condition, which occurred because the model is not sensitive enough to differences in the optic flow in the outside path and Z-axis conditions. Heading bias in the model is preserved over time without (b) and with (c) competition in MSTd. doi:10.1371/journal.pcbi.1003476.g009 outside path conditions (Figure <ref type="figure" target="#fig_8">7b</ref>), so the model signals the veridical heading. Neither heading errors produced by the human subjects nor by the model were influenced by the path radius.</p><p>Figures <ref type="figure">9b-c</ref> depict the temporal evolution of the spatial distribution in MSTd among units sensitive to radial expansion without competition (Figures 9b) and with competition (Figures 9c). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulated Rotation</head><p>In human psychophysical studies that employ a simulated eye rotation condition, the observer moves on a straight path with an added amount of rotation <ref type="bibr" target="#b10">[11]</ref>. However, human subjects report the perception of moving along a curved path <ref type="bibr" target="#b14">[15]</ref>. We tested whether our model produces similar heading bias to human subjects in the simulated rotation condition, which would offer an mechanistic explanation of the curved path percepts. To compute heading bias, we compared the heading garnered by the model in the gaze along heading condition with that obtained when simulating observer travel along a straight path with added rotation rates between +6 0 . We simulated travel toward two fronto-parallel planes and otherwise mimicked experiment 2 of Royden et al. <ref type="bibr" target="#b10">[11]</ref>. Figure <ref type="figure" target="#fig_0">10</ref> depicts model heading bias (blue) for different amounts of simulated rotation fitted by a hyperbolic tangent function (a|tanh(bx), where a~18:45 and b~0:34, R 2 ~0:98). The red curve in Figure <ref type="figure" target="#fig_0">10</ref> shows the hyperbolic tangent function fit (30:88|tanh(0:12x),R 2 ~0:99) to mean human data from <ref type="bibr" target="#b10">[11]</ref>. The sigmoidal functions fit the human data and model well, and the two were well correlated with one another (r~0:98). Figure <ref type="figure" target="#fig_0">10</ref> shows that heading was biased in the direction of the simulated rotation, which is the same sign of error observed in Figure <ref type="figure">9a</ref>. Therefore, both the model and humans data exhibit heading bias in the simulated rotation condition, which may explain the curved path percepts in humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Is Competition in MSTd Necessary?</head><p>Our model incorporates competitive dynamics across a spiral space. To determine whether competition across spirality, spiral orientation (CW v.s. CCW), and visuotopic space in model MSTd was necessary to produce path errors comparable to humans, we selectively lesioned certain competitive interactions between model neurons. Path errors were computed by comparing the peak activity in spiral space to that obtained in the gaze along heading condition, as in the unlesioned case. Figure <ref type="figure" target="#fig_10">11</ref> compares human and intact model mean path errors with those produced when the three types of competition in the model were lesioned. In all cases, omitting a particular type of competitive interaction in the model resulted in changes in path errors. For instance, lesioning the horizontal spatial interactions between model MSTd neurons resulted in a shift and compression in path error across all path radii: the path errors for the inside path, on path, and gaze along heading conditions converged to the same value for each path radius, and path errors in the Z-axis and outside path conditions converged to a different value. Introducing lesions into model MSTd connections garnered results that did not exhibit the same pattern as human judgments. Human behavioral performance is compatible with the use of competitive interactions between subpopulations of cells in MSTd.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Different Dot Densities</head><p>We tested the model stability and path curvature estimation performance as a function of the number of dots in the scene. The path curvature judgments made by human subjects in the experiments of Li and Cheng <ref type="bibr" target="#b30">[31]</ref> and the model results shown in Figure <ref type="figure" target="#fig_8">7</ref> were derived from environments with 200 dots. Figure <ref type="figure" target="#fig_11">12</ref> shows model performance across the path curvature conditions as function of scene dot count. The y axis plots the path error deviation, which indicates the relative path error compared to that obtained with 200 dots. Independent of the path radius, the model yields reliable results, with modest mean path error deviations (v5 0 ) even with only 25 dots. Human path curvature judgments have been tested in environments containing different dot densities in conditions that most closely resemble those in the gaze along heading condition, and model produces similar errors to these human data <ref type="bibr" target="#b26">[27]</ref>. Path errors in scenes with greater numbers of dots than 200 also yielded low magnitude path error deviations, which indicates that the model results shown in Figure <ref type="figure" target="#fig_8">7</ref> are stable and model parameters did not overfit the human data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path Selective Neurons</head><p>Figure <ref type="figure" target="#fig_12">13a</ref> shows a model simulation of first-order optic flow experienced by the monkey in the experiments of Froehler and Duffy <ref type="bibr" target="#b42">[43]</ref>. The gaze of the monkey traveling along the circular track was tantamount to that of the Z-axis condition. Therefore, according to traditional theory, and the assumptions of the experimenters, the radial subpopulation of cells in MSTd was expected to be maximally active due to the absence of rotation in the instantaneous optic flow field. However, in our simulations the maximally active model MSTd subpopulation was tuned to spiral patterns rather than those that are radial (dark orange). When the angular rotation rate v exceeded that used by Froehler and Duffy <ref type="bibr" target="#b42">[43]</ref> (vwv 0 ), MSTd neurons in the model tuned to spiral patterns Figure <ref type="figure" target="#fig_0">10</ref>. Heading bias yielded by the model in the simulated rotation condition with rotation rates between +6 0 . When human subjects fixate on optic flow displays wherein an observer moves along a straight path with rotation, humans make large heading errors in the direction of the simulated rotation and report the perception of travel along a curved path. The model (blue) produced the same sigmoidal pattern of heading bias as human subjects (red). Both sets of data points were fit well with a hyperbolic tangent function. The similarity between model and human heading bias, suggests the model mechanisms can explain the curved path percept reported by human subjects. doi:10.1371/journal.pcbi.1003476.g010 remained the most active. When the angular rotation rate was comparable to that used in the Z-axis condition of Li and Cheng (vvv 0 ), the model neurons selective to radial patterns were most active. Our analysis indicates that temporal accumulation due to the dynamical properties of the MSTd model (Eq. 6) and the distance-dependent weighting (e {(m{x) 2 z(n{y) 2 , see Eq. 5) induced a peak shift in spiral space, from neurons sensitive to radial patterns to those sensitive to spirals. As shown in Figure <ref type="figure" target="#fig_12">13b</ref>, the temporal accumulation and spatial weightings transform the sequence of radial patterns with a 'drifting' FoE into a spiral pattern with a fixed FoE. When the speed around the circle is slower than that of the monkey in the experiments of Froehler and Duffy, the activity in MSTd spiral space is distributed so that the subpopulation of units tuned to radial expansion is most active. At higher speeds around the circle, the position of the MSTd peak shifts so that units sensitive to spiral patterns are most active (Figure <ref type="figure" target="#fig_12">13</ref>). The peak shift occurs at higher speeds because the temporal dynamics 'blur' the flow fields and the spatial weighting distorts the flow near the FoE. Our analysis suggests that the path selective neurons identified by Froehler and Duffy in MSTd are in fact preferentially tuned to spiral patterns, and the spiral space competition employed in our model can explain the mechanism underlying their path selective properties. We predict that if Froehler and Duffy performed their experiment at slower rotation rates, decreased spatio-temporal accumulation would occur and fewer MSTd neurons would yield a differential CCW versus CW path selectivity. In addition, we predict that if Li and Cheng simulate travel along circular paths at faster rotation rates in the Zaxis condition, subjects would underestimate path curvature to a lesser degree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this article, we present experiments using a computational model of the primate dorsal stream to test our claim that area MSTd can simultaneously code heading and path curvature. We posit that the underlying mechanism involves competition between neurons in MSTd that are sensitive to large field spiral motion patterns. Electrophysiological data support our definition of MSTd spiral tuning space as a continuum, ranging from radial expansion or contraction to CW and CCW center motion patterns (Figure <ref type="figure" target="#fig_2">3</ref>). We tested our spiral coding hypothesis through model simulations of observers moving along curvilinear paths, and comparing results to those garnered by studies of human path perception. We simulated the experiments of Li and Cheng, wherein observers viewed displays simulating travel along circular paths with different radii and loci of gaze <ref type="bibr" target="#b30">[31]</ref>. The model produced similar errors to humans that maintained five different patterns of gaze (Figure <ref type="figure" target="#fig_8">7</ref>). This indicates that, similar to human subjects, perception of path curvature is underestimated when gaze is along a fixed direction in the world (along the 'Z-axis'), outside the path, and on a location down the future path; overestimated with gaze is inside the path; and relatively accurate when gaze changes such that it is always in the heading direction (i.e. tangent to the circle). Figure <ref type="figure" target="#fig_8">7b</ref> shows that the model explains the human path errors through the rank ordering of activity peaks distributed along the MSTd spiral space sensitivity continuum. Overestimations and underestimations of path curvature occur in the model because each pattern of gaze influenced the retinal rotation differently over time. This shifted activity peaks in MSTd spiral space compared to the peak yielded when the observer was simulated to look where he was going, which commonly occurs This also occurred when for larger angular rotation rates (vwv 0 ). When the angular rotation was set to a comparable rate to that used in the Z-axis condition <ref type="bibr" target="#b30">[31]</ref> (vvv 0 ), model MSTd neurons most sensitive to radial expansion elicited the maximal activation. (b) Simplified model mechanisms that explain why neurons that are sensitive to spirals produced the peak activity in spiral space in the simulation of the Froehler and Duffy experiment, but did not in the simulation of the Z-axis condition. Consider the first-order optic flow (A and B) at two times (t 0 and t 1 ) during the circular path traversal (top row). Template matching in the model is inversely weighted by distance to the FoE or CoM (second row). The third row shows the optimal templates inversely weighted by distance (A ? and B ? ). Because model MSTd dynamically integrates afferent signals from model MT, activation due to the input at t 0 influences the activation due to the input at t 1 . Temporal accumulation in the model can be approximated by considering (1{a)AzaB, which temporally blends the two weighted fields. This yields a spiral field (bottom row), and explains why model MSTd neurons sensitive to spiral patterns are most active when the angular rotation rate about the circular path is sufficiently large. doi:10.1371/journal.pcbi.1003476.g013 during natural locomotion. The steady-state shifts in MSTd population activity compared to the natural gaze along heading gaze condition to which the model is calibrated results in systematic biases in path curvature estimation, similar to human subjects.</p><p>The reasons for comparing MSTd activity peaks in spiral space to that obtained in the gaze along heading condition are twofold. First, directing gaze in the direction of the heading naturally occurs in many activities, such as locomotion and driving. Aligning gaze along heading appears to be important for human perception of path because only in this gaze condition did humans accurately assess the path curvature <ref type="bibr" target="#b30">[31]</ref>. The results of Li and Cheng are supported by a number of similar studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>. When human mothers carry their infants, statistics during locomotion indicate that gaze is most often maintained within 20 0 of the heading direction <ref type="bibr" target="#b59">[60]</ref>. Second, human perception of space has been demonstrated to be inaccurate and it therefore would seem more likely that humans perceive path relative to conditions afforded during normal locomotion (i.e. when gaze naturally changes with heading direction) rather than perceiving path in absolute terms. For example, humans exhibit distorted judgments of distance and slant <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b61">62]</ref>. The rank order of the model MSTd activity peak positions in spiral space followed that of path errors made by human subjects (Figure <ref type="figure" target="#fig_8">7</ref>) across different gaze and path curvature conditions. This supports the idea that humans perceive their path of travel by using the pattern of MSTd activity yielded during natural location as a reference for when gaze changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path Perception in Different Visual Scenes</head><p>In the experiments of Li and Cheng, human path errors were not modulated by the structure of the visual scene <ref type="bibr" target="#b30">[31]</ref>. Our simulations demonstrated that model performance was only modestly impacted by the dot density of the ground plane (Figure <ref type="figure" target="#fig_11">12</ref>). This is consistent with the findings of Li and Cheng that denser textured environments did not modulate human path judgments. The robustness of the model results to dot density is also consistent with findings that indicate that path perception does not depend on local features in the environment <ref type="bibr" target="#b30">[31]</ref>. The stability of path errors across different types of scenes in humans and the model suggests that mechanisms underlying path perception depend on areas such as MSTd that prefer stimulation by large field pattern motion.</p><p>Existing studies of path perception have explored path perception during travel along ground planes <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b30">31]</ref>. We are unaware of investigations that explored other environmental structures, such as 3D dot clouds and fronto-parallel planes. Model simulations mainly contained ground plane environments due to their natural relevance to human locomotion and the availability of psychophysical data. To investigate the simulated rotation condition with our model, we mimicked the conditions of experiment 2 of Royden et al., which contained two dot frontoparallel planes <ref type="bibr" target="#b10">[11]</ref>. More work needs to be done to assess human path perception in different types of environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulated Rotation</head><p>The simulated rotation condition of Royden presents an interesting test for the model <ref type="bibr" target="#b10">[11]</ref>. We hypothesize that humans perceive that they are traveling along a curved path in the simulated rotation condition due to the activation of spiralselective neurons in MSTd. Our hypothesis is supported by simulations that demonstrate that spiral-selective units, not those tuned to radial expansion, are maximally active in the simulated rotation condition. Conversely, in the Z-axis condition of Li and Cheng, human subjects responded as if they were traversing a straight path despite actually traveling along a curved path. In this case, model neurons tuned to radial expansion produced the most activity, which signals a lack of path curvature and is consistent with human path errors. In the simulated rotation and Z-axis conditions, the spiral space mechanisms in the model correctly predict the perceived path curvature. This suggests that humans rely on retinal rotation (i.e. rotation not due to extra-retinal sources) to perceive the curvilinear path and that MSTd neuronal tuning to spirals extracts information about path curvature. The large heading biases produced by humans in the presence of retinal rotation <ref type="bibr" target="#b10">[11]</ref> is consistent with the finding of Orban and colleagues that MSTd neurons tuned to expansion do not appear to compensate for rotational components in the optic flow field, except when accompanied by an extra-retinal signal <ref type="bibr" target="#b43">[44]</ref>.</p><p>Interestingly, the environments and rotation rates tested by Li and Cheng and Royden et al. are remarkably similar, yet our model yields different heading bias in each of these experimental conditions reflecting the differences found in humans (compare Figure <ref type="figure">9a</ref> and 10). In particular, experiments 4 and 5 in the Royden et al. study both use ground planes defined by random dot patterns, with rotation rates in the range of +6 0 . Despite these similarities in the instantaneous optic flow fields, human heading bias reached +20 0 in the Royden et al. study and it did not exceed +5 0 in the experiment of Li and Cheng. The difference in heading bias may be attributed to spatio-temporal differences in the optic flow displays. As a dynamical system, our model responds differently to different spatio-temporal optic flow evolution <ref type="bibr" target="#b14">[15]</ref>. Rather than using a ground plane with a uniform dot density similar to that of Royden and colleagues, Li and Cheng distributed dots to maintain a constant density at different depths within the observer's field of view. This manipulation increased motion parallax in the displays, which has been shown to improve the accuracy of heading judgments <ref type="bibr" target="#b35">[36]</ref>. There were only 220 dots visible at the trial outset in the experiments of Royden and colleagues compared to 300 in the displays of Li and Cheng. Differences in motion parallax and dot density may account for the disparity in heading bias between the two studies.</p><p>It is also possible that subjects in the experiments of Royden et al. reported perceived path rather than heading. Our model provides a good quantitative fit to the heading bias in both studies. Only the spatio-temporal structure of the displays used to simulate the studies differed. If we assume that human subjects followed the experimental instructions, then our fit of the data is consistent with the reporting of heading. However, if we assume that subjects attempted to indicate the curvature of their path, then the interpretation of our data fit is incorrect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Representation of Path Curvature in MSTd</head><p>The activity curves in model MSTd spiral space (Figure <ref type="figure" target="#fig_8">7b</ref>) exhibit different widths and sharpnesses. Because model MSTd was configured as a soft winner-take-all network (Eq. 6), given sufficient time, the network will select a single MSTd unit to be active and all other model neurons will be suppressed through competition. The winning unit signals the path curvature through its pattern selectivity in spiral space. As noted in other computational studies <ref type="bibr" target="#b50">[51]</ref><ref type="bibr" target="#b51">[52]</ref><ref type="bibr" target="#b52">[53]</ref><ref type="bibr" target="#b56">57]</ref>, broad activation in the network could implicate a greater degree of uncertainty about the path curvature and the dynamical competitive interactions require longer to resolve a high confidence solution. We configured model MSTd with a single set of parameters, but it is possible in vivo that different subpopulations exhibit differential response latencies <ref type="bibr" target="#b62">[63]</ref>.</p><p>As depicted in Figure <ref type="figure" target="#fig_8">7b</ref>, simulations of travel along curved paths gives rise to complex distributions of activity across MSTd that are important to how the model encodes heading and path. It is unclear how the brain decodes this information that is distributed across the MSTd population. We believe the population activity is important to heading and path perception, and taking the argmax just provides a simple and straightforward method to assess model performance and properties about the MSTd population. Because competitive dynamics occur while input optic flow signals remain present, a total suppression of the activity of the non-winning units is not guaranteed to occur <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b62">63]</ref>. The argmax operation allows us to read out information about the most active model unit to understand model performance, and is not part of the model's operation. The winner-takeall mechanism is part to the model's operation, and as indicated by our results (Figure <ref type="figure" target="#fig_10">11</ref>), represents an important characteristic of the model that allows it to fit the human data.</p><p>We selected spiral templates in the model to resemble the optic flow patterns used in a number of electrophysiological studies <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b63">64]</ref> to investigate large motion pattern selectivity in neurons located in MSTd and other areas of the STS. Although electrophysiological studies report tuning in the spiral space that spans radial expansion, contraction, and center fields, actual MSTd neuron receptive fields may exhibit far greater complexity. Pack and colleagues modeled the feedforward subunit structure of MSTd neurons based on single-cell recordings and discovered complicated subunit configurations that deviated from characteristic radial, spiral, and center motion patterns <ref type="bibr" target="#b48">[49]</ref>. Feedback and other types of horizontal connectivity was not modeled, and only *50% of the MSTd response variance was accounted for, so the actual receptive fields of MSTd units are likely even more complex. MSTd receptive fields may follow the motion statistics experienced by primates during ecological locomotion along a ground surface. For instance, model templates spanned the entire visual field, but 'ecological templates' may be biased toward the lower portion of the visual field. The statistics of videos collected from head-mounted cameras on human mothers carrying infants show that the optic flow during locomotion is fairly evenly distributed across expanding, contracting, upward, downward, CW, and CCW motion patterns, with a bias for expansion <ref type="bibr" target="#b59">[60]</ref>. The selectivity of MSTd neurons in the sample of Graziano and colleagues also are biased toward expansive motion patterns. Humans accurately judge heading in environments with many different structures, even with dynamic occlusion, unless the textures become unstructured <ref type="bibr" target="#b29">[30]</ref>. Therefore, ecological statistics may be important for guiding the development of MSTd receptive fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path Selective Cells</head><p>In simulating monkey movement along a circular path, we found that the location of the MSTd activity peak in spiral space depended on the speed at which the circular path is traversed. At speeds slower around the circular track than that used by Froehler and Duffy, the optic flow more closely mimicked the Z-axis condition of Li and Cheng <ref type="bibr" target="#b30">[31]</ref>, and the subpopulation of MSTd neurons tuned to radial expansion was most active-thereby signaling travel along a straight path. However, when the path traversal speed equaled or exceeded that used in the study of Froehler and Duffy <ref type="bibr" target="#b42">[43]</ref>, the activity peak shifted rightward, signaling navigation along a curved path. Our analysis indicates that at a sufficiently fast speed around the track, the motion signal MSTd neurons receive in the experiment of Froehler and Duffy is temporally 'blurred' and actually resembles a spiral pattern (Figure <ref type="figure" target="#fig_12">13</ref>). Froehler and Duffy did not report testing selectivity to spirals in their sample. Our analysis and simulation results predict that the path selective neurons discovered by Froehler and Duffy were tuned to spirals rather than expansion patterns. We predict that human subjects would produce path curvature judgments consistent with the percept of traveling along a curved path in a psychophysical experiment with the Z-axis gaze condition when the rotation rate along the circle is increased. In this proposed experiment, the model makes the prediction that humans would produce different path errors in the Z-axis condition, depending on how much of and the speed at which the circular path is traversed.</p><p>Our model results suggest information about future path may be processed in areas as early as MSTd. Path estimation may more fundamentally indicate the functional role of area MSTd in primates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Exemplar first-order optic flow fields. (a) Radially expanding optic flow experienced by an observer traveling along a straight path on a ground plane. The optic flow contains the focus of expansion (FoE) singularity on the horizon, which indicates the heading direction. (b) Movement of an observer along a straight path, as in (a), but with a constant amount of rotation added to the first-order optic flow (simulated rotation condition). Human subjects that view displays with simulated rotation report traveling along a circular path. (c) First-order optic flow experienced by an observer traveling on a circular path whose gaze is along heading or tangent to the circular path. doi:10.1371/journal.pcbi.1003476.g001</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Experimental paradigm and sample optic flow fields from Froehler and Duffy, who report the existence of path selective neurons in MSTd [43]. A monkey seated in a sled traveled CCW (a) or CW (c) along a circular track while maintaining gaze on the distal wall of luminous dots. The body, head, and eye did not rotate so that the monkey always directly faced the distal wall. The monkey therefore experienced radially expanding or contracting optic flow without sources of rotation. (b,d) Instantaneous optic flow experienced by the monkey at different locations along the circular track. In (b) at t 0 , the monkey views a radially expanding optic flow while moving CCW when the heading direction is straight ahead, which is the same as the optic flow viewed CW 180 0 on the other side of the circle. Between t 0 and t 1 , the FoE drifts rightward until at t 1 it is out of view. At t 2 , the monkey experiences radial contraction. doi:10.1371/journal.pcbi.1003476.g002</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Spiral space continuum of motion patterns employed in electrophysiological studies to probe cell selectivity to spiral motion. Sensitivity to radial expansion and center motion is tested by the left and right ends of the continuum, respectively. Spiral patterns exist in between as an interpolation between the radial and center patterns. The spiral space also contains contracting spirals and those with CCW orientations (not shown). doi:10.1371/journal.pcbi.1003476.g003</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Schematic depiction of the model coding of path curvature and heading in MSTd. Neurons in a model MSTd hypercolumn possess selectivities across a spiral space spanning CW, CCW, radial expansion, radial contraction, and center motion patterns. The length and width dimensions of the schematic MSTd selectivity volume correspond to neurons with 2D visuotopic tuning. Therefore, at every position in the visual field, there is a model MSTd hypercolumn with a full set of units tuned to radial, spiral, and center optic flow patterns. For example, the hypercolumn on the top left corresponds to MSTd units with receptive fields centered on the top left portion of the visual field, which have focus of expansion or center of motion tuning in that location. Travel along a circular path elicits a distribution of activity within the MSTd volume (overlaid heat map). The position of the activity peak across the volume in the spiral space (depth) dimension corresponds to the model path curvature estimate, and the 2D position of the peak in the spatial dimensions (length and width) indicates the estimated heading direction. doi:10.1371/journal.pcbi.1003476.g004</figDesc><graphic coords="6,415.18,109.99,90.80,197.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Radial expansion and contraction templates are obtained by setting D A ~1 and D A ~{1, respectively. Center templates with CW and CCW orientations are constructed by setting D B ~1 and D B ~{1, respectively. The values of x 0 and y 0 determine the horizontal and vertical spatial offset of the FoE in the radial template and the center of motion (CoM) in the center field. Eq. 4 defines a spiral template, and the value of y determines the degree of spirality, with 0ƒyƒ1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Diagram of model V1-MT-MSTd. First-order local motion is computed in model V1. Model MT receives projections and spatially pools motion signals from model V1. A extra-retinal eye velocity gain field acts on the afferent signals from model MT in MSTd, which compensates for rotation introduced by pursuit eye movements proportional to the eye movement speed in the direction opposite that of the eye movement. A template match occurs in model MSTd, whereby the similarity is assessed between the afferent motion signal and motion field templates sampled in spiral space. A distance-dependent weighting exponentially discounts vector matches by distance from the template singularity. Finally, neurons selective to different spiral patterns, expansion and contraction, CW and CCW orientations, and 2D visuotopic location compete. doi:10.1371/journal.pcbi.1003476.g005</figDesc><graphic coords="7,146.99,447.65,148.10,105.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure</head><label></label><figDesc>Figure 7a depicts the path error obtained in each experimental condition, averaged across the three path curvatures. The random dot displays in model simulations and the human experiments contained 200 dots.In the Z-axis condition, an observer was simulated to travel on a circular path and gaze remained parallel to the Z-axis (Figure6a). The instantaneous vector field contained no rotation, the field at any time appeared to radially expand, and over time the FoE laterally 'drifted'. In the outside path condition, the simulated gaze was</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Observer gaze conditions during travel along a circular path tested in the model from Li and Cheng<ref type="bibr" target="#b30">[31]</ref>. The gaze in each condition is ''simulated'' within the computer display because human subjects in the experiments of Li and Cheng maintained fixation throughout the trial. We also tested the model on analogous conditions with pursuit eye movements (see Figure8). (a) Z-axis condition. The observer maintains a fixed body, head, and eye orientation, in the direction of the 'Z axis', during travel along the circular path. The optic flow field at every instant is radially expansive, and over time the FoE drifts horizontally. (b) Outside path condition. Observer gaze was maintained on a target positioned 15 0 outside the path. (c) On path condition. The observer maintained gaze on a target on the future path positioned 30 0 from the initial heading. (d) Inside path condition. Observer gaze was maintained on a target positioned 15 0 inside the path. (e) Gaze along heading condition. Observer gaze is always tangent to the circular path, which is most often the case during human locomotion. Human subjects in the experiments of Li and Cheng underestimated path curvature in the Z axis, outside path, and on path conditions, overestimated path curvature in the inside path condition, and yielded low error in their judgments in the gaze along heading condition. doi:10.1371/journal.pcbi.1003476.g006</figDesc><graphic coords="10,141.11,372.89,55.68,108.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Path errors obtained by the model in the five gaze conditions. (a) Path error averaged across circular path radius. Positive and negative path errors indicate overestimations and underestimations of path curvature, respectively, and zero path error signifies veridical performance. Both humans and the model underestimated path curvature in the Z axis, outside path, and on overestimated path curvature in the inside path condition, and elicited near veridical performance in the gaze along heading condition. (b)Model MSTd activity across spiral pattern selectivity space during an exemplar trial with a 38m path radius for the five gaze conditions. The location of each peak across the spiral continuum determines the model estimate of path curvature. For example, in the Z-axis condition (black), the MSTd activity peak occurs in the subpopulation sensitive to radial expansion (y~0), and therefore the model indicates zero path curvature (straight path). (c) Model path errors (solid lines) compared to human data from Li and Cheng (replotted, dashed lines) in the five gaze conditions as a function of path curvature<ref type="bibr" target="#b30">[31]</ref>. Model path errors were in good agreement in all gaze conditions with those based on human judgments (rw0:94), and path error decreased linearly (R 2 w0:95) with path curvature. Error bars correspond to standard error of the mean (SEM). doi:10.1371/journal.pcbi.1003476.g007</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>The x-axis corresponds to MSTd unit FoE selectivity to particular horizontal locations within the visual field. The simulation is of the Z-axis condition, wherein the instantaneous optic flow is always expanding radially without rotation, and Figures 9c shows the activity of model neurons tuned to radial expansion. The visuotopic positions of the activity peaks in MSTd do not change due to the competition, but the model competitive interactions sharpen the spatial distribution. Any heading bias therefore is preserved in the model through the competition in MSTd.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. The impact lesions to model MSTd have on path error. The mean path errors for human subjects and the model from Figure 7 are plotted on the two leftmost data columns for 58m (a), 38 m (b), 28m (c) radius paths. Lesions were introduced in the model MSTd connectivity by zeroing out competitive interactions in spiral space, across spiral orientation, and across 2D space between neurons in MSTd (see Eq. 6). Lesions had a detrimental impact on model performance, and path curvature estimates no longer mapped onto human judgments. The three competitive interactions in model MSTd were necessary to obtain our results. doi:10.1371/journal.pcbi.1003476.g011</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Robustness in model path curvature estimates for scenes containing 25-1500 dots. The deviation in path errors from those shown in Figure7are plotted for path radii of 28 m (a), 38m (b), and 58 m (c), respectively. Deviations in path error were modest, with mean errors falling within +5 0 of those depicted in Figure7. There were only small deviations in any condition when the scene contained at least §200 dots. doi:10.1371/journal.pcbi.1003476.g012</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Model simulation of the experiment of Froehler and Duffy<ref type="bibr" target="#b42">[43]</ref>. (a) Responses of the maximally-active model MSTd subpopulations in spiral space as a function of the angular rotation rate (i.e. how fast the circular path is traversed per unit of time). When the angular rotation rate matched that used by Froehler and Duffy (v~v 0 , dark orange), model MSTd neurons most sensitive to spiral patterns were most active. This also occurred when for larger angular rotation rates (vwv 0 ). When the angular rotation was set to a comparable rate to that used in the Z-axis condition<ref type="bibr" target="#b30">[31]</ref> (vvv 0 ), model MSTd neurons most sensitive to radial expansion elicited the maximal activation. (b) Simplified model mechanisms that explain why neurons that are sensitive to spirals produced the peak activity in spiral space in the simulation of the Froehler and Duffy experiment, but did not in the simulation of the Z-axis condition. Consider the first-order optic flow (A and B) at two times (t 0 and t 1 ) during the circular path traversal (top row). Template matching in the model is inversely weighted by distance to the FoE or CoM (second row). The third row shows the optimal templates inversely weighted by distance (A ? and B ? ). Because model MSTd dynamically integrates afferent signals from model MT, activation due to the input at t 0 influences the activation due to the input at t 1 . Temporal accumulation in the model can be approximated by considering (1{a)AzaB, which temporally blends the two weighted fields. This yields a spiral field (bottom row), and explains why model MSTd neurons sensitive to spiral patterns are most active when the angular rotation rate about the circular path is sufficiently large. doi:10.1371/journal.pcbi.1003476.g013</figDesc><graphic coords="17,425.15,369.17,80.61,78.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Parameter values used in simulations.</figDesc><table><row><cell>Parameter</cell><cell>Value</cell><cell>Description</cell></row><row><cell>E</cell><cell>1.0</cell><cell>Inverse cell time constant</cell></row><row><cell>a</cell><cell>3.25</cell><cell>Passive decay rate</cell></row><row><cell>b</cell><cell>1.0</cell><cell>Activation upper bound</cell></row><row><cell>m</cell><cell>2.5</cell><cell>Strength of inhibition from spatial competition</cell></row><row><cell>C</cell><cell>0.01</cell><cell>MSTd presynaptic threshold</cell></row><row><cell>f</cell><cell>0.07</cell><cell>Sigmoid shape parameter</cell></row><row><cell cols="3">doi:10.1371/journal.pcbi.1003476.t001</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>PLOS Computational Biology | www.ploscompbiol.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>February 2014 | Volume 10 | Issue 2 | e1003476</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>Supported in part by the <rs type="funder">Office of Naval Research (ONR)</rs> (<rs type="grantNumber">N00014-11-1-0535</rs>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_C4W49HZ">
					<idno type="grant-number">N00014-11-1-0535</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>Conceived and designed the experiments: OWL. Performed the experiments: OWL. Analyzed the data: OWL NAB. Wrote the paper: OWL NAB.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Ecological Approach To Visual Perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Psychology Press</publisher>
			<biblScope unit="page" from="1" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The State of Flow</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High-level motion processing</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Watanabe</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="315" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Perception of translational heading from optical flow</title>
		<author>
			<persName><forename type="first">Whw</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mwm</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Kalish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="646" to="660" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robustness of perception of heading from optic flow</title>
		<author>
			<persName><forename type="first">Ava</forename><surname>Van Den Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1285" to="1296" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Judgements of heading</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Van Den Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="2337" to="2350" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Processing differential image motion</title>
		<author>
			<persName><forename type="first">Jhj</forename><surname>Rieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dtd</forename><surname>Lawton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Opt Soc Am A</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="354" to="360" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recovering heading for visually-guided navigation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Hildreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1177" to="1192" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Perceiving heading in the presence of moving objects</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="315" to="331" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computing heading in the presence of moving objects: a model that uses motion-opponent operators</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Royden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="3043" to="3058" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Eye movements and optical flow</title>
		<author>
			<persName><forename type="first">Whw</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Djd</forename><surname>Hannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Opt Soc Am A</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="160" to="169" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Estimating heading during eye movements</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Royden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Crowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3197" to="3214" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The perception of heading during eye movements</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Royden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Msm</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaj</forename><surname>Crowell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page" from="583" to="585" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Depth information and perceived self-motion during simulated gaze rotations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Crowell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="3129" to="3145" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Humans can perceive heading without visual path information</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Sweet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2" to="2" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Analysis of misperceived observer motion during simulated eye rotations</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Royden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3215" to="3222" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mechanisms of heading perception in primate visual cortex</title>
		<author>
			<persName><forename type="first">Dcd</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rar</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Msm</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kvk</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="1544" to="1547" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Inuence of gaze rotation on the visual response of primate MSTd neurons</title>
		<author>
			<persName><forename type="first">Kvk</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dcd</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rar</forename><surname>Andersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="2764" to="2786" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pursuit Speed Compensation in Cortical Area MSTd</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="2630" to="2647" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Comparison of the Spatial Limits on Direction Selectivity in Visual Areas MT and V1</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Churchland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Priebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Lisberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1235" to="1245" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A neural model of visually guided steering, obstacle avoidance, and route selection</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mingolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1501" to="1531" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Guidance of locomotion on foot uses perceived target location rather than optic flow</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Rushton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Wann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="4" to="4" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Behavioral dynamics of intercepting a moving target</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Fajen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Brain Research</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="page" from="303" to="319" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Perceiving curvilinear heading in the presence of moving objects</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Fajen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1100" to="1119" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">View rotation is used to perceive path curvature from optic flow</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effects of reference objects and extra-retinal information about pursuit eye movements on curvilinear path perception from retinal flow</title>
		<author>
			<persName><forename type="first">Jck</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Heading but not path or the tau-equalization strategy is used in the visual control of steering toward a goal</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jck</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="20" to="20" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Perception of circular heading from optical flow</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Mestre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="28" to="43" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Can observers judge future circular path relative to a target from retinal flow</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="16" to="16" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Perceiving circular heading in noncanonical flow fields</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Fajen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Turvey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="31" to="56" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dynamic Occlusion and Optical Flow From Corrugated Surfaces</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Psychology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="209" to="239" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Perceiving path from optic flow</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jck</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="22" to="22" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Human heading estimation during visually simulated curvilinear motion</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Perrone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="573" to="590" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Path perception during rotation: inuence of instructions, depth range, and dot density</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Warren</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1879" to="1889" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Inuence of visual path information on human heading perception during rotation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="29" to="29" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visual control of locomotion</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="224" to="230" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Perception of heading during rotation: sufficiency of dense motion parallax and reference objects</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Warren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="3873" to="3894" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Why you should look where you are going</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Wann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Swapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="647" to="648" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Where we look when we steer</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Land</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<biblScope unit="page" from="742" to="744" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Higher Order Visual Processing in Macaque Extrastriate Cortex</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Orban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiological Reviews</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="59" to="89" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Medial superior temporal area neurons respond to speed patterns in optic flow</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wurtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2839" to="2851" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Response of monkey MST neurons to optic ow stimuli with shifted centers of motion</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wurtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="5192" to="5208" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mechanisms of Self-Motion Perception</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Britten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="389" to="410" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cortical neurons encoding path and place: where you go is where you are</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Froehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">295</biblScope>
			<biblScope unit="page" from="2462" to="2465" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Firstorder analysis of optical flow in monkey brain</title>
		<author>
			<persName><forename type="first">Gag</forename><surname>Orban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Lagae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Verri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Raiguel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PNAS</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="2595" to="2599" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Tuning of MST neurons to spiral motions</title>
		<author>
			<persName><forename type="first">Msm</forename><surname>Graziano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rar</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rjr</forename><surname>Snowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="54" to="67" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Neurons in the ventral intraparietal area of awake macaque monkey closely resemble neurons in the dorsal part of the medial superior temporal area in their responses to optic ow patterns</title>
		<author>
			<persName><forename type="first">Sjs</forename><surname>Schaafsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Duysens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="4056" to="4068" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Modulation of responses to optic flow in area 7a by retinotopic and oculomotor cues in monkey</title>
		<author>
			<persName><forename type="first">Hlh</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Siegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral cortex</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="647" to="661" />
			<date type="published" when="1991">1997. 1991</date>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Structure and function of visual area MT</title>
		<author>
			<persName><forename type="first">R</forename><surname>Born</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="157" to="189" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hierarchical processing of complex motion along the primate dorsal visual pathway</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Mineault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Khawaja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Butts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Pack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="972" to="980" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Contour enhancement, short term memory, and constancies in reverberating neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="213" to="257" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A motion pooling model of visually guided navigation explains human behavior in the presence of independently moving objects</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">W</forename><surname>Layton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mingolla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Browning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A neural model of how the brain computes heading from optic flow in realistic scenes</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Browning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mingolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="320" to="356" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cortical dynamics of navigation and steering in natural scenes: Motion-based object segmentation, heading, and obstacle avoidance</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Browning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mingolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1383" to="1398" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A review and evaluation of methods estimating ego-motion</title>
		<author>
			<persName><forename type="first">F</forename><surname>Raudies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="606" to="633" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The interpretation of a moving retinal image</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Longuet-Higgins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Prazdny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Proceedings of the Royal Society of London Series B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<biblScope unit="page">385</biblScope>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A neural model of motion processing and visual navigation by cortical area MST</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Grossberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Mingolla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Pack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral cortex</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="878" to="895" />
			<date type="published" when="1991">1999. 1991</date>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A Neural Circuit for Robust Time-to-Contact Estimation Based on Primate MST</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Browning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2946" to="2963" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The Simultaneous Coding of Heading and Path in Primate MSTd</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">W</forename><surname>Layton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Browning</surname></persName>
		</author>
		<ptr target="http://www.ijcnn2013.org/" />
	</analytic>
	<monogr>
		<title level="m">The 2013 International Joint Conference on Neural Networks (IJCNN)</title>
		<meeting><address><addrLine>Dallas, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08">2013. August 2013</date>
			<biblScope unit="page" from="4" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Eye Movements and a Rule for Perceiving Direction of Heading</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Turvey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="233" to="248" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Understanding the Development of Motion Processing by Characterizing Optic Flow Experienced by Infants and their Mothers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Raudies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Gilmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Kretch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Franchak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Adolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDL-EpiRob</title>
		<meeting>ICDL-EpiRob</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The visual perception of threedimensional length</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">J</forename><surname>Perotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Tittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="186" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Perceiving distance: A role of effort and intent</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Witt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Proffitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Epstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="577" to="590" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Recurrent competition explains temporal effects of attention in MSTd</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">W</forename><surname>Layton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Browning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Computational Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Sensitivity of MST neurons to optic flow stimuli. I. A continuum of response selectivity to large-field stimuli</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wurtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1329" to="1345" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
