<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding Engagement in Dementia Through Behavior. The Ethographic and Laban-Inspired Coding System of Engagement (ELICSE) and the Evidence-Based Model of Engagement-Related Behavior (EMODEB)</title>
				<funder>
					<orgName type="full">Erasmus Mundus Joint Doctorate (EMJD) in Interactive and Cognitive Environments</orgName>
					<orgName type="abbreviated">ICE</orgName>
				</funder>
				<funder ref="#_ppAztYe">
					<orgName type="full">Erasmus Mundus</orgName>
				</funder>
				<funder>
					<orgName type="full">Ethographic and Laban-Inspired Coding System of Engagement</orgName>
					<orgName type="abbreviated">ELICSE</orgName>
				</funder>
				<funder>
					<orgName type="full">Evidence-Based Model of Engagement-Related Behavior (EMODEB)</orgName>
				</funder>
				<funder ref="#_fC9ujxv">
					<orgName type="full">Toke van Telgen</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2018-05-24">24 May 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Phuong</forename><surname>Khiet</surname></persName>
						</author>
						<author>
							<persName><surname>Truong</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Giulia</forename><surname>Perugia</surname></persName>
							<email>g.perugia@tue.nl</email>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Designed Intelligence</orgName>
								<orgName type="department" key="dep2">Industrial Design</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Technical Research Center for Dependency Care and Autonomous Living</orgName>
								<orgName type="department" key="dep2">Automatic Control Department</orgName>
								<orgName type="institution">Technical University of Catalonia</orgName>
								<address>
									<addrLine>Vilanova i la</addrLine>
									<settlement>Geltrú</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roos</forename><surname>Van Berkel</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Designed Intelligence</orgName>
								<orgName type="department" key="dep2">Industrial Design</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marta</forename><surname>Díaz-Boladeras</surname></persName>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Technical Research Center for Dependency Care and Autonomous Living</orgName>
								<orgName type="department" key="dep2">Automatic Control Department</orgName>
								<orgName type="institution">Technical University of Catalonia</orgName>
								<address>
									<addrLine>Vilanova i la</addrLine>
									<settlement>Geltrú</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreu</forename><surname>Català-Mallofré</surname></persName>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Technical Research Center for Dependency Care and Autonomous Living</orgName>
								<orgName type="department" key="dep2">Automatic Control Department</orgName>
								<orgName type="institution">Technical University of Catalonia</orgName>
								<address>
									<addrLine>Vilanova i la</addrLine>
									<settlement>Geltrú</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthias</forename><surname>Rauterberg</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Designed Intelligence</orgName>
								<orgName type="department" key="dep2">Industrial Design</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emilia</forename><surname>Barakova</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Designed Intelligence</orgName>
								<orgName type="department" key="dep2">Industrial Design</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<settlement>Baltimore County</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Gualtiero Volpe</orgName>
								<orgName type="institution">University of Twente</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Università di Genova</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding Engagement in Dementia Through Behavior. The Ethographic and Laban-Inspired Coding System of Engagement (ELICSE) and the Evidence-Based Model of Engagement-Related Behavior (EMODEB)</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-05-24">24 May 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3389/fpsyg.2018.00690</idno>
					<note type="submission">This article was submitted to Human-Media Interaction, a section of the journal Frontiers in Psychology Received: 23 November 2017 Accepted: 20 April 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-29T00:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>nonverbal behavior</term>
					<term>body movement</term>
					<term>Laban Movement Analysis</term>
					<term>ethogram</term>
					<term>coding system</term>
					<term>dementia</term>
					<term>engagement</term>
					<term>structural equation modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ELICSE) and the model the Evidence-based Model of Engagement-related Behavior (EMODEB). To the best of our knowledge, the ELICSE and the EMODEB constitute the first formalization of engagement-related behavior for dementia that describes how behavior unfolds over time and what it means in terms of engagement.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Engagement in activities is of crucial importance for people with dementia. State of the art assessment techniques rely exclusively on behavior observation to measure engagement in dementia. These techniques are either too general to grasp how engagement is naturally expressed through behavior or too complex to be traced back to an overall engagement state. We carried out a longitudinal study to develop a coding system of engagement-related behavior that could tackle these issues and to create an evidence-based model of engagement to make meaning of such a coding system. Fourteen elderlies with mild to moderate dementia took part in the study. They were involved in two activities: a game-based cognitive stimulation and a robot-based free play. The coding system was developed with a mixed approach: ethographic and Laban-inspired. First, we developed two ethograms to describe the behavior of participants in the two activities in detail. Then, we used Laban Movement Analysis (LMA) to identify a common structure to the behaviors in the two ethograms and unify them in a unique coding system. The inter-rater reliability (IRR) of the coding system proved to be excellent for cognitive games (kappa = 0.78) and very good for robot play (kappa = 0.74). From the scoring of the videos, we developed an evidence-based model of engagement. This was based on the most frequent patterns of body part organization (i.e., the way body parts are connected in movement) observed during activities. Each pattern was given a meaning in terms of engagement by making reference to the literature. The model was tested using structural equation modeling (SEM). It achieved an excellent goodness of fit and all the hypothesized relations between variables were significant. We called the coding system that we developed the Ethographic and Laban-Inspired Coding System of Engagement</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Engagement in activities is of crucial importance for people with dementia <ref type="bibr" target="#b26">(Kolanowski et al., 2006;</ref><ref type="bibr" target="#b6">Brooker et al., 2007)</ref>. Indeed, a growing body of research has found that participation in activities is associated with augmented selfefficacy and self-esteem in dementia <ref type="bibr" target="#b4">(Benveniste et al., 2012)</ref> and is deemed useful to improve social bonding <ref type="bibr" target="#b58">(Wada and Shibata, 2008)</ref> and mood <ref type="bibr" target="#b36">(Moyle et al., 2013)</ref> and to reduce loneliness <ref type="bibr" target="#b47">(Robinson et al., 2013)</ref>, challenging behaviors <ref type="bibr" target="#b34">(Mordoch et al., 2013)</ref>, and medication consumption <ref type="bibr" target="#b35">(Moyle et al., 2015)</ref>.</p><p>At present, the benefits of participation in activities are predominantly measured with regard to their long-term clinical outcomes. However, there is an intermediate step between participation in activities and clinical gain that the majority of literature on dementia overlooks: when activities are meaningful, they have a higher clinical resonance <ref type="bibr" target="#b14">(Cohen-Mansfield et al., 2010)</ref>. A systematic assessment of engagement through behavior could be greatly beneficial to measure the meaningfulness and effectiveness of activities for the person with dementia and could be used as a complement to the assessment of clinical benefits. We define engagement as the psychological state of well-being, enjoyment and active involvement that is triggered by meaningful activities and causes people with dementia to be absorbed by the activity, more energetic and in a more positive mood <ref type="bibr">(Perugia et al., 2017c)</ref>.</p><p>Engagement is usually measured using self-reports <ref type="bibr" target="#b16">(Csikszentmihalyi and Larson, 1987;</ref><ref type="bibr" target="#b61">IJsselsteijn et al., 2008)</ref>. However, as dementia progresses, self-reports become an unfeasible form of assessment, since retrieval, reporting, and ranking of relevant information, especially if located in the past, gets significantly compromised. This is the reason why almost all assessment techniques of engagement for dementia rely on behavior observation. There are three ways to measure engagement through behavior: observational rating scales, ethograms, and coding schemes. An observational rating scale is a collection of items measured on a Likert scale and operationalized through behavior. An ethogram is the complete inventory of species-related behavior. Last, a coding scheme is an excerpt of an ethogram aimed at answering specific research questions. In the context of engagement assessment for dementia, observational rating scales are too general to grasp how engagement manifests itself through behavior and unfolds over time. Ethograms produce a complete yet segmented picture of engagement difficult to report to an overall state of engagement. Coding schemes are mostly developed by cherry-picking the target behaviors without the preventive development of an ethogram.</p><p>In order to solve this problem, we carried out a longitudinal study involving people with dementia in two very diverse activities: a game-based cognitive stimulation and a robotbased free play. This study had a twofold objective: (i) develop a reliable coding system of engagement-related behavior that saves the complexity of an ethogram but can be used across activities and (ii) create a model of engagement that describes how engagement-related behavior unfolds and how it can be interpreted in engagement terms.</p><p>To pursue the first objective, we employed a mixed approach: ethographic and Laban-inspired. First, we observed people with dementia during the two activities and developed two ethograms, one per activity, to describe their behavior. Second, we used Laban Movement Analysis (LMA; <ref type="bibr" target="#b28">Laban, 1966)</ref> to identify a common structure to the behaviors in the two ethograms and unify them in a unique coding system workable across activities. In this phase, we used the category shape of LMA, which formalizes how the body changes shape to respond to inner motives and to the environment. Moreover, we tested the interrater reliability (IRR) of the coding system to ensure that it was reliable across coders.</p><p>To pursue the second objective, we first scored all the videos collected during the study. Second, we identified patterns of behaviors recurring across sessions. To do this, we used the category body of LMA in the formalization of body part organization. Body part organization describes how body parts are connected in movement. As a last step, we summarized the patterns of behaviors into a model and tested the goodness of fit of the model using structural equation modeling (SEM). Each pattern of behavior was given a meaning in terms of engagement by making reference to the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Observational Rating Scales</head><p>Early measurements of engagement came in the form of observational rating scales. Observational rating scales are ordinal Likert-type scales that measure engagement through behavior. The most widely used in the field of gerontology is the Observational Measurement of Engagement (OME) developed by <ref type="bibr" target="#b12">Cohen-Mansfield et al. (2009)</ref>. In the OME, engagement is defined as "the act of being involved or occupied with a stimulus" and is measured across four dimensions: duration (time in seconds that the person with dementia is involved with the stimulus), attention (attentional allocation toward the stimulus measured on a 4-point Likert-scale), attitude (affective stance toward the stimulus measured on a 7-point Likert scale), and refusal (acceptance or rejection of the stimulus). Another broadly employed observational scale of engagement is the Menorah Park Engagement Scale (MPES), which has been developed by <ref type="bibr" target="#b24">Judge et al. (2000)</ref> to assess engagement in people with dementia involved in Montessori-based interventions. In the MPES, engagement is defined as "motor or verbal behavior exhibited in response to the activity" and is assessed along a single item, engagement, that can take four values: non-engagement (no motor or verbal behavior in response to the activity, e.g., stare into space, look away from the activity), self-engagement (selfdirected motor and verbal behavior in response to the activity, e.g., hand-wringing), passive engagement (passive motor and verbal behavior directed toward the activity, e.g., looking toward the activity, listening) and constructive engagement (proactive motor and verbal behavior directed toward the activity, e.g., manipulating objects, talking). A last observational scale that is widely used in dementia is the Observed Emotion Rating Scale (OERS; <ref type="bibr" target="#b30">Lawton et al., 1996)</ref>. It does not directly measure engagement but has often been used in concert with the OME and MPES to assess the emotional state of people with dementia during activities <ref type="bibr" target="#b36">(Moyle et al., 2013;</ref><ref type="bibr">Perugia et al., 2017b)</ref>. The OERS measures the intensity or duration of five affective states along a 5-point Likert-scale: pleasure, anxiety/fear, anger, sadness, and general alertness.</p><p>Observational rating scales are very useful tools to get a broad idea of the engagement state of the person with dementia during activities. However, they can grasp engagement only at a global level. Indeed, they do not get into the detail of how behavior naturally occurs and unfolds. They collect a general idea of engagement which is drawn from the occurrence of certain behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coding Schemes</head><p>A different approach toward measuring engagement is for instance adopted in the field of socially interactive robotics (SIR) where the study of interactions between humans and social robots is of crucial importance <ref type="bibr" target="#b44">(Pino et al., 2015)</ref>. Socially interactive robots are robots that engage socially with humans for the sake of social interaction itself <ref type="bibr" target="#b19">(Feil-Seifer and Mataric, 2011)</ref>. In the context of SIR, a considerable effort has been done to understand how people with dementia interact with social robots and how such an interaction could have a therapeutic value <ref type="bibr" target="#b3">(Bemelmans et al., 2012;</ref><ref type="bibr">Valentí Soler et al., 2015;</ref><ref type="bibr" target="#b48">Rouaix et al., 2017)</ref>. To understand the meaningfulness of the interactions that social robots promote, researchers have compiled repertoires of behaviors and used them to annotate videos. Just to make few examples, <ref type="bibr" target="#b53">Takayanagi et al. (2014)</ref> used a time sampling method to compare the effects of the social robot PARO (the arctic seal robot) to those of a stuffed animal (a lion) in people with mild/moderate and severe dementia. They divided videos into units of 10 s and at each interval scored whether the observed person talked (to PARO/lion, to the staff, to him/herself or to nobody), touched or stroked (PARO/lion), and had positive, neutral or negative facial expression. <ref type="bibr">Šabanović et al. (2013)</ref> explored the behavior behind PARO's therapeutic success by coding visual engagement (look at the robot), verbal engagement (speak, sing, vocalizations toward the robot), and physical engagement (pet, hit, hold, kiss, take/offer PARO). <ref type="bibr" target="#b57">Wada et al. (2010)</ref> tested the effectiveness of a manual for the use of PARO with people with dementia by scoring engagement on a coding sheet that comprised the classes: emotional expression (laugh, smile, no expression, hate), gaze (PARO, staff, user, others), talk (PARO, staff, user, others), and type of interactions with PARO (give, stroke, hold, other). Coding schemes have been employed also in other contexts. For instance, to assess engagement in multi-sensory and motor stimulation programs. <ref type="bibr" target="#b15">Cruz et al. (2011)</ref> assessed engagement during these types of interventions using a coding scheme composed of the following categories: engagement in the task, interactions with objects, verbal communication, smiling, laughing, nodding the head, and closed eyes.</p><p>The just described coding schemes provide a deeper understanding of behavior compared to observational scales. However, they grasp only some characteristics of behavior. Indeed, instead of considering behavior in its natural flow, they fragment it to pick up only the desired pieces of information. In these cases, since the fragmentation of behavior is not performed in a systematic way, it results in a cherry-picking of behaviors based on their perceived meaningfulness. Ideally, a researcher should first develop a complete inventory of behaviors (ethograms) and then focus on a portion of it (coding schemes) based on research questions. However, such practice is not reported in these studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethograms</head><p>Ethology is the discipline that studies animal behavior from a biological perspective. As a discipline, Ethology faces nearly the same constraint as gerontology for dementia: the inaccessibility of mental experiences <ref type="bibr" target="#b55">(Troisi, 1999)</ref>. To address this issue, Ethology has elaborated a very distinctive and powerful method of analysis which is rooted in direct observation, rigorous description and objective analysis of behavior, the ethogram.</p><p>The words ethogram and coding scheme are often used as synonyms in the literature. Some authors use the word ethogram as a synonym for coding scheme <ref type="bibr" target="#b15">(Cruz et al., 2011)</ref>, others use the word ethogram to designate a more thorough description and analysis of behavior that stems from field observation and incorporates a good deal of complexity <ref type="bibr" target="#b32">(Mabire et al., 2016)</ref>. In Ethology, the ethogram is the complete list of actions that a particular species performs, while the coding scheme is a portion of an ethogram aimed at answering specific research questions.</p><p>Recently, several ethograms have been developed to assess engagement in dementia. <ref type="bibr" target="#b39">Olsen et al. (2016)</ref> gauged engagement in people with dementia involved in Animal Assisted Activities (AAA) using an ethogram that comprised the following behaviors: conversation (unspecified target), look at (other people, the dog activity, other things), touch (people, dog), smile, or laugh at (dog, other things), sing/dance/clapping hands, stereotyped behavior, wandering around, agitated behavior, yawn, and sigh, no response, asleep, leaving the room, off camera. <ref type="bibr" target="#b23">Jøranson et al. (2016)</ref> studied the behaviors of people with dementia involved in interactions with PARO and grouped them in: conversation with or without PARO, observe (PARO, other participant/activity leader, other things in the room), smile/laughter (PARO, other participant/activity leader), physical contact with PARO, active with PARO, singing/whistling, clapping/humming/dancing, napping, walking around, repetitive movement, time out of recording, physical contact (with participant/activity leader), signs of discomfort, leaving the group, no response to contact. Perhaps one of the most complete ethograms of engagement built for dementia is the Video-Coding Incorporating Observed Emotions (VC-IOE; <ref type="bibr" target="#b22">Jones et al., 2015)</ref> The VC-IOE was compiled to assess the engagement of people with dementia with mobile telepresence and companion robots. It has six dimensions: facial emotional response (the OERS items: pleasure, anxiety/fear, anger, sadness, general alertness, none), verbal engagement (positive verbal engagement with stimulus, positive verbal engagement with facilitator, negative verbal engagement, no verbal engagement, missing), visual alertness/engagement (visually engaged with stimulus, visually engaged with facilitator/others, no visual engagement, missing visual), behavioral engagement (positive behavioral engagement, negative behavioral engagement, no behavioral engagement, missing behavior), collective engagement (using stimulus for collective engagement, no evidence of collective engagement), and agitation (based on Cohen-Mansfield Agitation Inventory-CMAI: evidence of agitation and no evidence of agitation; <ref type="bibr" target="#b27">Koss et al., 1997)</ref>.</p><p>The ethograms that we have described are optimal to study behavior in its complexity as it naturally occurs and flows. However, they produce a measurement of engagement that is segmented into many small pieces of information that cannot be traced back to an overall engagement state. For this reason, we decided to employ a mixed approach to develop a coding system: ethographic and Laban-inspired. First, we observed people with dementia involved in two very different activities and developed two ethograms to describe their behavior in the two contexts in a detailed way. At this level, we kept behaviors to a very fine granularity. Second, we used LMA to identify a common organizational structure to the behaviors in the two ethograms and unify them in a unique coding system viable for both activities<ref type="foot" target="#foot_2">foot_2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Laban Movement Analysis</head><p>LMA is a holistic framework that provides a vocabulary to describe, interpret and generate movement <ref type="bibr" target="#b2">(Bartenieff and Lewis, 1980)</ref>. It is organized into four main categories: body, space, effort, and shape <ref type="bibr" target="#b21">(Hackney, 2002)</ref>. The category body defines specific body parts (in terms of elements in the body structure) and how these body parts are connected in movement <ref type="bibr" target="#b33">(Maletic, 1987)</ref>. The orchestration of body parts (also called body part organization) can be successive (adjacent body parts move one after the other), sequential (non-adjacent body parts move one after the other), and simultaneous (all active body parts move together at the same time). The category space describes the specific direction of a movement with the center of the body as a reference point. The aim of this category is mapping the 3-dimensional structure of the body in relation to the 3-dimensional environment. The category effort regards the qualities of movement, how a movement is performed. The movement has four qualities: flow (ongoingness), weight (relating to power and gravity), space (focus), and time (change in speed) <ref type="bibr" target="#b5">(Bradley, 2008)</ref>. The category shape describes "attitudes toward the environment that are expressed in the way the body changes form" <ref type="bibr" target="#b60">(Wile and Cook, 2010)</ref>. There are three distinctions in the category shape, also referred to as modes of shape change: shape flow (changes in shape in relation to the self), directional shape (goal-oriented changes of the body shape in relation to the others and the environment), and shaping (molding and carving of the body in interaction with the others and the environment).</p><p>In the past, LMA has been used in numerous studies. For instance, to create and describe choreographies <ref type="bibr" target="#b45">(Preston-Dunlop, 1995)</ref>, recognize emotions in dance movement <ref type="bibr" target="#b9">(Camurri et al., 2003)</ref>, increase movement efficiency for factory workers <ref type="bibr" target="#b29">(Lamb, 1965)</ref>, develop "choreographies of interaction" for design activities <ref type="bibr" target="#b59">(Weerdesteijn et al., 2005)</ref>, communicate emotions and mental states to robots <ref type="bibr" target="#b31">(Lourens et al., 2010)</ref> and evoke and intensify the perception of emotions <ref type="bibr" target="#b50">(Shafir et al., 2016)</ref>.</p><p>In order to organize the ethograms in a unique coding system, we focused on the category shape and, in particular, on the modes of shape change. This was for three reasons. First, the category shape captures the way the body changes shape in relation to the self and the environment, and, in general, the behaviors in the ethograms mostly expressed a direction of the body toward the environment (other participants, facilitator, and game) that had a neutral, positive or negative affective nuance. Second, the modes of shape change conceive the body in its entirety and describe changes in its form as whole-body dynamics. This gave us the possibility to describe a large variety of body configurations by combining behaviors belonging to different body parts. Third, as the modes of shape change describe whole-body dynamics motivated by inner attitudes and by the environment, they were particularly suited to associate an engagement meaning to the different body configurations described<ref type="foot" target="#foot_3">foot_3</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frameworks of Engagement</head><p>At present, there is just one model of engagement developed for people with dementia, the Comprehensive Process Model of Engagement <ref type="bibr" target="#b13">(Cohen-Mansfield et al., 2011)</ref>. It describes a series of factors that influence engagement (measured with the OME) in people with dementia: environmental attributes (e.g., background noise, lighting, sound, number of persons in proximity) stimuli attributes (e.g., human social stimuli, simulated social stimuli, inanimate social stimuli) and personal attributes (e.g., gender, age, marital status, medication intake). As the experience of engagement is very difficult to study in people with dementia, very little is known on its characteristics and components. To draw a thorough framework of engagement for dementia, we must step into other domains and understand whether renowned models of user engagement are applicable to dementia. <ref type="bibr" target="#b0">Attfield et al. (2011)</ref> described user engagement as the "emotional, cognitive and behavioral connection that exists, at any point in time, and possibly over time, between a user and a resource." Such connection is described by a series of characteristics: focused attention, positive affect, aesthetics (i.e., the sensory and visual appeal of an interface), endurability (i.e., the likelihood of remembering an experience), novelty (i.e., the surprise effect provoked by a new experience), richness and control (i.e., the variety and complexity of thoughts, actions and perceptions evoked by the activity), reputation-trustexpectation and user context (i.e., the motivation, incentives, and benefits that users get from engagement). Some of these characteristics-namely endurability, novelty, richness and control-are difficult to study in dementia since they suppose preserved cognitive skills. Other characteristics-aesthetics and reputation-trust-expectation-are features of the technology influencing engagement, rather than elements composing it. Three elements of this framework might be transferred to the context of dementia: focused attention, positive affect and user context. Attentional and emotional involvement are unanimously considered the fundamentals of user engagement <ref type="bibr" target="#b12">(Cohen-Mansfield et al., 2009;</ref><ref type="bibr" target="#b43">Peters et al., 2009)</ref>. User characteristics are called personal attributes by <ref type="bibr" target="#b13">Cohen-Mansfield et al. (2011)</ref> and are proved to affect engagement in dementia. Indeed, <ref type="bibr">Perugia et al. (2017b)</ref> found out that motivational disorders, such as apathy and depression, negatively affect engagement in dementia.</p><p>When engagement is studied in the context of HRI, things change. <ref type="bibr" target="#b10">Castellano et al. (2009)</ref> involved children in a chess play with the robot iCat. They observed that, in such a context, engagement got influenced both by the task that the user had to carry out and by the social interaction with the agent. In general, the framework of Castellano and colleagues is applicable to dementia. Indeed, playful activities are usually carried out in groups in nursing homes. As a matter of fact, <ref type="bibr">Perugia et al. (2017a)</ref> applied thematic analysis to an inventory of behaviors displayed by people with dementia during playful activities and identified three main themes overlapping with those just described: attention (task-centered engagement), rapport (social interaction), and affect.</p><p>In the literature of user engagement, engagement is regarded as a process composed of a number of stages. <ref type="bibr" target="#b52">Sidner et al. (2005)</ref> defined engagement as "the process by which individuals in an interaction start, maintain, and end their perceived connection to one another." O'Brien and Toms (2008) identified four phases of engagement: point of engagement, sustained engagement, disengagement, and re-engagement. The conception of engagement as a process with a beginning, a development and an end can be easily reported to the context of dementia, especially if we are able to create a systematic description of the progression of engagement-related behavior over time.</p><p>A last feature of engagement to mention is its intensity. <ref type="bibr" target="#b7">Brown and Cairns (2004)</ref> observed three levels of the immersion in the game experience: engagement (the gamer invests time, effort, and attention), engrossment (the gamer's emotions are directly affected by the game), and total immersion (the gamer is cut off from reality, all that matters is the game). The first two levelsengagement and engrossment-can be transposed to the context of dementia as they can be gauged with objective measures (e.g., behavior, physiology). The latter-total immersion-cannot. Indeed, it must be assessed with subjective measures (e.g., selfreports) and it is related to a sense of detachment from reality and loss of spatial and temporal reference points that constitutes the normal condition of people with dementia.</p><p>To summarize, according to the literature, engagement is composed by focused attention (or task-engagement), social interaction (or rapport), and affect. It is a process that has a start (or point of engagement), a development (or sustained engagement), and an end (disengagement) and has different levels of intensity: engagement, engrossment, and total immersion. Within this paper, we present an evidence-based model of engagement-related behavior (EMODEB) that tries to report all these features of engagement to the context of dementia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MATERIALS AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Fourteen elderlies ranging in age from 69 to 92 years (M: 83.93, SD: 7.28) with a diagnosis of dementia took part in the study. Dementia severity was assessed with the Reisberg Global Deterioration Scale (scores of 4 or 5; <ref type="bibr" target="#b46">Reisberg et al., 1993)</ref> and the Mini-Examen Cognoscitivo (MEC, the Spanish version of the Mini-Mental State Examination, scores between 10 and 23; Vinyoles <ref type="bibr" target="#b56">Bargalló et al., 2002)</ref>. Inclusion criteria for the participation in the study were a diagnosis of mild to moderate dementia and the informed consent of both the participants and their legal guardians. Exclusion criteria were severe dementia, acute visual impairment, bed-ridden condition, reduced motility in the upper limbs, Parkinson's disease or Parkinson's disease dementia and strong hallucinatory or delusional states.</p><p>Participants meeting the inclusion criteria were randomly coupled and participated in the study in pairs (seven couples). The participants in the couples did not know each other prior to the start of the research. The coupling of participants was aimed at preserving the ecological validity of the study by creating a context as close as possible to that of a real-life activity, which is usually group-based.</p><p>The decision of excluding participants with severe dementia from this study was dictated by the need to identify behaviors strictly related to engagement. In severe dementia, ambiguous behaviors might appear during activities. For instance, severe dementia might cause participants to sleep during activities. In engagement terms, sleeping represents a lack of interest toward the activity. However, in the case of severe dementia, it might be as well due to the severity of the medical condition.</p><p>Another deterrent for the inclusion of people with severe dementia in this study was the sparsity of engagement-related behaviors displayed by people with severe dementia as compared to people with mild and moderate dementia during a pilot study. We assumed that the inventory of engagement-related behaviors would have been more complete if we had focused on participants with mild and moderate dementia. Moreover, we theorized that it would have constituted a superset of an inventory of engagementrelated behaviors compiled with persons with severe dementia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>The study followed a repeated measures design with two conditions: a game-based cognitive stimulation and a robotbased free play. Each activity was presented in a different session and was repeated three times within the study. As a result, the study was composed of six sessions, three of game-based cognitive stimulation and three of robot-based free play. The two activities were presented in alternated order across sessions. Game-based cognitive stimulation and robot-based free play were presented to participants every other week starting from game-based cognitive stimulation (see Table <ref type="table" target="#tab_0">1</ref> for an overview of the study design).</p><p>All sessions of activities were conducted by a clinician working in the nursing homes (i.e., the psychologist or the social educator of the care facility) at the presence of an experimenter (i.e., a researcher from the university). The pairing of facilitators with the couples was random, and the same clinician followed the same couples across all the sessions. The experimenter was present during sessions to ensure the timely execution of activities and to monitor the functioning of the equipment. In order for his/her presence not to be disruptive of the behavior of participants, the experimenter took part in the activities of the nursing homes for 1 month prior to the start of the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Activities</head><p>In the game-based cognitive stimulation, participants were asked to collaboratively complete three types of board games: jigsaw puzzles, shape puzzles and a game with dominoes. The jigsaw puzzles and the shape puzzles to complete were three. They were presented in a progressive order of difficulty, from the easiest to the most difficult across sessions (Table <ref type="table" target="#tab_0">1</ref>). The challenge level of jigsaw puzzles was customized according to the cognitive level of the participants in the couples. The right level of challenge was determined in a pilot study. Couples with one or both participants with mild dementia completed two 6-piece puzzles and one 9-piece puzzle. Couples with both participants with moderate dementia completed two 4-piece puzzles and one 6piece puzzle. The order of presentation of board games was randomized using a Latin squares technique and was always different across sessions.</p><p>In the robot-based free play, participants interacted with the animatronic pet robot Pleo (<ref type="url" target="http://www.pleoworld.com/pleo_rb/eng/lifeform.php">http://www.pleoworld.com/ pleo_rb/eng/lifeform.php</ref>). Pleo is a robotic dinosaur developed by UGOBE which acts as a living pet (Figure <ref type="figure">1</ref>). It has an array of sensors that allow it to make sense of the surrounding environment and interact with people. For instance, touch sensors to discriminate among different types of touch, microphones to perceive sound and orientate toward it, ground foot sensors to detect surfaces, a camera-based vision system to detect light and navigate and an internal clock to recognize the time to get up, eat or sleep. Pleo is also able to display its internal states (e.g., hunger, sleep) and moods (e.g., happy, scared). During sessions, participants were left free to interact with the robot spontaneously. The facilitators were given a script with a list of activities that Pleo could support (e.g., feed Pleo, make Pleo sleep), so that they could prompt further interaction in case of a deadlock.</p><p>The two activities were chosen for two reasons: they involved different skills (game-based cognitive stimulation: cognitive skills, robot-based free play: affective and social skills) and the artifacts used in the two activities had very different affordances <ref type="bibr" target="#b37">(Norman, 1999)</ref>. As a consequence, the two activities were likely to prompt different engagement states and different behavioral expressions of such engagement states. The fact that the two activities were likely to elicit different types of engagement was of substantial importance. Indeed, this study was aimed at developing a coding system of engagement-related behavior applicable to diverse activities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting</head><p>The study took place in two nursing homes in rooms that were usually allocated to recreational activities. A rectangular table was placed on one side of the room, and two hand-held cameras were arranged on top of mini-tripods and positioned one in front and one on the side of participants. The frontal camera was positioned on a small table, the lateral camera was either hidden on a library shelf or positioned on a desk.</p><p>During activities, the participants sat on the same side of the table. The facilitator always stood between the participants. The central positioning of the facilitator was meant not to influence the engagement state of the participants. Indeed, in a previous pilot study, we noticed that, when the facilitator spent more time closer to one of the participants, this had a negative influence on the flow of the session.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instruments and Measures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Video Recording</head><p>The cameras were switched on by the experimenter as participants reached the room and were turned off by the same when they left. Before the start of each session, facilitator and experimenter ran a habituation phase. They conversed shortly with participants about their week to get them accustomed to the experimental setting and comfortable with the situation of data collection. Albeit the presence of cameras might be thought of as a factor that could affect participants' behavior, we noticed that participants forgot about the cameras as the activity started.</p><p>To develop the ethograms, we used the video footage of the frontal camera. The lateral camera was used as a back-up in case the frontal camera did not work, or objects occluded the full visibility of behaviors. The original videos collected from the frontal camera were cut from the beginning of the activity to the end of the activity. Hence, the habituation phase was not considered in the development of the coding system and was also left out of the scoring. We considered the moment when the facilitator placed the first board game or Pleo on the table in front of the participants as the beginning of the activity and the moment when s/he removed the last board game or Pleo from the table as the end of the activity. The database of videos was composed of 42 sessions of play of the duration of 20-25 min (∼17.5 h of video footage). The database of videos was split in two parts. Thirty videos were used to develop the ethograms and structure them in a coding system (15 videos per activity type). Twelve videos (6 videos per activity type) were used to test the IRR of the coding system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Building the Coding System</head><p>The coding system of engagement-related behavior was built in 18 months by a multidisciplinary research team which included a certified movement analyst (CMA). The development of the coding system consisted of two phases: description and structuring. In the descriptive phase, we adopted an ethographic approach similar to that of <ref type="bibr" target="#b39">Olsen et al. (2016)</ref> and <ref type="bibr" target="#b23">Jøranson et al. (2016)</ref> and developed two ethograms, one per activity. In the structuring phase, we employed LMA to sort out the complexity of the two ethograms. This enabled us to identify commonalities among the behaviors displayed in the two activities and interpret each behavior in engagement terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodological note on the development of the coding system</head><p>The decision of building two ethograms, one per activity, instead of just one, had three motives. First, although the ethogram is operationalized as a catalog of species-related behavior in Ethology, ethologists acknowledge the role of context in shaping behavior. As a matter of fact, animal behavior broadly changes when studied in captivity and in the wild. Second, when behavior is kept to a very fine granularity, it is considerably influenced by the affordances of the objects populating the scene under study and by their use. Albeit stroking a robot and holding the pieces of a jigsaw puzzle can both be conceived as manipulations of a game, they are motivated by the specific affordances of the artifacts in use. Third, as the two activities under study had very different scopes of action (cognitive stimulation vs. affective and social disclosure), the behaviors they were likely to elicit greatly differed.</p><p>The two approaches, ethograms and LMA, were used in concert because they could contribute to the understanding of engagement-related behavior in different ways. On the one hand, ethograms, which are descriptive in nature, could give us the possibility to create a lexicon of engagement-related behavior without selecting the meaningful behaviors a priori. On the other hand, LMA, which is a holistic framework to describe and interpret movement, could enable us to find the structure of engagement-related behavior by appealing to the function of each behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Development of the ethograms</head><p>In order to develop the two ethograms, we first watched the thirty videos allocated to the construction of the coding system (thirty sessions: 15 of game-based cognitive stimulation, 15 of robotbased free play). Then, we described each video in a separate file by detailing the main events and behaviors in chronological order. Further, we watched each video at a slow speed and stopped it whenever we identified a micro-behavior. <ref type="bibr" target="#b18">Dautenhahn and Werry (2002)</ref> defined micro-behaviors as well-identifiable low-level action-movement-oriented behaviors recognizable by computational systems. Each micro-behavior was given a name and an operational description.</p><p>Before proceeding to the structuring phase, we removed from the ethograms those micro-behaviors that had an ambiguous meaning. For instance, we removed manipulators (e.g., scratching the chin or the scalp), adjustments (e.g., adjusting spectacles, watch, bracelets, earrings, clothes), and vocalizations (e.g., sighing and singing). These micro-behaviors occurred several times with different meanings. Sometimes participants scratched their scalp due to mental effort, other times simply because of itching. Sometimes they adjusted their clothes because of being fidgety, others due to discomfort. Sometimes they sang as a form of enjoyment, for instance while stroking Pleo. Other times, they sang while in an impasse during board games. The lack of a univocal meaning made it hard to figure out the contribution of these micro-behaviors to the assessment of engagement and brought us to their exclusion.</p><p>We also excluded verbal behavior from the ethograms. This decision was made with our target group in mind. Although the participants in this study had their language skills still preserved, most people with dementia do not <ref type="bibr" target="#b54">(Thompson, 1987;</ref><ref type="bibr" target="#b25">Klimova and Kuca, 2016)</ref> and it is of crucial importance to make meaning of their engagement-related behavior without being dependent on language production.</p><p>As a last step, we discarded head gestures, such as nodding, negation, head protruding, and co-speech gestures (i.e., hand and arm movements that accompany spoken language such as saying no with the index finger of the hand). These gestures were hard to relate to a specific element in the activity without resorting to language. For instance, suppose that a participant nods as a reply to the facilitator while s/he (the participant) is looking at the game. The information conveyed by the question of the facilitator would get lost in the analysis of nonverbal behavior and we might wrongly infer the nodding to be referred to the game.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structuring of the ethogram</head><p>As a first step in the structuring of the ethograms into a unique coding system, we stated the body portion involvement. We did so by making reference to the micro-behaviors in the two ethograms. In LMA, body portion involvement refers to which body parts are activated during movement <ref type="bibr" target="#b21">(Hackney, 2002)</ref>. The involvement might regard the whole body or single body parts. A whole body movement is a movement in which the body is involved in its entirety. For instance, walking on the street. A body part movement (also called gesture) is a movement that involves just a discrete part of the body. For instance, a head turning. The body parts involved in a movement might be body areas (i.e., head, torso, chest and pelvis), limbs (i.e., arms, hands, legs, feet), joints (e.g., shoulders, elbow, wrists), and body quadrants (i.e., right upper, left upper, right lower, left lower). The micro-behaviors in the ethograms involved two body areas, head, and torso, and two limbs, arms, and hands. Given that there were no specific behaviors in the ethograms involving exclusively the arms or the hands, we decided to group the two limbs in a single category. As a result, the body portion involvement of both the ethograms consisted of three body parts: head, torso and arms/hands. We grouped the micro-behaviors in the two ethograms according to the body part they involved.</p><p>As a second step of the structuring, we identified those micro-behaviors expressing a directional shape of the body parts (i.e., head, torso, arms/hands) and organized them based on their target in space. From the perspective of one of the participants, we identified five foci of the micro-behaviors: the partner, the facilitator, the experimenter, the game (i.e., the board games or Pleo) and none of them. Most micro-behaviors in the two ethograms described the movement of a body part aimed at addressing or physically reaching one of the foci. For instance, gaze toward the partner was a head movement aimed at addressing the focus partner. Similarly, lean in partner was a torso movement aimed at physically addressing the focus partner. Last, touch the partner was an arms/hands movement aimed at physically reaching the focus partner.</p><p>As a concluding step in the structuring of the ethograms, we studied the remaining micro-behaviors. We noticed that some of them expressed a directional shape with shaping support, while others a shape flow occurring simultaneously with a directional shape. These micro-behaviors could be seen as traits superimposed on the directional shape carrying an additional item of meaning in terms of engagement. Indeed, they all described an affective attitude of the participant, either positive or negative, toward the foci of the activity. We grouped these microbehaviors according to their meaning in terms of affect: positive or negative. There was just one exception to this paradigm which regarded micro-behaviors such as applauding or dancing with the arms and hands. These micro-behaviors did not express a directional movement toward the foci of the activity, but exclusively a gestural movement carrying a positive affective meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Coding System</head><p>The coding system resulting from the structuring process of the two ethograms can be retrieved in Tables A, B, and C in Appendix A (see Supplementary Material). We traced the structure of the ethograms (body portion involvement, directional shape, shape flow and shaping) back to a coding scheme that could be scored using the software Noldus Observer XT 10.5. In this section, we explain how we achieved this.</p><p>Observer XT gives the possibility to define clusters of behaviors, also called behavior groups. Behaviors in the groups can be either mutually exclusive (they cannot overlap in time) or start/stop behaviors (they can co-occur). For the former, the coder just needs to specify the start of a behavior and Observer XT assumes that the previous behavior is concluded. For the latter, the coder needs to specify both the beginning (start) and the end (stop) of the behavior, as Observer XT cannot infer it. In our case, we defined three behavior groups corresponding to the body parts involved in the activities: head behaviors, torso behaviors, and arms/hands behaviors.</p><p>The behaviors in each group were those directional shape micro-behaviors that we had organized based on their focus in the activity (partner, experimenter/facilitator, game, and none of them). Also, micro-behaviors such as applauding and dancing with the hands, which we had described as exceptions to our paradigm, were scored as behaviors (see positive signs of affection involving arms/hands and negative signs of affection involving arms/hands) and nested in the corresponding behavior group (arms/hands behaviors). As they were addressed to different foci, the behaviors in each behavior group did not overlap, thus we scored them as mutually exclusive<ref type="foot" target="#foot_4">foot_4</ref> .</p><p>Another feature of Observer XT is the possibility to add modifiers to behaviors in the behavior groups. Modifiers are additional specifications regarding a behavior that describe it more precisely or limit its scope. We chose to score the microbehaviors expressing affect as modifiers. These micro-behaviors were scored according to their affective meaning, positive or negative. Moreover, we added a neutral meaning which was scored when the directional shape behaviors appeared alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research Questions and Hypotheses</head><p>The research questions that we wanted to investigate with this study were four: (i) Is the coding system that we have developed reliable across different coders? (ii) Are there any recurring patterns of engagement-related behavior visible from the scoring of the coding system? (iii) Can we compile an evidence-based model using these recurring patterns? And, if yes, (iv) How good is the fit of this model?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical Approval</head><p>The study was conducted according to the Declaration of Helsinki, and to Spanish laws number 159/2007 and 41/2002. An informed written consent was signed by all the legal guardians of participants. All participants were informed about the study and gave their consent to participate. Both the consent of the legal guardian and that of the participant were required to take part in the data collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inter-rater Reliability</head><p>Inter-rater reliability (IRR) was performed on 12 videos (29% of the database). The videos were scored by two coders: the researcher involved in the study (GP) and an external independent coder that had not been involved in the study <ref type="bibr">(TvT)</ref>.</p><p>IRR between coders was calculated using the software Noldus Observer XT 10.5 with the Cohen's kappa statistic <ref type="bibr" target="#b11">(Cohen, 1960)</ref>. Observer XT calculates IRR by taking into account both the matching between the behaviors scored by the two coders and their overlap in time. We computed the global Cohen's kappa of the coding system, the Cohen's kappa of the behavior groups and the Cohen's kappa of single behaviors. With regards to the latter, we included in the calculation of the IRR only behaviors with a mean duration higher that 1% of the session. Indeed, the Cohen's kappa statistic is not accurate with very infrequent behaviors. We report kappa coefficients of behaviors occurring &lt;5% of the time. However, we suggest to interpret them with caution <ref type="bibr" target="#b17">(Dael et al., 2012)</ref>.</p><p>To evaluate the results of IRR, we referred to the thresholds set by <ref type="bibr" target="#b20">Fleiss (1981)</ref> and <ref type="bibr" target="#b1">Bakeman and Gottman (1987)</ref>. Fleiss suggested that a kappa between 0.40 and 0.60 represented a fair agreement, between 0.60 and 0.75 a good agreement and above 0.75 an excellent agreement. <ref type="bibr" target="#b1">Bakeman and Gottman (1987)</ref> considered a kappa coefficient lower than 0.70 as insufficient and proposed to interpret it with suspicion.</p><p>We report the results of the IRR in Table <ref type="table" target="#tab_1">2</ref>. With regards to the global IRR, this proved to be excellent for the game-based cognitive stimulation (kappa = 0.78) and very good for the robotbased free play (kappa = 0.74). As for behavior groups, IRR was excellent for head behaviors in the game-based cognitive stimulation (kappa = 0.76) and good in the robot-based free play (kappa = 0.70), very good for torso behaviors in both gamebased cognitive stimulation (kappa = 0.74) and robot-based free play (kappa = 0.73) and good for arms/hands behaviors in gamebased cognitive stimulation (kappa = 0.63), and robot-based free play (kappa = 0.71).</p><p>With regards to single behaviors, IRR was good to excellent for most of them. However, for some of them it could not be scored due to a frequency issue (&lt;1%) and for few of them it achieved unsatisfying results. We explained the unsatisfying kappa coefficients of "none of the target head movements" in the game-based cognitive stimulation and of "gaze toward facilitator/experimenter" in the robot-based free play with their low occurrence (&lt;5%). With regards to the low agreement of "none of the target head movements" during robot-based free play, it could be due to the sharp differences in the frequency of the behavior across participants (from 0.27 to 15.69%). For what regards "manipulate the game" in cognitive games, the moderate agreement could not be justified by appealing to a frequency issue. In this case, the disagreement was due to an incorrect classification of the behavior by the coders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Building of the Evidence-Based Model of Engagement-Related Behavior</head><p>In this section, we describe how LMA enabled us to identify patterns of engagement-related behavior, associate a meaning in terms of engagement to them and organize them in a model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Organization of Body Parts</head><p>In order to identify patterns of behaviors from the scoring of the coding system, we made reference to the formalization of body part organization <ref type="bibr" target="#b21">(Hackney, 2002)</ref>. Across activities, we observed a main pattern of body part organization in the directional shape behaviors: successive-space hold (with various gestures)successive (see Figure <ref type="figure" target="#fig_0">2</ref>). Successive organization appeared after the game was placed on the table by the facilitator. In this situation, the movement toward the game was initiated by the head and sequenced into arms/hands via the torso. After this successive movement, the head and the torso remained in the same position, while the arms/hands kept manipulating the game. This last organization of body parts can be described as a space hold of the head and torso with gestures of arms/hands. In LMA, space hold is the lock of specific body parts in space. When the game was removed from the table by the facilitator, we observed yet another instance of successive organization. The head of the participant initiated the movement of the torso backwards toward the seat. Then, this movement toward the seat progressed through the torso into the arms/hands. The pattern of body part organization successive-space hold (with various gestures)-successive occurred also when the participant wanted to address the partner. In this case, however, the initiation of the head led into a sideways movement of the torso toward the partner which then progressed into arms/hands. From the described patterns of body part organization, we hypothesized that movements directed toward the game and the partner were initiated by the head and that the head had a leading role in engagement-related behavior.</p><p>The successive-space hold (with various gestures)-successive pattern of body part organization was the most frequent during activities and, as it involved all the body parts specified in the ethograms, we called it full active participation when it was  <ref type="bibr">-)</ref> The duration of the behavior is too short to allow interpretation. The results of inter-rater reliability for the behavior negative signs of affection of the torso (SOAneg) are not reported as they did not occur in the 12 videos. directed toward the game (see the woman in Figure <ref type="figure" target="#fig_1">3A</ref> and the woman on the right in Figure <ref type="figure" target="#fig_1">3B</ref>) and full active social engagement when it was directed toward the partner (see the woman on the left in Figure <ref type="figure" target="#fig_1">3B</ref>).</p><p>The successive-space hold (with various gestures)-successive pattern of body part organization did not always involve all the body parts specified in the ethograms. We observed three variations of the main pattern of body part organization. The first occurred when the participants addressed the game (or the partner) exclusively with the head and held the head in the same position in space (see Figure <ref type="figure" target="#fig_2">4</ref>). The second appeared when they addressed the game (or the partner) with a successive movement of the head and the torso which was then held in the same position in space. The third took place when the participants  addressed the game (or the partner) with a sequential movement of the head and the arms/hands which was then held in the same position in space, without further activation of the torso (see Figure <ref type="figure" target="#fig_2">4</ref>).</p><p>Following <ref type="bibr" target="#b24">Judge et al. (2000)</ref>, we considered the first two variations as passive forms of engagement, as they did not involve a proactive manipulation of the artifacts in the activity. However, we acknowledged that the second variation was a step forward in terms of engagement with respect to the first one, as it also involved the activation of the torso. As a matter of fact, postural attitudes express a "corporeal readiness to act" <ref type="bibr" target="#b8">(Bull, 1951;</ref><ref type="bibr" target="#b51">Sheets-Johnstone, 1999)</ref>. With regards to the last variation, it did describe a constructive form of engagement. Nonetheless, the lack of torso involvement made this engagement look less complete. We called the first variation passive attention when the head was directed toward the game and social acknowledgment when it was directed toward the partner (see the man in Figure <ref type="figure" target="#fig_1">3C</ref>). We called the second variation attentional readiness when the head and torso were directed toward the game and social readiness when they were directed toward the partner. We called the third variation reduced active participation when the head and the arms/hands were directed toward the game and reduced active social engagement when they were directed toward the partner. As a consequence of this reasoning, we can conclude that: the more body parts are involved in the movement toward the game or toward the partner, the higher the engagement of the participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Organization of Modifiers</head><p>On top of these more directional movements, the coding system also featured behaviors expressing positive and negative affect. As these behaviors were superimposed on the directional ones, they added a further layer of meaning to them. The affective coloring specified the valence of engagement.</p><p>As affective behaviors vary due to the affordances and the uses of the artifacts in the activity, their patterns of body part organization greatly depend on the type of activity. For instance, during game-based cognitive stimulation, we could not isolate specific patterns of body part organization as affective behaviors were very rare. What we noticed, however, was that affective behaviors mostly appeared after the completion of the game and mostly involved the head (e.g., smile and laughter). As for robotbased free play, affective behaviors were rather frequent and involved two types of body part organization: successive and space hold (with or without various gestures). A typical successive body part organization appeared when the participant directed the head toward Pleo, smiled at it, initiated the approach toward Pleo with the chest, embraced the robot with both arms/hands, lift the robot to bring it close to the torso and hugged it. This sequence was sometimes followed by a space hold of the three body parts in the affective behavior (see the woman in Figure <ref type="figure" target="#fig_1">3C</ref>). Other times, it was followed by a space hold of the two body parts with gestures (e.g., hug the robot while stroking it, hug the robot and cradle it). Another successive body part phrasing occurred when the participant addressed Pleo with the head, smiled at it, initiated the approach toward Pleo with the chest and stroked the robot. Also in this case, the sequence was often followed by a space hold with gestures. This brought us to conclude that the more body parts are involved in the expression of affect, the more intense is the affective coloring of engagement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Model</head><p>To sum up, the analysis of body part organization brought us to the following conclusions:</p><p>1. The head has a leading role in engagement-related behavior. 2. The head initiates the movement of the torso toward the activity (i.e., the game or the partner). 3. The movement of the torso toward the activity can be then sequenced into arms/hands. 4. The head alone might initiate the movement of the arms/hands toward the activity. 5. The gestural support (positive or negative) might initiate the postural support (positive or negative). 6. The postural support (positive or negative) can be then sequenced into quality of gesture (positive or negative). 7. The gestural support (positive or negative) alone might initiate the quality of gesture (positive or negative).</p><p>These conclusions were transformed into seven hypothetical relations between variables<ref type="foot" target="#foot_5">foot_5</ref> . Respectively:</p><p>(H1) The variable gaze toward activity (i.e., head directed toward the game and the partner) is an exogenous variable (i.e., a variable whose value is not dependent on the value of other variables in the model). (H2) The variable gaze toward activity (i.e., head directed toward the game and the partner) has a direct effect on the variable lean toward activity (i.e., torso directed toward the game and the partner). (H3) The variable lean toward activity has a direct effect on the variable reach out activity (i.e., arms/hands reaching the game and the partner). (H4) The variable gaze toward activity (i.e., head directed toward the game and the partner) has a direct effect on the variable reach out activity. (H5) The variable gaze toward activity with gestural support (i.e., affective behaviors involving the head directed toward the game and the partner) has a direct effect on the variable lean toward activity with postural support (i.e., affective behaviors involving the torso directed toward the game and the partner). (H6) The variable lean toward activity with postural support has a direct effect on the variable reach out activity with quality of gesture (i.e., affective behaviors involving the arms/hands directed toward the game and the partner). (H7) The variable gaze toward activity with gestural support has a direct effect on the variable reach out activity with quality of gesture.</p><p>On top of these seven hypothetical relations, we added three additional ones. These were aimed at disclosing relationships between the behaviors and the modifiers pertaining to the same body part (i.e., head, torso, arms/hands).</p><p>(H8) The variable gaze toward activity has a direct effect on the variable gaze toward activity with gestural support. (H9) The variable lean toward activity has a direct effect on the variable lean toward activity with postural support. (H10) The variable reach out activity has a direct effect on the variable reach out activity with quality of gesture.</p><p>The model in Figure <ref type="figure" target="#fig_3">5</ref> depicts all the hypothetical relationships between variables (H2-H7: blue arrows, H8-H10: red arrows).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test of the Evidence-Based Model of Engagement-Related Behavior</head><p>To test the model, we scored all 42 videos in the database with the coding system and calculated the percentage of observation duration of each behavior and modifier. Before fitting the model, we performed a series of operations to reduce the data. To preserve the clarity of this section, we detail them in Table <ref type="table" target="#tab_2">3</ref>. The rationale behind the data reduction was suggested by our model. Indeed, we treated those behaviors directed toward the game or the partner as engagement-related behaviors and those behaviors directed toward the facilitator/experimenter or not directed toward the foci of the activity as disengagement-related behaviors.</p><p>The result of the data reduction was an engagement score for each body part ranging from -100 to 100, where -100 represented the highest disengagement with the activity (game and partner) and 100 the highest engagement with it. With regards to the modifiers, we took into account only the positive and negative modifiers referred to the game and the partner. We subtracted the negative modifiers from the positive. Thus, we obtained a negative score when negative engagement was predominant, a positive score when positive engagement prevailed and a score of zero when negative and positive engagement were even. We tested the model using SEM with the software SPSS Amos 22.0. We ran the model twice using the data from both activities. The first time, we calculated the Mahalanobis distance and identified the farthest observations from the centroid ones. The second time we fitted the model excluding the outlier observations (N = 7). Indeed, SEM is sensitive to violations to normal distribution. The model proved to be an excellent fit for the data [X 2 (6,N=77) = 5.866, p = 0.436; RMSEA = 0.000; NFI = 0.970; CFI = 1.000; RFI = 0.896; PNFI = 0.277] and almost all the hypothesized relations (H1-H10) between variables were significant (see Table <ref type="table" target="#tab_3">4</ref> and<ref type="table">Figure 5</ref>). H1 was confirmed by the goodness of fit of the model. H2-H10 were confirmed both by the goodness of fit of the model and by the significance of the model estimates. The only postulated relation between variables that was not significant was the one between lean toward the activity and reach out activity (H3). We ran two regression analyses to figure out whether this result depended on the behaviors directed toward the game or on those directed toward the partner. The results disclosed that near reach/lean toward game had a significant effect on manipulate game (β = 0.246, t (76) = 2.201, p &lt; 0.05) and lean in partner had a significant effect on reach out partner (β = 0.231, t (76) = 2.057, p &lt; 0.05). Compared to regression analysis, SEM calculates also an error term for the variables. Thus, the lack of a significant result for this relation depended on the size of the error term of the two variables and not on the lack of relationship between them.</p><p>With regards to the negative relations between the behavior lean toward activity and the modified lean toward activity with postural support and between the behavior reach out activity and the modified reach out activity with quality of gesture, these might be due to the fact that lean toward activity and reach out activity were more frequent during game-based cognitive stimulation, whereas their modified subsets lean toward activity with postural support and reach out activity with quality of gesture were more frequent during robot-based free play. Hence, the former could not be positive predictors of the latter in both activities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>The present study has been mainly limited by the small sample size. Future work should attempt to increase the sample size and include people with dementia coming from different cultural backgrounds and countries. Moreover, it should test whether the model holds in activities others than game-based cognitive stimulation and robot-based free play and in activities carried out in larger groups.</p><p>A further aspect to study is related to the set-up of the cameras. The second coder has reported that the chosen set-up of the cameras made it complex to score postural shifts. The frontal camera flattened the view and the other camera was not lateral enough to catch the detaching of the torso of the participant from the seat. We suggest that a good set-up to collect data should consist of three cameras, one frontal and two lateral and that the lateral cameras should be positioned exactly on the side of participants. This set-up would not just help in properly scoring postures, but also in scoring arms/hands movements occluded by objects.</p><p>Another limitation of this study is the number of coders. We tested the agreement of the coding system with two coders. However, a larger number of annotators would have made the analysis of IRR stronger. For what concerns statistical analyses, SEM is a statistic usually performed on large samples. In order to perform it, we used the scores of the same participants in different sessions as different observations. However, a better practice would be that of having a larger sample size and using just one score per participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>The body of work described in the present paper significantly advances the state of the art. We developed a coding system aimed at measuring engagement-related behavior across activities in people with dementia and a model to interpret the results of such a coding system in terms of engagement. We call the coding system the Ethographic and Laban-Inspired Coding System of Engagement (ELICSE) and the model the Evidencebased Model of Engagement-related behavior (EMODEB). Both have been developed for people with dementia. However, their use can be extended to people with difficulty of introspection and verbal communication (e.g., persons with autism).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion on the Coding System</head><p>With respect to observational rating scales, the ELICSE enables researchers to study the behavior of people with dementia in its complexity and temporal progression. Compared to available coding schemes, it gives an account of the continuous flow of behavior. As opposed to ethograms, it helps researchers to trace behavior back to an overall engagement state. The ELICSE achieved an excellent IRR in both game-based cognitive stimulation and robot-based free play (first research question: positive response).</p><p>The ELICSE has been developed in the context of gamebased cognitive stimulation and robot-based free play. However, for its characteristics, it can be applied to activities that: (i) do not entail physical effort, (ii) envisage a proactive role for the person with dementia, and (iii) involve the use of tangible artifacts (e.g., social robots, sensory stimulation, interactive technologies).</p><p>In order to apply the ELICSE to other activities, the researcher should adapt it. In any activity, there is a different context and a different body portion involvement. The context refers to the objects and actors in the activity (i.e., facilitator, experimenter, participant, robot, jigsaw puzzle, relative). The body portion involvement refers to the body parts involved in the movement toward the objects and the actors in the activity and in the expression of affect. The behaviors in the ELICSE can be generated by combining the body parts involved in the activity with the actors and objects in it. The modifiers in the ELICSE arise from the positive and negative behaviors superimposed on the more directional ones.</p><p>For instance, suppose we would like to measure engagement in a group-based sensory stimulation. We know that the sensory stimulation activity is carried out by two facilitators in groups of six people and that it features the use of patches with different textures. We also know that the sensorial stimulation is carried out in a sitting position and participants sit all around a circular table. The actors and objects of our activity would be three in this context: the facilitators, the participants, and the patches. As participants are sitting during the activity, the body parts addressing the facilitators, the other participants and the patches are likely to be the head, the torso and the arms and hands. The behaviors in the ELICSE would be the movements of the head, the torso and the arms/hands toward the facilitators, the other participants or the patches. The modifiers would be the behaviors superimposed on the directional ones expressing positive or negative affect. As an example, the movement of the head toward the patches would be gaze toward the patches, while the movement of the torso toward another participant would be lean toward/in the other participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion on the Model</head><p>The EMODEB is a model that describes the natural flow of behavior across body parts and details the meaning of different patterns of body part organization appearing during activities in terms of engagement. In agreement with the framework of Castellano and colleagues, the ELICSE is composed of three elements: task-engagement, social interaction and affect.</p><p>In concordance with Sidner et al. and O'Brien and Toms, the EMODEB identifies three stages in the expression of engagement, which are described in terms of patterns of body part organization (second research question: positive response). The successive movement of participants toward the game or the partner might be assimilated to the start of the engagement (or point of engagement) in the activity. The shape hold (with various gestures) can be interpreted as the maintenance of engagement (or sustained engagement). The successive movement of participants back to the seat might be read as the end of engagement (or disengagement). The relation between the body parts involved in the movement were summarized in a structural equation model (third research question: positive response). The SEM achieved an excellent fit and the relations between the body parts involved in the movement were all significant (forth research question: positive response).</p><p>According to the EMODEB, the behaviors in the ELICSE do not have the same importance in engagement terms as they are organized hierarchically. Based on the EMODEB, gaze toward activity is more important than lean toward activity and reach out activity, and reach out activity is more important than lean toward activity. Likewise for modifiers, gaze toward activity with gestural support is more important than lean toward activity with postural support and reach out activity with quality of gesture, and reach out activity with quality of gesture is more important than lean toward activity with postural support. The EMODEB demonstrates that the head behaviors and the arms/hands behaviors are respectively the starting and the conclusive point of both engagement-related (gaze toward activity, lean toward activity, reach out activity) and affect-related behavior (gaze toward activity with gestural support, lean toward activity with postural support, reach out activity with quality of gesture), and that the torso behaviors energize the passage between the start and the end of engagement-related and affect-related behavior without playing a substantial role in it.</p><p>The hierarchical organization of the behaviors in the ELICSE also supports our statement about the four levels of intensity of engagement-related behavior: (i) passive engagement (passive attention and social acknowledgement): head directed toward the game or the partner, (ii) readiness to engage (attentional readiness and social readiness): head and torso directed toward the game or the partner, (iii) reduced active engagement (reduced active participation and reduced active social engagement): head and arms/hands directed toward the game or the partner without the involvement of the torso (iv) full active engagement (full active participation and full active social engagement): head, torso and arms/hands directed toward the game or the partner. Moreover, it also backs up the existence of a similar hierarchical structuring for affective behaviors.</p><p>The four levels of engagement-related behavior are an expression of what Brown and Cairns defined as the first level of immersion in a game (the gamer invests time, effort and attention). The affective coloring of engagement in the EMODEB can have a negative or positive valence. Its intensity depends on the number of body parts involved in expressing affect. The affective coloring of full active engagement can be compared to the second level of immersion in a game (the gamer's emotions are directly affected by the game). As expected, the third level of immersion in the game formalized by Brown and Cairns, could not be isolated in the behavior of people with dementia during activities.</p><p>Future work on the EMODEB should focus on getting overall scores of engagement and affect and on scoring the intensity of engagement over time. The former goal can be achieved by assigning weights to each body part based on their importance in the model (e.g., head = 0.50, torso = 0.10, and arms/hands = 0.40) and computing weighted averages of engagement and affect. The latter objective could be fulfilled by associating a score to each level of engagement (e.g., from 1 to 4, where each unit is a level of engagement) and affect (e.g., -3 to +3, where -3 is negative engagement expressed with all three body parts and +3 positive engagement expressed with all three body parts) and code the progression of engagement over the session with a time-sampling technique. To the best of our knowledge, the EMODEB constitutes the first formalization of the way the engagement-related behavior of people with dementia naturally occurs and unfolds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSIONS</head><p>The present paper reported the results of a study aimed at developing a coding system of engagement-related behavior and a model of engagement-related behavior for people with dementia. The first objective resulted in the ELICSE, a coding system that can be used to quantify engagement-related behavior across diverse activities, but also to describe how this changes over time. The second objective led to the EMODEB, an evidence-based model of engagement that describes relationships between the behaviors of different body parts and associates them a meaning in terms of engagement. The ELICSE achieved an excellent IRR and the EMODEB proved to be an excellent fit for our data. The ELICSE and the EMODEB were developed in the context of game-based cognitive stimulation and robot-based free play. However, their use can be extended to other activities. To the best of our knowledge, the ELICSE and the EMODEB constitute the first formalization of engagement-related behavior for dementia that describes how behavior unfolds over time and what it means in terms of engagement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 2 |</head><label>2</label><figDesc>FIGURE 2 | Main pattern of body part organization.</figDesc><graphic coords="10,56.64,408.75,481.92,174.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 3 |</head><label>3</label><figDesc>FIGURE 3 | (A) Man: no body part is addressed toward the game or the partner (no engagement). Woman: all body parts are simultaneously addressed toward the game (full active participation); (B) Woman on the left: all body parts are simultaneously directed toward the partner (full active social engagement). Woman on the right: all body parts are directed toward the game (full active participation). (C) Man: just the head is directed toward the partner (social acknowledgement). Woman: all body parts are directed toward the game. Moreover all body parts express positive affect (positive full active participation).</figDesc><graphic coords="11,112.64,69.92,369.84,569.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 4 |</head><label>4</label><figDesc>FIGURE 4 | Examples of the first and third variations to the main pattern of body part organization.</figDesc><graphic coords="12,56.64,69.99,481.92,151.68" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 5 |</head><label>5</label><figDesc>FIGURE 5 | SEM of the evidence-bades model of engagement-related behavior. Significance level: *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001.</figDesc><graphic coords="13,312.78,69.31,229.68,249.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 |</head><label>1</label><figDesc>Overview of the study design.</figDesc><table><row><cell>First session</cell><cell>Second session</cell><cell>Third session</cell><cell>Fourth session</cell><cell>Fifth session</cell><cell>Sixth session</cell></row><row><cell>Jigsaw puzzle 1</cell><cell></cell><cell>Dominoes</cell><cell></cell><cell>Shape puzzle 1</cell><cell></cell></row><row><cell>Jigsaw puzzle 2</cell><cell></cell><cell>Jigsaw puzzle 1</cell><cell></cell><cell>Shape puzzle 2</cell><cell></cell></row><row><cell>Jigsaw puzzle 3</cell><cell></cell><cell>Jigsaw puzzle 2</cell><cell></cell><cell>Shape puzzle 3</cell><cell></cell></row><row><cell>Shape puzzle 1</cell><cell>Play with Pleo</cell><cell>Jigsaw puzzle 3</cell><cell>Play with Pleo</cell><cell>Dominoes</cell><cell>Play with Pleo</cell></row><row><cell>Shape puzzle 2</cell><cell></cell><cell>Shape puzzle 1</cell><cell></cell><cell>Jigsaw puzzle 1</cell><cell></cell></row><row><cell>Shape puzzle 3</cell><cell></cell><cell>Shape puzzle 2</cell><cell></cell><cell>Jigsaw puzzle 2</cell><cell></cell></row><row><cell>Dominoes</cell><cell></cell><cell>Shape puzzle 3</cell><cell></cell><cell>Jigsaw puzzle 3</cell><cell></cell></row></table><note><p>FIGURE 1 | The animatronic pet robot, Pleo.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2 |</head><label>2</label><figDesc>Inter-rater reliability with a tolerance window of 3 s.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">COGNITIVE GAMES</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ROBOT PLAY</cell><cell></cell><cell></cell></row><row><cell>Behavior</cell><cell></cell><cell>Duration (%)</cell><cell></cell><cell cols="2">Reliability</cell><cell></cell><cell>Duration (%)</cell><cell></cell><cell cols="2">Reliability</cell></row><row><cell></cell><cell>Mean</cell><cell>Min</cell><cell>Max</cell><cell>Prop.</cell><cell>Kappa</cell><cell>Mean</cell><cell>Min</cell><cell>Max</cell><cell>Prop.</cell><cell>Kappa</cell></row><row><cell>GP</cell><cell>2.19</cell><cell>0.24</cell><cell>5.60</cell><cell>0.83</cell><cell>0.70</cell><cell>13.70</cell><cell>3.16</cell><cell>22.41</cell><cell>0.82</cell><cell>0.69</cell></row><row><cell>GFE</cell><cell>5.31</cell><cell>1.79</cell><cell>12.24</cell><cell>0.83</cell><cell>0.71</cell><cell>4.48</cell><cell>0.42</cell><cell>12.29</cell><cell>0.75</cell><cell>0.59</cell></row><row><cell>GG</cell><cell>88.46</cell><cell>81.86</cell><cell>92.19</cell><cell>0.87</cell><cell>0.78</cell><cell>73.30</cell><cell>59.26</cell><cell>96.16</cell><cell>0.81</cell><cell>0.70</cell></row><row><cell>NoneH</cell><cell>4.04</cell><cell>2.27</cell><cell>6.65</cell><cell>0.76</cell><cell>0.59</cell><cell>8.52</cell><cell>0.27</cell><cell>15.69</cell><cell>0.67</cell><cell>0.46</cell></row><row><cell>HEAD</cell><cell>100</cell><cell></cell><cell></cell><cell>0.81</cell><cell>0.76</cell><cell>100</cell><cell></cell><cell></cell><cell>0.76</cell><cell>0.70</cell></row><row><cell>LIP</cell><cell>0.03</cell><cell>0.00</cell><cell>0.23</cell><cell>-</cell><cell>-</cell><cell>0.42</cell><cell>0.00</cell><cell>3.48</cell><cell>-</cell><cell>-</cell></row><row><cell>NRLTG</cell><cell>58.96</cell><cell>10.58</cell><cell>100.00</cell><cell>0.87</cell><cell>0.76</cell><cell>41.67</cell><cell>6.80</cell><cell>100.00</cell><cell>0.81</cell><cell>0.71</cell></row><row><cell>NoneT</cell><cell>41.01</cell><cell>0.00</cell><cell>89.43</cell><cell>0.87</cell><cell>0.75</cell><cell>57.91</cell><cell>0.00</cell><cell>93.21</cell><cell>0.89</cell><cell>0.79</cell></row><row><cell>TORSO</cell><cell>100</cell><cell></cell><cell></cell><cell>0.87</cell><cell>0.74</cell><cell>100</cell><cell></cell><cell></cell><cell>0.82</cell><cell>0.73</cell></row><row><cell>RoP</cell><cell>0.67</cell><cell>0.00</cell><cell>2.89</cell><cell>-</cell><cell>-</cell><cell>0.41</cell><cell>0.00</cell><cell>1.31</cell><cell>-</cell><cell>-</cell></row><row><cell>RoFE</cell><cell>0.06</cell><cell>0.00</cell><cell>0.43</cell><cell>-</cell><cell>-</cell><cell>0.11</cell><cell>0.00</cell><cell>0.32</cell><cell>-</cell><cell>-</cell></row><row><cell>MG</cell><cell>64.13</cell><cell>49.94</cell><cell>75.97</cell><cell>0.77</cell><cell>0.59</cell><cell>45.03</cell><cell>6.49</cell><cell>84.33</cell><cell>0.80</cell><cell>0.70</cell></row><row><cell>SOApos</cell><cell>0.16</cell><cell>0.00</cell><cell>1.57</cell><cell>-</cell><cell>-</cell><cell>0.18</cell><cell>0.00</cell><cell>1.72</cell><cell>-</cell><cell>-</cell></row><row><cell>NoneAH</cell><cell>34.98</cell><cell>23.94</cell><cell>47.18</cell><cell>0.82</cell><cell>0.67</cell><cell>54.27</cell><cell>15.09</cell><cell>92.21</cell><cell>0.88</cell><cell>0.77</cell></row><row><cell>ARMS/HANDS</cell><cell>100</cell><cell></cell><cell></cell><cell>0.77</cell><cell>0.63</cell><cell>100</cell><cell></cell><cell></cell><cell>0.79</cell><cell>0.71</cell></row><row><cell>ELISCE</cell><cell>100</cell><cell></cell><cell></cell><cell>0.80</cell><cell>0.78</cell><cell>100</cell><cell></cell><cell></cell><cell>0.77</cell><cell>0.74</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3 |</head><label>3</label><figDesc>Data Reduction for SEM.</figDesc><table><row><cell>Variable name</cell><cell>Abbreviation</cell><cell>Data reduction</cell></row><row><cell>GAZE ACTIVITY</cell><cell>GAct</cell><cell>= (GP + GG) -(GFE + NoneH)</cell></row><row><cell>LEAN TOWARD ACTIVITY</cell><cell>LTAct</cell><cell>= (LIP + NRLTG) -(NoneT)</cell></row><row><cell>REACH OUT ACTIVITY</cell><cell>RoAct</cell><cell>= (RoP + MG) -(RoFE + NoneAH)</cell></row><row><cell>GAZE ACTIVITY (gestural support)</cell><cell>GAct_gsup</cell><cell>= (GP_pos + GG_pos) -(GP_neg + GG_neg)</cell></row><row><cell>LEAN TOWARD ACTIVITY (postural support)</cell><cell>LTAct_postsup</cell><cell>= (LIP_pos + NRLTG_pos) -(LIP_neg + NRLTG_neg)</cell></row><row><cell>REACH OUT ACTIVITY (quality of gesture)</cell><cell>RoAct_qogest</cell><cell>= (RoP_pos + MG_pos + SOA_pos) -(RoP_neg + MG_neg + SOA_neg)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 4 |</head><label>4</label><figDesc>Path estimates of the evidence-based model of engagement-related behavior.</figDesc><table><row><cell></cell><cell>Hypothesized path</cell><cell>Estimate</cell><cell>S.E.</cell><cell>C.R.</cell><cell>p</cell><cell>Hypothesis supported</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes/no</cell></row><row><cell>H2</cell><cell>GAct → LTAct</cell><cell>0.372</cell><cell>0.680</cell><cell>3.499</cell><cell>*** &lt; 0.001</cell><cell>Yes</cell></row><row><cell>H3</cell><cell>LTAct → RoAct</cell><cell>0.122</cell><cell>0.060</cell><cell>1.079</cell><cell>&gt; 0.05</cell><cell>No</cell></row><row><cell>H4</cell><cell>GAct → RoAct</cell><cell>0.349</cell><cell>0.386</cell><cell>3.099</cell><cell>** &lt; 0.01</cell><cell>Yes</cell></row><row><cell>H5</cell><cell>GAct → GAct_gsup</cell><cell>0.240</cell><cell>0.099</cell><cell>2.159</cell><cell>* &lt; 0.05</cell><cell>Yes</cell></row><row><cell>H6</cell><cell>RoAct → RoAct_qogest</cell><cell>-0.255</cell><cell>0.017</cell><cell>-5.998</cell><cell>*** &lt; 0.001</cell><cell>Yes</cell></row><row><cell>H7</cell><cell>GAct_gsup → LTAct_postsup</cell><cell>0.390</cell><cell>0.106</cell><cell>3.750</cell><cell>*** &lt; 0.001</cell><cell>Yes</cell></row><row><cell>H8</cell><cell>LTAct_postsup → RoAct_qogest</cell><cell>0.845</cell><cell>0.068</cell><cell>18.563</cell><cell>*** &lt; 0.001</cell><cell>Yes</cell></row><row><cell>H9</cell><cell>GAct_gsup → RoAct_qogest</cell><cell>0.112</cell><cell>0.069</cell><cell>2.444</cell><cell>* &lt; 0.05</cell><cell>Yes</cell></row><row><cell>H10</cell><cell>LTAct → LTAct_postsup</cell><cell>-0.218</cell><cell>0.015</cell><cell>-2.102</cell><cell>* &lt; 0.05</cell><cell>Yes</cell></row></table><note><p>Significance level: *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Frontiers in Psychology | www.frontiersin.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>May 2018 | Volume 9 | Article 690</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2"><p>Note that we used the term coding system, instead of coding scheme. A coding scheme is a portion of an ethogram. A coding system is an organization of the behaviors in the ethogram.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_3"><p>As the LMA framework provides a holistic approach to movement, we would like to emphasize that the focus on the category shape did not entail an abandon of the other categories.Frontiers in Psychology | www.frontiersin.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>As a side note, we would like to inform the reader that from now on we will use the term micro-behaviors to refer to the low-level action-movement-oriented behaviors in the ethograms. Instead, we will speak about behaviors to refer to the clusters of micro-behaviors in the coding system.Frontiers in Psychology | www.frontiersin.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>From this moment of the paper on we will use the term variable instead of behavior and we will use the variables' names detailed in Table3.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>ACKNOWLEDGMENTS</head><p>We would like to thank the nursing homes <rs type="grantName">Redós de Sant Josep i Sant Pere</rs> (<rs type="affiliation">Sant Pere de Ribes, Barcelona</rs>) and <rs type="person">La Mallola</rs> (<rs type="affiliation">Esplugues de Llobregat, Barcelona</rs>) for the precious help during data collection. In particular, <rs type="person">Anna Barea</rs>, <rs type="person">Laia Aranda</rs>, <rs type="person">Elizabeth Seguer</rs>, and <rs type="person">Neus Sanchez</rs>. We also would like to thank <rs type="person">Yuan Feng</rs>, <rs type="person">Kyra Frederiks</rs>, and <rs type="funder">Toke van Telgen</rs>. A special thanks goes to Ruud van Reijmersdal for the hand-drawn illustrations.</p></div>
			</div>
			<div type="funding">
<div><p>Understanding Engagement in Dementia Through Behavior. The <rs type="funder">Ethographic and Laban-Inspired Coding System of Engagement (ELICSE)</rs> and the <rs type="funder">Evidence-Based Model of Engagement-Related Behavior (EMODEB)</rs>.</p></div>
			</div>
			<div type="funding">
<div><head>FUNDING</head><p>This work was supported in part by the <rs type="funder">Erasmus Mundus Joint Doctorate (EMJD) in Interactive and Cognitive Environments (ICE)</rs>, which is funded by <rs type="funder">Erasmus Mundus</rs> under the <rs type="institution">FPA</rs> no <rs type="grantNumber">2010-2012</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fC9ujxv">
					<orgName type="grant-name">Redós de Sant Josep i Sant Pere</orgName>
				</org>
				<org type="funding" xml:id="_ppAztYe">
					<idno type="grant-number">2010-2012</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR CONTRIBUTIONS</head><p>GP contributed to the conception, design, data collection, analysis and interpretation of the study; RvB contributed to the analysis and interpretation of the study; MD-B, AC-M, EB, and MR supervised the conception, design, data collection, analysis and interpretation of the study; GP wrote the paper; RvB contributed to the writing and critical revision of the paper; MD-B, AC-M, MR, and EB: critically reviewed the paper and gave the final approval of the version submitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY MATERIAL</head><p>The Supplementary Material for this article can be found online at: <ref type="url" target="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00690/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fpsyg. 2018.00690/full#supplementary-material</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest Statement:</head><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards a science of user engagement (position paper)</title>
		<author>
			<persName><forename type="first">S</forename><surname>Attfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kazai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lalmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Piwowarski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM Workshop on User Modelling for Web Applications</title>
		<meeting><address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Applying observational methods: A systematic view</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bakeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gottman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Infant Development</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Osofsky</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1987">1987</date>
			<biblScope unit="page" from="818" to="854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Body Movement</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bartenieff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Routledge</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Socially Assistive Robots in elderly care: a systematic review into effects and effectiveness</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bemelmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Gelderblom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jonker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>De Witte</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jamda.2010.10.002</idno>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Direct. Assoc</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="114" to="120" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The MINWii project: renarcissization of patients suffering from Alzheimer&apos;s disease through video game-based music therapy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Benveniste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jouvelot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Péquignot</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.entcom.2011.12.004</idno>
	</analytic>
	<monogr>
		<title level="j">Enter. Comp</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="111" to="120" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Bradley</surname></persName>
		</author>
		<title level="m">Rudolf Laban</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enriching opportunities for people living with dementia in nursing homes: an evaluation of a multi-level activity-based model of care</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Brooker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Woolley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1080/13607860600963679</idno>
	</analytic>
	<monogr>
		<title level="j">Aging Mental Health</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="361" to="370" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A grounded investigation of game immersion</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cairns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI&apos;04 Extended Abstracts on Human Factors in Computing Systems</title>
		<meeting><address><addrLine>Vienna</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="1297" to="1300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The Attitude Theory of Emotion</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951">1951</date>
			<publisher>Nervous and Mental Disease Monographs</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recognizing emotion from dance movement: comparison of spectator recognition and automated techniques</title>
		<author>
			<persName><forename type="first">A</forename><surname>Camurri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lagerlöf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Volpe</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1071-5819(03)00050-8</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Hum. Comp. Stud</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="213" to="225" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting user engagement with a robot companion using task and social interaction-based features</title>
		<author>
			<persName><forename type="first">G</forename><surname>Castellano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Leite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Mcowan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 International Conference on Multimodal Interfaces</title>
		<meeting>the 2009 International Conference on Multimodal Interfaces<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="119" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1177/001316446002000104</idno>
	</analytic>
	<monogr>
		<title level="j">Educ. Psychol. Measur</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960">1960</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Engagement in persons with dementia: the concept and its measurement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen-Mansfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dakheel-Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marx</surname></persName>
		</author>
		<idno type="DOI">10.1097/JGP.0b013e31818f3a52</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Geriatr. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="299" to="307" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The comprehensive process model of engagement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen-Mansfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Murad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Regier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thein</surname></persName>
		</author>
		<idno type="DOI">10.1097/JGP.0b013e318202bf5b</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Geriatr. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="859" to="870" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>b013e318 202bf5b</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The impact of past and present preferences on stimulus engagement in nursing home residents with dementia</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen-Mansfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Thein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dakheel-Ali</surname></persName>
		</author>
		<idno type="DOI">10.1080/13607860902845574</idno>
	</analytic>
	<monogr>
		<title level="j">Aging Mental Health</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="67" to="73" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effects of a motor and multisensory-based approach on residents with moderateto-severe dementia</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sousa</surname></persName>
		</author>
		<idno type="DOI">10.1177/1533317511411177</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Alzheimers Dis. Other Dement</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="282" to="289" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Validity and reliability of the experience-sampling method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Csikszentmihalyi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Larson</surname></persName>
		</author>
		<idno type="DOI">10.1097/00005053-198709000-00004</idno>
	</analytic>
	<monogr>
		<title level="j">J. Nervous Mental Dis</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="page" from="526" to="536" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Body Action and Posture Coding System (BAP): development and reliability</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mortillaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10919-012-0130-0</idno>
	</analytic>
	<monogr>
		<title level="j">J. Nonverbal Behav</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="97" to="121" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A quantitative technique for analysing robot-human interactions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Werry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Systems</title>
		<meeting><address><addrLine>Lausanne</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002">2002. 2002</date>
			<biblScope unit="page" from="1132" to="1138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Socially assistive robotics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Feil-Seifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mataric</surname></persName>
		</author>
		<idno type="DOI">10.1109/MRA.2010.940150</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Magaz</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="24" to="31" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><surname>Fleiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Methods for Rates and Proportions</title>
		<title level="s">Wiley Series in Probability and Statistics</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Making Connections: Total Body Integration through Bartenieff Fundamentals</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hackney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Routledge</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Assessing engagement in people with dementia: a new approach to assessment using video analysis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Moyle</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.apnu.2015.06.019</idno>
	</analytic>
	<monogr>
		<title level="j">Arch. Psychiat. Nurs</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="377" to="382" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Group activity with Paro in nursing homes: systematic investigation of behaviors in participants</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jøranson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rokstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Aamodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ihlebaek</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1041610216000120</idno>
	</analytic>
	<monogr>
		<title level="j">Int. Psychogeriatr</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1345" to="1354" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Use of montessori-based activities for clients with dementia in adult day care: effects on engagement</title>
		<author>
			<persName><forename type="first">K</forename><surname>Judge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Camp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Orsulic-Jeras</surname></persName>
		</author>
		<idno type="DOI">10.1177/153331750001500105</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Alzheimers Dis. Other Dement</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="42" to="46" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Speech and language impairments in dementia</title>
		<author>
			<persName><forename type="first">B</forename><surname>Klimova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kuca</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jab.2016.02.002</idno>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Biomed</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="97" to="103" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Factors that relate to activity engagement in nursing home residents</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kolanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Buettner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Litaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1177/153331750602100109</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Alzheimers Dis. Other Dement</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="15" to="22" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Assessing patterns of agitation in Alzheimer&apos;s disease patients with the cohen-mansfield agitation inventory</title>
		<author>
			<persName><forename type="first">E</forename><surname>Koss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ernesto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen-Mansfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Ferris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grundman</surname></persName>
		</author>
		<idno type="DOI">10.1097/00002093-199700112-00007</idno>
	</analytic>
	<monogr>
		<title level="j">Alzheimer Dis. Assoc. Dis</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="45" to="50" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Laban</surname></persName>
		</author>
		<title level="m">Choreutics. Alton: Dance</title>
		<imprint>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Posture and Gesture. An Introduction to the Study of Physical Behaviour</title>
		<author>
			<persName><forename type="first">W</forename><surname>Lamb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965">1965</date>
			<publisher>Gerald Duckworth &amp; Co</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Observed affect in nursing home residents with Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Lawton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Van Haitsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klapper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Gerontol. Ser. B Psychol. Sci. Soc. Sci</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="3" to="P14" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Communicating emotions and mental states to robots in a real-time parallel framework using Laban movement analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lourens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Berkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barakova</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.robot.2010.08.006</idno>
	</analytic>
	<monogr>
		<title level="j">Robot. Autonom. Syst</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1256" to="1265" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Social interactions between people with dementia: pilot evaluation of an observational instrument in a nursing home</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Mabire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vrignaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Garitte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vernooij-Dassen</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1041610215002483</idno>
	</analytic>
	<monogr>
		<title level="j">Int. Psychoger</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1005" to="1015" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Body -Space -Expression. The Development of Rudolf Laban&apos;s Movement and Dance Concepts</title>
		<author>
			<persName><forename type="first">V</forename><surname>Maletic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Mouton de Gruyter</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Use of social commitment robots in the care of elderly people with dementia: a literature review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mordoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Osterreicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Thompson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.maturitas.2012.10.015</idno>
	</analytic>
	<monogr>
		<title level="j">Maturitas</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="14" to="20" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Effect of an interactive therapeutic robotic animal on engagement, mood states, agitation and psychotropic drug use in people with dementia: a cluster-randomised controlled trial protocol</title>
		<author>
			<persName><forename type="first">W</forename><surname>Moyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Draper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thalib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmjopen-2015-009097</idno>
	</analytic>
	<monogr>
		<title level="j">BMJ Open</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9097</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Exploring the effect of companion robots on emotional expression in older adults with dementia: a pilot randomized controlled trial</title>
		<author>
			<persName><forename type="first">W</forename><surname>Moyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cook</surname></persName>
		</author>
		<idno type="DOI">10.3928/00989134-20130313-03</idno>
	</analytic>
	<monogr>
		<title level="j">J. Gerontol. Nurs</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="46" to="53" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Affordance, conventions, and design</title>
		<author>
			<persName><forename type="first">D</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.1145/301153.301168</idno>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="38" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">What is user engagement? A conceptual framework for defining user engagement with technology</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Toms</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.20801</idno>
	</analytic>
	<monogr>
		<title level="j">J. Assoc. Inform. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="938" to="955" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Engagement in elderly persons with dementia attending animal-assisted group activity</title>
		<author>
			<persName><forename type="first">C</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bergland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Enders-Slegers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ihlebaek</surname></persName>
		</author>
		<idno type="DOI">10.1177/1471301216667320</idno>
	</analytic>
	<monogr>
		<title level="j">Dementia</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Epub ahead of print</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modelling engagement in dementia through behaviour. Contribution for socially interactive robotics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Perugia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Díaz Boladeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Català Mallofré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rauterberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barakova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rehabilitation Robotics (ICORR), International Conference on</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1112" to="1117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Quantity of movement as a measure of engagement for dementia: the influence of motivational disorders</title>
		<author>
			<persName><forename type="first">G</forename><surname>Perugia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rodríguez-Martín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Boladeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Mallofré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barakova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rauterberg</surname></persName>
		</author>
		<idno type="DOI">10.1177/1533317517739700</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Alzheimers Dis. Other Demen</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="112" to="121" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Electrodermal activity: explorations in the psychophysiology of engagement with social robots in dementia</title>
		<author>
			<persName><forename type="first">G</forename><surname>Perugia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rodríguez-Martín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Díaz Boladeras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Català Mallofré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barakova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rauterberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot and Human Interactive Communication (RO-MAN) International Symposium on</title>
		<meeting><address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="1248" to="1254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An exploration of user engagement in HCI</title>
		<author>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Castellano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Affective-Aware Virtual Agents and Social Robots</title>
		<meeting>the International Workshop on Affective-Aware Virtual Agents and Social Robots<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Attitudes and opinions of older adults toward socially assistive robots</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boulay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jouen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rigaud</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnagi.2015.00141</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Aging Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">141</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Are we ready for robots that care for us?</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Dance Words</title>
		<author>
			<persName><forename type="first">V</forename><surname>Preston-Dunlop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Taylor &amp; Francis</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Empirical evaluation of the global deterioration scale for staging Alzheimer&apos;s disease</title>
		<author>
			<persName><forename type="first">H</forename><surname>Reisberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Ferris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Sclan</surname></persName>
		</author>
		<idno type="DOI">10.1176/ajp.150.4.680-a</idno>
	</analytic>
	<monogr>
		<title level="j">Am. J. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="680" to="682" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The psychosocial effects of a companion Robot: a randomized controlled trial</title>
		<author>
			<persName><forename type="first">H</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kerse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Broadbent</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jamda.2013.02.007</idno>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Direct. Assoc</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="661" to="667" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Affective and engagement issues in the conception and assessment of a Robot-Assisted psychomotor therapy for persons with dementia</title>
		<author>
			<persName><forename type="first">N</forename><surname>Rouaix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Retru-Chavastel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rigaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Monnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lenoir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pino</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2017.00950</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">950</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">PARO robot affects diverse interaction modalities in group sensory therapy for older adults with dementia</title>
		<author>
			<persName><forename type="first">S</forename><surname>Šabanović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on 2013</title>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>in Rehabilitation Robotics (ICORR</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Emotion regulation through movement: unique sets of movement characteristics are associated with and enhance basic emotions</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shafir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Tsachor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">B</forename><surname>Welch</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2015.02030</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">2030</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Emotion and movement. A beginning empiricalphenomenological analysis of their relationship</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sheets-Johnstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consc. Stud</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="259" to="277" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Explorations in engagement for humans and robots</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Sidner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Kidd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rich</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2005.03.005</idno>
	</analytic>
	<monogr>
		<title level="j">Artif. Intel</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="140" to="164" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Comparison of verbal and emotional responses of elderly people with mild/moderate dementia and those with severe dementia in responses to seal Robot</title>
		<author>
			<persName><forename type="first">K</forename><surname>Takayanagi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kirita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shibata</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnagi.2014.00257</idno>
	</analytic>
	<monogr>
		<title level="j">PARO. Front. Aging Neurosci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">257</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Language in dementia part I: A review</title>
		<author>
			<persName><forename type="first">I</forename><surname>Thompson</surname></persName>
		</author>
		<idno type="DOI">10.1002/gps.930020304</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Geriat. Psychiatry</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="145" to="161" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ethological research in clinical psychiatry: the study of nonverbal behavior during interviews</title>
		<author>
			<persName><forename type="first">A</forename><surname>Troisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Soler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Agüera-Ortiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Olazarán Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mendoza Rebolledo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pérez Muñoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rodríguez Pérez</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnagi.2015.00133</idno>
		<idno>doi: 10.3389/fnagi.2015.00133</idno>
	</analytic>
	<monogr>
		<title level="j">Neurosci. Biobehav. Rev</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">133</biblScope>
			<date type="published" when="1999">1999. 2015</date>
		</imprint>
	</monogr>
	<note>Front. Aging Neurosci</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Concordancia entre el miniexamen cognoscitivo y el mini-mental state examination en el cribado del déficit cognitivo</title>
		<author>
			<persName><forename type="first">E</forename><surname>Vinyoles Bargalló</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vila Domènech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Argimon Pallàs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Espinàs Boquet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Abos Pueyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Limón</forename><surname>Ramírez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<idno type="DOI">10.1016/S0212-6567(02)78956-7</idno>
	</analytic>
	<monogr>
		<title level="j">Aten. Primar</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5" to="13" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Development and preliminary evaluation of a caregiver&apos;s manual for robot therapy using the therapeutic seal robot Paro</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Uehara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot and Human Interactive Communication</title>
		<meeting><address><addrLine>RO-MAN; Viareggio</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="533" to="538" />
		</imprint>
	</monogr>
	<note>International Symposium on 2010</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Social and physiological influences of robot therapy in a care house</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shibata</surname></persName>
		</author>
		<idno type="DOI">10.1075/is.9.2.06wad</idno>
	</analytic>
	<monogr>
		<title level="j">Int. Stud</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="258" to="276" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>wad</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Moving design: to design emotion through movement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Weerdesteijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Desmet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gielen</surname></persName>
		</author>
		<idno type="DOI">10.2752/146069205789338324</idno>
	</analytic>
	<monogr>
		<title level="j">Design J</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="28" to="40" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Moving About. Capturing Movement Highlights Using Motif Notation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cook</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Charlotte Wile Publisher</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">The Game Experience Questionnaire: Development of a Self-Report Measure to Assess Player Experiences of Digital Games</title>
		<author>
			<persName><forename type="first">W</forename><surname>Ijsselsteijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Poels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>De Kort</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Eindhoven</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
