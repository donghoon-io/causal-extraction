<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimating statistical power for structural equation models in developmental cognitive science: A tutorial in R</title>
				<funder ref="#_54DXk2S #_Ew75Gk8">
					<orgName type="full">Jacobs Foundation</orgName>
				</funder>
				<funder ref="#_7vFA2NY">
					<orgName type="full">Max Planck Dahlem Campus of Cognition</orgName>
					<orgName type="abbreviated">MPDCC</orgName>
				</funder>
				<funder>
					<orgName type="full">International Max Planck Research School</orgName>
				</funder>
				<funder ref="#_tcDCWw7">
					<orgName type="full">German Research Foundation</orgName>
				</funder>
				<funder ref="#_uSX4qGa">
					<orgName type="full">International Max Planck Research School on Computational Methods in Psychiatry and Ageing Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-05-28">28 May 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Elisa</forename><forename type="middle">S</forename><surname>Buchberger</surname></persName>
							<email>buchberger@mpib-berlin.mpg.de</email>
							<idno type="ORCID">0000-0001-5377-9722</idno>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Lifespan Psychology</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Human Development</orgName>
								<address>
									<addrLine>Lentzeallee 94</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chi</forename><forename type="middle">T</forename><surname>Ngo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Lifespan Psychology</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Human Development</orgName>
								<address>
									<addrLine>Lentzeallee 94</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aaron</forename><surname>Peikert</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Lifespan Psychology</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Human Development</orgName>
								<address>
									<addrLine>Lentzeallee 94</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Max Planck</orgName>
								<orgName type="institution">UCL Centre for Computational Psychiatry and Ageing Research</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Imaging Neuroscience</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Lifespan Psychology</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Human Development</orgName>
								<address>
									<addrLine>Lentzeallee 94</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Max Planck</orgName>
								<orgName type="institution">UCL Centre for Computational Psychiatry and Ageing Research</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">MSB Medical School Berlin</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Markus</forename><surname>Werkle-Bergner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Lifespan Psychology</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Human Development</orgName>
								<address>
									<addrLine>Lentzeallee 94</addrLine>
									<postCode>14195</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Markus</forename><surname>Werkle</surname></persName>
						</author>
						<title level="a" type="main">Estimating statistical power for structural equation models in developmental cognitive science: A tutorial in R</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-05-28">28 May 2024</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3758/s13428-024-02396-2</idno>
					<note type="submission">Accepted: 6 March 2024 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T20:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Determining the compositional structure and dimensionality of psychological constructs lies at the heart of many research questions in developmental science. Structural equation modeling (SEM) provides a versatile framework for formalizing and estimating the relationships among multiple latent constructs. While the flexibility of SEM can accommodate many complex assumptions on the underlying structure of psychological constructs, it makes a priori estimation of statistical power and required sample size challenging. This difficulty is magnified when comparing non-nested SEMs, which prevents the use of traditional likelihood-ratio tests. Sample size estimates for SEM model fit comparisons typically rely on generic rules of thumb. Such heuristics can be misleading because statistical power in SEM depends on a variety of model properties. Here, we demonstrate a Monte Carlo simulation approach for estimating a priori statistical power for model selection when comparing non-nested models in an SEM framework. We provide a step-by-step guide to this approach based on an example from our memory development research in children.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Over the past decades, many psychological constructs that had originally been conceptualized as unitary entities have been shown to be multifactorial phenomena. A prominent example are the early debates about component factors of intelligence <ref type="bibr" target="#b15">(Cattell, 1971;</ref><ref type="bibr" target="#b24">Horn, 1970</ref><ref type="bibr" target="#b25">Horn, , 1978) )</ref> or personality <ref type="bibr" target="#b37">(McCrae &amp; Costa, 1985)</ref>. However, also more specialized cognitive abilities such as executive functions <ref type="bibr">(Hedden &amp; Sedlmeier &amp; Gigerenzer, 1989;</ref><ref type="bibr" target="#b65">Vankov, Bowers, &amp; Munafó, 2014)</ref>. However, determining required sample size in an SEM approach is far from trivial. While the investigation of target effects in SEM can be achieved via analytical computations <ref type="bibr" target="#b55">(Satorra &amp; Saris, 1985)</ref>, tackling more complex research questions that rely on the comparison of non-nested models poses a challenge in determining sufficient sample sizes.</p><p>In this study, we implemented a Monte Carlo-based simulation approach and provide a step-by-step guide for conducting randomization-based analyses for a priori sample size estimations for non-nested model comparison. Specifically, we exemplify this approach with a specific research question, focusing on the componential structure of memory processes in early childhood (for theoretical background see <ref type="bibr">Buchberger, Brandmaier, Lindenberger, Werkle-Bergner, &amp; Ngo, in press)</ref>. Memory developmental research represents an excellent example for this methodological approach, as researchers from different fields have put forth competing ideas on the underlying structure of memory in childhood: While a rich body of empirical work from many decades has focused on the dichotomy between episodic and semantic memory <ref type="bibr" target="#b64">(Tulving, 1972)</ref>, more recent neurocomputational theories have introduced a process-focused approach to memory development. Tenets from contemporary memory models invite the hypothesis that three kinds of neurocomputations may complementarily support adaptive memory functioning, thereby assuming a tri-partite structure of memory <ref type="bibr" target="#b36">(McClelland et al., 1995;</ref><ref type="bibr" target="#b46">Norman &amp; O'Reilly, 2003;</ref><ref type="bibr" target="#b56">Schapiro et al., 2017)</ref>. Such competing theories on the underlying structure of memory can be addressed via model comparisons in an SEM framework. In this tutorial, we address two overarching issues that affect estimates of statistical power for such comparisons: (i) the separability of the theoretical constructs and (ii) the reliability with which the constructs are being measured. We employ this example to demonstrate the procedure and the utility of such methods, with the aim of illustrating a transferable approach to other research questions in different domains and disciplines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SEM in developmental cognitive neuroscience</head><p>SEM uses information about the relationship between multiple measured variables to uncover the structure of unobservable constructs, rendering this methodological framework a powerful tool in the field of developmental cognitive neuroscience (e.g., <ref type="bibr" target="#b2">Baltes et al., 1988;</ref><ref type="bibr" target="#b30">Kievit et al., 2018)</ref>. Most notably, it enables the translation from theories to testable mathematical models that can simultaneously include numerous observable indicators and multiple latent constructs of interest (such as behavioral constructs and neural correlates). Thus, it allows simultaneous modeling of the relation-ships among theoretical constructs and their co-development across different developmental windows.</p><p>In an SEM framework, theoretical constructs of interest are operationalized as latent variables that capture the underlying commonalities across a set of (measured) manifest variables. Manifest variables can directly be observed (such as items in a questionnaire or indices derived from a behavioral task) and are commonly illustrated as squares in graphical depictions of SEM. Latent variables represent hypothetical constructs that are not directly observable (such as a latent factor of intelligence or memory), but are inferred from a selection of manifest variables. In graphical depictions of SEM, latent variables are commonly shown as circles. The strength of a loading, that is, a path from a latent variable to an observed variable, represents the extent to which the observed variance is accounted for by the latent factor. In other words, the loading indicates how well a given manifest variable captures the latent construct.</p><p>The relationship among manifest and latent variables can be described in a mathematical model, which specifies all assumed parameters. Two models M1 and M2 are referred to as nested, if the parameter space in a more restrictive model M2 represents a subspace of the parameter space of the more general model M1 <ref type="bibr" target="#b4">(Bentler &amp; Bonett, 1980)</ref>. This means that the two models only differ with regards to the specification of one or multiple parameters. Nesting of models is usually achieved via constraining free parameters from M1 to equality or to known constants. The concept of nesting represents a convenient characteristic when comparing competing models, as it allows the use of a likelihood-ratio test to evaluate their relative model fits <ref type="bibr" target="#b55">(Satorra &amp; Saris, 1985)</ref>. When comparing non-nested models, researchers usually revert to the comparison of model fit indices that indicate how well a given model describes the data, such as the Bayesian information criterion (BIC, <ref type="bibr" target="#b51">Raftery, 1986;</ref><ref type="bibr" target="#b58">Schwarz, 1978)</ref>, the Akaike information criterion (AIC, <ref type="bibr" target="#b0">Akaike, 1974)</ref>, the root mean square error of approximation <ref type="bibr">(RMSEA, Steiger, 2016)</ref>, and the Comparative Fit Index (CFI, <ref type="bibr" target="#b3">Bentler, 1990</ref>, but see "Discussion and conclusion" for a discussion of recently proposed non-nested likelihood-ratio tests). Such indices can guide heuristic model selection, but do not allow for any statistical guarantees (e.g., a pre-specified type I error level).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical power in SEM</head><p>Over the past decades, the issue of low statistical power and its consequences for the interpretation of scientific findings has gained awareness in neurocognitive and psychological research <ref type="bibr" target="#b18">(Cohen, 1988;</ref><ref type="bibr" target="#b33">MacCallum &amp; Austin, 2000;</ref><ref type="bibr" target="#b35">Maxwell, 2004;</ref><ref type="bibr" target="#b54">Rossi, 1990)</ref>. Statistical power refers to the probability of rejecting a null hypothesis, when it is indeed false (i.e., the probability of not committing a type II error) and is directly linked to the sample size of a study, the magnitude of the targeted effect, and the reliability of measurement <ref type="bibr" target="#b10">(Brandmaier, Oertzen, Ghisletta, Lindenberger, &amp; Hertzog, 2018;</ref><ref type="bibr" target="#b18">Cohen, 1988)</ref>. While low statistical power decreases the scientific utility of any given study, it also decreases the likelihood that a given significant result actually reflects a true effect <ref type="bibr" target="#b13">(Button et al., 2013)</ref>. To allow well-designed empirical research to detect effects in the sample under investigation, a priori estimates of statistical power (that is computation of power estimates before conducting the study) and thus informed decisions on required sample size are crucial to prevent underpowered research <ref type="bibr" target="#b13">(Button et al., 2013)</ref>. While the desired level of statistical power can depend on specific aspects of the research question at hand, a typical convention for adequate power in the behavioral sciences is 0.8 <ref type="bibr" target="#b18">(Cohen, 1988)</ref>. However, others have argued that there is no reason to prefer type I errors over type II errors and thus one should better aim for a statistical power of 0.95, if the level of significance is kept at the conventional 5%. Note that, of course, considerations on statistical power and thus sample size estimates need to be balanced with the probability of committing type I errors, that is the probability to reject a null hypothesis if it is indeed true.</p><p>Various rules of thumb on required sample size in SEM have been recommended, including setting an absolute minimum of observations across the board <ref type="bibr" target="#b7">(Boomsma, 1985)</ref> and adjusting to the model complexity (i.e., setting a number of observations per estimated parameter, <ref type="bibr" target="#b5">Bentler &amp; Chou, 1987)</ref>. Unfortunately, such heuristics can be misleading, as statistical power in SEM is heavily influenced by parameters beyond the number of indicators per latent construct, e.g., the magnitude of factor loadings <ref type="bibr" target="#b68">(Wolf, Harrington, Clark, &amp; Miller, 2013)</ref>. Further, determining the required sample size for a given study depends on the research question. One common utility of SEM is to test whether a given effect in a model exceeds a specific threshold, such as testing whether the correlation of latent factors exceeds zero, or whether a specific parameter estimate differs between groups (i.e., target effect). Another common utility is to determine how well a given model describes the data, and/or whether one model describes the data better than a competing model <ref type="bibr">(i.e., model comparison)</ref>. These different research questions require different types of power: the power to detect a target effect vs. the power to detect model misspecification <ref type="bibr" target="#b67">(Wang &amp; Rhemtulla, 2021)</ref>. Further, theoretical assumptions on competing models can lead to the necessity to compare non-nested models, which prevents the use of traditional χ 2 -based power estimates and therefore requires alternative approaches to determining statistical power for SEM (see "Discussion and conclusion" for a more detailed discussion of recently proposed non-nested likelihood-ratio tests).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical power to detect a specific effect of interest</head><p>Central to many studies that employ SEM is the question of whether a specific parameter in a model (e.g., strength of a specific correlation or the slope parameter in a latent regression model) is different from a given value (e.g., <ref type="bibr" target="#b14">Canada, Hancock, &amp; Riggins, 2021)</ref>. Imagine that a researcher aims to test whether the correlation between two latent constructs significantly differs from zero. To this end, they would compare the model fit between one model in which the correlation parameter is freely estimated and another model in which it is fixed to zero <ref type="bibr" target="#b55">(Satorra &amp; Saris, 1985)</ref>. The corresponding null hypothesis in this case states that the parameter restrictions hold in the population. The difference in model fit will follow a χ 2 -distribution with degrees-of-freedom (df ) equal to the difference of freely estimated parameters between the two models, if the null hypothesis is true <ref type="bibr" target="#b45">(Neale, 2000, in this</ref> example df = 1, because only the correlation between the two latent factors is fixed in the restricted model). If restricting the parameter of interest results in a significantly poorer model fit, this would suggest that the respective parameter indeed significantly differs from zero.</p><p>Following the logic outlined above, researchers can determine the statistical power for detecting a target effect in an SEM framework before conducting the study. A key aspect for this a priori power calculation hinges on translating the differences in a specific parameter estimate into an effect size. Such translation can be achieved by investigating the discrepancy between the model-implied variance-covariance matrices associated with (1) the population model including the "true" parameter values and (2) the hypothesized model. The discrepancy between both matrices is quantified based on a specific fit function (for details on fit functions, see <ref type="bibr" target="#b6">Bollen, 1989)</ref>. As the investigation of a target effect practically translates into the comparison of nested models, researchers can in these cases analytically determine the statistical power and use this information for decisions on required sample size <ref type="bibr" target="#b55">(Satorra &amp; Saris, 1985)</ref>. Recently, several user-friendly tools have emerged that can guide modelers in deriving estimates for statistical power to estimate statistical power in SEM in such cases (e.g., the R packages semPower <ref type="bibr" target="#b28">Jobst, Bader, &amp; Moshagen, 2021</ref>; or power4SEM Jak, Jorgensen, Verdam, Oort, &amp; Elffers, 2020 for analytical approaches; and the Shiny app pwrSEM <ref type="bibr" target="#b67">Wang &amp; Rhemtulla, 2021</ref>; the interactive study planner tool <ref type="bibr">LIFESPAN Brandmaier, Oertzen, Ghisletta, Hertzog, &amp; Lindenberger, 2015;</ref><ref type="bibr"></ref> or the R package simsem <ref type="bibr" target="#b50">Pornprasertmanit, Miller, Schoemann, &amp; Jorgensen, 2021</ref> for simulation-based approaches).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical power for model comparison</head><p>A second question that is of interest for many researchers -especially in developmental cognitive neuroscience -pertains to identifying the one theoretical model (from a set of competing models) that best explains the given data <ref type="bibr" target="#b22">(Henson et al., 2016;</ref><ref type="bibr" target="#b41">Miller, Giesbrecht, Müller, McInerney, &amp; Kerns, 2012;</ref><ref type="bibr" target="#b47">Nyberg, 1994)</ref>. In the case of competing models that are nested, the analytical approach to this question (and therefore also considerations on statistical power) can be addressed analogously to the procedure outlined above (see <ref type="bibr" target="#b28">Jobst et al., 2021</ref> for a step-by step tutorial). However, comparing non-nested models prohibits the use of traditional χ 2 -based statistics and therefore poses additional methodological challenges in determining the 'best' model. Nevertheless, researchers should strive for a methodological approach that matches the theoretical assumptions, rather than vice versa, that is, moving away from wellgrounded theoretical considerations to meet methodological constraints. In cases where researchers aim to derive estimates of statistical power for non-nested model comparisons, randomization-based techniques offer an excellent alternative <ref type="bibr" target="#b19">(Efron &amp; Tibshirani, 1994)</ref>. In particular, Monte Carlo simulations have proven useful to bridging this gap <ref type="bibr" target="#b44">(Muthén &amp; Muthén, 2002</ref>, see "How does a simulation work: Power-estimations for the comparison of non-nested SEMs" for more details on Monte Carlo simulations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example: Competing models on the compositional structure of memory</head><p>For many decades, the compositional nature of memory in adults as well as its maturation across development has been of great interest in psychology, cognitive science, neuroscience, and artificial intelligence research. Different models on the compositional structure of memory have been heavily debated <ref type="bibr" target="#b36">(McClelland et al., 1995;</ref><ref type="bibr" target="#b46">Norman &amp; O'Reilly, 2003;</ref><ref type="bibr" target="#b56">Schapiro et al., 2017;</ref><ref type="bibr" target="#b64">Tulving, 1972)</ref>.</p><p>The most simplistic characterization of memory structure is to assume a unitary ability underlying different memory demands, akin to a g-factor of memory <ref type="bibr" target="#b60">(Spearman, 1904)</ref>. Such a unitary model of memory suggests no differentiation of component processes within declarative memory, but rather claims that the performance on various types of memory demands is grounded in a single ability factor.</p><p>An alternative prominent view is the classic dichotomy between episodic and semantic memory systems <ref type="bibr" target="#b61">(Squire, 1987;</ref><ref type="bibr" target="#b64">Tulving, 1972)</ref>. Such a bi-partite architecture of memory postulates a division between one component responsible for learning specific events embedded in their temporal and spatial context (episodic memory) and a second component responsible for learning regularities and extracting generalized knowledge (semantic memory). Previous research comparing a unitary vs. a bi-partite account of memory in an SEM framework has supported the idea of separable memory factors underlying declarative memory, at least in adults <ref type="bibr" target="#b47">(Nyberg, 1994)</ref>.</p><p>Adopting a process-oriented view, recent computational models of memory have argued for a functionalist distinction between memory specificity and generalization through a labor division between the hippocampus and the cortex <ref type="bibr" target="#b36">(McClelland et al., 1995;</ref><ref type="bibr" target="#b46">Norman &amp; O'Reilly, 2003)</ref>.</p><p>Here, a set of neurocomputations support different memory demands. Important to learning specific episodes are pattern separation that discriminates between similar memories through the reduction of representational similarity, and pattern completion that retrieves linked associations among co-occurring elements <ref type="bibr" target="#b34">(Marr, 1971;</ref><ref type="bibr" target="#b46">Norman &amp; O'Reilly, 2003;</ref><ref type="bibr" target="#b52">Rolls, 2016)</ref>. Both of these computations are thought to be specialties of the hippocampus. In contrast, the cortex is well suited to slowly learn statistical regularities that enables generalization <ref type="bibr" target="#b36">(McClelland et al., 1995;</ref><ref type="bibr" target="#b46">Norman &amp; O'Reilly, 2003)</ref>. Interestingly, rapid generalization also relies on the hippocampus, either via retrieval mechanisms of related episodes <ref type="bibr">(Kumaran &amp; McClelland, 2012)</ref> or via a distributed coding scheme carried by a specific subset of the hippocampal circuitry <ref type="bibr" target="#b56">(Schapiro et al., 2017)</ref>. From this vantage point, memory abilities take shape of a tripartite structure, encompassing pattern separation, pattern completion, and generalization as three separable mnemonic processes.</p><p>Which of these views best explains memory abilities across early development? This question requires adequate statistical methods that can adjudicate among multiple competing ideas on the underlying structure of memory. The simulation in the following section of this paper will address methodological challenges in study planning when aiming to compare three hypothetical models: a unitary model (Model 1), a bi-partite model (Model 2), and a tri-partite model (Model 3) on the compositional structure of memory (Fig. <ref type="figure" target="#fig_0">1</ref>). Specifically, we will focus on the issue of estimating statistical power for this model comparison. Here, we address the impact of two main aspects in particular: (i) the separability of the theoretical constructs, i.e., interrelatedness of the latent factors in the competing models and (ii) the reliability of the measures, i.e., the loadings of the manifest variables. Details on the theoretical basis and the selection of methodological indicators for each model can be found in <ref type="bibr">Buchberger et al. (in press</ref>). Important for this context is the fact that our specification of Models 2 and 3 results in a non-nested model comparison (due to the cross-loadings for the latent factors pattern separation and pattern completion and different allocation of the indicator Task 10). Therefore a priori estimations of statistical power for selecting the correct model call for a simulation-based approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>In the following, we demonstrate how to conduct a simulationbased power analysis for non-nested model comparisons.</p><p>Here, we refer to statistical power as the probability of correctly selecting a model given a selection of candidate models. In a hypothesis testing framework, the alternative hypothesis corresponds to a given model being the true model. Statistical power then reflects the correct selection rate of a model and the type I error corresponds to the probability of incorrectly selecting that model when one of the other candidates is the true model. For the sake of illustration, we will refer to the example on the compositional structure of memory outlined in "Example: Competing models on the compositional structure of memory" throughout. For this example, we aim to derive estimates of required sample size to identify the tri-partite model as the best-fitting model among the three competing models, if it indeed generated the data. In a step-by-step guide, we therefore show how to specify the competing models in R, how to set up different design conditions for the simulation, how to define the functions to generate, analyze, and summarize synthetic data and how to execute the simulation. Based on two separate simulations, we show how the separability of theoretical constructs ("What is the impact of the separability of theoretical models on estimates of statistical power?") and the reliability of the manifest variables ("What is the impact of the reliability of manifest variables on estimates of statistical power?") impacts estimates of statistical power for model comparisons by varying inter-factor correlations and factor loadings across different conditions of the simulation. Finally, we employ the same simulation-based approach to investigate type I error rates, that is erroneously identifying the tri-partite model as the best-fitting model if the bi-partite or unitary model generated the data ("How can simulations inform us about type I error rates?").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How does a simulation work: Power-estimations for the comparison of non-nested SEMs</head><p>To investigate statistical power for deciding between competing theoretical non-nested models, we suggest a Monte Carlo simulation-based approach <ref type="bibr" target="#b40">(Metropolis, Rosenbluth, Rosenbluth, Teller, &amp; Teller, 1953)</ref>. Monte Carlo studies represent a computer-intensive simulation, which allows to approximate statistical power for a given study design <ref type="bibr" target="#b44">(Muthén &amp; Muthén, 2002)</ref>. While Monte Carlo simulations can be implemented for a variety of research questions, the flexibility of the approach makes them especially well suited for obtaining a priori power estimates for the comparison of nonnested SEMs. Furthermore, analytical approaches are tied to assumptions (e.g., no missing data, multivariate normality), whereas simulation-based approaches allow for arbitrary data generating processes. In Monte Carlo studies, synthetic data are repeatedly generated with a set of different hypothesized parameter values and analyzed across all samples. Summary statistics from the entirety of the simulated datasets are then used to draw conclusions <ref type="bibr" target="#b44">(Muthén &amp; Muthén, 2002;</ref><ref type="bibr" target="#b48">Paxton, Curran, Bollen, Kirby, &amp; Chen, 2001</ref>). The general procedure of Monte Carlo simulations follows a common core structure: (i) generate -in which multiple synthetic datasets are generated based on the hypothesized models, (ii) analyze -in which the synthetic data are analyzed for every iteration of the simulation, (iii) summarize -in which the results are pooled over all simulation iterations. This general procedure is applicable to a variety of scenarios. When comparing competing SEMs, it is necessary to specify the competing theoretical models, and decide on the simulation design, that is which model parameters of interest should be modified across the simulations. Finally, researchers need to evaluate the results from the simulation in order to derive practical implications from the simulation (see Fig. <ref type="figure" target="#fig_1">2</ref>). While these steps can be manually coded in a statistical research software, such as R, the implementation of a simulation can become increasingly complex and error-prone with increasing number of conditions that are being simulated. A useful tool that can guide novice simulators in setting up a Monte Carlo simulation is the R package simDesign <ref type="bibr" target="#b16">(Chalmers &amp; Adkins, 2020)</ref>, which facilitates the implementation of the internal logic of generate -analyze -simulate and can accommodate various research designs. All simulation steps in this study were therefore implemented within the simDesign package.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step 1: Specifying competing SEMs</head><p>The first step of the simulation is translating the theoretical assumptions about latent constructs of interest and the manifest variables into an SEM. This step entails (a) specifying the number of latent factors (how many theoretical constructs are thought to influence the observed behavior in the manifest variables?), and (b) the allocation of each manifest variable to (at least one) latent variable (which of the manifest variables captures the respective latent construct?). In R, the structure of a SEM can be easily implemented using lavaan syntax <ref type="bibr" target="#b53">(Rosseel, 2012)</ref>. Typically, useful operators for specifying a model entail factor loadings (=~), (co-)variances (~~), and means or intercepts (~1). The tri-partite model (Fig. <ref type="figure" target="#fig_0">1</ref>, Model 3) could be specified in lavaan syntax as the following:</p><p>123 The model is defined by a model string, which specifies three latent factors of memory (Pattern Separation [ps]; Pattern Completion, [pc]; Generalization, [gen]) which are measured through the manifest variables (tasks 1 to 13). Note that lavaan entails several user-friendly functions for fitting models that automatically include default settings for model components that are not explicitly specified (e.g., adding residual variances, covariances of exogenous latent variables). Thus, the model syntax can be kept very concise (check documentation of the respective function for full information on default settings).</p><p>Estimating statistical power for model comparisons requires that researchers specify each of the competing models and all aspects in which they differ from one another (e.g., in number of latent factors, allocations of manifest variables; For specifications of Models 1 and 2, see supplementary R code on GitHub, <ref type="bibr" target="#b12">Buchberger, Ngo, Peikert, Brandmaier, &amp; Werkle-Bergner, 2024)</ref>.</p><p>Step 2: Simulation design When defining the structure of the theoretical model for data generation, it is crucial to specify all parameters in the model, particularly the loading strength of the manifest variables, along with the means and (co-)variances of the latent factors. This step also requires the specification of which parameter values should be kept constant or which should be modified across different simulation iterations. Parameters for which there are strong assumptions (e.g., derived from previous work) can be entered in the models and kept constant. Parameters for which the impact on statistical power is of interest should be included as a condition in the simulation design. For example, if the question pertains to how the reliability of the measures may impact the estimates of required sample size, different levels of loading strength can be included in the conditions for which data is being simulated. The createDesign() function of the simDesign package can be used to create a full list of conditions for the simulation. All parameters that should be varied in the simulation are included as arguments in the creat-eDesign() function. Full crossings of all possible values for the different parameters are then generated as conditions for the simulation. Note, however, that the number of simulation conditions and therefore the required computation time increases exponentially for full combinations of all simulation conditions. Researchers should thus be mindful about the number of conditions in a given simulation to avoid overly computationally intensive simulations, which can further be increasingly difficult to interpret. If only specific combinations of the parameters in the simulation are of interest for a given research question, the resulting design data frame can be adjusted accordingly, e.g., by deleting specific rows from the data frame. Below is our design data frame that includes different simulation conditions for (i) the loading strength of the manifest variables and (ii) the sample sizes: design_load_model3 &lt;-createDesign( loading_strength = seq(0.5, 0.9, 0.1), sample_size = seq(50, 200, 5),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># […] )</head><p>Here, the design for the Monte Carlo simulations consists of five loading strength conditions (i.e., 0.5 to 0.9 in increments of 0.1). The sample size is varied from 50 to 200 in increments of 5. In total, data for 155 conditions (5 × 31) are generated.</p><p>Step 3: Generate Next, we define the mechanism to generate the synthetic data. An easy way to generate synthetic data within an SEM framework in R is the simulateData() function available in the lavaan package <ref type="bibr" target="#b53">(Rosseel, 2012)</ref>. In the example on memory composition, we simulate multivariate normal data, as the indicators represent continuous values of task performance from the memory tasks. However, the simulation approach presented here can of course be extended to dichotomous or polytomous data for other use cases. Within the generate function, all parameters that are predetermined across iterations can be directly entered into the generating model syntax. However, all parameters that are supposed to be varied between different iterations of the simulation need to be accessed through the condition argument that is returned through the createDesign() function in step 2. It can be useful to examine the resulting datasets prior to running the simulation to assess whether the data generating mechanism returns realistic datasets (e.g., regarding the variability of the data, extreme values), to allow for refining the generate function accordingly (similar to prior predictive checks as often suggested in the context of Bayesian approaches, <ref type="bibr" target="#b20">Gelman et al., 2020)</ref>. Given our interests in the effect of loading strength and strength of covariance between the latent factors, we define these parameters in step 2 (Design) such that they can now be called via the condition argument in the generate function: Here, we define the generate function for the tripartite model. The factor loadings specified in step 2 (Design) are called from the condition argument such that they are varied across different iterations of the simulation, and are defined as "a" for syntax readability. For standardization purposes (that is, the total variance of each manifest variable summing up to 1), the loadings of indicators Task5 and Task6 are set to a √ (2+2•cov1) to account for cross-loadings on multiple factors and are defined as "b" to ease syntax readability (cov1 = covariance between the latent factors pattern separation and pattern completion). Both loading parameters a and b are stored in the list "parameters" such that they can be called via the glue_data function from the glue package <ref type="bibr" target="#b23">(Hester &amp; Bryan, 2022)</ref> to concatenate the model string. The residual variances of the manifest variables are set to 1a 2 for standardization purposes. The population model is defined by a model string, which specifies three latent factors (ps, pc, gen) measured by the 13 manifest indicators (ps: tasks 1 to 6, pc: tasks 5 to 9, gen: tasks 10 to 13), the residual variances as defined above and the covariance between the latent factors as defined in the condition argument. The data are simulated from the model syntax via the simulateData() function from the lavaan package <ref type="bibr" target="#b53">(Rosseel, 2012)</ref> and stored as "dat".</p><p>Note that the Monte Carlo simulation method does not limit researchers to the simulation of normally distributed data, but can be used with any form of data-generating mechanism. Further, the simulation-based approach allows researchers to anticipate and investigate the effects of (planned) missingness in the data on estimates for statistical power <ref type="bibr" target="#b8">(Brandmaier, 2020;</ref><ref type="bibr" target="#b57">Schoemann, Miller, Pornprasertmanit, &amp; Wu, 2014)</ref>. Here, different amounts and patterns of missingness can be entered into the simulation by removing data from the generated datasets. The resulting data can then be analyzed and summarized to investigate the effects of attrition, planned or random missingness on the estimates for statistical power. The implementation of these characteristics of the data is beyond the scope of this tutorial. However, in research scenarios in which violations of the normality assumption or missing data can be expected, researchers should consider a simulation-based approach to estimate statistical power, as the approach presented here is free from any assumptions on the data distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step 4: Analyze</head><p>In this step, we define the analyze function, which specifies how the data generated in step 3 should be analyzed. For the comparison of non-nested models, we rely on a combination of relative and absolute model fit parameters (for discussion of an alternative model selection approach, see "Discussion and conclusion"). We fit each of the competing models to each of the simulated data sets using the sem() function from the lavaan package <ref type="bibr" target="#b53">(Rosseel, 2012)</ref> with a maximum likelihood estimator and extract different measures of model fit using the helper function get_fitmeasures() (see funs.R in the supplementary material on GitHub, <ref type="bibr" target="#b12">Buchberger et al., 2024)</ref>, namely the Comparative Fit Index (CFI, <ref type="bibr" target="#b3">Bentler, 1990)</ref>, root mean square error of approximation (RMSEA, <ref type="bibr" target="#b62">Steiger, 2016)</ref> and the Bayesian information criterion (BIC, <ref type="bibr" target="#b51">Raftery, 1986)</ref>. The function returns the fit measures, the simulation model that was used in the respective iteration and information on model convergence. The analyze function for the example on memory composition could thus look like this: analyze_results &lt;function(condition, dat, fixed_objects = fixed_objects) { fits &lt;-map(fixed_objects, ~sem( ., dat, std.lv = TRUE)) ms &lt;-map(fits, get_fitmeasures) ret &lt;-list( fitmeasures = ms, sim_model = condition$sim_model, sample_size = condition$sample_size, loadingstrength = condition$ loading_strength, covariance = condition$cov1, converged = map_lgl( fits, is_converged) ) }</p><p>Step 5: Summarize</p><p>In step 5, we define how the results from the analyze step should be summarized. To this end, we extract how often the model used to generate the data (step 2) was actually recovered as the best-fitting model. We implemented the following decision rules for identifying the best-fitting model: (i) We define cut-off criteria for an adequate model fit according to established rules as CFI &gt; .95 and RMSEA &lt; 0.06 <ref type="bibr" target="#b26">(Hu &amp; Bentler, 1999)</ref>. (ii) Among the models that meet the cut-off criteria, we select the best-fitting model for each data set based on the relative model fit (lowest BIC value). The goal of (i) and (ii) is to check whether the ground truth model that generated the data can be identified as the best-fitting model in a given simulation run. For cases in which a given dataset does not converge for one of the models, we consider the outcome of these iterations as failing to recover the correct model. We summarize the proportion of successful model recovery for each combination of model parameters in the simulation separately. The summarize function that concatenates the results across simulation iterations for the example on the structure of memory in childhood could thus look like this: </p><formula xml:id="formula_0">summarize_results &lt;- function(condition</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>return(ret) }</head><p>First, the function restructures the results from the analyze function to obtain a tidy data frame with the fit measures for each model in a separate row. This data is then summarized for each iteration. The function identifies (a) the ground truth model that generated the data in this simulation iteration (sim_model) and (b) the model which produced the best model fit (best). Here, the best model is defined as "0" if one of the three theoretical models did not converge, or if none of the models met the cut-off criteria as defined above. Otherwise, the best model is selected among the ones that met the cut-off criteria based on the relative model fit. The function returns the argument best_3, indicating how often across all iterations Model 3 was identified as the best-fitting model, and best_sim, indicating how often the model that simulated the data was identified as the best-fitting model (note that in the current analysis, both values are identical. best_sim can however be useful to investigate type I error, see "How can simulations inform us about type I error rates?").</p><p>Step 6: Running and evaluating the simulation In a final step, we call the runSimulation() function from the simDesign package to execute the consecutive steps outlined above. Running the simulation for our example could look like this: In this function, the pre-defined functions generate_data(), analyze_results() and summarise_results() are called. The number of replications is specified in the replications argument. To ensure reasonable stability of the results, a sufficient number of replications is recommended. In our example, we simulated 1000 datasets per condition. This leads to a standard error of the simulated power of less than 0.5%. The store_results argument can be used to store the individual results generated by the summarize function, allowing users to investigate the outcome on every iteration (in this example, the data frame containing all fit measures and convergence information for each iteration). Note, however, that storing the individual results increases computation time and size of the resulting outcome arguments. The argument parallel can be used for parallel processing across multiple cores (e.g., when running the analysis on a computer cluster) to reduce computation time. If not specified otherwise, all available cores will be used per default when parallel = TRUE.</p><p>The output can then be used to examine power curves (see Fig. <ref type="figure">3</ref>) for each of the parameters of interest in the simulation. Power curves are line plots that depict how changing one variable (e.g., sample size) would affect the power of the test. In the example, we can plot power curves demonstrating the impact of the separability of the theoretical constructs, implemented as the strength of the covariance between the latent factors, or the impact of the reliability of the measures, implemented as the strength of the loadings, on power estimation. Importantly, these data reveal the relative importance of different model parameters on sample size requirements. To obtain easily readable outputs, we plot the sample size from the simulation (x-axis) against the frequency with which the data-generating model was correctly recovered as the bestfitting model (y-axis). To derive estimates on the required sample size in the example presented here, we aimed for a power of 95% in recovering the ground truth model as the best-fitting model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results: Statistical power estimates for investigating the compositional structure of memory</head><p>What is the impact of the separability of theoretical models on estimates of statistical power?</p><p>In the example of comparing competing models of memory structure, we first examined the separability of the theoretical models by investigating the influence of the latent factors' correlations on statistical power estimates. In our example simulation, we investigated the statistical power to retrieve Model 3 as the best-fitting model, when it indeed generated the data, while varying sample sizes from 50 to 200 and factor inter-correlations from 0.1 to 0.9. In this case, we restricted the simulated correlations between the latent factors to positive values, as there is no indication in the literature to suspect a negative relation among these memory capacities (e.g., Tucker-Drob, <ref type="bibr" target="#b63">Brandmaier, &amp; Lindenberger, 2019)</ref>. Figure <ref type="figure">3A</ref> displays the obtained power curves illustrating the estimated statistical power dependent on the total sample size and the factor inter-correlation. For this estimate, the loading of the manifest variables was fixed at 0.7 and the inter-correlation between all latent factors were varied simultaneously.</p><p>As expected, statistical power increased with increasing sample size. However, the separability of the latent factors mattered: The higher the correlations between factors, the less able we were to distinguish multi-factor models from a one-factor model. That is, the smaller the difference between competing models, the greater the sample size that would be Fig. <ref type="figure">3</ref> Simulation results: Estimated statistical power for correctly selecting the data-generating model, i.e., Model 3 (y-axis) as a function of sample size (x-axis) with varying the factor inter-correlations when the loading strength was fixed to 0.7 (A) ; and with varying the loading strength when the factor inter-correlation was fixed to 0.3 (B).</p><p>For each combination of parameters, 1000 datasets were simulated. The red dashed horizontal line positioned at 95% discovery rate reflects the cut-off for identifying the appropriate sample size. The syntax to generate these plots with ggplot() can be found in the supplementary R Code on GitHub required to dissociate between them with adequate power. For very high levels of inter-correlation (0.8 and higher) the increase of statistical power with increasing sample size was remarkably lower than for lower levels of inter-correlation (0.7 and below). When the inter-factor correlation was 0.9, not even a larger sample size (N =200) achieved an adequate level of power of 80%. These results are not surprising given that increasing the inter-correlations between the latent factors renders the models more similar to each other or -in the case of correlations approaching 1 -identical, making their distinction impossible. For moderate levels of intercorrelation (&lt;= 0.7) a statistical power of 95% was reached for N = 125.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What is the impact of the reliability of manifest variables on estimates of statistical power?</head><p>In a second step, we further examined the effect of the construct reliability on statistical power by investigating the loading strength of the manifest variables. To this end, we conducted a second simulation following the steps outlined above while varying the sample size from 50 to 200 and the loadings of the manifest variables from 0.5 to 0.9. Figure <ref type="figure">3B</ref> displays the obtained power curves, illustrating statistical power dependent on total sample size and loading strength of the manifest variables. For this estimate, the factor intercorrelation was set to 0.3. Again, increasing sample size led to higher statistical power. However, the loading strength impacted estimates of statistical power: the higher the loadings of the manifest variables, the higher the statistical power achieved by a given sample size. For reasonably high levels of factor loadings (&gt;= 0.7), a statistical power of 95% was reached for N = 125.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How can simulations inform us about type I error rates?</head><p>The main part of this tutorial has focused on estimating statistical power that is required to reject a null hypothesis when it is indeed false. However, it is necessary to also consider the reverse -rejecting a null hypothesis that is in fact true (type I error). In our example, type I error would be committed by misidentifying Model 3 as the best-fitting model when in reality, the data were generated from either Models 1 or 2. We can leverage the simulation approach to quantify type I error rates dependent on the different simulation conditions (e.g., inter-factor correlations, factor loadings). We conducted an analogous analysis to the one outlined above ("Step 1: Specifying competing SEMs" -"Step 6: Running and evaluating the simulation"), with the difference that Models 1 and 2 are defined as the generating population models (step 3, "Step 3: Generate"). The outcomes of this analysis show the probability of erroneously identifying an overly complex model, when the more simplistic models generated the data (see Fig. <ref type="figure" target="#fig_4">4</ref>).</p><p>The results of this analysis reveal that even for low levels of loadings strength (&lt; 0.7), the probability of erroneously picking Model 3 as the best-fitting model is reasonably low (&lt; 8%). Likewise, this probability remains reasonably low for different levels of inter-factor correlations for all sample  <ref type="bibr">)</ref>. Note that the y-axis reaches from 0 to 20% for the sake of visibility sizes (&lt; 5%). Thus, in this specific model comparison type I error probability does not appear to be the main aspect driving sample size requirements for an informative research design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deriving a sample estimate from the simulation results</head><p>To derive a joint sample size estimate from the different parameters in the simulation, it is crucial to reiterate the theoretical assumptions on the strength of all parameters investigated in the simulation. In our illustration, it is reasonable to assume that the latent factors in the tri-partite model (Model 3, Fig. <ref type="figure" target="#fig_0">1</ref>) are only moderately correlated (below 0.7). Therefore, our model comparison requires a sample size of N = 125 to reach statistical power of 95% to adjudicate between the theoretical models, if the hypothesized model (Model 3) generates the data. We further assume that the manifest vari-ables capture the latent constructs reasonably well -that is, exerting a loading strength of 0.7 or above. The results of the simulation suggest that, again, N = 125 would suffice to achieve 95% with regard to the reliability of the manifest factors. In our example, the results of both analyses align, such that a sample size of N = 125 suffices to achieve a power of 95% regarding both the separability of the theoretical constructs and the reliability of the indicators. In cases where the derived sample estimate differs between the two analyses we suggest deriving the more conservative estimate of required sample size from the two simulations. The results from the type I error analysis further indicate that the probability of erroneously choosing an overly complex model is generally low. Therefore, the probability of committing a type I error for the sample size derived from the simulations on model separability and measurement reliability (N = 125) is negligible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion and conclusion</head><p>SEM offers a powerful tool for modeling multivariate relationships between psychological constructs. Maximizing its utility in psychological sciences hinges on the integration of its complex characteristics with power estimation -another key tenet of scientific rigor. Our work plifies roadmap for navigating of two efforts by implementing a priori power estimation within an SEM framework. In the case of information-theoretic model comparisons for nonnested models, statistical power cannot be determined based on traditional χ 2 -based statistics. Monte Carlo simulations provide a useful tool to circumvent this methodological challenge <ref type="bibr" target="#b44">(Muthén &amp; Muthén, 2002)</ref>, allowing researchers to derive informed decisions on sample size planning to ensure sufficient statistical power and prevent uninformative or misleading research <ref type="bibr" target="#b13">(Button et al., 2013)</ref>. In this study, we illustrate a step-by-step approach to implementing a Monte Carlo simulation in the statistical programming language R to estimate the required sample size for model comparisons of non-nested models. The complete code is available on GitHub <ref type="bibr" target="#b12">(Buchberger et al., 2024)</ref> to yield a starting point for researchers who want to implement their own Monte Carlo power simulations.</p><p>The results from our illustration highlight the importance of two model parameters: the separability of the theoretical models on the basis of factor inter-correlation, and the reliability with which the construct can be measured on the basis of the loading strength of the manifest variables. These results align with theoretical knowledge on SEM <ref type="bibr" target="#b68">(Wolf et al., 2013)</ref>, but they provide additional insights on the tangible impact of these parameters on statistical power estimation in the specific research design discussed here and in other SEMs more broadly.</p><p>First, we showed that detecting differences in model fit requires increasingly many participants the higher the intercorrelation of the factors turns out practically. Therefore, it is warranted to consider the actual separability of the constructs in question to avoid underpowered sampling plans. We acknowledge that committing to specific parameter values, such as factor inter-correlations, can be difficult when setting up the population models for the simulations. Thus, we recommend researchers to consult existing literature in order to make informed assumptions on the relationship among different latent factors. For cases in which no or little evidence exists on the relationship between the constructs under investigation, we recommend to enter these inter-correlations into the simulation as parameter of interest (as demonstrated in the example of this paper) and to then carefully evaluate what level of resolution is required when separating inter-related factors depending on practical relevance.</p><p>Second, the results on the loadings of manifest variables stresses the importance of employing indicators that capture the latent construct with high reliability <ref type="bibr" target="#b69">(Zuo, Xu, &amp; Milham, 2019)</ref>. Considering the issue of reliability is a crucial step in experimental design, as the reliability of the indicators heavily influences the practical ability to identify the targeted latent construct with sufficient precision and differentiate between competing models. Again, committing to population values can be difficult, especially if there is no prior work from which to draw values. In this case, we still advise to estimate plausible values from related scientific areas. For instance, selecting factor loading strength in the tri-partite model is not straightforward. However, we can do a literature search on similar models and take the reported test reliability (e.g., a test-retest) or construct reliability (e.g., coefficient alpha) and translate this back into factor loadings strength and residual loadings (see <ref type="bibr" target="#b10">Brandmaier et al., 2018</ref> for examples on how to parametrize longitudinal models from minimal available information). If information about test reliability is available, we set the loadings to the square-root of the reliability to take this prior information into account. Then, this yields the following construct reliability for our design (assuming identical loadings across k items):</p><formula xml:id="formula_1">α = k λ 2 k λ 2 + 1 -λ 2 (1)</formula><p>If instead, prior knowledge about construct reliability exists and this reliability estimate α was based on k items, we solve Eq. 1 for λ and obtain an estimate that may serve to inform our factor loadings:</p><formula xml:id="formula_2">λ = α α + k -α • k (2)</formula><p>For example, taking from a literature search that the construct reliability of the construct of interest (reported as Cronbach's alpha) was 0.7 and the estimate was based on k=4 tests, we set our loadings to λ = 0.61 (using Eq. 2). If a study reported a test-retest correlation of a single test to be r=0.8, then we set the factor loading to λ = √ 0.8 = 0.64. If in doubt, we suggest using conservative values rather than too liberal values to avoid underpowered studies.</p><p>Note that in this tutorial, we limited our analyses to investigating the impact of either the separability of the theoretical constructs or the impact of the reliability of the estimates by keeping the other parameter constant throughout the simulation. The interaction of these parameters may differentially impact the resultant sample size estimates. However, a thorough investigation of the interaction of the two influencing factors would exponentially increase the number of conditions in a simulation. In our example on memory component processes, we therefore confined our simulation separate analyses in the interest of conciseness. For interested readers, two additional analyses on (a) the effect of loading strength on estimates of power for higher levels of inter-factor correlation (0.7 as opposed to 0.3 the original simulation) and (b) inter-factor on estimates of for lower levels of factor-loadings opposed to 0.7 in the original simulation) can be found in the appendix of this manuscript. Given that previous work on memory development supports the assumption of reasonably high factor loadings and moderate inter-factor correlation in the present example, these additional analyses leave our conclusions unchanged.</p><p>Further, we have presented an approach that leverages a combination of absolute and relative model fit parameters to adjudicate between competing models. While such parameter-based decisions are well established in the field, they may result in choosing one model over the other, even in cases when differences in model fit parameters are very small, as one can never conclude that two models fit equally well or that there is too little data to make a decision with enough confidence. An alternative approach to this criterion for model selection originates from a theory by <ref type="bibr" target="#b66">Vuong (1989)</ref>, who suggested likelihood-ratio tests for non-nested models. Recent advances that build on this idea have postulated a framework that allows to test hypotheses of model distinguishability and difference in fit <ref type="bibr" target="#b31">(Levy &amp; Hancock, 2007</ref><ref type="bibr" target="#b32">, 2011)</ref>, which can be applied to non-nested SEMs and easily implemented via new software packages in R (nonnest2, <ref type="bibr" target="#b39">Merkle, You, &amp; Preacher, 2016)</ref>. The resulting recommendations for the comparison of non-nested SEMs posit a stepwise procedure to test whether competing non-nested models are distinguishable in a given population and, if yes, whether one fits the data significantly better than the other. Importantly, this method derives interval estimates for differences in non-nested information criteria <ref type="bibr" target="#b39">(Merkle et al., 2016)</ref>. Thus, this approach not only allows concluding that one or the other model fits the data better but also allows for the possibility to conclude that there is insufficient evidence to determine which of two models fits a given dataset better. This stepwise procedure can be implemented as a model selection criterion in a power simulation like the one presented above. To integrate model selection via a likelihood-ratio test for non-nested models into the current simulation, one would need to adapt the summarize function accordingly, such that it identifies model 3 as the best-fitting model only if (a) the competing models are distinguishable on the simulated data set of a given iteration, (b) the likelihood-ratio test for non-nested models indicates a significantly better fit for Model 3 compared to Models 1 and 2 and (c) Model 3 reaches the cutoffs for absolute model fit, as defined in the previous simulation. The vuongtest() function from the nonnest2 package <ref type="bibr" target="#b38">(Merkle &amp; You, 2014)</ref> can be a helpful tool for integrating these tests into the sim-ulation. While a systematic investigation of the interplay of indicator reliability, separability of latent factors and statistical power for model selection via model fit parameters versus the likelihood-ratio test for non-nested models is beyond the scope of this tutorial, it is worth noting that such an alternative approach may yield better model recovery in certain cases. The conditions under which model selection via the likelihood-ratio test for non-nested models provides better estimates of statistical power are thus an interesting avenue for future research.</p><p>While we demonstrate in this tutorial that simulationbased techniques help overcome methodological shortcomings from traditional analytical approaches, the randomness that is inherent to such approaches may seem at odds with efforts in results reproducibility and replicability. Here, a clear-cut solution is through transparent and accessible documentation of the simulation code and adequate software management. That is, researchers should make use of repositories on platforms such as GitHub or the Open Science Framework to make code scripts available to other researchers, and clearly specify the versions of software programs and packages that were used (e.g., via containerization or at least in written form). We thus urge researchers to seriously consider the issue of reproducibility for their simulation analyses to make outcomes of such a priori power estimates easily accessible to other researchers and reviewers (for a more detailed guideline on a reproducible workflow in R see <ref type="bibr" target="#b49">Peikert, Lissa, &amp; Brandmaier, 2021</ref> and the implementation of this manuscript on GitHub as an example). Note, however, that -specifically in cases when simulations are parallelized on computing clusters -the exact reproducibility of simulations as demonstrated in this tutorial might be compromised, even when a seed is specified in the analysis script. Nevertheless, a sufficiently high number of iterations ensures replicability, i.e., comparable estimates of statistical power. Derived conclusions about required sample size will therefore remain unaffected.</p><p>In sum, we argue that sample size planning in the case of non-nested SEM comparisons can be achieved via a simulation-based approach. In particular, we highlighted that the separability of theoretical constructs, as well as the reliability of the measures, have a major impact on estimates of statistical power. To this end, we hope that this tutorial advances the use of simulation-based approaches to estimating statistical power for model selection when comparing non-nested models in an SEM framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Path diagrams of three competing SEMs on the structure of memory. Squares represent observed performance measures on the behavioral tasks. Circles represent latent constructs (PS = Pattern Separation, PC = Pattern Completion, GEN = Generalization). Single-headed</figDesc><graphic coords="5,53.65,56.96,487.69,570.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>Fig. 2 Schematic overview of the simulation process</figDesc><graphic coords="7,53.65,56.33,487.69,134.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>$loading_strength/ sqrt(2+2*condition$cov1)) tasks &lt;-str_c("task", 1:13) error_vars &lt;-glue::glue_collapse( glue::glue_data(parameters, "{tasks} ~~{1 -aˆ2} * {tasks}"),"\n") pop_model &lt;-glue::glue_data( parameters, "ps =~{a}*task1 + {a}*task2 + {a}*task3 + {a}*task4 + {b}*task5 + {b}*task6\n pc =~{b}*task5 + {b}*task6 + {a}*task7 + {a}*task8 + {a}*task9\n gen =~{a}*task10+ {a}*task11 + {a}*task12+ {a}*task13\n {error_vars} ps ~~{condition$cov1}*pc\n ps ~~{condition$cov2}*gen\n pc ~~{condition$cov3}*gen") dat &lt;-data.frame(simulateData(pop_model, sample.nobs = condition$sample_size))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4</head><label>4</label><figDesc>Fig. 4 Simulation results: Probability to erroneously pick Model 3 as the best-fitting model when indeed Model 1 (A1) or Model 2 (A2/B2) generated the data, as a function of total sample size (x-axis) and the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="11,84.64,85.34,422.20,139.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="15,83.29,220.10,411.64,364.72" type="bitmap" /></figure>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements This work was conducted within the project</p></div>
			</div>


			<div type="funding">
<div><p><rs type="institution">Planck Institute for Human Development</rs>. ESB was a fellow of the <rs type="funder">International Max Planck Research School</rs> on the Life Course (LIFE; <ref type="url" target="http://www.imprs-life.mpg.de/en">http:// www.imprs-life.mpg.de/en</ref>). AP was a fellow of the <rs type="funder">International Max Planck Research School on Computational Methods in Psychiatry and Ageing Research</rs> (<rs type="grantNumber">COMP2PSYCH</rs>, <ref type="url" target="https://www.mps-ucl-centre.mpg.de/comp2psych">https://www.mps-ucl-centre.mpg. de/comp2psych</ref>). MW-B received support from the <rs type="funder">Jacobs Foundation</rs> (<rs type="grantName">Early Career Research Fellowship</rs> <rs type="grantNumber">2017-2019</rs>, <rs type="grantNumber">2016-1217-16</rs>). CTN's work is supported by a grant from the <rs type="funder">German Research Foundation</rs> (DFG; <rs type="grantNumber">NG 191/2-1</rs>) and an <rs type="grantName">Early Career Research Fellowship</rs> by the <rs type="funder">Jacobs Foundation</rs> (<rs type="grantNumber">2021-1417-99</rs>). We are grateful to all members of RHYME and LIME projects for valuable feedback on the project. Finally, we acknowledge support by the <rs type="funder">Max Planck Dahlem Campus of Cognition (MPDCC)</rs>. The authors declare no competing interests. The latest supplementary materials for this article are available on GitHub <ref type="bibr" target="#b12">(Buchberger et al., 2024)</ref>. The version of code and data used as the basis for this PDF is "36688df".</p><p>Funding Open Access funding enabled and organized by <rs type="person">Projekt DEAL</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uSX4qGa">
					<idno type="grant-number">COMP2PSYCH</idno>
				</org>
				<org type="funding" xml:id="_54DXk2S">
					<idno type="grant-number">2017-2019</idno>
					<orgName type="grant-name">Early Career Research Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_tcDCWw7">
					<idno type="grant-number">2016-1217-16</idno>
				</org>
				<org type="funding" xml:id="_Ew75Gk8">
					<idno type="grant-number">NG 191/2-1</idno>
					<orgName type="grant-name">Early Career Research Fellowship</orgName>
				</org>
				<org type="funding" xml:id="_7vFA2NY">
					<idno type="grant-number">2021-1417-99</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices Statement</head><p>The supplementary materials for this article (including the data and R scripts) are publicly available on GitHub <ref type="bibr" target="#b12">(Buchberger et al., 2024)</ref>. The analyses reported in this manuscript were not preregistered. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix 1. Interaction effects inter-factor correlation and factor loadings</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAC.1974.1100705</idno>
		<ptr target="https://doi.org/10.1109/TAC.1974.1100705" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Addressing the replication crisis: Using original studies to design replication studies with appropriate statistical power</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Maxwell</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2017.1289361</idno>
		<ptr target="https://doi.org/10.1080/00273171.2017.1289361" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="305" to="324" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Life-span developmental psychology: Introduction to research methods</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Baltes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Reese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Nesselroade</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Erlbaum</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparative fit indexes in structural models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.107.2.238</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.107.2.238" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="246" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Significance tests and goodness of fit in the analysis of covariance structures</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Bonett</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.88.3.588</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.88.3.588" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="588" to="606" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Practical issues in structural modeling</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chou</surname></persName>
		</author>
		<idno type="DOI">10.1177/0049124187016001004</idno>
		<ptr target="https://doi.org/10.1177/0049124187016001004" />
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="117" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<title level="m">Structural equations with latent variables</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="volume">210</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nonconvergence, improper solutions, and starting values in LISREL maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boomsma</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294248</idno>
		<ptr target="https://doi.org/10.1007/BF02294248" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="242" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimal planned missing data design for linear latent growth curve models</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-019-01325-y</idno>
		<ptr target="https://doi.org/10.3758/s13428-019-01325-y" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="1445" to="1458" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LIFESPAN: A tool for the computer-aided design of longitudinal studies</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Von Oertzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ghisletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hertzog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lindenberger</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2015.00272</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2015.00272" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Precision, reliability, and effect size of slope variance in latent growth curve models: Implications for statistical power analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Von Oertzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ghisletta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lindenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hertzog</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2018.00294</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2018.00294" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Buchberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lindenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werkle-Bergner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Ngo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The process structure of memory abilities in early and middle childhood</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Supplemental materials for preprint: Estimating statistical power for structural equation models in developmental cognitive science: A tutorial in r</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Buchberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Werkle-Bergner</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.10450596</idno>
		<ptr target="https://doi.org/10.5281/zenodo.10450596" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Power failure: Why small sample size undermines the reliability of neuroscience</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Button</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Ioannidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mokrysz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Nosek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Flint</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Munafó</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn3475</idno>
		<ptr target="https://doi.org/10.1038/nrn" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">3475</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Developmental changes in episodic memory across early-to mid-childhood: Insights from a latent longitudinal approach</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Canada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Riggins</surname></persName>
		</author>
		<idno type="DOI">10.1080/09658211.2021.2006233</idno>
		<ptr target="https://doi.org/10.1080/09658211.2021.2006233" />
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="248" to="261" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Cattell</surname></persName>
		</author>
		<title level="m">Abilities: Their structure, growth, and action</title>
		<imprint>
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Writing effective and reliable monte carlo simulations with the SimDesign package</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Chalmers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Adkins</surname></persName>
		</author>
		<idno type="DOI">10.20982/tqmp.16.4.p248</idno>
		<ptr target="https://doi.org/10.20982/tqmp.16.4.p248" />
	</analytic>
	<monogr>
		<title level="m">The Quantitative Methods for Psychology</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="248" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The statistical power of abnormal-social psychological research: A review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0045186</idno>
		<ptr target="https://doi.org/10.1037/h0045186" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Abnormal and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="145" to="153" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Statistical power analysis for the behavioral sciences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>NJ Lawrence Earlbaum Associates</publisher>
			<pubPlace>Hilsdale</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An introduction to the bootstrap</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Margossian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Modrák</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2011.01808" />
		<title level="m">Bayesian workflow</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Individual differences in executive processing predict susceptibility to interference in verbal working memory</title>
		<author>
			<persName><forename type="first">T</forename><surname>Hedden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="DOI">10.1037/0894-4105.20.5.511</idno>
		<ptr target="https://doi.org/10.1037/0894-4105.20.5.511" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="511" to="528" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multiple determinants of lifespan memory differences</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Henson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Emery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Erzinclioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kievit</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep32527</idno>
		<ptr target="https://doi.org/10.1038/srep32527" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">32527</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Glue: Interpreted string literals</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bryan</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=glue" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Organization of data on life-span development of human abilities</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Life-span developmental psychology</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="423" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Horn</surname></persName>
		</author>
		<title level="m">Human ability systems. Life-Span Development and Behavior</title>
		<imprint>
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705519909540118</idno>
		<ptr target="https://doi.org/10.1080/10705519909540118" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Analytical power calculations for structural equation modeling: A and shiny app</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G E</forename><surname>Verdam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Oort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Elffers</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-020-01479-0</idno>
		<ptr target="https://doi.org/10.3758/s13428-020-01479-0" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1385" to="1406" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A tutorial on assessing statistical power and determining sample size for structural equation models</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Jobst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moshagen</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000423</idno>
		<ptr target="https://doi.org/10.1037/met0000423" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="207" to="221" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Estimation of a model with multiple indicators and multiple causes of a single latent variable</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Goldberger</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1975.10482485</idno>
		<ptr target="https://doi.org/10.1080/01621459.1975.10482485" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">351</biblScope>
			<biblScope unit="page" from="631" to="639" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Developmental cognitive neuroscience using latent change score models: A tutorial and applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kievit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-L</forename><surname>Van Harmelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M M</forename><surname>De Mooij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moutoussis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.dcn.2017.11.007</idno>
		<ptr target="https://doi.org/10.1016/j.dcn.2017.11.007" />
	</analytic>
	<monogr>
		<title level="j">Developmental Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="99" to="117" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A framework of statistical tests for comparing mean and covariance structure models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273170701329112</idno>
		<ptr target="https://doi.org/10.1080/00273170701329112" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="66" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An extended model comparison framework for covariance and mean structure models, accommodating multiple groups and latent mixtures</title>
		<author>
			<persName><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<idno type="DOI">10.1177/0049124111404819</idno>
		<ptr target="https://doi.org/10.1177/0049124111404819" />
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="256" to="278" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Applications of structural equation modeling in psychological research</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Austin</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.psych.51.1.201</idno>
		<ptr target="https://doi.org/10.1146/annurev.psych.51.1.201" />
	</analytic>
	<monogr>
		<title level="j">Annual Review Psychology</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="201" to="226" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Simple memory: A theory for archicortex</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.1971.0078</idno>
		<ptr target="https://doi.org/10.1098/rstb.1971.0078" />
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. R. Soc. London</title>
		<imprint>
			<biblScope unit="volume">262</biblScope>
			<biblScope unit="page" from="23" to="81" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The persistence of underpowered studies in psychological research: Causes, consequences, and remedies</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Maxwell</surname></persName>
		</author>
		<idno type="DOI">10.1037/1082-989X.9.2.147</idno>
		<ptr target="https://doi.org/10.1037/1082-989X.9.2.147" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">147</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Mcnaughton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.102.3.419</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.102.3.419" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="419" to="457" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Updating norman&apos;s adequate taxonomy: Intelligence and personality dimensions in natural language and in questionnaires</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mccrae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Costa</surname></persName>
		</author>
		<idno type="DOI">10.1037//0022-3514.49.3.710</idno>
		<ptr target="https://doi.org/10.1037//0022-3514.49.3.710" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="710" to="721" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">nonnest2: Tests of non-nested models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>You</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=nonnest2" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Testing nonnested structural equation models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Preacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">151</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Equation of state calculations by fast computing machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teller</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.1699114</idno>
		<ptr target="https://doi.org/10.1063/1.1699114" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1087" to="1092" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A latent variable approach to determining the structure of executive function in preschool children</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F</forename><surname>Giesbrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mcinerney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Kerns</surname></persName>
		</author>
		<idno type="DOI">10.1080/15248372.2011.585478</idno>
		<ptr target="https://doi.org/10.1080/15248372.2011.585478" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognition and Development</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="395" to="423" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Analysis of the elements of attention: A neuropsychological approach</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Mirsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Ahearn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Kellam</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01109051</idno>
		<ptr target="https://doi.org/10.1007/BF01109051" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychology Review</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="145" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The unity and diversity of executive functions and their contributions to complex frontal lobe tasks: A latent variable analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Miyake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Witzki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Howerter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Wager</surname></persName>
		</author>
		<idno type="DOI">10.1006/cogp.1999.0734</idno>
		<ptr target="https://doi.org/10.1006/cogp.1999.0734" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="100" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How to use a monte carlo study to decide on sample size and determine power</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthén</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15328007SEM0904_8</idno>
		<ptr target="https://doi.org/10.1207/S15328007SEM0904_8" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="599" to="620" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Individual fit, heterogeneity, and missing data in multigroup sem. In Modeling longitudinal and multiple-group data: Practical issues, applied approaches, and specific examples</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Neale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Modeling hippocampal and neocortical contributions to recognition memory: A complementary-learning-systems approach</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>O'reilly</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.110.4.611</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.110.4.611" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="611" to="646" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A structural equation modeling approach to the multiple memory systems question</title>
		<author>
			<persName><forename type="first">L</forename><surname>Nyberg</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.20.2.485</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.20.2.485" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="485" to="491" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Monte carlo experiments: Design and implementation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15328007SEM0802_7</idno>
		<ptr target="https://doi.org/10.1207/S15328007SEM0802_7" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="287" to="312" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reproducible research in r: A tutorial on how to do the same thing more than once</title>
		<author>
			<persName><forename type="first">A</forename><surname>Peikert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Lissa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<idno type="DOI">10.3390/psych3040053</idno>
		<ptr target="https://doi.org/10.3390/psych3040053" />
	</analytic>
	<monogr>
		<title level="j">Psych</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="836" to="867" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Simsem: SIMulated structural equation modeling. R Package Version 0</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pornprasertmanit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schoemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Jorgensen</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=simsem" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="5" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Choosing models for cross-classifications</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<idno type="DOI">10.2307/2095483</idno>
		<ptr target="https://doi.org/10.2307/2095483" />
	</analytic>
	<monogr>
		<title level="j">American Sociological Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="146" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Pattern separation, completion, and categorisation in the hippocampus and neocortex</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Rolls</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.nlm.2015.07.008</idno>
		<ptr target="https://doi.org/10.1016/j.nlm.2015.07.008" />
	</analytic>
	<monogr>
		<title level="j">Neurobiology of Learning and Memory</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="4" to="28" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Lavaan: An r package for structural equation modeling and more version 0.5-12 (BETA)</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v048.i02</idno>
		<ptr target="https://doi.org/10.18637/jss.v048.i02" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Statistical power of psychological research: What have we gained in 20 years</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Rossi</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-006X.58.5.646</idno>
		<ptr target="https://doi.org/10.1037/0022-006X.58.5.646" />
	</analytic>
	<monogr>
		<title level="j">Journal of Consulting and Clinical Psychology</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="646" to="656" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Power of the likelihood ratio test in covariance structure analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Saris</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294150</idno>
		<ptr target="https://doi.org/10.1007/BF02294150" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="83" to="90" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Complementary learning systems within the hippocampus: A neural network modelling approach to reconciling episodic memory with statistical learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Schapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2016.0049</idno>
		<ptr target="https://doi.org/10.1098/rstb.2016.0049" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<date type="published" when="1711">2017. 1711. 20160049</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Using monte carlo simulations to determine power and sample size for planned missing designs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Schoemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pornprasertmanit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1177/0165025413515169</idno>
		<ptr target="https://doi.org/10.1177/0165025413515169" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Behavioral Development</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="471" to="479" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Estimating the dimension of a model</title>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
		<idno type="DOI">10.1214/aos/1176344136</idno>
		<ptr target="https://doi.org/10.1214/aos/1176344136" />
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Do studies of statistical power have an effect on the power of studies?</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sedlmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.105.2.309</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.105.2.309" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="316" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">General intelligence objectively determined and measured</title>
		<author>
			<persName><forename type="first">C</forename><surname>Spearman</surname></persName>
		</author>
		<idno type="DOI">10.2307/1412107</idno>
		<ptr target="https://doi.org/10.2307/1412107" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="201" to="293" />
			<date type="published" when="1904">1904</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Memory and brain</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Notes on the steiger-lind handout. Structural Equation Modeling: A</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Steiger</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2016.1217487</idno>
		<ptr target="https://doi.org/10.1080/10705511.2016.1217487" />
	</analytic>
	<monogr>
		<title level="j">Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="777" to="781" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Coupled cognitive changes in adulthood: A meta-analysis</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Tucker-Drob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Brandmaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lindenberger</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000179</idno>
		<ptr target="https://doi.org/10.1037/bul" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">179</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Episodic and semantic memory</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tulving</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organization of Memory</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="381" to="403" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Article commentary: On the persistence of low power in psychological science</title>
		<author>
			<persName><forename type="first">I</forename><surname>Vankov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bowers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Munafó</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470218.2014.885986</idno>
		<ptr target="https://doi.org/10.1080/17470218.2014.885986" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1037" to="1040" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Likelihood ratio tests for model selection and nonnested hypotheses</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">H</forename><surname>Vuong</surname></persName>
		</author>
		<idno type="DOI">10.2307/1912557</idno>
		<ptr target="https://doi.org/10.2307/1912557" />
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="307" to="333" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Power analysis for parameter estimation in structural equation modeling: A discussion and tutorial</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rhemtulla</surname></persName>
		</author>
		<idno type="DOI">10.1177/2515245920918253</idno>
		<ptr target="https://doi.org/10.1177/2515245920918253" />
	</analytic>
	<monogr>
		<title level="m">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">2515245920918253</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Sample size requirements for structural equation models: An evaluation of power, bias, and solution propriety</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Harrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1177/0013164413495237</idno>
		<ptr target="https://doi.org/10.1177/0013164413495237" />
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="913" to="934" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Harnessing reliability for neuroscience research</title>
		<author>
			<persName><forename type="first">X.-N</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Milham</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-019-0655-x</idno>
		<ptr target="https://doi.org/10.1038/s41562-019-0655-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="768" to="771" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
