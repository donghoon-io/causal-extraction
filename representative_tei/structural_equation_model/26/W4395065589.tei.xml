<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gaussian distributional structural equation models: A framework for modeling latent heteroscedasticity</title>
				<funder ref="#_kaTcyYa">
					<orgName type="full">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-05-26">26 May 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Luna</forename><surname>Fazio</surname></persName>
							<email>bmfaziol@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">TU Dortmund University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul-Christian</forename><surname>BÃ¼rkner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">TU Dortmund University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gaussian distributional structural equation models: A framework for modeling latent heteroscedasticity</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-05-26">26 May 2025</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:2404.14124v2[stat.ME]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>structural equation modeling</term>
					<term>distributional regression</term>
					<term>Bayesian inference</term>
					<term>heteroscedasticity</term>
					<term>measurement invariance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accounting for the complexity of psychological theories requires methods that can predict not only changes in the means of latent variables -such as personality factors, creativity, or intelligence -but also changes in their variances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural equation modeling (SEM) is the framework of choice for analyzing complex relationships among latent variables, but the modeling of latent variances as a function of other latent variables is a task that current methods only support to a limited extent.</head><p>In this paper, we develop a Bayesian framework for Gaussian distributional SEM which broadens the scope of feasible models for latent heteroscedasticity. We use statistical simulation to validate our framework across four distinct model structures, in which we demonstrate that reliable statistical inferences can be achieved and that computation can be performed with sufficient efficiency for practical everyday use. We illustrate our framework's applicability in a real-world case study that addresses a substantive hypothesis from personality psychology.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Structural equation modeling (SEM) is a widely-used statistical framework that can be regarded as an extension of regression models: it allows modeling multiple dependent variables simultaneously, including relationships among them, as well as the introduction of measurement error and unobserved (latent) variables (for a comprehensive introduction see <ref type="bibr" target="#b9">Bollen, 1989;</ref><ref type="bibr" target="#b33">Kline, 2016)</ref>. As with regression, the classic formulation of SEM presents an idealized setting where, among other simplifications, it is assumed that the model's parameters (intercepts, coefficients and (co-)variances) all take on values that are constant across people, conditions, etc. Such an assumption often does not hold in practice and this has motivated a rich literature on methods for handling non-invariant parameters (see below). Extending this line of research, we develop a Bayesian framework for Gaussian distributional SEMs, which, compared to past approaches, supports more flexible models of latent heteroscedasticity when dependencies on other latent variables are involved. We demonstrate our framework's statistical validity and usefulness through simulation studies on four distinct structural models and a real-world case study applied to a research question from personality psychology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>The problem of invariance has received attention since the early days of factor analysis, initially focusing on invariance of the covariance matrix of observed data across selected subgroups of some larger population <ref type="bibr" target="#b59">(Thomson &amp; Ledermann, 1939)</ref>. The introduction of the multiple-group model methodology in <ref type="bibr" target="#b30">JÃ¶reskog (1971)</ref> marked the shift in focus to the invariance of model parameters that prevails today. It was followed by the development of moderated factor analysis (MFA), which enabled modeling parameter values via known functions of observed variables (moderators), including continuous ones; this meant that evaluation of invariance stopped being limited to comparisons over discrete groups <ref type="bibr" target="#b5">(Bauer &amp; Hussong, 2009)</ref>. A further extension, local structural equation modeling (LSEM), fits the model multiple times over the moderators' range in combination with an observation weighting scheme to produce a nonparametric estimate of the moderation functions, thereby avoiding the assumption of a known functional form <ref type="bibr" target="#b26">(Hildebrandt, LÃ¼dtke, Robitzsch, Sommer, &amp; Wilhelm, 2016)</ref>. There are additional approaches which are particularly suited for assessment of non-invariance under specific assumptions of magnitude or structure (for an overview see <ref type="bibr" target="#b36">LeitgÃ¶b et al., 2023</ref>), but we do not discuss them here as they are less related to our proposed framework. The above-mentioned techniques already provide a great deal of flexibility for modeling varying parameters within the SEM framework, but they all share the requirement that the moderator be an observed variable. A set of related approaches known as heteroscedastic factor models use MFA-like regressions on residual item variance and factor loading parameters together with skewed latent variable distributions <ref type="bibr" target="#b44">(Molenaar, Dolan, &amp; van der Maas, 2011;</ref><ref type="bibr" target="#b45">Molenaar, Dolan, &amp; Verhelst, 2010)</ref>. Another approach introduced in <ref type="bibr" target="#b43">Molenaar (2015)</ref> is to use latent skewed distributions to allow the model to account for the effects of continuous latent moderators on the latent trait of interest. However, it achieves so by effectively marginalizing over the moderator and hence is not applicable when one wishes to include a measurement model for the latent moderator. In his discussion, Molenaar mentions this limitation and notes that models with explicit latent moderators would constitute a useful addition to the literature, citing methods for investigating latent heteroscedasticity <ref type="bibr" target="#b46">(Molenaar, Van Der Sluis, Boomsma, &amp; Dolan, 2012)</ref> and latent variable interactions <ref type="bibr" target="#b32">(Klein &amp; Moosbrugger, 2000)</ref> as examples. Indeed, one can already find some developments towards the use of latent predictors for latent variances. For instance, the works of <ref type="bibr" target="#b49">Nestler (2020)</ref> and <ref type="bibr" target="#b38">Martin and Rast (2022)</ref>, motivated from the perspective of measurement reliability, provide techniques for modeling the variance of measurement errors (which can be conceived of as a special type of latent variable) as dependent on other latent variables. The original formulation of MFA <ref type="bibr" target="#b5">(Bauer &amp; Hussong, 2009)</ref> also received an extended treatment in <ref type="bibr" target="#b4">Bauer (2017)</ref>, where it is emphasized that the method can be used to assess measurement invariance and differential item functioning, including the case of both observed and latent moderators of item-level residual variances. Moving beyond heteroscedastic errors, modeling of the residual variance of a structural latent variable has also been demonstrated under a frequentist framework in a simple latent regression setting (i.e. one exogenous latent variable predicting one endogenous latent variable; de Kort, Dolan, Lubke, and <ref type="bibr" target="#b17">Molenaar, 2017)</ref>. One key challenge in maximum likelihood estimation of SEM is that latent variables can be regarded as incidental <ref type="bibr" target="#b50">(Neyman &amp; Scott, 1948)</ref> or nuisance <ref type="bibr" target="#b3">(Basu, 1977)</ref> parameters, which means that they must be marginalized out of the likelihood in order for consistent estimates to be obtainable. When latent heteroscedasticity is introduced, a closed-form expression of the marginal likelihood will generally not be available and numerical integration has to be performed at each step of the maximization procedure (e.g. <ref type="bibr" target="#b25">Hessen and Dolan, 2009)</ref>. Such an approach is sometimes called Marginal Maximum Likelihood (MML) and corresponds to an application of the more general expectation-maximization (EM) algorithm <ref type="bibr" target="#b7">(Bock &amp; Aitkin, 1981)</ref>. As the quadrature methods that are commonly used to approximate the integral do not scale well with dimension (which in turn grows with the number of latent variables), de <ref type="bibr" target="#b17">Kort et al. (2017)</ref> have suggested that Bayesian procedures could provide a viable alternative to MML for estimation of larger models with latent heteroscedasticity. To our knowledge, a systematic assessment of such an approach has not yet been conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Our contributions</head><p>We develop and validate a Bayesian approach to support latent moderators of latent variances, which works by including latent variables as parameters to sample from instead of marginalizing over them. Such an approach has been termed conditional likelihood in the latent variable literature (e.g. <ref type="bibr" target="#b41">Merkle, Furr, and Rabe-Hesketh, 2019)</ref> and it was favored in earlier methods for obtaining full posterior distributions in Bayesian SEM as it enabled the use of Gibbs sampling <ref type="bibr" target="#b35">(Lee, 2007)</ref>. With the development of algorithms such as Hamiltonian Monte Carlo (HMC; <ref type="bibr" target="#b6">Betancourt, 2018;</ref><ref type="bibr" target="#b48">Neal, 2012)</ref>, it was no longer necessary to use conditional distributions that could be sampled from and contemporary Bayesian SEM software has moved to use marginal likelihoods due to the increased sampling efficiency gained by not having the latent variables as additional parameters <ref type="bibr" target="#b40">(Merkle, Fitzsimmons, Uanhoro, &amp; Goodrich, 2021)</ref>. As mentioned above, however, latent moderators cannot be handled in full generality when using marginal likelihoods, which is why we adopt a conditional likelihood approach in this paper. We implement our framework in the probabilistic programming language Stan, which provides an expressive syntax and powerful algorithms to specify and fit open-ended Bayesian models <ref type="bibr">(Stan Development Team, 2023)</ref>. To avoid users having to interact with Stan directly, we extended the R package brms, designed to simplify the process of fitting Bayesian regression models in Stan while still providing access to advanced regression techniques that can be combined in a modular fashion <ref type="bibr" target="#b10">(BÃ¼rkner, 2017;</ref><ref type="bibr">R Core Team, 2023)</ref>. We realize latent variable models with moderators in brms by utilizing its functionality for model-based imputation and distributional regression models, models predicting distributional parameters beyond the mean, for example, also variances or standard deviations (see <ref type="bibr" target="#b18">Fahrmeir, Kneib, Lang, and Marx, 2021</ref><ref type="bibr">, Chapter 10 and BÃ¼rkner, 2018</ref><ref type="bibr">, 2021)</ref>. By representing latent variables as missing observations and placing them as predictors of distributional parameters, we obtain an MFA-like procedure that admits latent moderators with more flexibility than methods based on marginal likelihoods. In the remainder of this article we describe and evaluate our conditional likelihood approach for continuous latent moderators on both latent means and variances. In Section 2, we formally introduce the model and establish the corresponding notation. In Section 3, we present are large-scale simulation study to evaluate our approach, with results showing good convergence and parameter recovery in all investigated models. We demonstrate an application to a substantive hypothesis from personality psychology in Section 4. Finally, in Section 5 we discuss limitations and future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model description</head><p>Below, we formally introduce the developed SEM framework. Going forward, we will make an important simplifying assumption: all the variables in the model are conditionally normally distributed. This is not an inherent limitation of the approach we present, as it allows the specification of any continuous distribution for the latent variables, with moderation on other parameters beyond the mean. However, we find that this simplified setting already involves enough complexity for a rich discussion and practical relevance, so we omit a more general treatment in order to keep a reasonable scope for this paper. Additionally, we will omit structural manifest variables and fixed covariates from the following exposition as their inclusion is straightforward and our interest here is to discuss latent-to-latent regressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model likelihood</head><p>We begin by describing the general structure of the model. Let ğ¼ be some set indexing individual observations over the relevant units of analysis (e.g., institutions, individuals, time points, etc.). For each ğ‘– âˆˆ ğ¼, we have a vector ğœ» ğ‘– = (ğœ 1ğ‘– , . . . , ğœ ğ‘™ğ‘– , . . . , ğœ ğ¿ğ‘– ) of latent variables and for each ğœ ğ‘™ğ‘– , the vector y ğ‘™ğ‘– = (ğ‘¦ ğ‘™1ğ‘– , . . . , ğ‘¦ ğ‘™ğ‘šğ‘– , . . . , ğ‘¦ ğ¿ ğ‘€ğ‘– ) holds the corresponding manifest indicator variables. Here, ğ‘€ denotes the number of manifest variables of the ğ‘™th factor, with ğ‘€ being allowed to vary over ğ‘™. Then, the distribution of the variables can be written as</p><formula xml:id="formula_0">ğœ ğ‘™ğ‘– | ğœ» ğ‘– âˆ¼ Normal(ğœ‡ ğ‘™ğ‘– , ğœ ğ‘™ğ‘– ) ğ‘¦ ğ‘™ğ‘šğ‘– | ğœ ğ‘™ğ‘– âˆ¼ Normal(ğœˆ ğ‘™ğ‘š + ğœ† ğ‘™ğ‘š ğœ ğ‘™ğ‘– , ğœ ğ‘™ğ‘š ),<label>(1)</label></formula><p>where ğœˆ ğ‘™ğ‘š is the intercept of the manifest variable and ğœ† ğ‘™ğ‘š is its factor loading. Both the mean ğœ‡ ğ‘™ğ‘– and standard deviation ğœ ğ‘™ğ‘– of each latent variable can depend on other latent variables. We consider dependencies of the form given by a generalized additive predictor</p><formula xml:id="formula_1">ğœ‚ ğœƒ ğ‘™ ğ‘– = ğ¾ ğœƒ ğ‘™ âˆ‘ï¸ ğ‘˜=0 ğ›½ ğ‘˜ğœƒ ğ‘™ ğ‘“ ğ‘˜ğœƒ ğ‘™ (ğœ» ğ‘– ),<label>(2)</label></formula><p>where ğœƒ stands for the likelihood parameter of interest (ğœ‡ or ğœ) and ğ›½ ğ‘˜ğœƒ ğ‘™ are the coefficients for each continuous (possibly non-linear) transformation ğ‘“ ğ‘˜ğœƒ ğ‘™ of the latent variables. For clarity, we point out that if one wishes to include an intercept in the model, this can be done by setting ğ‘“ 0ğœƒ ğ‘™ = 1 and incorporating fixed covariates more generally is a matter of putting their values as a constant part in the ğ‘“ ğ‘˜ğœƒ ğ‘™ . With this notation, each parameter is related to its predictor via the appropriate link function: </p><formula xml:id="formula_2">ğœ‡ ğ‘™ğ‘– = identity(ğœ‚ ğœ‡ ğ‘™ ğ‘– ) = ğœ‚ ğœ‡ ğ‘™ ğ‘– , ğœ ğ‘™ğ‘– = exp(ğœ‚ ğœ ğ‘™ ğ‘– ).<label>(3)</label></formula><p>Following terminology from the latent variable model literature (e.g. <ref type="bibr" target="#b41">Merkle et al., 2019)</ref>, one could obtain the marginal likelihood by integrating out the latent variables:</p><formula xml:id="formula_4">ğ‘(y | ğœ½ ğœ» , ğœ½ y ) = âˆ« ğ‘(y, ğœ» | ğœ½ ğœ» , ğœ½ y )ğ‘‘ğœ» . (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>The use of marginal likelihoods is a necessity in frequentist settings as latent variables play the role of incidental parameters, which results in inconsistent estimates if they are included in the estimation process <ref type="bibr" target="#b50">(Neyman and Scott, 1948</ref>; also see discussion at the end of <ref type="bibr" target="#b25">Hessen and Dolan, 2009)</ref>. On the other hand, there are no formal impediments for performing Bayesian inference while including latent variables as part of the model parameters. The form of the likelihood in which latent variables are explicitly included is called the conditional likelihood, as one can decompose Eq. 4 into a likelihood for the indicator variables conditioned on the latent variables, and a likelihood for the latent variables themselves:</p><formula xml:id="formula_6">ğ‘(y, ğœ» | ğœ½ ğœ» , ğœ½ y ) = ğ‘(y | ğœ», ğœ½ y ) ğ‘(ğœ» | ğœ½ ğœ» ).<label>(6)</label></formula><p>As discussed in Section 1, we use conditional likelihoods in this paper because marginalization would not produce a closed-form expression in the presence of latent predictors for latent variances.</p><p>Because we use the Bayesian framework for inference (see the Estimation section for more information), a complete specification must also include priors for the parameters. We can write the resulting joint posterior as</p><formula xml:id="formula_7">ğ‘(ğœ», ğœ½ ğœ» , ğœ½ y | y) âˆ ğ‘(y | ğœ», ğœ½ y ) ğ‘(ğœ» | ğœ½ ğœ» ) ğ‘(ğœ½ y ) ğ‘(ğœ½ ğœ» ) = ğ¿ ğ‘™=1 ğ‘(y ğ‘™ | ğœ ğ‘™ , ğœ½ y ) ğ‘(ğœ ğ‘™ | PA(ğœ ğ‘™ ), ğœ½ ğœ» ) ğ‘(ğœ½ y ) ğ‘(ğœ½ ğœ» ),<label>(7)</label></formula><p>where PA(ğœ ğ‘™ ) âŠ† ğœ» -ğ‘™ denotes the parents of latent variable ğœ ğ‘™ among the set of all other latent variables ğœ» -ğ‘™ , that is, all latent variables that contribute to the additive predictors ğ ğ‘™ or ğˆ ğ‘™ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Identification</head><p>The model as given above is underidentified. Unless otherwise noted, identification for models in this paper is obtained by setting the expectation of all latent variables to 0, which identifies their mean, and the loading factor of one item to 1, which identifies their scale (see <ref type="bibr">Bollen, 1989, p. 238</ref> for an introduction to identification in SEM). Our model additionally introduces coefficients for the latent variance linear predictor, so it is valid to ask whether these parameters are identified too. Below, we provide a formal argument demonstrating that a link from observed data to parameter values can be drawn without the need for any new constraints, thus showing identification.</p><p>To start with, consider the simplified scenario where we assume the latent values to be observed directly. Let ğœ 0 be the variable whose variance we are interested in predicting based on the values of ğœ 1 , . . . , ğœ ğ¾ so that</p><formula xml:id="formula_8">Var ğœ 0 = exp Î£ ğ¾ ğ‘˜=1 ğ›½ ğ‘˜ ğœ ğ‘˜ ,<label>(8)</label></formula><p>which means that the coefficients are related to the ratio of variances given a unit increase in one of the predictors. Without loss of generality, consider increasing ğœ 1 by one. Then, we find</p><formula xml:id="formula_9">Var ğœ 0 | (ğœ 1 + 1), ğœ {2,...,ğ¾ } Var ğœ 0 | ğœ 1 , ğœ {2,...,ğ¾ } = exp(ğ›½ 1 (ğœ 1 + 1) + Î£ ğ¾ ğ‘˜=2 ğ›½ ğ‘˜ ğœ ğ‘˜ ) exp(ğ›½ 1 ğœ 1 + Î£ ğ¾ ğ‘˜=2 ğ›½ ğ‘˜ ğœ ğ‘˜ ) = exp(ğ›½ 1 ),<label>(9)</label></formula><p>thus showing identification of the coefficients ğ›½ 1 , . . . , ğ›½ ğ¾ if there is variation in the corresponding latent variables. Estimation of the coefficients in such a model is a well-studied topic (e.g. <ref type="bibr" target="#b24">Harvey, 1976)</ref> and can be regarded as a particular case of the more general distributional regression framework (e.g., see Chapter 10 of <ref type="bibr" target="#b18">Fahrmeir et al., 2021)</ref>.</p><p>Coming back to our non-simplified model, we do not actually observe the latent variables but rather noisy measurements as defined in Eq. 1, and we want to show whether it's possible to infer changes in the latent variance from those available observations. For this purpose, a more helpful way of writing the measurement model is</p><formula xml:id="formula_10">ğ‘¦ ğ‘™ğ‘š = ğœ† ğ‘™ğ‘š ğœ ğ‘™ + ğœ€ ğ‘™ğ‘š , ğœ€ ğ‘™ğ‘š âˆ¼ Normal(0, ğœ ğ‘™ğ‘š ),<label>(10)</label></formula><p>which can be combined with Eq. 8 to untangle the latent variance from the error variance. Let us examine the observed variance of some measurement ğ‘¦ 0ğ‘š of ğœ 0 , conditional on observed measurements ğ‘¦ {1,...,ğ¾ }ğ‘š for the latent predictors. For simplicity, and without loss of generality, we take a single measurement per latent variable so the ğ‘š subscript is dropped. This gives us</p><formula xml:id="formula_11">Var ğ‘¦ 0 | ğ‘¦ {1,...,ğ¾ } , ğœ€ {1,...,ğ¾ } = Var [ğœ† 0 ğœ 0 + ğœ€ 0 ] = ğœ† 2 0 Varğœ 0 + ğœ 2 0 (11) = ğœ† 2 0 exp(Î£ ğ¾ ğ‘˜=1 ğ›½ ğ‘˜ ğœ ğ‘˜ ) + ğœ 2 0 = ğœ† 2 0 exp(Î£ ğ¾ ğ‘˜=1 ğ›½ ğ‘˜ (ğ‘¦ ğ‘˜ -ğœ€ ğ‘˜ )/ğœ† ğ‘˜ ) + ğœ 2 0 . (<label>12</label></formula><formula xml:id="formula_12">)</formula><p>The last expression still contains unobserved variables in the form of the error terms ğœ€ {1,...,ğ¾ } , but we can apply the law of iterated expectations to deal with them. We use Eqs. 11 and 12 to work in terms of the latent variance we are interested in:</p><formula xml:id="formula_13">Var ğœ 0 | ğ‘¦ {1,...,ğ¾ } = E ğœ€ Var ğœ 0 | ğ‘¦ {1,...,ğ¾ } , ğœ€ {1,...,ğ¾ } = E ğœ€ exp(Î£ ğ¾ ğ‘˜=1 ğ›½ ğ‘˜ (ğ‘¦ ğ‘˜ -ğœ€ ğ‘˜ )/ğœ† ğ‘˜ ) = exp(Î£ ğ¾ ğ‘˜=1 ğ›½ ğ‘˜ ğ‘¦ ğ‘˜ /ğœ† ğ‘˜ )E ğœ€ exp(-Î£ ğ¾ ğ‘˜=1 ğ›½ ğ‘˜ ğœ€ ğ‘˜ /ğœ† ğ‘˜ ) = exp(Î£ ğ¾ ğ‘˜=1 ğ›½ ğ‘˜ ğ‘¦ ğ‘˜ /ğœ† ğ‘˜ ) exp(Î£ ğ¾ ğ‘˜=1 ğ›½ 2 ğ‘˜ ğœ 2 ğ‘˜ /2ğœ† 2 ğ‘˜ )<label>(13)</label></formula><p>where the last step uses the fact that the expectation of the exp-sum of error terms is equivalent to the product of expectations of independent log-normal random variables. With Eqs. 11 and 13, we can obtain an expression that is analogous to Eq. 9, but fully expressed in terms of observable measurements (common factors are omitted):</p><formula xml:id="formula_14">Var ğ‘¦ 0 | (ğ‘¦ 1 + 1), ğ‘¦ {2,...,ğ¾ } -ğœ 2 0 Var ğ‘¦ 0 | ğ‘¦ 1 , ğ‘¦ {2,...,ğ¾ } -ğœ 2 0 = Var ğœ 0 | (ğ‘¦ 1 + 1), ğ‘¦ {2,...,ğ¾ } Var ğœ 0 | ğ‘¦ 1 , ğ‘¦ {2,...,ğ¾ } = exp(ğ›½ 1 (ğ‘¦ 1 + 1)/ğœ† 1 + Î£ ğ¾ ğ‘˜=2 ğ›½ ğ‘˜ ğ‘¦ ğ‘˜ /ğœ† ğ‘˜ ) exp(ğ›½ 1 ğ‘¦ 1 /ğœ† 1 + Î£ ğ¾ ğ‘˜=2 ğ›½ ğ‘˜ ğ‘¦ ğ‘˜ /ğœ† ğ‘˜ ) = exp(ğ›½ 1 /ğœ† 1 ). (<label>14</label></formula><formula xml:id="formula_15">)</formula><p>Hence, observable changes in the variance of the measurement ğ‘¦ 0 across measurements ğ‘¦ ğ‘˜ of the latent variance predictors provide sufficient information to estimate the coefficients and no additional identification constraints are required because ğœ 2 0 and ğœ† 1 are already identified by the usual constraints on the measurement model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Estimation</head><p>We use Bayesian inference for model fitting. At a high level, the process consists of first specifying a prior distribution (further discussed in the next subsection), which describes our state of knowledge before seeing the data, and combining it with the data-informed model likelihood to obtain a posterior distribution, which represents our updated state of knowledge about the parameters' values. An accessible introduction to Bayesian inference can be found in <ref type="bibr" target="#b29">Johnson, Ott, and Dogucu (2022)</ref>. Calculating the posterior distribution is the main challenge during inference as the expression involves a high-dimensional integral which will not have a closed-form beyond a few special cases; hence, it becomes necessary to resort to numerical methods. We use Markov chain Monte Carlo (MCMC), specifically adaptive Hamiltonian Monte Carlo as implemented in the Stan probabilistic programming language <ref type="bibr" target="#b27">(Hoffman, Gelman, et al., 2014;</ref><ref type="bibr">Stan Development Team, 2023)</ref>. Adaptive HMC is a class of efficient algorithms that can accurately sample complicated parameter spaces and Stan is a well-tested project that is freely available for all major operating systems. All MCMC algorithms produce sequences of samples (known as chains) from the target distribution as its output, which we can then directly use to obtain estimates of parameter means, credibility intervals, transformations, and other quantities of interest <ref type="bibr" target="#b21">(Gelman et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Prior specification</head><p>In the ideal Bayesian workflow, all model parameters are given priors that represent some state of knowledge which will be updated through the likelihood as new data arrives. The purpose of this paper, however, is to investigate the set of conditions under which our approach can produce useful results. Hence, we adopt the minimalist position <ref type="bibr" target="#b22">(Gelman, Simpson, &amp; Betancourt, 2017)</ref> for all simulations, i.e. we attempt to identify the weakest priors for each model that will still produce reliable inferences. The criteria we use to assess reliability are described in Section 3.1 and the specific priors are introduced along with their corresponding models in Section 3.3. Readers looking for practical advice on how to set priors for SEM can find an excellent resource in van Erp (2020) and <ref type="bibr" target="#b62">Winter and Depaoli (2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Simulations</head><p>We investigated the viability of our approach through statistical simulation. Specifically, we tested four structural models that are likely to be relevant for practitioners: a simple two-factor model, a model with mediators, a model with interactions and a model with a sequential structure. The metrics used for assessment are introduced next, followed by a description of the computational setup, and then each model is presented together with the respective results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model diagnostics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Convergence</head><p>While MCMC methods can work well in practice, convergence to a target distribution is an asymptotic property, so it is always necessary to verify convergence empirically <ref type="bibr" target="#b14">(BÃ¼rkner, Scholz, &amp; Radev, 2023)</ref>. This can be achieved by running multiple chains with randomized initial values and then examining whether they exhibit similar distributions; one commonly recommended convergence diagnostic is the potential scale reduction factor R (often just called "Rhat"). Briefly, it compares the variance between and within chains as a proxy for convergence and returns a value in [1, âˆ), where values closer to 1 indicate the chains have more similar distributions. A detailed treatment can be found in <ref type="bibr" target="#b61">Vehtari, Gelman, Simpson, Carpenter, and BÃ¼rkner (2021)</ref>, where they also provide the recommendation to consider R â‰¤ 1.01 as a reliable indicator of convergence. For the purpose of our simulation study, we relaxed the threshold to 1.05, as we have access to the ground truth values and therefore were able to verify that posterior estimates retained acceptable quality up to that point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Calibration</head><p>Convergence alone does not tell us whether our MCMC draws provide a good approximation to the true posterior distribution. However, we can use the draws themselves to diagnose the quality of our approximation if we also have knowledge of the true data-generating distribution; this is the key idea behind Simulation-Based Calibration (SBC; <ref type="bibr" target="#b58">Talts, Betancourt, Simpson, Vehtari, and Gelman, 2020)</ref>. For this method, one samples parameters from the prior which are passed to the likelihood for data generation, the model is then fit over the resulting datasets, and the sum of ranks of the posterior draws relative to the true value is calculated; when a uniform distribution of rank sums is recovered, our posterior is said to be calibrated (explained below). To assess uniformity, we used the graphical tests proposed in SÃ¤ilynoja, BÃ¼rkner, and Vehtari (2022) (see Figure <ref type="figure" target="#fig_0">1</ref>). Calibration in the context of SBC is, strictly speaking, a statement about the expected coverage of posterior intervals over the joint distribution of data and parameters. In practice, this means that it can readily detect posterior approximations that consistently under-/overestimate the location or uncertainty that the true posterior would output for a given parameter; however, it can miss less obvious mismatches and hence does not provide a global guarantee of correctness <ref type="bibr" target="#b42">(ModrÃ¡k et al., 2023)</ref>. Fortunately, the procedure can be augmented with data-dependent quantities to provide a more stringent test; in particular, we also test the model likelihood, which greatly increases the sensitivity of the test as also demonstrated by ModrÃ¡k et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Effective sample size and efficiency</head><p>Even if the model is calibrated and has converged, we only have a finite sample of MCMC draws from the posterior, so we must ensure that the estimation error is small enough to give us reliable inference. It is also necessary to account for the autocorrelation that is often present in the chains as this further reduces their information content; Effective Sample Size (ESS) is a diagnostic that addresses this by estimating the number of independent draws that the information in our chains is equivalent to (Section 11.5, <ref type="bibr" target="#b21">Gelman et al., 2014)</ref>. We consider an ESS of at least 100 per independent MCMC chain to be sufficient for reliable estimation and separately report bulk ESS and tail ESS, as suggested by <ref type="bibr" target="#b61">Vehtari et al. (2021)</ref>. As having a high enough ESS is a prerequisite for accurate inference, a question of practical importance is how long one has to run a model for in order to achieve the desired precision. We calculate ESS per second (ESS/s) as it provides a simple measure of sampling efficiency for each model. However, this will vary considerably depending on the priors used, the data at hand, and the computer one uses to fit the model; the intent here is only to determine whether the models can run in a reasonable time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Parameter recovery</head><p>To evaluate parameter recovery, we use bias and the Root Mean Squared Error (RMSE). Given a set ğœƒ (ğ‘ ) of ğ‘† posterior draws and a true value ğœƒ * , we have</p><formula xml:id="formula_16">Bias = 1 ğ‘† ğ‘† âˆ‘ï¸ ğ‘ =1 ğœƒ (ğ‘ ) -ğœƒ * , (<label>15</label></formula><formula xml:id="formula_17">) RMSE = 1 ğ‘† ğ‘† âˆ‘ï¸ ğ‘ =1 (ğœƒ (ğ‘ ) -ğœƒ * ) 2 . (<label>16</label></formula><formula xml:id="formula_18">)</formula><p>Posterior means will almost surely (in the formal sense) have non-zero bias whenever proper priors are used. However, they are also consistent estimators and we show that, for our models, this leads to the bias being negligible. As bias does not account for posterior uncertainty, we also report RMSE because it provides an overall indication of estimation error by incorporating both posterior bias and variance into a single measure. This relation can be shown explicitly by rearranging Eq. 16:</p><formula xml:id="formula_19">RMSE 2 = 1 ğ‘† ğ‘† âˆ‘ï¸ ğ‘ =1 (ğœƒ (ğ‘ ) -Î¸) 2 Variance + ( Î¸ -ğœƒ * ) 2 Bias 2 , (<label>17</label></formula><formula xml:id="formula_20">)</formula><p>where Î¸ = (1/ğ‘†)Î£ ğ‘† ğ‘ =1 ğœƒ (ğ‘ ) is the posterior mean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Computational setup</head><p>The workflow of our simulation study can be summarized in four key steps:</p><p>1. For each model, we found a relatively tight generative prior distribution, such that parameter vectors drawn from the joint prior could be used to simulate datasets without degeneracies (e.g., without values close to zero for variances or factor loadings) with high probability.</p><p>2. We drew 250 parameter vectors from the generative prior and with each of these, we subsequently generated a dataset of 500 observations from the model likelihood.</p><p>3. We fitted the model twice, using two different priors, for each of the generated datasets: first with the generative prior itself and second with a much wider, weakly informative prior.</p><p>4. Finally, we processed the resulting posterior samples to obtain model diagnostics in the following manner:</p><p>â€¢ Convergence was examined in both sets of models. Below, we only report convergence for the models with the weakly informative prior, as convergence for the models with the generative prior was always superior (see Appendix A).</p><p>â€¢ Calibration was assessed on the models that used the generative prior, because only there SBC is valid.</p><p>â€¢ Metrics for parameter recovery and sampling efficiency were calculated from the models with the weakly informative prior. We excluded models with any R &gt; 1.05 from this calculation to avoid artefacts caused by clear non-convergence.</p><p>Our simulations were fully implemented using the R programming language (R Core Team, 2023). We specified our models in the brms package <ref type="bibr" target="#b10">(BÃ¼rkner, 2017)</ref>, which provides a user-friendly interface for generation of Stan code, and wraps the cmdstanr and posterior packages, which respectively provide functions for interfacing with Stan itself and for extracting model diagnostics <ref type="bibr" target="#b13">(BÃ¼rkner, Gabry, Kay, &amp; Vehtari, 2023;</ref><ref type="bibr" target="#b20">Gabry, ÄŒeÅ¡novar, &amp; Johnson, 2023)</ref>. Functions needed for dataset generation, linking true parameter values to specific fits and plotting calibration diagnostics were provided by the SBC package <ref type="bibr" target="#b31">(Kim, Moon, ModrÃ¡k, &amp; SÃ¤ilynoja, 2023)</ref>. To facilitate reproducibility, the simulation pipeline itself was built to run via the targets package <ref type="bibr" target="#b34">(Landau, 2021)</ref>. The full code is available at an online repository.1 The complete pipeline was run on a MacBook Pro with M2 chip, where it took approximately 42 hours to complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>To aid visualisation of the models that follow, we introduce a novel graphical representation to complement the previously established notation. As our models allow the mean (ğœ‡) and standard deviation (ğœ) of a latent variable distribution to be independently influenced by other latent variables, we extend the usual path diagram notation to show both of these parameters explicitly.</p><p>The diagram for a single latent variable with a five-item measurement model is shown in Figure <ref type="figure">2</ref>. This corresponds to the following statistical model:</p><formula xml:id="formula_21">ğœ 1 âˆ¼ Normal(ğœ‡ 1 , ğœ 1 ) ğ‘¦ 1ğ‘šğ‘– âˆ¼ Normal(ğœ† 1ğ‘š ğœ 1ğ‘– , ğœ 1ğ‘š ),<label>(18)</label></formula><p>with ğ‘š âˆˆ {1, . . . , 5} and ğœ† 11 = 1 for identification. All the models in this section use five items per latent variable and a unit factor loading identification constraint, as in the example above. For brevity, we omit the measurement models in the descriptions that follow.</p><p>1See the folder simulation-study at <ref type="url" target="https://github.com/bdlvm-project/gdsem-paper">https://github.com/bdlvm-project/gdsem-paper</ref> </p><formula xml:id="formula_22">ğœ‡ ğœ ğœ 1 ğ‘¦ 1 1 ğ‘¦ 1 2 ğ‘¦ 1 3 ğ‘¦ 1 4 ğ‘¦ 1 5 1</formula><p>Figure <ref type="figure">2</ref>: Extended path diagram notation which explicitly shows the parameters (ğœ‡ and ğœ) that determine the latent variable's distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Two-factor model</head><p>We start with a two-factor model as this is the simplest setup where we can have a latent variance that is conditional on the value of another latent variable. The mathematical notation for the model is</p><formula xml:id="formula_23">ğœ 1 âˆ¼ Normal(0, ğœ 1 ) ğœ 2 âˆ¼ Normal(ğœ‡ 2 , ğœ 2 ) ğœ‡ 2 = ğ›½ 1ğœ‡ 2 ğœ 1 log ğœ 2 = ğ›½ 0ğœ 2 + ğ›½ 1ğœ 2 ğœ 1 . (19)</formula><p>The path diagram representation is shown in Figure <ref type="figure">3</ref>. The priors used for generation and fitting are described in Table <ref type="table" target="#tab_1">1</ref>.</p><formula xml:id="formula_24">ğœ‡ ğœ ğœ 1 ğœ‡ ğœ ğœ 2</formula><p>Figure <ref type="figure">3</ref>: Two-factor model. ğœ 1 influences both the mean and standard deviation of ğœ 2 .</p><p>The calibration plots in Figure <ref type="figure" target="#fig_1">4a</ref> show that all model parameters and the log-likelihood are well-calibrated. </p><formula xml:id="formula_25">Î² Î¼ Î² 0Ïƒ Î² 1Ïƒ Î» Ï„</formula><p>Log-likelihood 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . The heatmap in Figure <ref type="figure" target="#fig_1">4b</ref> shows that about two-thirds of the simulations produced estimates with R between 1.00 and 1.01. Factor loadings (ğœ†) appear to be the parameters most likely to present suboptimal convergence but major problems are rare, with only two simulations having R &gt; 1.05. We did not find any feature of the simulations that distinctly explained the variation in R which suggests it is primarily caused by variations in the random initializations of parameter values. Such occasional convergence issues are known to occur when fitting Bayesian SEMs in general so attempting to refit with a different seed is an advisable first step.2. Finally, our parameter recovery plots (Figure <ref type="figure" target="#fig_1">4c</ref>) show that bias is negligible across all model parameters. The values for RMSE need to be interpreted in the context of each parameter's relevant scale: for the slope on the standard deviation ğ›½ 1ğœ , the parameter we are most interested in, an RMSE of 0.05 is low enough to expect that the model can be usefully employed to obtain directional estimates. This result is encouraging given that it comes from datasets with only 500 observations; studies with a larger sample size would be able to produce even more precise inferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Mediation model</head><p>One common use of SEM is mediation analysis, which allows researchers to quantify direct and indirect effects for a given variable. We show that our approach allows investigating mediation for effects on both means and standard deviations by fitting the following model:</p><formula xml:id="formula_26">ğœ 1 âˆ¼ Normal(0, ğœ 1 ) ğœ 2 âˆ¼ Normal(ğœ‡ 2 , ğœ 2 ) ğœ‡ 2 = ğ›½ 1ğœ‡ 2 ğœ 1 log ğœ 2 = ğ›½ 0ğœ 2 + ğ›½ 1ğœ 2 ğœ 1 ğœ 3 âˆ¼ Normal(ğœ‡ 3 , ğœ 3 ) ğœ‡ 3 = ğ›½ 1ğœ‡ 3 ğœ 1 log ğœ 3 = ğ›½ 0ğœ 3 + ğ›½ 1ğœ 3 ğœ 1 ğœ 4 âˆ¼ Normal(ğœ‡ 4 , ğœ 4 ) ğœ‡ 4 = ğ›½ 1ğœ‡ 4 ğœ 1 + ğ›½ 2ğœ‡ 4 ğœ 2 log ğœ 4 = ğ›½ 0ğœ 4 + ğ›½ 1ğœ 4 ğœ 1 + ğ›½ 2ğœ 4 ğœ 3 . (20)</formula><p>Here, ğœ 1 has a direct effect on the ğœ‡ and ğœ for ğœ 2 , ğœ 3 , and ğœ 4 . Additionally, it has an indirect effect on ğœ‡ of ğœ 4 through ğœ 2 and an indirect effect on ğœ of ğœ 4 through ğœ 3 . The path diagram is shown in Figure <ref type="figure">5</ref>. Priors for this model are shown in Table <ref type="table" target="#tab_2">2</ref>.</p><p>2For instance, this is also recommended in the documentation for Bayesian SEM package blavaan. The calibration plots in Figure <ref type="figure" target="#fig_2">6a</ref> show good calibration across all test quantities. Convergence in Figure <ref type="figure" target="#fig_2">6b</ref> again appears to be good in general; there are 17 simulations with R &gt; 1.05, but we traced these cases back to generated datasets that produced very small variances in ğœ 3 , which led to unstable estimates for factor loadings and error variances. We verified that refitting these cases with a different initialization was sufficient to resolve the issue (results not shown).</p><formula xml:id="formula_27">Î² Î¼ Î² 0Ïƒ Î² â‰¥1Ïƒ Î» Ï„</formula><p>Log-likelihood 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . Results for parameter recovery in Figure <ref type="figure" target="#fig_2">6c</ref> show no significant bias and RMSE is only slightly increased for all slopes (on both ğœ‡ and ğœ) in the model compared to the previous two-factor model. This is an expected consequence of including mediators in the model, as having multiple paths for a given effect widens the range of coefficient values that are compatible with the data. In general, assessing mediation imposes increases in sample size and methodological complexity <ref type="bibr" target="#b47">(Montoya, 2023;</ref><ref type="bibr" target="#b55">Rohrer, HÃ¼nermund, Arslan, &amp; Elson, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Interaction model</head><p>We have mentioned in the Introduction that the ability to study moderation in general is a feature of interest for users of SEM frameworks. Our approach was created with the intent of providing more flexible models for moderation on latent variances, but we found that it can also accommodate moderation on structural paths with ease, since it can be represented through interactions between variables on the same linear predictor. We show this by fitting the moderation model depicted in Figure <ref type="figure" target="#fig_4">8</ref>, mathematically expressed as:</p><formula xml:id="formula_28">ğœ 1 âˆ¼ Normal(0, ğœ 1 ) ğœ 2 âˆ¼ Normal(0, ğœ 2 ) ğœ 3 âˆ¼ Normal(0, ğœ 3 ) ğœ 4 âˆ¼ Normal(ğœ‡ 4 , ğœ 4 ) ğœ‡ 4 = ğ›½ 1ğœ‡ 4 ğœ 1 + ğ›½ 2ğœ‡ 4 ğœ 1 ğœ 2 log ğœ 4 = ğ›½ 0ğœ 4 + ğ›½ 1ğœ 4 ğœ 1 + ğ›½ 2ğœ 4 ğœ 1 ğœ 3 . (21) Î² Î¼ Î² 0Ïƒ Î² â‰¥1Ïƒ Î» Ï„</formula><p>Log-likelihood 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . The priors used to fit this model are given in Table <ref type="table" target="#tab_3">3</ref>  The results in Figure <ref type="figure" target="#fig_3">7</ref> show that the model is well-calibrated and has good convergence overall. Parameter recovery is in line with the previous models, showing no evidence of bias as well as low RMSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Sequential model</head><p>Model structures that contain longer sequences of latent variables can be relevant in studies that involve measurements over time <ref type="bibr" target="#b2">(Asparouhov, Hamaker, &amp; MuthÃ©n, 2018)</ref>  study detailed causal structures <ref type="bibr" target="#b64">(Zugna et al., 2022)</ref>. A thorough investigation of models in that space is well beyond the scope of this paper, but we considered it relevant to at least explore whether issues with our approach could become apparent only when fitting a longer sequence of dependencies between latent variables. The model we constructed additionally shows that transformations of latent variables are also supported in this approach (Figure <ref type="figure">9</ref>). Using mathematical notation:</p><formula xml:id="formula_29">ğœ 1 âˆ¼ Normal(0, ğœ 1 ) ğœ ğ‘— âˆ¼ Normal(ğœ‡ ğ‘— , ğœ ğ‘— ) ğœ‡ ğ‘— = ğ›½ 1ğœ‡ ğ‘— ğœ ğ‘—-1 log ğœ ğ‘— = ğ›½ 0ğœ ğ‘— + ğ›½ 1ğœ ğ‘— ğœ 2 ğ‘—-1 ,<label>(22)</label></formula><p>where ğ‘— âˆˆ {2, 3, 4, 5} for this case. Model priors are shown in Table <ref type="table" target="#tab_4">4</ref>.</p><formula xml:id="formula_30">ğœ‡ ğœ ğœ 1 ğœ‡ ğœ ğœ 5 ğœ‡ ğœ ğœ 2 ğœ‡ ğœ ğœ 4 ğœ‡ ğœ ğœ 3 ğœ 2 1 ğœ 2 2 ğœ 2 3 ğœ 2 4 Figure 9: Sequential model.</formula><p>Readers familiar with time series may note that setting an equality constraint on the coefficients would give the form of an autoregressive model, but testing this for lengths of time series representative of real applications would involve computational challenges that we do not aim to tackle here.</p><formula xml:id="formula_31">Î² Î¼ Î² 0Ïƒ Î² â‰¥1Ïƒ Î» Ï„</formula><p>Log-likelihood 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . 7 5 1 . 0 0 0 . 0 0 0 . 2 5 0 . 5 0 0 . The sequential structure of this model meant that, for certain parameter draws from the generative prior, there was a runaway increase in latent variance. Therefore, we had to drop one out of the 250 datasets due to overflowing variances which caused numerical errors. Similarly to the mediation model, there were also 18 datasets with unrealistic values for the variance parameters, which is reflected as a larger fraction of models with convergence issues in Figure <ref type="figure" target="#fig_5">10</ref>. Nonetheless, calibration for this model was good, the vast majority of simulations converged well, and estimates don't show any major sign of bias. We did note a longer tail of high-RMSE estimates for the ğ›½ â‰¥1ğœ coefficients, but the bulk of simulations remained at levels comparable to the previously tested models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5">Comparing ESS</head><p>All the diagnostics discussed so far are based on a finite amount of samples drawn from the posterior and so, in principle, are subject to estimation error. The left side of Figure <ref type="figure" target="#fig_6">11</ref> shows that across all models and parameters, the resulting ESS was well above the recommended threshold of 100 samples per chain, both for bulk and tail estimates, which establishes that our sample-based diagnostics are providing reliable information. On the top right side of Figure <ref type="figure" target="#fig_6">11</ref> we depict the ESS per second, which is a measure of the sampling efficiency of our models. As expected, increasing the number of latent variables in the model generally leads to decreases in sampling efficiency. Available alternatives for SEM based on marginal likelihoods do not allow latent moderation to be modeled with the same degree of flexibility as our approach, so a direct comparison cannot be made, but we consider that our conditional likelihood models are sufficiently fast for practical everyday use: the lower right corner of Figure <ref type="figure" target="#fig_6">11</ref> shows that the vast majority of models took less than a minute to fit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Case study</head><p>We sought to address a substantively relevant research question using dataset from a real study in order to demonstrate the usefulness and flexibility of our model. We reached out to the authors of <ref type="bibr" target="#b37">Mader, Arslan, Schmukle, and Rohrer (2023)</ref>, as their paper investigates the association between neuroticism and intra-person variation in negative affect, both of which can be conceptualized as latent variables.</p><p>A key finding of Mader et al. is that floor effects must be accounted for to reliably detect the neuroticism-emotional variability association. They used a hierarchical distributional regression model, where each individual's mean negative affect score was treated as a censored outcome and both its mean and variance were regressed against their mean neuroticism score. This is already quite an advanced model, but it has some shortcomings as it ignores the uncertainty in the score means and assumes every item should be weighted equally. However, methods available at the time would not have allowed to properly model the latent nature of neuroticism and negative affect while simultaneously estimating how one affects the variability of the other. One of the authors kindly provided us with access to a subset of the Goettingen Ovulatory Cycle Diaries 2 dataset.3 The recruitment and data collection process is described in <ref type="bibr" target="#b1">Arslan, Reitz, Driebe, Gerlach, and Penke (2021)</ref>. Briefly, women filled out a form upon recruitment, which included a personality questionnaire, and were subsequently invited to fill out an online diary every day for 70 days, which included items on loneliness, irritability, self-esteem, stress and mood. We used this set of items as measurements for the emotional affect construct and the personality items in the initial questionnaire for the neuroticism construct. The study used a planned missingness design, which allows us to drop all incomplete observations without risk of bias. This leaves a total of 1039 women, each observed between 1 and 11 times (mean: 2.5).</p><p>We aim to follow the model given in <ref type="bibr" target="#b37">Mader et al. (2023)</ref> as closely as possible. Therefore, we consider item responses at the extremes of the scale as censored and use a hierarchical structure to account for the repeated within-person observations. Abbreviating neuroticism as Ne and emotional affect as Em, our model can be notationally expressed as </p><formula xml:id="formula_32">= ï£± ï£´ ï£´ ï£´ ï£² ï£´ ï£´ ï£´ ï£³ 0 ğ‘¦ * Em,ğ‘š,ğ‘–, ğ‘— â‰¤ 0 ğ‘¦ * Em,ğ‘š,ğ‘–, ğ‘— 0 &lt; ğ‘¦ * Em,ğ‘š,ğ‘–, ğ‘— &lt; 4 4 4 â‰¤ ğ‘¦ * Em,ğ‘š,ğ‘–, ğ‘—<label>(23)</label></formula><p>where ğ‘– indexes individual participants, ğ‘— indexes their responses over the study duration, ğ‘› âˆˆ {1, . . . , 8} indexes the items measuring neuroticism, ğ‘š âˆˆ {1, . . . , 5} indexes the items measuring emotional affect, ğ›¾ represents person-specific random intercepts, and ğ‘¦ represents the observed (censored) responses to the questionnaires. The corresponding path diagram is shown in Figure <ref type="figure" target="#fig_0">12</ref>.</p><p>To obtain an identified model, we set ğœ‡ Ne = ğ›½ 0ğœ‡ Em = 0 and ğœ Ne = ğœ† Em,1 = 1. We chose the variance identification constraints pragmatically by fitting each latent variable in a separate model under each possible choice of constraint and picking the one which resulted in higher ESS for the remaining parameters, but in general one should also keep in mind the way constraints interact with priors <ref type="bibr" target="#b23">(Graves &amp; Merkle, 2021)</ref>. We fit the model using weakly informative priors for all parameters as described in This case study illustrates how our approach opens the door for more truthful modeling of measurement processes. The results show that the latent parameters can be well-estimated even as part of a more complex model structure. Furthermore, the implementation cost of adding censoring and varying intercepts for this analysis was essentially negligible as these features were already available in the brms package. This extensibility arises from the underlying conditional likelihood formulation of the latent variable model and it should offer more flexibility for researchers who wish to build sophisticated models without the need to develop distinct, SEM-specific implementations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this article, we developed a Gaussian distributional SEM framework for flexible estimation of latent variable models that include latent moderators of both latent means and latent variances. We achieved this by using a Bayesian framework, which confirms the suggestion put forward by de <ref type="bibr" target="#b17">Kort et al. (2017)</ref> that Bayesian estimation should be a viable approach for handling latent heteroscedasticity within more complex model structures.</p><p>Our simulation study used four distinct model structures to test the reliability of the estimates obtained through the conditional likelihood approach. Although our results show that all model parameters were well-calibrated, we wish to emphasize that the SBC procedure only provides information for the parameter region covered by the generative prior, and the ones we used were relatively narrow. We did not systematically investigate wider generative priors because they produced datasets with unrealistic properties and, as a result, lead to convergence issues too often to be reliably fitted. However, we did employ weakly informative priors for the assessment of convergence and parameter recovery with favorable results. Therefore, we anticipate our framework to function well across a broad range of prior specifications. That said, it is highly recommended that users employ prior predictive checks to ensure the appropriateness of their choices in any particular analysis <ref type="bibr" target="#b62">(Winter and Depaoli, 2023</ref> provide a practical illustration of this technique in the specific context of SEM).</p><p>One important practical consideration that we did not address here is the impact of model misspecification on the resulting inferences. Results from de <ref type="bibr" target="#b17">Kort et al. (2017)</ref> show that biased estimates will be obtained in situations where heteroscedasticity and nonlinearity are simultaneously present. Given that the model examined by de Kort et al. can be seen as a special case of the structures we have considered here, we expect the same caveats to carry over. For future research, the analogy with distributional regression directly suggests the possibility of using conditional likelihood SEMs to explore non-Gaussian distributions for latent variables, including the specification of moderators on distributional parameters beyond the variance. As mentioned above, we also faced the challenge of specifying sensible generative priors while designing our simulation study. It has already been highlighted by <ref type="bibr" target="#b39">Merkle, Ariyo, Winter, and Garnier-Villarreal (2023)</ref> that the default approach of using non-informative priors implies data-generating processes that are incompatible with the patterns that would motivate using SEM in the first place. However, during model validation (e.g., when performing SBC) one would also like to cover as much of the parameter space as possible. Therefore, a relevant direction may be to move away from the usual approach of specifying priors on each individual model parameter and instead explore methods that use information expressed on more intuitive scales to construct the implied prior on the parameter scale (e.g., <ref type="bibr" target="#b0">Aguilar and BÃ¼rkner, 2023;</ref><ref type="bibr" target="#b8">Bockting, Radev, and BÃ¼rkner, 2023)</ref>. Another possibility that we recently became aware of is to keep non-informative priors while simultaneously introducing imaginary data in order to produce an updated prior (for an overview of the approach see Ibrahim, Chen, Gwon, and Chen, 2015; we demonstrate an application to SEM in <ref type="bibr" target="#b19">Fazio, Scholz, and BÃ¼rkner, 2024)</ref>.</p><p>Finally, while we have shown that the performance of our Gaussian distributional SEMs is sufficient for practical everyday applications, there is certainly room for further optimization. For this paper we used the brms-generated Stan code as-is, but we are aware that applying a non-centered parametrization <ref type="bibr" target="#b51">(Papaspiliopoulos, Roberts, &amp; SkÃ¶ld, 2007)</ref> to the latent variables leads to noticeable performance gains, so it would be helpful to implement this as an option in brms itself. Alternatively, variational approximations can be used in place of MCMC for fast posterior estimation. Initial results for SEM estimation have been encouraging <ref type="bibr" target="#b16">(Dang &amp; Maestrini, 2022)</ref> but the statistical performance of these approximate methods still needs to be studied in a wider range of scenarios. Another promising set of approaches are those from the field of simulation-based inference, in particular, machine learning-based methods of posterior estimation and amortized inference <ref type="bibr" target="#b15">(Cranmer, Brehmer, &amp; Louppe, 2020;</ref><ref type="bibr" target="#b53">Radev, Mertens, Voss, Ardizzone, &amp; Kothe, 2022;</ref><ref type="bibr" target="#b63">Zammit-Mangion, Sainsbury-Dale, &amp; Huser, 2024)</ref>. These techniques offer much faster inference-time results at the upfront cost of an initial training phase, but we have not found works that show their specific application to SEM estimation at this time. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Simulation-based rank histograms (top) and corresponding empirical cumulative distribution function (ECDF) difference plots (bottom) for three hypothetical quantities of interest. The blue areas in the ECDF difference plots indicate 95%-confidence bands under the assumptions of uniformity and thus allow for a null-hypothesis significance test of self-consistent calibration. Left: A well-calibrated quantity. Center: A miscalibrated quantity with too many lower ranks indicating a positive bias in the estimated posteriors. Right: A miscalibrated quantity with too many extreme ranks indicating overconfident posteriors (i.e., variance underestimated).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Simulation diagnostics for the two-factor model. (a) ECDF difference plots. Curves are overlaid when there are multiple parameters of the same type. (b) Heatmap showing the average R for each parameter type in each simulation. Simulations are arranged in ascending order across the x-axis according to their overall mean R. (c) Box plots of the error distribution for average bias and average RMSE per simulation and parameter type. Simulations with convergence issues (any parameter with R &gt; 1.05) were excluded. 14</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Simulation diagnostics for the mediation model. (a) ECDF difference plots. Curves are overlaid when there are multiple parameters of the same type. (b) Heatmap showing the average R for each parameter type in each simulation. Simulations are arranged in ascending order across the x-axis according to their overall mean R. (c) Box plots of the error distribution for average bias and average RMSE per simulation and parameter type. Simulations with convergence issues (any parameter with R &gt; 1.05) were excluded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Simulation diagnostics for the interaction model. (a) ECDF difference plots. Curves are overlaid when there are multiple parameters of the same type. (b) Heatmap showing the average R for each parameter type in each simulation. Simulations are arranged in ascending order across the x-axis according to their overall mean R. (c) Box plots of the error distribution for average bias and average RMSE per simulation and parameter type. Simulations with convergence issues (any parameter with R &gt; 1.05) were excluded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Interaction model. Dashed lines represent deterministic transformations; in this case, taking the product of two latent variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Simulation diagnostics for the sequential model. (a) ECDF difference plots. Curves are overlaid when there are multiple parameters of the same type. (b) Heatmap showing the average R for each parameter type in each simulation. Simulations are arranged in ascending order across the x-axis according to their overall mean R. (c) Box plots of the error distribution for average bias and average RMSE per simulation and parameter type. Simulations with convergence issues (any parameter with R &gt; 1.05) were excluded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Top two plots show the distribution of average effective sample size (ESS) and average ESS per second over all simulations, after excluding those with convergence issues (any parameter with R &gt; 1.05). Lower right corner is the distribution of wall time of those simulations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure A.1: Convergence and parameter recovery results for fits with the generative prior.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Let us set ğœ½ ğœ» = (ğ›½ 1ğœ‡ 1 , . . . , ğ›½ ğ¾ ğœ‡ ğ¿ , ğ›½ 1ğœ 1 , . . . , ğ›½ ğ¾ğœ ğ¿ ) to denote the vector of structural parameters and ğœ½ y = (ğœˆ 11 , . . . , ğœˆ ğ¿ ğ‘€ , ğœ† 11 , . . . , ğœ† ğ¿ ğ‘€ , ğœ 11 , . . . , ğœ ğ¿ ğ‘€ ) to denote the vector of measurement model parameters. Then, the full likelihood can be written as ğ‘(y, ğœ» | ğœ½ ğœ» , ğœ½ y ).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Prior specifications for the two-factor model.</figDesc><table><row><cell>Parameter type</cell><cell>Notation</cell><cell>Generative prior</cell><cell>Weakly informative prior</cell></row><row><cell>Latent mean</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Slope</cell><cell>ğ›½ 1ğœ‡ 2</cell><cell>Normal(1, 0.3)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Latent std. dev.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Initial</cell><cell>ğœ 1</cell><cell>Gamma [0.7,âˆ) (11, 11)</cell><cell>Gamma(5, 5)</cell></row><row><cell>Intercept</cell><cell>ğ›½ 0ğœ 2</cell><cell>Exp-Gamma(11, 11)</cell><cell>Exp-Gamma(5, 5)</cell></row><row><cell>Slope</cell><cell>ğ›½ 1ğœ 2</cell><cell>Normal(0.15, 0.05)</cell><cell>Normal(0, 0.5)</cell></row><row><cell>Item parameters</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Factor loadings</cell><cell>ğœ†</cell><cell>Normal(1, 0.3)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Error std. dev.</cell><cell>ğœ</cell><cell>Normal [0.3,âˆ) (0.5, 0.15)</cell><cell>Gamma(2.5, 5)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Prior specifications for the mediation model.</figDesc><table><row><cell>Parameter type</cell><cell>Notation</cell><cell>Generative prior</cell><cell>Weakly informative prior</cell></row><row><cell>Latent mean</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Slope</cell><cell>ğ›½ â‰¥1ğœ‡</cell><cell>Normal(1, 0.3)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Latent std. dev.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Initial</cell><cell>ğœ 1</cell><cell>Gamma [0.7,âˆ) (11, 11)</cell><cell>Gamma(5, 5)</cell></row><row><cell>Intercept</cell><cell>ğ›½ 0ğœ 2 , ğ›½ 0ğœ 3 , ğ›½ 0ğœ 4</cell><cell>Exp-Gamma(11, 11)</cell><cell>Exp-Gamma(5, 5)</cell></row><row><cell>Slope</cell><cell>ğ›½ 1ğœ 2 , ğ›½ 1ğœ 3 , ğ›½ 2ğœ 4 ğ›½ 1ğœ 4</cell><cell>Normal(-0.15, 0.05) Normal(0.15, 0.05)</cell><cell>Normal(0, 0.5)</cell></row><row><cell>Item parameters</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Factor loadings</cell><cell>ğœ†</cell><cell>Normal(1, 0.3)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Error std. dev.</cell><cell>ğœ</cell><cell>Normal [0.3,âˆ) (0.5, 0.15)</cell><cell>Gamma(2.5, 5)</cell></row><row><cell></cell><cell></cell><cell>ğœ‡ ğœ</cell><cell></cell></row><row><cell></cell><cell></cell><cell>ğœ 3</cell><cell></cell></row><row><cell></cell><cell>ğœ‡ ğœ</cell><cell>ğœ‡ ğœ</cell><cell></cell></row><row><cell></cell><cell>ğœ 1</cell><cell>ğœ 4</cell><cell></cell></row><row><cell></cell><cell></cell><cell>ğœ‡ ğœ</cell><cell></cell></row><row><cell></cell><cell></cell><cell>ğœ 2</cell><cell></cell></row></table><note><p>Figure 5: Mediation model. ğœ 1 has direct and indirect effects on both of ğœ 4 's parameters.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>. Prior specifications for the interaction model.</figDesc><table><row><cell>Parameter type</cell><cell>Notation</cell><cell cols="2">Generative prior</cell><cell>Weakly informative prior</cell></row><row><cell>Latent mean</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Slope</cell><cell>ğ›½ 1ğœ‡ 4 ğ›½ 2ğœ‡ 4</cell><cell cols="2">Normal(1, 0.3) Normal(0.5, 0.3)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Latent std. dev.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Initial</cell><cell>ğœ 1 , ğœ 2 , ğœ 3</cell><cell cols="2">Gamma [0.7,âˆ) (11, 11)</cell><cell>Gamma(5, 5)</cell></row><row><cell>Intercept</cell><cell>ğ›½ 0ğœ 4</cell><cell cols="2">Exp-Gamma(11, 11)</cell><cell>Exp-Gamma(5, 5)</cell></row><row><cell>Slope</cell><cell>ğ›½ 1ğœ 4 ğ›½ 2ğœ 4</cell><cell cols="2">Normal(0.1, 0.05) Normal(0.05, 0.05)</cell><cell>Normal(0, 0.5)</cell></row><row><cell>Item parameters</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Factor loadings</cell><cell>ğœ†</cell><cell></cell><cell>Normal(1, 0.3)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Error std. dev.</cell><cell>ğœ</cell><cell cols="2">Normal [0.3,âˆ) (0.5, 0.15)</cell><cell>Gamma(2.5, 5)</cell></row><row><cell></cell><cell>ğœ‡ ğœ</cell><cell></cell><cell cols="2">ğœ‡ ğœ</cell></row><row><cell></cell><cell>ğœ 2</cell><cell></cell><cell>ğœ 3</cell></row><row><cell></cell><cell></cell><cell>ğœ 1 ğœ 2</cell><cell>ğœ 1 ğœ 3</cell></row><row><cell></cell><cell>ğœ‡ ğœ</cell><cell></cell><cell cols="2">ğœ‡ ğœ</cell></row><row><cell></cell><cell>ğœ 1</cell><cell></cell><cell>ğœ 4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>or in those which seek to Prior specifications for the sequential model.</figDesc><table><row><cell>Parameter type</cell><cell>Notation</cell><cell>Generative prior</cell><cell>Weakly informative prior</cell></row><row><cell>Latent mean</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Slope</cell><cell>ğ›½ 1ğœ‡</cell><cell>Normal(0, 0.2)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Latent std. dev.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Intercept</cell><cell>ğ›½ 0ğœ 1</cell><cell>Gamma [0.7,âˆ) (11, 11)</cell><cell>Gamma(5, 5)</cell></row><row><cell>Intercept</cell><cell>ğ›½ 0ğœ â‰¥2</cell><cell>Exp-Gamma(11, 11)</cell><cell>Exp-Gamma(5, 5)</cell></row><row><cell>Slope</cell><cell>ğ›½ 1ğœ</cell><cell>Normal(0, 0.05)</cell><cell>Normal(0, 0.5)</cell></row><row><cell>Item parameters</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Factor loadings</cell><cell>ğœ†</cell><cell>Normal(1, 0.3)</cell><cell>Normal(0, 2.5)</cell></row><row><cell>Error std. dev.</cell><cell>ğœ</cell><cell>Normal [0.3,âˆ) (0.5, 0.15)</cell><cell>Gamma(2.5, 5)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>ğœ Ne,ğ‘– âˆ¼ Normal(ğœ‡ Ne , ğœ Ne ) ğœ Em,ğ‘–, ğ‘— âˆ¼ Normal(ğœ‡ Em,ğ‘– , ğœ Em,ğ‘– ) ğœ‡ Em,ğ‘– = ğ›½ 0ğœ‡ Em + ğ›½ 1ğœ‡ Em ğœ Ne,ğ‘– + ğ›¾ ğœ‡ Em ,ğ‘– log ğœ Em,ğ‘– = ğ›½ 0ğœ Em + ğ›½ 1ğœ Em ğœ Ne,ğ‘– + ğ›¾ ğœ Em ,ğ‘– ğ›¾ ğœ‡ Em ,ğ‘– âˆ¼ Normal(0, ğœ ğœ‡ Em ) ğ›¾ ğœ Em ,ğ‘– âˆ¼ Normal(0, ğœ ğœ Em ) ğ‘¦ * Ne,ğ‘›,ğ‘– âˆ¼ Normal(ğœˆ Ne,ğ‘› + ğœ† Ne,ğ‘› ğœ Ne,ğ‘– , ğœ Ne,ğ‘› ) ğ‘— âˆ¼ Normal(ğœˆ Em,ğ‘š + ğœ† Em,ğ‘š ğœ Em,ğ‘–, ğ‘— , ğœ Em,ğ‘š )</figDesc><table><row><cell>ğ‘¦ Ne,ğ‘›,ğ‘– =</cell><cell>ï£± ï£´ ï£´ ï£´ ï£²</cell><cell cols="2">1 ğ‘¦  *  Ne,ğ‘›,ğ‘– 1 &lt; ğ‘¦  *  ğ‘¦  *  Ne,ğ‘›,ğ‘– â‰¤ 1 Ne,ğ‘›,ğ‘– &lt; 5</cell></row><row><cell>ğ‘¦  *  Em,ğ‘š,ğ‘–,</cell><cell>ï£´ ï£´ ï£´ ï£³</cell><cell>5</cell><cell>5 â‰¤ ğ‘¦  *  Ne,ğ‘›,ğ‘–</cell></row></table><note><p>3Codebook available at https://rubenarslan.github.io/gocd2/ ğ‘¦ Em,ğ‘š,ğ‘–, ğ‘—</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>table 5 .</head><label>5</label><figDesc>It was implemented using the brms package and code is available online.4 Posterior means and credible intervals are shown in Figure13. The key parameter of interest ğ›½ ğœ was well-estimated with an Rhat of 1.00 and ESS above 1200 for bulk and tail, and had a posterior mean of 0.11 with a [0.05, 0.18] 95% credible interval; this is consistent with<ref type="bibr" target="#b37">Mader et al. (2023)</ref>, which pooled 13 studies to produce an estimate of 0.10 [0.07, 0.13]. Strictly speaking, the parameters cannot be directly compared as the free factor loadings in our model lead to items being weighed differently, but investigating measurement invariance is beyond the scope of this example (however, see<ref type="bibr" target="#b54">Robitzsch and LÃ¼dtke, 2023)</ref>.</figDesc><table><row><cell cols="5">Latent variable parameters</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğ›½ 1ğœ‡ Em</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ ğœ‡ Em</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğ›½ 0ğœ Em</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğ›½ 1ğœ Em</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ ğœ Em</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>-0.2</cell><cell>-0.1</cell><cell>0.0</cell><cell></cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell></row><row><cell cols="3">Item parameters</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,1</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,2</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,3</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,5</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,6</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,7</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Ne,8</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Ne,8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Em,1</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Em,1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Em,2</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Em,2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Em,3</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Em,3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Em,4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Em,4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ğœ† Em,5</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ğœ Em,5</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1.0</cell><cell>1.1</cell><cell>0.50</cell><cell></cell><cell>0.75</cell><cell>1.00</cell><cell>1.25</cell><cell>1.50</cell></row><row><cell cols="11">Figure 13: Posterior means and credible intervals (thick line: 50%, thin line: 95%) for model 23</cell></row></table><note><p>4See the folder case-study at https://github.com/bdlvm-project/gdsem-paper</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research was partially funded by <rs type="funder">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation</rs>) Project <rs type="grantNumber">497785967</rs>. We thank <rs type="person">Timo Stenz</rs> for producing the path diagrams shown in this paper and the anonymous reviewers who provided us with valuable feedback.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_kaTcyYa">
					<idno type="grant-number">497785967</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Intuitive joint priors for Bayesian linear multilevel models: The R2D2M2 prior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<idno type="DOI">10.1214/23-EJS2136</idno>
	</analytic>
	<monogr>
		<title level="j">Electronic Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Routinely randomize potential sources of measurement reactivity to estimate and adjust for biases in subjective reports</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Reitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Driebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Gerlach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Penke</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000294</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic Structural Equation Models</title>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Hamaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>MuthÃ©n</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2017.1406803</idno>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="388" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the Elimination of Nuisance Parameters</title>
		<author>
			<persName><forename type="first">D</forename><surname>Basu</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1977.10481002</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">358</biblScope>
			<biblScope unit="page" from="355" to="366" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A more general model for testing measurement invariance and differential item functioning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bauer</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000077</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="507" to="526" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Psychometric approaches for developing commensurate measures across independent studies: Traditional and new models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Hussong</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0015583</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="125" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A Conceptual Introduction to Hamiltonian Monte Carlo</title>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1701.02434</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Marginal maximum likelihood estimation of item parameters: Application of an EM algorithm</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aitkin</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02293801</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="443" to="459" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Simulation-Based Prior Knowledge Elicitation for Parametric Bayesian Models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bockting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2308.11672</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<title level="m">Structural equations with latent variables</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Brms : An R Package for Bayesian Multilevel Models Using Stan</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v080.i01</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Advanced Bayesian Multilevel Modeling with the R Package brms</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<idno type="DOI">10.32614/RJ-2018-017</idno>
	</analytic>
	<monogr>
		<title level="j">The R Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">395</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bayesian Item Response Modeling in R with brms and Stan</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v100.i05</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="1" to="54" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Posterior: Tools for working with posterior distributions</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Some models are useful, but how do we know which ones? Towards a unified Bayesian model taxonomy</title>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.1214/23-SS145</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics Surveys</title>
		<imprint>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The frontier of simulation-based inference</title>
		<author>
			<persName><forename type="first">K</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Louppe</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1912789117</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="30055" to="30062" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fitting Structural Equation Models via Variational Approximations</title>
		<author>
			<persName><forename type="first">K.-D</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maestrini</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2022.2053857</idno>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="839" to="853" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Studying the Strength of Prediction Using Indirect Mixture Modeling: Nonlinear Latent Regression with Heteroskedastic Residuals</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>De Kort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Lubke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Molenaar</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2016.1250636</idno>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="313" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Fahrmeir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kneib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Marx</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-63882-8</idno>
		<title level="m">Regression: Models, Methods and Applications</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Fazio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<title level="m">Generative Bayesian Modeling with Implicit Priors</title>
		<imprint>
			<date type="published" when="2024-08-12">2024. August 12</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Cmdstanr: R interface to &apos;CmdStan</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>ÄŒeÅ¡novar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>manual</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><surname>Rubin</surname></persName>
		</author>
		<title level="m">Bayesian Data Analysis</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">B</forename></persName>
		</editor>
		<meeting><address><addrLine>Boca Raton, Fla; Taylor &amp; Francis</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The prior can generally only be understood in the context of the likelihood</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<idno type="DOI">10.3390/e19100555</idno>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">555</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A note on identification constraints and information criteria in Bayesian latent variable models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-021-01649-8</idno>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="795" to="804" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Estimating regression models with multiplicative heteroscedasticity. Econometrica</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Harvey</surname></persName>
		</author>
		<idno type="DOI">10.2307/1913974</idno>
	</analytic>
	<monogr>
		<title level="j">journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="461" to="465" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Heteroscedastic one-factor models and marginal maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1348/000711007X248884</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="77" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Exploring Factor Model Parameters across Continuous Variables with Local Structural Equation Models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hildebrandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>LÃ¼dtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robitzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wilhelm</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2016.1142856</idno>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="257" to="258" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1593" to="1623" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1002/sim.6728</idno>
	</analytic>
	<monogr>
		<title level="m">The power prior: Theory and applications</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3724" to="3749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Q</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dogucu</surname></persName>
		</author>
		<idno type="DOI">10.1201/9780429288340</idno>
		<title level="m">Bayes Rules!: An Introduction to Applied Bayesian Modeling</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>st ed.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simultaneous factor analysis in several populations</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>JÃ¶reskog</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02291366</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="409" to="426" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">SBC: Simulation based calibration for rstan/cmdstanr models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>ModrÃ¡k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>SÃ¤ilynoja</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>manual</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation of latent interaction effects with the LMS method</title>
		<author>
			<persName><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moosbrugger</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02296338</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="457" to="474" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Principles and practice of structural equation modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Kline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>The Guilford Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Fourth edition</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The targets R package: A dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Landau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">57</biblScope>
			<biblScope unit="page">2959</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">Structural Equation Modeling: A Bayesian Approach</title>
		<meeting><address><addrLine>Chichester, England; Hoboken, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Measurement invariance in the social sciences: Historical development, methodological challenges, state of the art, and future perspectives</title>
		<author>
			<persName><forename type="first">H</forename><surname>LeitgÃ¶b</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Seddig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Behr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Davidov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>De Roover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.ssresearch.2022.102805</idno>
	</analytic>
	<monogr>
		<title level="j">Social Science Research</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page">102805</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Emotional (in)stability: Neuroticism is associated with increased variability in negative emotion after all</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Schmukle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rohrer</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2212154120</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">2212154120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rast</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-022-09847-9</idno>
	</analytic>
	<monogr>
		<title level="m">The Reliability Factor: Modeling Individual Reliability with Multiple Items from a Single Assessment</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="1318" to="1342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ariyo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garnier-Villarreal</surname></persName>
		</author>
		<title level="m">Opaque prior distributions in Bayesian latent variable models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Efficient Bayesian Structural Equation Modeling in Stan</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fitzsimmons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uanhoro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Goodrich</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v100.i06</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">100</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bayesian Comparison of Latent Variable Models: Conditional Versus Marginal Likelihoods</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Furr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rabe-Hesketh</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-019-09679-0</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="802" to="829" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Simulation-Based Calibration Checking for Bayesian Computation: The Choice of Test Quantities Shapes Sensitivity</title>
		<author>
			<persName><forename type="first">M</forename><surname>ModrÃ¡k</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Huurre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>FaltejskovÃ¡</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Heteroscedastic Latent Trait Models for Dichotomous Data</title>
		<author>
			<persName><forename type="first">D</forename><surname>Molenaar</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-014-9406-0</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="625" to="644" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Modeling Ability Differentiation in the Second-Order Factor Model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Molenaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Van Der Maas</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2011.607095</idno>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="578" to="594" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Testing and modelling non-normality within the one-factor model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Molenaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Verhelst</surname></persName>
		</author>
		<idno type="DOI">10.1348/000711009X456935</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="293" to="317" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Detecting Specific Genotype by Environment Interactions Using Marginal Maximum Likelihood Estimation in the Classical Twin Design</title>
		<author>
			<persName><forename type="first">D</forename><surname>Molenaar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Sluis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Boomsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">V</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10519-011-9522-x</idno>
	</analytic>
	<monogr>
		<title level="j">Behavior Genetics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="483" to="499" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Selecting a Within-or Between-Subject Design for Mediation: Validity, Causality, and Statistical Power</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Montoya</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2022.2077287</idno>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="616" to="636" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1206.1901</idno>
		<title level="m">MCMC using Hamiltonian dynamics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Modelling inter-individual differences in latent within-person variation: The confirmatory factor level variability model</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nestler</surname></persName>
		</author>
		<idno type="DOI">10.1111/bmsp.12196</idno>
	</analytic>
	<monogr>
		<title level="j">The British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="452" to="473" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Consistent Estimates Based on Partially Consistent Observations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Neyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
		<idno type="DOI">10.2307/1914288</idno>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A General Framework for the Parametrization of Hierarchical Models</title>
		<author>
			<persName><forename type="first">O</forename><surname>Papaspiliopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">O</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>SkÃ¶ld</surname></persName>
		</author>
		<idno type="DOI">10.1214/088342307000000014</idno>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing. R Foundation for Statistical Computing</title>
		<author>
			<orgName type="collaboration">R Core Team.</orgName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">BayesFlow: Learning Complex Stochastic Models With Invertible Neural Networks</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">K</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ardizzone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kothe</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2020.3042395</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1452" to="1466" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Why Full, Partial, or Approximate Measurement Invariance Are Not a Prerequisite for Meaningful and Valid Group Comparisons</title>
		<author>
			<persName><forename type="first">A</forename><surname>Robitzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>LÃ¼dtke</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2023.2191292</idno>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="859" to="870" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">That&apos;s a Lot to Process! Pitfalls of Popular Path Models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rohrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>HÃ¼nermund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elson</surname></persName>
		</author>
		<idno type="DOI">10.1177/25152459221095827</idno>
	</analytic>
	<monogr>
		<title level="j">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">251524592210958</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Graphical test for discrete uniformity and its applications in goodness-of-fit evaluation and multiple sample comparison</title>
		<author>
			<persName><forename type="first">T</forename><surname>SÃ¤ilynoja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11222-022-10090-6</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<orgName type="collaboration">Stan Development Team.</orgName>
		</author>
		<title level="m">Stan Modeling Language Users Guide and Reference Manual</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Validating Bayesian Inference Algorithms with Simulation-Based Calibration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Talts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1804.06788</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The influence of multivariate selection on the factorial analysis of ability</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ledermann</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2044-8295.1939.tb00919.x</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="288" to="306" />
			<date type="published" when="1939">1939</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Bayesian structural equation modeling: The power of the prior</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Erp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">Gildeprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Rank-Normalization, Folding, and Localization: An Improved R for Assessing Convergence of MCMC</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>BÃ¼rkner</surname></persName>
		</author>
		<idno type="DOI">10.1214/20-BA1221</idno>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>with Discussion</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Illustrating the Value of Prior Predictive Checking for Bayesian Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2022.2164286</idno>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1000" to="1021" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Zammit-Mangion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sainsbury-Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huser</surname></persName>
		</author>
		<title level="m">Neural Methods for Amortized Inference</title>
		<imprint>
			<date type="published" when="2024-10-10">2024, October 10</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Applied causal inference methods for sequential mediators</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zugna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Fasanelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Heude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Scelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Richiardi</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12874-022-01764-w</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Medical Research Methodology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">301</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
