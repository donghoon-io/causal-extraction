<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Network Topology Inference via Elastic Net Structural Equation Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Panagiotis</forename><forename type="middle">A</forename><surname>Traganitis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of ECE &amp; Digital Technology Center</orgName>
								<orgName type="institution">Univ. of Minnesota</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yanning</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of ECE &amp; Digital Technology Center</orgName>
								<orgName type="institution">Univ. of Minnesota</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Georgios</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
							<email>georgios@umn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of ECE &amp; Digital Technology Center</orgName>
								<orgName type="institution">Univ. of Minnesota</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Network Topology Inference via Elastic Net Structural Equation Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Networks</term>
					<term>Topology inference</term>
					<term>Structural Equation Models</term>
					<term>Elastic Net</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Linear structural equation models (SEMs) have been very successful in identifying the topology of complex graphs, such as those representing social and brain networks. In many cases however, the presence of highly correlated nodes hinders performance of the available SEM estimators that rely on the least-absolute shrinkage and selection operator (LASSO). To this end, an elastic net based SEM is put forth, to infer causal relations between nodes belonging to networks, in the presence of highly correlated data. An efficient algorithm based on the alternating direction method of multipliers (ADMM) is developed, and preliminary tests on synthetic as well as real data demonstrate the effectiveness of the proposed approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Networks have ubiquitous presence in a plethora of disciplines such as sociology, communications and machine learning among others, where their ability to model a multitude of complex systems <ref type="bibr" target="#b17">[18]</ref> has rendered them indispensable. These complex systems may include naturally emerging networks, such as social and communication or power networks, or model-induced ones, employed to simplify the representation of a system, such as brain networks <ref type="bibr" target="#b21">[22]</ref>. Given a graph representation of a network, various tools from graph theory and network science <ref type="bibr" target="#b17">[18]</ref> can be employed to draw inferences from nodal variable dependencies. Examples of such inferences include behavioral prediction of complex systems <ref type="bibr" target="#b12">[13]</ref>, and detection of communities over social or brain graphs <ref type="bibr" target="#b3">[4]</ref>, among others. In addition, many machine learning <ref type="bibr" target="#b1">[2]</ref> and signal processing <ref type="bibr" target="#b22">[23]</ref> tasks can be performed over a graph. All these tasks, however, presume knowledge of the network graph representation. While this information may be naturally available in some networks, such as power or communication networks, in many cases, such as brain networks, it has to be inferred.</p><p>Network topology inference aims to discover the (typically sparse) connectivity between nodes, given only nodal measurements, and thus has practical implications in a multitude of settings. Examples of such applications include discovery of causal links between brain regions, or identifying how contagions spread <ref type="bibr" target="#b0">[1]</ref>. Prior works. Several approaches have been proposed for inferring the topology of networks. Probabilistic models rely Work in this paper was supported by ARO grant W911NF-15-1-0492, and NSF CyberSEES grant 1442686. on maximum likelihood estimation to obtain edge weights <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Structural equation models (SEMs) are simple yet capable of capturing causal relationships <ref type="bibr" target="#b10">[11]</ref>. The basic premise of a SEM is that a node measurement depends linearly on those of its neighbors, plus possibly an additive exogenous input. Linear SEMs have wide applicability in fields as diverse as sociology <ref type="bibr" target="#b6">[7]</ref>, psychometrics <ref type="bibr" target="#b15">[16]</ref> and genetics <ref type="bibr" target="#b2">[3]</ref>, and have recently been employed to track dynamic topologies of social networks <ref type="bibr" target="#b0">[1]</ref>, by leveraging the typically sparse connectivity of a network. In addition, nonlinear SEMs have been advocated to model nonlinear phenomena <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, and also for capturing nonlinear connectivity between pairs of nodes <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>. All aforementioned approaches, however, employ LASSO <ref type="bibr" target="#b9">[10]</ref> type solvers, which tend to ignore multiple edges that arise when data are highly correlated.</p><p>The aim of the present work is to introduce a novel method that enables topology inference of networks by employing an elastic net <ref type="bibr" target="#b23">[24]</ref> solver, that performs well even in scenarios where some of the data are highly correlated. In addition, even when data are not highly correlated, the proposed elastic net SEM performs at least as well as the regular LASSO solver. Notation. Boldface uppercase (lowercase) letters indicate matrices (column vectors). The vector containing the diagonal elements of a matrix is denoted by diag(•), while 0 and 1 denote the all-zeros and all-ones vectors, respectively. Calligraphic uppercase letters denote sets, and |A| represents the cardinality of A. Operators • 2 and • 1 stand for the L 2 -and L 1norms of a vector, respectively, (•) denotes vector and matrix transposition, and tr(•) denotes the trace of a matrix. The matrix operator • 0 denotes the number of nonzero entries of its argument, while Bdiag{X, Y, Z} denotes a block-diagonal matrix, with the matrices X, Y and Z in its diagonal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. NETWORK MODEL AND PROBLEM STATEMENT</head><p>Consider a network consisting of N nodes be modeled as a graph G(V, E), where V is the set of vertices/nodes, with |V| = N , and E is the set of edges between nodes. This graph can be further described using a binary N × N adjacency matrix A whose (i, j)-th entry is given by</p><formula xml:id="formula_0">α ij = 0 if (i, j) ∈ E = 0 otherwise;<label>(1)</label></formula><p>hence, α ij is nonzero if there exists a directed edge between nodes i and j. Accordingly, weights assigned to edges can be captured by an N × N matrix W. Example of possible network topology and its connection with structural equation models <ref type="bibr" target="#b19">[20]</ref>.</p><p>Consider now a process observed over the entire network, with y im denoting the m-th observation at node i. A linear SEM <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref> obeys the relationship</p><formula xml:id="formula_1">y im = j =i α ij y jm + b ii x im + im<label>(2)</label></formula><p>where the m-th observation at node i depends linearly on the corresponding endogenous observations of the neighboring nodes of i, with the addition of a possible exogenous variable x im . Here, im captures unmodeled dynamics, such as noise.</p><p>An example of such a model is shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p><p>Upon defining the M × 1 vectors y i := [y i1 , . . . , y iM ] ,</p><formula xml:id="formula_2">x i := [x i1 , . . . , x iM ] , the N × 1 vector b = [b 11 , b 22 , . . . , b NN ] , and the M × N matrices Y := [y 1 , . . . , y N ], X := [x 1 , . . . , x N ], (2) can be cast into matrix form Y = YA + XB + E (<label>3</label></formula><formula xml:id="formula_3">)</formula><p>where B is an N × N diagonal matrix with b as its diagonal, and E collects all the noise variables. Given nodal measurements across the entire network, Y, and exogenous inputs X the task of topology inference is to find the unknown adjacency matrix A of the underlying network. Note that typical connectivity of real-world networks is sparse, as nodes usually connect to few other nodes, thus the adjacency matrix A is expected to be sparse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. TOPOLOGY INFERENCE ALGORITHM</head><p>Having established the network model, we next consider estimating the wanted adjacency matrices in the noisy SEM of (3). In order to estimate the unknowns in (3), or (2), the following sparsity promoting optimization problem is proposed:</p><formula xml:id="formula_4">min A,B 1 2 Y -YA -XB 2 F + λ 1 A 1 + λ 2 2 A 2 F subject to diag(A) = 0<label>(4)</label></formula><p>where the constraint diag(A) = 0 ensures that there are no self-loops, λ 1 and λ 2 are regularization scalars for the L 1 and Frobenius norms, and • 1 denotes the L 1 -norm of the vectorized matrix. Also, note that the objective function in (4) is convex. The following proposition justifies the use of the elastic net penalty, the weighted sum of L 1 and L 2 norms, instead of just using the sparsity promoting L 1 norm, typically employed in LASSO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 1 ( [24]</head><p>). Suppose that the nodal measurements {y i } have unit norm. Let a * := [a * 1 , . . . , a * N ] be the optimal solution to the following optimization problem</p><formula xml:id="formula_5">f (a) = 1 2 z -Ya 2 2 + λ 1 a 1 + λ 2 2 a 2 2 (5)</formula><p>and suppose a * i a * j &gt; 0. With ψ ij := y i y j it then holds that</p><formula xml:id="formula_6">|a * i -a * j | ≤ 2(1 -ψ ij ) λ 2 z 2 (6)</formula><p>Proof: Since a * is the minimizer of ( <ref type="formula">5</ref>) it holds that</p><formula xml:id="formula_7">f (a * ) ≤ f (0) ⇒ z -Ya * 2 ≤ z 2 . (<label>7</label></formula><formula xml:id="formula_8">)</formula><p>In addition the gradient of f at a * will vanish, that is</p><formula xml:id="formula_9">-Y (z -Ya * ) + λ 1 ∂ a * 1 + λ 2 a * = 0.<label>(8)</label></formula><p>Now consider the i-th and j-th rows of ( <ref type="formula" target="#formula_9">8</ref>)</p><formula xml:id="formula_10">-y i (z -Ya * ) + λ 1 sign(a * i ) + λ 2 a * i = 0 (9) -y j (z -Ya * ) + λ 1 sign(a * j ) + λ 2 a * j = 0.<label>(10)</label></formula><p>Subtracting ( <ref type="formula" target="#formula_10">10</ref>) from ( <ref type="formula">9</ref>) yields</p><formula xml:id="formula_11">λ 2 (a * i -a * j ) = (y i -y j ) (z -Ya * )<label>(11)</label></formula><p>Taking the norm of both sides and invoking the Cauchy-Schwarz inequality</p><formula xml:id="formula_12">|a * i -a * j | ≤ 2(1 -ψ ij ) λ 2 z -Ya * 2 ≤ 2(1 -ψ ij ) λ 2 z 2<label>(12)</label></formula><p>where the last inequality follows from <ref type="bibr" target="#b6">(7)</ref>. Proposition 1 suggests that when two nodal measurements are highly correlated, the elastic net solver will likely have these two nodes connected to the same set of other nodes. This is in contrast to LASSO <ref type="bibr" target="#b9">[10]</ref> solvers for <ref type="bibr" target="#b2">(3)</ref>, where in the presence of highly correlated data, the L 1 norm regularization promotes only one connection.</p><p>Note that if λ 2 = 0 then (4) reduces to the SEM obtained via LASSO <ref type="bibr" target="#b0">[1]</ref>. In order to solve (4), the alternating direction method of multipliers (ADMM <ref type="bibr" target="#b5">[6]</ref>) will be employed. Consider the auxiliary variables C and D, and re-write (4) as</p><formula xml:id="formula_13">min A,C,B,D 1 2 Y -YA -XB 2 F + λ 1 C 1 + λ 2 2 A 2 F subject to diag(C) = 0, A = C, B = D<label>(13)</label></formula><p>Note that, here D is a diagonal matrix. The augmented Lagrangian of ( <ref type="formula" target="#formula_13">13</ref>) is then Update A using (15).</p><formula xml:id="formula_14">L = 1 2 Y -YA -XB 2 F + λ 1 C 1 + λ 2 2 A 2 F + tr U 1 (A -C + diag(C)) + ρ 2 A -C + diag(C) 2 F + tr(U 2 (B -D)) + ρ 2 B -D 2 F (<label>14</label></formula><formula xml:id="formula_15">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Update B using ( <ref type="formula">16</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Update auxiliary variable C using (17).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Update auxiliary variable D using <ref type="bibr" target="#b18">(19)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Update Lagrange multipliers using (20) 8: end while where U 1 and U 2 denote Lagrange multipliers, while ρ is a positive scalar. Henceforth, matrix superscripts denote ADMM iteration indices. The update for A can be obtained by taking the derivative of L with respect to (w.r.t.) A and equating it to zero</p><formula xml:id="formula_16">∂L ∂A = 0 ⇒<label>(15)</label></formula><formula xml:id="formula_17">(K Y + (λ 2 + ρ)I) A i = K Y -K Y,X B -U i-1 1 + ρC i-1 .</formula><p>Here I is the identity matrix of appropriate dimension, and K Y,X denotes the inner product matrix between the columns of Y and X, that is K Y,X := Y X. Also, let by definition</p><formula xml:id="formula_18">K Y := K Y,Y .</formula><p>The update for B can be obtained in a similar manner ∂L ∂B = 0 ⇒ (16)</p><formula xml:id="formula_19">(K X + ρI) B i = K X,Y (I -A i ) -U i-1 2 + ρD i-1 .</formula><p>Accordingly, the update for the C is given by</p><formula xml:id="formula_20">J = T λ1/ρ A i + 1 ρ U i-1 1 ⇒ C i = J -diag(J)<label>(17)</label></formula><p>where T κ (•) denotes the elementwise soft-thresholding operator defined as</p><formula xml:id="formula_21">T κ (x) := ⎧ ⎪ ⎨ ⎪ ⎩ x -κ ,x &gt; κ 0 , |x| ≤ κ x + κ ,x &lt; -κ. (<label>18</label></formula><formula xml:id="formula_22">)</formula><p>The diagonal entries of D are updated as follows</p><formula xml:id="formula_23">d = 1 ρ diag(U i-1 2 ) + diag(B i ) ⇒ D i = ⎡ ⎢ ⎢ ⎢ ⎣ d 1 d 2 . . . d N ⎤ ⎥ ⎥ ⎥ ⎦ (<label>19</label></formula><formula xml:id="formula_24">)</formula><p>where d k is the k-th entry of d. Finally, the Lagrange multipliers are updated as</p><formula xml:id="formula_25">U i 1 = U i-1 1 + ρ A i -C i U i 2 = U i-1 2 + ρ B i -D i . (<label>20</label></formula><formula xml:id="formula_26">)</formula><p>The steps of our topology inference algorithm are listed in Alg. 1. Since ( <ref type="formula" target="#formula_4">4</ref>) is convex, this ADMM procedure will converge in a finite number of iterations. The update complexity of A and B is O(N 3 ), while the update complexity of the auxiliary variables C and D is O(N 2 ) and O(N ) respectively. This brings the overall complexity of the algorithm to O(I(N 3 + N 2 + N )), where I is the number of required ADMM iterations until convergence.</p><p>Remark 1. The proposed ADMM solver for the Elastic Net SEM, can also solve LASSO SEM's by setting λ 2 = 0.</p><p>Remark 2. All the variable updates are separable per node, i.e. each column of A can be updated separately, which lends it self naturally to a distributed implementation of the algorithm; see also <ref type="bibr" target="#b5">[6]</ref>.</p><p>Remark 3. The present topology identification approach can be extended to cope with dynamically changing networks, by employing an exponentially weighted least-squares cost in (4), along the lines of <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. NUMERICAL TESTS</head><p>The proposed scheme is validated in this section using synthetic and real data. In all tests Elastic Net SEM is compared to LASSO SEM <ref type="bibr" target="#b0">[1]</ref>, both implemented using the ADMM algorithm outlined in Section III. An edge is declared present if αij ≥ 10 -1 . Given the support S of the ground truth adjacency matrix A with entries</p><formula xml:id="formula_27">[S] ij = 1, if a ij = 0 0, otherwise</formula><p>and the support Ŝ of estimated adjacency matrix Â with entries,</p><formula xml:id="formula_28">[ Ŝ] ij = 1, if âij ≥ 10 -1 0,</formula><p>otherwise the metric evaluated is the edge identification error rate (EIER) given by</p><formula xml:id="formula_29">EIER = S -Ŝ 0 N (N -1) × 100%.</formula><p>The software employed to conduct all experiments is MAT-LAB <ref type="bibr" target="#b14">[15]</ref>. All results represent averages over 10 independent Monte Carlo runs. In all experiments the ADMM parameter ρ is set to 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Synthetic data</head><p>A synthetic network with L = 4 non-overlapping communities and N = L =1 N is generated. Here, N denotes the number of nodes in the -th community, which were set as N = {4, 8, 16, 32}. The connectivity pattern in each community is generated based on the following seed matrix</p><formula xml:id="formula_30">S 0 = ⎡ ⎢ ⎢ ⎣ 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 ⎤ ⎥ ⎥ ⎦ .<label>(21)</label></formula><p>The adjacency matrix in each community is generated as</p><formula xml:id="formula_31">[A ] ij ∼ Bernoulli(0.9[S ] ij )</formula><p>, where S = S 0 ⊗ 1 ×1 , and ⊗ denotes the Kronecker product. The overall adjacency matrix of the network is then defined as A = Bdiag{A 1 , . . . , A L }, while the matrix of exogenous effects is set as B = I. The number of observations per node is M = 54. For the nodes in each community, the N × M exogenous variable matrix X was generated as X = X ⊗ 1 ×1 , with each entry of X drawn from a standardized normal distribution. The exogenous variable matrix for the entire network is formed as X = [X 1 , . . . , X L ] . Setting σ = 0.01, noise terms were sampled independently as it ∼ N (0, σ 2 ). Finally, the measurement matrices were generated based on the linear SEM of (3) as Y = (I -A) -1 (BX + E).</p><p>The Elastic Net SEM parameters are λ 1 = 0.005, λ 2 = 0.1, while for LASSO SEM λ = 0.005. Fig. <ref type="figure" target="#fig_1">2a</ref> shows the heatmap of the ground truth adjacency matrix A for one instance of this network. For the same instance, Figs. <ref type="figure" target="#fig_1">2b</ref> and<ref type="figure" target="#fig_1">2c</ref> depict the estimated adjacency matrices for Elastic Net SEM and LASSO SEM, respectively. Results for this network are listed in Tab. I. Clearly, Elastic Net SEM is able to identify more edges in this scenario, while LASSO SEM performs worse. As the data are generated to be highly correlated, this experiment showcases the shortcomings of the LASSO solver for SEM <ref type="bibr" target="#b0">[1]</ref> compared to the Elastic Net. Indeed, LASSO SEM tends to ignore many edges that correspond to highly correlated data.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Real data</head><p>Further tests were conducted based on real gene regulatory network data <ref type="bibr" target="#b2">[3]</ref>. Nodes in this networks represent 39 immunerelated genes, while the measurements consist of gene expression data from 69 unrelated Nigerian individuals <ref type="bibr" target="#b4">[5]</ref>. The gene expression levels were treated as endogenous inputs, while genotypes of the genes involved were considered as the exogenous inputs. Note that, in this scenario, there is no groundtruth adjacency matrix, thus only Elastic Net SEM and LASSO SEM are compared. Fig. <ref type="figure" target="#fig_2">3</ref> shows the results for this dataset. The parameters for this experiment were λ 1 = 600, λ 2 = 600 for Elastic Net SEM, and λ = 600 for LASSO SEM. While both algorithms provide similar adjacency matrices, note that Elastic Net SEM is able to identify two more edges than SEM. This could possibly facilitate the discovery of novel causal patterns, that may not be captured by LASSO-based SEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS AND FUTURE WORK</head><p>This paper introduced a novel approach for network topology inference, termed Elastic Net SEM, which is based on linear structural equation models. The proposed method exploits  the sparse connectivity of the network, through the elastic net, to identify possible directed edges, even in the presence of highly correlated data, a scenario where LASSO typically fails. Elastic Net SEM was efficiently implemented using an ADMM algorithm and preliminary tests on synthetic and real data showcase promising results compared to the LASSObased SEM. Future research will focus on extensive numerical tests with real datasets, extensions to multi-layer networks, as well as distributed implementations and corresponding identifiability analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1.</figDesc><graphic coords="2,95.27,53.96,158.51,98.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Heatmaps of adjacency matrices for a 4-community synthetic network. White (black) squares indicate the presence (absence) of an edge.</figDesc><graphic coords="4,452.87,363.44,91.69,72.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Heatmaps of adjacency matrices for the gene regulatory network, with N = 39 nodes in total. White (black) squares indicate the presence (absence) of an edge.</figDesc><graphic coords="4,334.67,363.44,91.69,72.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Exogenous inputs X; parameters {λ 1 , λ 2 , ρ} Output: Estimate of network adjacency matrix A 1: Initialize all variables to 0.</figDesc><table /><note><p>2017 25th European Signal Processing Conference (EUSIPCO) ISBN 978-0-9928626-7-1 © EURASIP 2017 Algorithm 1 Elastic Net SEM Topology Inference Input: Nodal measurements Y; 2: while Not converged do 3:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I AVERAGE</head><label>I</label><figDesc>NUMBER OF MISIDENTIFIED EDGES FOR ELASTIC NET SEM</figDesc><table /><note><p>AND SEM FOR A SYNTHETIC NETWORK.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2017" xml:id="foot_0"><p>25th European Signal Processing Conference (EUSIPCO) ISBN 978-0-9928626-7-1 © EURASIP 2017</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Proximal-gradient algorithms for tracking cascades over social networks</title>
		<author>
			<persName><forename type="first">B</forename><surname>Baingana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mateos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Sig. Proc</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="563" to="575" />
			<date type="published" when="2014-08">Aug. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">th European Signal Processing Conference (EUSIPCO)</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006. 2017</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
	<note>Pattern Recognition and Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inference of gene regulatory networks with sparse structural equation models exploiting genetic perturbations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Bazerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comp. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2013-05">May 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Community detection in graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="75" to="174" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A second generation human haplotype map of over 3.1 million snps</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Frazer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Ballinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Hinds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Stuve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Gibbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Belmont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Boudreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hardenbol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Leal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">449</biblScope>
			<biblScope unit="issue">7164</biblScope>
			<biblScope unit="page" from="851" to="861" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Decentralized learning for wireless communications and networking</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mateos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Schizas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Splitting Methods in Communication and Imaging</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Glowinski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Osher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Yin</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Structural equation methods in the social sciences</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="page" from="979" to="1001" />
			<date type="published" when="1972-11">Nov. 1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Structure and dynamics of information pathways in online media</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Gomez</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM Intl. Conf. on Web Search and Data Mining</title>
		<meeting>the sixth ACM Intl. Conf. on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A comparison of methods for estimating quadratic effects in nonlinear structural equation models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Harring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-C</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">193</biblScope>
			<date type="published" when="2012-06">Jun. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural Equation Modeling: Foundations and Extensions</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>nd ed</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A nonlinear structural equation mixture modeling approach for nonnormally distributed latent predictor variables</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kelava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nagengast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="468" to="481" />
			<date type="published" when="2014-06">Jun. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Statistical analysis of network data with R</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">D</forename><surname>Kolaczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Csárdi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Model comparison of nonlinear structural equation models with fixed covariates</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Y</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="47" />
			<date type="published" when="2003-03">Mar. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><surname>Matlab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>The Math-Works Inc</publisher>
			<pubPlace>Natick, Massachusetts</pubPlace>
		</imprint>
	</monogr>
	<note>version 8.6.0 (R2015b</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A general structural equation model with dichotomous, ordered categorical, and continuous latent variable indicators</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="132" />
			<date type="published" when="1984-03">Mar. 1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the convexity of latent social network inference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1741" to="1749" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The structure and function of complex networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="167" to="256" />
			<date type="published" when="2003-06">June 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Uncovering the temporal dynamics of diffusion networks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">28th Int. Conf. Mach. Learn</title>
		<meeting><address><addrLine>Bellevue, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07">July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Nonlinear structural equation models for network topology inference</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Baingana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Giannakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Conference on Information Science and Systems</title>
		<meeting>of Annual Conference on Information Science and Systems<address><addrLine>Princeton NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-03">March 2016</date>
			<biblScope unit="page" from="163" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Kernel-based structural equation models for topology identification of directed networks</title>
		<ptr target="http://arxiv.org/abs/1605.03122" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<idno type="arXiv">arXiv:1610.06551</idno>
		<title level="m">Nonlinear structural vector autoregressive models for inferring effective brain network connectivity</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
