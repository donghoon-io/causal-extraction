<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Comparative Study on the Performance of GSCA and CSA in Parameter Recovery for Structural Equation Models With Ordinal Observed Variables</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2018-12-05">05 December 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kwanghee</forename><surname>Jung</surname></persName>
							<email>kwanghee.jung@ttu.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Educational Psychology and Leadership</orgName>
								<orgName type="institution">Texas Tech University</orgName>
								<address>
									<settlement>Lubbock</settlement>
									<region>TX</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pavel</forename><surname>Panko</surname></persName>
							<email>pavel.panko@ttu.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Educational Psychology and Leadership</orgName>
								<orgName type="institution">Texas Tech University</orgName>
								<address>
									<settlement>Lubbock</settlement>
									<region>TX</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jaehoon</forename><surname>Lee</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Educational Psychology and Leadership</orgName>
								<orgName type="institution">Texas Tech University</orgName>
								<address>
									<settlement>Lubbock</settlement>
									<region>TX</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heungsun</forename><surname>Hwang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Psychology</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Ball State University</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Houston</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Comparative Study on the Performance of GSCA and CSA in Parameter Recovery for Structural Equation Models With Ordinal Observed Variables</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-12-05">05 December 2018</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3389/fpsyg.2018.02461</idno>
					<note type="submission">This article was submitted to Quantitative Psychology and Measurement, a section of the journal Frontiers in Psychology Received: 08 April 2018 Accepted: 20 November 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>generalized structured component analysis</term>
					<term>alternating least squares estimation</term>
					<term>maximum likelihood estimation</term>
					<term>diagonally weighted least squares estimation</term>
					<term>structural equation modeling</term>
					<term>covariance structure analysis</term>
					<term>monte carlo simulation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A simulation based comparative study was designed to compare two alternative approaches to structural equation modeling-generalized structured component analysis (GSCA) with the alternating least squares (ALS) estimator vs. covariance structure analysis (CSA) with the maximum likelihood (ML) estimator or the weighted least squares mean and variance adjusted (WLSMV) estimator-in terms of parameter recovery with ordinal observed variables. The simulated conditions included the number of response categories in observed variables, distribution of ordinal observed variables, sample size, and model misspecification. The simulation outcomes focused on average root mean square error (RMSE) and average relative bias (RB) in parameter estimates. The results indicated that, by and large, GSCA-ALS recovered structural path coefficients more accurately than CSA-ML and CSA-WLSMV in either a correctly or incorrectly specified model, regardless of the number of response categories, observed variable distribution, and sample size. In terms of loadings, CSA-WLSMV outperformed GSCA-ALS and CSA-ML in almost all conditions. Implications and limitations of the current findings are discussed, as well as suggestions for future research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Latent variable modeling has become a methodological mainstay in social and behavioral sciences research and beyond. Specifically, structural equation modeling (SEM; <ref type="bibr" target="#b21">Jöreskog, 1970</ref><ref type="bibr" target="#b22">Jöreskog, , 1973))</ref>, a method of path analysis using latent variables, has been extensively utilized and evaluated by substantive experts and methodological researchers. However, as there are many different approaches for conducting SEM (e.g., covariance structure analysis, partial least squares path modeling, generalized structured component analysis), many questions regarding optimal modeling approaches still exist. For instance, responding to estimation challenges in the context of ordinal observed variables and developing strategies to counteract model misspecifications are areas of importance in SEM research (e.g., <ref type="bibr" target="#b15">Flora and Curran, 2004;</ref><ref type="bibr" target="#b2">Bandalos, 2008;</ref><ref type="bibr" target="#b26">Li, 2016)</ref>.</p><p>Recently, <ref type="bibr" target="#b26">Li (2016)</ref> carried out a simulation study to examine the performance of covariance structural analysis (CSA) with ordinal observed variables, comparing the conventional normal-theory estimation method, maximum likelihood (ML), with the methods employing a robust correction for nonnormality. ML estimation uses a sample covariance matrix as input data under the assumption of continuous observed variables and multivariate normality of the observed variables, while the robust methods, diagonally weighted least squares (DWLS) estimation and unweighted least squares (ULS) estimation, use a polychoric correlation matrix with the assumption that a continuous and normally distributed latent variable underlies each observed variable. In this simulation, the study conditions were manipulated by varying distributional properties of ordinal observed variables, the number of response categories, and sample size. The simulation results revealed that compared to ML, DWLS, and ULS produced more accurate estimates for the factor loadings in all differing number of response categories; as well as for the path coefficients in nearly all asymmetric distribution conditions. Similar to previous findings (see <ref type="bibr" target="#b28">Muthén et al., 1997)</ref>, both DWLS and ULS did not require a large sample for the parameter recovery-i.e., a sample size of 200 or 300 would be sufficient for accurate parameter estimation. In short, <ref type="bibr" target="#b26">Li (2016)</ref> showed that when observed variables in SEM are ordinal variables, DWLS and ULS are favorable to ML in terms of parameter recovery. Nevertheless, ML would be recommended for cases with observed variables that have symmetric distributions in a large sample.</p><p>In the current study, we incorporate generalized structured component analysis (GSCA; <ref type="bibr" target="#b16">Hwang and</ref><ref type="bibr">Takane, 2004, 2014)</ref>, which is component-based SEM and an alternative to factorbased CSA <ref type="bibr" target="#b35">(Tenenhaus, 2008;</ref><ref type="bibr" target="#b34">Rigdon, 2012)</ref>, for use with continuous and ordinal observed variables. GSCA postulates that weighted composites or components of indicators may serve as proxies for latent variables as in principal component analysis, while factor-based CSA assumes that common factors may approximate latent variables as in common factor analysis. As such, GSCA is capable of providing unique latent variable scores while avoiding latent variable score indeterminacy in CSA. More importantly, GSCA can accommodate models with a higher degree of complexity, which may be difficult or impossible for factor-based SEM due to technical difficulties such as model nonidentification, presence of improper solution, non-convergence, and so on. <ref type="bibr" target="#b20">Hwang and Takane (2014)</ref> highlighted the practical usefulness of GSCA in regard to flexibility in model specification and computational efficiency in parameter estimation. At a glance, GSCA uses an alternating least squares (ALS; De <ref type="bibr" target="#b12">Leeuw et al., 1976)</ref> algorithm for parameter estimation and employs the bootstrap method <ref type="bibr" target="#b14">(Efron, 1982)</ref> to assess the reliability of parameter estimates without rigid distributional assumptions (e.g., multivariate normality assumption that is often made in CSA). Thus, it allows for stable parameter estimates even in a small sample.</p><p>A simulation study by <ref type="bibr" target="#b18">Hwang et al. (2010)</ref> examined the parameter recovery in GSCA-ALS and CSA-ML using a relatively simple model with three latent variables and three normally distributed, continuous observed variables per latent variable. This study showed that when the model is correctly specified, CSA-ML tends to produce better parameter estimates compared to GSCA-ALS. In contrast, when the model is misspecified, GSCA-ALS tends to have superior parameter recovery. These findings suggest that GSCA-ALS is recommended over CSA-ML unless a correct model specification is ensured. Unfortunately, little is known for the ordinal variable case, even though Likerttype ordinal scales are very commonly used to operationalize latent variables in applied research. If researchers inadvertently treat ordinal variables as continuous, it may lead to unreliable parameter estimates and incorrect inferences <ref type="bibr" target="#b15">(Flora and Curran, 2004)</ref>. Therefore, a thorough, empirical examination is imperative to understand the performance of GSCA-ALS, in comparison with CSA, on parameter recovery for ordinal observed variables.</p><p>The organization of this article is as follows. The following sections demonstrate GSCA and CSA approaches to SEM and discuss some estimation issues relevant to those methods. Then, the design and analysis procedure of a Monte Carlo simulation study are presented. In the final section, the authors discuss study findings and implications, as well as limitations and directions for future research. The present study may contribute to the literature by allowing for researchers and practitioners to acknowledge viable options and potential consequences and implications of their choice when conducting a SEM analysis with ordinal observed variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GENERALIZED STRUCTURED COMPONENT ANALYSIS WITH ALTERNATING LEAST SQUARES (GSCA-ALS)</head><p>Generalized structured component analysis (GSCA) is component-based SEM <ref type="bibr" target="#b35">(Tenenhaus, 2008)</ref>. GSCA defines latent variables as weighted composites or components of observed variables as follows:</p><formula xml:id="formula_0">γ i = Wz i</formula><p>where z i denotes a vector of observed variables for a respondent i (i =1, . . . , N), γ i is a vector of latent variables for a respondent i, and W is a matrix consisting of component weights assigned to observed variables. This equation is called the weighted relation model. Both z i and γ i are assumed to be standardized with zero mean and unit variance. Here, components or weighted composites of the indicators are assumed to be proxies for latent variables in GSCA or other multivariate methods, aiming to capture the most representative variation in the indicators. In contrast, in factor-based CSA, common factors are postulated as latent variables, which are assumed to only account for covariances among indicators.</p><p>GSCA comprises two additional equations for model specifications. One is for the measurement model which specifies the relationships between observed variables and latent variables, and the other is for the structural model which captures the relationships among latent variables. The measurement model is given by the following:</p><formula xml:id="formula_1">z i = Cγ i + ε i ,</formula><p>where C is a matrix of loadings relating latent variables to observed variables and ε i is a vector of residuals for z i . The structural model is defined by the following:</p><formula xml:id="formula_2">γ i = Bγ i + ξ i ,</formula><p>where B is a matrix of path coefficients connecting latent variables among themselves and ξ i is a vector of residuals for γ i .</p><p>Then, the GSCA model is derived from integrating the three submodels into a single, general model as follows:</p><formula xml:id="formula_3">z i γ i = C B γ i + ε i ξ i I W z i = C B Wz i + ε i ξ i Vz i = AWz i + e i ,</formula><p>where</p><formula xml:id="formula_4">V = I W , A = C B , e i = ε i ξ i ,</formula><p>and I is an identity matrix <ref type="bibr" target="#b16">(Hwang and</ref><ref type="bibr">Takane, 2004, 2014)</ref>.</p><p>The unknown parameters of GSCA (W and A) are estimated such that the sum of squares of all residuals (e i ) is as small as possible across all respondents. This pertains to minimizing the following least squares criterion:</p><formula xml:id="formula_5">φ = N i = 1 (Vz i -AWz i ) ′ (Vz i -AWz i ) ,</formula><p>with respect to W and A, subject to the constraint that each latent variable is standardized, N i = 1 γ 2 id = N, where γ id is the dth element of γ i . An ALS algorithm was developed to minimize the least squares criterion-we therefore refer to this approach as GSCA-ALS. This algorithm alternates two main steps as many times as necessary until all parameter estimates stabilize. In the first step, for fixed W, A is updated in the least squares manner. In the second step, W is updated in the least squares sense for fixed A (for a detailed description of the algorithm, see <ref type="bibr" target="#b20">(Hwang and Takane, 2014)</ref>). In GSCA-ALS, a bootstrap method is utilized to calculate the standard errors and confidence intervals of parameter estimates without the multivariate normality assumption of observed variables. The bootstrapped standard errors or confidence intervals can be used for testing the statistical significance of the parameter estimates.</p><p>The simulation study by <ref type="bibr" target="#b18">Hwang et al. (2010)</ref> investigated the performance of GSCA-ALS and CSA-ML using a simple model with three latent variables and normally distributed, continuous observed variables. They arrived at two major conclusions. First, when the model is correctly specified, factor-based CSA-ML may be used over GSCA-ALS. Second, when the model is incorrectly specified, GSCA-ALS may be chosen over factor-based CSA-ML. In another Monte Carlo simulation study, Dynamic GSCA <ref type="bibr" target="#b23">(Jung et al., 2012)</ref>, an extended model of GSCA for longitudinal and time series analysis, showed reasonable parameter recovery rates with a very complex model (i.e., seven latent variables were nearly fully connected by contemporaneous reciprocal relations and by autoregressive paths), even in small samples (i.e., n = 50 or 100).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COVARIANCE STRUCTURAL ANALYSIS WITH MAXIMUM LIKELIHOOD (CSA-ML)</head><p>Using the notations commonly used in covariance structure analysis (CSA) <ref type="bibr" target="#b3">(Bollen, 1989;</ref><ref type="bibr" target="#b24">Kaplan, 2008)</ref>, the measurement models for endogenous variables and exogenous variables are defined by the following:</p><formula xml:id="formula_6">y = Y η + e and x = x ξ + δ,</formula><p>where y is a vector of endogenous observed variables, η is a vector of endogenous latent variables, x is a vector of exogenous observed variables, ξ is a vector of exogenous latent variables, Y and x are factor loading matrices, and e and δ are uniqueness vectors, respectively. The structural model is defined by the following:</p><formula xml:id="formula_7">η = Bη + Ŵξ + ζ</formula><p>where B is a matrix of path coefficients relating the latent endogenous variables to each other, Ŵ is a matrix of path coefficients relating endogenous variables to exogenous variables, and ζ is a vector of disturbance terms.</p><p>Assuming the multivariate normality of observed variables, the ML estimator produces parameter estimates that maximize the fit function F ML <ref type="bibr" target="#b3">(Bollen, 1989)</ref>:</p><formula xml:id="formula_8">F ML = ln (θ ) + trace S -1 (θ ) -ln |S| -r</formula><p>where θ denotes a vector of model parameters, (θ ) is a model implied covariance matrix, S is a sample covariance matrix, and r is the total number of observed variables. CSA-ML assumes the observed data to be multivariate normally distributed, but often this assumption is not tenable for ordinal variables. In such case, CSA-ML can yield remarkably erroneous parameter estimates <ref type="bibr" target="#b5">(Boomsma, 1982;</ref><ref type="bibr" target="#b9">Chou et al., 1991)</ref>. This problem is exacerbated with small samples-for instance, <ref type="bibr" target="#b0">Anderson and Gerbing (1984)</ref> and <ref type="bibr" target="#b5">(Boomsma, 1982</ref><ref type="bibr" target="#b6">(Boomsma, , 1985) )</ref> showed that the chance of an improper or inadmissible solution, such as negative residual variance estimates, increases with non-normally distributed ordinal observations from a small sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COVARIANCE STRUCTURAL ANALYSIS WITH WEIGHTED LEAST SQUARES (CSA-WLSMV)</head><p>Weighted least squares (WLS) is an asymptotically distributionfree estimator for non-normal continuous or categorical data <ref type="bibr" target="#b7">(Brown, 2006)</ref>. It utilizes a consistent estimate of the asymptotic covariance matrix of sample variances and covariances <ref type="bibr" target="#b8">(Browne, 1984)</ref>. <ref type="bibr" target="#b27">Muthén (1984)</ref> adapted this approach for SEM with ordinal observed variables by making the assumption that a normal, latent response distribution underlies each ordinal observed variable in the population. That is, first, thresholds are estimated from the univariate marginal distribution, and then polychoric correlations are estimated from the bivariate marginal distributions for the given threshold estimates <ref type="bibr" target="#b30">(Olsson, 1979)</ref>. A consistent estimator of the asymptotic covariance matrix of the polychoric correlation and threshold estimates is used as a weight matrix to obtain parameter estimates by minimizing the WLS fit function F WLS <ref type="bibr" target="#b27">(Muthén, 1984)</ref>:</p><formula xml:id="formula_9">F WLS = [s -σ ( θ)] ′ -1 [s -σ ( θ)]</formula><p>where s is a vector containing the non-duplicated, vectorized elements of sample statistics (i.e., polychoric correlation and threshold estimates), θ is a vector of model parameters, is a model-implied vector consisting the non-dupulicated, vectorized elements of the polychoric correlation matrix * θ [i.e., σ θ = vec( * θ )].</p><p>Previous simulations studies have shown that WLS is prone to non-covergence problems with small samples and complex models <ref type="bibr" target="#b15">(Flora and Curran, 2004)</ref>. When sample sizes are small, the estimated asymptotic covariance matrix shows great sampling variation, and its inversion is typically infeasible. Moreover, as the number of ordinal observed variables increases, the size and invertibility of the weight matrix grow rapidly, leading to computational challenges and numerical issues in parameter estimation <ref type="bibr" target="#b8">(Browne, 1984)</ref>. To circumvent these problems, diagonally weighted least squares (DWLS, <ref type="bibr" target="#b10">Christoffersson, 1977)</ref> estimation has been proposed by choosing a reduced and invertible asymptotic covariance matrix. The fit function can be represented as:</p><formula xml:id="formula_10">F DWLS = [s -σ ( θ)] ′ D -1 [s -σ ( θ)]</formula><p>where D involves only diagonal elements of the estimated asymptotic covariance matrix of the polychoric correlation and threshold estimates. The weighted least squares mean and variance adjusted (WLSMV) estimator <ref type="bibr" target="#b1">(Asparouhov and Muthén, 2010)</ref> for DWLS estimation was chosen for the current investigation. WLSMV approximates the mean of the expected χ 2 distribution as well as its variance. WLSMV has been found to outperform WLS in case of small samples and complex models, even when non-normally-distributed ordinal data with small number of categories were analyzed <ref type="bibr" target="#b15">(Flora and Curran, 2004;</ref><ref type="bibr" target="#b2">Bandalos, 2008;</ref><ref type="bibr" target="#b13">DiStefano and Morgan, 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MATERIALS AND METHODS</head><p>The relative performance of CSA (using the ML or WLSMV estimator) and GSCA (using the ALS estimator) with nonnormally-distributed ordinal data was analyzed using a Monte Carlo simulation. Considering a comparability with previous simulation work, a similar five-factor data-generating model as used in <ref type="bibr" target="#b26">Li (2016)</ref> was utilized to compare primarily the parameter recovery under the conditions of correct or incorrect model specification. Additionally, the current simulation considered several condition factors such as different number of response categories, level of distributional asymmetry, and sample size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Population model</head><p>Figure <ref type="figure" target="#fig_0">1</ref> depicts the structural layout of the data-generating model (i.e., population model) used for the current simulation. As in the study by <ref type="bibr" target="#b26">Li (2016)</ref>, a five-factor structural equation model with four ordinal observed variables were selected to ensure a representative structural equation model from an applied standpoint. The structural part of the population model (i.e., structural model) contains three endogenous and two exogenous latent variables with a series of structural regression paths specified between them, which range in magnitude from a coefficient of 0.1 to 0.6. As shown in Figure <ref type="figure" target="#fig_0">1</ref>, the six endogenous-to-exogenous paths are labeled by γ ; and the three exogenous-to-exogenous paths are labeled by β. The single correlation term between the two endogenous latent variables is labeled by φ. Additionally, the measurement part of the population model (i.e., measurement model) was set to be homogenous between all the latent variables, i.e., each latent variable featured four observed variables with standardized loadings of 0.8, 0.7, 0.6, and 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulation Design</head><p>The population model was estimated with either correct or incorrect structural model specification. Under structural misspecification, we have chosen to omit the four weakest paths in the model, namely, γ 22 , γ 31 , γ 32 , and β 31 . This choice represents the a priori decision to exclude effects that have been shown to be non-significant in previous studies. The exclusion of such paths is common in SEM; it presents a seemingly acceptable detraction from an unknown data-generating model based on a negligible difference in model fit. Those three omitted paths under model misspecification are depicted as dotted lines in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>For observed variables, we simulated several different instances of ordinal data configuration that are most commonly encountered in applied research. Specifically, we manipulated the number of response categories by using observed variables with 4, 5, 6, and 7 categories. In addition, we considered two different distributions for those observed variables; a symmetric distribution with zero skewness and kurtosis ranging from -0.49 to -0.48, and an asymmetric distribution with skewness from -1.39 to -1.38 and kurtosis from 1.14 to 1.19.</p><p>Sample size was also one of the condition factors under study. In the CSA literature, there are many articles focusing on finding an optimal sample size within different data environments, with recommendations usually varying by the number of parameters in the model. On the other hand, GSCA models make no such restrictions, and are reportedly able to provide adequate estimates at sample sizes commonly considered small under CSA <ref type="bibr" target="#b20">(Hwang and Takane, 2014)</ref>. To empirically test the difference, we considered five sample sizes, ranging from what have been previously reported as small (n = 50, 100, 200), medium (n = 500), and large (n = 1000). The algorithms used for model estimation included ALS estimator for GSCA and ML and WLSMV estimators for CSA. Previous research, including Li (2016), <ref type="bibr" target="#b15">Flora and Curran (2004)</ref>, and <ref type="bibr" target="#b28">Muthén et al. (1997)</ref>, has shown that WLSMV is superior to ML in case of ordinal observed variables in terms of accuracy and bias. At the same time, WLSMV is known to have convergencerelated stringencies related to low sample size <ref type="bibr" target="#b15">(Flora and Curran, 2004)</ref>. For this reason, we have chosen to include both estimation methods for CSA.</p><p>In sum, there were 2 (misspecification: yes/no) × 4 (number of response categories) × 2 (observed variable distributions) × 5 (sample sizes) = 80 experimental conditions in the current simulation. Five hundred samples were drawn in each of 80 conditions, yielding a total of 40,000 replications. Data generation was completed using the MONTECARLO command in Mplus 7 <ref type="bibr" target="#b27">(Muthén and</ref><ref type="bibr" target="#b29">Muthén, 1998-2012)</ref>. Data analysis was performed using Mplus 7 for CSA models and using the R software (R Core Team, 2017) with the gesca package <ref type="bibr" target="#b17">(Hwang et al., 2016)</ref> for GSCA models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Criteria</head><p>We considered two primary evaluation criteria for parameter recovery: (a) average relative bias of parameter estimates, (b) average root-mean-squared error of parameter estimates. The formulae for relative bias (RB) and root mean square error (RMSE) for the estimated value θ of each parameter k (k = 1, . . . , p) in replication j (j = 1, . . . , r) relative to its respective population parameter value θ , are as follows:</p><formula xml:id="formula_11">RB θk = 1 r r j = 1 θkj -θ k θ k × 100%</formula><p>and</p><formula xml:id="formula_12">RMSE θk = 1 r r j=1 θkj -θ k θ k 2 .</formula><p>RB quantifies the amount to which the estimated parameter values detract from the true parameter values. This measure further indicates the degree to which the chosen algorithm properly estimates the model parameters. On the other hand, RMSE represents the degree to which the estimated parameter values vary around the parameter value, thereby incorporating both bias and variance of the estimated parameters. For this study, we calculated means of the RB and RMSE across the loading and path coefficients to ascertain the average value of each measure across each type of parameter:</p><formula xml:id="formula_13">RB a θ = 1 p p k = 1 RB θk and RMSE a θ = 1 p p k = 1 RMSE θk .</formula><p>Although we acknowledge the importance of adhering to a singular criterion for non-ignorable bias in parameter estimates, we agree with <ref type="bibr" target="#b33">Reise et al. (2013)</ref> that in many similar cases, parameter bias is largely context dependent and therefore comparing against an absolute criterion can be misleading. We therefore chose to interpret parameter bias as well as error within each study condition and our conclusions were drawn relative to the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-convergence</head><p>The quality of the results was also evaluated for each condition by considering the proportion of non-converged solutions. We define non-convergence as instance in which either (1) the software program exceeds the number of default iterations without meeting the usual convergence criterion, or (2) the model converged on an improper solution that contains one or more non-positive definite matrices, also referred to as a Heywood case. In either case, the non-converged solutions were excluded from any further analysis and were not incorporated in the presented results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter Recovery</head><p>We began by determining the simulation conditions that produced substantial variability in the path coefficients and loadings. In order to conceptualize variability as distinct from the specified fluctuation in the model parameters, we calculated the mean absolute difference (MAD) of parameters and their estimates as follows:</p><formula xml:id="formula_14">MAD = P j=1 | θj -θ j | P</formula><p>where θj and θ j are an estimate and its parameter, respectively, and P is the number of parameters. The MAD of the estimated parameters θj was analyzed as the outcome in an analysis of variance (ANOVA) model, with the five simulation design parameters serving as predictors. The interaction terms of those design parameters were also included as predictors in up to a maximum-possible 5-way interaction. Due to the large number of available observations, we focused on effect sizes (e.g., η 2 ) of the predictors rather than their statistical significance (see <ref type="bibr" target="#b31">Paxton et al., 2001)</ref>, and decided to interpret only those effects which were at least medium in magnitude, e.g., η 2 ≥ 0.06 <ref type="bibr" target="#b11">(Cohen, 1988)</ref>.</p><p>For the path coefficients, the estimator (η 2 = 0.49), model misspecification (η 2 = 0.18), and observed variable distribution (η 2 = 0.07) were considered, as were their interactions: estimator by misspecification (η 2 = 0.56), estimator by distribution (η 2 = 0.08), and distribution by misspecification (η 2 = 0.11). For the loadings, only the estimator was considered (η 2 = 0.84). Note that all the exact values of RMSE and RB of loadings and path coefficients are provided in tables as Supplementary Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loadings</head><p>Considering the current simulation incorporated model misspecification at the structural level but not at the measurement level, we did not expect to see a difference in recovery of loading parameters between the correct and incorrect specification conditions. This finding was confirmed, as shown in Figures <ref type="figure" target="#fig_1">2,</ref><ref type="figure" target="#fig_2">3</ref>. The pattern of parameter recovery was also similar between the symmetric and asymmetric distribution conditions. That is, in both distribution conditions, average RMSE suggested that CSA-WLSMV (WLSMV, hereafter) had the lowest estimation error, followed by CSA-ML (ML, hereafter) and lastly GSCA-ALS (ALS, hereafter). However, ALS showed similar performance to both CSA conditions when the indicators where asymmetrically distributed. According to average RB, in both indicator-symmetry conditions, ML and WLSMV had better recovery than ALS. Overall, ML was more biased relative to WLSMV but even more so in the asymmetric condition.</p><p>For all three algorithms, in general, average RMSE decreased as the sample size increased in a non-linear (quadratic) fashion. However, sample size had no effect on bias-see the relatively flat trajectories of average RB over different sample sizes in the figures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Path Coefficients</head><p>Although the pattern of parameter recovery in path coefficients was similar between the symmetric and asymmetric distribution conditions, the effect of model misspecification was compelling, as shown in Figures <ref type="figure" target="#fig_3">4,</ref><ref type="figure" target="#fig_4">5</ref>. In the correct specification condition (see left panels of Figures <ref type="figure" target="#fig_3">4,</ref><ref type="figure" target="#fig_4">5</ref>), average RMSE suggested that ALS had much lower estimation error than both ML and WLSMV when the sample size was small, but at a sample size of 500 or greater, the amount of estimation error became negligible in each algorithm. According to average RB, when the (structural) model was correctly specified, ML and WLSMV had lower estimation error than ALS. On the other hand, under model misspecification (see right panels of Figures <ref type="figure" target="#fig_3">4,</ref><ref type="figure" target="#fig_4">5</ref>), ALS outperformed the CSAbased methods in terms of both average RMSE and average RB, regardless of sample size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-convergence</head><p>The non-convergence issues of CSA-based models resided primarily with small sample sizes, which is to be expected due to the complexity of the population model. Markedly, neither ML nor WLSMV yielded any successfully converged solutions in the conditions with a sample size of 50. The two CSAbased estimation methods experienced similar non-convergence problems in the other small sample size conditions-the most problematic conditions were those in which the model contained asymmetrically-distributed observed variables with more than four categories, a sample size of 100, and was estimated with WLSMV (41-57% converged). A lesser degree of non-convergence was observed in the model that was also estimated with WLSMV but had either asymmetricallydistributed variables with four categories or symmetricallydistributed variables with any number of categories (73-79% converged). The least severe conditions for non-convergence involved asymmetric distribution, &lt;6 categories, a sample size of 100, and ML (85-94% converged). All other conditions at  a sample size of 200 and below had trivial amount of nonconvergence (95-99% converged). No non-convergence was observed for CSA-based models with a sample size of 500 or greater. Under ALS estimation, there were no instances of nonconvergence even at the smallest sample size of 50, suggesting that ALS vastly outperformed both ML and WLSMV on this metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>In this Monte Carlo simulation study, we demonstrated the relative performance of GSCA-ALS, CSA-ML, and CSA-WLSMV with ordinal observed variables in terms of parameter recovery. The major findings can be summarized as follows. First, when the structural model was correctly specified, all three algorithms under-estimated the parameter values of path coefficients in a similar degree when the sample size was small. However, both CSA-ML and CSA-WLSMV produced unbiased path coefficient estimates when the sample size was 200 or larger, compared to GSCA-ALS. On the other hand, taking into account both bias and variability of the parameter estimates (i.e., average RMSE), GSCA-ALS showed much smaller error in estimating path coefficients than both CSA-ML and CSA-WLSMV when the sample size was small, but at a sample size of 500 or larger the magnitude of estimation error became negligible across all three algorithms. Second, when the structural model was incorrectly specified, GSCA-ALS outperformed the two CSAbased methods in terms of parameter recovery of the path  coefficients. That is, GSCA-ALS showed a trivial amount of estimation error compared to both CSA-ML and CSA-WLSMV and overwhelmingly smaller biases, regardless of the sample size. Third, the different conditions of observed variable distribution (i.e., symmetric or asymmetric) did not lead to considerable differences in parameter recovery of the path coefficients among the methods. On the other hand, the simulation results for the loadings indicated that under the asymmetric distribution condition, GSCA-ALS had lower estimation error than CSA-ML and CSA-WLSMV, and both CSA-ML and GSCA-ALS produced extremely biased loading estimates. In the symmetric distribution condition, both CSA-ML and CSA-WLSMV generally had better recovery of the loadings than GSCA-ALS in terms of both estimation error and bias. Fourth, CSA-ML and CSA-WLSMV suffered from massive-to-moderate non-convergence problems with small sample sizes (i.e., 50, 100, and 200). On the other hand, GSCA-ALS did not encounter any convergence problems even at the smallest sample size of 50.</p><p>These findings have important implications for researchers in substantive areas who apply structural equation modeling for their non-normally distributed ordered data. The choice over different estimation algorithms should be carefully considered especially when the sample size is less than moderate or/and when they are uncertain if the model has been correctly specified. Our stimulation results revealed outperformance of GSCA-ALS over both CSA-ML and CSA-WLSMV under model misspecification. Thus, we would recommend the adoption of GSCA-ALS when a correct specification of (structural) model cannot be ensured. In addition, when the sample size is relatively small (e.g., 100 or smaller), our findings suggest GSCS-ALS as the method of choice. In all other circumstances, when the researcher assures the model of being correctly specified, we recommend CSA-WLSMV. The WLSMV estimator has demonstrated superior parameter recovery for both loadings and path coefficients, when the model is correctly specified.</p><p>Despite these significant contributions, the current study has several limitations. Most apparently, for the comparative study of GSCA and CSA in parameter recovery, we generated simulation data within the CSA framework-i.e., assuming that latent variables are approximated by common factors rather than components of observed variables. The measurement model in CSA is typically a confirmatory factor-analytic model, where common factors explain the covariances among indicators and unique factors represent measurement error. On the other hand, the measurement model in GSCA is a confirmatory componentanalytic model (e.g., <ref type="bibr" target="#b25">Kiers et al., 1996)</ref>, where components aim to explain the entire variances of the indicators with no distinction between common and unique variances. In this sense, GSCA cannot define and handle measurement error in the same way as common factor analysis, tending to produce biased parameter estimates of factor-based models. Consequently, GSCA might be placed at a disadvantage in this simulation study.</p><p>We should have considered alternative data generation procedures as well in a fair manner. Moreover, although the present simulation involved a more realistic structural model and most relevant conditions, the relative performance of each method might be conditional on the specific levels chosen for the experimental conditions. Thus, it might be necessary to consider a broad range of conditions and models for more rigorous investigations.</p><p>Given the superiority of GSCA-ALS over CSA-ML and CSA-WLSMV under model misspecification, future studies would expand their scope to other robust CSA methods for a comparison with GSCA-ALS. For instance, <ref type="bibr" target="#b3">Bollen (1996)</ref> recommended using two-stage least squares (2SLS) estimation for CSA in the presence of incorrectly specified models. CSA-2SLS is a limited-information estimation procedure that employs one equation at a time in parameter estimation, and consequently a specification error in one equation does not necessarily affects the other equations. <ref type="bibr" target="#b4">Bollen et al. (2007)</ref> have empirically demonstrated the robustness of 2SLS to misspecification, as compared to CSA-ML. Thus, a Monte Carlo simulation on the relative performance of CSA-2SLS and GSCA-ALS under various misspecification conditions would ascertain the relative benefits of each approach. Another direction for future studies is to compare GSCA-ALS with its regularized extension (rGSCA-ALS; <ref type="bibr" target="#b16">(Hwang, 2009)</ref>). rGSCA-ALS combines a ridge type of regularization into GSCA in a unified framework, thereby handling potential multicollinearity problems more effectively. In the preliminary simulation study, rGSCA-ALS was found to provide parameter estimates that are as good as or better than those from original GSCA-ALS in various conditions of normally-distributed data. Therefore, it is suggested to compare GSCA-ALS and rGSCA-ALS under more realistic situations involving observed ordinal variables and the presence of multicollinearity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc>FIGURE 1 | The population structural model with five latent variables. The paths omitted in the misspecification condition are displayed as dotted lines.</figDesc><graphic coords="5,126.14,69.47,342.96,271.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 2 |</head><label>2</label><figDesc>FIGURE 2 | Estimation error and bias in loadings with symmetrically distributed indictors.</figDesc><graphic coords="7,110.64,70.04,374.16,200.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 3 |</head><label>3</label><figDesc>FIGURE 3 | Estimation error and bias in loadings with asymmetrically distributed indictors.</figDesc><graphic coords="7,112.14,318.31,371.40,199.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 4 |</head><label>4</label><figDesc>FIGURE 4 | Estimation error and bias in structural path coefficients with symmetrically-distributed indicators.</figDesc><graphic coords="8,112.14,69.59,371.40,199.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIGURE 5 |</head><label>5</label><figDesc>FIGURE 5 | Estimation error and bias in structural path coefficients with asymmetrically-distributed indicators.</figDesc><graphic coords="8,112.14,316.32,371.40,199.08" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Frontiers in Psychology | www.frontiersin.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>December 2018 | Volume 9 | Article 2461</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR CONTRIBUTIONS</head><p>KJ contributed to technical development, empirical analyses, and manuscript writing. PP contributed to technical development, empirical analyses, and manuscript writing. JL contributed to manuscript writing, and HH contributed to manuscript writing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTARY MATERIAL</head><p>The Supplementary Material for this article can be found online at: <ref type="url" target="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.02461/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fpsyg. 2018.02461/full#supplementary-material</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest Statement:</head><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The effect of sampling error on convergence, improper solutions, and goodness-of-fit indices for maximum likelihood confirmatory factor analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Gerbing</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294170</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="155" to="173" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Weighted Least Squares Estimation with Missing Data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<ptr target="http://www.statmodel.com/download/GstrucMissingRevision.pdf" />
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Is parceling really necessary? A comparison of results from item parceling and categorical variable methodology</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Bandalos</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705510801922340</idno>
	</analytic>
	<monogr>
		<title level="m">Struct Equation Model</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="211" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An alternative two stage least squares (2SLS) estimator for latent variable equations</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02296961</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<editor>
			<persName><surname>Wiley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="109" to="121" />
			<date type="published" when="1989">1989. 1996</date>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>Structural Equations With Latent Variables</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Latent variable models under misspecification. Two-stage least squares (2SLS) and maximum likelihood (ML) estimators</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1177/0049124107301947</idno>
	</analytic>
	<monogr>
		<title level="j">Sociol. Methods Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="48" to="86" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The robustness of LISREL against small sample sizes in factor analysis models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boomsma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Systems Under Indirect Observation: Causality, Structure, Prediction (Part I</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wold</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North-Holland</publisher>
			<date type="published" when="1982">1982</date>
			<biblScope unit="page" from="149" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nonconvergence, improper solutions, and starting values in LISREL maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boomsma</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294248</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="345" to="370" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Confirmatory Factor Analysis for Applied Research</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Guildford</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Asymptotically distribution-free methods for the analysis of covariance structures</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2044-8317.1984.tb00789.x</idno>
	</analytic>
	<monogr>
		<title level="j">Br. J. Math. Stat. Psychol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="62" to="83" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scaled test statistics and robust standard errors for non-normal data in covariance structure analysis: a monte carlo study</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satorra</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2044-8317.1991.tb00966.x</idno>
	</analytic>
	<monogr>
		<title level="j">Br. J. Math. Stat. Psychol</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="347" to="357" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Two-step weighted least squares factor analysis of dichotomized variables</title>
		<author>
			<persName><forename type="first">A</forename><surname>Christoffersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="433" to="438" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<title level="m">Statistical Power for the Behavioural Sciences, 2nd Edn</title>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Additive structure in qualitative data: an alternating least squares method with optimal scaling features</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takane</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02296971</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="471" to="503" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A comparison of diagonal weighted least squares robust estimation techniques for ordinal data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Distefano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Morgan</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2014.915373</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equation Model</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="425" to="438" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Jackknife, the Bootstrap, and Other Resampling Plans</title>
		<author>
			<persName><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CBMS-NSF Regional Conference Series in Applied Mathematics</title>
		<meeting><address><addrLine>Philadelphia, PA)</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982">1982</date>
			<biblScope unit="volume">38</biblScope>
		</imprint>
	</monogr>
	<note>SIAM</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An empirical evaluation of alternative methods of estimation for confirmatory factor analysis with ordinal data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Flora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<idno type="DOI">10.1037/1082-989X.9.4.466</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="466" to="491" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Regularized generalized structured component analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-009-9119-y</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="517" to="530" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">gesca: Generalized Structured Component Analysis (GSCA)</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=gesca" />
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>R package version 1.0.3. Available online at</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A comparative study on parameter recovery of three approaches to structural equation modeling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tomiuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<idno type="DOI">10.1509/jmkr.47.4.699</idno>
	</analytic>
	<monogr>
		<title level="j">J. Market. Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="699" to="712" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generalized structured component analysis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takane</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02295841</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="81" to="99" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Generalized Structured Component Analysis: A Component-Based Approach to Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Chapman and Hall/CRC Press</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A general method for analysis of covariance structures</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
		<idno type="DOI">10.1093/biomet/57.2.239</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="409" to="426" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A generating method for estimating a linear structural equation system</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jöreskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural Equation Models in the Social Sciences eds</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Goldberger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">D</forename><surname>Duncan</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1973">1973</date>
			<biblScope unit="page" from="85" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dynamic GSCA (Generalized Structured Component Analysis) with applications to the analysis of effective connectivity in functional neuroimaging data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Woodward</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-012-9284-2</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="827" to="848" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
		<title level="m">Structural Equation Modeling: Foundations and Extensions, 10th Edn</title>
		<meeting><address><addrLine>Newbury Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage Publications</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The analysis of multitrait multimethod matrices via constrained components analysis</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A L</forename><surname>Kiers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Takane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M F</forename><surname>Berge</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294039</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="601" to="628" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The performance of ML, DWLS, and ULS estimation with robust corrections in structural equation models with ordinal variables</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000093</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Methods</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="369" to="387" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A general structural equation model with dichotomous, ordered categorical, and continuous latent variable indicators</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294210</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">132</biblScope>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Robust Inference using Weighted Least Squares and Quadratic Estimating Equations in Latent Variable Modeling with Categorical and Continuous Outcomes</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Du Toit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Spisic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
	<note>Unpublished manuscript</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthén</surname></persName>
		</author>
		<title level="m">Mplus User&apos;s Guide, 7th Edn</title>
		<meeting><address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Author</publisher>
			<date type="published" when="1998">1998-2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation of the polychoric correlation coefficient</title>
		<author>
			<persName><forename type="first">U</forename><surname>Olsson</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02296207</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="443" to="460" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Monte carlo experiments: design and implementation</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1207/S.15328007S.</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equation Model</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="287" to="312" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multidimensionality and structural coefficient bias in structural equation modeling: a bifactor perspective</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Reise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">F</forename><surname>Widaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Haviland</surname></persName>
		</author>
		<idno type="DOI">10.1177/0013164412449831</idno>
	</analytic>
	<monogr>
		<title level="j">Educ. Psychol. Measure</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="5" to="26" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rethinking partial least squares path modeling: in praise of simple methods</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Rigdon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.lrp.2012.09.010</idno>
	</analytic>
	<monogr>
		<title level="j">Long Range Plann</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="341" to="358" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Component-based structural equation modelling</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tenenhaus</surname></persName>
		</author>
		<idno type="DOI">10.1080/14783360802159543</idno>
	</analytic>
	<monogr>
		<title level="j">Total Qual. Manage. Bus. Excell</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="871" to="886" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
