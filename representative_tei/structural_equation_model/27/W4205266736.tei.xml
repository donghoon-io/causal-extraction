<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How Ethical Issues Raised by Human-Robot Interaction can Impact the Intention to use the Robot?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2022-01-13">13 January 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Reza</forename><surname>Etemad-Sajadi</surname></persName>
							<idno type="ORCID">0000-0002-9239-5593</idno>
						</author>
						<author>
							<persName><forename type="first">Antonin</forename><surname>Soussan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Théo</forename><surname>Schöpfer</surname></persName>
						</author>
						<title level="a" type="main">How Ethical Issues Raised by Human-Robot Interaction can Impact the Intention to use the Robot?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-01-13">13 January 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1007/s12369-021-00857-8</idno>
					<note type="submission">Accepted: 4 December 2021 /</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-21T19:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Human-robot interaction</term>
					<term>Ethical issues</term>
					<term>Trust and safety</term>
					<term>Social cues</term>
					<term>Autonomy</term>
					<term>Responsibility</term>
					<term>Privacy and data protection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The goal of this research is to focus on the ethical issues linked to the interaction between humans and robots in a service delivery context. Through this user study, we want to see how ethics influence user's intention to use a robot in a frontline service context. We want to observe the importance of each ethical attribute on user's intention to use the robot in the future. To achieve this goal, we incorporated a video that showed Pepper, the robot, in action. Then respondents had to answer questions about their perception of robots based on the video. Based on a final sample of 341 respondents, we used structural equation modeling (SEM) to test our hypotheses. The results show that the most important ethical issue is the Replacement and its implications for labor. When we look at the impact of the ethical issues on the intention to use, we discovered that the variables impacting the most are Social cues, Trust and Safety.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The service sector has always been a laboratory for innovations, as it is an inflection point between productivity and personalization. In this matter, technologies such as AI, clouding, and data banks have been implemented to revolutionize the future of the industry. Robotics, of course, is also a newcomer in the service sector. Robots used in this field are called "service robots". They are defined as "system-based autonomous and adaptable interfaces that interact, communicate and deliver service to an organization's customers" <ref type="bibr" target="#b66">[68]</ref>.</p><p>Whenever a new technology emerges, it tends to induce fear and a lack of trust. The interactions can be complicated as some people do not understand the technology and can be biased towards it. Ethical considerations play an essential role in the interaction between the consumer and technology, as society creates an ensemble of implicit and explicit rules to protect itself. Privacy, security, liability, dehumanization, and unemployment are part of the main concerns users may have B Reza Etemad-Sajadi reza.etemad@ehl.ch 1 EHL, HES-SO, University of Applied Sciences Western Switzerland, Lausanne, Switzerland <ref type="bibr" target="#b17">[18]</ref>. Nevertheless, robots are no exception to the rule and tend to exacerbate these fears. As personifications of technology, they have been the object of fantasy for many years. Besides, because service robots, compared to other robots, work directly with clients of a company they have an immediate impact on the reputation of the company. Robots, and especially service robots, have proven to be useful in "dull, dirty, or dangerous" tasks <ref type="bibr" target="#b42">[44]</ref>, p. 4), but they can take different forms: functional and social. For our research, we want to identify ethical issues that have an impact on the interactions between humans and service robots. Are robots being used to save money by replacing humans? How is our personal data used during (and after) an interaction with a robot? To what extent is the behavior of robots unpredictable? All of these questions can have an impact on the intention to use service robots. The safety of human beings is questioned since a mistake made by a robot could lead to dangerous situations. People are also afraid that robots will replace them, which would pose economic and human unemployment problems. This would create dependency on robots. Psychological risks are also predicted, such as problems of attachment, fears, or the confusion between artificial and real <ref type="bibr" target="#b64">[66]</ref>. Some existing regulations could be applied to the notion of safety with robots. An example would be the Code of Ethics of the Association for Computing Machinery (ACM), which states that: "When designing or implementing systems, computing professionals must attempt to ensure that the products of their efforts will be used in socially responsible ways, will meet social needs, and will avoid harmful effects to health and welfare" <ref type="bibr" target="#b45">[47]</ref>, p. 354).</p><p>The originality of this research stems from the fact that potential users will have to define the importance of each ethical attribute on their overall intention to use service robot in the future. This empirical study will therefore be centered on participants' assessment of certain ethical items. This method should allow us to uncover which ethical items are important for the customer's intention to use a service robot. Moreover, we focus our ethical issues applied to service robots in order to have more concrete ethical guidelines for this precise technology. However, the aim of this paper is not to uncover novel ethical issues, but to build on the ethical dimensions discussed in the existing literature to test the customers' intention to use service robots. Finally, this article will not be about all types of robots (such as military, medical, or industrial robots), but will focus solely on social robots used in a service delivery context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Service Robots</head><p>Service robots are robots specialized in acting in a service delivery context. Their unique feature is that they interact with human customers socially. They can also be defined as social service robots <ref type="bibr" target="#b66">[68]</ref>, as they can create some degree of automated social presence. They make the customer feel that they are with another social entity <ref type="bibr" target="#b61">[63]</ref>. The literature states that there are three main attributes that should be taken into consideration in a service context: representation, anthropomorphism, and task orientation <ref type="bibr" target="#b66">[68]</ref>. The representation can be split into two different categories: virtual (e.g., Alexa by Amazon or Google assistant) or physical (e.g., Pepper or SARA Singapore's Automated Responsive Assistant), which is the case for our research. The embodiments can be anthropomorphic according to the human-like characteristics, but behavior can also contribute to the perception of anthropomorphism which can be split into two distinct categories: humanoid (e.g., NAO or Pepper manufactured by Softbank robotics) or non-humanoid (e.g., Roomba the vacuum-cleaner robot). Lastly, the task orientation can differ between basic preprogrammed tasks (e.g., Roomba the cleaning robot), more cognitive-analytical tasks (e.g., image analysis software assistant for medical diagnosis), or socio-emotional tasks (e.g., SARA Singapore's Automated Responsive Assistant) <ref type="bibr" target="#b66">[68]</ref>. The same authors listed different characteristics that distinguish service robots and frontline employees on a micro (service training, learning, and customer experience), meso (market level), and macro dimension (societal level).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Ethics and Robots</head><p>"The emergence of the robotics industry is developing in much the same way that the computer business did 30 years ago" <ref type="bibr" target="#b20">[21]</ref>. As developed by Calo <ref type="bibr" target="#b6">[7]</ref>, robotics has a specific set of essential qualities and it generates distinct ethical and legal issues. When diving into the literature about robots, we can observe that most researchers support this statement. On the other hand, some concerns about the impact of robotics have emerged within society, as documented by numerous researchers, mainly because this technology could be unpredictable and potentially dangerous. For most technologies, the first concern is the safety of the product. Robotics is no exception to this rule. As robots are coded by human engineers and often consist of millions of lines of code, errors can occur. While these mistakes may not harm people in 'more basic' technological applications, they can be more problematic in the context of robotics. A great example is when, in 2010, the U.S. military lost control of a drone for more than thirty minutes. The drone violated a restricted airspace by flying towards Washington D.C. before operators managed to re-establish communication with it <ref type="bibr" target="#b5">[6]</ref>. Another concern is hacking, meaning that ill-intentioned individuals could take control of the robot. Furthermore, it is still unclear who should be responsible in case the robot makes an error. Holding robots responsible for their actions, especially if they are social robots, could lead to a better acceptance of them. However, affective responses towards robots differ from those towards human agents, implying that the responsibility is not perceived as valuable <ref type="bibr" target="#b60">[62]</ref>. Lin et al. <ref type="bibr" target="#b43">[45]</ref> adds that a natural way to minimize the risks that a robot could pose would be by programming them to obey laws and codes of ethics. Nevertheless, it remains an open question as to which ethical code or punishment should apply.</p><p>The social presence of robots is another gray area that will impact laws and regulations as well. KASPAR and IROMEC, for example, are specifically designed to be social mediators for children with special needs (e.g., Autism Spectrum Disorders) <ref type="bibr" target="#b40">[42]</ref>. Lin et al. <ref type="bibr" target="#b43">[45]</ref> explored the degree of companionship a robot should have: could it be a companion like a human or a pet? Could it be used as a drinking partner or a sexual partner? Or should a robot just be a "slave"?</p><p>Privacy is another issue to consider in this context. Indeed, research about privacy has proven the importance of this factor in a human-human context (medical records, lawyers, and clients). Research was then generalized to human-machine interactions: data privacy <ref type="bibr" target="#b52">[54]</ref>. Furthermore, it is now known that "data is the new oil" <ref type="bibr" target="#b3">[4]</ref>. Companies sell data, and they are considered the world's most valuable resource. More recently, the European Union has addressed this concept with the General Data Protection Regulation (GDPR), which became effective on May 25, 2018. It is the first and most important regulation concerning data privacy. The regulation focuses on several key requirements: consent of subjects for data processing, anonymizing collected data to protect privacy, providing data breach notifications, safely handling the transfer of data across borders and requiring certain companies to appoint a data protection officer to oversee GDPR compliance <ref type="bibr" target="#b10">[11]</ref>. If companies do not respect this regulation, they can pay fines up to 4% of their total global turnover or EUR 20 million.</p><p>Robots use lots of data to function at their full potential. In the context of service delivery, this could translate into the preferences of a customer or facial recognition for personalizing the customer experience. A robot needs to have this information to understand their interaction partners and thus behave intelligently <ref type="bibr" target="#b29">[30]</ref>. They are, therefore, subject to data privacy and related legislation.</p><p>As with any industrial or technological revolution, one of the biggest concerns is job losses. Some experts argue that every job that will disappear is being replaced by a new one <ref type="bibr" target="#b7">[8]</ref>. A standard response to the job-loss concern is that humans will be able to use more energy where they can make more impact <ref type="bibr" target="#b43">[45]</ref>. In other words, robots could improve working conditions (by doing menial tasks) and human productivity. Empathy, communication, creativity, and flexibility seem to be a competitive advantage against robots <ref type="bibr" target="#b11">[12]</ref>.</p><p>Trust is one of the major element in any social relation. People can become dependent on technology <ref type="bibr" target="#b14">[15]</ref>, which is why it has become an important issue in the development of new technologies. Technology has become such an important social actor that the characteristics of the relation are similar to human-human relationships. A sense of security, credibility, reliability, loyalty, and accuracy then applies to technology as well <ref type="bibr" target="#b48">[50]</ref>.</p><p>As robots become increasingly ubiquitous, ethical questions have become a central preoccupation. Experts have tried to identify critical ethical attributes and remedy them through ethical charters. The first one known was written by the science-fiction novelist Isaac Asimov in 1942. The European Robotics Research Network (EURON) decided to create, in 2005, The Roboethic Roadmap to provide a systematic assessment of ethical issues involved in the area of robotics R&amp;D. Finally, in 2007 in South Korea, a panel of experts met to adopt a robotic ethical charter. The idea was to create an ethical guideline to define the roles and functions of robots in the future <ref type="bibr" target="#b51">[53]</ref>.</p><p>Through this study, we want to explore the way ethics influence user's intention to use a service robot. We want to observe the importance of each ethical attribute on user's intention to use the service robot in the future. In the next section, we will share our research model and hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Research Model and Hypotheses</head><p>In this research, we will try to identify factors related to ethical issues that also impact the intention to use the robot in the future in a service delivery context (e.g., restaurant, hotel, hospital, etc.). Figure <ref type="figure" target="#fig_0">1</ref> shows our research model, and our hypotheses will be defined hereafter.</p><p>We have seen that service robots' appearance and behavior can closely resemble those of humans <ref type="bibr" target="#b66">[68]</ref>. Research has proven that too close a resemblance to a human might affect the acceptance of a robot <ref type="bibr" target="#b13">[14]</ref>. By human behaviors, we intend cases in which a robot acts as if it were human in a service delivery context, regardless of the shape of the robot (e.g., we might imagine a frontline service robot shaped as dog with human behaviors). Therefore, we will take this point into consideration in assessing the customers' intention to use the robot. A robot, in addition to delivering a service, needs to be a social actor (any person who undertakes social action). It can be translated by the fact that robots can be pleasant conversational partners or can even play a social role in a team. As defined by Darling <ref type="bibr" target="#b9">[10]</ref>, a "social robot" is a physically embodied, autonomous agent that communicates with humans through social cues, learning adaptively and mimicking human social states. van Doorn et al. <ref type="bibr" target="#b61">[63]</ref> theorized that a service robot's Automated Social Presence (i.e., giving the impression that there is someone else present with us) might have an impact on the customer experience. However, social presence is not the only characteristic which can make robots human-like. Emotions are important, and, according to de Kervenoael et al. <ref type="bibr" target="#b11">[12]</ref>, empathy could play a crucial role in Human-Robot Interaction (HRI). The authors showed that empathy has a significant and positive impact on the intention to use a social robot. Acting like a human is not only being able to display emotions, but also having facial expressions. In a study where participants played a game (Akinator) with a robot, researchers demonstrated that if the robot mirrors the facial expressions of the person with whom it is interacting, the intention to use the robot increases compared to when the robot does not display any facial expressions <ref type="bibr" target="#b24">[25]</ref>. As Wirtz et al. <ref type="bibr" target="#b66">[68]</ref> highlight, for human-robot relations to be successful, robots need to act like humans do. Indeed, they need to follow social norms and display the right emotions at the right time. In the context of service delivery robots this dimension can be directly and/or indirectly linked to ethics. Indeed, through the interviews also that we did before this study (with companies using robots, associations linked to AI &amp; ethics, Robot companies providers, etc.), we found that the social/human cues can be an antecedent for measuring the intention to use and for defining ethical issues. When we ask for example the following question to the users: "I perceive robots as social actors", one can claim that this question can be evaluated/interpreted through an ethical point of view. For this reason, we decided to integrate this dimension to our model. Therefore, we hypothesize that the more a robot acts like a human, the higher the user's intention to use it will be.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H1</head><p>The more a robot is expected to act like a human (social cues), the higher the user's intention to use it.</p><p>The next hypothesis focuses on the notion of trust. Lee &amp; See <ref type="bibr" target="#b39">[41]</ref> summarized several definition of trust and the way it can be measured according to each context. The focus was on the dimension of trust in automation, beliefs, attitudes, intentions, and behaviour. As mentioned in their article, people respond socially to technology and therefore trust influences reliance on automation. A simple definition of trust consistent with these considerations is the attitude that an agent will help achieve an individual's goals in a situation characterized by uncertainty and vulnerability <ref type="bibr" target="#b39">[41]</ref>. The level of trust in a service robot can impact the user intention to use it in the future. Etemad-Sajadi &amp; Sturman <ref type="bibr" target="#b15">[16]</ref> also found that trust has a significant impact on the intention to use a service robot. Indeed, for a product/service to be trusted, it needs to be safe. The issues could be mostly with their software design <ref type="bibr" target="#b43">[45]</ref> and lead to non-negligible problems. The safety issues robots could pose are related to physical, psychological and emotional damages. As for the physical safety of users, Salvini et al. <ref type="bibr" target="#b52">[54]</ref>, p. 456) notice that "As a matter of fact, predictability, namely, the possibility to tell in advance a machine behaviour, which is a fundamental criteria for determining the safety of industrial robots, is not applicable to a service robot, due to its ability to generate autonomous behaviour in response to changing environments". Vasic &amp; Billard <ref type="bibr" target="#b62">[64]</ref> share the same opinion: they observed that mobile robots are increasingly present in workplaces where they do not have an assigned functioning space, as would be the case for industrial robots. In this context, as the authors argue, robots rely on their sensor to avoid physical contact with humans, which can sometimes be fallible. Robots are also vulnerable to cyberattacks, which can create dangerous situations for users. Denning et al. <ref type="bibr" target="#b12">[13]</ref> cite multiple possible attacks that people could possibly be subjected to with robots at home, such as an attacker eavesdropping on conversations being had in the home. Finally, researchers have shown that people can be emotionally attached to their robots (Roomba™ the vacuum cleaner robot in this case), to the point of caring and worrying about them <ref type="bibr" target="#b57">[59]</ref>. In the context of robots in elderly care, Sparrow &amp; Sparrow <ref type="bibr" target="#b53">[55]</ref> argue that, for now, robots are "not capable of real friendship, love, or concern" (p. 154). They concluded that technology is only deceiving users into thinking they are being cared for. The question of emotional harm can therefore be asked: could there be dependence on robots which could harm users emotionally <ref type="bibr" target="#b50">[52]</ref>? According to these points, we hypothesize that the more the robot is safe and trustworthy, the higher the user's intention to use it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H2</head><p>The more a robot is safe and trustworthy, the higher the user's intention to use it.</p><p>It is still unclear to which extent a robot should be kept under supervision, controlled, or act on its own. This study aims to consider this point. Beer et al. <ref type="bibr" target="#b1">[2]</ref> define autonomy as "the extent to which a system can carry out its own processes and operations without external control" (p. 77). In other words, autonomy is the degree to which a robot can do its tasks without a human's input. The concept also refers to the ability of a robot to adapt to its environment and is crucial to study HRI <ref type="bibr" target="#b58">[60]</ref>. We hypothesize that the higher the perception of a robot's autonomy, the higher the user's intention to use it will be.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H3</head><p>The more a robot is expected to act autonomously, the higher the user's intention to use it.</p><p>When a problem occurs among humans, responsibility is an inevitable legal and psychological process. In the case of robotics, it is still unclear who should be responsible, as laws and regulations are still emerging in this area, and the philosophical debate is still ongoing (cf., among others: <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b36">38,</ref><ref type="bibr" target="#b46">48,</ref><ref type="bibr" target="#b54">56]</ref>. In an empirical study, Furlough et al. <ref type="bibr" target="#b19">[20]</ref> found that when an error occurs, people tend to blame humans first, then robots and finally the environment. In their study, when the robot was described to the participant as autonomous, it received more blame than when it was described as non-autonomous, although it still received less blame than humans. These results were corroborated by a study conducted by Leo &amp; Huh <ref type="bibr" target="#b41">[43]</ref>, who found that, in case of service failures, humans tend to attribute less blame to robots than humans. With these results in mind, it appears important for a company (i.e., humans,) to take responsibility for errors, even when those mistakes are made by a robot. Therefore, we hypothesize that the more a company seems to be responsible for their robot's acts, the more customers will intend to use the robot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H4</head><p>The more a company, through its use of a robot, seems to be responsible for the robot's acts, the higher the user's intention to use it.</p><p>Privacy and data protection have been a central subject for a few years now, especially with the adoption of GDPR and some scandals like Cambridge Analytics during the American presidential campaign. It is an important concern and thus a point to take into consideration in our research. Robots are equipped with sensors such as cameras and microphones in order to navigate their environment and interact with people. However, this also means that they are capable of collecting information and data, which can be seen as a risk for the privacy of customers <ref type="bibr" target="#b66">[68]</ref>. Moreover, customers do not always appear to understand the kind of data collected by a robot <ref type="bibr" target="#b38">[40]</ref>. Similarly, users may be biased into thinking that their privacy is more protected than it really is. Indeed, preliminary results by Tonkin et al. <ref type="bibr" target="#b59">[61]</ref> showed that embodied systems (i.e., having a more anthropomorphic physical form) tend to decrease customer privacy concerns compared to non-embodied ones, which means that embodied robots might collect more data than a non-embodied one. There are laws in place that regulate data collection and protect individuals, such as the General Data Protection Regulation (GDPR) in the European Union <ref type="bibr" target="#b33">[34]</ref>. Nevertheless, it is important to assess how privacy and data protection impacts the user's intention to use a robot. An empirical study led by Vitale et al. <ref type="bibr" target="#b65">[67]</ref> found that transparent systems (i.e., a system openly communicating the privacy policies it uses) result in a better user experience (out of the 5 UX variables: more attractive, more dependable, more stimulating and more novel) than systems that are not transparent. Consequently, we hypothesize that the more a robot is seen as a threat to privacy and data protection, the lower the user's intention to use it will be.</p><p>H5 When the robot is seen as a threat to privacy and data protection, it impacts negatively the user's intention to use it.</p><p>In every technological revolution, people tend to be afraid of the revolution's impact on jobs and unemployment. As robots tend to be more precise, they can process a large amount of data and act rapidly. They will, therefore, replace certain jobs. On the other hand, they can be a great partner in improving the productivity and efficiency of human workers or in completing unpleasant or menial tasks <ref type="bibr" target="#b7">[8]</ref>. As Salvini et al. <ref type="bibr" target="#b49">[51]</ref> highlighted, the price of a robot has decreased while the cost of human labor has increased, and the authors argue that the same will surely happen with social robots in the near future. This fact can naturally raise concerns about the place of humans in the workforce. Moreover, the International Federation of Robotics (who are of the opinion that humans will remain competitive and that automation will create new jobs (IFR, [37]) stated that robots can improve a company's productivity for certain tasks which they execute more efficiently than humans (IFR <ref type="bibr" target="#b35">[36]</ref>). According to a survey analysis conducted by Morikawa <ref type="bibr" target="#b44">[46]</ref>, about 30% of human workers fear being replaced by either a robot or AI, which is substantial but far from constituting a majority of workers. Looking at the data of a European citizens' survey, Granulo et al. <ref type="bibr" target="#b26">[27]</ref> also reported that citizens tend to be scared of being replaced in their jobs by robots. As Salvini et al. (2010, p. 456) argue, "One of the strongest social motivations for not accepting a robot, perhaps above and beyond safety and aesthetic considerations, is related to the widespread feeling that robots can take over jobs that are traditionally the domain of humans". In the present research 123 paper, we hypothesize that when robots are seen as a potential threat to their employment, the user's intention to use a robot decreases.</p><p>H6 When a robot is seen as a threat to human jobs, it decreases the user's intention to use it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Measures, Sampling and Data collection procedures</head><p>Response options for each item have been ranked from 1 (strongly disagree) to 7 (strongly agree). Table <ref type="table" target="#tab_0">1</ref> summarizes the constructs and the items.</p><p>It was important for us that everybody would start the survey with some basic knowledge of and experience with robots in a service delivery context. To achieve this goal, we incorporated a video that showed Pepper, the robot, in action on the campus of an international business school in Switzerland. The Fig. <ref type="figure">2</ref> shows Pepper in action, going to a table of potential users and having a conversation. The robot was controlled with the Avatar Remote Control application on a tablet (developed by our partners from Heigvd). Questions asked by the users were very diverse, ranging from "How is the weather?" to precise questions about the school.</p><p>Then respondents had to answer questions about their perception of robots based on the video. The estimated duration for answering to our survey was 10 min. The survey was taken by a panel of very different people, as everyone in the future could potentially interact with this kind of robot. To do so, we decided to share the survey via four main platforms: Prolific, WhatsApp, Facebook, and LinkedIn. We also compared the results according to their sources in order to identify if we would have significant differences between the clusters. No significant differences were observed. In the end, we obtained 341 responses, out of which 57.1% of respondents were female, and 42.9% were male. The average age of people taking the survey was 33 years old and the median was 29 years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Analysis Method</head><p>Structural equation modeling (SEM) was adopted to test the hypotheses due to the fact that the model contains several latent variables. SmartPLS 3.0 was used for the analysis. We employed a bootstrapping method (500 sub-samples) to test the significant level of regression path coefficients. We used the blindfolding approach (cross-validated communality and redundancy). The quality of each structural equation was measured by the cv-redundancy index (i.e., Stone-Geisser Q 2 ). Q 2 measures the extent to which observed values are reconstructed by the model and its parameter estimates <ref type="bibr" target="#b8">[9]</ref>. The technique represents a synthesis of function fitting and cross-validation <ref type="bibr" target="#b31">[32]</ref>. If its value is around 0.35, it means that there is a high predictive relevance <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b31">32]</ref>. In this model, the independent variables are therefore good predictors of intention to use, as Q 2 is equal to 0.327.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reliability and Validity of Measures</head><p>Table <ref type="table" target="#tab_1">2</ref> shows that all latent variables have a composite reliability higher than 0.7, confirming that the scale reliabilities have adequate and stable measurement properties. Convergent and discriminant validity are components of a larger measurement concept known as construct validity <ref type="bibr" target="#b56">[58]</ref>. Convergent validity is shown when each measurement item is strongly correlated with its construct. It is usually satisfied by retaining variables whose loadings are high, indicating that they share sufficient variance with their related construct. Discriminant validity is confirmed when each measurement item is weakly correlated with all other constructs except with the one with which it is theoretically associated <ref type="bibr" target="#b23">[24]</ref>. With PLS, convergent and discriminant validities are confirmed if each construct Average Variance Extracted (AVE) is larger than its correlation with other constructs. Moreover, each item should load more highly on its assigned construct than on the other constructs <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b56">58]</ref>. Table <ref type="table" target="#tab_1">2</ref> shows the intercorrelation of the research constructs. The diagonal of this matrix represents the square root of the average variance extracted. For adequate discriminant validity, the diagonal elements should be significantly larger than the correlation of the specific construct with any of the other constructs and should be at least 0.5 <ref type="bibr" target="#b16">[17]</ref>. In our case, one can claim that discriminant validity is confirmed and sufficient to support the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Discussion</head><p>Figures <ref type="figure">3</ref> and<ref type="figure">4</ref> show our results. On Fig. <ref type="figure">3</ref>, the vertical axis represents the mean for each latent variable and the horizontal axis represents the impact of the independents variables on the "intention to use". Focusing first on the vertical axis, we observed that the most important ethical issue is the "replacement and its implications for labor" (i.e., I think robots in a service delivery context will cut employment) with an average of 5.25 on a Likert scale from 1 to 7 (SD 1.35). The second dimension is the "privacy and data protection" (i.e., I mind giving personal information to a robot in a ser- 123 Fig. <ref type="figure">2</ref> The pepper robot in action vice delivery context) with an average of 5.09 (SD 1.36).</p><p>The third most worrying dimension is "responsibility" (i.e., I think the law, and subsequent punishment, should apply to robots in a service delivery context) with an average of 4.62 (SD 1.87). The value of means for "trust and safety", "social cues", and "autonomy" are respectively 4.43 (SD 1.48), 3.9 (SD 1.44), and 3.46 (SD 1.23).</p><p>When we measure the impact of each ethical issue on the intention to use the robot in the future, we observe that "trust and safety" (i.e., I perceive robots as safe in a service delivery context) is the most impacting variable on the decision whether to use the robot. Therefore, our hypothesis H2 (γ 0.380) is accepted. The second variable impacting the intention to use a service delivery robot is "social cues" (i.e., I perceive robots as social actors in a service delivery context), and this confirms our hypothesis H1 (γ 0.325). The third variable impacting negatively the intention to use the robot is "privacy and data protection". This result confirms hypothesis H5 (γ -0.178). The fourth variable impacting the intention to use is the "responsibility". Indeed, H4 is barely accepted (γ 0.079). As far as "autonomy" (i.e., "I think that a robot in a service delivery context should be able to act on its own") is concerned, one can claim that the impact is not relevant to the intention to use and that the perception of this dimension as an ethical problem is also not very high compared to the other ethical issues. This is also the case for the variable named "replacement". Therefore, H3 and H6 are rejected. Our model explains 50.7% of the intention to use  and therefore one can claim that our ethical issues are good predictors of the intention to use the robot Table <ref type="table" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This study has shed light on the extent to which ethical issues influence the intention to use robots. Four out of six items were found to have a significant effect on the intention to use a service robot: social cues, trust/safety, responsibility, and privacy/data protection. The two hypotheses which were rejected, namely autonomy and human replacement, do not play a role in the intention of a customer to use a robot. However, it does not mean that these variables do not constitute important ethical considerations. When we look at the fear of human replacement, the perception of this dimension is very high meaning that people are afraid of being replaced. That said, this variable is not directly impacting the intention to use the robot. It can be interesting to see in the future the indirect impact of these dimensions (autonomy and human replacement) on the intention to use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Managerial Implications</head><p>Robots in a service delivery context are still not very common. Researchers, engineers and service delivery professionals should not forget the ethical questions linked to the ambition to test and use robots in the future. As an example, Battistuzzi et al. <ref type="bibr" target="#b32">[33]</ref> developed a research ethics training module in the context of culture-aware robots and environmental sensor systems for elderly support. This training can help researchers conduct experiments in an ethically appropriate manner.</p><p>Our research can help service delivery professionals and engineers to understand how they can make robots more desirable by also considering ethical issues. Robots in a service delivery context will become increasingly omnipresent, and they can genuinely enhance service quality. While a good return on investment for hotels <ref type="bibr" target="#b69">[71]</ref>, they must understand how robots can be used and programmed to maximize guests' intention to use. We found that the sentiment of trust and safety is the factor that impacts the intention to use the robot the most. Moreover, we saw that robots are expected The more a robot is expected to act like a human (social cues), the higher the user's intention to use it</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confirmed</head><p>Trust and Safety H2: The more a robot is safe and trustworthy, the higher the user's intention to use it Confirmed Autonomy H3: The more a robot is expected to act autonomously, the higher the user's intention to use it Rejected Responsibility H4: The more a company, through its use of a robot, seems to be responsible for the robot's acts, the higher the user's intention to use it</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confirmed</head><p>Privacy and data protection H5: When the robot is seen as a threat to privacy and data protection, it impacts negatively the user's intention to use it Confirmed Replacement H6: When a robot is seen as a threat to human jobs, it decreases the user's intention to use it Rejected to display social cues. In order to optimize the use of robots, we advise companies to heed the following ethical concerns. Below you will find the 6 dimensions:</p><p>1. Social Cues According to our findings, the more a robot displays social cues, the higher the user's intention to use it will be. Therefore, robots should deliver a service that is as human-like as possible and, thus, include social features. However, a service robot should not hinder or replace human-to-human interactions <ref type="bibr" target="#b4">[5]</ref>. It is important to guarantee this aspect when a company want to use robots in a service delivery context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Trust and Safety</head><p>The extent to which a robot is deemed safe and trustworthy is important to the user's intention to use the technology. Although it can be argued that designers and producers are responsible for creating robots that are safe for users <ref type="bibr" target="#b45">[47]</ref>, companies using a service robot must always guarantee this major dimension. 3. Autonomy Even though, in our case, this variable did not have an influence on the user's intention to use a robot, the idea of being able to restrict a robot's autonomy can be found in ethical charters. Therefore, we argue that a company using a service robot should always be able to regulate a robot's autonomy, especially in cases when the consequences of the robot's actions cannot be totally controlled. 4. Responsibility A robot's responsibility for its actions is important for the user's intention to use the technology. Therefore, companies using a service robot should pay attention to this point and clearly define, before the deployment of their robot, who is responsible for the robot's actions <ref type="bibr" target="#b42">[44]</ref>, pp. 8-10, <ref type="bibr" target="#b45">[47]</ref>. Moreover, to ensure liability, a robot's actions and decisions must always be traceable <ref type="bibr" target="#b34">[35]</ref>. 5. Privacy and Data Protection Privacy and data protection play a big role in the intention to use a robot. First, a company using a service robot should always respect its customers' right to privacy <ref type="bibr" target="#b47">[49]</ref>. As transparency (i.e., disclosure about what, how and why is collected) leads to a better user experience <ref type="bibr" target="#b65">[67]</ref>, we advise companies (and their robots) to be transparent regarding the collection and use of their customers' data <ref type="bibr" target="#b34">[35]</ref>. Secondly, companies using service robots should ensure that they protect their customer's data by encrypting and safekeeping them. Third, companies should always make sure that the robot's data collection follows official guidelines and local laws <ref type="bibr" target="#b47">[49]</ref>. Finally, as mentioned by Fosch-Villaronga &amp; Millard <ref type="bibr" target="#b18">[19]</ref>, several legal and regulatory questions have to be considered by the integration of physical robotic systems with cloud-based services. 6. Human Workers Replacement Although this variable was not found to be important in our model, best practices in relation to the subject can be established. A company should incorporate its employees in the choices and decisions related to the service robot, such as the choice of the robot, or the decisions related to the definition of its tasks <ref type="bibr" target="#b2">[3]</ref>. In case a robot should take a worker's job, the firm should retrain its employee for a new occupation <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Limitations</head><p>This research paper has several limitations. First, as demonstrated by Beer et al. <ref type="bibr" target="#b0">[1]</ref>, socio-demographic factors are a key determinant of the acceptance and the intention to use a robot. Our research did not evenly represent ages or cultures/nationalities. Second, we decided to introduce our survey with a 1-min video in order to align the different respondents. This method may have altered some answers to the survey. Moreover, the video showed the robot Pepper in a service delivery context. Therefore, the results might be only generalizable to robots similar to Pepper in shape (i.e., humanoid robots which are still far from resembling closely to a human). Indeed, there are many different types of service robots which have not been tested and therefore we have to be careful in the generalization of our findings. Third, we have to be careful on the generalization of our findings due to the external validity and our scenario-based study compared to a real interaction. Moreover, there is a "wow" effect when you interact for a first time with a service robot and after several interactions, the experience can become usual. Fourth, this exploratory research sometimes highlighted the weakness of some items. In addition to this point, the low reliability has forced us to delete, in certain instances, an important number of items. That said, in the end, we have four accepted and two rejected hypotheses, and more than 50% of our dependent variable is explained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Suggestions for Future Research</head><p>For future research, we advise extending the geographic scope to minimize the influence of socio-demographic factors. Another way to work with this problem would be to use two determined perimeters with different socio-demographic factors (e.g., Switzerland and Japan). As this technology is still new and some people might be afraid to use it, in the future, a constructed experimentation and survey could be applied regularly (every five to ten years) to monitor the evolution of ethical issues and the intention to use robots. Moreover, the data of this research was collected before the COVID-19 outbreak. In the context of the pandemic, people have to protect themselves and others with measures such as social distancing. Consequently, human-to-human interactions have been more complicated than before. However, an interesting aspect is that robots can help in the current situation, and different solutions have been considered or developed (e.g., development of a telerobot for healthcare applications: <ref type="bibr" target="#b67">[69]</ref>, global review of robots during the COVID-19 pandemic with a focus on the tourism and hospitality field: <ref type="bibr" target="#b68">[70]</ref>. With this in mind, people might get more used to interacting with robots, and the variables influencing their intention to use, or the quality of service delivered by a robot might also change. As Kim et al. <ref type="bibr" target="#b37">[39]</ref> showed, during health crises such as the COVID-19 pandemic, people tend to prefer a robot-based service than one delivered by humans, whereas they prefer the opposite (or a mixed-model) in 'normal' times. Therefore, it would be interesting to replicate the present study in the mid-term future, to see whether the ethical items selected are still relevant to the intention to use a service robot, or if other ethical dimensions arise.</p><p>Funding Open access funding provided by University of Applied Sciences and Arts Western Switzerland (HES-SO).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 Research model</figDesc><graphic coords="4,70.12,56.21,455.08,308.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 Fig. 4</head><label>34</label><figDesc>Fig. 3 Perception of each dimension and the impact of the intention to use</figDesc><graphic coords="8,182.23,495.14,361.48,217.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,69.64,56.84,455.08,363.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Questionnaire items</cell><cell>Constructs</cell><cell>Items</cell><cell>Adapted from</cell></row><row><cell></cell><cell>Social cues</cell><cell>I want robots in a service delivery</cell><cell>Beer et al. [1], Gefen et al. [23]</cell></row><row><cell></cell><cell></cell><cell>context to be human-like</cell><cell></cell></row><row><cell></cell><cell></cell><cell>I want robots in a service delivery</cell><cell></cell></row><row><cell></cell><cell></cell><cell>context to act like humans</cell><cell></cell></row><row><cell></cell><cell></cell><cell>I perceive robots as social actors</cell><cell></cell></row><row><cell></cell><cell></cell><cell>(any person who undertakes social</cell><cell></cell></row><row><cell></cell><cell></cell><cell>action) in a service delivery</cell><cell></cell></row><row><cell></cell><cell></cell><cell>context</cell><cell></cell></row><row><cell></cell><cell>Trust and Safety</cell><cell>I perceive robots as safe in a service</cell><cell>Stahl and Coeckelbergh [57], Gefen</cell></row><row><cell></cell><cell></cell><cell>delivery context</cell><cell>et al. [23]</cell></row><row><cell></cell><cell></cell><cell>I think that robots in a service</cell><cell></cell></row><row><cell></cell><cell></cell><cell>delivery context are vulnerable to</cell><cell></cell></row><row><cell></cell><cell></cell><cell>hackers (i)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>I would hesitate to use robots in a</cell><cell></cell></row><row><cell></cell><cell></cell><cell>service delivery context for fear of</cell><cell></cell></row><row><cell></cell><cell></cell><cell>making errors that will harm me</cell><cell></cell></row><row><cell></cell><cell></cell><cell>(i)</cell><cell></cell></row><row><cell></cell><cell>Autonomy</cell><cell>I think a robot in a service delivery</cell><cell>Stahl and Coeckelbergh [57],</cell></row><row><cell></cell><cell></cell><cell>context should deliver limited</cell><cell>European Union's Convention on</cell></row><row><cell></cell><cell></cell><cell>tasks (i)</cell><cell>Roboethics (2010)</cell></row><row><cell></cell><cell></cell><cell>I think a robot in a service delivery</cell><cell></cell></row><row><cell></cell><cell></cell><cell>context should be able to act on its</cell><cell></cell></row><row><cell></cell><cell></cell><cell>own</cell><cell></cell></row><row><cell></cell><cell>Responsibility</cell><cell>I think the law, and subsequent</cell><cell>Lin et al. [45], Stahl and</cell></row><row><cell></cell><cell></cell><cell>punishment, should apply to</cell><cell>Coeckelbergh [57],</cell></row><row><cell></cell><cell></cell><cell>robots in a service delivery</cell><cell></cell></row><row><cell></cell><cell></cell><cell>context</cell><cell></cell></row><row><cell></cell><cell></cell><cell>The company is responsible for the</cell><cell></cell></row><row><cell></cell><cell></cell><cell>robot's actions in case a client is</cell><cell></cell></row><row><cell></cell><cell></cell><cell>wrongly informed by the robot</cell><cell></cell></row><row><cell></cell><cell>Privacy and Data protection</cell><cell>I should be informed of how robots</cell><cell>Graeff and Harmon [26], Stahl and</cell></row><row><cell></cell><cell></cell><cell>will use information about me</cell><cell>Coeckelbergh [57]</cell></row><row><cell></cell><cell></cell><cell>I don't mind giving personal</cell><cell></cell></row><row><cell></cell><cell></cell><cell>information to a robot in a service</cell><cell></cell></row><row><cell></cell><cell></cell><cell>delivery context (ex: name, age,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>food preferences for informative</cell><cell></cell></row><row><cell></cell><cell></cell><cell>robots, nature of my illness for a</cell><cell></cell></row><row><cell></cell><cell></cell><cell>healthcare robot, etc.) (i)</cell><cell></cell></row><row><cell></cell><cell>Replacement</cell><cell>I think robots in a service delivery</cell><cell>Lin et al. [45]</cell></row><row><cell></cell><cell></cell><cell>context will contribute to</cell><cell></cell></row><row><cell></cell><cell></cell><cell>unemployment</cell><cell></cell></row><row><cell></cell><cell></cell><cell>I think robots in a service delivery</cell><cell></cell></row><row><cell></cell><cell></cell><cell>context can improve the working</cell><cell></cell></row><row><cell></cell><cell></cell><cell>conditions of human coworkers (i)</cell><cell></cell></row><row><cell></cell><cell>Intention to use</cell><cell>Assuming I could have access to a</cell><cell>Venkatesh [65], Hellier et al. [31]</cell></row><row><cell></cell><cell></cell><cell>robot in a service delivery context,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>I would use it</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Assuming I could have access to a</cell><cell></cell></row><row><cell></cell><cell></cell><cell>robot in a service delivery context,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>I would prefer to use it instead of</cell><cell></cell></row><row><cell></cell><cell></cell><cell>a human</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Overall, I was impressed by robots</cell><cell></cell></row><row><cell></cell><cell></cell><cell>in a service delivery context</cell><cell></cell></row><row><cell></cell><cell></cell><cell>I would recommend to the people</cell><cell></cell></row><row><cell></cell><cell></cell><cell>surrounding me to interact with a</cell><cell></cell></row><row><cell></cell><cell></cell><cell>robot in a service delivery context</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Reliability and discriminant validity</figDesc><table><row><cell>Constructs</cell><cell cols="2">Composite reliability</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell></row><row><cell>1. Autonomy</cell><cell>0.70</cell><cell></cell><cell>0.75 a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2. Social cues</cell><cell>0.83</cell><cell></cell><cell>0.32</cell><cell>0.79</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3. Intention to use</cell><cell>0.89</cell><cell></cell><cell>0.36</cell><cell>0.52</cell><cell>0.82</cell><cell></cell><cell></cell><cell></cell></row><row><cell>4. Privacy and data protection</cell><cell>1</cell><cell></cell><cell>-0.35</cell><cell>-0.37</cell><cell>-0.49</cell><cell>1</cell><cell></cell><cell></cell></row><row><cell>5. Replacement</cell><cell>1</cell><cell></cell><cell>-0.11</cell><cell>-0.01</cell><cell>-0.10</cell><cell>0.17</cell><cell>1</cell><cell></cell></row><row><cell>6. Responsibility</cell><cell>1</cell><cell></cell><cell>0.08</cell><cell>0.16</cell><cell>0.17</cell><cell>-0.04</cell><cell>0.13</cell><cell>1</cell></row><row><cell>7. Trust and safety</cell><cell>0.89</cell><cell></cell><cell>0.325</cell><cell>0.267</cell><cell>0.57</cell><cell>-0.44</cell><cell>-0.20</cell><cell>0.06</cell><cell>0.89</cell></row><row><cell cols="2">a &gt; Diagonal: (Average variance extracted) 1/2 ( λ i</cell><cell>2 /n) 1/2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Summary</figDesc><table><row><cell>hypotheses</cell><cell>of the</cell><cell>Constructs</cell><cell>Hypotheses</cell><cell>Status</cell></row><row><cell></cell><cell></cell><cell>Social cues</cell><cell>H1:</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Availability</head><p>The datasets analysed during the current study are available from the corresponding author on reasonable request.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adap-tation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ref type="url" target="http://creativecommons.org/licenses/by/4.0/">http://creativecomm ons.org/licenses/by/4.0/</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Understanding robot acceptance</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Beer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Mitzner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rogers</forename><forename type="middle">Wa</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="1" to="45" />
		</imprint>
		<respStmt>
			<orgName>Georgia Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Toward a framework for levels of robot autonomy in human-robot interaction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Beer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Fisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rogers</forename><forename type="middle">Wa</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Human-Robot Interact</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="74" to="99" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Current trends in robotics: technology and ethics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Bekey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot ethics: the ethical and social implications of robotics</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Abney</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Bekey</surname></persName>
		</editor>
		<meeting><address><addrLine>London, England</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="17" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Council Post: Data Is The New Oil --And That&apos;s A Good Thing</title>
		<author>
			<persName><surname>Bhageshpur</surname></persName>
		</author>
		<ptr target="https://www.forbes.com/sites/forbestechcouncil/2019/11/15/data-is-the-new-oil-and-thats" />
	</analytic>
	<monogr>
		<title level="j">Forbes</title>
		<imprint>
			<biblScope unit="page">7304</biblScope>
			<date type="published" when="2019-11-15">2019. November 15</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robot Caregivers: Ethical Issues across the Human Lifespan</title>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot ethics: the ethical and social implications of robotics</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Abney</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Bekey</surname></persName>
		</editor>
		<meeting><address><addrLine>London, England</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="251" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Navy Drone Violated Washington Airspace</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bumiller</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2010/08/26/us/26drone.html" />
	</analytic>
	<monogr>
		<title level="j">The New York Times</title>
		<imprint>
			<date type="published" when="2010-08-25">2010. August 25</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robotics and the new cyberlaw</title>
		<author>
			<persName><forename type="first">R</forename><surname>Calo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Calif Law Rev</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="101" to="146" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robots &apos;to replace up to 20 million factory jobs&apos; by 2030</title>
		<author>
			<persName><forename type="first">Cellan-Jones</forename></persName>
		</author>
		<ptr target="https://www.bbc.com/news/business-48760799" />
	</analytic>
	<monogr>
		<title level="j">BBC News</title>
		<imprint>
			<date type="published" when="2019-06-26">2019. June 26</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The partial least squares approach to structural equation modeling</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Chin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Modern Method Business Res</title>
		<imprint>
			<biblScope unit="volume">295</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="295" to="336" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Extending legal protection to social robots: the effects of anthropomorphism, empathy, and violent behavior towards robotic objects</title>
		<author>
			<persName><forename type="first">K</forename><surname>Darling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Edward Elgar Publishing</publisher>
		</imprint>
	</monogr>
	<note>Robot law</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What is the General Data Protection Regulation? Understanding &amp; Complying with GDPR Requirements in 2019</title>
		<author>
			<persName><forename type="first">J</forename><surname>De Groot</surname></persName>
		</author>
		<ptr target="https://digitalguardian.com/blog/what-gdpr-general-data-protection-regulation-understanding-and-complying-gdpr-data-protection" />
	</analytic>
	<monogr>
		<title level="j">Digital Guardian</title>
		<imprint>
			<date type="published" when="2020-09-30">2020. September 30</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Leveraging human-robot interaction in hospitality services: Incorporating the role of perceived value, empathy, and information sharing into visitors&apos; intentions to use social robots</title>
		<author>
			<persName><forename type="first">R</forename><surname>De Kervenoael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schwob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tour Manage</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A spotlight on security and privacy risks with future household robots</title>
		<author>
			<persName><forename type="first">T</forename><surname>Denning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Koscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kohno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International conference on ubiquitous computing</title>
		<meeting>the 11th International conference on ubiquitous computing</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Anthropomorphism and the social robot</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Duffy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot Auton Syst</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="177" to="190" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Building technology trust in ICT application at a university</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ejdys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Emerg Mark</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="980" to="997" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How to Increase the Customer Experience by the Usage of Remote Control Robot Concierge Solutions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Etemad-Sajadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Sturman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Robotics</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluating structural equation models with unobservable variables and measurement error</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fornell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Larcker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Mark Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gathering expert opinions for social robots&apos; ethical, legal, and societal concerns: Findings from four international workshops</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fosch-Villaronga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamò-Larrieux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Soc Robot</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="441" to="458" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cloud robotics law and regulation: Challenges in the governance of complex and dynamic cyber-physical ecosystems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fosch-Villaronga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Millard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot Auton Syst</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="77" to="91" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attributing blame to robots: I the influence of robot autonomy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Furlough</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Gillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Factors J Human Factors Ergonomics Soci</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="592" to="602" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Robot in Every Home</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Am</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="65" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Structural equation modeling and regression: guidelines for research practice</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gefen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Boudreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communi Associat Infor Sys</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Trust and TAM in online shopping: an integrated model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gefen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Karahanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Straub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIS Q</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="90" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A practical guide to factorial validity using PLS-graph: tutorial and annotated example</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gefen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Straub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Assoc Inf Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="91" to="109" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gonsior</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sosnowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Radig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wollherr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kühnlenz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MAN</title>
		<imprint>
			<biblScope unit="page" from="350" to="356" />
			<date type="published" when="2011">2011. 2011</date>
			<pubPlace>Atlanta, GA</pubPlace>
		</imprint>
	</monogr>
	<note>RO</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Collecting and using personal data: consumers&apos; awareness and concerns</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Graeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harmon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Consum Mark</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="302" to="318" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Psychological reactions to human versus robotic job replacement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Granulo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Puntoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1062" to="1069" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mind the gap: responsible robotics and the problem of responsibility</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Gunkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ethics Inf Technol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="307" to="320" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An assessment of the use of partial least squares structural equation modeling in marketing research</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Mena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Acad Mark Sci</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="414" to="433" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Hedaoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wadgaonkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Knight</surname></persName>
		</author>
		<title level="m">A robot barista comments on its clients: social attitudes toward robot data use 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="66" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Customer repurchase intention: a general structural equation model</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Hellier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Geursen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Rickard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur J Mark</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11/12</biblScope>
			<biblScope unit="page" from="1762" to="1800" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The use of partial least squares path modeling in international marketing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Henseler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Ringle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Sinkovics</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv Int Mark</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="277" to="319" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Socially assistive robots, older adults and research ethics: the case for case-based ethics training</title>
		<author>
			<persName><forename type="first">L</forename><surname>Battistuzzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sgorbissa</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12369-020-00652-x</idno>
		<ptr target="https://doi.org/10.1007/s12369-020-00652-x" />
	</analytic>
	<monogr>
		<title level="j">Int J Social Robot</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robotics and law: Key legal and regulatory implications of the robotics age (Part I of II)</title>
		<author>
			<persName><forename type="first">C</forename><surname>Holder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Khurana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Law Secur Rev</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="383" to="402" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems</title>
		<author>
			<persName><surname>Ieee</surname></persName>
		</author>
		<ptr target="https://standards.ieee.org/content/ieee-standards/en/industry-connections/ec/autonomous-systems.html" />
	</analytic>
	<monogr>
		<title level="m">The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>First Edition</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The impact of robots on productivity, employment and jobs</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>International Federation of Robotics</publisher>
		</imprint>
	</monogr>
	<note>A positioning paper by the International Federation of Robotics 37. International Federation of Robotics (2018) Robots and the workplace of the future. A positioning paper by the International Federation of Robotics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Technology with no human responsibility?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Bus Ethics</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="707" to="715" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Preference for robot service or human service in hotels? Impacts of the COVID-19 pandemic</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Badu-Baiden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Giroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Hosp Manag</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Understanding users&apos; perception of privacy in human-robot interaction</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kiesler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th international conference on Human-robot interaction -HRI</title>
		<meeting>the 6th international conference on Human-robot interaction -HRI</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="181" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Trust in automation: Designing for appropriate reliance</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>See</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum Factors</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="80" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robot companions for children with down syndrome</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Iacono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interact Stud</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="112" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Who gets the blame for service failures? Attribution of responsibility toward robot versus human service providers and service firms</title>
		<author>
			<persName><forename type="first">X</forename><surname>Leo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Huh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Hum Behav</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Introduction to Robot Ethics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot ethics: the ethical and social implications of robotics</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Abney</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Bekey</surname></persName>
		</editor>
		<meeting><address><addrLine>London, England</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="3" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Robot ethics: the ethical and social implications of robotics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Bekey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Who are afraid of losing their jobs to artificial intelligence and robots? evidence from a survey</title>
		<author>
			<persName><forename type="first">M</forename><surname>Morikawa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
	<note>EconStor, GLO Discussion Paper</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Ethical regulations on robotics in Europe</title>
		<author>
			<persName><forename type="first">M</forename><surname>Nagenborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Capurro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pingel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI &amp; Soc</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="366" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Attributing agency to automated systems: reflections on human-robot collaborations and responsibility-loci</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nyholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Eng Ethics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1201" to="1219" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A code of ethics for the human-robot interaction profession</title>
		<author>
			<persName><forename type="first">L</forename><surname>Riek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of we robot</title>
		<meeting>we robot</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Not so different after all: a cross-discipline view of trust</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Rousseau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Sitkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Camerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad Manag Rev</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="393" to="404" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Design for acceptability: improving robots&apos; coexistence in human society</title>
		<author>
			<persName><forename type="first">P</forename><surname>Salvini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Laschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Soc Robot</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="460" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The inherent dangers of unidirectional emotional bonds between humans and social robots</title>
		<author>
			<persName><forename type="first">M</forename><surname>Scheutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robot ethics: the ethical and social implications of robotics</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Lin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Abney</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Bekey</surname></persName>
		</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="205" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Looking forward to sociable robots</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shaw-Garlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Soc Robot</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="260" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Understanding privacy</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Solove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">In the hands of machines? The future of aged care</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sparrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sparrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind Mach</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="161" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Killer robots</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sparrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Appl Philos</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="77" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ethics of healthcare robotics: Towards responsible research and innovation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Stahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Coeckelbergh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robot Auton Syst</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="152" to="161" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Validation guidelines for IS positivist research</title>
		<author>
			<persName><forename type="first">D</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-C</forename><surname>Boudreau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gefen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Assoc Inf Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="380" to="427" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">My roomba is rambo&quot;: intimate home appliances</title>
		<author>
			<persName><forename type="first">J</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Grinter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">I</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UbiComp 2007: ubiquitous Computing Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4717</biblScope>
			<biblScope unit="page" from="145" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Toward a framework for human-robot interaction</title>
		<author>
			<persName><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-Comp Interact</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="24" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Tonkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vitale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ojha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Judge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Williams</surname></persName>
		</author>
		<title level="m">Embodiment, Privacy and Social Robots: May I Remember You? Social Robotics</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="506" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">When robots appear to have a mind: the human perception of machine agency and responsibility</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Woerdt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Haselager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Ideas Psychol</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="93" to="100" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Domo Arigato Mr Roboto: emergence of automated social presence in organizational frontlines and customers&apos; service experiences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Doorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Noble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hulland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Ostrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Petersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Service Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="58" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Safety issues in human-robot interactions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vasic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Billard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Determinants of perceived ease of use: integrating control, intrinsic motivation, and emotion into the technology acceptance model</title>
		<author>
			<persName><forename type="first">V</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf Syst Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="342" to="365" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Veruggio</surname></persName>
		</author>
		<title level="m">The EURON Roboethics Roadmap. 2006 6th IEEE-RAS International Conference on Humanoid Robots</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="612" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Be more transparent and users will like you: a robot privacy and user experience design experiment. HRI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vitale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tonkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Herse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ojha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Judge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM/IEEE international conference on human-robot interaction</title>
		<meeting>the 2018 ACM/IEEE international conference on human-robot interaction</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="379" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Brave new world: service robots in the frontline</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wirtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paluch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Serv Manag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="907" to="931" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Keep healthcare workers safe: application of teleoperated robot in isolation ward for COVID-19 prevention and control</title>
		<author>
			<persName><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese J Mech Eng</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">From high-touch to high-tech: COVID-19 drives robotics adoption</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P-J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Lew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tour Geogr</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="724" to="734" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Robot rooms&quot;: how guests use and perceive hotel robots</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cornell Hospital Report</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Publisher&apos;s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
