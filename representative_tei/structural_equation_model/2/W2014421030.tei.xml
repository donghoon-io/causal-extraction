<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EDUCATIONAL AND PSYCHOLOGICAL MEASUREMENT CRIBBIE AND JAMIESON STRUCTURAL EQUATION MODELS AND THE REGRESSION BIAS FOR MEASURING CORRELATES OF CHANGE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Cribbie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Manitoba</orgName>
								<orgName type="institution" key="instit2">Lakehead University</orgName>
								<orgName type="institution" key="instit3">York University</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Manitoba</orgName>
								<orgName type="institution" key="instit2">Lakehead University</orgName>
								<orgName type="institution" key="instit3">York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Jamieson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Manitoba</orgName>
								<orgName type="institution" key="instit2">Lakehead University</orgName>
								<orgName type="institution" key="instit3">York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EDUCATIONAL AND PSYCHOLOGICAL MEASUREMENT CRIBBIE AND JAMIESON STRUCTURAL EQUATION MODELS AND THE REGRESSION BIAS FOR MEASURING CORRELATES OF CHANGE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-14T17:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ANCOVA and regression both exhibit a directional bias when measuring correlates of change. This bias confounds the comparison of changes between naturally occurring groups with large pretest differences (ANCOVA), or for identifying predictors of change when the predictor is correlated with pretest (regression). This bias is described in some detail. A computer simulation study is presented, which shows that properly identified structural equation models are not susceptible to this bias. Neither gain scores (posttest minus pretest) nor structural equation models exhibit the "regression bias." Other factors, such as skewness, that may confound measurement of change are also discussed.</p><p>The issue of measuring change and predictors of change is fundamental to many areas of research in education and psychology. Although much attention has been directed at the importance of measurements at multiple time periods and the value of growth curves (e.g., <ref type="bibr" target="#b14">Lawrence &amp; Hancock, 1998;</ref><ref type="bibr" target="#b24">Rogosa &amp; Willett, 1985;</ref><ref type="bibr" target="#b30">Willett, 1997)</ref>, there has been renewed interest in the two phase, pretest-posttest design (e.g., <ref type="bibr" target="#b18">Maris, 1998;</ref><ref type="bibr" target="#b31">Williams &amp; Zimmerman, 1996)</ref>. Although this simple design does not permit the detailed analysis of individual growth patterns, it has many useful features and is widely used. This design has two main advantages over a posttest-only design: (a) it permits error variance due to consistent individual differences to be removed, thereby increasing power; and (b) it permits the groups to be</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>equated for baseline differences thereby increasing the internal validity of the design.</p><p>Two statistical methods are generally used to analyze data from this design. One method uses "gain scores," d = yx, where y is the posttest score and x is the pretest score. Gain scores are sometimes called change scores or difference scores. The independent t test comparing mean gain scores for two groups yields the identical conclusion as the interaction term in a 2 (groups) by 2 (pretest/posttest) mixed-ANOVA and answers the question of whether the two groups changed differently. The second method for analyzing this design is ANCOVA, in which the pretest is used as the covariate and the posttest is used as the dependent (criterion) variable. ANCOVA is the discrete case of a partial correlation or R-squared change from multiple regression and answers the question of whether group membership predicts posttest scores after pretest differences between groups are "controlled for" or "removed" (i.e., Did the groups change differently?).</p><p>These two methods each achieve the dual goals of controlling for pretest (sometimes called baseline) differences and removing error variance. Gain scores achieve these goals through subtraction: The consistent individual differences are subtracted out, which leaves less error variance and removes individual differences from between-group differences. ANCOVA achieves these goals through use of regression lines. The regression line relating pretest and posttest scores within each group is used to calculate a residual score for each participant that contains the amount of posttest not predictable from pretest, which leaves less error variance. The regression lines are also used to adjust the posttest mean to what the mean would have been expected to be if the two groups had started at the same baseline. Because this latter correction is a focus of attention later in this article, it will be described in a bit more detail now.</p><p>ANCOVA involves an adjusted treatment mean, Y′ j , that estimates what performance in the jth group would have been if the group mean on the covariate X j had been equal to the grand mean for the covariate X. This is calculated from</p><formula xml:id="formula_0">Y′ j = Y j -b w (X j -X), (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where b w is the pooled slope from the within-group regression and Y j is the observed mean on the posttest, which will contain the treatment effect. To understand the nature of this adjustment, it is necessary to focus on what is predicted under the null hypothesis. For example, in a two-group problem, the expected values of Y′ 1 and Y′ 2 are equal for H o : µ 1 = µ 2 . Hence,</p><formula xml:id="formula_2">Y 1 -b w (X 1 -X) = Y 2 -b w (X 2 -X). (<label>2</label></formula><formula xml:id="formula_3">)</formula><p>This reduces to</p><formula xml:id="formula_4">Y 1 -Y 2 = b w (X 1 -X 2 ).<label>(3)</label></formula><p>Equation 3 can be used to illustrate how the expected differences in the posttest (Y j ) will change as a function of differences in the pretest (X j ) and the slope (b w ). An example of this effect is presented in Table <ref type="table">1</ref>.</p><p>From Table <ref type="table">1</ref> it is clear that when b w is equal to 1, the expected difference in the posttest means equals the difference in the pretest means. However, when b w is less than 1, the posttest means are expected to come closer together. For illustration, with a pretest difference of +20 and b w = .5, the expected difference in the posttest means is +10. Thus, ANCOVA expects the posttest means to come closer together than they were at pretest, to regress toward zero difference. The expected difference in posttest means is greater when either the pretest means are farther apart or the slope of the within-group regression (b w ) is lower. The value of b w will generally be less than 1.0 because</p><formula xml:id="formula_5">b w = r xy (s y /s x )<label>(4)</label></formula><p>and r xy will be less than 1.0 due to measurement error. If the data are approximately normally distributed, the variability should be fairly constant from pretest to posttest. Problems associated with skewed data are addressed in the discussion.</p><p>It has been known for some time that the gain score and ANCOVA methods can produce different conclusions. The most dramatic demonstration of this difference is known as Lord's Paradox. <ref type="bibr" target="#b16">Lord (1967)</ref> presented a hypothetical example of a group of male and a group of female adolescents each weighed on 2 consecutive years. Even though both groups gained the identical number of pounds (the posttest difference = pretest difference), ANCOVA resulted in the conclusion that males increased significantly more than did females, whereas a t test on gain scores yielded a t of zero. The resolution of Lord's paradox is quite simple. Assuming b w is less than 1.0, the observed posttest difference will be greater than expected. The observed difference in posttest means did not regress as expected by ANCOVA under H o , so the difference in posttest means was interpreted by ANCOVA as being significantly higher than expected. The group with the higher pretest mean (males) was found by ANCOVA to gain significantly more weight than females because they did not regress at posttest as expected.</p><p>It is clear that ANCOVA involves a quite different method for measuring change than analysis of gain scores. With gain scores, the expected posttest difference under H o will be equal to the pretest difference in means. With ANCOVA, the expected posttest difference will be closer to zero than the pre-test difference. Thus, ANCOVA expects the pretest mean difference to decrease at posttest.</p><p>The important issue is when each of gain scores and ANCOVA is the correct model. When should each be used? The advice most often given is that ANCOVA should only be used with randomized experiments and should be avoided with naturally occurring groups <ref type="bibr" target="#b6">(Huitema, 1980;</ref><ref type="bibr" target="#b23">Rogosa, 1988;</ref><ref type="bibr" target="#b26">Schafer, 1992)</ref>. The rationale for this advice is that when groups are assigned at random, the group with the higher mean will have received more positive random errors, whereas the group with the lower mean will have received more negative random errors, both of which will tend toward zero on posttest. So, regression toward the mean is expected when groups are randomly assigned. On the other hand, if groups are naturally occurring, there is no reason to expect the mean differences to dissipate. On the contrary, it is more reasonable to assume the mean differences will be maintained on posttest (the gain score assumption).</p><p>Although the advice to avoid ANCOVA with naturally occurring groups is widely offered, this advice is conspicuously absent from two articles that were published in influential journals <ref type="bibr" target="#b18">(Maris, 1998;</ref><ref type="bibr" target="#b29">Wainer, 1991)</ref>. These articles based their recommendations on a causal model designed by Rubin that was specifically applied to resolve Lord's Paradox <ref type="bibr" target="#b4">(Holland &amp; Rubin, 1983</ref>). Rubin's model focuses on untested control groups-basically, the question of how the individuals would have changed had there been no treatment. Rather than simply focusing on the question, Did the groups change differently? Rubin's model asks, Did the groups change differently, relative to how they would have changed had they received the control condition? Unfortunately, Rubin's model appears to have distracted attention from the main issue determining when ANCOVA should be used, namely the reason for the baseline differences. Furthermore, there are many possible control groups that might be considered because there really is no single "control condition" implied by a question of differential response to a treatment. Moreover, Rubin's model led <ref type="bibr" target="#b29">Wainer (1991)</ref> to make an incorrect statement that ANCOVA might be preferred to gain scores when there is an underlying baseline drift (scores are increasing even without treatment). That statement is quite incorrect because ANCOVA will still be the wrong method in this situation unless the groups are assigned at random, and gain scores are not affected by the problem of baseline drift.</p><p>By failing to provide clear guidelines about when ANCOVA should be used, these two articles (as well as others) have left this issue open, so researchers have the option of choosing either ANCOVA or gain scores. <ref type="bibr" target="#b11">Jamieson (1999)</ref> recently pointed out that this option creates an ethical dilemma for researchers because the two methods are too differentially powerful to detect differences in changes. Simply by looking at the direction of pretest differences and knowing which group is expected to change more, it is possible to identify which of ANCOVA or gain scores will be more powerful to detect this hypothesized difference (see Figure <ref type="figure">4</ref> in <ref type="bibr" target="#b11">Jamieson, 1999</ref>, for an illustration of the patterns of differences that each of ANCOVA or gain scores are better able to detect). <ref type="bibr" target="#b11">Jamieson (1999)</ref> pointed out that ANCOVA has a directional bias that is a function of the direction of pretest differences and the direction of differences in change: "ANCOVA is biased to find significance in means which stay apart (parallel lines, as in Lord's paradox) or which diverge. Conversely it is biased against detecting significant effects when the lines converge" (p. 159). Because the difference in power between gain scores and ANCOVA is always in a predictable direction, it is essential to have clear guidelines so that each method will be used only when it is the correct model, to avoid the ethical dilemma and associated Type 1 errors that result from capitalizing on chance differences.</p><p>The directional bias also extends beyond the ANCOVA case to the continuous case, where a continuous "third variable" replaces group membership. Thus, instead of asking which group changed more, the question becomes whether a third variable is correlated with amount of change. This question arises in psychophysiology as identifying personality or lifestyle predictors of physiological reactivity to stress, and in clinical or educational contexts as identifying what types of individuals will benefit most from a program. What variables predict who will change the most? <ref type="bibr" target="#b9">Jamieson (1994)</ref> showed that the "ANCOVA bias" also appears in the case of the continuous third variable. For generality, the bias will now be referred to as the regression bias.</p><p>Using computer simulations, Jamieson (1994) compared the partial correlation between a third variable and posttest, controlling for pretest, with the correlation between the third variable and the gain score (d = yx). The partial correlation is the generalization of ANCOVA to a continuous variable, whereas the correlation with the gain score is the generalization of the gain score approach. Simulations were examined that manipulated two conditions: (a) the correlation of the third variable with pretest and (b) the correla-tion of the third variable with the gain score. When the third variable was uncorrelated with pretest, both gain score correlations and the partial correlations yielded comparable values. However, when the third variable was correlated with pretest, the partial correlations and gain score correlations differed. The pattern of differences showed that partial correlations were biased to detect statistically significant relationships with change, which were in the same direction as the correlation with baseline, and were biased against detecting statistical significance when the correlations were in opposite direction. When the correlation between the third variable and change was zero, large correlations with baseline resulted in many significant partial correlations (Type 1 errors). Thus, the baseline correlation could result in the finding of statistically significant correlation of the third variable with change, even when the real correlation was zero. This finding is the generalization of Lord's Paradox to a continuous variable.</p><p>Jamieson (1994) also showed when there was a very large correlation between the third variable and pretest, the regression method sometimes detected statistically significant correlations with change that were in the opposite direction from the real correlation. In every case where there was a large correlation of the third variable with baseline, regression was biased to detect correlations with change in only one direction. These findings are extensions of the ANCOVA bias: When the third variable is highly correlated with pretest (which is comparable to large baseline differences in ANCOVA), regression measures are biased to detect a correlation of change with the third variable that is in the same direction as the correlation with baseline (which is comparable to detecting mean differences that diverge from pretest to posttest in ANCOVA). The ethical dilemma described in <ref type="bibr" target="#b11">Jamieson (1999)</ref> also applies to the case of a continuous variable. For example, suppose one predicts that physically fit individuals will show lower heart rate increases to stress than physically unfit. Pretest heart rate shows a large difference because fit individuals have lower heart rates (heart rate is negatively correlated with fitness level). If the study was done with two groups (fit, unfit), then ANCOVA will be biased to find the group with the higher pretest heart rate (unfit) to show a larger increase to stress. On the other hand, if, instead of dichotomizing fitness, a fitness score was used as a predictor of heart rate increase, the regression approach will be biased to detect a negative partial correlation of fitness and posttest heart rate (unfit increasing more). In both cases, the effect could simply be an artifact of the statistical method, not a real finding.</p><p>The reason for the regression bias is well understood. Basically, the problem with regression is that the covariate (pretest) is assumed to be measured without error (see, e.g., <ref type="bibr">Darlington, 1990, p. 203)</ref>. The greater the amount of error variance in the pretest, the less effective regression will be in eliminating pretest variation from the measure of change. The findings of <ref type="bibr" target="#b9">Jamieson (1994)</ref> show that one is in precisely the same situation when a third variable is strongly correlated with pretest, as when there are large baseline differences with naturally occurring groups. In both cases, the use of regression-based methods can result in erroneous conclusions.</p><p>The present study was designed to determine whether the regression bias also appears when a structural equation model is used to measure change. <ref type="bibr" target="#b19">Raykov (1992</ref><ref type="bibr" target="#b20">Raykov ( , 1993</ref><ref type="bibr" target="#b21">Raykov ( , 1994) )</ref> and others have presented structural models that measure change using two congeneric variables (both measures of the same construct), each measured at pretest and posttest. The models include a latent variable for the construct of "change" and allow examination of the relationship between change and a third variable construct, also measured by two congeneric variables. For example, heart rate and systolic blood pressure might both be measured before and after exposure to a stressor. The latent variable change is then a measure of increased cardiovascular activity. A third variable construct, perhaps Type A behavior measured by both a questionnaire and a structured interview, could then be examined as a predictor of the cardiovascular response to stress.</p><p>Because structural equation models (SEM) involve explicit modeling of error variance for all observed and latent measures, it should not be susceptible to the regression bias. The purpose of the following study is to evaluate whether this is in fact true. Simulations were created, similar to those of <ref type="bibr" target="#b9">Jamieson (1994)</ref> except that two measures are included instead of one. Different conditions are then created to manipulate the correlation of the third variable with pretest, and the correlation of the third variable with change. Three summary statistics are then examined to determine the effect of these manipulations: (a) the correlation between the gain scores and the third variable; (b) the partial correlation between the third variable and posttest, controlling for pretest; and (c) the path from the structural model linking the latent third variable to the latent change measure. The first two statistics are included to replicate the regression bias demonstrated by <ref type="bibr" target="#b9">Jamieson (1994)</ref>. The third statistic will show whether SEM are also affected by the regression bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Pseudorandom normal variates were generated by the SAS generator RANNOR (SAS Institute, 1990a). The data generation was similar to methods used in <ref type="bibr" target="#b12">Jamieson and Howk (1992)</ref> and <ref type="bibr" target="#b9">Jamieson (1994)</ref>. Three normally distributed variables were generated with means of zero and standard deviations of two to represent (a) a pretest (baseline) for two congeneric measures (X), (b) a measure of amount of change (C) in the two measures from pretest to posttest, and (c) a construct underlying a third variable or correlate of change (Z). In addition, six normally distributed variables were generated with means of zero and standard deviations of one to account for measurement error in the dependent variables.</p><p>Pretest measures of the repeatedly assessed variables were computed from the construct (X) and error variables (e 1 , e 2 ):</p><formula xml:id="formula_6">PRE 1 = X + e 1 , PRE 2 = X + e 2 .</formula><p>Posttest measures were computed by adding a measure of change (C) to the pretest construct (X) and individual error variables (e 3 , e 4 ):</p><formula xml:id="formula_7">POST 1 = X + C + e 3 , POST 2 = X + C + e 4 .</formula><p>The advantage of using computer simulated data is that specific relationships can be built into the data and tested using various statistical methods. In this study, the data were generated such that there was either a positive, negative, or null relationship between the two congeneric measures of the third variable (Z1, Z2) and pretest, as well as a positive or negative relationship between the two measures of the third variable and change. The positive and negative relationships were identical in magnitude. Therefore, six conditions were created by manipulating the relationships between the third variable measures and baseline (0, +, -), and the third variable measures and change (+, -). For example, to generate congeneric third variable measures that correlate positively with baseline and negatively with change, Z1 = Z + .75X -.75C + e 5 , Z2 = Z + .75X -.75C + e 6 .</p><p>(5)</p><p>The variability of the latent pretest (X) and change (C) constructs were reduced (i.e., premultiplied by .75) to generate empirically realistic correlations between the third variable measures and the pretest/posttest measures. In addition, to generate third variable measures that are not correlated with pretest scores, the pretest construct (X) is removed from the equation. For example, to generate third variable measures that are correlated positively with change, but not correlated with baseline, Z1 = Z + .75C + e 5 , Z2 = Z + .75C + e 6 .</p><p>(6)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gain Scores</head><p>Gain scores (G1, G2) for the two repeatedly assessed variables were computed by taking the difference between pretest and posttest scores:</p><formula xml:id="formula_8">G1 = POST 1 -PRE 1 , G2 = POST 2 -PRE 2 .</formula><p>Correlations were computed between each of the gain scores and each of the congeneric measures of the third variable. A mean correlation was computed by averaging the four correlations between the gain scores and third variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regression-Based Method (partial correlations)</head><p>Partial correlations were computed between posttest scores and the congeneric measures of the third variable after controlling for the corresponding pretest scores. An average partial correlation was computed by averaging the four partial correlations between the posttest scores and the third variable measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural Equation Modeling</head><p>The structural model used in this study (see Figure <ref type="figure" target="#fig_0">1</ref>) was derived from research by <ref type="bibr" target="#b20">Raykov (1993</ref><ref type="bibr" target="#b21">Raykov ( , 1994</ref><ref type="bibr" target="#b22">Raykov ( , 1997))</ref>; <ref type="bibr" target="#b17">MacCallum, Kim, Malarkey, and Kiecolt-Glaser (1997)</ref>; <ref type="bibr" target="#b2">Duncan et al. (1997);</ref><ref type="bibr" target="#b28">Steyer, Eid, and Schwenkmezger (1997)</ref>; and others for measuring change and identifying correlates of change with SEM. The observed variables in this model are the two pretest measures, the two posttest measures, and the two congeneric measures of the third variable. Latent measures in this model represent the baseline (X), the true change between pretest and posttest (C), and the third variable construct (Z). The model definition equations for this model are</p><formula xml:id="formula_9">PRE 1 = X + e 1 , PRE 2 = X + e 2 , POST 1 = X + (a)C + e 3 , POST 2 = X + (b)C + e 4 , Z1 = (c)Z + e 5 , Z2 = Z + e 6 ,</formula><p>where a, b, and c are unknown path coefficients to be estimated from the data, and e 1e 6 are the corresponding errors of measurement, also estimated from the data, with the constraint that e 1 = e 3 and e 2 = e 4 . The variances of the latent baseline and third variable constructs were estimated from the data, and to achieve identification of the model, the variance of the latent change variable was set equal to one. The model contains 12 degrees of freedom, with 9 unknowns being estimated from 15 covariances and 6 variances.</p><p>To test the fit of the model to the data, the Goodness of Fit Index (GFI) <ref type="bibr" target="#b13">(Jöreskog &amp; Sörbom, 1989)</ref>, Adjusted Goodness of Fit Index (AGFI) <ref type="bibr" target="#b13">(Jöreskog &amp; Sörbom, 1989)</ref>, and Root Mean Square Error of Approximation (RMSEA) <ref type="bibr" target="#b0">(Browne &amp; Cudeck, 1993)</ref> were recorded for each analysis. Cutoff values of .95 were used to establish a good fit for the GFI and AGFI <ref type="bibr" target="#b27">(Shevlin &amp; Miles, 1998)</ref>, and .05 was used to establish a good fit for the RMSEA <ref type="bibr" target="#b0">(Browne &amp; Cudeck, 1993;</ref><ref type="bibr" target="#b5">Hu &amp; Bentler, 1999)</ref>. <ref type="bibr" target="#b3">Fan, Thompson, and Wang (1999)</ref> found that, relative to other fit indices, the GFI, AGFI, and RMSEA were sensitive to model misspecifications, the GFI and AGFI were insensitive to estimation method, and the RMSEA was insensitive to sample size variation. Based on these results, <ref type="bibr" target="#b3">Fan et al. (1999)</ref> recommended the use of these fit indices in research. As always, it is important to examine multiple fit indices to get a good overall "picture" of the fit of the model to the data.</p><p>Change score correlations, partial correlations, and structural model analyses were computed over 1,000 simulations of 200 cases each, for the six conditions. All analyses were performed using SAS (SAS Institute, 1990a). The structural models were tested against the data using SAS PROC CALIS (SAS Institute, 1990b) and maximum likelihood estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gain Scores</head><p>The mean correlations between the gain scores and the third variables for the six conditions can be found in Table <ref type="table" target="#tab_1">2</ref>. The results were equivalent to those of <ref type="bibr" target="#b9">Jamieson (1994)</ref>, with the correlations between the gain scores and the third variables consistent across each of the conditions. In other words, the correlations between the gain scores and the third variable scores were unaffected by the relationship of the third variable with pretest. As expected, the correlations between the gain scores and the third variable were larger when there was no correlation between the pretest scores and the third variables as a result of the increased proportion of variability accounted for by the correlation between change and the third variables (see Equations 5 and 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regression (partial correlation)</head><p>The mean partial correlations between the posttest scores and each of the third variables after controlling for pretest scores can be found in Table <ref type="table">3</ref>. The Note. All parameters not fixed at a set value (1) are estimated from the data, with the only constraint that E1 = E3 and E2 = E4.</p><p>results were again consistent with those found by <ref type="bibr" target="#b9">Jamieson (1994)</ref>. When there was no relationship between pretest scores and third variable scores, the average partial correlations were quite similar to the gain score correlations, although when a relationship existed between baseline scores and third variable scores, the partial correlations were biased. Specifically, when the relationship between the baseline scores and the third variable scores was congruent with the relationship between change and the third variable scores (i.e., both relationships positive or both relationships negative), the partial correlations were inflated. In contrast, when the relationship between the baseline scores and the third variable scores was incongruent with the relationship between change and the third variable scores (i.e., one relationship positive and one relationship negative), the partial correlations were deflated. Thus, partial correlations of a third variable with change are very much affected by the correlation of the third variable with baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural Modeling</head><p>To verify that the proposed structural model provided a good fit to the simulated data, the mean GFI, AGFI, and RMSEA were computed for each condition. The mean GFI, AGFI, and RMSEA were similar across conditions and indicate a good overall and parsimonious fit of the model <ref type="bibr">(.983 to .984, .965 to .966, and .018 to .019, respectively)</ref>. The mean correlations between the latent third variable and the latent change variable for the six conditions can be found in Table <ref type="table">4</ref>. The results for the proposed model were similar to the results found for the change score correlations; namely, the relationship between the third variables and change was unaffected by the relationship between the third variables and baseline. Again, as expected, the correlations between the change scores and the third variable were larger when there was no correlation between the pretest scores and the third variables as a result of the increased proportion of variability accounted for by the correlation between change and the third variables (see Equations 5 and 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>These simulations replicate the regression bias demonstrated by <ref type="bibr" target="#b9">Jamieson (1994)</ref> and show that SEM are not affected by this bias. Although the correlation of a third variable with pretest confounded regression measures of change, SEM and gain scores were unaffected. This finding, although not surprising, is nevertheless reassuring and confirms that SEM are an unbiased method for identifying correlates of change. SEM are becoming more widely used and have great potential for testing unambiguous, predetermined, and theoretically important models. However, in situations where SEM are not appropriate, either because of small sample size or because two congeneric measures are not available, gain scores remain a good alternative for analyzing change because they are not affected by correlations of a third variable with pretest.</p><p>However, gain scores are not perfect. Although earlier concerns about poor reliability of gain scores are no longer seen as a serious problem <ref type="bibr" target="#b15">(Llabre, Spitzer, Saab, Ironson, &amp; Schneiderman, 1991;</ref><ref type="bibr" target="#b31">Williams &amp; Zimmerman, 1996)</ref>, the question remains of whether gain scores might also be biased measures of change under some circumstances. <ref type="bibr" target="#b29">Wainer (1991)</ref>  (1995) used computer simulations to compare gain scores and ANCOVA when variance decreased from pretest to posttest. The decrease in variance was created through simulating a floor/ceiling effect, through skewness, and through just manipulating variance. In all three cases, gain scores lost power relative to ANCOVA when the variance decreased from pretest to posttest. Jamieson (1999) described a principle that gain scores are confounded with pretest whenever data are skewed. As an illustration, he offers the following example:</p><p>Another way to illustrate this principle is to consider a measurement model in which the true dimension is normally distributed, but the observed measure is positively skewed. Suppose a square root transformation will change the observed measure to a normal distribution, eliminating the skewness and thereby reflecting the true underlying process. Consider a numerical illustration, in which observed scores of 25 and 100 correspond to true scores of 5 and 10 (the square roots). If a task produced an increase of 1 in each true score, from 5 to 6 and from 10 to 11, this would correspond to changes in the observed scores from 25 to 36 and from 100 to 121. The changes for the observed scores are 36 -25 = 9 and 121 -100 = 21. Thus the observed scores show a difference (21 -9 = 15) in the amount of change, even though the true scores both have the identical increase of 1 unit. The positive skewness caused the higher score to change more. <ref type="bibr">(pp. 156-157)</ref> Thus, there is a real concern about the confound of comparing changes in groups that start from different baselines when the data are skewed. At present, the best solution appears to be to examine the shape of the distribution and apply an appropriate transformation, if possible. <ref type="bibr" target="#b31">Williams and Zimmerman (1996)</ref> recently dealt in some depth with the issue of changing shape of distributions. They pointed out that in many educational contexts, data may start from a floor (positively skewed distribution) and increase in variance in response to a treatment to show a more symmetrical distribution. If the data are only skewed at pretest, a transformation applied to both pretest and posttest would not be appropriate. It is not clear how to obtain an unbiased measure of change in such circumstances. Although there are still unanswered questions about how to measure change in the 2-phase design, the two guidelines suggested by <ref type="bibr" target="#b11">Jamieson (1999)</ref> are a good starting point: Avoid ANCOVA except for randomized experiments, and avoid using gain scores with skewed data.</p><p>The potential of SEM for measuring correlates of change is an important topic for further research. The present study showed that SEM are not affected by the regression bias and are able to accurately estimate the relationship between a third variable and change, independent of whether the third variable is also correlated with pretest. One question of particular importance is whether SEM will show the same confounds with skewed data that are evident with gain scores. Previous research has reported that maximum likelihood estimation in SEM is relatively robust to moderate violations of normality <ref type="bibr" target="#b7">(Ip &amp; Willson, 1998)</ref> and that asymptotically distribution-free test statistics may provide accurate parameter estimates and standard errors for nonnormal data. Therefore, it is possible that SEM, unlike gain scores, may provide accurate estimates (and statistical tests) of the relationship between change and correlates of change when the variables are skewed. We are currently exploring this question.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The structural model used to identify correlates of change.</figDesc><graphic coords="10,159.12,138.82,294.32,115.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Mean Correlations Between the Gain Scores and the Third Variables</figDesc><table><row><cell>Baseline and Third Variable Relationship</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Alternative ways of assessing model fit</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cudeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Testing structural equation models</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Long</surname></persName>
		</editor>
		<meeting><address><addrLine>Newbury Park, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Sage</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="136" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Regression and linear models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Darlington</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Latent variable modeling of longitudinal and multilevel substance abuse data</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alpert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hops</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stoolmiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Multivariate Behavioral Research</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="275" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Effects of sample size, estimation methods, and model specification on structural equation modeling fit indexes</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="56" to="83" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On Lord&apos;s Paradox</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles of modern psychological measurement</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Wainer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Messick</surname></persName>
		</editor>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="3" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The analysis of covariance and alternatives</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Huitema</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980">1980</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Ip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Willson</surname></persName>
		</author>
		<title level="m">Parameter estimates and fit indices in covariance structure analysis with nonnormal data. Paper presented at the 1998 Annual Meeting of the American Educational Research Association</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-04">1998. April</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The law of initial values: Five factors or two?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jamieson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="233" to="239" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Correlates of reactivity: Problems with regression based methods</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jamieson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="73" to="78" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measurement of change and the law of initial values: A computer simulation study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jamieson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="38" to="46" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dealing with baseline differences: Two principles and two dilemmas</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jamieson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="155" to="161" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The law of initial values: A four factor theory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Howk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="53" to="61" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Jöreskog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sörbom</surname></persName>
		</author>
		<title level="m">LISREL 7: A guide to the program and applications</title>
		<meeting><address><addrLine>Chicago</addrLine></address></meeting>
		<imprint>
			<publisher>SPSS</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Assessing change over time using latent growth modeling</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement and Evaluation in Counseling and Development</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="211" to="224" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The reliability and specificity of delta versus residualized change as measures of cardiovascular reactivity to behavioral challenges</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Llabre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Saab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Ironson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Schneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="701" to="711" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A paradox in the interpretation of group comparisons</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Lord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="304" to="305" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Studying multivariate change using multilevel models and latent curve models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Malarkey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kiecolt-Glaser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Multivariate Behavioral Research</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="215" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Covariance adjustment versus gain scores-revisited</title>
		<author>
			<persName><forename type="first">E</forename><surname>Maris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="309" to="327" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Structural models for studying correlates and predictors of change</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australian Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="101" to="112" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A structural equation model for measuring residualized change and discerning patterns of growth or decline</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="53" to="71" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Studying correlates and predictors of longitudinal change using structural equation modeling</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="63" to="77" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Simultaneous study of individual and group patterns of latent longitudinal change using structural equation modeling</title>
		<author>
			<persName><forename type="first">T</forename><surname>Raykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="212" to="236" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Myths about longitudinal research</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Rogosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Methodological issues in aging research</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Schaie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Campbell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Meredith</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Rawlings</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="171" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Understanding correlates of change by modeling individual differences in growth</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Rogosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="203" to="228" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m">Cary, NC: Author. SAS Institute</title>
		<meeting><address><addrLine>Cary, NC</addrLine></address></meeting>
		<imprint>
			<publisher>Author</publisher>
			<date type="published" when="1990">1990a. 1990b</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
		<respStmt>
			<orgName>SAS Institute.</orgName>
		</respStmt>
	</monogr>
	<note>SAS/STAT user&apos;s guide</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Analysis of pretest-posttest designs</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Schafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Measurement and Evaluation in Counselling and Development</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2" to="4" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Effects of sample size, model specification and factor loadings on the GFI in confirmatory factor analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shevlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N V</forename><surname>Miles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="85" to="90" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modeling true intraindividual change: True change as a latent variable</title>
		<author>
			<persName><forename type="first">R</forename><surname>Steyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schwenkmezger</surname></persName>
		</author>
		<ptr target="www.hsp.de/MPR" />
	</analytic>
	<monogr>
		<title level="j">Methods of Psychological Research</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adjusting for differential base rates: Lord&apos;s paradox again</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wainer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="147" to="151" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Measuring change: What individual growth modeling buys you</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Change and development</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Amsel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Reninger</surname></persName>
		</editor>
		<meeting><address><addrLine>Mahwah, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="213" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Are simple gain scores obsolete?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Zimmerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="59" to="69" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
