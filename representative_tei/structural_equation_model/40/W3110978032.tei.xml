<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dangers of the Defaults: A Tutorial on the Impact of Default Priors When Using Bayesian SEM With Small Samples</title>
				<funder ref="#_JxYAYgg">
					<orgName type="full">Netherlands</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2020-12-11">11 December 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Martin</forename><surname>Hecht</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Sanne</forename><forename type="middle">C</forename><surname>Smid</surname></persName>
							<email>s.c.smid@uu.nl</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Methodology and Statistics</orgName>
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<settlement>Utrecht Netherlands</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sonja</forename><forename type="middle">D</forename><surname>Winter</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychological Sciences</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Merced Merced</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Goethe University</orgName>
								<address>
									<settlement>Frankfurt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Teacher Education Zug</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Humboldt University of Berlin</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dangers of the Defaults: A Tutorial on the Impact of Default Priors When Using Bayesian SEM With Small Samples</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-12-11">11 December 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.3389/fpsyg.2020.611963</idno>
					<note type="submission">This article was submitted to Quantitative Psychology and Measurement, a section of the journal Frontiers in Psychology Received: 29 September 2020 Accepted: 20 November 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.1" ident="GROBID" when="2025-10-28T23:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian SEM</term>
					<term>default priors</term>
					<term>informative priors</term>
					<term>small sample size</term>
					<term>Shiny app</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When Bayesian estimation is used to analyze Structural Equation Models (SEMs), prior distributions need to be specified for all parameters in the model. Many popular software programs offer default prior distributions, which is helpful for novel users and makes Bayesian SEM accessible for a broad audience. However, when the sample size is small, those prior distributions are not always suitable and can lead to untrustworthy results. In this tutorial, we provide a non-technical discussion of the risks associated with the use of default priors in small sample contexts. We discuss how default priors can unintentionally behave as highly informative priors when samples are small. Also, we demonstrate an online educational Shiny app, in which users can explore the impact of varying prior distributions and sample sizes on model results. We discuss how the Shiny app can be used in teaching; provide a reading list with literature on how to specify suitable prior distributions; and discuss guidelines on how to recognize (mis)behaving priors. It is our hope that this tutorial helps to spread awareness of the importance of specifying suitable priors when Bayesian SEM is used with small samples.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Bayesian estimation of Structural Equation Models (SEMs) has gained popularity in the last decades (e.g., <ref type="bibr" target="#b22">Kruschke et al., 2012;</ref><ref type="bibr" target="#b41">van de Schoot et al., 2017)</ref>, and is more and more often used as a solution to problems caused by small sample sizes (e.g., McNeish, 2016a; König and van de Schoot, 2017)<ref type="foot" target="#foot_0">foot_0</ref> . With small samples, frequentist estimation [such as (restricted) Maximum Likelihood or (weighted) least squares estimation] of SEMs can result in non-convergence of the model, which means that the estimator was unable to find the maximum (or minimum) for the derivative of the model parameters. Even when a model converges, simulation studies have shown that the parameter estimates may be inadmissible (e.g., Heywood cases) or inaccurate (i.e., the estimate deviates from the population value; <ref type="bibr" target="#b3">Boomsma, 1985;</ref><ref type="bibr" target="#b32">Nevitt and Hancock, 2004)</ref>. In contrast to frequentist methods, Bayesian methods do not rely on large sample techniques, which make Bayesian methods an appealing option when only a small sample is available. Within the Bayesian framework, prior distributions need to be specified for all parameters in the model 2 . This additional step may pose a barrier for novice users of Bayesian methods. To make Bayesian SEM accessible to a broad audience, popular software programs for analyzing Bayesian SEMs, such as Mplus <ref type="bibr">(Muthén and</ref><ref type="bibr" target="#b31">Muthén, (1998-2017)</ref>) and the blavaan package <ref type="bibr" target="#b30">(Merkle and Rosseel, 2018)</ref> in R (R Core Team, 2018), offer default prior distributions. However, those default prior distributions are not suitable in all cases. When samples are small, the use of solely default priors can result in inaccurate estimates-particularly severely inaccurate variance parameters-unstable results, and a high degree of uncertainty in the posterior distributions (e.g., <ref type="bibr" target="#b11">Gelman, 2006;</ref><ref type="bibr" target="#b27">McNeish, 2016a;</ref><ref type="bibr" target="#b36">Smid et al., 2019b)</ref>. These three consequences of using default priors with small samples severely limit the inferences that can be drawn about the parameters in the model.</p><p>With small samples, the performance of Bayesian estimation highly depends on the prior distributions, whether they are software defaults or specified by the researcher (e.g., <ref type="bibr" target="#b12">Gelman et al., 2014;</ref><ref type="bibr" target="#b16">Kaplan, 2014;</ref><ref type="bibr" target="#b26">McElreath, 2016)</ref>. <ref type="bibr" target="#b27">McNeish (2016a)</ref> discussed that small sample problems (such as nonconvergence, inadmissible and inaccurate parameter estimates) cannot be fixed by only switching from a frequentist to a Bayesian estimator. Instead, he argues that if Bayesian methods are used with small samples, "prior distributions must be carefully considered" <ref type="bibr">(McNeish, 2016a, p. 764</ref>). This advice is not new: <ref type="bibr" target="#b17">Kass and Wasserman (1996)</ref> already warned against relying on default prior settings with small samples. In the quarter-century since that initial warning, Bayesian estimation is increasingly used to deal with small samples (van de <ref type="bibr">Schoot et al., 2017;</ref><ref type="bibr" target="#b36">Smid et al., 2019b</ref>). Yet researchers remain stubbornly reliant on default priors, despite clear caution against their use (as shown by <ref type="bibr" target="#b27">McNeish, 2016a;</ref><ref type="bibr" target="#b19">König and van de Schoot, 2017;</ref><ref type="bibr" target="#b41">van de Schoot et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goals of This Tutorial Paper</head><p>In this tutorial paper, we provide a non-technical discussion of the risks associated with the use of default priors. We discuss how default priors can unintentionally behave as highly informative priors when samples are small. Next, we demonstrate an educational online Shiny app (available on our Open Science Framework (OSF) page via <ref type="url" target="https://osf.io/m6byv">https://osf.io/m6byv</ref>), in which users can examine the impact of varying prior distributions and sample size on model results. We discuss how the Shiny app can be used in teaching and provide an online reading list (available via <ref type="url" target="https://osf.io/pnmde">https://osf.io/pnmde</ref>) with literature on Bayesian estimation, and particularly on how to specify suitable prior 2 Prior distributions represent information about the parameters and can be based on previous studies or the beliefs of experts in the field. The prior distributions are then updated by the likelihood (observed data depended on the model). By using methods such as Markov chain Monte Carlo (MCMC), the posterior distribution is simulated, which is a combination of the prior and likelihood. For references with an elaborate introduction into Bayesian estimation, we refer to our reading list (<ref type="url" target="https://osf.io/pnmde">https://osf.io/pnmde</ref>).</p><p>distributions. Finally, we provide guidelines on how to recognize (mis)behaving priors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>WHAT IS A SMALL SAMPLE?</head><p>Before we continue our discussion of the potential dangers of default priors with small samples, we need to address the question: What exactly is a small sample? Whether a sample is small depends on the complexity of the model that is estimated. One way to express the size of a sample is to look at the ratio between the number of observations and the number of unknown parameters in the model (e.g., <ref type="bibr" target="#b23">Lee and Song, 2004;</ref><ref type="bibr" target="#b35">Smid et al., 2019a)</ref>. A sample could be considered very small when this ratio is 2, which means there are just two observations for each unknown parameter. As SEMs often include many unknown parameters (i.e., factor loadings, intercepts, covariances), samples that may appear relatively large are in fact very small. For example, a confirmatory factor analysis (CFA) model with three latent factors and fifteen observed items consists of 48 unknown parameters: 12 factor loadings (first factor loading fixed at 1 for identification), 15 intercepts, 15 residual variances, three factor variances, and three factor covariances. In this scenario, a sample of 100 participants would still be considered very small (ratio = 2.08). This example demonstrates that general rules of thumb about sample sizes for SEM (e.g., n &gt; 100; <ref type="bibr" target="#b18">Kline, 2015)</ref> can be misleading as they do not take into account model complexity. Furthermore, model complexity depends on more than just the number of parameters that are estimated. Other factors that play are role in model complexity are whether the model includes components such as categorical variables, latent factors, multiple groups, or latent classes. A recent review of simulation studies on SEM <ref type="bibr" target="#b36">(Smid et al., 2019b)</ref> showed that authors of these simulation papers have widely varying definitions of a "small sample size, " ranging from extremely small (e.g., n = 8 assessed at three time points with one continuous variable; van <ref type="bibr" target="#b39">de Schoot et al., 2015)</ref> to what some might consider moderately sized (e.g., n = 200 with 12 ordinal variables; <ref type="bibr" target="#b4">Chen et al., 2015)</ref>. Thus, assessing whether a sample is (too) small is unfortunately not as easy as checking whether a certain number of participants has been reached, and should be done on an analysis-by-analysis basis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DANGERS OF THE DEFAULTS</head><p>The risks associated with default priors when Bayesian SEM is used with small samples can be described as a combination of the following three factors.</p><p>First, when samples are small, priors have a relatively larger impact on the posterior than when samples are large. The posterior can be seen as a compromise between the prior and the likelihood. With a larger sample size, the likelihood dominates the posterior (see Figure <ref type="figure" target="#fig_0">1C</ref>). However, with a small sample size, the likelihood has relatively less weight on the posterior. Accordingly, the prior has relatively more weight on the posterior (see Figure <ref type="figure" target="#fig_0">1A</ref>). Therefore, it is of great importance to specify suitable prior distributions when samples are small (e.g., <ref type="bibr" target="#b12">Gelman et al., 2014)</ref>.</p><p>Second, most of the default priors have very wide distributions. For instance, the Mplus default prior for means and regression coefficients is a Normal distribution with a mean hyperparameter of zero and a variance of 10 10 (Muthén and <ref type="bibr">Muthén, (1998</ref><ref type="bibr">Muthén, ( -2017))</ref>). The variance hyperparameter corresponds to a standard deviation of 100.000, meaning, that 68% of the prior distribution contains values between -100.000 and 100.000, and 95% of the prior distribution contains values between -200.000 and 200.000<ref type="foot" target="#foot_4">foot_4</ref> . When such default priors are specified, a wide range of parameter values can be sampled from the posterior during the Bayesian analysis. All those parameter values are therefore considered plausible, which might not always be appropriate. For instance, when measuring mathematical ability on a scale from 0 to 100, values below 0 and above 100 cannot be present in the data. Specifying a default prior with such a wide distribution on the mean of mathematical ability will put a lot of weight on values that are not reasonable (see e.g., <ref type="bibr">Stan Development Team, 2017 p. 131)</ref>. For small sample sizes, the combination of the relatively larger impact of the prior on the posterior and the wide distribution of default priors can lead to extremely incorrect parameter estimates (see e.g., <ref type="bibr" target="#b11">Gelman, 2006;</ref><ref type="bibr" target="#b27">McNeish, 2016a</ref>; and the systematic literature review of <ref type="bibr" target="#b36">Smid et al., 2019b)</ref>.</p><p>The third factor that plays a role, is the false belief that default priors are non-informative priors which "let the data speak." Default priors can act as highly informative priors, as they can heavily influence the posterior distribution and impact the conclusions of a study (see e.g., <ref type="bibr" target="#b2">Betancourt, 2017)</ref>. As explained by McNeish (2016a, p. 752): "with small samples, the idea of non-informative priors is more myth than reality (. . .)." The terminology of informative and non-informative priors can therefore be confusing (see also <ref type="bibr">Bainter, 2017, p. 596</ref>). In addition, different software programs use different default priors (see Table <ref type="table" target="#tab_0">1</ref>). <ref type="bibr">van Erp et al. (2018, p. 26</ref>) investigated the performance of multiple default priors and concluded that, especially with small samples, all investigated default priors performed very differently, and "that there is not one default prior that performed consistently better than the other priors (. . .)."</p><p>The choice of software could thus unintentionally influence the results of a study (see e.g., <ref type="bibr" target="#b15">Holtmann et al., 2016)</ref>, which is problematic if one is not aware of this. Note that we are not advocating against default priors in general. Default priors can be suitable-even when samples are small-in cases where all values in the prior distribution are reasonable and can occur in the data (for example values around 100,000 or 200,000 are realistic in housing price data, see e.g., LeGower and Walsh, 2017). However, the use of default priors is problematic when researchers assume they let "the data speak" while in reality they "let the default priors speak, " meaning that the priors can heavily impact the results without one being aware of this.</p><p>In the next section, we discuss the Shiny app that we developed to demonstrate in an example the possible informative behavior of default priors when the sample is small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHINY APP: THE IMPACT OF DEFAULT PRIORS</head><p>We have created a Shiny app that serves as an educational tool that can be used to learn more about the impact of default priors in Bayesian SEM. It can be found online via <ref type="url" target="https://osf.io/m6byv">https://osf.io/m6byv</ref>, together with supplementary files and R code to reproduce the app. In addition, we have created a lesson plan (available for download in the app) to support the educational focus of the app. The app consists of three pages: (1) a page where users can interactively explore the impact of prior settings and sample size on a Bayesian latent growth model (see Figure <ref type="figure">2</ref>), (2) an overview of the prior specifications used in the app, and (3) a list of further resources to learn more about various aspects of Bayesian SEM. The main, interactive, page includes a menu that walks users through selecting their sample size, prior specification settings, and running the model a first time and a second time with a doubled number of iterations (in line with the WAMBS checklist of <ref type="bibr" target="#b8">Depaoli and van de Schoot, 2017)</ref>. The models in the Shiny Threshold N(0, 10 10 ) N(0, 3.16)</p><p>Default priors corresponding to Mplus version 8.4 (see <ref type="bibr" target="#b0">Asparouhov and Muthén, 2010)</ref>, and blavaan version 0.3-8 (see <ref type="bibr" target="#b29">Merkle, 2019)</ref>. Prior distributions in Mplus are placed on the variance, while the prior distributions in blavaan are by default placed on the precisions (the inverse of the variance) unless stated otherwise. Abbreviations in order of appearance: N, Normal distribution with hyperparameters mean µ and variance σ 2 ; I, Identity Matrix; IG, Inverse Gamma; G, Gamma; IW, Inverse Wishart; W, Wishart; B, Beta distribution. 1 The prior for the observed and latent variable parameters is placed on the standard deviation (the square root of the variance).</p><p>2 In blavaan, three MCMC packages can be used (target = "stan," "stanclassic" and "jags") for the analysis. For all the MCMC packages, the same default priors are specified, with one exception: for target = "jags," a different prior for the covariance is specified.</p><p>FIGURE 2 | Main page of the Shiny app, where users can interactively explore the impact of prior settings and sample size in a Bayesian Latent Growth Model.</p><p>app were externally run using the software Mplus <ref type="bibr">(Muthén and</ref><ref type="bibr" target="#b31">Muthén, (1998-2017)</ref>) to enhance the user experience<ref type="foot" target="#foot_5">foot_5</ref> . The main window on the page has five tabs that can be used to ( <ref type="formula">1</ref>) see what model is estimated, (2) check convergence of the model using the potential scale reduction factor (PSFR; <ref type="bibr" target="#b13">Gelman and Rubin, 1992)</ref>, examine the precision of the posterior samples with the effective sample size (ESS), (3) look at plots of the prior, likelihood, and posterior and trace plots, (4) inspect parameter estimates, (5) access the lesson plan.</p><p>The Model, Sample Sizes, and Priors Used in the Shiny App</p><p>The model, sample sizes, and prior settings used in the Shiny app are based on <ref type="bibr" target="#b35">Smid et al. (2019a)</ref>. Specifically, the model is a latent growth model (LGM) with a latent intercept and linear slope, four time points, and a continuous long-term variable (i.e., distal outcome) that is predicted by the latent intercept and slope (see Figure <ref type="figure" target="#fig_1">3</ref>). A long-term variable is a variable that is collected at a wave of assessment that occurs long after the other waves of assessment in the LGM. An example of a distal outcome is young adult levels of depression that are predicted by conduct and emotional problems at ages 4-16 <ref type="bibr" target="#b20">(Koukounari et al., 2017)</ref>. Users can select one of three sample sizes: 26, 52, 325, which represent a very small, small, and relatively large sample for the model of interest, which has 13 unknown parameters.</p><p>Three different prior specifications are included in the app: one specification using software default priors and two specifications with increasing numbers of thoughtful priors. The default priors that we selected are those specified in Mplus <ref type="bibr">(Muthén and</ref><ref type="bibr" target="#b31">Muthén, (1998-2017)</ref>) and are called "Mplus default priors" in the Shiny app. The two thoughtful prior specifications, called "Partial Thoughtful Priors" and "Full Thoughtful Priors, " were taken from <ref type="bibr" target="#b36">Smid et al. (2019b)</ref>, details of which are included on the second page of the Shiny app. In short, "Partial Thoughtful Priors" includes informative priors for the mean of the intercept and slope of the LGM, the regression coefficients, and the intercept of the distal outcome. "Full Thoughtful Priors" includes informative priors on all parameters in the model, with the exception of the residual variances. These two specifications reflect scenarios where a researcher has access to prior knowledge regarding some or most of the parameters in the model.</p><p>The specific hyperparameter values of the thoughtful priors (e.g., where the center of the prior is and how narrow the prior is) in the example used in the app are somewhat arbitrary because they are based on a simulation study. Specifically, the priors are all centered around the (known) population values and the width of the priors is based on the width of the posterior distribution of the analysis done with Mplus default priors. This approach is most closely related to a type of prior specification called data dependent prior specification <ref type="bibr" target="#b28">(McNeish, 2016b)</ref>, where an initial analysis using default priors or frequentist estimation methods provides the values for the prior hyperparameters. In applied research, data dependent priors are controversial, as the researcher technically double-dips by using their data to specify the priors that are subsequently used to analyze their data <ref type="bibr" target="#b5">(Darnieder, 2011)</ref>. To resolve this issue, researchers could split their data in half and base the prior specification for the Bayesian analysis on the results of a frequentist analysis using 50% of the total sample. As this approach would further reduce the sample size for the final analysis, this approach for specifying priors may not be feasible with small sample sizes.</p><p>The two thoughtful prior specifications included in the app are just two examples of how thoughtful priors can be included in Bayesian SEM. Other sources that can be used for specifying thoughtful priors include previous research, meta-analyses, or knowledge from experts in the field (for in-depth discussions of these topics, we refer to <ref type="bibr" target="#b47">Zondervan-Zwijnenburg et al., 2017;</ref><ref type="bibr" target="#b25">Lek and van de Schoot, 2018;</ref><ref type="bibr" target="#b40">van de Schoot et al., 2018)</ref>. Even if prior knowledge is not readily available, researchers can think about impossible and implausible values for the parameters and specify prior distributions that only contain information about the typical range of the parameters. To illustrate this idea, imagine that the distal outcome of the LGM shown in Figure <ref type="figure" target="#fig_1">3</ref> was measured with a questionnaire that had a range from 0 to 20. A researcher could use this information to specify a prior for the intercept of the distal outcome that makes values outside of that range highly improbable [e.g., N(10, 15)]. For some parameters, it may be challenging to identify prior hyperparameters that will exclude implausible values. For example, the inverse Gamma distribution is often used as a prior for the (residual) variance parameters. The parameters of this distribution, called shape and scale, are not as easily interpreted and thoughtfully specified as the mean and variance of a normal distribution. Fortunately, methods for specifying thoughtful prior hyperparameters for the inverse Gamma distribution have been suggested (e.g., <ref type="bibr" target="#b46">Zitzmann et al., 2020)</ref>. Alternatively, researchers may decide to switch to a different distribution altogether <ref type="bibr" target="#b42">(van Erp et al., 2018)</ref>. Examples include the half-Cauchy prior <ref type="bibr" target="#b11">(Gelman, 2006;</ref><ref type="bibr" target="#b33">Polson and Scott, 2012)</ref> or reference priors such as Jeffrey's prior <ref type="bibr" target="#b38">(Tsai and Hsiao, 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Using the Shiny App as a Teacher</head><p>Since this Shiny app was explicitly developed to serve as an educational tool, we have created a worksheet and answer key that can be downloaded directly in the app itself 5 . In addition, it is possible within our app to export all plots and tables created. These can be used in answering the questions on the worksheet. By making students aware of the impact of relying on default settings when samples are small, we hope to teach students about the importance of specifying suitable prior distributions and to contribute to the responsible use of Bayesian SEM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GUIDELINES: HOW TO RECOGNIZE A (MIS)BEHAVING PRIOR?</head><p>To formulate suitable prior distributions and to check afterward whether the priors are "behaving, " information is needed about the reasonable range of values for the parameters in the model. This information can be based on previous studies, the scale or questionnaire that is used, or expert knowledge from the field. In our reading list (available via <ref type="url" target="https://osf.io/pnmde">https://osf. io/pnmde</ref>), we provide an overview of relevant literature on how to specify suitable priors based on multiple sources of information. Below, we discuss four ways to identify a (mis)behaving prior after conducting a Bayesian analysis (see also Table <ref type="table" target="#tab_1">2</ref>), by inspecting for all parameters the (a) effective sample size, (b) trace plots, (c) prior-likelihood-posterior distributions, and (d) the posterior standard deviation and 95% highest posterior density.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effective Sample Size</head><p>Inspecting the effective sample size (ESS) of each parameter in the model is a good first step in the search for misbehaving priors. The ESS represents the number of independent samples that have the same precision as the total number of samples in the posterior chains <ref type="bibr" target="#b14">(Geyer, 1992)</ref>. The ESS is closely related to the concept of autocorrelation, where current draws from the posterior distribution are dependent on previous draws from the posterior 5 The worksheet can be found on the main page under the fifth tab ("Lesson Plan"). Prior-likelihood-posterior comparison -Substantial deviation between prior, likelihood and/or posterior: e.g., a posterior that is much narrower or wider than the prior and likelihood, while taking into account the amount of information in the prior (i.e., level of informativeness of the prior) and in the likelihood (i.e., sample size)</p><p>Posterior SD and 95% HPD -Much smaller or larger posterior SD or 95% HPD than expected based on the amount of information in the prior (i.e., level of informativeness of the prior) and in the likelihood (i.e., sample size)</p><p>distribution. Autocorrelation is undesirable as it increases the uncertainty in posterior estimates. If autocorrelation within the chains is low, then the ESS approaches the total number of samples in the posterior chains, and the posterior distribution will be more precise and more likely to approximate the parameter estimate well <ref type="bibr" target="#b45">(Zitzmann and Hecht, 2019)</ref>. If autocorrelation within the chains is high, a larger number of samples will be necessary to reach an adequate ESS. A low ESS can be the first indicator that there might be a misbehaving prior.</p><p>Multiple recommendations have been made about how to assess whether the ESS is too low: Zitzmann and Hecht ( <ref type="formula">2019</ref>) recommend that ESSs should ideally be over 1,000 to ensure that there is enough precision in the chain. It is also possible to compute a lower bound for the number of effective samples required using a desired level of precision and the credible interval level of interest <ref type="bibr" target="#b43">(Vats et al., 2019;</ref><ref type="bibr" target="#b9">Flegal et al., 2020)</ref>. Finally, it can also be helpful to look at the ratio of the ESS to the total number of samples, where a ratio &lt; 0.1 indicates that there are high levels of autocorrelation in the chains (although this does not necessarily indicate that the posterior distribution is not precise; <ref type="bibr" target="#b10">Gabry et al., 2019)</ref>.</p><p>A low ESS can serve as the first clue that something might be wrong, but even if all ESSs appear acceptable, plots and posterior estimates should be inspected to further confirm if priors are behaving.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trace Plots</head><p>Three characteristics of a trace plot can indicate a misbehaving prior. First, the shape of the trace plot: If the multiple chains are well-behaved, the chains should resemble the hungry caterpillar after 6 days of eating (see Figure <ref type="figure" target="#fig_2">4A</ref>). A misbehaving prior can result in trace plots that exhibit spikes, closely resembling alien communication captured in a sci-fi movie (Figure <ref type="figure" target="#fig_2">4C</ref>). Second, do the values that are covered by the posterior make sense for this parameter, or is the y-axis stretched to cover unrealistic values? Even when subtle spikes are present (Figure <ref type="figure" target="#fig_2">4B</ref>), the y-axis range could show that the chains are drawing improbable values from the posterior distribution and should be given extra attention. Third, a lack of overlap of the chains can indicate a misbehaving prior. When the chains do not overlap, it indicates that they are sampling from different parts of the posterior distribution and are not converging toward the same location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prior-Likelihood-Posterior Comparison</head><p>One important aspect of our Shiny app is that the prior, likelihood, and posterior distributions are visualized to make comparisons across different priors and sample size settings easy<ref type="foot" target="#foot_6">foot_6</ref> . When there is a substantial deviation between the prior, likelihood and posterior distributions, results should be interpreted with caution, especially when the sample size is small. Researchers should decide how much impact of the prior and likelihood on the posterior is desirable. Is it preferable that the posterior is a compromise between the prior and likelihood, or that the posterior is dominated by one of two? For instance, when the likelihood and the prior deviate a lot, one might not want to trust the posterior results<ref type="foot" target="#foot_7">foot_7</ref> . In case of small samples, the results might especially be driven by the prior distributions. This is only desirable when researchers trust the specified prior distributions, not when they are defaults of the software program.</p><p>Figure <ref type="figure" target="#fig_2">4</ref> shows the prior-likelihood-posterior comparison for three parameters. Although the prior distributions (dashed lines) look completely flat, default prior distributions were used for all parameters. In Figure <ref type="figure" target="#fig_2">4A</ref>, the posterior (solid line) closely follows the likelihood distribution (dotted line), which is desirable here because the default prior (dashed line) is specified and we do not want it to impact the posterior much. In Figures <ref type="figure" target="#fig_2">4B,</ref><ref type="figure">C</ref>, the posteriors seem to have tails that are too fat (kurtotic) compared to the likelihood distribution and the flat default priors, and results should therefore be inspected further.</p><p>Posterior SD and 95% HPD</p><p>The posterior standard deviation (SD) and 95% credible (or highest posterior density; HPD) interval can be inspected to assess whether the estimates are unusually certain or uncertain.</p><p>Uncertainty is demonstrated by a large posterior SD and a wide 95% HPD. Available information about reasonable values for the parameters as well as the amount of information in the prior and likelihood should be used to assess whether the level of (un)certainty of the posterior is reasonable. For instance, in Figure <ref type="figure" target="#fig_2">4C</ref>, a posterior SD of 94.64 is reported, which is a much higher value than would be expected for a regression estimate and implies that some very extreme values were likely sampled from the posterior. This level of uncertainty is also reflected by the extreme spikes in the trace plot and the kurtotic posterior distribution. The parameters depicted in Figure <ref type="figure" target="#fig_2">4</ref> illustrate that the combination of a non-informative prior and a small sample size does not always lead to problems across all parameters in a model. It is important to note that even if it appears that the priors of the main parameter(s) of interest are behaving well, a misbehaving prior that is located elsewhere in the model may lead to inaccuracies in the posterior estimates of the main parameters. For example, in a multilevel SEM with a between-level covariate effect, the between-level variance estimate may not be of substantive interest. However, a supposedly non-informative prior [IG(0.001, 0.001)] for the between-level variance parameter can turn into a misbehaving prior when the amount of variance located at the between-level is large <ref type="bibr" target="#b7">(Depaoli and Clifton, 2015)</ref>. In a simulation study, <ref type="bibr" target="#b7">Depaoli and Clifton (2015)</ref> showed that this misbehaving prior resulted in a biased posterior estimate of the between-level covariate effect. A researcher who only inspected the trace plot for the betweenlevel covariate effect may not have realized that their results were negatively affected by a prior placed on between-level variance parameter. For that reason, it is critical to always examine all parameters in the SEM.</p><p>What to Do If You Suspect a Misbehaving Prior?</p><p>When one of the trace plots, prior-likelihood-posterior distribution plots, posterior SDs or 95% HPDs show signs of a misbehaving prior, results should not be trusted, and researchers should proceed with caution. Unfortunately, we cannot provide rules of thumb for when these indicators of misbehavior become problematic. It depends on the specified prior, the data, the parameter, the model of interest, and the personal judgment of the researcher. A sensitivity analysis can help assess the impact of the specified prior distributions on the posterior (see <ref type="bibr" target="#b8">Depaoli and van de Schoot, 2017;</ref><ref type="bibr" target="#b42">van Erp et al., 2018)</ref>. Again, it is up to the researcher to decide whether a certain amount of impact of the prior is desirable or not. Therefore, Bayesian SEM should only be used with small samples when researchers are able and willing to make these types of decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reporting of Bayesian SEM</head><p>Although a rich body of literature exists on good practice of how to perform and what to report for a Bayesian analysis (see e.g., <ref type="bibr">Kruschke, 2015, pp. 721-725;</ref><ref type="bibr" target="#b8">Depaoli and van de Schoot, 2017)</ref>, we want to stress the importance of transparency and reporting every decision. We advise to always provide an (online) appendix in which is explained in detail which priors are specified and why these specific priors are chosen. For more literature and examples on reporting Bayesian SEM, we refer to our reading list on <ref type="url" target="https://osf.io/pnmde">https: //osf.io/pnmde</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AN ILLUSTRATION: THE IMPACT OF DEFAULT PRIORS</head><p>To illustrate the impact of prior settings and sample size-and the informative behavior of default priors with a small sample sizewe retrieved the trace plots, prior-likelihood-posterior plots, and posterior SDs from the Shiny app for a single parameter: the regression effect of the distal outcome regressed on the linear slope (β 2 in Figure <ref type="figure" target="#fig_1">3</ref>). The plots (Figure <ref type="figure" target="#fig_3">5</ref>) show signs of a misbehaving prior when samples are small (n = 26, or 52 for this model) when default priors are used. Specifically, the trace plots exhibit spikes that reach highly improbable values for the regression coefficient, the plots have a stretched y-axis, and show chains that are not overlapping. Moreover, the priorlikelihood-posterior plots for the two small sample sizes show that the posterior distribution (solid line) is wider than the likelihood estimate (dotted line). Overall, the plots displayed in Figure <ref type="figure" target="#fig_3">5</ref> show that default priors, which are assumed to be non-informative, can impact the results when samples are small. Options for improving model estimation include increasing the sample size or specifying suitable priors for the parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUMMARY</head><p>In this tutorial paper, we discussed the risks associated with default priors in Bayesian SEM when samples are small. We described the dangers of the defaults as a combination of three factors: (a) the relatively larger impact of the prior on the posterior when samples are small, (b) the wide distribution of default priors that often contain unrealistic values, and (c) the false belief that default priors are non-informative priors. We demonstrated an interactive Shiny app, in which users can investigate the impact of priors and sample size on model results. The Shiny app can also be used to teach students about responsible use of Bayesian SEM with small samples. In this paper, we showed that default priors can act as highly informative priors when samples are small. We provided an overview of relevant literature (available via <ref type="url" target="https://osf.io/pnmde">https://osf.io/pnmde</ref>) on how to specify suitable priors based on multiple sources of information. We discussed how to recognize a misbehaving prior by inspecting (a) the effective sample sizes, (b) trace plots, (c) the comparison of prior-likelihood-posterior distributions, and (d) posterior standard deviation and 95% highest posterior densities.</p><p>It is important to note that we are not arguing that researchers are solely responsible for breaking away from their reliance on default priors. There are several strategies that could be employed to help researchers improve their decisions regarding prior specification. A simple way in which the use of Bayesian methods can be improved is by making available educational tools, such as the App introduced in this paper, to a broad audience of researchers. More generally, software developers could implement notifications that nudge users to check the impact of their prior distributions through techniques proposed in the current paper (e.g., flag low ESSs and suggest inspection of trace plots). Another opportunity to intervene and improve occurs during the peer-review process. Reviewers should closely examine the decisions authors have made regarding their prior specification and intervene if the decisions made by the authors were inappropriate. In such a case, a reviewer can advise that major revisions are in order to ensure that Bayesian methods were applied appropriately.</p><p>Bayesian SEM should only be used with small samples when information is available about the reasonable range of values for all parameters in the model. This information is necessary to formulate suitable prior distributions and to check afterward whether the priors are "behaving." It is our hope that this tutorial paper helps spread awareness that the use of Bayesian estimation is not a quick solution to small sample problems in SEM, and that we encourage researchers to specify suitable prior distributions and carefully check the results when using Bayesian SEM with small samples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc>FIGURE 1 | Examples of prior, likelihood and posterior distributions under small (A), medium (B), and large (C) sample sizes. The posterior distribution is dominated by the prior under the small sample size (A), and dominated by the likelihood under the large sample size (C).</figDesc><graphic coords="3,107.91,69.02,377.40,120.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 3 |</head><label>3</label><figDesc>FIGURE 3 | The Latent Growth Model with a distal (long-term) outcome variable that is used in the Shiny app, including population values (model and population values based on Smid et al., 2019a).</figDesc><graphic coords="5,97.11,394.13,399.00,281.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 4 |</head><label>4</label><figDesc>FIGURE 4 | Traceplots; prior, likelihood, posterior plots; posterior standard deviation (SD) and 95% highest posterior density interval (HPD) for three parameters: mean intercept (A), residual variance of the distal outcome (B) and the regression effect of the slope on the distal outcome (C) under sample size n = 26 and Mplus default priors (examples retrieved from the Shiny app). *The Mplus default prior for residual variance parameters is IG(-1, 0), which is improper (i.e., does not integrate to 1) and has a constant density of 1 on the interval (-∞, ∞) (Asparouhov and Muthén, 2010).</figDesc><graphic coords="7,55.20,348.13,482.82,308.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 5 |</head><label>5</label><figDesc>FIGURE 5 | Trace plots; prior, likelihood, posterior plots; posterior standard deviation (SD) and 95% highest posterior density intervals (HPD) for regression coefficient β 2 under sample sizes n = 26, 52, 325 when Mplus default priors and partial thoughtful priors are specified. (A,B,E,F,I,J) Trace plot. (C,D,G,H,K,L) Prior, Likelihood, Posterior Plot.</figDesc><graphic coords="9,64.95,69.02,463.32,490.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,74.61,318.17,444.00,347.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 |</head><label>1</label><figDesc>Overview of default prior distributions of main parameters for the software program Mplus and the use of Mplus, JAGS and Stan via the R package blavaan.</figDesc><table><row><cell>Mplus (v. 8.4) Priors on</cell><cell>Blavaan (v. 0.3-8) Priors on</cell></row><row><cell>variance σ 2</cell><cell>precision 1/σ 2 or standard</cell></row><row><cell></cell><cell>deviation σ denoted by (SD)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2 |</head><label>2</label><figDesc>Possible signs of "misbehaving" priors.</figDesc><table><row><cell cols="2">Effective sample size</cell></row><row><cell>-</cell><cell>Low effective sample size (i.e., &lt; 1, 000) can be a first indication that the priors are problematic</cell></row><row><cell cols="2">Trace plots</cell></row><row><cell>-</cell><cell>Spikes: shape of alien communication captured in a sci-fi movie instead of a fat caterpillar</cell></row><row><cell>-</cell><cell>Highly improbable values for the parameter on the y-axis based on information about the</cell></row><row><cell></cell><cell>reasonable range of values about parameters</cell></row><row><cell>-</cell><cell>Chains that are not overlapping</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>There are many other reasons why researchers use Bayesian SEM, such as the ability to estimate models that are not identified in the frequentist framework or to resolve issues with missing data, non-linearity, and non-normality (see e.g.,Wagenmakers  et al.,  </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2008;Kaplan, 2014, pp. 287-290;<ref type="bibr" target="#b41">van de Schoot et al., 2017)</ref>. However, the focus of this paper is the use of Bayesian estimation to deal with small samples.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2"><p>Frontiers in Psychology | www.frontiersin.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3"><p>December 2020 | Volume 11 | Article 611963</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_4"><p>Hyperparameters are the parameters of prior distributions, such as the mean and variance of the Normal distribution, and the alpha and beta in inverse gamma.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_5"><p>This popular, user-friendly software program for estimating Bayesian SEM has made it extremely easy to be a naive user of Bayesian statistics (one only needs to include the line "Estimator = Bayes;" in the input file).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6"><p>For details on how we visualized priors, likelihood and posterior distributions, we refer to the OSF (https://osf.io/m6byv).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7"><p>For readers interested in the impact of so-called prior-data conflict, we refer to simulation studies by<ref type="bibr" target="#b6">Depaoli (2014);</ref><ref type="bibr" target="#b15">Holtmann et al. (2016), and</ref><ref type="bibr" target="#b35">Smid et al. (2019a)</ref>.</p></note>
		</body>
		<back>

			<div type="funding">
<div><head>FUNDING</head><p>SS was supported by a grant from the <rs type="funder">Netherlands</rs> organization for scientific research: <rs type="grantNumber">NWO-VIDI-452-14-006</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JxYAYgg">
					<idno type="grant-number">NWO-VIDI-452-14-006</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AUTHOR CONTRIBUTIONS</head><p>SS designed the tutorial manuscript and shiny app, and further developed the idea of the shiny app with SW. SW worked out the code for the shiny app with input and feedback from SS. SS took the lead in writing the manuscript. SW wrote the "Shiny App" section and provided feedback on the manuscript. Both authors contributed to the article and approved the submitted version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest:</head><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<ptr target="http://www.statmodel.com/download/BayesAdvantages18.pdf" />
		<title level="m">Bayesian Analysis of Latent Variable Models Using Mplus</title>
		<imprint>
			<date type="published" when="2010-10-06">2010. accessed October 6, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bayesian estimation for item factor analysis models with sparse categorical indicators</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Bainter</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2017.1342203</idno>
	</analytic>
	<monogr>
		<title level="j">Multivar. Behav. Res</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="593" to="615" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">How the Shape of a Weakly Informative Prior Affects Inferences</title>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<ptr target="https://mc-stan.org/users/documentation/case-studies/weakly_informative_shapes.html" />
		<imprint>
			<date type="published" when="2017-10-06">2017. accessed October 6, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nonconvergence, improper solutions, and starting values in lisrel maximum likelihood estimation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boomsma</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294248</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="229" to="242" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Estimation of the latent mediated effect with ordinal data using the limited-information and Bayesian full-information approaches</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-014-0526-3</idno>
	</analytic>
	<monogr>
		<title level="j">Behav. Res. Methods</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1260" to="1273" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bayesian Methods for Data-Dependent Priors. Doctoral dissertation</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Darnieder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<pubPlace>Columbus, OH</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Ohio State University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The impact of &quot;inaccurate&quot; informative priors for growth parameters in Bayesian growth mixture modeling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2014.882686</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="239" to="252" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A bayesian approach to multilevel structural equation modeling with continuous and dichotomous outcomes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Clifton</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2014.937849</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="327" to="351" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving transparency and replication in Bayesian statistics: the WAMBS-checklist</title>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000065</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Methods</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="240" to="261" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">mcmcse: Monte Carlo Standard Errors for MCMC. R Package Version 1.4-1</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Flegal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dai</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=mcmcse" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Visualization in Bayesian workflow</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<idno type="DOI">10.1111/rssa.12378</idno>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. A Stat. Soc</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="389" to="402" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Prior distributions for variance parameters in hierarchical models (Comment on Article by Browne and Draper)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<idno type="DOI">10.1214/06-ba117a</idno>
	</analytic>
	<monogr>
		<title level="j">Bayesian Anal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="515" to="534" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Dunson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<title level="m">Bayesian Data Analysis, 3rd Edn</title>
		<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inference from iterative simulation using multiple sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<idno type="DOI">10.1214/ss/1177011136</idno>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="457" to="472" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Practical Markov chain monte carlo Author(s)</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Geyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="473" to="483" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comparison of ML, WLSMV, and Bayesian methods for multilevel structural equation models in small samples: a simulation study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Holtmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lochner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eid</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2016.1208074</idno>
	</analytic>
	<monogr>
		<title level="j">Multivar. Behav. Res</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="661" to="680" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Bayesian Statistics for the Social Sciences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kaplan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>The Guilford Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The selection of prior distributions by formal rules</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wasserman</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1996.10477003</idno>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="1343" to="1370" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Kline</surname></persName>
		</author>
		<title level="m">Principles and Practice of Structural Equation Modeling, 4th Edn</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Guilford Press</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian statistics in educational research: a look at the current state of affairs</title>
		<author>
			<persName><forename type="first">C</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<idno type="DOI">10.1080/00131911.2017.1350636</idno>
	</analytic>
	<monogr>
		<title level="j">Educ. Rev</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pathways from maternal depression to young adult offspring depression: an exploratory longitudinal mediation analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Koukounari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stringaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Maughan</surname></persName>
		</author>
		<idno type="DOI">10.1002/mpr.1520</idno>
	</analytic>
	<monogr>
		<title level="j">Int. J. Methods Psychiatr. Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">1520</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan, 2nd Edn</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Academic Press</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The time has come Bayesian methods for data analysis in the organizational sciences</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Aguinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Joo</surname></persName>
		</author>
		<idno type="DOI">10.1177/1094428112457829</idno>
	</analytic>
	<monogr>
		<title level="j">Organ. Res. Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="722" to="752" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Evaluation of the bayesian and maximum likelihood approaches in analyzing structural equation models with small sample sizes</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-Y</forename><surname>Song</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327906mbr3904_4</idno>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behav. Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="653" to="686" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Promise scholarship programs as place-making policy: evidence from school enrollment and housing prices</title>
		<author>
			<persName><forename type="first">M</forename><surname>Legower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Walsh</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jue.2017.06.001</idno>
	</analytic>
	<monogr>
		<title level="j">J. Urban Econ</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="74" to="89" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Development and evaluation of a digital expert elicitation method aimed at fostering elementary school teachers&apos; diagnostic competence</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<idno type="DOI">10.3389/feduc.2018.00082</idno>
	</analytic>
	<monogr>
		<title level="j">Front. Educ</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">82</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Statistical Rethinking: A Bayesian Course with Examples in R and Stan</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mcelreath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioca Raton</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Taylor &amp; Francis Group</publisher>
			<pubPlace>FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On using bayesian methods to address small sample problems</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcneish</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2016.1186549</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="750" to="773" />
			<date type="published" when="2016">2016a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Using data-dependent priors to mitigate small sample bias in latent growth models: a discussion and illustration using Mplus</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mcneish</surname></persName>
		</author>
		<idno type="DOI">10.3102/1076998615621299</idno>
	</analytic>
	<monogr>
		<title level="j">J. Educ. Behav. Stat</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="27" to="56" />
			<date type="published" when="2016">2016b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Merkle</surname></persName>
		</author>
		<ptr target="https://faculty.missouri.edu/~{}merklee/blavaan/prior.html" />
		<imprint>
			<date type="published" when="2019-10-06">2019. accessed October 6, 2020</date>
		</imprint>
	</monogr>
	<note>Prior Distributions. Available online at</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">blavaan: Bayesian structural equation models via Parameter expansion</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Softw</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">K</forename><surname>Muthén</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthén</surname></persName>
		</author>
		<title level="m">Mplus User&apos;s Guide, 8th Edn</title>
		<meeting><address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Muthén &amp; Muthén</publisher>
			<date type="published" when="1998">1998-2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evaluating small sample approaches for model test statistics in structural equation modeling</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nevitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15327906MBR3903_3</idno>
	</analytic>
	<monogr>
		<title level="j">Multivar. Behav. Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="439" to="478" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the half-Cauchy prior for a global scale parameter</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Polson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Scott</surname></persName>
		</author>
		<idno type="DOI">10.1214/12-ba730</idno>
	</analytic>
	<monogr>
		<title level="j">Bayesian Anal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="887" to="902" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<orgName type="collaboration">R Core Team</orgName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint>
			<date type="published" when="2018-10-06">2018. accessed October 6, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Predicting a distal outcome variable from a latent growth model: ML versus Bayesian estimation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Smid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2019.1604140</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2019">2019a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bayesian versus frequentist Estimation for structural equation models in small sample contexts: a systematic review</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Smid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcneish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miočević</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2019.1577140</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Stan Modeling Language: User&apos;s Guide and Reference Manual. Version 2.17.0. Stan Development Team</title>
		<author>
			<persName><forename type="first">Stan</forename><surname>Development</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Team</forename></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2015.1044653</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Computation of reference Bayesian inference for variance components in longitudinal studies</title>
		<author>
			<persName><forename type="first">M.-Y</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Hsiao</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00180-007-0100-x</idno>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="587" to="604" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Analyzing small data sets using Bayesian estimation: the case of posttraumatic stress symptoms following mechanical ventilation in burn survivors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Broere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Perryck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zondervan-Zwijnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Van Loey</surname></persName>
		</author>
		<idno type="DOI">10.3402/ejpt.v6.25216</idno>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Psychotraumatol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">25216</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bayesian PTSD-trajectory analysis with informed priors based on a systematic literature search and expert elicitation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sijbrandij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Olff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">E</forename><surname>Van Loey</surname></persName>
		</author>
		<idno type="DOI">10.1080/00273171.2017.1412293</idno>
	</analytic>
	<monogr>
		<title level="j">Multivar. Behav. Res</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="267" to="291" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A systematic review of Bayesian papers in psychology: the last 25 years</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zondervan-Zwijnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000100</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Methods</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="217" to="239" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Prior sensitivity analysis in default Bayesian structural equation modeling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Van Erp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mulder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Oberski</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000162</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol. Methods</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="363" to="388" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multivariate output analysis for Markov chain monte carlo</title>
		<author>
			<persName><forename type="first">D</forename><surname>Vats</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Flegal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1093/biomet/asz002</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="321" to="337" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Bayesian evaluation of informative hypotheses</title>
		<author>
			<persName><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lodewyckx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Iverson</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-0-387-09612-4_9</idno>
	</analytic>
	<monogr>
		<title level="m">Statistics for Social and Behavioral Sciences</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Hoijtink</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Klugkist</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Boelen</surname></persName>
		</editor>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="181" to="207" />
		</imprint>
	</monogr>
	<note>Bayesian versus frequentist inference</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Going beyond convergence in Bayesian estimation: why precision matters too and how to assess it</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hecht</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2018.1545232</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="646" to="661" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the performance of Bayesian approaches in small samples: a comment on</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zitzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lüdtke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Robitzsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mcneish</forename><surname>Smid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mioèeviae</forename><surname>Van De Schoot</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2020.1752216</idno>
	</analytic>
	<monogr>
		<title level="j">Struct. Equ. Modeling</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>Epub ahead of print</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Where do priors come from? Applying guidelines to construct informative priors in small sample research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zondervan-Zwijnenburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peeters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Depaoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van De Schoot</surname></persName>
		</author>
		<idno type="DOI">10.1080/15427609.2017.1370966</idno>
	</analytic>
	<monogr>
		<title level="j">Res. Hum. Dev</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="305" to="320" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
